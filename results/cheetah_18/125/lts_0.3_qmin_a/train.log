{"episode_reward": 0.0, "episode": 1.0, "duration": 17.1947660446167, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.4978928565979004, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.220036396377283, "critic_loss": 0.037874715982663974, "actor_loss": -14.928048493824907, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 60.92745351791382, "step": 3000}
{"episode_reward": 64.23745942424972, "episode": 4.0, "batch_reward": 0.16045559441298246, "critic_loss": 0.06361179744452237, "actor_loss": -16.662054195404053, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.853498935699463, "step": 4000}
{"episode_reward": 126.25164238500872, "episode": 5.0, "batch_reward": 0.15674749392271042, "critic_loss": 0.06055935167148709, "actor_loss": -14.574347478866578, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.92585015296936, "step": 5000}
{"episode_reward": 68.08745680806562, "episode": 6.0, "batch_reward": 0.1510622065216303, "critic_loss": 0.05644693886116147, "actor_loss": -14.833837414741517, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.884276390075684, "step": 6000}
{"episode_reward": 161.06760089923833, "episode": 7.0, "batch_reward": 0.1530312938094139, "critic_loss": 0.05564099096693099, "actor_loss": -15.454408197402953, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89139723777771, "step": 7000}
{"episode_reward": 158.95592721051904, "episode": 8.0, "batch_reward": 0.14555089899897575, "critic_loss": 0.05853820147737861, "actor_loss": -14.77524427986145, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93400478363037, "step": 8000}
{"episode_reward": 62.95686498862023, "episode": 9.0, "batch_reward": 0.1390067251101136, "critic_loss": 0.10158051048964262, "actor_loss": -15.727192512512207, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.886719942092896, "step": 9000}
{"episode_reward": 145.0729633425792, "episode": 10.0, "batch_reward": 0.136568769313395, "critic_loss": 0.12207176424190402, "actor_loss": -14.812590909957885, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93440556526184, "step": 10000}
{"episode_reward": 53.482978237086385, "episode": 11.0, "batch_reward": 0.12715918023884296, "critic_loss": 0.1136220344081521, "actor_loss": -15.39787186050415, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.22013974189758, "step": 11000}
{"episode_reward": 49.483884182669385, "episode": 12.0, "batch_reward": 0.12247337210923433, "critic_loss": 0.14183402748405932, "actor_loss": -15.045506504058839, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.92696499824524, "step": 12000}
{"episode_reward": 75.58393717337955, "episode": 13.0, "batch_reward": 0.11624091134220361, "critic_loss": 0.13192995043098926, "actor_loss": -14.78456784248352, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.938617706298828, "step": 13000}
{"episode_reward": 33.07917388295565, "episode": 14.0, "batch_reward": 0.11164047277718782, "critic_loss": 0.13544742029160262, "actor_loss": -14.157121215820313, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.938779592514038, "step": 14000}
{"episode_reward": 59.01326829678403, "episode": 15.0, "batch_reward": 0.1078026867583394, "critic_loss": 0.15380963967740535, "actor_loss": -14.852845247268677, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.919055700302124, "step": 15000}
{"episode_reward": 42.9190777967067, "episode": 16.0, "batch_reward": 0.1024518192447722, "critic_loss": 0.20021838158369065, "actor_loss": -14.58603738975525, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.90705919265747, "step": 16000}
{"episode_reward": 37.39280193403495, "episode": 17.0, "batch_reward": 0.09933627814799548, "critic_loss": 0.20387694458663463, "actor_loss": -14.154120250701904, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91801357269287, "step": 17000}
{"episode_reward": 45.758431205511826, "episode": 18.0, "batch_reward": 0.09648881022259594, "critic_loss": 0.17972387320548297, "actor_loss": -13.683275886535645, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.919764518737793, "step": 18000}
{"episode_reward": 46.970534286300186, "episode": 19.0, "batch_reward": 0.09179512598738074, "critic_loss": 0.17873866517469286, "actor_loss": -14.692217422485351, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.904767751693726, "step": 19000}
{"episode_reward": 32.475180739551455, "episode": 20.0, "batch_reward": 0.08896793287247419, "critic_loss": 0.19124122934788465, "actor_loss": -14.653062677383422, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.929601907730103, "step": 20000}
{"episode_reward": 42.48366327888872, "episode": 21.0, "batch_reward": 0.08707694101706147, "critic_loss": 0.2629748775139451, "actor_loss": -15.260452043533325, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.203941822052, "step": 21000}
{"episode_reward": 38.152661552554854, "episode": 22.0, "batch_reward": 0.08355115036666393, "critic_loss": 0.22361368303745985, "actor_loss": -15.29311170578003, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.929964065551758, "step": 22000}
{"episode_reward": 8.273757094582336, "episode": 23.0, "batch_reward": 0.0813119088858366, "critic_loss": 0.19584798742085696, "actor_loss": -15.189978309631348, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.95425248146057, "step": 23000}
{"episode_reward": 32.18931728996186, "episode": 24.0, "batch_reward": 0.08111154979094863, "critic_loss": 0.2342245502769947, "actor_loss": -15.90037382888794, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.906168460845947, "step": 24000}
{"episode_reward": 91.29470888213812, "episode": 25.0, "batch_reward": 0.08302278105169535, "critic_loss": 0.25692945694178343, "actor_loss": -15.896892965316772, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.927729606628418, "step": 25000}
{"episode_reward": 111.5628849192617, "episode": 26.0, "batch_reward": 0.08374373374134302, "critic_loss": 0.2850867357701063, "actor_loss": -16.099266384124757, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91382145881653, "step": 26000}
{"episode_reward": 108.89394764673891, "episode": 27.0, "batch_reward": 0.08466079657897353, "critic_loss": 0.32524109590053557, "actor_loss": -16.19810227203369, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.933491468429565, "step": 27000}
{"episode_reward": 112.11670679250784, "episode": 28.0, "batch_reward": 0.08287650296837092, "critic_loss": 0.31343259011954067, "actor_loss": -16.21712484550476, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.922536373138428, "step": 28000}
{"episode_reward": 42.00369656069439, "episode": 29.0, "batch_reward": 0.08250233923271298, "critic_loss": 0.3149010097309947, "actor_loss": -16.198627393722536, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.92742943763733, "step": 29000}
{"episode_reward": 38.72157914531699, "episode": 30.0, "batch_reward": 0.08322216199710965, "critic_loss": 0.3009586081430316, "actor_loss": -16.198910934448243, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91108012199402, "step": 30000}
{"episode_reward": 130.88358420226004, "episode": 31.0, "batch_reward": 0.08496641955152154, "critic_loss": 0.3647964697852731, "actor_loss": -16.402693075180053, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.23652243614197, "step": 31000}
{"episode_reward": 141.19893141116134, "episode": 32.0, "batch_reward": 0.08762546230107546, "critic_loss": 0.4547983598858118, "actor_loss": -17.0473175239563, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.890575408935547, "step": 32000}
{"episode_reward": 254.58723641038316, "episode": 33.0, "batch_reward": 0.08920956337824464, "critic_loss": 0.46181778052449224, "actor_loss": -16.957919202804565, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93071222305298, "step": 33000}
{"episode_reward": 32.920246857391184, "episode": 34.0, "batch_reward": 0.08849548010900617, "critic_loss": 0.45758663323521614, "actor_loss": -16.596196489334105, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.9210422039032, "step": 34000}
{"episode_reward": 90.63530458496537, "episode": 35.0, "batch_reward": 0.09027166393399239, "critic_loss": 0.5194332472980022, "actor_loss": -17.27002558898926, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.918840646743774, "step": 35000}
{"episode_reward": 179.43912617417982, "episode": 36.0, "batch_reward": 0.09085184333473444, "critic_loss": 0.5240529016852379, "actor_loss": -17.48495788192749, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.92820119857788, "step": 36000}
{"episode_reward": 48.92253528234126, "episode": 37.0, "batch_reward": 0.09092828366160392, "critic_loss": 0.5279733059257269, "actor_loss": -17.476783521652223, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.92220950126648, "step": 37000}
{"episode_reward": 135.42008022136886, "episode": 38.0, "batch_reward": 0.09366284215822816, "critic_loss": 0.5348429962396621, "actor_loss": -17.625154373168947, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.921921253204346, "step": 38000}
{"episode_reward": 183.28227500748852, "episode": 39.0, "batch_reward": 0.09359482070803642, "critic_loss": 0.5694587275981903, "actor_loss": -17.823508531570436, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.945188283920288, "step": 39000}
{"episode_reward": 79.37973925664566, "episode": 40.0, "batch_reward": 0.09298136371001602, "critic_loss": 0.5534937287569046, "actor_loss": -17.710897706985474, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.910017251968384, "step": 40000}
{"episode_reward": 51.64226263218716, "episode": 41.0, "batch_reward": 0.09291502632200718, "critic_loss": 0.6166448309570551, "actor_loss": -17.624648929595946, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.24023795127869, "step": 41000}
{"episode_reward": 86.42930698996027, "episode": 42.0, "batch_reward": 0.09528068796172738, "critic_loss": 0.666189670830965, "actor_loss": -17.485950757980348, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.880595445632935, "step": 42000}
{"episode_reward": 379.1547273431288, "episode": 43.0, "batch_reward": 0.10007631397247314, "critic_loss": 0.7239585597664118, "actor_loss": -18.13654341506958, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.918256759643555, "step": 43000}
{"episode_reward": 106.05889348150406, "episode": 44.0, "batch_reward": 0.09916700480878353, "critic_loss": 0.6520172534435987, "actor_loss": -18.008071590423583, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.939639568328857, "step": 44000}
{"episode_reward": 63.34497027962443, "episode": 45.0, "batch_reward": 0.10205350238457322, "critic_loss": 0.6802502609044313, "actor_loss": -18.283336055755615, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.889293670654297, "step": 45000}
{"episode_reward": 344.9260310337442, "episode": 46.0, "batch_reward": 0.10503926841914654, "critic_loss": 0.6948801309615373, "actor_loss": -18.832785758972168, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.92975425720215, "step": 46000}
{"episode_reward": 124.58383117642747, "episode": 47.0, "batch_reward": 0.10401211760193109, "critic_loss": 0.6479505596458912, "actor_loss": -18.424658140182494, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.934882879257202, "step": 47000}
{"episode_reward": 68.61681547711862, "episode": 48.0, "batch_reward": 0.10683704148977995, "critic_loss": 0.6598236013650894, "actor_loss": -18.508530185699463, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.877541303634644, "step": 48000}
{"episode_reward": 414.30734345650114, "episode": 49.0, "batch_reward": 0.11268467907607556, "critic_loss": 0.7777070371210575, "actor_loss": -19.190266098022462, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.928773880004883, "step": 49000}
{"episode_reward": 369.35366468387105, "episode": 50.0, "batch_reward": 0.11820848519355058, "critic_loss": 0.7653521033674479, "actor_loss": -19.71027338218689, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91444444656372, "step": 50000}
{"episode_reward": 398.9804889869019, "episode": 51.0, "batch_reward": 0.12265961156785488, "critic_loss": 0.6934471860080957, "actor_loss": -20.093232343673705, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.2412793636322, "step": 51000}
{"episode_reward": 357.5270115007981, "episode": 52.0, "batch_reward": 0.12832729683071376, "critic_loss": 0.7004178264141083, "actor_loss": -20.891311164855956, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.96072244644165, "step": 52000}
{"episode_reward": 413.02076211108556, "episode": 53.0, "batch_reward": 0.13252412836253644, "critic_loss": 0.6680906277894973, "actor_loss": -21.14269967842102, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.937172651290894, "step": 53000}
{"episode_reward": 229.4119597382391, "episode": 54.0, "batch_reward": 0.13494352766871454, "critic_loss": 0.7235266481637954, "actor_loss": -21.175132907867432, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.96326756477356, "step": 54000}
{"episode_reward": 420.91360168248093, "episode": 55.0, "batch_reward": 0.14103603660315275, "critic_loss": 0.6978002348095178, "actor_loss": -21.744927627563477, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.92669367790222, "step": 55000}
{"episode_reward": 419.97904469503413, "episode": 56.0, "batch_reward": 0.14568495374172927, "critic_loss": 0.633317083671689, "actor_loss": -22.263471153259278, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.984508991241455, "step": 56000}
{"episode_reward": 444.31230085605694, "episode": 57.0, "batch_reward": 0.15105215752124787, "critic_loss": 0.634988809749484, "actor_loss": -23.01589220428467, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.932304620742798, "step": 57000}
{"episode_reward": 429.23136217600234, "episode": 58.0, "batch_reward": 0.1539559562727809, "critic_loss": 0.6194861305058003, "actor_loss": -22.90298348236084, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.906148195266724, "step": 58000}
{"episode_reward": 118.1872914638951, "episode": 59.0, "batch_reward": 0.15464659097790717, "critic_loss": 0.6340182138085365, "actor_loss": -23.38305997085571, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.911186933517456, "step": 59000}
{"episode_reward": 440.6309067632201, "episode": 60.0, "batch_reward": 0.16030091462284327, "critic_loss": 0.6088982767015696, "actor_loss": -23.839570465087892, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.925712823867798, "step": 60000}
{"episode_reward": 447.5141550065124, "episode": 61.0, "batch_reward": 0.1655869465470314, "critic_loss": 0.5576622316092252, "actor_loss": -24.244994899749756, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.169864654541016, "step": 61000}
{"episode_reward": 486.88817957457064, "episode": 62.0, "batch_reward": 0.17076657069474457, "critic_loss": 0.5312938921898603, "actor_loss": -24.342096752166746, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.919924020767212, "step": 62000}
{"episode_reward": 513.4597677452218, "episode": 63.0, "batch_reward": 0.1759348667562008, "critic_loss": 0.5159872611165046, "actor_loss": -24.953070724487304, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89186143875122, "step": 63000}
{"episode_reward": 463.9250184917869, "episode": 64.0, "batch_reward": 0.1801608048900962, "critic_loss": 0.5027381697297096, "actor_loss": -25.140522506713868, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.919321298599243, "step": 64000}
{"episode_reward": 430.5914303226361, "episode": 65.0, "batch_reward": 0.18405703925341368, "critic_loss": 0.5002674259096384, "actor_loss": -25.543890964508055, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.910353899002075, "step": 65000}
{"episode_reward": 491.5411405481249, "episode": 66.0, "batch_reward": 0.1894210378229618, "critic_loss": 0.4517751110494137, "actor_loss": -25.797246749877928, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93951439857483, "step": 66000}
{"episode_reward": 466.09600473829, "episode": 67.0, "batch_reward": 0.1927464116960764, "critic_loss": 0.4485937195569277, "actor_loss": -26.358393337249755, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.911818504333496, "step": 67000}
{"episode_reward": 374.44516511913724, "episode": 68.0, "batch_reward": 0.19555459384620189, "critic_loss": 0.4368486011326313, "actor_loss": -26.346510566711427, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.90862798690796, "step": 68000}
{"episode_reward": 442.6197667260626, "episode": 69.0, "batch_reward": 0.19873189337551594, "critic_loss": 0.4700714572370052, "actor_loss": -26.553093475341797, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.90388512611389, "step": 69000}
{"episode_reward": 464.49986066073734, "episode": 70.0, "batch_reward": 0.20283674655854703, "critic_loss": 0.4271387380361557, "actor_loss": -26.991830837249754, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.925567150115967, "step": 70000}
{"episode_reward": 496.07452318252564, "episode": 71.0, "batch_reward": 0.20744764325022697, "critic_loss": 0.4322859438061714, "actor_loss": -27.17430912399292, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.21286392211914, "step": 71000}
{"episode_reward": 472.8021934955657, "episode": 72.0, "batch_reward": 0.21050607730448245, "critic_loss": 0.40624053090810774, "actor_loss": -27.52986580657959, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.943575382232666, "step": 72000}
{"episode_reward": 490.07447829216954, "episode": 73.0, "batch_reward": 0.21477992974221707, "critic_loss": 0.43888457922637464, "actor_loss": -27.852048038482668, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89306879043579, "step": 73000}
{"episode_reward": 500.8524765673232, "episode": 74.0, "batch_reward": 0.21894831526279449, "critic_loss": 0.42847604644298554, "actor_loss": -28.285753383636475, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.929343223571777, "step": 74000}
{"episode_reward": 468.51562696009773, "episode": 75.0, "batch_reward": 0.22279703885316848, "critic_loss": 0.45062841583788393, "actor_loss": -28.315903003692625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.96578311920166, "step": 75000}
{"episode_reward": 495.7789487002284, "episode": 76.0, "batch_reward": 0.22513160778582095, "critic_loss": 0.4853175152987242, "actor_loss": -28.80355010986328, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.896228075027466, "step": 76000}
{"episode_reward": 465.5796821295131, "episode": 77.0, "batch_reward": 0.22705700087547304, "critic_loss": 0.4923304998278618, "actor_loss": -29.24178815841675, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.956722259521484, "step": 77000}
{"episode_reward": 266.7792047577595, "episode": 78.0, "batch_reward": 0.22745120733976365, "critic_loss": 0.4914687677025795, "actor_loss": -29.599485641479493, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93808650970459, "step": 78000}
{"episode_reward": 7.629147897900973, "episode": 79.0, "batch_reward": 0.22311370800435543, "critic_loss": 0.5229412543326616, "actor_loss": -29.88013004684448, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.92878818511963, "step": 79000}
{"episode_reward": 3.674368259971662, "episode": 80.0, "batch_reward": 0.22079799802601338, "critic_loss": 0.5477896644175053, "actor_loss": -30.328108310699463, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.968119144439697, "step": 80000}
{"episode_reward": 6.118624316070691, "episode": 81.0, "batch_reward": 0.21821936754882335, "critic_loss": 0.5255631480962039, "actor_loss": -30.924561920166017, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.309006690979004, "step": 81000}
{"episode_reward": 10.692878632585739, "episode": 82.0, "batch_reward": 0.2155243025869131, "critic_loss": 0.4576830865442753, "actor_loss": -31.280373626708986, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.938225746154785, "step": 82000}
{"episode_reward": 7.346199516278108, "episode": 83.0, "batch_reward": 0.21341155450046062, "critic_loss": 0.4258339812755585, "actor_loss": -31.551570686340334, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.94039034843445, "step": 83000}
{"episode_reward": 14.98266838595592, "episode": 84.0, "batch_reward": 0.2105528108328581, "critic_loss": 0.39020713554322717, "actor_loss": -31.427517642974852, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.904076099395752, "step": 84000}
{"episode_reward": 19.389623105086898, "episode": 85.0, "batch_reward": 0.208414742782712, "critic_loss": 0.34816926742345095, "actor_loss": -31.28094181060791, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.937220096588135, "step": 85000}
{"episode_reward": 27.938063637756258, "episode": 86.0, "batch_reward": 0.20681999637186527, "critic_loss": 0.34018686311692, "actor_loss": -31.10225979232788, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93907618522644, "step": 86000}
{"episode_reward": 34.535321274097406, "episode": 87.0, "batch_reward": 0.2052076314240694, "critic_loss": 0.32496539831906557, "actor_loss": -30.761032905578613, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.940672636032104, "step": 87000}
{"episode_reward": 78.97347887211413, "episode": 88.0, "batch_reward": 0.2050702437609434, "critic_loss": 0.32489073532819746, "actor_loss": -30.60268674468994, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.943403720855713, "step": 88000}
{"episode_reward": 488.088392749455, "episode": 89.0, "batch_reward": 0.20871097475290298, "critic_loss": 0.3516311395615339, "actor_loss": -30.637405769348145, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91535496711731, "step": 89000}
{"episode_reward": 496.4743842943635, "episode": 90.0, "batch_reward": 0.211777856528759, "critic_loss": 0.3607380991131067, "actor_loss": -30.834087493896483, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.945221424102783, "step": 90000}
{"episode_reward": 487.3485653789982, "episode": 91.0, "batch_reward": 0.21575741788744926, "critic_loss": 0.3716396915763617, "actor_loss": -30.697082801818848, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.25390982627869, "step": 91000}
{"episode_reward": 503.1543804296058, "episode": 92.0, "batch_reward": 0.21856469082832336, "critic_loss": 0.36902088558673857, "actor_loss": -31.239077934265136, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.923219680786133, "step": 92000}
{"episode_reward": 480.7897522198932, "episode": 93.0, "batch_reward": 0.22074198639392853, "critic_loss": 0.4037673162668943, "actor_loss": -31.02031624221802, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.947176218032837, "step": 93000}
{"episode_reward": 525.0386491933601, "episode": 94.0, "batch_reward": 0.22395038138329984, "critic_loss": 0.40230702455341816, "actor_loss": -31.605614765167235, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.916040420532227, "step": 94000}
{"episode_reward": 538.7049570542449, "episode": 95.0, "batch_reward": 0.2276558083295822, "critic_loss": 0.4014614363312721, "actor_loss": -31.898652240753172, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.92651391029358, "step": 95000}
{"episode_reward": 514.097243896529, "episode": 96.0, "batch_reward": 0.23022294828295709, "critic_loss": 0.4196994898617268, "actor_loss": -32.13520910263062, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.959611177444458, "step": 96000}
{"episode_reward": 525.0455507018403, "episode": 97.0, "batch_reward": 0.23370517811179162, "critic_loss": 0.39265458948910237, "actor_loss": -32.40752922821045, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.92163586616516, "step": 97000}
{"episode_reward": 506.51641236308484, "episode": 98.0, "batch_reward": 0.23800566816329957, "critic_loss": 0.3725791626870632, "actor_loss": -32.86207091903687, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.932276964187622, "step": 98000}
{"episode_reward": 530.8082729395004, "episode": 99.0, "batch_reward": 0.23935459092259406, "critic_loss": 0.3581663818880916, "actor_loss": -32.867357883453366, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.972031354904175, "step": 99000}
{"episode_reward": 522.8767429271842, "episode": 100.0, "batch_reward": 0.24309984204173088, "critic_loss": 0.34930487687885764, "actor_loss": -33.012316341400144, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.9400954246521, "step": 100000}
{"episode_reward": 500.21564108780666, "episode": 101.0, "batch_reward": 0.2439928895831108, "critic_loss": 0.32541879287362097, "actor_loss": -33.134952587127685, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.202226877212524, "step": 101000}
{"episode_reward": 515.8843118102146, "episode": 102.0, "batch_reward": 0.2459901015907526, "critic_loss": 0.3255507384687662, "actor_loss": -33.43197395324707, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.9215145111084, "step": 102000}
{"episode_reward": 533.5238874857702, "episode": 103.0, "batch_reward": 0.2500196526199579, "critic_loss": 0.3142790550738573, "actor_loss": -33.60332781219483, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.90745711326599, "step": 103000}
{"episode_reward": 534.5299497782696, "episode": 104.0, "batch_reward": 0.25323559656739236, "critic_loss": 0.31136762495338915, "actor_loss": -33.73130641555786, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.910200595855713, "step": 104000}
{"episode_reward": 517.7061655610244, "episode": 105.0, "batch_reward": 0.2560723894238472, "critic_loss": 0.30997871021181345, "actor_loss": -33.90207008361816, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.941587686538696, "step": 105000}
{"episode_reward": 514.8849139882295, "episode": 106.0, "batch_reward": 0.257174371778965, "critic_loss": 0.31794400069117545, "actor_loss": -33.7624553565979, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.949408531188965, "step": 106000}
{"episode_reward": 404.843149177139, "episode": 107.0, "batch_reward": 0.25931192496418953, "critic_loss": 0.3187035619467497, "actor_loss": -34.22132916641235, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.926099061965942, "step": 107000}
{"episode_reward": 523.4622123445579, "episode": 108.0, "batch_reward": 0.26270084646344183, "critic_loss": 0.31628121818602084, "actor_loss": -34.691689239501954, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.903549432754517, "step": 108000}
{"episode_reward": 552.0558003596191, "episode": 109.0, "batch_reward": 0.2652731997817755, "critic_loss": 0.31828680375218393, "actor_loss": -34.751955478668215, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.936556816101074, "step": 109000}
{"episode_reward": 530.0316992481797, "episode": 110.0, "batch_reward": 0.2675371368676424, "critic_loss": 0.33235230496525764, "actor_loss": -34.91559757232666, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89197826385498, "step": 110000}
{"episode_reward": 540.310403182241, "episode": 111.0, "batch_reward": 0.27000526782870293, "critic_loss": 0.32676346875727175, "actor_loss": -35.096430294036864, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.215874433517456, "step": 111000}
{"episode_reward": 537.3333343699665, "episode": 112.0, "batch_reward": 0.2730166865736246, "critic_loss": 0.31594604274630544, "actor_loss": -35.25317734527588, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.864940643310547, "step": 112000}
{"episode_reward": 516.2371601204806, "episode": 113.0, "batch_reward": 0.27352446952462195, "critic_loss": 0.3104834599047899, "actor_loss": -35.28542962265015, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.895689010620117, "step": 113000}
{"episode_reward": 519.2320643764808, "episode": 114.0, "batch_reward": 0.27537741757929324, "critic_loss": 0.3002680462002754, "actor_loss": -35.467049995422364, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.9202561378479, "step": 114000}
{"episode_reward": 517.4420007984644, "episode": 115.0, "batch_reward": 0.27957844439148904, "critic_loss": 0.29921321555972097, "actor_loss": -35.52327261352539, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.90527057647705, "step": 115000}
{"episode_reward": 541.5496360169384, "episode": 116.0, "batch_reward": 0.2813877927660942, "critic_loss": 0.3219667726829648, "actor_loss": -35.79328286743164, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.932470083236694, "step": 116000}
{"episode_reward": 514.3181411366061, "episode": 117.0, "batch_reward": 0.28220582208037376, "critic_loss": 0.3021540055125952, "actor_loss": -35.80514479446411, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.955652236938477, "step": 117000}
{"episode_reward": 504.58344620487776, "episode": 118.0, "batch_reward": 0.2850376206189394, "critic_loss": 0.30276660227775576, "actor_loss": -35.91187373352051, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.87071442604065, "step": 118000}
{"episode_reward": 518.400652770093, "episode": 119.0, "batch_reward": 0.28656816862523554, "critic_loss": 0.29868133990466594, "actor_loss": -35.88805144119263, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89103865623474, "step": 119000}
{"episode_reward": 534.3951199131984, "episode": 120.0, "batch_reward": 0.2881686328798532, "critic_loss": 0.2962901070266962, "actor_loss": -35.820488704681395, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.933638095855713, "step": 120000}
{"episode_reward": 538.6509443665287, "episode": 121.0, "batch_reward": 0.29237780418992043, "critic_loss": 0.2984820396974683, "actor_loss": -36.148727138519284, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.17760515213013, "step": 121000}
{"episode_reward": 534.3559066233681, "episode": 122.0, "batch_reward": 0.2930436520427465, "critic_loss": 0.3030056523308158, "actor_loss": -36.3290210723877, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.880555152893066, "step": 122000}
{"episode_reward": 544.1017712775742, "episode": 123.0, "batch_reward": 0.29566325387358666, "critic_loss": 0.28347627010196447, "actor_loss": -36.653527759552, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.92997694015503, "step": 123000}
{"episode_reward": 528.8847645684193, "episode": 124.0, "batch_reward": 0.2962955348491669, "critic_loss": 0.32686053501814605, "actor_loss": -36.778582279205324, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.891185998916626, "step": 124000}
{"episode_reward": 519.9934664653199, "episode": 125.0, "batch_reward": 0.2979150065481663, "critic_loss": 0.30784962330013516, "actor_loss": -36.78346575546264, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.892417907714844, "step": 125000}
{"episode_reward": 529.0788934854789, "episode": 126.0, "batch_reward": 0.3001741353869438, "critic_loss": 0.30485958771407606, "actor_loss": -37.01059995269775, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.932167530059814, "step": 126000}
{"episode_reward": 525.0833296431033, "episode": 127.0, "batch_reward": 0.30113653902709486, "critic_loss": 0.31020245783030986, "actor_loss": -37.13837638092041, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93529200553894, "step": 127000}
{"episode_reward": 539.8287888282318, "episode": 128.0, "batch_reward": 0.3039554109573364, "critic_loss": 0.28709541661292315, "actor_loss": -37.40738311386109, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89669680595398, "step": 128000}
{"episode_reward": 524.0260464480386, "episode": 129.0, "batch_reward": 0.3054299585223198, "critic_loss": 0.2870422813668847, "actor_loss": -37.69278559494018, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.919412851333618, "step": 129000}
{"episode_reward": 527.0317005887132, "episode": 130.0, "batch_reward": 0.30713238143920896, "critic_loss": 0.30640163757652045, "actor_loss": -37.38380752182007, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.96144199371338, "step": 130000}
{"episode_reward": 493.27966433199134, "episode": 131.0, "batch_reward": 0.3097545469999313, "critic_loss": 0.29397627703100443, "actor_loss": -37.653911003112796, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.200204610824585, "step": 131000}
{"episode_reward": 524.4528350829978, "episode": 132.0, "batch_reward": 0.31016788163781167, "critic_loss": 0.3010855279788375, "actor_loss": -37.39619076156616, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.911648988723755, "step": 132000}
{"episode_reward": 540.5259129616254, "episode": 133.0, "batch_reward": 0.31167876279354095, "critic_loss": 0.28387320713698866, "actor_loss": -37.891724586486816, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.869626760482788, "step": 133000}
{"episode_reward": 536.5666754344245, "episode": 134.0, "batch_reward": 0.31300438365340233, "critic_loss": 0.28767378387600184, "actor_loss": -37.92876071166992, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.90726900100708, "step": 134000}
{"episode_reward": 476.14686974763293, "episode": 135.0, "batch_reward": 0.3148529870510101, "critic_loss": 0.3065196758955717, "actor_loss": -37.88064051055908, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91288733482361, "step": 135000}
{"episode_reward": 554.0346312181903, "episode": 136.0, "batch_reward": 0.3168700687289238, "critic_loss": 0.3005188083872199, "actor_loss": -37.99736145401001, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.899458169937134, "step": 136000}
{"episode_reward": 497.83227660903253, "episode": 137.0, "batch_reward": 0.31797648291289804, "critic_loss": 0.3090041531398892, "actor_loss": -37.914979274749754, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.924400568008423, "step": 137000}
{"episode_reward": 545.8560943333714, "episode": 138.0, "batch_reward": 0.32037579640746117, "critic_loss": 0.3051880599334836, "actor_loss": -37.834683010101315, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.887279748916626, "step": 138000}
{"episode_reward": 540.2387808696891, "episode": 139.0, "batch_reward": 0.32148843505978586, "critic_loss": 0.31417830849438905, "actor_loss": -38.089399559021, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.952688455581665, "step": 139000}
{"episode_reward": 544.6563061274322, "episode": 140.0, "batch_reward": 0.322491511464119, "critic_loss": 0.31149143281579017, "actor_loss": -38.14241530609131, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93230390548706, "step": 140000}
{"episode_reward": 534.7779446943033, "episode": 141.0, "batch_reward": 0.3247680848538876, "critic_loss": 0.3160268160328269, "actor_loss": -38.089150321960446, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.22623014450073, "step": 141000}
{"episode_reward": 553.2540180116259, "episode": 142.0, "batch_reward": 0.32684042024612425, "critic_loss": 0.2968843572437763, "actor_loss": -38.199799755096436, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.967231512069702, "step": 142000}
{"episode_reward": 570.345692074082, "episode": 143.0, "batch_reward": 0.32830213811993597, "critic_loss": 0.30829297048598525, "actor_loss": -38.469825073242184, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.92948293685913, "step": 143000}
{"episode_reward": 555.3505714109336, "episode": 144.0, "batch_reward": 0.3296374850273132, "critic_loss": 0.3125770269706845, "actor_loss": -38.53153214263916, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93835139274597, "step": 144000}
{"episode_reward": 542.3329674299774, "episode": 145.0, "batch_reward": 0.3324906359612942, "critic_loss": 0.32161592289060353, "actor_loss": -38.56517002868652, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.961881160736084, "step": 145000}
{"episode_reward": 561.3645395882677, "episode": 146.0, "batch_reward": 0.33225794449448587, "critic_loss": 0.29643595217168334, "actor_loss": -38.87582737350464, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.926027059555054, "step": 146000}
{"episode_reward": 550.2703225647164, "episode": 147.0, "batch_reward": 0.33419762837886813, "critic_loss": 0.2871071264371276, "actor_loss": -38.9593051071167, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.95552897453308, "step": 147000}
{"episode_reward": 574.7013549518131, "episode": 148.0, "batch_reward": 0.33646540823578835, "critic_loss": 0.3035916519239545, "actor_loss": -39.06391359710693, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.324111223220825, "step": 148000}
{"episode_reward": 558.1229744579581, "episode": 149.0, "batch_reward": 0.33715136417746544, "critic_loss": 0.29324848000705245, "actor_loss": -39.055859886169436, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.910733222961426, "step": 149000}
{"episode_reward": 555.5673069975927, "episode": 150.0, "batch_reward": 0.33961789894104005, "critic_loss": 0.29561229172348974, "actor_loss": -39.321692436218264, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
