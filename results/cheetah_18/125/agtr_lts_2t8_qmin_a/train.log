{"episode_reward": 0.0, "episode": 1.0, "duration": 13.949410915374756, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.2549386024475098, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.22179279226229642, "critic_loss": 0.05508597820429563, "actor_loss": -36.64865762880203, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 71.21088433265686, "step": 3000}
{"episode_reward": 116.34392143537319, "episode": 4.0, "batch_reward": 0.17318466733396054, "critic_loss": 0.06350770142674446, "actor_loss": -28.058028263606133, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.623618364334106, "step": 4000}
{"episode_reward": 32.186029116094446, "episode": 5.0, "batch_reward": 0.14104445040225982, "critic_loss": 0.05825287109613419, "actor_loss": -24.953276353925467, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.93980360031128, "step": 5000}
{"episode_reward": 33.73312591168826, "episode": 6.0, "batch_reward": 0.1259611315652728, "critic_loss": 0.06326247852295637, "actor_loss": -22.980780095502734, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.969749927520752, "step": 6000}
{"episode_reward": 159.29629700912096, "episode": 7.0, "batch_reward": 0.13971660297363997, "critic_loss": 0.09717948980256916, "actor_loss": -23.42103331376612, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.852040767669678, "step": 7000}
{"episode_reward": 229.2055464880087, "episode": 8.0, "batch_reward": 0.15043109903484583, "critic_loss": 0.10955647845938801, "actor_loss": -24.89980742776394, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.713820219039917, "step": 8000}
{"episode_reward": 169.3828503284283, "episode": 9.0, "batch_reward": 0.14909129812568425, "critic_loss": 0.13482799000665546, "actor_loss": -23.54809605178237, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.339634656906128, "step": 9000}
{"episode_reward": 165.6999742710488, "episode": 10.0, "batch_reward": 0.1562041453793645, "critic_loss": 0.16924141389131547, "actor_loss": -25.33616639494896, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.338555335998535, "step": 10000}
{"episode_reward": 180.08257609780952, "episode": 11.0, "batch_reward": 0.15340651472657918, "critic_loss": 0.16321627552062273, "actor_loss": -23.621375684022905, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.49043273925781, "step": 11000}
{"episode_reward": 72.7282546088302, "episode": 12.0, "batch_reward": 0.14525326896458865, "critic_loss": 0.16746844609826803, "actor_loss": -22.795791619062424, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.540207386016846, "step": 12000}
{"episode_reward": 115.84387736133759, "episode": 13.0, "batch_reward": 0.1435404397547245, "critic_loss": 0.2031461324542761, "actor_loss": -22.235439776182176, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.91379189491272, "step": 13000}
{"episode_reward": 69.95021786835653, "episode": 14.0, "batch_reward": 0.13915452270954848, "critic_loss": 0.2039906663224101, "actor_loss": -22.500068744897842, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.185259103775024, "step": 14000}
{"episode_reward": 101.8456309326099, "episode": 15.0, "batch_reward": 0.13738184459507466, "critic_loss": 0.20664458733797073, "actor_loss": -20.4723394446373, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.261908054351807, "step": 15000}
{"episode_reward": 109.03299733255437, "episode": 16.0, "batch_reward": 0.13194216819852592, "critic_loss": 0.20242014548927545, "actor_loss": -19.936661188602447, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.854094982147217, "step": 16000}
{"episode_reward": 36.70630365880262, "episode": 17.0, "batch_reward": 0.12772376568615437, "critic_loss": 0.23223401729017495, "actor_loss": -19.959064709186553, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.39387559890747, "step": 17000}
{"episode_reward": 81.23161812731797, "episode": 18.0, "batch_reward": 0.12620029345154762, "critic_loss": 0.21725054141879083, "actor_loss": -19.37479169845581, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.406879901885986, "step": 18000}
{"episode_reward": 89.57980496107889, "episode": 19.0, "batch_reward": 0.1255329300686717, "critic_loss": 0.23574014230817555, "actor_loss": -18.442378472328187, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.32049870491028, "step": 19000}
{"episode_reward": 168.4276041816303, "episode": 20.0, "batch_reward": 0.12358685074746609, "critic_loss": 0.26645471216738226, "actor_loss": -17.88431803035736, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.18129801750183, "step": 20000}
{"episode_reward": 43.02739153170533, "episode": 21.0, "batch_reward": 0.12563795974850656, "critic_loss": 0.31556690768897533, "actor_loss": -17.324406465530394, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.88806700706482, "step": 21000}
{"episode_reward": 214.40497249001314, "episode": 22.0, "batch_reward": 0.126523957580328, "critic_loss": 0.3271381324529648, "actor_loss": -17.9502765083313, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.345220804214478, "step": 22000}
{"episode_reward": 94.8947688157302, "episode": 23.0, "batch_reward": 0.12720045156031848, "critic_loss": 0.3326403273791075, "actor_loss": -18.634310326576234, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.798120498657227, "step": 23000}
{"episode_reward": 209.79511105925246, "episode": 24.0, "batch_reward": 0.127307183817029, "critic_loss": 0.3746811485141516, "actor_loss": -17.852135811805724, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.50546908378601, "step": 24000}
{"episode_reward": 52.86929803100626, "episode": 25.0, "batch_reward": 0.1245017975345254, "critic_loss": 0.3622265581786632, "actor_loss": -18.0633400888443, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.187360048294067, "step": 25000}
{"episode_reward": 47.61773849418958, "episode": 26.0, "batch_reward": 0.1251132809817791, "critic_loss": 0.39489938047528267, "actor_loss": -18.318628504753114, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.528603315353394, "step": 26000}
{"episode_reward": 296.37550234662666, "episode": 27.0, "batch_reward": 0.13029627254605294, "critic_loss": 0.4337252099215984, "actor_loss": -18.64421539402008, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.55809760093689, "step": 27000}
{"episode_reward": 138.7331247044737, "episode": 28.0, "batch_reward": 0.1289177141338587, "critic_loss": 0.4034896277189255, "actor_loss": -18.29601905155182, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.47617483139038, "step": 28000}
{"episode_reward": 69.11566549455972, "episode": 29.0, "batch_reward": 0.13148361414670945, "critic_loss": 0.4238023223280907, "actor_loss": -17.637440264701844, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.290994882583618, "step": 29000}
{"episode_reward": 358.0292578676664, "episode": 30.0, "batch_reward": 0.1373770106807351, "critic_loss": 0.4512546440809965, "actor_loss": -18.56352283191681, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.07894277572632, "step": 30000}
{"episode_reward": 236.8491399189619, "episode": 31.0, "batch_reward": 0.14144724018126725, "critic_loss": 0.5144764696210623, "actor_loss": -18.695736923217773, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.82621359825134, "step": 31000}
{"episode_reward": 291.6787190493914, "episode": 32.0, "batch_reward": 0.1469073650315404, "critic_loss": 0.5575499488413334, "actor_loss": -19.867725206375123, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.680638551712036, "step": 32000}
{"episode_reward": 395.97953623901606, "episode": 33.0, "batch_reward": 0.1554120398312807, "critic_loss": 0.46432540282607077, "actor_loss": -21.017773105621337, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.43394374847412, "step": 33000}
{"episode_reward": 397.1788450450263, "episode": 34.0, "batch_reward": 0.15924131239950656, "critic_loss": 0.4555628733932972, "actor_loss": -22.398668148040773, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.625580310821533, "step": 34000}
{"episode_reward": 157.17969409800315, "episode": 35.0, "batch_reward": 0.16036378303170204, "critic_loss": 0.4045173716247082, "actor_loss": -21.713214336395264, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.343485355377197, "step": 35000}
{"episode_reward": 156.5696839106942, "episode": 36.0, "batch_reward": 0.16049218226969242, "critic_loss": 0.4023922865539789, "actor_loss": -22.327527002334595, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.08076286315918, "step": 36000}
{"episode_reward": 266.35735566682047, "episode": 37.0, "batch_reward": 0.16154742881655693, "critic_loss": 0.4377093451172113, "actor_loss": -22.113245183944702, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.309058904647827, "step": 37000}
{"episode_reward": 138.7343876184188, "episode": 38.0, "batch_reward": 0.16413339056819679, "critic_loss": 0.4155217669010162, "actor_loss": -22.0121839427948, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.345212936401367, "step": 38000}
{"episode_reward": 388.94494118879516, "episode": 39.0, "batch_reward": 0.1702221553400159, "critic_loss": 0.4282405766099691, "actor_loss": -22.33479583930969, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.62373685836792, "step": 39000}
{"episode_reward": 408.57695678939956, "episode": 40.0, "batch_reward": 0.17650011330097914, "critic_loss": 0.4357147732824087, "actor_loss": -23.15825510978699, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.34536862373352, "step": 40000}
{"episode_reward": 457.2827486740849, "episode": 41.0, "batch_reward": 0.18404394635558127, "critic_loss": 0.43838193742930887, "actor_loss": -24.986131046295167, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.460848569869995, "step": 41000}
{"episode_reward": 437.5974166372673, "episode": 42.0, "batch_reward": 0.189452926710248, "critic_loss": 0.41093808291852474, "actor_loss": -26.104162403106688, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.65237593650818, "step": 42000}
{"episode_reward": 507.2708616398172, "episode": 43.0, "batch_reward": 0.19753747622668744, "critic_loss": 0.4021074004471302, "actor_loss": -26.652557579040526, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.736666202545166, "step": 43000}
{"episode_reward": 442.17051859812733, "episode": 44.0, "batch_reward": 0.20262514904141427, "critic_loss": 0.3985659741461277, "actor_loss": -27.117558879852297, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.253154277801514, "step": 44000}
{"episode_reward": 467.40388407450007, "episode": 45.0, "batch_reward": 0.20918365839123726, "critic_loss": 0.39251790826022626, "actor_loss": -27.357289890289305, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.47058606147766, "step": 45000}
{"episode_reward": 485.7565329389212, "episode": 46.0, "batch_reward": 0.21496570087969302, "critic_loss": 0.3594655276983976, "actor_loss": -28.02000834274292, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.68821358680725, "step": 46000}
{"episode_reward": 530.0793964909577, "episode": 47.0, "batch_reward": 0.22297873641550542, "critic_loss": 0.35727378726005554, "actor_loss": -28.01499545288086, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.852285861968994, "step": 47000}
{"episode_reward": 510.3329538197617, "episode": 48.0, "batch_reward": 0.22478889536857605, "critic_loss": 0.37993217845261096, "actor_loss": -28.68071691131592, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.4091477394104, "step": 48000}
{"episode_reward": 117.22184788110842, "episode": 49.0, "batch_reward": 0.22707061482965946, "critic_loss": 0.3867304172515869, "actor_loss": -28.456915100097657, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.031816244125366, "step": 49000}
{"episode_reward": 547.0199097631241, "episode": 50.0, "batch_reward": 0.23145527850091457, "critic_loss": 0.41648699218034746, "actor_loss": -29.529274578094483, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.2844455242157, "step": 50000}
{"episode_reward": 547.0762232241563, "episode": 51.0, "batch_reward": 0.23778258846700193, "critic_loss": 0.4328431145846844, "actor_loss": -30.508693893432618, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.78550052642822, "step": 51000}
{"episode_reward": 380.19739750092293, "episode": 52.0, "batch_reward": 0.2406927480995655, "critic_loss": 0.45582681700587274, "actor_loss": -31.17445764541626, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.56413507461548, "step": 52000}
{"episode_reward": 503.34447666914434, "episode": 53.0, "batch_reward": 0.24608025494217872, "critic_loss": 0.4651392576992512, "actor_loss": -32.00679647064209, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.386707067489624, "step": 53000}
{"episode_reward": 476.4900872346886, "episode": 54.0, "batch_reward": 0.250653623059392, "critic_loss": 0.49256880177557466, "actor_loss": -32.84793759918213, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.481348514556885, "step": 54000}
{"episode_reward": 478.5616002396362, "episode": 55.0, "batch_reward": 0.25528140072524547, "critic_loss": 0.551002146139741, "actor_loss": -33.38454605484009, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.617780685424805, "step": 55000}
{"episode_reward": 385.8866838063467, "episode": 56.0, "batch_reward": 0.2571460836529732, "critic_loss": 0.6374075437784195, "actor_loss": -34.673500907897946, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.272807121276855, "step": 56000}
{"episode_reward": 506.16706553555144, "episode": 57.0, "batch_reward": 0.2621182459294796, "critic_loss": 0.7514127647876739, "actor_loss": -36.67668135070801, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.736645936965942, "step": 57000}
{"episode_reward": 508.07272628283056, "episode": 58.0, "batch_reward": 0.26607462579011915, "critic_loss": 0.6573768190294504, "actor_loss": -38.14680082702637, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.123237371444702, "step": 58000}
{"episode_reward": 487.9230882963186, "episode": 59.0, "batch_reward": 0.26862142887711526, "critic_loss": 0.6207269137650728, "actor_loss": -39.0891770401001, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.05208468437195, "step": 59000}
{"episode_reward": 483.8850998563212, "episode": 60.0, "batch_reward": 0.2728578604906797, "critic_loss": 0.5986586405336857, "actor_loss": -39.97912101745605, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.097656726837158, "step": 60000}
{"episode_reward": 460.5913022181451, "episode": 61.0, "batch_reward": 0.27448319271206856, "critic_loss": 0.6388914856016636, "actor_loss": -40.679225952148435, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.21961164474487, "step": 61000}
{"episode_reward": 253.10798287959884, "episode": 62.0, "batch_reward": 0.2714175652861595, "critic_loss": 0.6052311203628779, "actor_loss": -41.29423590087891, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.65042734146118, "step": 62000}
{"episode_reward": 3.210380513038039, "episode": 63.0, "batch_reward": 0.2711316097527742, "critic_loss": 0.6429451447725296, "actor_loss": -41.73497833251953, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.002038955688477, "step": 63000}
{"episode_reward": 517.9493812402592, "episode": 64.0, "batch_reward": 0.27225174170732497, "critic_loss": 1.1813712909519671, "actor_loss": -44.15996948242187, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.027937650680542, "step": 64000}
{"episode_reward": 128.25692902298186, "episode": 65.0, "batch_reward": 0.27302830328047273, "critic_loss": 0.8342778411805629, "actor_loss": -45.84892046356201, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.499654531478882, "step": 65000}
{"episode_reward": 468.77089289336317, "episode": 66.0, "batch_reward": 0.27429977658390997, "critic_loss": 0.7056468559503555, "actor_loss": -46.334092811584476, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.02595615386963, "step": 66000}
{"episode_reward": 2.1114013695174103, "episode": 67.0, "batch_reward": 0.26836104118824006, "critic_loss": 0.6529788629412651, "actor_loss": -46.57041949462891, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.70959973335266, "step": 67000}
{"episode_reward": 5.076082900850951, "episode": 68.0, "batch_reward": 0.2645786602497101, "critic_loss": 0.6032162396609784, "actor_loss": -46.41287461090088, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.88865375518799, "step": 68000}
{"episode_reward": 7.604067744461883, "episode": 69.0, "batch_reward": 0.2603285564035177, "critic_loss": 0.5627469967901707, "actor_loss": -46.12632926177979, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.73621654510498, "step": 69000}
{"episode_reward": 7.943063675528835, "episode": 70.0, "batch_reward": 0.25706855906546117, "critic_loss": 0.5455779895484447, "actor_loss": -46.17162836456299, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.751317739486694, "step": 70000}
{"episode_reward": 10.453087916791413, "episode": 71.0, "batch_reward": 0.25376112316548827, "critic_loss": 0.47947278444468977, "actor_loss": -46.10979658508301, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.18069338798523, "step": 71000}
{"episode_reward": 6.85650513899373, "episode": 72.0, "batch_reward": 0.25098117291927335, "critic_loss": 0.40304521889984607, "actor_loss": -45.71118933105469, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.193496227264404, "step": 72000}
{"episode_reward": 8.222670270238718, "episode": 73.0, "batch_reward": 0.24656924936175345, "critic_loss": 0.35810200764238836, "actor_loss": -45.115854446411134, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.678128957748413, "step": 73000}
{"episode_reward": 8.080697323569979, "episode": 74.0, "batch_reward": 0.24457912728190423, "critic_loss": 0.39305376608669756, "actor_loss": -44.72421027374268, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.674449682235718, "step": 74000}
{"episode_reward": 120.90000222504472, "episode": 75.0, "batch_reward": 0.243671087667346, "critic_loss": 0.3896068924218416, "actor_loss": -44.24063600921631, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.897704601287842, "step": 75000}
{"episode_reward": 261.3361780100059, "episode": 76.0, "batch_reward": 0.24099733351171015, "critic_loss": 0.36044581577181817, "actor_loss": -43.98001544189453, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.575690507888794, "step": 76000}
{"episode_reward": 11.472252661162184, "episode": 77.0, "batch_reward": 0.239839935824275, "critic_loss": 0.3690143233090639, "actor_loss": -43.45527812194824, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.24047064781189, "step": 77000}
{"episode_reward": 13.282592014181507, "episode": 78.0, "batch_reward": 0.23623371706902982, "critic_loss": 0.3562441644519567, "actor_loss": -43.14016952514648, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.730858087539673, "step": 78000}
{"episode_reward": 5.478031011866028, "episode": 79.0, "batch_reward": 0.23298992325365545, "critic_loss": 0.34994170495867727, "actor_loss": -42.39624189758301, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.714664936065674, "step": 79000}
{"episode_reward": 9.057427617165821, "episode": 80.0, "batch_reward": 0.22986758576333524, "critic_loss": 0.32995960357785226, "actor_loss": -41.77845645141601, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.617652654647827, "step": 80000}
{"episode_reward": 7.661840432054255, "episode": 81.0, "batch_reward": 0.22751869708299638, "critic_loss": 0.30644022403657434, "actor_loss": -41.373324577331545, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.33805727958679, "step": 81000}
{"episode_reward": 10.066685135631444, "episode": 82.0, "batch_reward": 0.22503891494870185, "critic_loss": 0.28677914184331893, "actor_loss": -40.86167783355713, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.908913135528564, "step": 82000}
{"episode_reward": 39.91551335604948, "episode": 83.0, "batch_reward": 0.2234760591983795, "critic_loss": 0.3173105234056711, "actor_loss": -40.40251152801514, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.91148066520691, "step": 83000}
{"episode_reward": 104.29550877094537, "episode": 84.0, "batch_reward": 0.2219827492237091, "critic_loss": 0.29312070898711684, "actor_loss": -40.120470405578615, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.028735399246216, "step": 84000}
{"episode_reward": 94.58564129225475, "episode": 85.0, "batch_reward": 0.2200449217557907, "critic_loss": 0.272995033711195, "actor_loss": -39.763257347106936, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.645564079284668, "step": 85000}
{"episode_reward": 70.89588497376312, "episode": 86.0, "batch_reward": 0.21823604457080364, "critic_loss": 0.23658291859179736, "actor_loss": -39.56297637176514, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.091785192489624, "step": 86000}
{"episode_reward": 62.242096655966954, "episode": 87.0, "batch_reward": 0.21699095226824283, "critic_loss": 0.2103507772833109, "actor_loss": -39.40888451385498, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.83363938331604, "step": 87000}
{"episode_reward": 64.8573716359109, "episode": 88.0, "batch_reward": 0.21464627714455128, "critic_loss": 0.209741488866508, "actor_loss": -38.86932434082031, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.636923789978027, "step": 88000}
{"episode_reward": 71.10369968732127, "episode": 89.0, "batch_reward": 0.21298818291723728, "critic_loss": 0.2339689982905984, "actor_loss": -38.36273210144043, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.45916199684143, "step": 89000}
{"episode_reward": 82.00635488412094, "episode": 90.0, "batch_reward": 0.21362547202408314, "critic_loss": 0.27861705133318904, "actor_loss": -38.211334579467774, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.594804763793945, "step": 90000}
{"episode_reward": 142.5058756248053, "episode": 91.0, "batch_reward": 0.2118044819533825, "critic_loss": 0.3390486169978976, "actor_loss": -38.46937327575684, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.916170835494995, "step": 91000}
{"episode_reward": 70.52931437280611, "episode": 92.0, "batch_reward": 0.21028639715909958, "critic_loss": 0.349334493085742, "actor_loss": -38.56767321777344, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.5524320602417, "step": 92000}
{"episode_reward": 23.208189830709323, "episode": 93.0, "batch_reward": 0.20792627495527266, "critic_loss": 0.36387326635420325, "actor_loss": -38.258728981018066, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.129212617874146, "step": 93000}
{"episode_reward": 118.72434407044695, "episode": 94.0, "batch_reward": 0.20553654631972312, "critic_loss": 0.38693696495890617, "actor_loss": -38.25097421264648, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.77077341079712, "step": 94000}
{"episode_reward": 4.84785293865507, "episode": 95.0, "batch_reward": 0.2039191370010376, "critic_loss": 0.43801652982831, "actor_loss": -38.500584671020505, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.776930809020996, "step": 95000}
{"episode_reward": 3.7633836146454236, "episode": 96.0, "batch_reward": 0.20238979454338552, "critic_loss": 0.5174460654258728, "actor_loss": -39.52098836135864, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.668412446975708, "step": 96000}
{"episode_reward": 1.7959825517716888, "episode": 97.0, "batch_reward": 0.2003697405308485, "critic_loss": 0.6292765490412712, "actor_loss": -40.8972455329895, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.56631588935852, "step": 97000}
{"episode_reward": 3.1384239117218247, "episode": 98.0, "batch_reward": 0.1982595552057028, "critic_loss": 0.6860126376748085, "actor_loss": -41.74363857269287, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.387281894683838, "step": 98000}
{"episode_reward": 4.133803113199514, "episode": 99.0, "batch_reward": 0.1953772594332695, "critic_loss": 0.5731348861157894, "actor_loss": -41.78749642944336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.687196731567383, "step": 99000}
{"episode_reward": 10.75769454553735, "episode": 100.0, "batch_reward": 0.1942517441213131, "critic_loss": 0.48301877073943617, "actor_loss": -42.029539459228516, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.599623441696167, "step": 100000}
{"episode_reward": 7.454948097560673, "episode": 101.0, "batch_reward": 0.19234902803599835, "critic_loss": 0.4528420462161303, "actor_loss": -41.97337674713135, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.891714334487915, "step": 101000}
{"episode_reward": 3.753428668993249, "episode": 102.0, "batch_reward": 0.19116688154637815, "critic_loss": 0.4872869946360588, "actor_loss": -41.61715269088745, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.755763292312622, "step": 102000}
{"episode_reward": 6.1495970607191826, "episode": 103.0, "batch_reward": 0.18939337110519408, "critic_loss": 0.4530886541903019, "actor_loss": -41.422768115997314, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.68474245071411, "step": 103000}
{"episode_reward": 8.505723953194028, "episode": 104.0, "batch_reward": 0.1870803864002228, "critic_loss": 0.37335088235139846, "actor_loss": -40.93787535858154, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.321095943450928, "step": 104000}
{"episode_reward": 8.292049848222424, "episode": 105.0, "batch_reward": 0.18612504982948302, "critic_loss": 0.3610399494469166, "actor_loss": -40.46329717636108, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.773611545562744, "step": 105000}
{"episode_reward": 9.683229170353918, "episode": 106.0, "batch_reward": 0.18420728266239167, "critic_loss": 0.3297677177414298, "actor_loss": -39.96165211105347, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.482890367507935, "step": 106000}
{"episode_reward": 11.15955071277325, "episode": 107.0, "batch_reward": 0.18147499935328962, "critic_loss": 0.3237840446829796, "actor_loss": -39.70562268447876, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.781805992126465, "step": 107000}
{"episode_reward": 8.005768006038359, "episode": 108.0, "batch_reward": 0.18065626400709153, "critic_loss": 0.30799972620606425, "actor_loss": -39.21434958648682, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.32617735862732, "step": 108000}
{"episode_reward": 9.482545116842116, "episode": 109.0, "batch_reward": 0.17825565519928932, "critic_loss": 0.28873889438062905, "actor_loss": -38.861670917510985, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.15379047393799, "step": 109000}
{"episode_reward": 10.930297380555103, "episode": 110.0, "batch_reward": 0.17645319877564908, "critic_loss": 0.23238352455198766, "actor_loss": -38.415010478973386, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.5269832611084, "step": 110000}
{"episode_reward": 11.531590448275757, "episode": 111.0, "batch_reward": 0.1767750602811575, "critic_loss": 0.1950302989333868, "actor_loss": -38.03076831817627, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.79239296913147, "step": 111000}
{"episode_reward": 23.542156183622964, "episode": 112.0, "batch_reward": 0.17448197243362665, "critic_loss": 0.1912891041189432, "actor_loss": -37.31860508346558, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.34143090248108, "step": 112000}
{"episode_reward": 13.88733020937502, "episode": 113.0, "batch_reward": 0.17422335767000913, "critic_loss": 0.17032946929335593, "actor_loss": -36.932247875213626, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.01623296737671, "step": 113000}
{"episode_reward": 18.073972290988834, "episode": 114.0, "batch_reward": 0.17122149132937192, "critic_loss": 0.18290203798562288, "actor_loss": -36.21759037780762, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.44182538986206, "step": 114000}
{"episode_reward": 15.136878486091941, "episode": 115.0, "batch_reward": 0.17294375083595515, "critic_loss": 0.2140706320926547, "actor_loss": -35.67012621688843, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.961111307144165, "step": 115000}
{"episode_reward": 515.0803864558951, "episode": 116.0, "batch_reward": 0.17433790104836225, "critic_loss": 0.21037161253392697, "actor_loss": -35.15472778701782, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.50769805908203, "step": 116000}
{"episode_reward": 522.3971516024698, "episode": 117.0, "batch_reward": 0.1776446069031954, "critic_loss": 0.23074830955266953, "actor_loss": -34.77463852310181, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.38453984260559, "step": 117000}
{"episode_reward": 529.1209769772498, "episode": 118.0, "batch_reward": 0.18074538584798575, "critic_loss": 0.2579968544244766, "actor_loss": -34.5386287689209, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.359950065612793, "step": 118000}
{"episode_reward": 512.2047334064636, "episode": 119.0, "batch_reward": 0.18384996400773526, "critic_loss": 0.25354773057252167, "actor_loss": -34.36715740966797, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.70742416381836, "step": 119000}
{"episode_reward": 564.2276740680697, "episode": 120.0, "batch_reward": 0.18603152860701083, "critic_loss": 0.30669374979287384, "actor_loss": -34.1708592338562, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.668108463287354, "step": 120000}
{"episode_reward": 517.9588312727614, "episode": 121.0, "batch_reward": 0.19040852272510528, "critic_loss": 0.2700846327021718, "actor_loss": -34.295890449523924, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.5147020816803, "step": 121000}
{"episode_reward": 547.6971573991358, "episode": 122.0, "batch_reward": 0.1934816153049469, "critic_loss": 0.28893608739227056, "actor_loss": -34.207417095184326, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.138973712921143, "step": 122000}
{"episode_reward": 533.8935283170612, "episode": 123.0, "batch_reward": 0.19574130085110664, "critic_loss": 0.2724133739322424, "actor_loss": -34.326406028747556, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.033430337905884, "step": 123000}
{"episode_reward": 525.9897800016594, "episode": 124.0, "batch_reward": 0.19828208492696286, "critic_loss": 0.30764217089861634, "actor_loss": -34.14187844848633, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.11684250831604, "step": 124000}
{"episode_reward": 541.8056257234166, "episode": 125.0, "batch_reward": 0.2019562649279833, "critic_loss": 0.2937115821838379, "actor_loss": -34.30031868743897, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.227845430374146, "step": 125000}
{"episode_reward": 552.9243882279357, "episode": 126.0, "batch_reward": 0.20340798801183702, "critic_loss": 0.3066912810206413, "actor_loss": -34.223320960998535, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.66798210144043, "step": 126000}
{"episode_reward": 544.2473044229841, "episode": 127.0, "batch_reward": 0.2075005321800709, "critic_loss": 0.3107303201779723, "actor_loss": -34.35911843490601, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.4334716796875, "step": 127000}
{"episode_reward": 568.3846477547959, "episode": 128.0, "batch_reward": 0.20911382026970388, "critic_loss": 0.279743133790791, "actor_loss": -34.34967176818848, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.207776308059692, "step": 128000}
{"episode_reward": 543.9095591194313, "episode": 129.0, "batch_reward": 0.2112146709561348, "critic_loss": 0.28907568569481373, "actor_loss": -34.54178944015503, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.707213878631592, "step": 129000}
{"episode_reward": 542.4923885503744, "episode": 130.0, "batch_reward": 0.21494238193333148, "critic_loss": 0.27513204762339594, "actor_loss": -34.55387070083618, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.673614978790283, "step": 130000}
{"episode_reward": 549.207065751757, "episode": 131.0, "batch_reward": 0.21664860166609287, "critic_loss": 0.2915538525730371, "actor_loss": -34.5113307723999, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.664194107055664, "step": 131000}
{"episode_reward": 104.23876501203655, "episode": 132.0, "batch_reward": 0.2160500082373619, "critic_loss": 0.29039708548784254, "actor_loss": -34.36933855819702, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.594608545303345, "step": 132000}
{"episode_reward": 544.8570905729042, "episode": 133.0, "batch_reward": 0.220167937412858, "critic_loss": 0.3029735329672694, "actor_loss": -34.82822818374634, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.190595626831055, "step": 133000}
{"episode_reward": 547.1702447508417, "episode": 134.0, "batch_reward": 0.2205780475139618, "critic_loss": 0.3231550731137395, "actor_loss": -35.01538808822632, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.004043102264404, "step": 134000}
{"episode_reward": 526.9728211832605, "episode": 135.0, "batch_reward": 0.2230640164911747, "critic_loss": 0.3000439432412386, "actor_loss": -35.30863073730469, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.315942525863647, "step": 135000}
{"episode_reward": 479.2842968448365, "episode": 136.0, "batch_reward": 0.22531278862059118, "critic_loss": 0.31119513952732086, "actor_loss": -35.174821010589596, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.044066905975342, "step": 136000}
{"episode_reward": 562.0242734653615, "episode": 137.0, "batch_reward": 0.22785926692187786, "critic_loss": 0.29336181972175834, "actor_loss": -35.421375720977785, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.128516674041748, "step": 137000}
{"episode_reward": 566.9019048980796, "episode": 138.0, "batch_reward": 0.2304056421816349, "critic_loss": 0.293889160938561, "actor_loss": -35.722678329467776, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.644116640090942, "step": 138000}
{"episode_reward": 527.7067215187863, "episode": 139.0, "batch_reward": 0.23277049277722836, "critic_loss": 0.285150858938694, "actor_loss": -36.11304484558106, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.484361171722412, "step": 139000}
{"episode_reward": 558.3896362228355, "episode": 140.0, "batch_reward": 0.2353464655727148, "critic_loss": 0.283870094537735, "actor_loss": -36.18292398452759, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.257715463638306, "step": 140000}
{"episode_reward": 557.856159073484, "episode": 141.0, "batch_reward": 0.23734516510367393, "critic_loss": 0.32268612743914127, "actor_loss": -36.25263551330566, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.85391163825989, "step": 141000}
{"episode_reward": 562.9917910474704, "episode": 142.0, "batch_reward": 0.2396114947795868, "critic_loss": 0.2770857814475894, "actor_loss": -36.35533860015869, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.390268802642822, "step": 142000}
{"episode_reward": 554.139237152723, "episode": 143.0, "batch_reward": 0.24291619275510312, "critic_loss": 0.2794604937210679, "actor_loss": -36.553302604675295, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.186169147491455, "step": 143000}
{"episode_reward": 518.1002758444722, "episode": 144.0, "batch_reward": 0.24294913907349108, "critic_loss": 0.26733091516047713, "actor_loss": -36.45931635284424, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.574652671813965, "step": 144000}
{"episode_reward": 557.6274716460365, "episode": 145.0, "batch_reward": 0.24685968838632108, "critic_loss": 0.27139216390997173, "actor_loss": -36.67200048446655, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.12096095085144, "step": 145000}
{"episode_reward": 556.1434875830674, "episode": 146.0, "batch_reward": 0.24792029714584352, "critic_loss": 0.2631699991002679, "actor_loss": -36.684786773681644, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.405014276504517, "step": 146000}
{"episode_reward": 567.1846100840804, "episode": 147.0, "batch_reward": 0.24980058811604977, "critic_loss": 0.23736486042290925, "actor_loss": -36.53984306335449, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.264298677444458, "step": 147000}
{"episode_reward": 551.278590559925, "episode": 148.0, "batch_reward": 0.25148453307151797, "critic_loss": 0.26872618770599366, "actor_loss": -36.819505187988284, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.597808837890625, "step": 148000}
{"episode_reward": 550.5906249336784, "episode": 149.0, "batch_reward": 0.25390285627543924, "critic_loss": 0.2289675749912858, "actor_loss": -36.85845265197754, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.78424620628357, "step": 149000}
{"episode_reward": 566.7094304313013, "episode": 150.0, "batch_reward": 0.25657694558799266, "critic_loss": 0.2670578242912888, "actor_loss": -37.06661332321167, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
