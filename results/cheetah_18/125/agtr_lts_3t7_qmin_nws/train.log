{"episode_reward": 0.0, "episode": 1.0, "duration": 13.234294414520264, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.156334638595581, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.21813924874453275, "critic_loss": 0.278111954206907, "actor_loss": -38.95953896199288, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 70.62754511833191, "step": 3000}
{"episode_reward": 22.09603207585276, "episode": 4.0, "batch_reward": 0.15177046709507705, "critic_loss": 0.17317087663710118, "actor_loss": -21.386250816345214, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.552139043807983, "step": 4000}
{"episode_reward": 99.01769939035229, "episode": 5.0, "batch_reward": 0.13314606227725745, "critic_loss": 0.14491078155115247, "actor_loss": -21.266584078788757, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.33482813835144, "step": 5000}
{"episode_reward": 23.41862531240823, "episode": 6.0, "batch_reward": 0.1122147259786725, "critic_loss": 0.09352730872482061, "actor_loss": -20.26262844276428, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.51864218711853, "step": 6000}
{"episode_reward": 33.730135332300826, "episode": 7.0, "batch_reward": 0.10714004652202129, "critic_loss": 0.1442673744931817, "actor_loss": -19.54883063983917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.547432899475098, "step": 7000}
{"episode_reward": 116.0484645022043, "episode": 8.0, "batch_reward": 0.10347371602803469, "critic_loss": 0.14845860037207603, "actor_loss": -20.321576208114625, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.267967224121094, "step": 8000}
{"episode_reward": 45.73067659193602, "episode": 9.0, "batch_reward": 0.09864868427440524, "critic_loss": 0.14237152345478535, "actor_loss": -19.324211060523986, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.474987268447876, "step": 9000}
{"episode_reward": 83.18522780954954, "episode": 10.0, "batch_reward": 0.09874279685691, "critic_loss": 0.1619683641269803, "actor_loss": -20.392247729301452, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.771594762802124, "step": 10000}
{"episode_reward": 120.44408705045774, "episode": 11.0, "batch_reward": 0.10169535900652409, "critic_loss": 0.1684837651178241, "actor_loss": -18.910752415657043, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.59333944320679, "step": 11000}
{"episode_reward": 81.68045068286206, "episode": 12.0, "batch_reward": 0.09680108156055212, "critic_loss": 0.18135663556307555, "actor_loss": -17.960098330020905, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.57286500930786, "step": 12000}
{"episode_reward": 32.73963255484685, "episode": 13.0, "batch_reward": 0.09560947701334953, "critic_loss": 0.20184918916225433, "actor_loss": -17.599889314174654, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.17171549797058, "step": 13000}
{"episode_reward": 128.7484760024295, "episode": 14.0, "batch_reward": 0.09327110239863395, "critic_loss": 0.2056692139431834, "actor_loss": -18.080459495067597, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.753576517105103, "step": 14000}
{"episode_reward": 15.84394516827631, "episode": 15.0, "batch_reward": 0.09156840838119387, "critic_loss": 0.2304375715777278, "actor_loss": -15.905738697052001, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.51724910736084, "step": 15000}
{"episode_reward": 81.75547869746009, "episode": 16.0, "batch_reward": 0.09367726395651699, "critic_loss": 0.3060345984250307, "actor_loss": -15.535470564365387, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.58173370361328, "step": 16000}
{"episode_reward": 231.59323859289984, "episode": 17.0, "batch_reward": 0.10311767008900642, "critic_loss": 0.3644153668135405, "actor_loss": -17.41601815503836, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.41050434112549, "step": 17000}
{"episode_reward": 240.4528485122923, "episode": 18.0, "batch_reward": 0.11050130759179592, "critic_loss": 0.38197962795197965, "actor_loss": -18.449475706219673, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.51009488105774, "step": 18000}
{"episode_reward": 230.72941763290012, "episode": 19.0, "batch_reward": 0.1165134529620409, "critic_loss": 0.4032006854712963, "actor_loss": -17.30245264750719, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.185266733169556, "step": 19000}
{"episode_reward": 235.46225907982875, "episode": 20.0, "batch_reward": 0.12085302011668682, "critic_loss": 0.4335324450582266, "actor_loss": -17.48741369128227, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.848058938980103, "step": 20000}
{"episode_reward": 90.65318834788938, "episode": 21.0, "batch_reward": 0.12124642135947943, "critic_loss": 0.4102510822713375, "actor_loss": -17.075009628653525, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.103084564208984, "step": 21000}
{"episode_reward": 141.1824452721092, "episode": 22.0, "batch_reward": 0.12680458717048168, "critic_loss": 0.3327857351601124, "actor_loss": -17.773003199100494, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.47641372680664, "step": 22000}
{"episode_reward": 411.5515228047868, "episode": 23.0, "batch_reward": 0.1318122740164399, "critic_loss": 0.32658039528131483, "actor_loss": -18.820570386886597, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.20288586616516, "step": 23000}
{"episode_reward": 30.34188675686669, "episode": 24.0, "batch_reward": 0.13021657709032297, "critic_loss": 0.30135747949779035, "actor_loss": -17.7109992685318, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.77593994140625, "step": 24000}
{"episode_reward": 133.33456977854223, "episode": 25.0, "batch_reward": 0.13088779257237912, "critic_loss": 0.294713141836226, "actor_loss": -18.285980177879335, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.48738741874695, "step": 25000}
{"episode_reward": 193.18831087283718, "episode": 26.0, "batch_reward": 0.13316880748420953, "critic_loss": 0.32603075982630253, "actor_loss": -18.40958034324646, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.95099687576294, "step": 26000}
{"episode_reward": 250.36953526253674, "episode": 27.0, "batch_reward": 0.1399677447229624, "critic_loss": 0.32269524893164636, "actor_loss": -18.549802350997926, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.024109840393066, "step": 27000}
{"episode_reward": 318.54703612891797, "episode": 28.0, "batch_reward": 0.14434228145331143, "critic_loss": 0.33650671307742597, "actor_loss": -18.791526290893554, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.360048055648804, "step": 28000}
{"episode_reward": 151.49441805639128, "episode": 29.0, "batch_reward": 0.14381204097718, "critic_loss": 0.330881486415863, "actor_loss": -17.743928483963014, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.626664400100708, "step": 29000}
{"episode_reward": 70.09261733933008, "episode": 30.0, "batch_reward": 0.1413719020560384, "critic_loss": 0.3156055938154459, "actor_loss": -17.398416543960572, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.643333435058594, "step": 30000}
{"episode_reward": 107.02102114251262, "episode": 31.0, "batch_reward": 0.1407468707934022, "critic_loss": 0.3054541676864028, "actor_loss": -16.991684165000915, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.515132665634155, "step": 31000}
{"episode_reward": 149.20086487723236, "episode": 32.0, "batch_reward": 0.1406021010056138, "critic_loss": 0.3116146859675646, "actor_loss": -16.742144413948058, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.215834856033325, "step": 32000}
{"episode_reward": 131.1417893405244, "episode": 33.0, "batch_reward": 0.13975459907203913, "critic_loss": 0.3392724885195494, "actor_loss": -16.008114003181458, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.781918048858643, "step": 33000}
{"episode_reward": 107.16367496308834, "episode": 34.0, "batch_reward": 0.13946879195421935, "critic_loss": 0.3045179840251803, "actor_loss": -17.129559690475464, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.398199796676636, "step": 34000}
{"episode_reward": 114.11470137739714, "episode": 35.0, "batch_reward": 0.1381005517989397, "critic_loss": 0.3059048023894429, "actor_loss": -16.05723554992676, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.34223747253418, "step": 35000}
{"episode_reward": 95.3765698319941, "episode": 36.0, "batch_reward": 0.13867587336152792, "critic_loss": 0.3056781310066581, "actor_loss": -16.852553656578063, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.972908973693848, "step": 36000}
{"episode_reward": 336.56049907692267, "episode": 37.0, "batch_reward": 0.1442175352051854, "critic_loss": 0.31056314051896333, "actor_loss": -16.619265836715698, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.323532819747925, "step": 37000}
{"episode_reward": 267.40210441125583, "episode": 38.0, "batch_reward": 0.1459282969981432, "critic_loss": 0.3538451930731535, "actor_loss": -16.37160767364502, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.55682134628296, "step": 38000}
{"episode_reward": 104.16752441105244, "episode": 39.0, "batch_reward": 0.14426423563808202, "critic_loss": 0.31244373352080584, "actor_loss": -16.176664625167845, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.163695812225342, "step": 39000}
{"episode_reward": 104.24622789910008, "episode": 40.0, "batch_reward": 0.14650945363938808, "critic_loss": 0.3427328094094992, "actor_loss": -16.451429712295532, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.35690426826477, "step": 40000}
{"episode_reward": 343.78384821121506, "episode": 41.0, "batch_reward": 0.15182721518725156, "critic_loss": 0.40483177959918976, "actor_loss": -16.748539224624633, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.89091682434082, "step": 41000}
{"episode_reward": 411.60312152280784, "episode": 42.0, "batch_reward": 0.15776169925928116, "critic_loss": 0.4422543155401945, "actor_loss": -17.925040674209594, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.29238772392273, "step": 42000}
{"episode_reward": 376.4388891624346, "episode": 43.0, "batch_reward": 0.16069171775132418, "critic_loss": 0.3725226370990276, "actor_loss": -18.091719583511352, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.571349620819092, "step": 43000}
{"episode_reward": 161.77498946021342, "episode": 44.0, "batch_reward": 0.16309613360464573, "critic_loss": 0.34517271199822425, "actor_loss": -18.282282287597656, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.373459100723267, "step": 44000}
{"episode_reward": 427.35786890875204, "episode": 45.0, "batch_reward": 0.1687873547375202, "critic_loss": 0.3478514682650566, "actor_loss": -18.807860418319702, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.399152278900146, "step": 45000}
{"episode_reward": 341.22970941170576, "episode": 46.0, "batch_reward": 0.16978975227475165, "critic_loss": 0.34459436136484145, "actor_loss": -18.817352025985716, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.474730014801025, "step": 46000}
{"episode_reward": 86.18818413718114, "episode": 47.0, "batch_reward": 0.17147855731099845, "critic_loss": 0.292672950014472, "actor_loss": -18.454851234436035, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.640008449554443, "step": 47000}
{"episode_reward": 374.2833535181323, "episode": 48.0, "batch_reward": 0.17515362191945313, "critic_loss": 0.3148381558954716, "actor_loss": -18.93423440170288, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.83299946784973, "step": 48000}
{"episode_reward": 266.9369621707451, "episode": 49.0, "batch_reward": 0.17546900305151938, "critic_loss": 0.31374809772521256, "actor_loss": -19.110974889755248, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.545732259750366, "step": 49000}
{"episode_reward": 124.77133391776324, "episode": 50.0, "batch_reward": 0.17500073786079884, "critic_loss": 0.3297224622145295, "actor_loss": -19.179734184265136, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.63200068473816, "step": 50000}
{"episode_reward": 311.8705252813155, "episode": 51.0, "batch_reward": 0.17876159623265267, "critic_loss": 0.3380755533277988, "actor_loss": -19.547901462554933, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.73664593696594, "step": 51000}
{"episode_reward": 418.09763179390853, "episode": 52.0, "batch_reward": 0.18332564602792262, "critic_loss": 0.3498544104099274, "actor_loss": -20.49179037475586, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.32880997657776, "step": 52000}
{"episode_reward": 424.0001919671191, "episode": 53.0, "batch_reward": 0.18823340889811516, "critic_loss": 0.3119837009832263, "actor_loss": -20.815790658950807, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.005138635635376, "step": 53000}
{"episode_reward": 410.46806217396, "episode": 54.0, "batch_reward": 0.19276528173685073, "critic_loss": 0.311264532789588, "actor_loss": -21.37312595939636, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.639035940170288, "step": 54000}
{"episode_reward": 462.7472078642745, "episode": 55.0, "batch_reward": 0.19761869864165782, "critic_loss": 0.28101299617439507, "actor_loss": -21.77662412071228, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.6234028339386, "step": 55000}
{"episode_reward": 406.01271861988795, "episode": 56.0, "batch_reward": 0.2013610001206398, "critic_loss": 0.2770595010370016, "actor_loss": -22.44230704498291, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.110841751098633, "step": 56000}
{"episode_reward": 481.4098347220773, "episode": 57.0, "batch_reward": 0.20663359881937504, "critic_loss": 0.2887678304538131, "actor_loss": -22.854485357284545, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.502307653427124, "step": 57000}
{"episode_reward": 491.7372758933354, "episode": 58.0, "batch_reward": 0.21185291488468647, "critic_loss": 0.30062932600080966, "actor_loss": -23.57803310394287, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.41448998451233, "step": 58000}
{"episode_reward": 433.3743271448108, "episode": 59.0, "batch_reward": 0.2146508747935295, "critic_loss": 0.3363448453247547, "actor_loss": -24.053979736328124, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.507562398910522, "step": 59000}
{"episode_reward": 310.3709230414409, "episode": 60.0, "batch_reward": 0.21592919473350047, "critic_loss": 0.33603895542025564, "actor_loss": -23.961049282073976, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.77277135848999, "step": 60000}
{"episode_reward": 442.3262701879123, "episode": 61.0, "batch_reward": 0.21988749507069588, "critic_loss": 0.3489352215230465, "actor_loss": -24.76386626434326, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.82487201690674, "step": 61000}
{"episode_reward": 285.0381730558059, "episode": 62.0, "batch_reward": 0.22116464048624038, "critic_loss": 0.32282799077033997, "actor_loss": -24.5403596572876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.482677221298218, "step": 62000}
{"episode_reward": 510.8919431765369, "episode": 63.0, "batch_reward": 0.2256673986017704, "critic_loss": 0.2912047605738044, "actor_loss": -25.248601444244386, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.49734377861023, "step": 63000}
{"episode_reward": 521.7884860006021, "episode": 64.0, "batch_reward": 0.23073050321638583, "critic_loss": 0.30991644342243674, "actor_loss": -25.676573596954345, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.168486833572388, "step": 64000}
{"episode_reward": 491.0717217488069, "episode": 65.0, "batch_reward": 0.23561309714615344, "critic_loss": 0.29583975120633843, "actor_loss": -26.082520862579347, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.876996994018555, "step": 65000}
{"episode_reward": 486.4417812518319, "episode": 66.0, "batch_reward": 0.23866103300452232, "critic_loss": 0.2842965811565518, "actor_loss": -26.67641939163208, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.638947248458862, "step": 66000}
{"episode_reward": 488.1333469391255, "episode": 67.0, "batch_reward": 0.24223497840762137, "critic_loss": 0.3019304792881012, "actor_loss": -26.870397342681883, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.230663537979126, "step": 67000}
{"episode_reward": 500.3368438356158, "episode": 68.0, "batch_reward": 0.24504765567183495, "critic_loss": 0.29606106616556643, "actor_loss": -27.5272974357605, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.480464220046997, "step": 68000}
{"episode_reward": 511.41386780042865, "episode": 69.0, "batch_reward": 0.24821363951265812, "critic_loss": 0.30284530443698165, "actor_loss": -27.701889808654784, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.445533752441406, "step": 69000}
{"episode_reward": 167.68992293234285, "episode": 70.0, "batch_reward": 0.24832466235756875, "critic_loss": 0.3035955644622445, "actor_loss": -27.584450008392334, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.479122161865234, "step": 70000}
{"episode_reward": 479.89671147932233, "episode": 71.0, "batch_reward": 0.25269856774806976, "critic_loss": 0.2832624206021428, "actor_loss": -28.118351333618165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.056472301483154, "step": 71000}
{"episode_reward": 512.0757773093371, "episode": 72.0, "batch_reward": 0.25549741680920124, "critic_loss": 0.276755943544209, "actor_loss": -28.38765425109863, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.319108963012695, "step": 72000}
{"episode_reward": 500.26522702800384, "episode": 73.0, "batch_reward": 0.2589211109876633, "critic_loss": 0.29197291225939986, "actor_loss": -28.744796878814697, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.77817964553833, "step": 73000}
{"episode_reward": 514.2387226609421, "episode": 74.0, "batch_reward": 0.26269082476198674, "critic_loss": 0.2524840982705355, "actor_loss": -29.2032519569397, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.569278717041016, "step": 74000}
{"episode_reward": 498.0532076607037, "episode": 75.0, "batch_reward": 0.2672127111107111, "critic_loss": 0.3018579866737127, "actor_loss": -29.55218051147461, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.490938663482666, "step": 75000}
{"episode_reward": 530.7495375412622, "episode": 76.0, "batch_reward": 0.26913466382026674, "critic_loss": 0.2808470018357038, "actor_loss": -29.70794430923462, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.935543298721313, "step": 76000}
{"episode_reward": 507.3264231186214, "episode": 77.0, "batch_reward": 0.2725884181857109, "critic_loss": 0.2839801001623273, "actor_loss": -30.28076145172119, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.053168535232544, "step": 77000}
{"episode_reward": 502.24131802547134, "episode": 78.0, "batch_reward": 0.2758252845853567, "critic_loss": 0.28930968353152275, "actor_loss": -30.369463317871094, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.54932951927185, "step": 78000}
{"episode_reward": 560.5026614845731, "episode": 79.0, "batch_reward": 0.2789246906340122, "critic_loss": 0.2742901982814074, "actor_loss": -31.081753414154054, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.661291122436523, "step": 79000}
{"episode_reward": 527.3501602833923, "episode": 80.0, "batch_reward": 0.28204362857341764, "critic_loss": 0.2893735221922398, "actor_loss": -31.068203536987305, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.482600688934326, "step": 80000}
{"episode_reward": 542.1233361531929, "episode": 81.0, "batch_reward": 0.28674836732447145, "critic_loss": 0.2826456651464105, "actor_loss": -31.80138697052002, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.22061777114868, "step": 81000}
{"episode_reward": 516.7053700957874, "episode": 82.0, "batch_reward": 0.2892540252059698, "critic_loss": 0.2889489390403032, "actor_loss": -31.728618309020995, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.13250732421875, "step": 82000}
{"episode_reward": 513.1321355454734, "episode": 83.0, "batch_reward": 0.2919812212586403, "critic_loss": 0.2638837685361505, "actor_loss": -32.274758457183836, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.265889883041382, "step": 83000}
{"episode_reward": 554.3525879075653, "episode": 84.0, "batch_reward": 0.2948977638185024, "critic_loss": 0.27014842710644005, "actor_loss": -32.470767112731934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.14891743659973, "step": 84000}
{"episode_reward": 547.2184780418088, "episode": 85.0, "batch_reward": 0.29665478207170964, "critic_loss": 0.26218236033618453, "actor_loss": -32.57453411483765, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.11960244178772, "step": 85000}
{"episode_reward": 564.0023409102587, "episode": 86.0, "batch_reward": 0.3008537645339966, "critic_loss": 0.25894100924581287, "actor_loss": -33.03545426940918, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.46150541305542, "step": 86000}
{"episode_reward": 535.5760126685235, "episode": 87.0, "batch_reward": 0.3029455552101135, "critic_loss": 0.2665267522484064, "actor_loss": -33.322354217529295, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.704309701919556, "step": 87000}
{"episode_reward": 548.6370930940346, "episode": 88.0, "batch_reward": 0.30593629387021065, "critic_loss": 0.24867593842744828, "actor_loss": -33.70407796478271, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.544391632080078, "step": 88000}
{"episode_reward": 554.858931964841, "episode": 89.0, "batch_reward": 0.30817269964516164, "critic_loss": 0.24854947277158498, "actor_loss": -33.95201976776123, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.351362705230713, "step": 89000}
{"episode_reward": 519.4076708516441, "episode": 90.0, "batch_reward": 0.31088750970363616, "critic_loss": 0.26086167512834074, "actor_loss": -34.09714316558838, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.553417205810547, "step": 90000}
{"episode_reward": 497.67687235630467, "episode": 91.0, "batch_reward": 0.3132714096456766, "critic_loss": 0.2749570379331708, "actor_loss": -34.263157314300535, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.88959717750549, "step": 91000}
{"episode_reward": 527.2968525985204, "episode": 92.0, "batch_reward": 0.3157125297486782, "critic_loss": 0.27719750223308803, "actor_loss": -34.78086972427368, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.14829707145691, "step": 92000}
{"episode_reward": 500.896182503914, "episode": 93.0, "batch_reward": 0.31718495908379557, "critic_loss": 0.269189158834517, "actor_loss": -35.364906024932864, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.281506538391113, "step": 93000}
{"episode_reward": 554.0812825649449, "episode": 94.0, "batch_reward": 0.32045443773269655, "critic_loss": 0.26211383083462714, "actor_loss": -35.67866045379639, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.480421781539917, "step": 94000}
{"episode_reward": 543.7950500649025, "episode": 95.0, "batch_reward": 0.3227341278493404, "critic_loss": 0.26712454997003077, "actor_loss": -35.85414038848877, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.2554829120636, "step": 95000}
{"episode_reward": 568.4500768816961, "episode": 96.0, "batch_reward": 0.3239117235541344, "critic_loss": 0.25387376437336207, "actor_loss": -35.857033622741696, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.27709937095642, "step": 96000}
{"episode_reward": 538.9345678853704, "episode": 97.0, "batch_reward": 0.32709710842370987, "critic_loss": 0.24794468710571527, "actor_loss": -36.277321212768555, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.4306857585907, "step": 97000}
{"episode_reward": 568.9655060941869, "episode": 98.0, "batch_reward": 0.32999080273509024, "critic_loss": 0.23796091014891863, "actor_loss": -36.456683460235595, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.480889081954956, "step": 98000}
{"episode_reward": 594.0154003266601, "episode": 99.0, "batch_reward": 0.3323798947036266, "critic_loss": 0.23312564243376255, "actor_loss": -36.7817452545166, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.112284660339355, "step": 99000}
{"episode_reward": 557.2185085665407, "episode": 100.0, "batch_reward": 0.33470165607333185, "critic_loss": 0.24363492285460234, "actor_loss": -37.06843832015991, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.26291251182556, "step": 100000}
{"episode_reward": 541.9073222963194, "episode": 101.0, "batch_reward": 0.336011651724577, "critic_loss": 0.23759810337424278, "actor_loss": -37.359072052001956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.33787536621094, "step": 101000}
{"episode_reward": 525.3004221762307, "episode": 102.0, "batch_reward": 0.33740010678768156, "critic_loss": 0.24628049969673158, "actor_loss": -37.56948915100098, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.471847772598267, "step": 102000}
{"episode_reward": 571.4154494216972, "episode": 103.0, "batch_reward": 0.33891626888513565, "critic_loss": 0.22748853582143783, "actor_loss": -37.79085383605957, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.667062520980835, "step": 103000}
{"episode_reward": 384.60278135248285, "episode": 104.0, "batch_reward": 0.3427729489505291, "critic_loss": 0.24568072792887688, "actor_loss": -38.024513862609865, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.3271484375, "step": 104000}
{"episode_reward": 564.7581066485213, "episode": 105.0, "batch_reward": 0.344003528624773, "critic_loss": 0.2415535043925047, "actor_loss": -38.49207849121094, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.282843351364136, "step": 105000}
{"episode_reward": 569.3897718928006, "episode": 106.0, "batch_reward": 0.34498741146922113, "critic_loss": 0.25295243706554177, "actor_loss": -38.781617149353025, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.42874264717102, "step": 106000}
{"episode_reward": 564.3104925903152, "episode": 107.0, "batch_reward": 0.3472075448036194, "critic_loss": 0.2732454849928617, "actor_loss": -39.0194347076416, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.953766584396362, "step": 107000}
{"episode_reward": 525.9499683743583, "episode": 108.0, "batch_reward": 0.34920607537031173, "critic_loss": 0.2677241396680474, "actor_loss": -39.34268018341064, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.166345596313477, "step": 108000}
{"episode_reward": 549.6559564220299, "episode": 109.0, "batch_reward": 0.3507804698050022, "critic_loss": 0.26026735761016606, "actor_loss": -39.276884155273436, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.53593921661377, "step": 109000}
{"episode_reward": 591.8061751103191, "episode": 110.0, "batch_reward": 0.3538362517952919, "critic_loss": 0.2646820253655314, "actor_loss": -39.776138671875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.267300844192505, "step": 110000}
{"episode_reward": 603.981747840179, "episode": 111.0, "batch_reward": 0.3563274402618408, "critic_loss": 0.27126002181321385, "actor_loss": -40.21568200683594, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.92344355583191, "step": 111000}
{"episode_reward": 569.7595847602103, "episode": 112.0, "batch_reward": 0.35822872471809386, "critic_loss": 0.26813576675206424, "actor_loss": -40.637209098815916, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.845789432525635, "step": 112000}
{"episode_reward": 591.9724907074337, "episode": 113.0, "batch_reward": 0.3593361859023571, "critic_loss": 0.2815578533038497, "actor_loss": -40.746453857421876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.893104076385498, "step": 113000}
{"episode_reward": 575.9110278190832, "episode": 114.0, "batch_reward": 0.3617194651961327, "critic_loss": 0.27014784241467715, "actor_loss": -40.911324531555174, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.995490789413452, "step": 114000}
{"episode_reward": 586.09702269509, "episode": 115.0, "batch_reward": 0.3641185927093029, "critic_loss": 0.2826957338154316, "actor_loss": -41.27553172302246, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.5072124004364, "step": 115000}
{"episode_reward": 588.2424084993972, "episode": 116.0, "batch_reward": 0.36596483224630355, "critic_loss": 0.2581607098281383, "actor_loss": -41.56698197937012, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.91247797012329, "step": 116000}
{"episode_reward": 511.8752393552809, "episode": 117.0, "batch_reward": 0.3668852490782738, "critic_loss": 0.26485363025963304, "actor_loss": -41.83953920745849, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.642961263656616, "step": 117000}
{"episode_reward": 587.6633693041097, "episode": 118.0, "batch_reward": 0.36881136417388916, "critic_loss": 0.27289708953350783, "actor_loss": -42.0444154586792, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.478615522384644, "step": 118000}
{"episode_reward": 619.0047363411434, "episode": 119.0, "batch_reward": 0.3702671874165535, "critic_loss": 0.2742730153426528, "actor_loss": -42.349231140136716, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.518235206604004, "step": 119000}
{"episode_reward": 392.0298838974688, "episode": 120.0, "batch_reward": 0.37077191519737246, "critic_loss": 0.29803591780364513, "actor_loss": -42.567908378601075, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.8832745552063, "step": 120000}
{"episode_reward": 566.7078773538362, "episode": 121.0, "batch_reward": 0.3728588358461857, "critic_loss": 0.3271687784343958, "actor_loss": -42.776576553344725, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.80511713027954, "step": 121000}
{"episode_reward": 548.183998650508, "episode": 122.0, "batch_reward": 0.3748191405236721, "critic_loss": 0.3527838404774666, "actor_loss": -43.10546140289306, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.208179473876953, "step": 122000}
{"episode_reward": 555.6085108410509, "episode": 123.0, "batch_reward": 0.3761775580346584, "critic_loss": 0.40104855042695997, "actor_loss": -43.463909118652346, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.433902263641357, "step": 123000}
{"episode_reward": 460.87657819086803, "episode": 124.0, "batch_reward": 0.375802935987711, "critic_loss": 0.43587418876588346, "actor_loss": -43.694156196594236, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.36331558227539, "step": 124000}
{"episode_reward": 576.8112369122717, "episode": 125.0, "batch_reward": 0.3762237383425236, "critic_loss": 0.4918606149852276, "actor_loss": -44.2806900100708, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.70875573158264, "step": 125000}
{"episode_reward": 7.469219548836123, "episode": 126.0, "batch_reward": 0.3724424650371075, "critic_loss": 0.5673907555490733, "actor_loss": -45.3126044921875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.118797063827515, "step": 126000}
{"episode_reward": 323.33483985570575, "episode": 127.0, "batch_reward": 0.3725271443128586, "critic_loss": 0.6392210724204779, "actor_loss": -46.46833647918701, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.26227331161499, "step": 127000}
{"episode_reward": 383.65614231307376, "episode": 128.0, "batch_reward": 0.3724426166713238, "critic_loss": 0.7685972141027451, "actor_loss": -47.531546279907225, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.50520896911621, "step": 128000}
{"episode_reward": 10.535424290319437, "episode": 129.0, "batch_reward": 0.3702318481206894, "critic_loss": 0.8389707207679749, "actor_loss": -48.323117988586425, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.64380192756653, "step": 129000}
{"episode_reward": 6.338427396727498, "episode": 130.0, "batch_reward": 0.36706582915782926, "critic_loss": 0.8888755802810192, "actor_loss": -49.1654984588623, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.891732692718506, "step": 130000}
{"episode_reward": 6.752800491290207, "episode": 131.0, "batch_reward": 0.3652637715041637, "critic_loss": 0.953704623490572, "actor_loss": -50.34983171081543, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.0601921081543, "step": 131000}
{"episode_reward": 8.941435249970308, "episode": 132.0, "batch_reward": 0.36148787412047384, "critic_loss": 1.1965200096964836, "actor_loss": -51.62410154724121, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.49571943283081, "step": 132000}
{"episode_reward": 9.181675552131756, "episode": 133.0, "batch_reward": 0.35781284725666046, "critic_loss": 1.6183257694840432, "actor_loss": -53.98742712402344, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.82051658630371, "step": 133000}
{"episode_reward": 15.306352405687054, "episode": 134.0, "batch_reward": 0.35602211287617685, "critic_loss": 2.1963915982842446, "actor_loss": -57.84737171936035, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.112370252609253, "step": 134000}
{"episode_reward": 16.977631939743418, "episode": 135.0, "batch_reward": 0.35297270825505256, "critic_loss": 1.8946780189275743, "actor_loss": -61.01546340942383, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.448938846588135, "step": 135000}
{"episode_reward": 16.001191799026543, "episode": 136.0, "batch_reward": 0.3517050275504589, "critic_loss": 1.4881114670038222, "actor_loss": -63.45026657104492, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.62406611442566, "step": 136000}
{"episode_reward": 12.224537571752942, "episode": 137.0, "batch_reward": 0.34832741543650625, "critic_loss": 1.0889877879619598, "actor_loss": -64.55137969970703, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.31304144859314, "step": 137000}
{"episode_reward": 11.73271940155947, "episode": 138.0, "batch_reward": 0.34646598127484324, "critic_loss": 0.753972299695015, "actor_loss": -64.24732260131836, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.333707809448242, "step": 138000}
{"episode_reward": 12.474563806192403, "episode": 139.0, "batch_reward": 0.34296365880966184, "critic_loss": 0.6174177731871605, "actor_loss": -63.41164515686035, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.063584566116333, "step": 139000}
{"episode_reward": 27.500950924596495, "episode": 140.0, "batch_reward": 0.34004972997307775, "critic_loss": 0.5788471230715513, "actor_loss": -62.68416887664795, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.312960386276245, "step": 140000}
{"episode_reward": 37.43250484414057, "episode": 141.0, "batch_reward": 0.3392102466523647, "critic_loss": 0.6520696991086006, "actor_loss": -62.15782193756103, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.81184220314026, "step": 141000}
{"episode_reward": 41.93268961575746, "episode": 142.0, "batch_reward": 0.3369649557173252, "critic_loss": 0.7576525694131852, "actor_loss": -61.762952011108396, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.180855751037598, "step": 142000}
{"episode_reward": 311.21552949036345, "episode": 143.0, "batch_reward": 0.33797776225209236, "critic_loss": 0.7623077819645405, "actor_loss": -61.62859824371338, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.49811601638794, "step": 143000}
{"episode_reward": 298.9069737039374, "episode": 144.0, "batch_reward": 0.33788910871744154, "critic_loss": 0.7356570317745209, "actor_loss": -61.77425792694092, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.33976650238037, "step": 144000}
{"episode_reward": 267.37803429842637, "episode": 145.0, "batch_reward": 0.3367363582253456, "critic_loss": 0.6223023113161326, "actor_loss": -61.40132417297363, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.098917722702026, "step": 145000}
{"episode_reward": 292.1589533267384, "episode": 146.0, "batch_reward": 0.33653345653414724, "critic_loss": 0.5463757674992085, "actor_loss": -60.03402083587646, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.620906352996826, "step": 146000}
{"episode_reward": 351.5500365201364, "episode": 147.0, "batch_reward": 0.338029657125473, "critic_loss": 0.5977668660581112, "actor_loss": -60.39035703277588, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.204209089279175, "step": 147000}
{"episode_reward": 255.99512465354394, "episode": 148.0, "batch_reward": 0.3375901772081852, "critic_loss": 0.594679619640112, "actor_loss": -59.19540545654297, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.4045832157135, "step": 148000}
{"episode_reward": 407.0132157754229, "episode": 149.0, "batch_reward": 0.33793802520632743, "critic_loss": 0.5083707130551338, "actor_loss": -58.45399448394775, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.618836641311646, "step": 149000}
{"episode_reward": 508.9625226194603, "episode": 150.0, "batch_reward": 0.33878255879879, "critic_loss": 0.45329204298555853, "actor_loss": -57.47248191070557, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
