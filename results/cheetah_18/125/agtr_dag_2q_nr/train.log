{"episode": 1.0, "duration": 18.601263761520386, "episode_reward": 5.1931688606333894, "step": 1000}
{"episode": 2.0, "duration": 1.6395690441131592, "episode_reward": 454.7514538707513, "step": 2000}
{"episode": 3.0, "batch_reward": 0.23013642891401767, "critic_loss": 0.19790571347927402, "actor_loss": -45.317839985420434, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 84.4570529460907, "episode_reward": 255.6612838199836, "step": 3000}
{"episode": 4.0, "batch_reward": 0.24980341377854348, "critic_loss": 0.21813413208723068, "actor_loss": -45.35863484954834, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.348995208740234, "episode_reward": 280.32277023531583, "step": 4000}
{"episode": 5.0, "batch_reward": 0.26049270208179953, "critic_loss": 0.2203179013207555, "actor_loss": -45.5626410446167, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.192644119262695, "episode_reward": 383.6904718210636, "step": 5000}
{"episode": 6.0, "batch_reward": 0.2732628093659878, "critic_loss": 0.2294050675109029, "actor_loss": -45.93598383331299, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.917046070098877, "episode_reward": 253.80777121909054, "step": 6000}
{"episode": 7.0, "batch_reward": 0.27649409680068493, "critic_loss": 0.21476095025241376, "actor_loss": -45.8525005569458, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.42753553390503, "episode_reward": 356.2179485203756, "step": 7000}
{"episode": 8.0, "batch_reward": 0.287871871650219, "critic_loss": 0.20777088168263436, "actor_loss": -46.24153385162354, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.179375410079956, "episode_reward": 369.5999816937484, "step": 8000}
{"episode": 9.0, "batch_reward": 0.2945325113236904, "critic_loss": 0.2506924869120121, "actor_loss": -46.45154103088379, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.099684953689575, "episode_reward": 326.0432710089194, "step": 9000}
{"episode": 10.0, "batch_reward": 0.2985078125, "critic_loss": 0.26756804041564464, "actor_loss": -39.370402954101564, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 4438.622534036636, "episode_reward": 350.17713436301653, "step": 10000}
{"episode": 11.0, "batch_reward": 0.30519830510020257, "critic_loss": 0.20449637456983327, "actor_loss": -39.666964073181155, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.61554574966431, "episode_reward": 356.57499798947117, "step": 11000}
{"episode": 12.0, "batch_reward": 0.31010210907459257, "critic_loss": 0.19887552830576896, "actor_loss": -36.37614172363281, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 507.0337290763855, "episode_reward": 329.7951915344742, "step": 12000}
{"episode": 13.0, "batch_reward": 0.31020177817344663, "critic_loss": 0.20059326629340649, "actor_loss": -36.24883578491211, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 33.290207862854004, "episode_reward": 327.1076585884829, "step": 13000}
{"episode": 14.0, "batch_reward": 0.3069666066467762, "critic_loss": 0.2073645090162754, "actor_loss": -33.992951961517335, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 558.2511222362518, "episode_reward": 114.42208580658497, "step": 14000}
{"episode": 15.0, "batch_reward": 0.29912121507525447, "critic_loss": 0.1841934860870242, "actor_loss": -33.04590572357178, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 29.77627921104431, "episode_reward": 371.7987101395502, "step": 15000}
{"episode": 16.0, "batch_reward": 0.30379879888892175, "critic_loss": 0.1760351114049554, "actor_loss": -32.28269795608521, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 591.4948501586914, "episode_reward": 372.6052553685208, "step": 16000}
{"episode": 17.0, "batch_reward": 0.30793406745791435, "critic_loss": 0.18639274025708438, "actor_loss": -32.477263542175294, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 25.385862827301025, "episode_reward": 368.55287710826286, "step": 17000}
{"episode": 18.0, "batch_reward": 0.3117602741420269, "critic_loss": 0.19312562964856625, "actor_loss": -32.16743461227417, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 586.268616437912, "episode_reward": 374.9260736692347, "step": 18000}
{"episode": 19.0, "batch_reward": 0.31585421961545945, "critic_loss": 0.17142124519497157, "actor_loss": -32.42438101959228, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.34593892097473, "episode_reward": 394.4982894138913, "step": 19000}
{"episode": 20.0, "batch_reward": 0.31990360406041146, "critic_loss": 0.1574698820412159, "actor_loss": -32.280626697540285, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 627.6192016601562, "episode_reward": 390.0186213492793, "step": 20000}
{"episode": 21.0, "batch_reward": 0.32352379655838015, "critic_loss": 0.1535143978446722, "actor_loss": -32.34185667037964, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 47.98816394805908, "episode_reward": 395.4112100656316, "step": 21000}
{"episode": 22.0, "batch_reward": 0.32638663905858994, "critic_loss": 0.1483064325749874, "actor_loss": -32.52938547515869, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 600.4157028198242, "episode_reward": 390.4067894218891, "step": 22000}
{"episode": 23.0, "batch_reward": 0.32906088641285897, "critic_loss": 0.1353504293859005, "actor_loss": -32.700637935638426, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.238569021224976, "episode_reward": 388.2508479511681, "step": 23000}
{"episode": 24.0, "batch_reward": 0.3318412920832634, "critic_loss": 0.12180381627753377, "actor_loss": -32.92368758010864, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 616.0264132022858, "episode_reward": 382.76535849055176, "step": 24000}
{"episode": 25.0, "batch_reward": 0.3342817656695843, "critic_loss": 0.11984751120582222, "actor_loss": -32.981119060516356, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 30.1489999294281, "episode_reward": 395.3012546309348, "step": 25000}
{"episode": 26.0, "batch_reward": 0.3360977543890476, "critic_loss": 0.10759954944998026, "actor_loss": -32.836900390625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 620.9962565898895, "episode_reward": 378.45618581906047, "step": 26000}
{"episode": 27.0, "batch_reward": 0.33726019608974456, "critic_loss": 0.10850220324099064, "actor_loss": -32.895391513824464, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.893430948257446, "episode_reward": 383.95191160829233, "step": 27000}
{"episode": 28.0, "batch_reward": 0.33861173725128174, "critic_loss": 0.10249672772735358, "actor_loss": -33.04561062240601, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 616.72176861763, "episode_reward": 379.85733022105376, "step": 28000}
{"episode": 29.0, "batch_reward": 0.34184798926115034, "critic_loss": 0.09141809243708848, "actor_loss": -33.14278030014038, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 29.573816061019897, "episode_reward": 412.87331644500074, "step": 29000}
{"episode": 30.0, "batch_reward": 0.34406851610541345, "critic_loss": 0.0945290661714971, "actor_loss": -33.45493426513672, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 636.3626754283905, "episode_reward": 414.78222263109114, "step": 30000}
{"episode": 31.0, "batch_reward": 0.34638538175821304, "critic_loss": 0.09625838301703334, "actor_loss": -33.50055238723755, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 53.79158043861389, "episode_reward": 403.3678253953737, "step": 31000}
{"episode": 32.0, "batch_reward": 0.34844411170482636, "critic_loss": 0.08711737667024136, "actor_loss": -33.95729600143433, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 679.9795002937317, "episode_reward": 414.3325232381582, "step": 32000}
{"episode": 33.0, "batch_reward": 0.35012064066529275, "critic_loss": 0.08260305356979371, "actor_loss": -34.03132828903198, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.44127154350281, "episode_reward": 409.44706981758236, "step": 33000}
{"episode": 34.0, "batch_reward": 0.35179860311746597, "critic_loss": 0.0859977606870234, "actor_loss": -34.107947299957274, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 597.8183190822601, "episode_reward": 392.30888851501317, "step": 34000}
{"episode": 35.0, "batch_reward": 0.352774744451046, "critic_loss": 0.07912377396970988, "actor_loss": -34.09464001083374, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.26958441734314, "episode_reward": 394.622589564436, "step": 35000}
{"episode": 36.0, "batch_reward": 0.3538271734416485, "critic_loss": 0.07875824654847384, "actor_loss": -34.4474718170166, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 631.7255530357361, "episode_reward": 398.36959582732027, "step": 36000}
{"episode": 37.0, "batch_reward": 0.35527989560365675, "critic_loss": 0.07703446171432733, "actor_loss": -34.452717681884764, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 31.30271077156067, "episode_reward": 402.9482360665874, "step": 37000}
{"episode": 38.0, "batch_reward": 0.3551794377565384, "critic_loss": 0.09724448774009943, "actor_loss": -34.60448979949951, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 639.107221364975, "episode_reward": 201.47210941435443, "step": 38000}
{"episode": 39.0, "batch_reward": 0.3527104651033878, "critic_loss": 0.09303694905340672, "actor_loss": -34.123249984741214, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 24.84911584854126, "episode_reward": 420.3379218185015, "step": 39000}
{"episode": 40.0, "batch_reward": 0.3544897910952568, "critic_loss": 0.08981232227757573, "actor_loss": -34.15480062103271, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 653.118795633316, "episode_reward": 418.2171462394717, "step": 40000}
{"episode": 41.0, "batch_reward": 0.35534830057621003, "critic_loss": 0.08704197256267071, "actor_loss": -34.20870919799805, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 52.646950006484985, "episode_reward": 410.7587646105662, "step": 41000}
{"episode": 42.0, "batch_reward": 0.3573655938506126, "critic_loss": 0.08209538143500686, "actor_loss": -34.500098770141605, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 629.6974737644196, "episode_reward": 433.85614331095667, "step": 42000}
{"episode": 43.0, "batch_reward": 0.35912758830189706, "critic_loss": 0.07724744822457433, "actor_loss": -34.468732666015626, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 32.594306230545044, "episode_reward": 426.0210975981398, "step": 43000}
{"episode": 44.0, "batch_reward": 0.3606637333333492, "critic_loss": 0.0732000776976347, "actor_loss": -34.970662406921385, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 600.476114988327, "episode_reward": 415.863880680418, "step": 44000}
{"episode": 45.0, "batch_reward": 0.36118971812725065, "critic_loss": 0.06832039579376578, "actor_loss": -34.97871665191651, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.827412128448486, "episode_reward": 421.9812037938559, "step": 45000}
{"episode": 46.0, "batch_reward": 0.3625714149773121, "critic_loss": 0.06862708806246519, "actor_loss": -35.09523985290527, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 631.586475610733, "episode_reward": 421.77018651707294, "step": 46000}
{"episode": 47.0, "batch_reward": 0.3641267501115799, "critic_loss": 0.06719647995382548, "actor_loss": -35.22785160064697, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.37024664878845, "episode_reward": 416.5812254907093, "step": 47000}
{"episode": 48.0, "batch_reward": 0.3662055713534355, "critic_loss": 0.06385698527656496, "actor_loss": -35.33338451385498, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 628.3923292160034, "episode_reward": 431.37814710862676, "step": 48000}
{"episode": 49.0, "batch_reward": 0.36677311912178995, "critic_loss": 0.06467260805517436, "actor_loss": -35.436916481018066, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 30.422126293182373, "episode_reward": 428.69664415162504, "step": 49000}
{"episode": 50.0, "batch_reward": 0.3679791566133499, "critic_loss": 0.06388517542183399, "actor_loss": -35.362874710083005, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 630.802666425705, "episode_reward": 414.83164565892275, "step": 50000}
{"episode": 51.0, "batch_reward": 0.3683906918466091, "critic_loss": 0.06208541854470968, "actor_loss": -35.29044400024414, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 51.790430307388306, "episode_reward": 412.42569414111233, "step": 51000}
{"episode": 52.0, "batch_reward": 0.36952913099527357, "critic_loss": 0.06272112644091249, "actor_loss": -35.43314011383057, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 657.3568737506866, "episode_reward": 401.2281862256632, "step": 52000}
{"episode": 53.0, "batch_reward": 0.3704852041006088, "critic_loss": 0.05980389290116727, "actor_loss": -35.449954429626466, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.29359793663025, "episode_reward": 414.66220493428375, "step": 53000}
{"episode": 54.0, "batch_reward": 0.37099489015340803, "critic_loss": 0.061997961960732935, "actor_loss": -35.267364852905274, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 652.5322847366333, "episode_reward": 415.1362047259196, "step": 54000}
{"episode": 55.0, "batch_reward": 0.3719553978741169, "critic_loss": 0.05691791906766593, "actor_loss": -35.27735233306885, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 33.91653633117676, "episode_reward": 433.5888877583259, "step": 55000}
{"episode": 56.0, "batch_reward": 0.37283320909738543, "critic_loss": 0.050773156786337495, "actor_loss": -35.226098487854, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 613.7162909507751, "episode_reward": 433.90651446808545, "step": 56000}
{"episode": 57.0, "batch_reward": 0.3746420527100563, "critic_loss": 0.05079876939766109, "actor_loss": -35.37388891601562, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 24.92098045349121, "episode_reward": 439.42523412340853, "step": 57000}
{"episode": 58.0, "batch_reward": 0.37555528873205185, "critic_loss": 0.0527157256025821, "actor_loss": -35.59821124267578, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 579.0382215976715, "episode_reward": 386.9437149923189, "step": 58000}
{"episode": 59.0, "batch_reward": 0.3757339850068092, "critic_loss": 0.05478932936117053, "actor_loss": -35.577082229614255, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.25003790855408, "episode_reward": 391.6842282912773, "step": 59000}
{"episode": 60.0, "batch_reward": 0.37555923727154733, "critic_loss": 0.05890438215993345, "actor_loss": -35.47002464294434, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 602.9611673355103, "episode_reward": 404.65041073411305, "step": 60000}
{"episode": 61.0, "batch_reward": 0.37688900583982465, "critic_loss": 0.05428203306905925, "actor_loss": -35.56743560028076, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 48.36858820915222, "episode_reward": 416.5948929496131, "step": 61000}
{"episode": 62.0, "batch_reward": 0.3766281116604805, "critic_loss": 0.05065365866012871, "actor_loss": -35.27260208129883, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 634.3795239925385, "episode_reward": 421.46072653796864, "step": 62000}
{"episode": 63.0, "batch_reward": 0.3778951779901981, "critic_loss": 0.05047484623640776, "actor_loss": -35.32630237579346, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 31.014042854309082, "episode_reward": 426.7771433287819, "step": 63000}
{"episode": 64.0, "batch_reward": 0.3778655769228935, "critic_loss": 0.05007439573854208, "actor_loss": -35.33855680847168, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 645.4084451198578, "episode_reward": 401.27509856372046, "step": 64000}
{"episode": 65.0, "batch_reward": 0.3787279685735703, "critic_loss": 0.04851155842654407, "actor_loss": -35.41101013183594, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 30.556331396102905, "episode_reward": 384.2066479655765, "step": 65000}
{"episode": 66.0, "batch_reward": 0.37851659452915193, "critic_loss": 0.04730846350826323, "actor_loss": -35.1663809967041, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 642.6030218601227, "episode_reward": 406.04741382068187, "step": 66000}
{"episode": 67.0, "batch_reward": 0.3793410912156105, "critic_loss": 0.048296511149033904, "actor_loss": -35.162207305908204, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 32.584667682647705, "episode_reward": 408.67985199143175, "step": 67000}
{"episode": 68.0, "batch_reward": 0.3799893485307693, "critic_loss": 0.04817279190942645, "actor_loss": -35.17170952606201, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 633.7530813217163, "episode_reward": 397.09706649282896, "step": 68000}
{"episode": 69.0, "batch_reward": 0.37980524596571924, "critic_loss": 0.04676874001137912, "actor_loss": -35.10444217681885, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.81512713432312, "episode_reward": 389.4675383467272, "step": 69000}
{"episode": 70.0, "batch_reward": 0.3796471883952618, "critic_loss": 0.042183651115745305, "actor_loss": -34.88315196228027, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 652.8493542671204, "episode_reward": 402.81975505488043, "step": 70000}
{"episode": 71.0, "batch_reward": 0.38022335222363474, "critic_loss": 0.041006419947370885, "actor_loss": -34.97163319396973, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 51.13645076751709, "episode_reward": 393.263604878927, "step": 71000}
{"episode": 72.0, "batch_reward": 0.3805899626612663, "critic_loss": 0.043227086367085575, "actor_loss": -34.77801119232178, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 579.0368402004242, "episode_reward": 394.34019816493594, "step": 72000}
{"episode": 73.0, "batch_reward": 0.3800978661477566, "critic_loss": 0.04181404866650701, "actor_loss": -34.70314897155762, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 32.05767226219177, "episode_reward": 394.74900711119795, "step": 73000}
{"episode": 74.0, "batch_reward": 0.38042243871092796, "critic_loss": 0.040728110181167725, "actor_loss": -34.746634315490724, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 642.0518002510071, "episode_reward": 393.2772684664985, "step": 74000}
{"episode": 75.0, "batch_reward": 0.3814213232398033, "critic_loss": 0.04260007194243372, "actor_loss": -34.80071285247803, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.7431206703186, "episode_reward": 386.2429115711667, "step": 75000}
{"episode": 76.0, "batch_reward": 0.38128398528695107, "critic_loss": 0.04044109700620174, "actor_loss": -34.79156246948242, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 593.8946757316589, "episode_reward": 426.62711757700015, "step": 76000}
{"episode": 77.0, "batch_reward": 0.38194576266407965, "critic_loss": 0.03838264754414558, "actor_loss": -34.875530670166015, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.564836978912354, "episode_reward": 416.94250422021685, "step": 77000}
{"episode": 78.0, "batch_reward": 0.3826070166528225, "critic_loss": 0.0362899524718523, "actor_loss": -34.969219841003415, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 595.1766712665558, "episode_reward": 416.0390071055601, "step": 78000}
{"episode": 79.0, "batch_reward": 0.3830087214708328, "critic_loss": 0.03530911538377404, "actor_loss": -34.98267473602295, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 31.913612604141235, "episode_reward": 419.82100076169115, "step": 79000}
{"episode": 80.0, "batch_reward": 0.38301313132047654, "critic_loss": 0.0362763344720006, "actor_loss": -34.97586882019043, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 632.5989472866058, "episode_reward": 426.9669468303617, "step": 80000}
{"episode": 81.0, "batch_reward": 0.3839965455532074, "critic_loss": 0.033424817737191914, "actor_loss": -35.06355828857422, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 52.428683042526245, "episode_reward": 434.29631941237955, "step": 81000}
{"episode": 82.0, "batch_reward": 0.38498564371466637, "critic_loss": 0.03762122512422502, "actor_loss": -34.969478523254395, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 649.9051716327667, "episode_reward": 424.30941917168707, "step": 82000}
{"episode": 83.0, "batch_reward": 0.38491449227929114, "critic_loss": 0.03659987433440983, "actor_loss": -34.992471847534176, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.07612586021423, "episode_reward": 424.85677809470627, "step": 83000}
{"episode": 84.0, "batch_reward": 0.38586140403151514, "critic_loss": 0.03524675512313843, "actor_loss": -34.93875521850586, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 570.7514629364014, "episode_reward": 436.96463377477295, "step": 84000}
{"episode": 85.0, "batch_reward": 0.3868130713105202, "critic_loss": 0.038192476768046615, "actor_loss": -35.04020800018311, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.809325218200684, "episode_reward": 431.6762602517737, "step": 85000}
{"episode": 86.0, "batch_reward": 0.38687891426682475, "critic_loss": 0.03649282507225871, "actor_loss": -35.016312545776366, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 595.9668936729431, "episode_reward": 437.04968482059803, "step": 86000}
{"episode": 87.0, "batch_reward": 0.3868945580124855, "critic_loss": 0.03809599556960166, "actor_loss": -34.99458330535889, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 33.747239112854004, "episode_reward": 423.52649884404013, "step": 87000}
{"episode": 88.0, "batch_reward": 0.3879638956785202, "critic_loss": 0.03540980496816337, "actor_loss": -35.176403007507325, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 648.2971894741058, "episode_reward": 431.1856386445781, "step": 88000}
{"episode": 89.0, "batch_reward": 0.3878970762193203, "critic_loss": 0.03714346425049007, "actor_loss": -35.18140210723877, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 30.28437566757202, "episode_reward": 410.29247289919243, "step": 89000}
{"episode": 90.0, "batch_reward": 0.38839557513594625, "critic_loss": 0.03555977138318121, "actor_loss": -35.389776344299314, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 656.6970112323761, "episode_reward": 452.639445730256, "step": 90000}
{"episode": 91.0, "batch_reward": 0.38853108635544775, "critic_loss": 0.03492465138249099, "actor_loss": -35.43165631866455, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 55.32419800758362, "episode_reward": 447.6878477022032, "step": 91000}
{"episode": 92.0, "batch_reward": 0.3892625777423382, "critic_loss": 0.03739766884222627, "actor_loss": -35.472273963928224, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 601.1968672275543, "episode_reward": 425.03760148833715, "step": 92000}
{"episode": 93.0, "batch_reward": 0.3900928957760334, "critic_loss": 0.03549765806924552, "actor_loss": -35.50420858001709, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 30.125784397125244, "episode_reward": 414.1381191030348, "step": 93000}
{"episode": 94.0, "batch_reward": 0.3900782930850983, "critic_loss": 0.03410472398623824, "actor_loss": -35.47061108398437, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 667.5864350795746, "episode_reward": 437.6782655036903, "step": 94000}
{"episode": 95.0, "batch_reward": 0.39065635061264037, "critic_loss": 0.035153293024748566, "actor_loss": -35.56041639709473, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.260313749313354, "episode_reward": 425.1133716010664, "step": 95000}
{"episode": 96.0, "batch_reward": 0.3907165910303593, "critic_loss": 0.035954931097105146, "actor_loss": -35.36798064422607, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 601.0123269557953, "episode_reward": 422.5281940280298, "step": 96000}
{"episode": 97.0, "batch_reward": 0.3913783951997757, "critic_loss": 0.031928751101717355, "actor_loss": -35.42361768341065, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 32.764342069625854, "episode_reward": 419.29930858228016, "step": 97000}
{"episode": 98.0, "batch_reward": 0.3920443113744259, "critic_loss": 0.03483473678864539, "actor_loss": -35.35112853240967, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 633.9718811511993, "episode_reward": 435.99222724481064, "step": 98000}
{"episode": 99.0, "batch_reward": 0.3927175935506821, "critic_loss": 0.03500665278173983, "actor_loss": -35.48322589111328, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 29.419480562210083, "episode_reward": 440.8208264546293, "step": 99000}
{"episode": 100.0, "batch_reward": 0.3924546216130257, "critic_loss": 0.037155998913571235, "actor_loss": -34.95500472259521, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 627.4881300926208, "episode_reward": 426.4364344017109, "step": 100000}
{"episode": 101.0, "batch_reward": 0.3930380571782589, "critic_loss": 0.03559315213561058, "actor_loss": -35.04362078094483, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 51.966994762420654, "episode_reward": 424.5126573705607, "step": 101000}
{"episode": 102.0, "batch_reward": 0.39313339069485664, "critic_loss": 0.03692813707515597, "actor_loss": -34.272528938293455, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 571.3985948562622, "episode_reward": 434.79938595043393, "step": 102000}
{"episode": 103.0, "batch_reward": 0.39364800772070885, "critic_loss": 0.03751101564615965, "actor_loss": -34.38611061859131, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 31.796872854232788, "episode_reward": 427.9497590918773, "step": 103000}
{"episode": 104.0, "batch_reward": 0.3941900134086609, "critic_loss": 0.0372462438903749, "actor_loss": -33.64202964782715, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 635.8366434574127, "episode_reward": 447.1949251691566, "step": 104000}
{"episode": 105.0, "batch_reward": 0.3943024903535843, "critic_loss": 0.03861359606683254, "actor_loss": -33.737396938323975, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 31.405539989471436, "episode_reward": 468.7925882616015, "step": 105000}
{"episode": 106.0, "batch_reward": 0.3949070333838463, "critic_loss": 0.038500554006546735, "actor_loss": -33.5533383026123, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 628.1026968955994, "episode_reward": 407.7641422729273, "step": 106000}
{"episode": 107.0, "batch_reward": 0.39540101408958434, "critic_loss": 0.037296601789072154, "actor_loss": -33.66578495407104, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.36027431488037, "episode_reward": 407.06512310485397, "step": 107000}
{"episode": 108.0, "batch_reward": 0.39550058552622797, "critic_loss": 0.03925153018347919, "actor_loss": -33.496488132476806, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 635.7492415904999, "episode_reward": 437.2673441008123, "step": 108000}
{"episode": 109.0, "batch_reward": 0.3958722084760666, "critic_loss": 0.03894697244279086, "actor_loss": -33.61323364639282, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.74382400512695, "episode_reward": 450.2163086412814, "step": 109000}
{"episode": 110.0, "batch_reward": 0.39605777415633203, "critic_loss": 0.03980865487270057, "actor_loss": -33.52377593231201, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 635.8500835895538, "episode_reward": 446.64749858899467, "step": 110000}
{"episode": 111.0, "batch_reward": 0.39673645642399785, "critic_loss": 0.037654479255899785, "actor_loss": -33.666778854370115, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 48.48558759689331, "episode_reward": 444.11135059558467, "step": 111000}
{"episode": 112.0, "batch_reward": 0.39755835449695587, "critic_loss": 0.03759046863391995, "actor_loss": -33.679740070343016, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 631.6608986854553, "episode_reward": 432.8969467824829, "step": 112000}
{"episode": 113.0, "batch_reward": 0.3971672470271587, "critic_loss": 0.037684521051123736, "actor_loss": -33.77138317489624, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 31.64438772201538, "episode_reward": 443.58230662815464, "step": 113000}
{"episode": 114.0, "batch_reward": 0.39768985092639925, "critic_loss": 0.038574524734169245, "actor_loss": -33.926892959594724, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 633.9489715099335, "episode_reward": 424.6645800137162, "step": 114000}
{"episode": 115.0, "batch_reward": 0.3983828608393669, "critic_loss": 0.03860611001215875, "actor_loss": -34.08330883026123, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 30.697901725769043, "episode_reward": 452.3115156776947, "step": 115000}
{"episode": 116.0, "batch_reward": 0.39865317329764366, "critic_loss": 0.03676407219842076, "actor_loss": -34.448449928283694, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 621.4398102760315, "episode_reward": 460.8133746062696, "step": 116000}
{"episode": 117.0, "batch_reward": 0.39908185198903084, "critic_loss": 0.03548359783180058, "actor_loss": -34.64591983032226, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.49854874610901, "episode_reward": 459.93633113318856, "step": 117000}
{"episode": 118.0, "batch_reward": 0.39970982110500336, "critic_loss": 0.031484658904373644, "actor_loss": -35.197572479248045, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 644.231921672821, "episode_reward": 461.40683870795743, "step": 118000}
{"episode": 119.0, "batch_reward": 0.4004045994877815, "critic_loss": 0.03405411997996271, "actor_loss": -35.41864820098877, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.500905752182007, "episode_reward": 466.93732096215825, "step": 119000}
{"episode": 120.0, "batch_reward": 0.40112783065438273, "critic_loss": 0.03222436283063144, "actor_loss": -35.80857554626465, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 632.2034184932709, "episode_reward": 492.19857379250004, "step": 120000}
{"episode": 121.0, "batch_reward": 0.4016285687983036, "critic_loss": 0.03585909472592175, "actor_loss": -36.019248672485354, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 55.120404958724976, "episode_reward": 387.4789893586754, "step": 121000}
{"episode": 122.0, "batch_reward": 0.40189079561829566, "critic_loss": 0.03912866984680295, "actor_loss": -36.42776128387451, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 658.5200624465942, "episode_reward": 463.93483808169407, "step": 122000}
{"episode": 123.0, "batch_reward": 0.402414355635643, "critic_loss": 0.03366583384014666, "actor_loss": -36.61464414215088, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.919532775878906, "episode_reward": 381.36435257109684, "step": 123000}
{"episode": 124.0, "batch_reward": 0.4017190133035183, "critic_loss": 0.03748593149799854, "actor_loss": -36.8071559753418, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 604.0610077381134, "episode_reward": 497.5437302665359, "step": 124000}
{"episode": 125.0, "batch_reward": 0.40323335233330726, "critic_loss": 0.03982653566170484, "actor_loss": -37.11730818939209, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 33.45374321937561, "episode_reward": 477.8616470512445, "step": 125000}
{"episode": 126.0, "batch_reward": 0.40373827096819875, "critic_loss": 0.041313458489254114, "actor_loss": -37.36721111297607, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 654.0584819316864, "episode_reward": 486.3042199397687, "step": 126000}
{"episode": 127.0, "batch_reward": 0.4038572942018509, "critic_loss": 0.03770701106917113, "actor_loss": -37.560588088989256, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 33.90335416793823, "episode_reward": 483.31756460869303, "step": 127000}
{"episode": 128.0, "batch_reward": 0.4047642108798027, "critic_loss": 0.03993415457103401, "actor_loss": -37.87231507110596, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 687.6250360012054, "episode_reward": 286.16271721978933, "step": 128000}
{"episode": 129.0, "batch_reward": 0.4039323811233044, "critic_loss": 0.042863580176606776, "actor_loss": -37.91282272338867, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.259809255599976, "episode_reward": 491.36725112770364, "step": 129000}
{"episode": 130.0, "batch_reward": 0.40452223661541936, "critic_loss": 0.04142814921308309, "actor_loss": -38.19755576324463, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 701.4977102279663, "episode_reward": 501.3455011456146, "step": 130000}
{"episode": 131.0, "batch_reward": 0.40540852096676827, "critic_loss": 0.04160996876470745, "actor_loss": -38.35267807006836, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 50.165472745895386, "episode_reward": 496.39055305357425, "step": 131000}
{"episode": 132.0, "batch_reward": 0.4055378107130527, "critic_loss": 0.04086498197168112, "actor_loss": -38.53288444519043, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 627.0071227550507, "episode_reward": 525.7391484147587, "step": 132000}
{"episode": 133.0, "batch_reward": 0.406432330429554, "critic_loss": 0.03923403489217162, "actor_loss": -38.74023829650879, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.02969431877136, "episode_reward": 496.52750451642186, "step": 133000}
{"episode": 134.0, "batch_reward": 0.4070117354393005, "critic_loss": 0.03898264719359577, "actor_loss": -38.99006867980957, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 655.3456218242645, "episode_reward": 503.08370880492333, "step": 134000}
{"episode": 135.0, "batch_reward": 0.4079058149456978, "critic_loss": 0.03807837974652648, "actor_loss": -39.22797760772705, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.72655510902405, "episode_reward": 496.4569616912293, "step": 135000}
{"episode": 136.0, "batch_reward": 0.4089103017747402, "critic_loss": 0.03887260768096894, "actor_loss": -39.39509600067139, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 680.1865515708923, "episode_reward": 495.01533079632026, "step": 136000}
{"episode": 137.0, "batch_reward": 0.4093644441962242, "critic_loss": 0.03864961162116379, "actor_loss": -39.589372215271, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.22152256965637, "episode_reward": 514.9527631110827, "step": 137000}
{"episode": 138.0, "batch_reward": 0.4101134895682335, "critic_loss": 0.03703588972333818, "actor_loss": -39.79573857116699, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 679.0023272037506, "episode_reward": 501.0721978503877, "step": 138000}
{"episode": 139.0, "batch_reward": 0.4112491216361523, "critic_loss": 0.03667673535831273, "actor_loss": -39.98783087921142, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 32.387563705444336, "episode_reward": 544.0917934557037, "step": 139000}
{"episode": 140.0, "batch_reward": 0.41176535898447036, "critic_loss": 0.03835867106169462, "actor_loss": -40.181795372009276, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 661.4881007671356, "episode_reward": 532.9707321854254, "step": 140000}
{"episode": 141.0, "batch_reward": 0.4122929593026638, "critic_loss": 0.03668023151531816, "actor_loss": -40.3688924407959, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 57.91745400428772, "episode_reward": 525.7945585397156, "step": 141000}
{"episode": 142.0, "batch_reward": 0.4129638596475124, "critic_loss": 0.03904657781496644, "actor_loss": -40.525048141479495, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 640.52752161026, "episode_reward": 544.7215795901857, "step": 142000}
{"episode": 143.0, "batch_reward": 0.41464781349897384, "critic_loss": 0.037314997071400284, "actor_loss": -40.806395469665524, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 32.387346506118774, "episode_reward": 526.2248894613925, "step": 143000}
{"episode": 144.0, "batch_reward": 0.41540899899601935, "critic_loss": 0.0372649273602292, "actor_loss": -41.02948915863037, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 649.4205467700958, "episode_reward": 525.5966634329507, "step": 144000}
{"episode": 145.0, "batch_reward": 0.41552394986152646, "critic_loss": 0.038088123604655265, "actor_loss": -41.20462543487549, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 29.498993396759033, "episode_reward": 528.2255661963334, "step": 145000}
{"episode": 146.0, "batch_reward": 0.41627936163544654, "critic_loss": 0.04039876300282776, "actor_loss": -41.430354927062986, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 628.696295261383, "episode_reward": 315.37902939749205, "step": 146000}
{"episode": 147.0, "batch_reward": 0.41662021857500076, "critic_loss": 0.04319789120741189, "actor_loss": -41.593356498718265, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 30.198038578033447, "episode_reward": 557.8008578373516, "step": 147000}
{"episode": 148.0, "batch_reward": 0.41722011563181877, "critic_loss": 0.04690901460684836, "actor_loss": -41.81164225769043, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 641.595520734787, "episode_reward": 547.1992483520179, "step": 148000}
{"episode": 149.0, "batch_reward": 0.4180128506422043, "critic_loss": 0.04603490965440869, "actor_loss": -42.06966324615478, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.60467767715454, "episode_reward": 525.3445868708815, "step": 149000}
{"episode": 150.0, "batch_reward": 0.41897905975580213, "critic_loss": 0.0477415336035192, "actor_loss": -42.26515557861328, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
