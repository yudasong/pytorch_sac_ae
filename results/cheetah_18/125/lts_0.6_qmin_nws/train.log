{"episode_reward": 0.0, "episode": 1.0, "duration": 19.20907735824585, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.863457202911377, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.21735218521077143, "critic_loss": 0.06212251601668051, "actor_loss": -27.76273782407584, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 67.65979552268982, "step": 3000}
{"episode_reward": 15.248609674886948, "episode": 4.0, "batch_reward": 0.13906125761568547, "critic_loss": 0.02360101665649563, "actor_loss": -25.339371688738467, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.6100594997406, "step": 4000}
{"episode_reward": 20.267411733757886, "episode": 5.0, "batch_reward": 0.1128666261099279, "critic_loss": 0.02204320354666561, "actor_loss": -21.361755744352937, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.776989698410034, "step": 5000}
{"episode_reward": 17.186513674021143, "episode": 6.0, "batch_reward": 0.09644334959238768, "critic_loss": 0.032321179876104, "actor_loss": -21.283953015834093, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.944841384887695, "step": 6000}
{"episode_reward": 64.1757876996667, "episode": 7.0, "batch_reward": 0.09426488004997373, "critic_loss": 0.05290330221131444, "actor_loss": -23.075530535176398, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.498154878616333, "step": 7000}
{"episode_reward": 47.21265365229564, "episode": 8.0, "batch_reward": 0.08921871802955866, "critic_loss": 0.06386471842229366, "actor_loss": -20.64586035694927, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.68634867668152, "step": 8000}
{"episode_reward": 57.94807410136713, "episode": 9.0, "batch_reward": 0.0863870735950768, "critic_loss": 0.08709921906515956, "actor_loss": -19.567408258982002, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.22392749786377, "step": 9000}
{"episode_reward": 122.06319051203607, "episode": 10.0, "batch_reward": 0.09379942023009062, "critic_loss": 0.10824866231903434, "actor_loss": -20.77564926287532, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.42447066307068, "step": 10000}
{"episode_reward": 116.03098879666449, "episode": 11.0, "batch_reward": 0.10064588455855847, "critic_loss": 0.12402861531451345, "actor_loss": -21.64576622903347, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.470484256744385, "step": 11000}
{"episode_reward": 282.5866386370559, "episode": 12.0, "batch_reward": 0.11170896074175835, "critic_loss": 0.12749574257805943, "actor_loss": -21.09283302664757, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.905653953552246, "step": 12000}
{"episode_reward": 208.07026752102078, "episode": 13.0, "batch_reward": 0.11848503290116787, "critic_loss": 0.11729854179918767, "actor_loss": -21.873998044967653, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.078855276107788, "step": 13000}
{"episode_reward": 83.69580099395317, "episode": 14.0, "batch_reward": 0.11300847131758929, "critic_loss": 0.10705716755986214, "actor_loss": -19.583012306690215, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.603872060775757, "step": 14000}
{"episode_reward": 50.54074947227779, "episode": 15.0, "batch_reward": 0.11280872774869204, "critic_loss": 0.1157560837380588, "actor_loss": -22.03334914970398, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.911771535873413, "step": 15000}
{"episode_reward": 161.36734316048938, "episode": 16.0, "batch_reward": 0.1157312925234437, "critic_loss": 0.12857538513466715, "actor_loss": -21.83357505321503, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.135520458221436, "step": 16000}
{"episode_reward": 104.20929799742002, "episode": 17.0, "batch_reward": 0.11355834065377712, "critic_loss": 0.12755831694230438, "actor_loss": -20.365229679584502, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.64827823638916, "step": 17000}
{"episode_reward": 80.79948223379132, "episode": 18.0, "batch_reward": 0.11607723268866539, "critic_loss": 0.14116460325941443, "actor_loss": -20.458831945419313, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.144667387008667, "step": 18000}
{"episode_reward": 289.2799299820812, "episode": 19.0, "batch_reward": 0.12227731227129698, "critic_loss": 0.16529828310757874, "actor_loss": -20.449459124565124, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.049196481704712, "step": 19000}
{"episode_reward": 98.36431515939566, "episode": 20.0, "batch_reward": 0.12277764800935984, "critic_loss": 0.17964851036667823, "actor_loss": -22.04588399028778, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.97539234161377, "step": 20000}
{"episode_reward": 260.4542574906974, "episode": 21.0, "batch_reward": 0.13000799064338206, "critic_loss": 0.19891245210170747, "actor_loss": -22.79247584915161, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.23070406913757, "step": 21000}
{"episode_reward": 290.60462736631735, "episode": 22.0, "batch_reward": 0.13828341466188432, "critic_loss": 0.23480404603481292, "actor_loss": -22.663488924980165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.169243097305298, "step": 22000}
{"episode_reward": 282.38534645168477, "episode": 23.0, "batch_reward": 0.14399956633895636, "critic_loss": 0.24624798300862313, "actor_loss": -22.96557750225067, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.184438228607178, "step": 23000}
{"episode_reward": 146.15076982258543, "episode": 24.0, "batch_reward": 0.14094353272020818, "critic_loss": 0.25956539654731753, "actor_loss": -23.524485878944397, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.370436429977417, "step": 24000}
{"episode_reward": 78.52161229410586, "episode": 25.0, "batch_reward": 0.13954402977228164, "critic_loss": 0.2533134518414736, "actor_loss": -22.7465845079422, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.975531816482544, "step": 25000}
{"episode_reward": 112.65102083999804, "episode": 26.0, "batch_reward": 0.1402006311044097, "critic_loss": 0.2623137026131153, "actor_loss": -22.779883955001832, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.187620162963867, "step": 26000}
{"episode_reward": 193.5590122426957, "episode": 27.0, "batch_reward": 0.14447570227086545, "critic_loss": 0.3332928463891149, "actor_loss": -23.58765696144104, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.566548109054565, "step": 27000}
{"episode_reward": 368.64819901282186, "episode": 28.0, "batch_reward": 0.15033588173985482, "critic_loss": 0.3417668697983027, "actor_loss": -23.423211601257325, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.00563335418701, "step": 28000}
{"episode_reward": 167.65716854394154, "episode": 29.0, "batch_reward": 0.14869224495440722, "critic_loss": 0.3145941933915019, "actor_loss": -23.798639751434326, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.664310216903687, "step": 29000}
{"episode_reward": 46.72219849869093, "episode": 30.0, "batch_reward": 0.14416817118972539, "critic_loss": 0.30238707979768514, "actor_loss": -22.97935282230377, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.90335440635681, "step": 30000}
{"episode_reward": 32.12634288218941, "episode": 31.0, "batch_reward": 0.1434677124172449, "critic_loss": 0.30633902838826177, "actor_loss": -23.200740501403807, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.63121485710144, "step": 31000}
{"episode_reward": 169.75862567882623, "episode": 32.0, "batch_reward": 0.14283164168149232, "critic_loss": 0.30655653615295886, "actor_loss": -23.380108275413512, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.069724798202515, "step": 32000}
{"episode_reward": 96.02034741188184, "episode": 33.0, "batch_reward": 0.1406394280269742, "critic_loss": 0.290056015253067, "actor_loss": -23.227523845672607, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.68147897720337, "step": 33000}
{"episode_reward": 41.00310471964785, "episode": 34.0, "batch_reward": 0.1390477638989687, "critic_loss": 0.2725866007730365, "actor_loss": -21.863857513427735, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.043858766555786, "step": 34000}
{"episode_reward": 117.45231068365347, "episode": 35.0, "batch_reward": 0.13754394230246544, "critic_loss": 0.33411681617796424, "actor_loss": -22.730493949890135, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.72757625579834, "step": 35000}
{"episode_reward": 92.69461324611862, "episode": 36.0, "batch_reward": 0.1372153113335371, "critic_loss": 0.26491512095928194, "actor_loss": -21.599413570404053, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.207291841506958, "step": 36000}
{"episode_reward": 171.77249549136252, "episode": 37.0, "batch_reward": 0.1396649042889476, "critic_loss": 0.31225606229156255, "actor_loss": -22.202952905654907, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.213904857635498, "step": 37000}
{"episode_reward": 282.968845434017, "episode": 38.0, "batch_reward": 0.14249345370382072, "critic_loss": 0.3236700621917844, "actor_loss": -22.482553911209106, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.4041805267334, "step": 38000}
{"episode_reward": 129.886297320135, "episode": 39.0, "batch_reward": 0.14433913719654085, "critic_loss": 0.3374410818219185, "actor_loss": -23.09248669433594, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.398560762405396, "step": 39000}
{"episode_reward": 356.1296627795253, "episode": 40.0, "batch_reward": 0.14698271986097097, "critic_loss": 0.3120627166181803, "actor_loss": -23.185164041519165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.15774440765381, "step": 40000}
{"episode_reward": 80.62690433578464, "episode": 41.0, "batch_reward": 0.14502057529240847, "critic_loss": 0.3222006779760122, "actor_loss": -22.911338859558107, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.64960169792175, "step": 41000}
{"episode_reward": 92.12727375251777, "episode": 42.0, "batch_reward": 0.1428381311520934, "critic_loss": 0.37466204711049794, "actor_loss": -22.169084032058716, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.78933811187744, "step": 42000}
{"episode_reward": 40.95922159923439, "episode": 43.0, "batch_reward": 0.14387498442083596, "critic_loss": 0.36942987802624705, "actor_loss": -22.43473299026489, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.814724683761597, "step": 43000}
{"episode_reward": 379.7627516325818, "episode": 44.0, "batch_reward": 0.14884981233626604, "critic_loss": 0.3377360126078129, "actor_loss": -22.350496406555177, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.853137731552124, "step": 44000}
{"episode_reward": 371.4752643553818, "episode": 45.0, "batch_reward": 0.1549387123733759, "critic_loss": 0.36956704641878607, "actor_loss": -23.764903024673462, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.679869174957275, "step": 45000}
{"episode_reward": 352.5257438837121, "episode": 46.0, "batch_reward": 0.15845623341947793, "critic_loss": 0.3708638301938772, "actor_loss": -23.687892402648927, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.661892890930176, "step": 46000}
{"episode_reward": 374.2569927754721, "episode": 47.0, "batch_reward": 0.16393498365581036, "critic_loss": 0.4013298933058977, "actor_loss": -24.19251958847046, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.333115577697754, "step": 47000}
{"episode_reward": 338.69140121103675, "episode": 48.0, "batch_reward": 0.16539608208835124, "critic_loss": 0.3706737592667341, "actor_loss": -23.98972648048401, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.78937077522278, "step": 48000}
{"episode_reward": 106.40964189883206, "episode": 49.0, "batch_reward": 0.16438735204935073, "critic_loss": 0.35856054815649985, "actor_loss": -24.48869955444336, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.292388200759888, "step": 49000}
{"episode_reward": 171.8392154725209, "episode": 50.0, "batch_reward": 0.1648026233687997, "critic_loss": 0.4022444576472044, "actor_loss": -24.43426125717163, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.14167308807373, "step": 50000}
{"episode_reward": 203.21984599228261, "episode": 51.0, "batch_reward": 0.16408592218905688, "critic_loss": 0.37639028108119965, "actor_loss": -23.957643644332887, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.89001822471619, "step": 51000}
{"episode_reward": 62.780096854219984, "episode": 52.0, "batch_reward": 0.16419552385807037, "critic_loss": 0.3972458305358887, "actor_loss": -24.79350142288208, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.557186365127563, "step": 52000}
{"episode_reward": 291.8619474639197, "episode": 53.0, "batch_reward": 0.1668253335878253, "critic_loss": 0.42174597404152153, "actor_loss": -24.51857433128357, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.4178466796875, "step": 53000}
{"episode_reward": 434.25523341148994, "episode": 54.0, "batch_reward": 0.17255577200651168, "critic_loss": 0.4012083966657519, "actor_loss": -25.27843381881714, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.097233057022095, "step": 54000}
{"episode_reward": 383.92998285340826, "episode": 55.0, "batch_reward": 0.17630282185971738, "critic_loss": 0.364231468513608, "actor_loss": -25.31240723991394, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.922176361083984, "step": 55000}
{"episode_reward": 464.77088170345843, "episode": 56.0, "batch_reward": 0.17976912140846252, "critic_loss": 0.39961208872497084, "actor_loss": -26.09845585823059, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.699565410614014, "step": 56000}
{"episode_reward": 96.27560055552382, "episode": 57.0, "batch_reward": 0.1800405256599188, "critic_loss": 0.3799625375345349, "actor_loss": -25.685054021835327, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.260114192962646, "step": 57000}
{"episode_reward": 463.60025160193885, "episode": 58.0, "batch_reward": 0.18568219387531282, "critic_loss": 0.3815526875704527, "actor_loss": -25.811206714630128, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.38147735595703, "step": 58000}
{"episode_reward": 479.6548928735429, "episode": 59.0, "batch_reward": 0.1896596087217331, "critic_loss": 0.36010786482691765, "actor_loss": -26.072682907104493, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.166072845458984, "step": 59000}
{"episode_reward": 397.29365477107433, "episode": 60.0, "batch_reward": 0.19259008452296256, "critic_loss": 0.37386332999169825, "actor_loss": -26.934468145370484, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.857053518295288, "step": 60000}
{"episode_reward": 142.0546142556682, "episode": 61.0, "batch_reward": 0.1926433035582304, "critic_loss": 0.36769376090168954, "actor_loss": -26.840626625061034, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.20710611343384, "step": 61000}
{"episode_reward": 438.90121151358227, "episode": 62.0, "batch_reward": 0.19631633825600148, "critic_loss": 0.3801693977564573, "actor_loss": -26.916088832855223, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.191316604614258, "step": 62000}
{"episode_reward": 414.0441823170701, "episode": 63.0, "batch_reward": 0.19883270959556104, "critic_loss": 0.4454987567663193, "actor_loss": -27.117233283996583, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.37179923057556, "step": 63000}
{"episode_reward": 280.52853761802174, "episode": 64.0, "batch_reward": 0.20127244299650193, "critic_loss": 0.417087961435318, "actor_loss": -27.398722459793092, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.80866026878357, "step": 64000}
{"episode_reward": 427.86700099974405, "episode": 65.0, "batch_reward": 0.20521185311675072, "critic_loss": 0.4441837019175291, "actor_loss": -27.794254079818725, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.39201021194458, "step": 65000}
{"episode_reward": 402.3121421492354, "episode": 66.0, "batch_reward": 0.2072610813975334, "critic_loss": 0.4708604485243559, "actor_loss": -28.060562942504884, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.307013034820557, "step": 66000}
{"episode_reward": 131.47505415150474, "episode": 67.0, "batch_reward": 0.20422048819065095, "critic_loss": 0.4789623767733574, "actor_loss": -28.3591883354187, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.465503215789795, "step": 67000}
{"episode_reward": 62.59613569616998, "episode": 68.0, "batch_reward": 0.20437827941775322, "critic_loss": 0.4567082058340311, "actor_loss": -27.43350087928772, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.463399171829224, "step": 68000}
{"episode_reward": 427.47091342655426, "episode": 69.0, "batch_reward": 0.2075915589183569, "critic_loss": 0.47480065217614176, "actor_loss": -28.141466791152954, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.32544779777527, "step": 69000}
{"episode_reward": 425.5166288903702, "episode": 70.0, "batch_reward": 0.21084574688971042, "critic_loss": 0.48450036223232745, "actor_loss": -28.596180055618287, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.888996839523315, "step": 70000}
{"episode_reward": 442.7930445949982, "episode": 71.0, "batch_reward": 0.21508406348526476, "critic_loss": 0.49179093006253244, "actor_loss": -28.51841070175171, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.332581758499146, "step": 71000}
{"episode_reward": 440.14750017755574, "episode": 72.0, "batch_reward": 0.21706792691349983, "critic_loss": 0.5085379252582789, "actor_loss": -28.773690395355224, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.958929777145386, "step": 72000}
{"episode_reward": 430.6899244617678, "episode": 73.0, "batch_reward": 0.22088957971334458, "critic_loss": 0.5161157208681106, "actor_loss": -28.96856145095825, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.781879663467407, "step": 73000}
{"episode_reward": 459.509008456142, "episode": 74.0, "batch_reward": 0.22214033299684524, "critic_loss": 0.5203245834112168, "actor_loss": -29.605312118530275, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.086400747299194, "step": 74000}
{"episode_reward": 129.8463518221965, "episode": 75.0, "batch_reward": 0.22329634767770767, "critic_loss": 0.5170688922107219, "actor_loss": -29.771204067230226, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.167874336242676, "step": 75000}
{"episode_reward": 445.24783768961356, "episode": 76.0, "batch_reward": 0.22451835763454436, "critic_loss": 0.46472571827471254, "actor_loss": -29.716064517974853, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.752252340316772, "step": 76000}
{"episode_reward": 420.45735099811594, "episode": 77.0, "batch_reward": 0.22662815453112126, "critic_loss": 0.45602092815935613, "actor_loss": -29.951528793334962, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.522574186325073, "step": 77000}
{"episode_reward": 170.39443325227603, "episode": 78.0, "batch_reward": 0.2263278507590294, "critic_loss": 0.5138317086845636, "actor_loss": -29.946569988250733, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.442681074142456, "step": 78000}
{"episode_reward": 139.38494753579963, "episode": 79.0, "batch_reward": 0.22613283489644528, "critic_loss": 0.5302007662504912, "actor_loss": -28.91969515609741, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.91786026954651, "step": 79000}
{"episode_reward": 482.96372608138785, "episode": 80.0, "batch_reward": 0.2283916898369789, "critic_loss": 0.4630032520145178, "actor_loss": -29.64654823112488, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.45058274269104, "step": 80000}
{"episode_reward": 436.93962668264703, "episode": 81.0, "batch_reward": 0.23236858600378035, "critic_loss": 0.450565759524703, "actor_loss": -30.01437269592285, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.26250433921814, "step": 81000}
{"episode_reward": 457.8911382992491, "episode": 82.0, "batch_reward": 0.23478615060448646, "critic_loss": 0.551798574283719, "actor_loss": -31.067635318756103, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.336591243743896, "step": 82000}
{"episode_reward": 415.76742314852606, "episode": 83.0, "batch_reward": 0.23789191693067552, "critic_loss": 0.5181864790469408, "actor_loss": -30.49532334136963, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.287586450576782, "step": 83000}
{"episode_reward": 429.75114341253993, "episode": 84.0, "batch_reward": 0.23970724403858185, "critic_loss": 0.4738835871368647, "actor_loss": -31.341647808074953, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.07763695716858, "step": 84000}
{"episode_reward": 436.5503664991512, "episode": 85.0, "batch_reward": 0.2418461290448904, "critic_loss": 0.4603429605066776, "actor_loss": -31.54207615661621, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.227447032928467, "step": 85000}
{"episode_reward": 395.55787487555546, "episode": 86.0, "batch_reward": 0.24281609359383582, "critic_loss": 0.4821321359276772, "actor_loss": -30.99520403289795, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.592550039291382, "step": 86000}
{"episode_reward": 442.06234735555415, "episode": 87.0, "batch_reward": 0.24578227563202382, "critic_loss": 0.4862236396074295, "actor_loss": -31.734251914978028, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.488507986068726, "step": 87000}
{"episode_reward": 450.76675879956053, "episode": 88.0, "batch_reward": 0.24765651166439057, "critic_loss": 0.5035962513163685, "actor_loss": -31.547309883117677, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.298176527023315, "step": 88000}
{"episode_reward": 334.81474097558134, "episode": 89.0, "batch_reward": 0.2493894469588995, "critic_loss": 0.4674558437913656, "actor_loss": -31.895471130371092, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.129265069961548, "step": 89000}
{"episode_reward": 469.9731051271516, "episode": 90.0, "batch_reward": 0.25167447033524515, "critic_loss": 0.483202773809433, "actor_loss": -32.287617740631106, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.2637677192688, "step": 90000}
{"episode_reward": 495.6109745704007, "episode": 91.0, "batch_reward": 0.2532190770059824, "critic_loss": 0.4633339751660824, "actor_loss": -31.91861209869385, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.90690803527832, "step": 91000}
{"episode_reward": 169.87724178883002, "episode": 92.0, "batch_reward": 0.2535054008960724, "critic_loss": 0.47820019246637824, "actor_loss": -32.00875429153442, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.845887660980225, "step": 92000}
{"episode_reward": 291.63540153850664, "episode": 93.0, "batch_reward": 0.2532166486233473, "critic_loss": 0.4742091770917177, "actor_loss": -32.008806064605714, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.33272123336792, "step": 93000}
{"episode_reward": 289.74206998345755, "episode": 94.0, "batch_reward": 0.2540892741531134, "critic_loss": 0.49710924370586873, "actor_loss": -32.10482032775879, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.17687487602234, "step": 94000}
{"episode_reward": 452.4762310291338, "episode": 95.0, "batch_reward": 0.2557072271704674, "critic_loss": 0.46301791110634805, "actor_loss": -32.71935598754883, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.00649905204773, "step": 95000}
{"episode_reward": 456.2791537873602, "episode": 96.0, "batch_reward": 0.2577583912611008, "critic_loss": 0.4802389725893736, "actor_loss": -32.623094749450686, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.561727046966553, "step": 96000}
{"episode_reward": 478.4529394219342, "episode": 97.0, "batch_reward": 0.26066948944330215, "critic_loss": 0.4512424664199352, "actor_loss": -33.09619307327271, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.923116207122803, "step": 97000}
{"episode_reward": 462.51259124828437, "episode": 98.0, "batch_reward": 0.2633249814659357, "critic_loss": 0.5261402387470007, "actor_loss": -32.88623873519897, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.087371349334717, "step": 98000}
{"episode_reward": 478.223948883827, "episode": 99.0, "batch_reward": 0.2652322664707899, "critic_loss": 0.49189979906380177, "actor_loss": -33.27155599975586, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.067352533340454, "step": 99000}
{"episode_reward": 499.44770341389636, "episode": 100.0, "batch_reward": 0.2682562187165022, "critic_loss": 0.4469139764308929, "actor_loss": -33.039315868377685, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.766501903533936, "step": 100000}
{"episode_reward": 433.8391388046413, "episode": 101.0, "batch_reward": 0.2686504847407341, "critic_loss": 0.47862060195207595, "actor_loss": -33.45082403182983, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.77742004394531, "step": 101000}
{"episode_reward": 484.5429885486911, "episode": 102.0, "batch_reward": 0.26978669422864915, "critic_loss": 0.4447469451725483, "actor_loss": -33.459160007476804, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.760295152664185, "step": 102000}
{"episode_reward": 509.13468529246654, "episode": 103.0, "batch_reward": 0.273089548394084, "critic_loss": 0.4563134130388498, "actor_loss": -33.67053251266479, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.68239688873291, "step": 103000}
{"episode_reward": 507.6310676065741, "episode": 104.0, "batch_reward": 0.2758869082629681, "critic_loss": 0.45020327079296113, "actor_loss": -33.95758298873901, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.76753520965576, "step": 104000}
{"episode_reward": 469.22053518514224, "episode": 105.0, "batch_reward": 0.2780197126418352, "critic_loss": 0.4601875501871109, "actor_loss": -34.03709808731079, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.128194093704224, "step": 105000}
{"episode_reward": 476.1600658051699, "episode": 106.0, "batch_reward": 0.2787180991023779, "critic_loss": 0.44582908861339093, "actor_loss": -33.99019487380981, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.982561111450195, "step": 106000}
{"episode_reward": 450.6230506946609, "episode": 107.0, "batch_reward": 0.28107448863983153, "critic_loss": 0.508131159633398, "actor_loss": -34.165725086212156, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.69673252105713, "step": 107000}
{"episode_reward": 475.32344484977887, "episode": 108.0, "batch_reward": 0.2825462678819895, "critic_loss": 0.4333432675749064, "actor_loss": -34.43913251876831, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.56329917907715, "step": 108000}
{"episode_reward": 483.7411961606278, "episode": 109.0, "batch_reward": 0.28535180060565474, "critic_loss": 0.47612054567039014, "actor_loss": -35.04713372039795, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.84318733215332, "step": 109000}
{"episode_reward": 494.45134090677294, "episode": 110.0, "batch_reward": 0.28743391394615175, "critic_loss": 0.44367633558809755, "actor_loss": -34.916998390197755, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.159653186798096, "step": 110000}
{"episode_reward": 477.6087480066146, "episode": 111.0, "batch_reward": 0.2876699620038271, "critic_loss": 0.4204728627949953, "actor_loss": -35.22726441955567, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.07772469520569, "step": 111000}
{"episode_reward": 443.9117877904892, "episode": 112.0, "batch_reward": 0.2898096957057714, "critic_loss": 0.43186582922935485, "actor_loss": -35.097430698394774, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.42968988418579, "step": 112000}
{"episode_reward": 465.6737963607446, "episode": 113.0, "batch_reward": 0.2912347567826509, "critic_loss": 0.4044250143915415, "actor_loss": -34.92410256576538, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.502127170562744, "step": 113000}
{"episode_reward": 492.0570855023789, "episode": 114.0, "batch_reward": 0.2930764644443989, "critic_loss": 0.3991376926749945, "actor_loss": -35.98406396484375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.00659728050232, "step": 114000}
{"episode_reward": 487.3350761581594, "episode": 115.0, "batch_reward": 0.29508404844999314, "critic_loss": 0.47100142331421374, "actor_loss": -35.69196427154541, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.008831024169922, "step": 115000}
{"episode_reward": 465.02928717234283, "episode": 116.0, "batch_reward": 0.2967041552811861, "critic_loss": 0.4012324095070362, "actor_loss": -36.17696162033081, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.57734251022339, "step": 116000}
{"episode_reward": 452.02311839397123, "episode": 117.0, "batch_reward": 0.2982939016073942, "critic_loss": 0.4281961973756552, "actor_loss": -35.49336613082886, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.048709869384766, "step": 117000}
{"episode_reward": 485.9467536550641, "episode": 118.0, "batch_reward": 0.29943264709413053, "critic_loss": 0.4133924100100994, "actor_loss": -36.14682360458374, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.41588521003723, "step": 118000}
{"episode_reward": 462.6594189289159, "episode": 119.0, "batch_reward": 0.3008322038203478, "critic_loss": 0.4178533140271902, "actor_loss": -36.44772689819336, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.264610052108765, "step": 119000}
{"episode_reward": 473.6838748682483, "episode": 120.0, "batch_reward": 0.30185025197267534, "critic_loss": 0.41367413349449633, "actor_loss": -36.071237934112546, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.40004324913025, "step": 120000}
{"episode_reward": 435.50751443985837, "episode": 121.0, "batch_reward": 0.3031376129090786, "critic_loss": 0.38484640248119834, "actor_loss": -36.19981172180176, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.56961274147034, "step": 121000}
{"episode_reward": 439.98572894765965, "episode": 122.0, "batch_reward": 0.3040675514936447, "critic_loss": 0.41187265430390835, "actor_loss": -36.400313243865966, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.62906050682068, "step": 122000}
{"episode_reward": 468.71105789284843, "episode": 123.0, "batch_reward": 0.30564427794516086, "critic_loss": 0.4396570870429277, "actor_loss": -35.79830620956421, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.681817054748535, "step": 123000}
{"episode_reward": 462.92378252452545, "episode": 124.0, "batch_reward": 0.307082362100482, "critic_loss": 0.387077815592289, "actor_loss": -36.6766960105896, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.25728702545166, "step": 124000}
{"episode_reward": 478.55199830172484, "episode": 125.0, "batch_reward": 0.30801049222052096, "critic_loss": 0.4207370902746916, "actor_loss": -36.42448648834228, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.97256827354431, "step": 125000}
{"episode_reward": 470.4287033150148, "episode": 126.0, "batch_reward": 0.30833598640561105, "critic_loss": 0.4115267305523157, "actor_loss": -36.859455257415775, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.296200037002563, "step": 126000}
{"episode_reward": 452.2401409307093, "episode": 127.0, "batch_reward": 0.3106252609193325, "critic_loss": 0.37264253771305084, "actor_loss": -36.924608406066895, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.62368607521057, "step": 127000}
{"episode_reward": 477.70734908774864, "episode": 128.0, "batch_reward": 0.3123275710940361, "critic_loss": 0.3991391886919737, "actor_loss": -37.07392501449585, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.83502459526062, "step": 128000}
{"episode_reward": 474.7059593621392, "episode": 129.0, "batch_reward": 0.31230484795570373, "critic_loss": 0.37067170538008215, "actor_loss": -37.42710534286499, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.042407274246216, "step": 129000}
{"episode_reward": 462.63536886669027, "episode": 130.0, "batch_reward": 0.3143175848424435, "critic_loss": 0.3774642396569252, "actor_loss": -37.51246531677246, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.347747325897217, "step": 130000}
{"episode_reward": 463.8125167777784, "episode": 131.0, "batch_reward": 0.3164168521761894, "critic_loss": 0.3787169388979673, "actor_loss": -37.79255366897583, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.03668475151062, "step": 131000}
{"episode_reward": 480.1508640880872, "episode": 132.0, "batch_reward": 0.3172917483150959, "critic_loss": 0.40044189198315144, "actor_loss": -37.709217292785645, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.558490753173828, "step": 132000}
{"episode_reward": 463.150191440753, "episode": 133.0, "batch_reward": 0.31727354001998903, "critic_loss": 0.3802048109471798, "actor_loss": -37.578613971710205, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.8219633102417, "step": 133000}
{"episode_reward": 424.05553713498335, "episode": 134.0, "batch_reward": 0.31771521624922755, "critic_loss": 0.38084166863560676, "actor_loss": -37.77185007476807, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.226900815963745, "step": 134000}
{"episode_reward": 424.606155918779, "episode": 135.0, "batch_reward": 0.3195739143639803, "critic_loss": 0.3996105587258935, "actor_loss": -37.99646541976929, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.20361876487732, "step": 135000}
{"episode_reward": 423.9626568182038, "episode": 136.0, "batch_reward": 0.3199911441504955, "critic_loss": 0.38280901419371366, "actor_loss": -38.37130822372436, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.347737550735474, "step": 136000}
{"episode_reward": 473.46995965127854, "episode": 137.0, "batch_reward": 0.32044072505831717, "critic_loss": 0.362293516382575, "actor_loss": -38.04077353286743, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.094288110733032, "step": 137000}
{"episode_reward": 461.22758979813165, "episode": 138.0, "batch_reward": 0.32221422529220584, "critic_loss": 0.406284152418375, "actor_loss": -37.567713916778565, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.850759983062744, "step": 138000}
{"episode_reward": 455.49409379301613, "episode": 139.0, "batch_reward": 0.32343537172675135, "critic_loss": 0.33943619406223297, "actor_loss": -37.81598821258545, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.562247037887573, "step": 139000}
{"episode_reward": 436.754043724743, "episode": 140.0, "batch_reward": 0.3234586116671562, "critic_loss": 0.3634670869708061, "actor_loss": -37.59114908599854, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.760362148284912, "step": 140000}
{"episode_reward": 496.887907344877, "episode": 141.0, "batch_reward": 0.32579855129122737, "critic_loss": 0.36143441231548784, "actor_loss": -37.632431640625, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.440937995910645, "step": 141000}
{"episode_reward": 482.299318930928, "episode": 142.0, "batch_reward": 0.32595862314105034, "critic_loss": 0.3806708874553442, "actor_loss": -38.10355950546265, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.07399868965149, "step": 142000}
{"episode_reward": 452.4835253591284, "episode": 143.0, "batch_reward": 0.32849595054984093, "critic_loss": 0.37618050000071523, "actor_loss": -38.178173950195315, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.628374814987183, "step": 143000}
{"episode_reward": 490.56332912105705, "episode": 144.0, "batch_reward": 0.32822586959600447, "critic_loss": 0.3785042805969715, "actor_loss": -38.64732466888428, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.845479726791382, "step": 144000}
{"episode_reward": 477.11414535101966, "episode": 145.0, "batch_reward": 0.32999089986085894, "critic_loss": 0.3768705323189497, "actor_loss": -38.26883493804932, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.06930637359619, "step": 145000}
{"episode_reward": 465.6060447269492, "episode": 146.0, "batch_reward": 0.3298836908638477, "critic_loss": 0.37025064472854136, "actor_loss": -38.40565145874024, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.768482446670532, "step": 146000}
{"episode_reward": 477.8708371525222, "episode": 147.0, "batch_reward": 0.330926524579525, "critic_loss": 0.34353942399472, "actor_loss": -38.80623711013794, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.71597170829773, "step": 147000}
{"episode_reward": 455.98339336194294, "episode": 148.0, "batch_reward": 0.3332102463841438, "critic_loss": 0.38258365327119825, "actor_loss": -38.46099516677857, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.92349100112915, "step": 148000}
{"episode_reward": 501.1489423881667, "episode": 149.0, "batch_reward": 0.3329955122768879, "critic_loss": 0.34859056294709445, "actor_loss": -38.507537719726564, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.970791578292847, "step": 149000}
{"episode_reward": 487.07162268376544, "episode": 150.0, "batch_reward": 0.3350095020532608, "critic_loss": 0.3510403263270855, "actor_loss": -38.97964953613281, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
