{"episode_reward": 0.0, "episode": 1.0, "duration": 18.200315475463867, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.5389180183410645, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.2162947451081543, "critic_loss": 0.2456666607684237, "actor_loss": -46.80129981832821, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 62.30931305885315, "step": 3000}
{"episode_reward": 7.015048686269369, "episode": 4.0, "batch_reward": 0.13538702921569348, "critic_loss": 0.21812910861521959, "actor_loss": -49.18112052154541, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.610408306121826, "step": 4000}
{"episode_reward": 2.262758694644017, "episode": 5.0, "batch_reward": 0.10435479141399265, "critic_loss": 0.1872008540779352, "actor_loss": -50.54842459869385, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.762676000595093, "step": 5000}
{"episode_reward": 3.969635321193368, "episode": 6.0, "batch_reward": 0.08580814138054847, "critic_loss": 0.28376570193469525, "actor_loss": -53.16020335388183, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.967031717300415, "step": 6000}
{"episode_reward": 7.696354848306396, "episode": 7.0, "batch_reward": 0.07388545918092132, "critic_loss": 0.565341106981039, "actor_loss": -54.02688270568848, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.04058861732483, "step": 7000}
{"episode_reward": 3.9538196301128488, "episode": 8.0, "batch_reward": 0.06493069396913051, "critic_loss": 0.47896397283673287, "actor_loss": -60.7687406463623, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.952688694000244, "step": 8000}
{"episode_reward": 4.514545360055532, "episode": 9.0, "batch_reward": 0.05780660578235984, "critic_loss": 0.3424043887555599, "actor_loss": -63.24364459991455, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.35044026374817, "step": 9000}
{"episode_reward": 8.072825507426776, "episode": 10.0, "batch_reward": 0.052867225563153625, "critic_loss": 0.23640200575441123, "actor_loss": -63.14149662017822, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.107066869735718, "step": 10000}
{"episode_reward": 3.951050689011726, "episode": 11.0, "batch_reward": 0.048172002272680405, "critic_loss": 0.1932380596101284, "actor_loss": -60.830157524108884, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.17587447166443, "step": 11000}
{"episode_reward": 3.2659607974519402, "episode": 12.0, "batch_reward": 0.044390062732622027, "critic_loss": 0.15838401494175194, "actor_loss": -61.05080852508545, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.336509227752686, "step": 12000}
{"episode_reward": 3.003441601008607, "episode": 13.0, "batch_reward": 0.040819458162412045, "critic_loss": 0.1533260074555874, "actor_loss": -59.37676705932617, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.038156032562256, "step": 13000}
{"episode_reward": 6.073051981133845, "episode": 14.0, "batch_reward": 0.0389981835288927, "critic_loss": 0.17700478486716748, "actor_loss": -58.38413581085205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.795742511749268, "step": 14000}
{"episode_reward": 33.05105014104313, "episode": 15.0, "batch_reward": 0.038815824552439156, "critic_loss": 0.15725409710407257, "actor_loss": -56.8737678604126, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.241718769073486, "step": 15000}
{"episode_reward": 34.03804198481952, "episode": 16.0, "batch_reward": 0.03925298359338194, "critic_loss": 0.1944958301410079, "actor_loss": -54.74378579711914, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.010247707366943, "step": 16000}
{"episode_reward": 39.74818719014082, "episode": 17.0, "batch_reward": 0.04076264815870673, "critic_loss": 0.20096942753344774, "actor_loss": -52.83748082733154, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.1041738986969, "step": 17000}
{"episode_reward": 82.88306913256889, "episode": 18.0, "batch_reward": 0.041741158245131374, "critic_loss": 0.1916684114560485, "actor_loss": -50.48024474716186, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.149375200271606, "step": 18000}
{"episode_reward": 41.737785082180295, "episode": 19.0, "batch_reward": 0.04130492678005248, "critic_loss": 0.16093683686852456, "actor_loss": -47.06479281616211, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.142578601837158, "step": 19000}
{"episode_reward": 32.80561920267503, "episode": 20.0, "batch_reward": 0.03966945345513523, "critic_loss": 0.1259256711155176, "actor_loss": -45.99228181838989, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.063169956207275, "step": 20000}
{"episode_reward": 6.876010948083059, "episode": 21.0, "batch_reward": 0.038505889057181775, "critic_loss": 0.10575282929465174, "actor_loss": -44.27792247390747, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.57789874076843, "step": 21000}
{"episode_reward": 5.900446317109722, "episode": 22.0, "batch_reward": 0.03813677641190588, "critic_loss": 0.11271894049271941, "actor_loss": -42.681574626922604, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.448853015899658, "step": 22000}
{"episode_reward": 38.596136346018106, "episode": 23.0, "batch_reward": 0.040312540807761255, "critic_loss": 0.14121388806775212, "actor_loss": -41.23847827529907, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.755102396011353, "step": 23000}
{"episode_reward": 82.26520722002769, "episode": 24.0, "batch_reward": 0.040240922529250385, "critic_loss": 0.15806998789310456, "actor_loss": -39.75676248168946, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.85502052307129, "step": 24000}
{"episode_reward": 46.61071829610416, "episode": 25.0, "batch_reward": 0.03967651832289994, "critic_loss": 0.15805182130634784, "actor_loss": -38.29663217544556, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.179601669311523, "step": 25000}
{"episode_reward": 25.567068963873453, "episode": 26.0, "batch_reward": 0.04285405487008393, "critic_loss": 0.21107720107585193, "actor_loss": -38.08599733352661, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.866666555404663, "step": 26000}
{"episode_reward": 172.09184767655285, "episode": 27.0, "batch_reward": 0.04802013574168086, "critic_loss": 0.24382314769923688, "actor_loss": -38.191622814178466, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.49324917793274, "step": 27000}
{"episode_reward": 195.82512490382976, "episode": 28.0, "batch_reward": 0.0521115942876786, "critic_loss": 0.24698170880973339, "actor_loss": -38.07772127151489, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.885149478912354, "step": 28000}
{"episode_reward": 156.38220661527575, "episode": 29.0, "batch_reward": 0.05412970827147365, "critic_loss": 0.2053530930429697, "actor_loss": -37.59290752029419, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.750027894973755, "step": 29000}
{"episode_reward": 9.410707757945572, "episode": 30.0, "batch_reward": 0.05184532102011144, "critic_loss": 0.1573034746646881, "actor_loss": -36.905498889923095, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.783968687057495, "step": 30000}
{"episode_reward": 21.63998057314552, "episode": 31.0, "batch_reward": 0.0501260147690773, "critic_loss": 0.12756190983206034, "actor_loss": -36.12570030593872, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.41123056411743, "step": 31000}
{"episode_reward": 6.92453733002693, "episode": 32.0, "batch_reward": 0.04860082483291626, "critic_loss": 0.10638459249213338, "actor_loss": -35.20030857849121, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.77625870704651, "step": 32000}
{"episode_reward": 7.574940367421136, "episode": 33.0, "batch_reward": 0.05298713587597013, "critic_loss": 0.11592000037804245, "actor_loss": -34.428194236755374, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.594290733337402, "step": 33000}
{"episode_reward": 346.4146132162928, "episode": 34.0, "batch_reward": 0.0614882785640657, "critic_loss": 0.1338067255243659, "actor_loss": -33.898538780212405, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.0398006439209, "step": 34000}
{"episode_reward": 244.79091033818463, "episode": 35.0, "batch_reward": 0.06791364329308272, "critic_loss": 0.15957982386648656, "actor_loss": -33.065340171813965, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.77024817466736, "step": 35000}
{"episode_reward": 405.07297366248025, "episode": 36.0, "batch_reward": 0.07206841114163398, "critic_loss": 0.16687327172607183, "actor_loss": -32.36873572158814, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.047549962997437, "step": 36000}
{"episode_reward": 45.7832714509529, "episode": 37.0, "batch_reward": 0.07310141498222947, "critic_loss": 0.16518367140740156, "actor_loss": -31.49286150741577, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.23037552833557, "step": 37000}
{"episode_reward": 80.02756546343099, "episode": 38.0, "batch_reward": 0.07434775249287486, "critic_loss": 0.15126440223306417, "actor_loss": -30.57417950820923, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.5225350856781, "step": 38000}
{"episode_reward": 163.63085959427565, "episode": 39.0, "batch_reward": 0.07867905829101801, "critic_loss": 0.152680365934968, "actor_loss": -30.169812801361083, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.752987384796143, "step": 39000}
{"episode_reward": 428.72828032409154, "episode": 40.0, "batch_reward": 0.08882840329408645, "critic_loss": 0.15768517895787953, "actor_loss": -30.2938565864563, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.85061240196228, "step": 40000}
{"episode_reward": 493.7191345418292, "episode": 41.0, "batch_reward": 0.098352055888623, "critic_loss": 0.15750027517974377, "actor_loss": -30.4887677192688, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.66833472251892, "step": 41000}
{"episode_reward": 438.6508679590545, "episode": 42.0, "batch_reward": 0.10711983721330762, "critic_loss": 0.154386045999825, "actor_loss": -30.561655200958253, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.089614629745483, "step": 42000}
{"episode_reward": 492.899049563601, "episode": 43.0, "batch_reward": 0.11624946896731854, "critic_loss": 0.15660331397876143, "actor_loss": -30.935803634643555, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.219594955444336, "step": 43000}
{"episode_reward": 479.3647610225719, "episode": 44.0, "batch_reward": 0.12072833450138569, "critic_loss": 0.16351556208729745, "actor_loss": -30.88053150177002, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.005302667617798, "step": 44000}
{"episode_reward": 100.78155937137147, "episode": 45.0, "batch_reward": 0.12407796894758939, "critic_loss": 0.1682247089892626, "actor_loss": -30.760144287109377, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.884052276611328, "step": 45000}
{"episode_reward": 465.3937610047484, "episode": 46.0, "batch_reward": 0.13028916499763726, "critic_loss": 0.1644850193709135, "actor_loss": -31.040958198547365, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.284520149230957, "step": 46000}
{"episode_reward": 470.33086162561494, "episode": 47.0, "batch_reward": 0.13948355488479136, "critic_loss": 0.17222508525848387, "actor_loss": -31.0552951965332, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.95099425315857, "step": 47000}
{"episode_reward": 509.3766539316226, "episode": 48.0, "batch_reward": 0.14743490028381348, "critic_loss": 0.18821070785075425, "actor_loss": -31.355247093200685, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.904555082321167, "step": 48000}
{"episode_reward": 502.637126926717, "episode": 49.0, "batch_reward": 0.15226998028904198, "critic_loss": 0.19457904198020698, "actor_loss": -31.762807697296143, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.396650552749634, "step": 49000}
{"episode_reward": 174.60615223895738, "episode": 50.0, "batch_reward": 0.15275441930443048, "critic_loss": 0.20344166619330645, "actor_loss": -31.604596782684325, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.19425868988037, "step": 50000}
{"episode_reward": 251.7590449337939, "episode": 51.0, "batch_reward": 0.15612254670262338, "critic_loss": 0.22826173995435237, "actor_loss": -31.45496189880371, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.130144119262695, "step": 51000}
{"episode_reward": 514.3873441409986, "episode": 52.0, "batch_reward": 0.16052575675398112, "critic_loss": 0.21378288116306066, "actor_loss": -31.739288188934328, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.327300548553467, "step": 52000}
{"episode_reward": 147.20191381853442, "episode": 53.0, "batch_reward": 0.16340425615012646, "critic_loss": 0.1998048497289419, "actor_loss": -31.508264179229737, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.314231634140015, "step": 53000}
{"episode_reward": 496.18161114170226, "episode": 54.0, "batch_reward": 0.1690690605789423, "critic_loss": 0.20747595131397248, "actor_loss": -31.447471454620363, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.804595470428467, "step": 54000}
{"episode_reward": 482.7870504752572, "episode": 55.0, "batch_reward": 0.1737774017304182, "critic_loss": 0.23718114622682332, "actor_loss": -31.626204441070556, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.04192852973938, "step": 55000}
{"episode_reward": 444.7242844760289, "episode": 56.0, "batch_reward": 0.17986106093227863, "critic_loss": 0.20934678814560176, "actor_loss": -31.717990718841552, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.20014452934265, "step": 56000}
{"episode_reward": 520.8916082786535, "episode": 57.0, "batch_reward": 0.18702645187079905, "critic_loss": 0.2117931778728962, "actor_loss": -32.273616275787354, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.15471053123474, "step": 57000}
{"episode_reward": 534.0164841541157, "episode": 58.0, "batch_reward": 0.19307201048731804, "critic_loss": 0.18447245628386735, "actor_loss": -32.20792428588867, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.84227180480957, "step": 58000}
{"episode_reward": 515.9622732182963, "episode": 59.0, "batch_reward": 0.19784530057013036, "critic_loss": 0.1692381565272808, "actor_loss": -32.685926345825195, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.937193870544434, "step": 59000}
{"episode_reward": 545.1418372827479, "episode": 60.0, "batch_reward": 0.20343485608696937, "critic_loss": 0.16583225002139806, "actor_loss": -33.033970096588135, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.2251296043396, "step": 60000}
{"episode_reward": 534.5087615280368, "episode": 61.0, "batch_reward": 0.20898416662216188, "critic_loss": 0.18210917575657368, "actor_loss": -32.78095517349243, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.063977003097534, "step": 61000}
{"episode_reward": 552.6590232961735, "episode": 62.0, "batch_reward": 0.21350831811130047, "critic_loss": 0.15685036467015742, "actor_loss": -32.9253953742981, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.363630533218384, "step": 62000}
{"episode_reward": 518.3165376179963, "episode": 63.0, "batch_reward": 0.21816195660829543, "critic_loss": 0.17446052173525095, "actor_loss": -33.41049871444702, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.21616268157959, "step": 63000}
{"episode_reward": 549.673506057902, "episode": 64.0, "batch_reward": 0.22421936793625355, "critic_loss": 0.15747889760881661, "actor_loss": -33.534995349884035, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.761780261993408, "step": 64000}
{"episode_reward": 560.6888978588821, "episode": 65.0, "batch_reward": 0.22956064149737357, "critic_loss": 0.15880022288858892, "actor_loss": -33.822822479248046, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.408787727355957, "step": 65000}
{"episode_reward": 522.0728180292812, "episode": 66.0, "batch_reward": 0.23552702812850476, "critic_loss": 0.1721261665225029, "actor_loss": -34.15205134582519, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.077728271484375, "step": 66000}
{"episode_reward": 513.7598509544376, "episode": 67.0, "batch_reward": 0.23848151884973048, "critic_loss": 0.1744712438136339, "actor_loss": -34.318268211364746, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.95150661468506, "step": 67000}
{"episode_reward": 516.0986603550931, "episode": 68.0, "batch_reward": 0.24222253124415874, "critic_loss": 0.17514119228720665, "actor_loss": -34.461278068542484, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.813690423965454, "step": 68000}
{"episode_reward": 523.6324554812611, "episode": 69.0, "batch_reward": 0.24584944055974484, "critic_loss": 0.15584886059165, "actor_loss": -34.83426786422729, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.26425576210022, "step": 69000}
{"episode_reward": 550.164661333697, "episode": 70.0, "batch_reward": 0.2514439230710268, "critic_loss": 0.1654133876785636, "actor_loss": -35.24265293121338, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.873478174209595, "step": 70000}
{"episode_reward": 550.1801511143109, "episode": 71.0, "batch_reward": 0.25522554510831835, "critic_loss": 0.15019029127806424, "actor_loss": -35.42284999465942, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.55195069313049, "step": 71000}
{"episode_reward": 527.672132499198, "episode": 72.0, "batch_reward": 0.25917708149552343, "critic_loss": 0.1705665338858962, "actor_loss": -35.66711499404907, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.23773765563965, "step": 72000}
{"episode_reward": 570.8710896918827, "episode": 73.0, "batch_reward": 0.26385604563355447, "critic_loss": 0.1723671094402671, "actor_loss": -35.96258827209473, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.986957550048828, "step": 73000}
{"episode_reward": 540.6527003568771, "episode": 74.0, "batch_reward": 0.2669781425446272, "critic_loss": 0.17018265109509229, "actor_loss": -36.1214765625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.05979871749878, "step": 74000}
{"episode_reward": 402.6230231697817, "episode": 75.0, "batch_reward": 0.2696315456181765, "critic_loss": 0.17511602754890918, "actor_loss": -36.13501473999023, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.154767513275146, "step": 75000}
{"episode_reward": 562.9054988040336, "episode": 76.0, "batch_reward": 0.27309908904135227, "critic_loss": 0.1791413818076253, "actor_loss": -36.121704624176026, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.381794452667236, "step": 76000}
{"episode_reward": 536.5831282674903, "episode": 77.0, "batch_reward": 0.27703258889913557, "critic_loss": 0.18592806062102318, "actor_loss": -36.70402250289917, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.775201320648193, "step": 77000}
{"episode_reward": 577.1953557076772, "episode": 78.0, "batch_reward": 0.28078394329547884, "critic_loss": 0.20643290608376264, "actor_loss": -37.04876260375976, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.989929676055908, "step": 78000}
{"episode_reward": 539.7878125845781, "episode": 79.0, "batch_reward": 0.2836382438391447, "critic_loss": 0.24938736500591038, "actor_loss": -37.171763427734376, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.500150680541992, "step": 79000}
{"episode_reward": 563.4388629457039, "episode": 80.0, "batch_reward": 0.2870275083035231, "critic_loss": 0.31258063013851645, "actor_loss": -37.89271488952637, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.77764058113098, "step": 80000}
{"episode_reward": 544.8781839799971, "episode": 81.0, "batch_reward": 0.2905685358196497, "critic_loss": 0.31423417197167874, "actor_loss": -39.16184368133545, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.37359166145325, "step": 81000}
{"episode_reward": 545.0726128456726, "episode": 82.0, "batch_reward": 0.2940238564312458, "critic_loss": 0.2828241092264652, "actor_loss": -39.932514999389646, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.336528778076172, "step": 82000}
{"episode_reward": 540.7890543284124, "episode": 83.0, "batch_reward": 0.29384094654023646, "critic_loss": 0.30920507341623304, "actor_loss": -41.40294297027588, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.790804862976074, "step": 83000}
{"episode_reward": 3.3663583170813345, "episode": 84.0, "batch_reward": 0.2899764685332775, "critic_loss": 0.33020674899220465, "actor_loss": -42.18837924194336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.458523511886597, "step": 84000}
{"episode_reward": 2.7046596980312754, "episode": 85.0, "batch_reward": 0.2857240510284901, "critic_loss": 0.28742290295660494, "actor_loss": -42.18112167358399, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.02064609527588, "step": 85000}
{"episode_reward": 1.6853950925128862, "episode": 86.0, "batch_reward": 0.28230839873850344, "critic_loss": 0.22959315821528434, "actor_loss": -41.9411718826294, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.27263903617859, "step": 86000}
{"episode_reward": 3.3366619184016395, "episode": 87.0, "batch_reward": 0.280383833527565, "critic_loss": 0.1991524273008108, "actor_loss": -41.80255612182617, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.80419087409973, "step": 87000}
{"episode_reward": 5.191831459328672, "episode": 88.0, "batch_reward": 0.27680480635166166, "critic_loss": 0.18087806676328183, "actor_loss": -41.475363876342776, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.269575357437134, "step": 88000}
{"episode_reward": 2.2679285600032077, "episode": 89.0, "batch_reward": 0.27270910297334194, "critic_loss": 0.1611132924631238, "actor_loss": -41.028906272888186, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.655357599258423, "step": 89000}
{"episode_reward": 1.4573034284086681, "episode": 90.0, "batch_reward": 0.27004852452874184, "critic_loss": 0.1495801685974002, "actor_loss": -40.708916481018065, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.77794575691223, "step": 90000}
{"episode_reward": 2.125501278544169, "episode": 91.0, "batch_reward": 0.2679846217930317, "critic_loss": 0.15370069988444449, "actor_loss": -40.19915367889404, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.80562901496887, "step": 91000}
{"episode_reward": 1.4604122312228949, "episode": 92.0, "batch_reward": 0.26697386568784715, "critic_loss": 0.15058584805950523, "actor_loss": -39.924035102844236, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.111361026763916, "step": 92000}
{"episode_reward": 6.290844525478678, "episode": 93.0, "batch_reward": 0.2607306175231934, "critic_loss": 0.13735764610022305, "actor_loss": -39.40053402709961, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.773383378982544, "step": 93000}
{"episode_reward": 7.983460759362631, "episode": 94.0, "batch_reward": 0.2616406580358744, "critic_loss": 0.143194435082376, "actor_loss": -39.24225464630127, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.67879366874695, "step": 94000}
{"episode_reward": 545.419297140426, "episode": 95.0, "batch_reward": 0.2657847635447979, "critic_loss": 0.16478314518555998, "actor_loss": -39.25600016021728, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.239014387130737, "step": 95000}
{"episode_reward": 583.8200611841174, "episode": 96.0, "batch_reward": 0.2671980014294386, "critic_loss": 0.1440521494746208, "actor_loss": -38.94579154205322, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.109999179840088, "step": 96000}
{"episode_reward": 562.9686061963453, "episode": 97.0, "batch_reward": 0.2712005256563425, "critic_loss": 0.15764320410043, "actor_loss": -38.884640113830564, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.15418577194214, "step": 97000}
{"episode_reward": 542.5090147723527, "episode": 98.0, "batch_reward": 0.2756358666270971, "critic_loss": 0.15702567801624537, "actor_loss": -38.89481922149658, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.281407117843628, "step": 98000}
{"episode_reward": 557.1351258725108, "episode": 99.0, "batch_reward": 0.2772886851280928, "critic_loss": 0.14863509085029364, "actor_loss": -38.81295074462891, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.298482179641724, "step": 99000}
{"episode_reward": 558.4318471960721, "episode": 100.0, "batch_reward": 0.2805311666727066, "critic_loss": 0.1648473093211651, "actor_loss": -38.815289360046386, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.79773998260498, "step": 100000}
{"episode_reward": 550.947689217045, "episode": 101.0, "batch_reward": 0.2815765567868948, "critic_loss": 0.1706538526713848, "actor_loss": -38.77018868255615, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.67069387435913, "step": 101000}
{"episode_reward": 571.2512239405875, "episode": 102.0, "batch_reward": 0.2841100744903088, "critic_loss": 0.16941917438060045, "actor_loss": -38.97010327911377, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.404090404510498, "step": 102000}
{"episode_reward": 603.1774610713692, "episode": 103.0, "batch_reward": 0.2879420541971922, "critic_loss": 0.17370582757145167, "actor_loss": -39.091548072814945, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.792688369750977, "step": 103000}
{"episode_reward": 601.3052739867217, "episode": 104.0, "batch_reward": 0.29117882265150546, "critic_loss": 0.16356343051791192, "actor_loss": -39.09845346832275, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.755042552947998, "step": 104000}
{"episode_reward": 572.7836371446482, "episode": 105.0, "batch_reward": 0.29558504082262516, "critic_loss": 0.16689419952780007, "actor_loss": -39.274583641052246, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.765010118484497, "step": 105000}
{"episode_reward": 574.7300981069607, "episode": 106.0, "batch_reward": 0.29556691566109655, "critic_loss": 0.16576464214920997, "actor_loss": -39.07964328765869, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.79910922050476, "step": 106000}
{"episode_reward": 579.6468541542087, "episode": 107.0, "batch_reward": 0.29990127554535867, "critic_loss": 0.15272614086791872, "actor_loss": -39.506734260559085, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.752788066864014, "step": 107000}
{"episode_reward": 606.228200778987, "episode": 108.0, "batch_reward": 0.30304265522956847, "critic_loss": 0.17477917437255383, "actor_loss": -39.96240528106689, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.144191026687622, "step": 108000}
{"episode_reward": 575.3741217727442, "episode": 109.0, "batch_reward": 0.305289439573884, "critic_loss": 0.15065051686018704, "actor_loss": -40.0404641418457, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.414336442947388, "step": 109000}
{"episode_reward": 581.6766522662458, "episode": 110.0, "batch_reward": 0.3092793617546558, "critic_loss": 0.15305352856218815, "actor_loss": -40.27521488952637, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.746635675430298, "step": 110000}
{"episode_reward": 600.6852442042383, "episode": 111.0, "batch_reward": 0.3103111273050308, "critic_loss": 0.15527384605258704, "actor_loss": -40.567534477233885, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.77382159233093, "step": 111000}
{"episode_reward": 549.6295892650079, "episode": 112.0, "batch_reward": 0.3123282950669527, "critic_loss": 0.15365311726927758, "actor_loss": -40.524125297546384, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.937217235565186, "step": 112000}
{"episode_reward": 592.725858379132, "episode": 113.0, "batch_reward": 0.3148506877720356, "critic_loss": 0.16944602175056933, "actor_loss": -40.61053148651123, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.78359818458557, "step": 113000}
{"episode_reward": 612.1296034581487, "episode": 114.0, "batch_reward": 0.3165973823219538, "critic_loss": 0.17324391857534646, "actor_loss": -40.77272409057617, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.018882989883423, "step": 114000}
{"episode_reward": 589.3114363534693, "episode": 115.0, "batch_reward": 0.32006601226329806, "critic_loss": 0.1631974060423672, "actor_loss": -41.07630879974365, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.170978307724, "step": 115000}
{"episode_reward": 583.2549255839768, "episode": 116.0, "batch_reward": 0.32340597043931485, "critic_loss": 0.14840607495233415, "actor_loss": -41.27309272003174, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.794124126434326, "step": 116000}
{"episode_reward": 593.1584876460214, "episode": 117.0, "batch_reward": 0.3231997134834528, "critic_loss": 0.14741851891949773, "actor_loss": -41.31089644622803, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.874929428100586, "step": 117000}
{"episode_reward": 583.9010029868663, "episode": 118.0, "batch_reward": 0.3265542685985565, "critic_loss": 0.1530771253630519, "actor_loss": -41.36118706512451, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.258094310760498, "step": 118000}
{"episode_reward": 599.2635693812489, "episode": 119.0, "batch_reward": 0.3285841110497713, "critic_loss": 0.15322087390720845, "actor_loss": -41.59794589233398, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.092458248138428, "step": 119000}
{"episode_reward": 579.6594544011895, "episode": 120.0, "batch_reward": 0.32942388027906416, "critic_loss": 0.15115051884949207, "actor_loss": -41.62949493408203, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.779892683029175, "step": 120000}
{"episode_reward": 563.5476456855839, "episode": 121.0, "batch_reward": 0.333273911267519, "critic_loss": 0.1330717582292855, "actor_loss": -42.11548738098144, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.36381554603577, "step": 121000}
{"episode_reward": 574.0537644761141, "episode": 122.0, "batch_reward": 0.33475567504763604, "critic_loss": 0.1397960671298206, "actor_loss": -42.348665840148925, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.756757974624634, "step": 122000}
{"episode_reward": 581.9730435892019, "episode": 123.0, "batch_reward": 0.33848973029851914, "critic_loss": 0.14879674802720547, "actor_loss": -42.44989988708496, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.477074146270752, "step": 123000}
{"episode_reward": 601.211576629358, "episode": 124.0, "batch_reward": 0.3396224871873856, "critic_loss": 0.15359961511194706, "actor_loss": -42.6561782913208, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.989007234573364, "step": 124000}
{"episode_reward": 604.9361108485812, "episode": 125.0, "batch_reward": 0.34102398228645325, "critic_loss": 0.1467561754025519, "actor_loss": -42.78205056762695, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.749388933181763, "step": 125000}
{"episode_reward": 611.7186925613445, "episode": 126.0, "batch_reward": 0.3437861431837082, "critic_loss": 0.1406760728545487, "actor_loss": -42.98116206359863, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.446770668029785, "step": 126000}
{"episode_reward": 609.2272768594054, "episode": 127.0, "batch_reward": 0.345248655796051, "critic_loss": 0.14771400118991732, "actor_loss": -43.15798418426514, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.25161623954773, "step": 127000}
{"episode_reward": 575.6675830621588, "episode": 128.0, "batch_reward": 0.34764273518323896, "critic_loss": 0.14109829755872488, "actor_loss": -43.30091679382324, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.000988006591797, "step": 128000}
{"episode_reward": 592.9407803480385, "episode": 129.0, "batch_reward": 0.3489986576139927, "critic_loss": 0.14074893166869878, "actor_loss": -43.595336288452145, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.383833408355713, "step": 129000}
{"episode_reward": 566.9567170037328, "episode": 130.0, "batch_reward": 0.35172045531868934, "critic_loss": 0.13403635178133846, "actor_loss": -43.57664316558838, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.29627776145935, "step": 130000}
{"episode_reward": 581.138399611062, "episode": 131.0, "batch_reward": 0.3541962702870369, "critic_loss": 0.15148516522720457, "actor_loss": -43.65566013336181, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.172372817993164, "step": 131000}
{"episode_reward": 602.6134703825671, "episode": 132.0, "batch_reward": 0.3549745326042175, "critic_loss": 0.13995110643282532, "actor_loss": -43.587425476074216, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.890440940856934, "step": 132000}
{"episode_reward": 584.0492906709147, "episode": 133.0, "batch_reward": 0.355987654030323, "critic_loss": 0.14651799163594842, "actor_loss": -43.8845146560669, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.574838399887085, "step": 133000}
{"episode_reward": 616.6539993490144, "episode": 134.0, "batch_reward": 0.3582873014807701, "critic_loss": 0.1458619927316904, "actor_loss": -43.97603159332275, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.778381824493408, "step": 134000}
{"episode_reward": 588.437989388917, "episode": 135.0, "batch_reward": 0.3595966962575913, "critic_loss": 0.13428533528372646, "actor_loss": -43.85985208892822, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.747970581054688, "step": 135000}
{"episode_reward": 622.6650284804974, "episode": 136.0, "batch_reward": 0.362210633546114, "critic_loss": 0.14421877036243677, "actor_loss": -44.353539665222165, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.114868879318237, "step": 136000}
{"episode_reward": 584.8284025659933, "episode": 137.0, "batch_reward": 0.3632369684278965, "critic_loss": 0.15125812381505965, "actor_loss": -44.24890538024902, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.532190799713135, "step": 137000}
{"episode_reward": 611.4869192354234, "episode": 138.0, "batch_reward": 0.36556675013899803, "critic_loss": 0.15177868575975298, "actor_loss": -44.470753349304196, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.792855262756348, "step": 138000}
{"episode_reward": 593.4900180738298, "episode": 139.0, "batch_reward": 0.3664848351478577, "critic_loss": 0.13592260295897723, "actor_loss": -44.69907666015625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.829134702682495, "step": 139000}
{"episode_reward": 597.1889963321801, "episode": 140.0, "batch_reward": 0.3676058201789856, "critic_loss": 0.13912740433961154, "actor_loss": -44.76212601470947, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.65181851387024, "step": 140000}
{"episode_reward": 623.568832139755, "episode": 141.0, "batch_reward": 0.37116797450184824, "critic_loss": 0.13569666777178646, "actor_loss": -44.90820076751709, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.59986233711243, "step": 141000}
{"episode_reward": 598.7892610080477, "episode": 142.0, "batch_reward": 0.3715818844139576, "critic_loss": 0.14295028883218766, "actor_loss": -44.74329082489014, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.182084321975708, "step": 142000}
{"episode_reward": 620.074972823482, "episode": 143.0, "batch_reward": 0.37543410125374793, "critic_loss": 0.14067472231388092, "actor_loss": -45.15550212860107, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.94577693939209, "step": 143000}
{"episode_reward": 609.7753213543334, "episode": 144.0, "batch_reward": 0.37493170872330667, "critic_loss": 0.12975862381979822, "actor_loss": -45.219447914123535, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.77331042289734, "step": 144000}
{"episode_reward": 561.6732792048286, "episode": 145.0, "batch_reward": 0.37883808293938637, "critic_loss": 0.15612860158085823, "actor_loss": -45.329288627624514, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.130282163619995, "step": 145000}
{"episode_reward": 588.419029747882, "episode": 146.0, "batch_reward": 0.3773651740252972, "critic_loss": 0.14017203644290566, "actor_loss": -45.44591269683838, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.865885496139526, "step": 146000}
{"episode_reward": 636.2823210568771, "episode": 147.0, "batch_reward": 0.37969691839814185, "critic_loss": 0.13988535243645311, "actor_loss": -45.643199226379394, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.777716875076294, "step": 147000}
{"episode_reward": 582.30023339007, "episode": 148.0, "batch_reward": 0.3821901470422745, "critic_loss": 0.15162593288719653, "actor_loss": -45.76812104034424, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.53327465057373, "step": 148000}
{"episode_reward": 582.0702059517516, "episode": 149.0, "batch_reward": 0.38296144372224805, "critic_loss": 0.14954060434550048, "actor_loss": -45.7353638381958, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.85448670387268, "step": 149000}
{"episode_reward": 590.3991019921976, "episode": 150.0, "batch_reward": 0.38486661624908447, "critic_loss": 0.152314580462873, "actor_loss": -45.886011764526366, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
