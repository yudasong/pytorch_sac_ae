{"episode_reward": 0.0, "episode": 1.0, "duration": 12.866973876953125, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.1189377307891846, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.22074813243944513, "critic_loss": 0.20256144310080357, "actor_loss": -44.25968972336249, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 71.35657572746277, "step": 3000}
{"episode_reward": 106.64586997834607, "episode": 4.0, "batch_reward": 0.18576112158596517, "critic_loss": 0.20288732782006264, "actor_loss": -40.19380809783936, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.853909254074097, "step": 4000}
{"episode_reward": 178.92274740401223, "episode": 5.0, "batch_reward": 0.18618372444808484, "critic_loss": 0.2535944326519966, "actor_loss": -39.0464461479187, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.21940541267395, "step": 5000}
{"episode_reward": 137.6794082445611, "episode": 6.0, "batch_reward": 0.182496757671237, "critic_loss": 0.253409743770957, "actor_loss": -36.80060019683838, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.95969796180725, "step": 6000}
{"episode_reward": 187.48255413029554, "episode": 7.0, "batch_reward": 0.17728069858253, "critic_loss": 0.2308492632880807, "actor_loss": -34.68433334350586, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.343838214874268, "step": 7000}
{"episode_reward": 109.41221707645616, "episode": 8.0, "batch_reward": 0.17095965294539928, "critic_loss": 0.2169032738059759, "actor_loss": -33.13716394805908, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.42810559272766, "step": 8000}
{"episode_reward": 147.27909743634675, "episode": 9.0, "batch_reward": 0.17123184564709665, "critic_loss": 0.21941564179956913, "actor_loss": -31.959801349639893, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.011303424835205, "step": 9000}
{"episode_reward": 244.4993912089025, "episode": 10.0, "batch_reward": 0.16984663952887058, "critic_loss": 0.21285474045574665, "actor_loss": -31.258486660003662, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.078643798828125, "step": 10000}
{"episode_reward": 39.4127809795534, "episode": 11.0, "batch_reward": 0.16798121718317272, "critic_loss": 0.23480109412223102, "actor_loss": -30.3334479637146, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.390637159347534, "step": 11000}
{"episode_reward": 278.66014202543647, "episode": 12.0, "batch_reward": 0.1779204561561346, "critic_loss": 0.24231640514731406, "actor_loss": -30.679654243469237, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.94068741798401, "step": 12000}
{"episode_reward": 256.8721738439486, "episode": 13.0, "batch_reward": 0.1774873336702585, "critic_loss": 0.21796617951989175, "actor_loss": -30.007190227508545, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.12996006011963, "step": 13000}
{"episode_reward": 81.45124928463638, "episode": 14.0, "batch_reward": 0.17246214538812638, "critic_loss": 0.22629320043325424, "actor_loss": -29.40710466003418, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.416355848312378, "step": 14000}
{"episode_reward": 147.58589127740325, "episode": 15.0, "batch_reward": 0.1739447422400117, "critic_loss": 0.22804882352799177, "actor_loss": -28.454510581970215, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.062681436538696, "step": 15000}
{"episode_reward": 190.81090919144654, "episode": 16.0, "batch_reward": 0.16772475455701352, "critic_loss": 0.21790110401809215, "actor_loss": -27.236498649597166, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.9361515045166, "step": 16000}
{"episode_reward": 29.45604359079823, "episode": 17.0, "batch_reward": 0.1611404057368636, "critic_loss": 0.19698923905938864, "actor_loss": -26.6407978515625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.347682237625122, "step": 17000}
{"episode_reward": 79.68318429914363, "episode": 18.0, "batch_reward": 0.16339265476167203, "critic_loss": 0.18738005550205708, "actor_loss": -26.512640060424804, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.09874653816223, "step": 18000}
{"episode_reward": 377.0016678388951, "episode": 19.0, "batch_reward": 0.17071913945674896, "critic_loss": 0.206355060108006, "actor_loss": -26.76403229522705, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.351444959640503, "step": 19000}
{"episode_reward": 169.70379039582588, "episode": 20.0, "batch_reward": 0.17534731017053126, "critic_loss": 0.20673387592285872, "actor_loss": -26.49673636627197, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.157185554504395, "step": 20000}
{"episode_reward": 433.549688528253, "episode": 21.0, "batch_reward": 0.1884109704196453, "critic_loss": 0.1977933887988329, "actor_loss": -27.11619560623169, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.38020730018616, "step": 21000}
{"episode_reward": 447.99581274120277, "episode": 22.0, "batch_reward": 0.19807079599797725, "critic_loss": 0.20751566599309446, "actor_loss": -27.949872764587404, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.47194266319275, "step": 22000}
{"episode_reward": 240.58496574607642, "episode": 23.0, "batch_reward": 0.1955900580585003, "critic_loss": 0.19983399833738805, "actor_loss": -27.76829940032959, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.215765953063965, "step": 23000}
{"episode_reward": 65.96627674472238, "episode": 24.0, "batch_reward": 0.19592646422982216, "critic_loss": 0.19701713088154793, "actor_loss": -27.09480099105835, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.745471954345703, "step": 24000}
{"episode_reward": 432.6951641444468, "episode": 25.0, "batch_reward": 0.20639174468815327, "critic_loss": 0.20746804536879063, "actor_loss": -28.36885572052002, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.22498059272766, "step": 25000}
{"episode_reward": 454.0387804926534, "episode": 26.0, "batch_reward": 0.21453485517203807, "critic_loss": 0.22649350157380105, "actor_loss": -28.92097013092041, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.23627734184265, "step": 26000}
{"episode_reward": 309.00441451696366, "episode": 27.0, "batch_reward": 0.22000209040939808, "critic_loss": 0.2696749795973301, "actor_loss": -29.05667834854126, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.426532745361328, "step": 27000}
{"episode_reward": 471.01709255231043, "episode": 28.0, "batch_reward": 0.22839960892498493, "critic_loss": 0.3173697162717581, "actor_loss": -29.839476776123046, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.224738121032715, "step": 28000}
{"episode_reward": 443.4906269092566, "episode": 29.0, "batch_reward": 0.23669237385690212, "critic_loss": 0.4912007590606809, "actor_loss": -29.783560939788817, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.26851463317871, "step": 29000}
{"episode_reward": 369.74173497345697, "episode": 30.0, "batch_reward": 0.241818603053689, "critic_loss": 1.6052502548694612, "actor_loss": -31.552965576171875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.100446224212646, "step": 30000}
{"episode_reward": 453.0295506651527, "episode": 31.0, "batch_reward": 0.2413780389279127, "critic_loss": 3.6252768172025682, "actor_loss": -35.135945175170896, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.558735370635986, "step": 31000}
{"episode_reward": 19.213037141209522, "episode": 32.0, "batch_reward": 0.23417789366841316, "critic_loss": 4.982947913408279, "actor_loss": -38.7480972290039, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.281906127929688, "step": 32000}
{"episode_reward": 28.606060585724915, "episode": 33.0, "batch_reward": 0.2287185528576374, "critic_loss": 6.042678602218628, "actor_loss": -42.851423446655275, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.617490530014038, "step": 33000}
{"episode_reward": 9.777503788251702, "episode": 34.0, "batch_reward": 0.22135554134845734, "critic_loss": 6.564227508783341, "actor_loss": -47.24006866455078, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.30266284942627, "step": 34000}
{"episode_reward": 12.046496937609508, "episode": 35.0, "batch_reward": 0.2155980945378542, "critic_loss": 7.286953590154647, "actor_loss": -53.747156826019285, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.035332679748535, "step": 35000}
{"episode_reward": 12.537124457104103, "episode": 36.0, "batch_reward": 0.20947642847895623, "critic_loss": 7.840450055599213, "actor_loss": -58.791191970825196, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.196443796157837, "step": 36000}
{"episode_reward": 11.064991873265205, "episode": 37.0, "batch_reward": 0.2034848638921976, "critic_loss": 6.801295990467072, "actor_loss": -65.04529356384278, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.67120361328125, "step": 37000}
{"episode_reward": 12.47287072728465, "episode": 38.0, "batch_reward": 0.19950731340050698, "critic_loss": 5.275360792398453, "actor_loss": -71.73992407989502, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.455111265182495, "step": 38000}
{"episode_reward": 14.325696409565094, "episode": 39.0, "batch_reward": 0.1948602964133024, "critic_loss": 4.533230536460876, "actor_loss": -77.20861504364014, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.20539665222168, "step": 39000}
{"episode_reward": 19.609186292100954, "episode": 40.0, "batch_reward": 0.1903358312472701, "critic_loss": 3.432757112264633, "actor_loss": -76.91043096160888, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.288381338119507, "step": 40000}
{"episode_reward": 21.65647673865609, "episode": 41.0, "batch_reward": 0.1874497580230236, "critic_loss": 2.736338421702385, "actor_loss": -76.70893663024903, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.34179496765137, "step": 41000}
{"episode_reward": 27.979202951703098, "episode": 42.0, "batch_reward": 0.18169825243949891, "critic_loss": 2.756609479665756, "actor_loss": -75.0289521560669, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.452993869781494, "step": 42000}
{"episode_reward": 55.72184425335348, "episode": 43.0, "batch_reward": 0.17844051320105792, "critic_loss": 2.871992121577263, "actor_loss": -73.84056657791137, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.815579652786255, "step": 43000}
{"episode_reward": 27.76244861111466, "episode": 44.0, "batch_reward": 0.1759428735896945, "critic_loss": 2.9438105722665786, "actor_loss": -72.89049488830567, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.320829153060913, "step": 44000}
{"episode_reward": 22.313705974720826, "episode": 45.0, "batch_reward": 0.17161353342980146, "critic_loss": 2.78649987924099, "actor_loss": -75.43091665267944, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.234352350234985, "step": 45000}
{"episode_reward": 5.180851915599952, "episode": 46.0, "batch_reward": 0.16854388685524463, "critic_loss": 3.102910525560379, "actor_loss": -73.34060146331787, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.125465154647827, "step": 46000}
{"episode_reward": 7.488024820014056, "episode": 47.0, "batch_reward": 0.16519229064881802, "critic_loss": 4.440842879772187, "actor_loss": -73.86406289291382, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.483031511306763, "step": 47000}
{"episode_reward": 7.170038136874362, "episode": 48.0, "batch_reward": 0.16124076757580041, "critic_loss": 5.31869914150238, "actor_loss": -74.2150435295105, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.186180353164673, "step": 48000}
{"episode_reward": 25.4644833032895, "episode": 49.0, "batch_reward": 0.15837391474097967, "critic_loss": 5.377332720041275, "actor_loss": -79.81462993621827, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.359097719192505, "step": 49000}
{"episode_reward": 19.902783086963968, "episode": 50.0, "batch_reward": 0.1551283731237054, "critic_loss": 5.454698356151581, "actor_loss": -81.25294067001343, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.10610580444336, "step": 50000}
{"episode_reward": 13.967080128835446, "episode": 51.0, "batch_reward": 0.15423861600458622, "critic_loss": 6.705239561319352, "actor_loss": -82.06343785476685, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.71336078643799, "step": 51000}
{"episode_reward": 14.452228947655351, "episode": 52.0, "batch_reward": 0.1498072065040469, "critic_loss": 7.012551723241806, "actor_loss": -87.0169199142456, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.319334506988525, "step": 52000}
{"episode_reward": 13.404366416184043, "episode": 53.0, "batch_reward": 0.1470699752345681, "critic_loss": 7.097111604213715, "actor_loss": -85.14253730392456, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.944761514663696, "step": 53000}
{"episode_reward": 12.325361750737242, "episode": 54.0, "batch_reward": 0.14454937125742434, "critic_loss": 7.297662778377533, "actor_loss": -88.07450615310668, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.519442319869995, "step": 54000}
{"episode_reward": 14.330447240266057, "episode": 55.0, "batch_reward": 0.14275654284656047, "critic_loss": 7.9674518158435825, "actor_loss": -87.73690041351318, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.11446523666382, "step": 55000}
{"episode_reward": 12.850120224938829, "episode": 56.0, "batch_reward": 0.14068051233142614, "critic_loss": 7.810915367126465, "actor_loss": -92.95654885482789, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.885285139083862, "step": 56000}
{"episode_reward": 25.393413407770176, "episode": 57.0, "batch_reward": 0.13757438220083715, "critic_loss": 7.496136732578278, "actor_loss": -91.60964043807984, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.086827278137207, "step": 57000}
{"episode_reward": 28.93182245554531, "episode": 58.0, "batch_reward": 0.13721773447841407, "critic_loss": 6.58671802520752, "actor_loss": -89.67453823852539, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.058664560317993, "step": 58000}
{"episode_reward": 12.840383859945307, "episode": 59.0, "batch_reward": 0.13415905624628066, "critic_loss": 6.583230211496353, "actor_loss": -88.5336650238037, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.16528868675232, "step": 59000}
{"episode_reward": 15.038327066074338, "episode": 60.0, "batch_reward": 0.13264489800482987, "critic_loss": 7.755741374254226, "actor_loss": -90.37321016693116, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.173473119735718, "step": 60000}
{"episode_reward": 29.46120548661972, "episode": 61.0, "batch_reward": 0.1308720955327153, "critic_loss": 9.698762849330903, "actor_loss": -88.57535675048828, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.266380071640015, "step": 61000}
{"episode_reward": 23.7029967285542, "episode": 62.0, "batch_reward": 0.12971361627429723, "critic_loss": 12.519488338947296, "actor_loss": -87.57462343978882, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.477288961410522, "step": 62000}
{"episode_reward": 42.37336257724302, "episode": 63.0, "batch_reward": 0.1291442132666707, "critic_loss": 11.707324868679047, "actor_loss": -87.87482611846924, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.38795804977417, "step": 63000}
{"episode_reward": 249.75793741650565, "episode": 64.0, "batch_reward": 0.13145537297427654, "critic_loss": 10.461232481002808, "actor_loss": -90.58281161499023, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.386576652526855, "step": 64000}
{"episode_reward": 244.0728959053814, "episode": 65.0, "batch_reward": 0.13354359009116887, "critic_loss": 9.586207966804505, "actor_loss": -90.10152532577514, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.512170791625977, "step": 65000}
{"episode_reward": 253.60886574869468, "episode": 66.0, "batch_reward": 0.13355817436426878, "critic_loss": 7.72858150100708, "actor_loss": -91.67319227218628, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.100847005844116, "step": 66000}
{"episode_reward": 190.636871376472, "episode": 67.0, "batch_reward": 0.1356293947249651, "critic_loss": 5.836008726119995, "actor_loss": -95.57877032089233, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.655158281326294, "step": 67000}
{"episode_reward": 276.4226659217637, "episode": 68.0, "batch_reward": 0.1387721070125699, "critic_loss": 4.903620819091797, "actor_loss": -89.75702077484131, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.126283407211304, "step": 68000}
{"episode_reward": 316.36637796988174, "episode": 69.0, "batch_reward": 0.13842622281610967, "critic_loss": 4.218436824202538, "actor_loss": -90.47646254730225, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.85210108757019, "step": 69000}
{"episode_reward": 54.86607203984862, "episode": 70.0, "batch_reward": 0.13718775177001954, "critic_loss": 3.052964642047882, "actor_loss": -90.06496812438965, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.090707540512085, "step": 70000}
{"episode_reward": 4.421004692336279, "episode": 71.0, "batch_reward": 0.13781099066883326, "critic_loss": 2.4210893458127973, "actor_loss": -84.76646312713623, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.204516649246216, "step": 71000}
{"episode_reward": 325.6801094858806, "episode": 72.0, "batch_reward": 0.13965075233578683, "critic_loss": 1.984536035656929, "actor_loss": -83.46987167739869, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.169109106063843, "step": 72000}
{"episode_reward": 367.6765077913914, "episode": 73.0, "batch_reward": 0.14283324282616378, "critic_loss": 1.9658803665041924, "actor_loss": -80.81462591171265, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.24527931213379, "step": 73000}
{"episode_reward": 164.85479155461525, "episode": 74.0, "batch_reward": 0.14496654722094535, "critic_loss": 1.616324561715126, "actor_loss": -81.29945449066162, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.47119402885437, "step": 74000}
{"episode_reward": 442.6958342974742, "episode": 75.0, "batch_reward": 0.14964255774021148, "critic_loss": 1.462997708261013, "actor_loss": -79.58854358673096, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.167749881744385, "step": 75000}
{"episode_reward": 465.05197841599613, "episode": 76.0, "batch_reward": 0.15198618514090775, "critic_loss": 1.373380046069622, "actor_loss": -76.90224038696289, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.74474859237671, "step": 76000}
{"episode_reward": 466.6148666964265, "episode": 77.0, "batch_reward": 0.15647203365713358, "critic_loss": 1.2608259395956993, "actor_loss": -75.18359161376954, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.420674324035645, "step": 77000}
{"episode_reward": 496.62450042743484, "episode": 78.0, "batch_reward": 0.1619847923666239, "critic_loss": 1.1717491169571876, "actor_loss": -74.40546815490723, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.394749641418457, "step": 78000}
{"episode_reward": 467.18367688682645, "episode": 79.0, "batch_reward": 0.1650101311802864, "critic_loss": 1.0715311383605004, "actor_loss": -68.6169008178711, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.249648571014404, "step": 79000}
{"episode_reward": 473.84088529987906, "episode": 80.0, "batch_reward": 0.1683154890909791, "critic_loss": 0.9994093543291092, "actor_loss": -69.23822012710572, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.101430892944336, "step": 80000}
{"episode_reward": 478.6457927466908, "episode": 81.0, "batch_reward": 0.17297485689073802, "critic_loss": 0.833042887121439, "actor_loss": -67.85787867355347, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.0035126209259, "step": 81000}
{"episode_reward": 483.5851960030341, "episode": 82.0, "batch_reward": 0.1772307363972068, "critic_loss": 0.7300830042660237, "actor_loss": -69.45487218475341, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.383760690689087, "step": 82000}
{"episode_reward": 472.7007785205984, "episode": 83.0, "batch_reward": 0.18109907173365355, "critic_loss": 0.680375233411789, "actor_loss": -64.9407597541809, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.380992650985718, "step": 83000}
{"episode_reward": 459.60552445056175, "episode": 84.0, "batch_reward": 0.1846951179653406, "critic_loss": 0.5872696861326695, "actor_loss": -65.67074101257325, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.19898819923401, "step": 84000}
{"episode_reward": 479.32491485495353, "episode": 85.0, "batch_reward": 0.1881095369756222, "critic_loss": 0.5243189020752906, "actor_loss": -63.76027326965332, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.043063640594482, "step": 85000}
{"episode_reward": 482.75615589940924, "episode": 86.0, "batch_reward": 0.19192534330487251, "critic_loss": 0.4805704130530357, "actor_loss": -60.480573013305666, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.10503911972046, "step": 86000}
{"episode_reward": 487.6793113554024, "episode": 87.0, "batch_reward": 0.1949531624019146, "critic_loss": 0.43487938593328, "actor_loss": -60.39196467590332, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.530107975006104, "step": 87000}
{"episode_reward": 479.39401912667904, "episode": 88.0, "batch_reward": 0.1971019778549671, "critic_loss": 0.39959379498660563, "actor_loss": -58.39782398223877, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.06932806968689, "step": 88000}
{"episode_reward": 470.87891043378926, "episode": 89.0, "batch_reward": 0.2016939363181591, "critic_loss": 0.4020722536146641, "actor_loss": -57.71886045074463, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.410643339157104, "step": 89000}
{"episode_reward": 511.49907121417124, "episode": 90.0, "batch_reward": 0.20426716473698617, "critic_loss": 0.386373076453805, "actor_loss": -57.057202827453615, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.388463020324707, "step": 90000}
{"episode_reward": 506.8815544290165, "episode": 91.0, "batch_reward": 0.20688872128725053, "critic_loss": 0.37778822116553784, "actor_loss": -54.79504964447022, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.12606883049011, "step": 91000}
{"episode_reward": 496.38237683719944, "episode": 92.0, "batch_reward": 0.21053650830686094, "critic_loss": 0.3581408749073744, "actor_loss": -54.2493366317749, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.99878764152527, "step": 92000}
{"episode_reward": 492.7619626753574, "episode": 93.0, "batch_reward": 0.21408825597167014, "critic_loss": 0.31345978163182736, "actor_loss": -53.22816463470459, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.453026056289673, "step": 93000}
{"episode_reward": 500.5689355476965, "episode": 94.0, "batch_reward": 0.21726272077858447, "critic_loss": 0.33511102589964864, "actor_loss": -52.454344047546385, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.584529876708984, "step": 94000}
{"episode_reward": 501.29401544843313, "episode": 95.0, "batch_reward": 0.2189895748645067, "critic_loss": 0.3151412592381239, "actor_loss": -52.173423233032224, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.242417812347412, "step": 95000}
{"episode_reward": 151.57352480299372, "episode": 96.0, "batch_reward": 0.21923159456253052, "critic_loss": 0.31289577507972716, "actor_loss": -50.70379881286621, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.74860453605652, "step": 96000}
{"episode_reward": 500.3100830369162, "episode": 97.0, "batch_reward": 0.22166228704154492, "critic_loss": 0.30521287651360035, "actor_loss": -50.19045552062988, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.25468349456787, "step": 97000}
{"episode_reward": 425.78341863945946, "episode": 98.0, "batch_reward": 0.2231736067980528, "critic_loss": 0.32022890125215053, "actor_loss": -48.659800437927245, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.58642315864563, "step": 98000}
{"episode_reward": 493.40831718204697, "episode": 99.0, "batch_reward": 0.22733174960315228, "critic_loss": 0.30806969994306566, "actor_loss": -48.32753914642334, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.50964665412903, "step": 99000}
{"episode_reward": 511.08053271427343, "episode": 100.0, "batch_reward": 0.22905050481855868, "critic_loss": 0.3096162377744913, "actor_loss": -47.29459952545166, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.992215156555176, "step": 100000}
{"episode_reward": 476.8101902792975, "episode": 101.0, "batch_reward": 0.2320718043744564, "critic_loss": 0.29564371797442435, "actor_loss": -47.145426750183105, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.30165147781372, "step": 101000}
{"episode_reward": 519.2413263670147, "episode": 102.0, "batch_reward": 0.23361754408478738, "critic_loss": 0.3029131841659546, "actor_loss": -46.28810303497315, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.25960922241211, "step": 102000}
{"episode_reward": 502.9315905473707, "episode": 103.0, "batch_reward": 0.2369683019667864, "critic_loss": 0.29157336039096116, "actor_loss": -45.63294411468506, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.37787413597107, "step": 103000}
{"episode_reward": 515.2896883904206, "episode": 104.0, "batch_reward": 0.24048542176187038, "critic_loss": 0.2725660942196846, "actor_loss": -45.30573847198486, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.48059105873108, "step": 104000}
{"episode_reward": 485.0152032334594, "episode": 105.0, "batch_reward": 0.24234935383498668, "critic_loss": 0.2943620923310518, "actor_loss": -44.678523849487306, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.26396632194519, "step": 105000}
{"episode_reward": 487.92207410131863, "episode": 106.0, "batch_reward": 0.24508557488024235, "critic_loss": 0.2820301232635975, "actor_loss": -44.23088218688965, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.237992763519287, "step": 106000}
{"episode_reward": 493.40709805401855, "episode": 107.0, "batch_reward": 0.24730217115581035, "critic_loss": 0.26947294979542497, "actor_loss": -43.68831357574463, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.86293363571167, "step": 107000}
{"episode_reward": 483.7924293259009, "episode": 108.0, "batch_reward": 0.24863643227517604, "critic_loss": 0.27262764459848404, "actor_loss": -43.348027755737306, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.09956169128418, "step": 108000}
{"episode_reward": 496.1040396945019, "episode": 109.0, "batch_reward": 0.2524106817394495, "critic_loss": 0.29060671366751195, "actor_loss": -43.24716262054444, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.763976573944092, "step": 109000}
{"episode_reward": 494.8976941552428, "episode": 110.0, "batch_reward": 0.25406461749970916, "critic_loss": 0.2622539599686861, "actor_loss": -42.69332987976074, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.040696620941162, "step": 110000}
{"episode_reward": 512.0515811929482, "episode": 111.0, "batch_reward": 0.25601745569705964, "critic_loss": 0.2619200812727213, "actor_loss": -42.519653984069826, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.743194818496704, "step": 111000}
{"episode_reward": 495.66870259071743, "episode": 112.0, "batch_reward": 0.25835196439921854, "critic_loss": 0.2492839589715004, "actor_loss": -42.14575566101074, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.56147313117981, "step": 112000}
{"episode_reward": 499.8110348223304, "episode": 113.0, "batch_reward": 0.25996937860548497, "critic_loss": 0.25728609014302495, "actor_loss": -41.798220275878904, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.18944525718689, "step": 113000}
{"episode_reward": 506.6232686222107, "episode": 114.0, "batch_reward": 0.26330851252377035, "critic_loss": 0.2463483557999134, "actor_loss": -41.688021926879884, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.305731058120728, "step": 114000}
{"episode_reward": 481.46872405803026, "episode": 115.0, "batch_reward": 0.26466991046071053, "critic_loss": 0.26309811411798, "actor_loss": -41.44962728881836, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.23404335975647, "step": 115000}
{"episode_reward": 500.18858006106433, "episode": 116.0, "batch_reward": 0.26766630589962004, "critic_loss": 0.24987404059618712, "actor_loss": -41.22995337677002, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.533412218093872, "step": 116000}
{"episode_reward": 495.79903438024536, "episode": 117.0, "batch_reward": 0.2690855090469122, "critic_loss": 0.2423815131187439, "actor_loss": -41.076255859375, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.111188888549805, "step": 117000}
{"episode_reward": 491.44162474186646, "episode": 118.0, "batch_reward": 0.2707256516814232, "critic_loss": 0.24391246289014817, "actor_loss": -40.749180519104, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.46109628677368, "step": 118000}
{"episode_reward": 513.2580624519383, "episode": 119.0, "batch_reward": 0.2730981736034155, "critic_loss": 0.23997585725039244, "actor_loss": -40.70573860168457, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.162399291992188, "step": 119000}
{"episode_reward": 519.5946260283238, "episode": 120.0, "batch_reward": 0.27502744741737845, "critic_loss": 0.2373291897624731, "actor_loss": -40.55509224700928, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.479976177215576, "step": 120000}
{"episode_reward": 487.8972330430803, "episode": 121.0, "batch_reward": 0.2764704958796501, "critic_loss": 0.24557525005191563, "actor_loss": -40.262489753723145, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.33647966384888, "step": 121000}
{"episode_reward": 478.81542617320883, "episode": 122.0, "batch_reward": 0.2780424961894751, "critic_loss": 0.24192044675350188, "actor_loss": -40.18759559631348, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.275850772857666, "step": 122000}
{"episode_reward": 493.91932439262945, "episode": 123.0, "batch_reward": 0.28015127719938754, "critic_loss": 0.249586810618639, "actor_loss": -40.2554722442627, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.28139090538025, "step": 123000}
{"episode_reward": 483.41650932025874, "episode": 124.0, "batch_reward": 0.2816102175563574, "critic_loss": 0.24269388473778963, "actor_loss": -40.10840477752686, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.263781547546387, "step": 124000}
{"episode_reward": 521.6310562782587, "episode": 125.0, "batch_reward": 0.2837462684363127, "critic_loss": 0.24433128583431243, "actor_loss": -39.920210639953616, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.368662357330322, "step": 125000}
{"episode_reward": 496.15881128503025, "episode": 126.0, "batch_reward": 0.28466728834807875, "critic_loss": 0.24785886408388616, "actor_loss": -39.70876863861084, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.27876925468445, "step": 126000}
{"episode_reward": 388.44536637240026, "episode": 127.0, "batch_reward": 0.285480600848794, "critic_loss": 0.26547115951031447, "actor_loss": -39.771242385864255, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.391286611557007, "step": 127000}
{"episode_reward": 504.54048575676137, "episode": 128.0, "batch_reward": 0.28806068629026416, "critic_loss": 0.2582701682150364, "actor_loss": -40.03469788360596, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.449503183364868, "step": 128000}
{"episode_reward": 526.1462128845365, "episode": 129.0, "batch_reward": 0.28905006529390814, "critic_loss": 0.255693594455719, "actor_loss": -40.180467208862304, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.317310333251953, "step": 129000}
{"episode_reward": 522.0991049217147, "episode": 130.0, "batch_reward": 0.29160144355893136, "critic_loss": 0.2296421225145459, "actor_loss": -40.322744720458985, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.225182056427002, "step": 130000}
{"episode_reward": 521.4759171628898, "episode": 131.0, "batch_reward": 0.2936207328438759, "critic_loss": 0.2201804767549038, "actor_loss": -40.179687881469725, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.390254497528076, "step": 131000}
{"episode_reward": 533.3441170237517, "episode": 132.0, "batch_reward": 0.29595947486162183, "critic_loss": 0.2227931832894683, "actor_loss": -40.312466705322265, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.27896809577942, "step": 132000}
{"episode_reward": 514.4388382008898, "episode": 133.0, "batch_reward": 0.29680816154181955, "critic_loss": 0.23613289792090655, "actor_loss": -40.21195876312256, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.44087290763855, "step": 133000}
{"episode_reward": 520.0449705192002, "episode": 134.0, "batch_reward": 0.2974009440839291, "critic_loss": 0.21786034897714854, "actor_loss": -40.021822952270504, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.639524459838867, "step": 134000}
{"episode_reward": 516.3625736874728, "episode": 135.0, "batch_reward": 0.2995688989162445, "critic_loss": 0.21412467712908984, "actor_loss": -39.88405504608154, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.728729009628296, "step": 135000}
{"episode_reward": 500.28012555693846, "episode": 136.0, "batch_reward": 0.30109166353940964, "critic_loss": 0.21241170954704286, "actor_loss": -39.71139284515381, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.034268856048584, "step": 136000}
{"episode_reward": 528.5878214565713, "episode": 137.0, "batch_reward": 0.3026940993964672, "critic_loss": 0.1924771594107151, "actor_loss": -39.93131127166748, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.198479175567627, "step": 137000}
{"episode_reward": 511.6435746189531, "episode": 138.0, "batch_reward": 0.30457867431640623, "critic_loss": 0.21034036418050528, "actor_loss": -40.19561132049561, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.65330195426941, "step": 138000}
{"episode_reward": 366.39276770563583, "episode": 139.0, "batch_reward": 0.3054613638520241, "critic_loss": 0.2222893449664116, "actor_loss": -40.050391410827636, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.461755514144897, "step": 139000}
{"episode_reward": 494.70325868872334, "episode": 140.0, "batch_reward": 0.3058166301995516, "critic_loss": 0.2255648100078106, "actor_loss": -39.88530838012695, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.194349765777588, "step": 140000}
{"episode_reward": 518.803487912768, "episode": 141.0, "batch_reward": 0.30693807601928713, "critic_loss": 0.22525879622995854, "actor_loss": -40.04678857421875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.40910768508911, "step": 141000}
{"episode_reward": 495.3511387521702, "episode": 142.0, "batch_reward": 0.30872155544161795, "critic_loss": 0.23046456157416106, "actor_loss": -39.70949784088135, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.399863481521606, "step": 142000}
{"episode_reward": 514.6689074261124, "episode": 143.0, "batch_reward": 0.3096380478143692, "critic_loss": 0.21221187985688447, "actor_loss": -39.740298835754395, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.5384624004364, "step": 143000}
{"episode_reward": 508.3245476401309, "episode": 144.0, "batch_reward": 0.3125566902756691, "critic_loss": 0.22285756799578665, "actor_loss": -39.70673352813721, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.176692724227905, "step": 144000}
{"episode_reward": 514.0613274133325, "episode": 145.0, "batch_reward": 0.31305113530158996, "critic_loss": 0.23141668401658536, "actor_loss": -39.838167335510256, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.24620819091797, "step": 145000}
{"episode_reward": 521.7549593100381, "episode": 146.0, "batch_reward": 0.31447458708286286, "critic_loss": 0.24304399928450585, "actor_loss": -39.86488597869873, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.833384037017822, "step": 146000}
{"episode_reward": 497.8858563879355, "episode": 147.0, "batch_reward": 0.31570521849393846, "critic_loss": 0.22112122436612844, "actor_loss": -39.535645095825195, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.390575408935547, "step": 147000}
{"episode_reward": 531.7386014013431, "episode": 148.0, "batch_reward": 0.3180811762809753, "critic_loss": 0.23438467438519, "actor_loss": -39.90527616882324, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.066884517669678, "step": 148000}
{"episode_reward": 521.1307426349598, "episode": 149.0, "batch_reward": 0.3193045555055141, "critic_loss": 0.21495552817732097, "actor_loss": -40.01836949157715, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.34096932411194, "step": 149000}
{"episode_reward": 526.6649972939794, "episode": 150.0, "batch_reward": 0.3207731022834778, "critic_loss": 0.23090214124321937, "actor_loss": -39.79509039306641, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
