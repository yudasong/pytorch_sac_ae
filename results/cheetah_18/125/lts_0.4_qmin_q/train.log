{"episode_reward": 0.0, "episode": 1.0, "duration": 17.25652050971985, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.4927098751068115, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.2190077690983383, "critic_loss": 0.17859390563703886, "actor_loss": -44.356403782826604, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 62.70260524749756, "step": 3000}
{"episode_reward": 38.99626838091528, "episode": 4.0, "batch_reward": 0.1508065238147974, "critic_loss": 0.11400471350550652, "actor_loss": -39.75028858947754, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.55276656150818, "step": 4000}
{"episode_reward": 41.75716277243377, "episode": 5.0, "batch_reward": 0.13061884489655495, "critic_loss": 0.1637927355580032, "actor_loss": -37.62361842346191, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.381883144378662, "step": 5000}
{"episode_reward": 125.63543887472214, "episode": 6.0, "batch_reward": 0.13935888642072677, "critic_loss": 0.28188873932510616, "actor_loss": -36.263607826232914, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.993841409683228, "step": 6000}
{"episode_reward": 148.26274489174747, "episode": 7.0, "batch_reward": 0.1483877886980772, "critic_loss": 0.2641389250084758, "actor_loss": -35.63191403579712, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.959373474121094, "step": 7000}
{"episode_reward": 261.8822534908209, "episode": 8.0, "batch_reward": 0.14820552410185336, "critic_loss": 0.4243166472315788, "actor_loss": -37.77168284606934, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.442257165908813, "step": 8000}
{"episode_reward": 110.99724235737106, "episode": 9.0, "batch_reward": 0.1403078914359212, "critic_loss": 0.8015425336956978, "actor_loss": -39.64342185974121, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.865054845809937, "step": 9000}
{"episode_reward": 8.53235255738266, "episode": 10.0, "batch_reward": 0.12740242528915405, "critic_loss": 0.6921535255014897, "actor_loss": -40.974562377929686, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.96173071861267, "step": 10000}
{"episode_reward": 10.355946655844692, "episode": 11.0, "batch_reward": 0.11479287584871053, "critic_loss": 0.6537100576758385, "actor_loss": -43.193129211425784, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.28603982925415, "step": 11000}
{"episode_reward": 6.694778581964999, "episode": 12.0, "batch_reward": 0.10588108519464731, "critic_loss": 0.6628277263045311, "actor_loss": -45.49976198577881, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.575215578079224, "step": 12000}
{"episode_reward": 8.169207404341414, "episode": 13.0, "batch_reward": 0.09798982946947217, "critic_loss": 0.5984310458600521, "actor_loss": -46.692615238189696, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.12784171104431, "step": 13000}
{"episode_reward": 8.888424785748118, "episode": 14.0, "batch_reward": 0.09140652444586157, "critic_loss": 0.5474834388494492, "actor_loss": -48.543208892822264, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.454538822174072, "step": 14000}
{"episode_reward": 7.506442175929715, "episode": 15.0, "batch_reward": 0.08576012791320682, "critic_loss": 0.4100791447907686, "actor_loss": -47.11692491149903, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.266350984573364, "step": 15000}
{"episode_reward": 9.111437144035964, "episode": 16.0, "batch_reward": 0.08080868339166045, "critic_loss": 0.348747088059783, "actor_loss": -46.50884264755249, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89207696914673, "step": 16000}
{"episode_reward": 9.248308874956132, "episode": 17.0, "batch_reward": 0.07719844325259329, "critic_loss": 0.3224597321152687, "actor_loss": -46.5780327835083, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.45251965522766, "step": 17000}
{"episode_reward": 27.067667669850593, "episode": 18.0, "batch_reward": 0.0755257237739861, "critic_loss": 0.40145207636058333, "actor_loss": -45.66173078155518, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.261194705963135, "step": 18000}
{"episode_reward": 81.12991535562828, "episode": 19.0, "batch_reward": 0.07676309389993548, "critic_loss": 0.44225088542699814, "actor_loss": -44.58630967330932, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.961663484573364, "step": 19000}
{"episode_reward": 113.10390657385528, "episode": 20.0, "batch_reward": 0.0783780356310308, "critic_loss": 0.4300259090512991, "actor_loss": -43.597820461273194, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.96630048751831, "step": 20000}
{"episode_reward": 105.69404643849752, "episode": 21.0, "batch_reward": 0.0802587671764195, "critic_loss": 0.46426180510222914, "actor_loss": -42.59786753845215, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.028554916381836, "step": 21000}
{"episode_reward": 122.35361989339934, "episode": 22.0, "batch_reward": 0.08104448863491416, "critic_loss": 0.7321949699819088, "actor_loss": -42.08165892791748, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.349899291992188, "step": 22000}
{"episode_reward": 47.28753125770961, "episode": 23.0, "batch_reward": 0.07857887858897447, "critic_loss": 0.9085316422581673, "actor_loss": -42.53800241470337, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.952539920806885, "step": 23000}
{"episode_reward": 36.848414256569605, "episode": 24.0, "batch_reward": 0.07781207406520843, "critic_loss": 0.9578470270037651, "actor_loss": -42.52573155975342, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.969478845596313, "step": 24000}
{"episode_reward": 74.92273326302596, "episode": 25.0, "batch_reward": 0.07823745074495674, "critic_loss": 0.7888265903890133, "actor_loss": -43.67626385116577, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.734389305114746, "step": 25000}
{"episode_reward": 58.147947166040304, "episode": 26.0, "batch_reward": 0.0762893130891025, "critic_loss": 0.6090382879078389, "actor_loss": -42.926147594451905, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.911761045455933, "step": 26000}
{"episode_reward": 23.96776326109781, "episode": 27.0, "batch_reward": 0.07359971682354807, "critic_loss": 0.49776094694435596, "actor_loss": -42.53026819229126, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.39579939842224, "step": 27000}
{"episode_reward": 10.194395302240828, "episode": 28.0, "batch_reward": 0.07127984580397606, "critic_loss": 0.42288485883176324, "actor_loss": -42.19124988174438, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.265790939331055, "step": 28000}
{"episode_reward": 15.411935173574424, "episode": 29.0, "batch_reward": 0.07044752002507448, "critic_loss": 0.3500841231495142, "actor_loss": -40.92508851623535, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.148297786712646, "step": 29000}
{"episode_reward": 16.005245150330786, "episode": 30.0, "batch_reward": 0.06786600989103317, "critic_loss": 0.32447790800035, "actor_loss": -40.15974571228028, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.979494333267212, "step": 30000}
{"episode_reward": 18.270821706770334, "episode": 31.0, "batch_reward": 0.06682166187465191, "critic_loss": 0.3703504613637924, "actor_loss": -39.22108781433106, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.76942706108093, "step": 31000}
{"episode_reward": 51.933736957695274, "episode": 32.0, "batch_reward": 0.0672121805883944, "critic_loss": 0.5675215868800878, "actor_loss": -39.18998945617676, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.5739586353302, "step": 32000}
{"episode_reward": 77.60073327249526, "episode": 33.0, "batch_reward": 0.0666257900595665, "critic_loss": 0.5613548422157765, "actor_loss": -41.712273414611815, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.974749088287354, "step": 33000}
{"episode_reward": 25.275148199037975, "episode": 34.0, "batch_reward": 0.06646156531199812, "critic_loss": 0.45522300112247466, "actor_loss": -43.48901049041748, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.988809823989868, "step": 34000}
{"episode_reward": 93.73116236585955, "episode": 35.0, "batch_reward": 0.0654413855113089, "critic_loss": 0.366363451346755, "actor_loss": -41.72529815673828, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.978426456451416, "step": 35000}
{"episode_reward": 13.253697714969107, "episode": 36.0, "batch_reward": 0.0642399137057364, "critic_loss": 0.327232340529561, "actor_loss": -41.27242214202881, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.998795986175537, "step": 36000}
{"episode_reward": 19.637593171083832, "episode": 37.0, "batch_reward": 0.0630498553365469, "critic_loss": 0.29252704587578776, "actor_loss": -40.79898971939087, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.9926815032959, "step": 37000}
{"episode_reward": 14.537481205887598, "episode": 38.0, "batch_reward": 0.06167805057764053, "critic_loss": 0.2644810222387314, "actor_loss": -39.76583338165283, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.35557746887207, "step": 38000}
{"episode_reward": 12.350161084234104, "episode": 39.0, "batch_reward": 0.06004419382289052, "critic_loss": 0.24484054984897374, "actor_loss": -37.845005310058596, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.98315453529358, "step": 39000}
{"episode_reward": 12.311707565447742, "episode": 40.0, "batch_reward": 0.059226160380989316, "critic_loss": 0.2436579015776515, "actor_loss": -37.32193765640259, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93423628807068, "step": 40000}
{"episode_reward": 17.65233683319629, "episode": 41.0, "batch_reward": 0.060538441367447376, "critic_loss": 0.2914126711636782, "actor_loss": -36.29278493118286, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.954588890075684, "step": 41000}
{"episode_reward": 114.92900227749246, "episode": 42.0, "batch_reward": 0.05955106309428811, "critic_loss": 0.3377562261670828, "actor_loss": -36.60972090530395, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.805335521697998, "step": 42000}
{"episode_reward": 30.520459304055535, "episode": 43.0, "batch_reward": 0.06173717514798045, "critic_loss": 0.31679623521864414, "actor_loss": -37.133810920715334, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.954102754592896, "step": 43000}
{"episode_reward": 193.90364180128054, "episode": 44.0, "batch_reward": 0.06454914128035306, "critic_loss": 0.2999027116894722, "actor_loss": -36.96971329116821, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.051722764968872, "step": 44000}
{"episode_reward": 185.8577851904278, "episode": 45.0, "batch_reward": 0.06655859776213766, "critic_loss": 0.2779655800610781, "actor_loss": -35.54888477706909, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.900472402572632, "step": 45000}
{"episode_reward": 88.11306226750293, "episode": 46.0, "batch_reward": 0.0659103958569467, "critic_loss": 0.25000266228616236, "actor_loss": -35.10223746109009, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.9192156791687, "step": 46000}
{"episode_reward": 54.83569214382113, "episode": 47.0, "batch_reward": 0.06800405295938253, "critic_loss": 0.24685533276945354, "actor_loss": -34.54677310180664, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.95782446861267, "step": 47000}
{"episode_reward": 197.66502710071387, "episode": 48.0, "batch_reward": 0.06854470143839717, "critic_loss": 0.2450489738509059, "actor_loss": -33.85652869033814, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.2555193901062, "step": 48000}
{"episode_reward": 70.57403834005129, "episode": 49.0, "batch_reward": 0.06851590020209551, "critic_loss": 0.2600313423499465, "actor_loss": -32.61683054351807, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.150177001953125, "step": 49000}
{"episode_reward": 67.31957025123452, "episode": 50.0, "batch_reward": 0.0696226405724883, "critic_loss": 0.2767792881429195, "actor_loss": -31.877803367614746, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.44995355606079, "step": 50000}
{"episode_reward": 165.92354166797986, "episode": 51.0, "batch_reward": 0.07015733030438423, "critic_loss": 0.30051049126684665, "actor_loss": -31.283948333740234, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.01982617378235, "step": 51000}
{"episode_reward": 54.769790284858644, "episode": 52.0, "batch_reward": 0.07029971496760845, "critic_loss": 0.2855449605360627, "actor_loss": -30.296251949310303, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.92197871208191, "step": 52000}
{"episode_reward": 50.328252021481084, "episode": 53.0, "batch_reward": 0.07000933234393597, "critic_loss": 0.27838292832672595, "actor_loss": -29.81539656829834, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.11971378326416, "step": 53000}
{"episode_reward": 82.90148532715877, "episode": 54.0, "batch_reward": 0.06975699447840453, "critic_loss": 0.26854337091743946, "actor_loss": -29.653695346832276, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.250051975250244, "step": 54000}
{"episode_reward": 89.17892947610724, "episode": 55.0, "batch_reward": 0.07095284225419164, "critic_loss": 0.24718612549453975, "actor_loss": -29.683861011505126, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.982755661010742, "step": 55000}
{"episode_reward": 42.22776397411727, "episode": 56.0, "batch_reward": 0.0694894806817174, "critic_loss": 0.22496828021854162, "actor_loss": -29.021404472351072, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.371259689331055, "step": 56000}
{"episode_reward": 43.35490949954265, "episode": 57.0, "batch_reward": 0.06957137230783701, "critic_loss": 0.20675655683130026, "actor_loss": -28.49688274002075, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.37962508201599, "step": 57000}
{"episode_reward": 68.98063241971468, "episode": 58.0, "batch_reward": 0.06918251622840763, "critic_loss": 0.1847111049219966, "actor_loss": -28.376738090515136, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.392762899398804, "step": 58000}
{"episode_reward": 59.474686712485216, "episode": 59.0, "batch_reward": 0.07178136975690723, "critic_loss": 0.18348283322155476, "actor_loss": -27.82925527191162, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.058160543441772, "step": 59000}
{"episode_reward": 398.94778309605186, "episode": 60.0, "batch_reward": 0.07644720274582505, "critic_loss": 0.1825168405622244, "actor_loss": -27.813978580474853, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.476574897766113, "step": 60000}
{"episode_reward": 183.11513942069527, "episode": 61.0, "batch_reward": 0.07822863583266736, "critic_loss": 0.18283878197520972, "actor_loss": -27.56558319091797, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.41404581069946, "step": 61000}
{"episode_reward": 194.81289701032236, "episode": 62.0, "batch_reward": 0.07932657269388438, "critic_loss": 0.19584398293495178, "actor_loss": -27.194576595306398, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.90789771080017, "step": 62000}
{"episode_reward": 79.57427192459748, "episode": 63.0, "batch_reward": 0.07898259813338518, "critic_loss": 0.2021965834200382, "actor_loss": -26.63956177520752, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.21335768699646, "step": 63000}
{"episode_reward": 87.24265839322386, "episode": 64.0, "batch_reward": 0.07857593978568912, "critic_loss": 0.19700018066167832, "actor_loss": -26.125245613098144, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.07086753845215, "step": 64000}
{"episode_reward": 42.31687086991959, "episode": 65.0, "batch_reward": 0.07997244950011373, "critic_loss": 0.1996928419098258, "actor_loss": -25.795804103851317, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.17111325263977, "step": 65000}
{"episode_reward": 292.34665871949096, "episode": 66.0, "batch_reward": 0.08227601412311196, "critic_loss": 0.1937941430658102, "actor_loss": -25.678101085662842, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.772346019744873, "step": 66000}
{"episode_reward": 73.37282943581255, "episode": 67.0, "batch_reward": 0.08370662639662624, "critic_loss": 0.2019670839384198, "actor_loss": -25.15303298187256, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.89744544029236, "step": 67000}
{"episode_reward": 407.3045805114907, "episode": 68.0, "batch_reward": 0.08836879278346896, "critic_loss": 0.19634719195961953, "actor_loss": -25.144613315582276, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.955845832824707, "step": 68000}
{"episode_reward": 468.1315981259569, "episode": 69.0, "batch_reward": 0.09425655633211136, "critic_loss": 0.20251793958246708, "actor_loss": -25.22012706756592, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.88628578186035, "step": 69000}
{"episode_reward": 387.7307857915588, "episode": 70.0, "batch_reward": 0.0985688619427383, "critic_loss": 0.1918548387736082, "actor_loss": -25.158417491912843, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.2734272480011, "step": 70000}
{"episode_reward": 390.2780939434381, "episode": 71.0, "batch_reward": 0.10247324063628913, "critic_loss": 0.20381756914407015, "actor_loss": -25.111743255615234, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.4309618473053, "step": 71000}
{"episode_reward": 435.6750595804205, "episode": 72.0, "batch_reward": 0.10492154440283775, "critic_loss": 0.2125019619092345, "actor_loss": -24.941428649902345, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.377427339553833, "step": 72000}
{"episode_reward": 75.87540376677904, "episode": 73.0, "batch_reward": 0.10697187820822, "critic_loss": 0.20497976201027632, "actor_loss": -24.79794931793213, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.80383849143982, "step": 73000}
{"episode_reward": 458.12245421329675, "episode": 74.0, "batch_reward": 0.1111924384906888, "critic_loss": 0.22299918682128192, "actor_loss": -25.017609844207765, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.956939697265625, "step": 74000}
{"episode_reward": 457.99600370052633, "episode": 75.0, "batch_reward": 0.11729054849594832, "critic_loss": 0.21926540673524142, "actor_loss": -25.052872177124023, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.200769186019897, "step": 75000}
{"episode_reward": 473.28634347408877, "episode": 76.0, "batch_reward": 0.12068193623423576, "critic_loss": 0.22924949957430363, "actor_loss": -25.09143439102173, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.234327793121338, "step": 76000}
{"episode_reward": 490.1954893429692, "episode": 77.0, "batch_reward": 0.125635270960629, "critic_loss": 0.20829733119904995, "actor_loss": -25.340224739074706, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.226598739624023, "step": 77000}
{"episode_reward": 467.6703844847934, "episode": 78.0, "batch_reward": 0.13101885957270862, "critic_loss": 0.21878778154402972, "actor_loss": -25.563791160583495, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.321619272232056, "step": 78000}
{"episode_reward": 466.09736081773616, "episode": 79.0, "batch_reward": 0.13350198031961918, "critic_loss": 0.2213406031727791, "actor_loss": -25.33563221359253, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.3147714138031, "step": 79000}
{"episode_reward": 449.96537366539036, "episode": 80.0, "batch_reward": 0.13890326419472696, "critic_loss": 0.21831624243408443, "actor_loss": -25.643919551849365, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.265686511993408, "step": 80000}
{"episode_reward": 497.97457967957433, "episode": 81.0, "batch_reward": 0.1433441444784403, "critic_loss": 0.2119340518862009, "actor_loss": -25.860255584716796, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.22300982475281, "step": 81000}
{"episode_reward": 475.23494473034316, "episode": 82.0, "batch_reward": 0.14791694997251034, "critic_loss": 0.21593347331881524, "actor_loss": -26.098442440032958, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.155210494995117, "step": 82000}
{"episode_reward": 485.62648974335605, "episode": 83.0, "batch_reward": 0.15153962618112565, "critic_loss": 0.19520387426018715, "actor_loss": -26.169219135284425, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.936789512634277, "step": 83000}
{"episode_reward": 468.362501831231, "episode": 84.0, "batch_reward": 0.1548779578730464, "critic_loss": 0.19777806098014117, "actor_loss": -26.397833232879638, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.178801774978638, "step": 84000}
{"episode_reward": 462.15061083094724, "episode": 85.0, "batch_reward": 0.15911254597455263, "critic_loss": 0.20702524656802415, "actor_loss": -26.620231761932374, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.314563512802124, "step": 85000}
{"episode_reward": 453.7191608310749, "episode": 86.0, "batch_reward": 0.1617618041485548, "critic_loss": 0.20135301034152508, "actor_loss": -26.515643772125244, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.58593225479126, "step": 86000}
{"episode_reward": 461.8965417927595, "episode": 87.0, "batch_reward": 0.16449286325275897, "critic_loss": 0.19914002764225006, "actor_loss": -26.25273941421509, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.919811964035034, "step": 87000}
{"episode_reward": 269.67316662776267, "episode": 88.0, "batch_reward": 0.1664972095414996, "critic_loss": 0.18824104878306389, "actor_loss": -26.24293783569336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.33832025527954, "step": 88000}
{"episode_reward": 510.4956729800874, "episode": 89.0, "batch_reward": 0.17075941390544175, "critic_loss": 0.18782718577235938, "actor_loss": -26.738177532196044, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.39880681037903, "step": 89000}
{"episode_reward": 357.6160025565976, "episode": 90.0, "batch_reward": 0.172930624358356, "critic_loss": 0.18945481165498496, "actor_loss": -26.7902783203125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.60786724090576, "step": 90000}
{"episode_reward": 475.2703607792855, "episode": 91.0, "batch_reward": 0.17617888835072518, "critic_loss": 0.19087747459113596, "actor_loss": -26.783724979400635, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.272740840911865, "step": 91000}
{"episode_reward": 494.2614348459874, "episode": 92.0, "batch_reward": 0.17889964608848094, "critic_loss": 0.1955359802916646, "actor_loss": -27.187114944458006, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.144213438034058, "step": 92000}
{"episode_reward": 465.6994985870762, "episode": 93.0, "batch_reward": 0.18207000990957023, "critic_loss": 0.19546185660362245, "actor_loss": -27.055175548553468, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.9523286819458, "step": 93000}
{"episode_reward": 498.7441992148153, "episode": 94.0, "batch_reward": 0.18647600407898426, "critic_loss": 0.18842581483721732, "actor_loss": -27.478540435791015, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.448273181915283, "step": 94000}
{"episode_reward": 494.9216502891482, "episode": 95.0, "batch_reward": 0.18898353289067746, "critic_loss": 0.2016826194524765, "actor_loss": -27.890266304016112, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.26481795310974, "step": 95000}
{"episode_reward": 493.78591311829365, "episode": 96.0, "batch_reward": 0.192559696868062, "critic_loss": 0.1895843620374799, "actor_loss": -27.815123355865477, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.497578620910645, "step": 96000}
{"episode_reward": 461.0637427518967, "episode": 97.0, "batch_reward": 0.19454338811337948, "critic_loss": 0.1927390675097704, "actor_loss": -28.262157447814943, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.98432445526123, "step": 97000}
{"episode_reward": 499.3872437398946, "episode": 98.0, "batch_reward": 0.1974578829109669, "critic_loss": 0.1994497499614954, "actor_loss": -28.07994365310669, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.81843090057373, "step": 98000}
{"episode_reward": 422.2165312889747, "episode": 99.0, "batch_reward": 0.20169074404239654, "critic_loss": 0.19378658068180085, "actor_loss": -28.45231576156616, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.35215449333191, "step": 99000}
{"episode_reward": 484.69608562253154, "episode": 100.0, "batch_reward": 0.20400453394651413, "critic_loss": 0.20755426727235318, "actor_loss": -28.3001047744751, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.430800199508667, "step": 100000}
{"episode_reward": 497.4901680129949, "episode": 101.0, "batch_reward": 0.20563893403112887, "critic_loss": 0.2061304914355278, "actor_loss": -28.862268981933592, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.22850203514099, "step": 101000}
{"episode_reward": 492.91087173670735, "episode": 102.0, "batch_reward": 0.20849686083197594, "critic_loss": 0.21694986473023892, "actor_loss": -29.01112812423706, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.392149448394775, "step": 102000}
{"episode_reward": 525.4196577633589, "episode": 103.0, "batch_reward": 0.21170873272418975, "critic_loss": 0.2152835224494338, "actor_loss": -29.190659858703615, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.226573944091797, "step": 103000}
{"episode_reward": 513.5164093901217, "episode": 104.0, "batch_reward": 0.21546506321430206, "critic_loss": 0.19411996195465325, "actor_loss": -29.34681748199463, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.090169429779053, "step": 104000}
{"episode_reward": 448.3253411056658, "episode": 105.0, "batch_reward": 0.21793872864544392, "critic_loss": 0.1951679534614086, "actor_loss": -29.070175376892088, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.441087245941162, "step": 105000}
{"episode_reward": 503.3072920633434, "episode": 106.0, "batch_reward": 0.22018324790894986, "critic_loss": 0.1939069500491023, "actor_loss": -29.160586574554443, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.272024631500244, "step": 106000}
{"episode_reward": 509.4409717570375, "episode": 107.0, "batch_reward": 0.22241155876219273, "critic_loss": 0.20222657325863838, "actor_loss": -29.86551880645752, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.954365730285645, "step": 107000}
{"episode_reward": 485.1336007327926, "episode": 108.0, "batch_reward": 0.2243862314224243, "critic_loss": 0.1919636834785342, "actor_loss": -30.1558565826416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.87110447883606, "step": 108000}
{"episode_reward": 507.6092838540632, "episode": 109.0, "batch_reward": 0.22858794949948788, "critic_loss": 0.19574422162026167, "actor_loss": -30.312942535400392, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.02946901321411, "step": 109000}
{"episode_reward": 483.89543622630816, "episode": 110.0, "batch_reward": 0.23107633724808693, "critic_loss": 0.1890386121571064, "actor_loss": -30.513594955444336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.96660852432251, "step": 110000}
{"episode_reward": 500.40960805632585, "episode": 111.0, "batch_reward": 0.23239496731758116, "critic_loss": 0.1920212630853057, "actor_loss": -30.596898323059083, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.63269901275635, "step": 111000}
{"episode_reward": 500.9383802303499, "episode": 112.0, "batch_reward": 0.23501659904420374, "critic_loss": 0.19917029360681773, "actor_loss": -30.75486859512329, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.969974517822266, "step": 112000}
{"episode_reward": 330.99132852104293, "episode": 113.0, "batch_reward": 0.23531898987293243, "critic_loss": 0.20128150799870492, "actor_loss": -30.6841509475708, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.116272687911987, "step": 113000}
{"episode_reward": 460.4893753607521, "episode": 114.0, "batch_reward": 0.23796474251151084, "critic_loss": 0.1912463445290923, "actor_loss": -31.378648014068602, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.343339681625366, "step": 114000}
{"episode_reward": 497.55269724035355, "episode": 115.0, "batch_reward": 0.2404545458704233, "critic_loss": 0.1998640729188919, "actor_loss": -31.14264762496948, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.77838635444641, "step": 115000}
{"episode_reward": 498.1682512538287, "episode": 116.0, "batch_reward": 0.24326745922863482, "critic_loss": 0.1881470043361187, "actor_loss": -31.656718647003174, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.951329708099365, "step": 116000}
{"episode_reward": 517.5699952823458, "episode": 117.0, "batch_reward": 0.24588501904904841, "critic_loss": 0.20027414555847645, "actor_loss": -31.63301361846924, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.059980154037476, "step": 117000}
{"episode_reward": 502.15543582011145, "episode": 118.0, "batch_reward": 0.24720258168876172, "critic_loss": 0.19935601776093245, "actor_loss": -32.11702188873291, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.35200262069702, "step": 118000}
{"episode_reward": 511.19452605228275, "episode": 119.0, "batch_reward": 0.24926179732382298, "critic_loss": 0.19028192325681448, "actor_loss": -31.87310846710205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.97431254386902, "step": 119000}
{"episode_reward": 492.8024844161138, "episode": 120.0, "batch_reward": 0.2514400060325861, "critic_loss": 0.20305386802554132, "actor_loss": -31.76773387145996, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.554617881774902, "step": 120000}
{"episode_reward": 519.4709417903458, "episode": 121.0, "batch_reward": 0.2543564298152924, "critic_loss": 0.19489694537967445, "actor_loss": -32.08396773147583, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.74610424041748, "step": 121000}
{"episode_reward": 485.20286958160904, "episode": 122.0, "batch_reward": 0.25589334377646444, "critic_loss": 0.19309411177784205, "actor_loss": -32.337377403259275, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.945202827453613, "step": 122000}
{"episode_reward": 516.9396963017674, "episode": 123.0, "batch_reward": 0.2572273821383715, "critic_loss": 0.20694238375872373, "actor_loss": -32.21293745803833, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.488337993621826, "step": 123000}
{"episode_reward": 125.80649334883785, "episode": 124.0, "batch_reward": 0.25656549313664434, "critic_loss": 0.21082801262289286, "actor_loss": -32.576356285095216, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.309174299240112, "step": 124000}
{"episode_reward": 516.3958716491173, "episode": 125.0, "batch_reward": 0.2586026848554611, "critic_loss": 0.20581025536358358, "actor_loss": -32.34174510192871, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.527453899383545, "step": 125000}
{"episode_reward": 524.4567808105407, "episode": 126.0, "batch_reward": 0.2605907251685858, "critic_loss": 0.19889995569735766, "actor_loss": -32.87403168869019, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.96522045135498, "step": 126000}
{"episode_reward": 519.9686332843219, "episode": 127.0, "batch_reward": 0.26236295886337757, "critic_loss": 0.21127425254136323, "actor_loss": -32.98039743423462, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.92702627182007, "step": 127000}
{"episode_reward": 510.2264050683314, "episode": 128.0, "batch_reward": 0.26457112312316894, "critic_loss": 0.18825218584388495, "actor_loss": -33.23820775604248, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.037837028503418, "step": 128000}
{"episode_reward": 510.09083310670087, "episode": 129.0, "batch_reward": 0.2662499081194401, "critic_loss": 0.1970225915685296, "actor_loss": -33.42087579345703, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.980639934539795, "step": 129000}
{"episode_reward": 480.5747173981329, "episode": 130.0, "batch_reward": 0.2681884940266609, "critic_loss": 0.20560487049818038, "actor_loss": -33.19935176086426, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.221251487731934, "step": 130000}
{"episode_reward": 509.6109395070901, "episode": 131.0, "batch_reward": 0.27109911024570466, "critic_loss": 0.19190165559947492, "actor_loss": -33.45263224029541, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.798935651779175, "step": 131000}
{"episode_reward": 513.3596869405, "episode": 132.0, "batch_reward": 0.2725235372632742, "critic_loss": 0.20044587612152098, "actor_loss": -33.4778938369751, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.964577674865723, "step": 132000}
{"episode_reward": 498.80072396567925, "episode": 133.0, "batch_reward": 0.2733052602112293, "critic_loss": 0.20053673942387104, "actor_loss": -33.92060249710083, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.24419927597046, "step": 133000}
{"episode_reward": 517.8507323973005, "episode": 134.0, "batch_reward": 0.27510191513597965, "critic_loss": 0.192210344620049, "actor_loss": -34.215473178863526, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.383519649505615, "step": 134000}
{"episode_reward": 480.8425190809194, "episode": 135.0, "batch_reward": 0.27685688620805743, "critic_loss": 0.2020668910369277, "actor_loss": -33.749801662445066, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.740118503570557, "step": 135000}
{"episode_reward": 527.9744059527958, "episode": 136.0, "batch_reward": 0.2777017345279455, "critic_loss": 0.19059388004243374, "actor_loss": -33.799267169952394, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.980932235717773, "step": 136000}
{"episode_reward": 103.69473953973268, "episode": 137.0, "batch_reward": 0.2776499927043915, "critic_loss": 0.21417473734915257, "actor_loss": -33.58366757965088, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.80770754814148, "step": 137000}
{"episode_reward": 534.1255228516897, "episode": 138.0, "batch_reward": 0.2800460390150547, "critic_loss": 0.20762160717695952, "actor_loss": -33.747662425994875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.146913290023804, "step": 138000}
{"episode_reward": 517.3631523351723, "episode": 139.0, "batch_reward": 0.2816045050024986, "critic_loss": 0.21188531415164472, "actor_loss": -33.99992083740234, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.974064826965332, "step": 139000}
{"episode_reward": 507.91738808107533, "episode": 140.0, "batch_reward": 0.28219282335042956, "critic_loss": 0.22188344276696442, "actor_loss": -33.976023021698, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.675484895706177, "step": 140000}
{"episode_reward": 526.4801629469263, "episode": 141.0, "batch_reward": 0.28415378522872925, "critic_loss": 0.21280404140055179, "actor_loss": -34.064868408203125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.397852420806885, "step": 141000}
{"episode_reward": 536.6753762092868, "episode": 142.0, "batch_reward": 0.2864866152256727, "critic_loss": 0.21486526887863874, "actor_loss": -34.326687114715575, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.984607934951782, "step": 142000}
{"episode_reward": 525.9193826178409, "episode": 143.0, "batch_reward": 0.2880102113634348, "critic_loss": 0.22007223697006703, "actor_loss": -34.321692848205565, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.83423662185669, "step": 143000}
{"episode_reward": 515.9800740417322, "episode": 144.0, "batch_reward": 0.29031010065972807, "critic_loss": 0.20752615452557802, "actor_loss": -34.67366312789917, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.243372678756714, "step": 144000}
{"episode_reward": 498.5607696123808, "episode": 145.0, "batch_reward": 0.29087141540646555, "critic_loss": 0.2210697713494301, "actor_loss": -34.59755376434326, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.014078378677368, "step": 145000}
{"episode_reward": 523.6831853005226, "episode": 146.0, "batch_reward": 0.29239968794584276, "critic_loss": 0.20522281028330325, "actor_loss": -35.40509810638428, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.164912223815918, "step": 146000}
{"episode_reward": 500.4075794353743, "episode": 147.0, "batch_reward": 0.29400282302498815, "critic_loss": 0.20895353300869465, "actor_loss": -35.08821754074096, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.321982860565186, "step": 147000}
{"episode_reward": 523.9978431414459, "episode": 148.0, "batch_reward": 0.29594898456335067, "critic_loss": 0.2184661343097687, "actor_loss": -35.22855345916748, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.84022331237793, "step": 148000}
{"episode_reward": 516.820534217781, "episode": 149.0, "batch_reward": 0.2976815436184406, "critic_loss": 0.2104834007024765, "actor_loss": -35.4483692817688, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.918866872787476, "step": 149000}
{"episode_reward": 514.9257035413202, "episode": 150.0, "batch_reward": 0.30026133738458155, "critic_loss": 0.21355401642620564, "actor_loss": -35.68426504135132, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
