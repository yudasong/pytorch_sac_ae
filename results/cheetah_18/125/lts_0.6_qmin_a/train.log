{"episode_reward": 0.0, "episode": 1.0, "duration": 17.811355590820312, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.5316588878631592, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.22260384991511617, "critic_loss": 0.04901261346227737, "actor_loss": -28.58490569053358, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 61.92099070549011, "step": 3000}
{"episode_reward": 106.2771920766239, "episode": 4.0, "batch_reward": 0.1779114522859454, "critic_loss": 0.0689365010652691, "actor_loss": -26.89538845229149, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.88558578491211, "step": 4000}
{"episode_reward": 102.22322493457236, "episode": 5.0, "batch_reward": 0.15322564999759197, "critic_loss": 0.05386526961438358, "actor_loss": -22.49068093919754, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.355371475219727, "step": 5000}
{"episode_reward": 35.69224913136253, "episode": 6.0, "batch_reward": 0.14030000849813223, "critic_loss": 0.06921207609772682, "actor_loss": -22.385346449017526, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.53640604019165, "step": 6000}
{"episode_reward": 96.12022137052185, "episode": 7.0, "batch_reward": 0.1308862144947052, "critic_loss": 0.0773438476845622, "actor_loss": -23.642589292526246, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.07959747314453, "step": 7000}
{"episode_reward": 134.47965752543152, "episode": 8.0, "batch_reward": 0.1410463231652975, "critic_loss": 0.12450103875249624, "actor_loss": -23.555697044610977, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.38586926460266, "step": 8000}
{"episode_reward": 202.37032036223184, "episode": 9.0, "batch_reward": 0.14752410673350097, "critic_loss": 0.16566390664875508, "actor_loss": -23.247272974967956, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.445533752441406, "step": 9000}
{"episode_reward": 201.27163230935648, "episode": 10.0, "batch_reward": 0.1521333207935095, "critic_loss": 0.22010764937847851, "actor_loss": -24.13442028713226, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.087158203125, "step": 10000}
{"episode_reward": 159.3072789808292, "episode": 11.0, "batch_reward": 0.14790602480620146, "critic_loss": 0.2184322667568922, "actor_loss": -24.026581755638123, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.40328121185303, "step": 11000}
{"episode_reward": 61.060063422678596, "episode": 12.0, "batch_reward": 0.13856642393767835, "critic_loss": 0.21369043854624034, "actor_loss": -21.768600859165193, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.14236330986023, "step": 12000}
{"episode_reward": 40.84558406608709, "episode": 13.0, "batch_reward": 0.12942664489150046, "critic_loss": 0.21045976398140193, "actor_loss": -21.176087867736815, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.298192024230957, "step": 13000}
{"episode_reward": 22.1968144615999, "episode": 14.0, "batch_reward": 0.12134779812395573, "critic_loss": 0.23267759366333485, "actor_loss": -19.22690178489685, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.92444896697998, "step": 14000}
{"episode_reward": 24.70273039279898, "episode": 15.0, "batch_reward": 0.1191567397788167, "critic_loss": 0.23745576320588588, "actor_loss": -21.144107469558715, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.54897665977478, "step": 15000}
{"episode_reward": 104.81541068130049, "episode": 16.0, "batch_reward": 0.11640481965988875, "critic_loss": 0.25550975458323955, "actor_loss": -20.53434924650192, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.828264474868774, "step": 16000}
{"episode_reward": 67.68316584545619, "episode": 17.0, "batch_reward": 0.11597376648336649, "critic_loss": 0.24008331218361856, "actor_loss": -19.502757199287416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.161353826522827, "step": 17000}
{"episode_reward": 132.8141903799907, "episode": 18.0, "batch_reward": 0.11316785915941, "critic_loss": 0.24277979128062724, "actor_loss": -19.030547396659852, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.37168288230896, "step": 18000}
{"episode_reward": 29.700636793487142, "episode": 19.0, "batch_reward": 0.1145567438825965, "critic_loss": 0.277085181362927, "actor_loss": -18.832296414375307, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.3162739276886, "step": 19000}
{"episode_reward": 257.0472471591199, "episode": 20.0, "batch_reward": 0.1158565435707569, "critic_loss": 0.31357751719653604, "actor_loss": -20.11755796813965, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.05865454673767, "step": 20000}
{"episode_reward": 43.32472357776265, "episode": 21.0, "batch_reward": 0.11550963534414768, "critic_loss": 0.3655926054418087, "actor_loss": -19.99056830215454, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.650572061538696, "step": 21000}
{"episode_reward": 94.64848682065771, "episode": 22.0, "batch_reward": 0.1145701457709074, "critic_loss": 0.2852294179722667, "actor_loss": -19.138294637680055, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.173972368240356, "step": 22000}
{"episode_reward": 96.59789468135035, "episode": 23.0, "batch_reward": 0.11330275171995163, "critic_loss": 0.3243523983955383, "actor_loss": -18.675204652786256, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.67534351348877, "step": 23000}
{"episode_reward": 86.05913937462898, "episode": 24.0, "batch_reward": 0.11469238396734, "critic_loss": 0.32023147348314523, "actor_loss": -19.488210523605346, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.804836988449097, "step": 24000}
{"episode_reward": 177.85670086547327, "episode": 25.0, "batch_reward": 0.1134705325216055, "critic_loss": 0.2881800887212157, "actor_loss": -18.800461866378786, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.057040452957153, "step": 25000}
{"episode_reward": 45.689947020325675, "episode": 26.0, "batch_reward": 0.11072554235905409, "critic_loss": 0.31823320758342744, "actor_loss": -18.40679508972168, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.09503483772278, "step": 26000}
{"episode_reward": 47.26958029974428, "episode": 27.0, "batch_reward": 0.11132763265073299, "critic_loss": 0.3153146483451128, "actor_loss": -18.817549593925477, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.344890117645264, "step": 27000}
{"episode_reward": 238.945241449583, "episode": 28.0, "batch_reward": 0.11348541199415922, "critic_loss": 0.3146200523301959, "actor_loss": -18.32575718688965, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.01664113998413, "step": 28000}
{"episode_reward": 66.17907861986778, "episode": 29.0, "batch_reward": 0.11138386454433202, "critic_loss": 0.3126555378437042, "actor_loss": -18.438993741989137, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.815913915634155, "step": 29000}
{"episode_reward": 28.697156102397976, "episode": 30.0, "batch_reward": 0.1082105263993144, "critic_loss": 0.3362385817170143, "actor_loss": -17.754705260276793, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.431202173233032, "step": 30000}
{"episode_reward": 35.094594126491906, "episode": 31.0, "batch_reward": 0.1064584492482245, "critic_loss": 0.3604645989462733, "actor_loss": -17.827946019649506, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.63545298576355, "step": 31000}
{"episode_reward": 42.206257906001774, "episode": 32.0, "batch_reward": 0.10857114856690168, "critic_loss": 0.39658251978456976, "actor_loss": -18.295184201240538, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.469013690948486, "step": 32000}
{"episode_reward": 383.5396892540903, "episode": 33.0, "batch_reward": 0.11667557349056006, "critic_loss": 0.4169133429378271, "actor_loss": -19.171542282104493, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.121716499328613, "step": 33000}
{"episode_reward": 356.8098591603476, "episode": 34.0, "batch_reward": 0.12127480951696634, "critic_loss": 0.37885561703145504, "actor_loss": -18.621669701576234, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.82691788673401, "step": 34000}
{"episode_reward": 99.58420913941693, "episode": 35.0, "batch_reward": 0.12277659433335066, "critic_loss": 0.3900351933091879, "actor_loss": -19.650383924484252, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.99018406867981, "step": 35000}
{"episode_reward": 320.7515209942733, "episode": 36.0, "batch_reward": 0.12835518811643123, "critic_loss": 0.4179196104705334, "actor_loss": -19.288769481658935, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.905866861343384, "step": 36000}
{"episode_reward": 338.47458211151684, "episode": 37.0, "batch_reward": 0.13416987697035074, "critic_loss": 0.4539860625565052, "actor_loss": -20.225571800231933, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.030810117721558, "step": 37000}
{"episode_reward": 366.0524768310178, "episode": 38.0, "batch_reward": 0.13833997892588376, "critic_loss": 0.43241236566007135, "actor_loss": -20.8323940114975, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.274320602416992, "step": 38000}
{"episode_reward": 99.96210334729255, "episode": 39.0, "batch_reward": 0.13874739719927312, "critic_loss": 0.3826112218946218, "actor_loss": -21.425291934967042, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.95990777015686, "step": 39000}
{"episode_reward": 363.31015504579244, "episode": 40.0, "batch_reward": 0.14605758015066386, "critic_loss": 0.41153093679249286, "actor_loss": -21.942677558898925, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.817774295806885, "step": 40000}
{"episode_reward": 380.9612462449401, "episode": 41.0, "batch_reward": 0.15196352179348468, "critic_loss": 0.43197700423002244, "actor_loss": -22.619687267303465, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.33050060272217, "step": 41000}
{"episode_reward": 399.12843567084514, "episode": 42.0, "batch_reward": 0.15807931984215975, "critic_loss": 0.4305280079394579, "actor_loss": -22.817110195159913, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.451140880584717, "step": 42000}
{"episode_reward": 444.6772582491778, "episode": 43.0, "batch_reward": 0.1646225403994322, "critic_loss": 0.42756542772054673, "actor_loss": -23.69390296936035, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.176300287246704, "step": 43000}
{"episode_reward": 424.2049631310413, "episode": 44.0, "batch_reward": 0.17030207259953023, "critic_loss": 0.4055171532779932, "actor_loss": -23.70259720993042, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.82154154777527, "step": 44000}
{"episode_reward": 425.07837331517527, "episode": 45.0, "batch_reward": 0.1767490435242653, "critic_loss": 0.4034981745034456, "actor_loss": -25.181114538192748, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.477569818496704, "step": 45000}
{"episode_reward": 425.08807873039484, "episode": 46.0, "batch_reward": 0.18071297749876977, "critic_loss": 0.42305203542113307, "actor_loss": -25.095038639068605, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.579888343811035, "step": 46000}
{"episode_reward": 394.159948280671, "episode": 47.0, "batch_reward": 0.1867888811379671, "critic_loss": 0.42618789479136465, "actor_loss": -25.6082024936676, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.83936834335327, "step": 47000}
{"episode_reward": 451.4057531922792, "episode": 48.0, "batch_reward": 0.1902125050574541, "critic_loss": 0.4060087933242321, "actor_loss": -25.623271066665648, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.94054865837097, "step": 48000}
{"episode_reward": 132.2597980232949, "episode": 49.0, "batch_reward": 0.19163732002675532, "critic_loss": 0.408283597946167, "actor_loss": -26.265564556121827, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.964475393295288, "step": 49000}
{"episode_reward": 448.5527197905692, "episode": 50.0, "batch_reward": 0.1950392712056637, "critic_loss": 0.386512320548296, "actor_loss": -26.60973938369751, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.105144262313843, "step": 50000}
{"episode_reward": 392.11027163310274, "episode": 51.0, "batch_reward": 0.19933072866499424, "critic_loss": 0.4105347082018852, "actor_loss": -26.77952187156677, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.09063911437988, "step": 51000}
{"episode_reward": 362.88299923237344, "episode": 52.0, "batch_reward": 0.20274307903647423, "critic_loss": 0.4539285792708397, "actor_loss": -27.888257062911986, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91256856918335, "step": 52000}
{"episode_reward": 414.74162944240385, "episode": 53.0, "batch_reward": 0.20871787542104722, "critic_loss": 0.4237351654469967, "actor_loss": -27.93998153877258, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.359079360961914, "step": 53000}
{"episode_reward": 482.29215204828284, "episode": 54.0, "batch_reward": 0.21153167919814586, "critic_loss": 0.42494684052467346, "actor_loss": -28.455660066604615, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.441688537597656, "step": 54000}
{"episode_reward": 359.893466414837, "episode": 55.0, "batch_reward": 0.21573375289142133, "critic_loss": 0.41144576175510883, "actor_loss": -28.559592584609984, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.332589864730835, "step": 55000}
{"episode_reward": 453.4002972858528, "episode": 56.0, "batch_reward": 0.21925193013250827, "critic_loss": 0.428812819942832, "actor_loss": -29.36842460823059, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.69917607307434, "step": 56000}
{"episode_reward": 404.9135131094441, "episode": 57.0, "batch_reward": 0.2232387059032917, "critic_loss": 0.43422248829901217, "actor_loss": -29.529027864456175, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.582727670669556, "step": 57000}
{"episode_reward": 429.22378463855716, "episode": 58.0, "batch_reward": 0.2265848000794649, "critic_loss": 0.3971894375830889, "actor_loss": -29.381941917419432, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.83577275276184, "step": 58000}
{"episode_reward": 433.51365321389125, "episode": 59.0, "batch_reward": 0.22809474477171898, "critic_loss": 0.4152813172787428, "actor_loss": -29.576721410751343, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.373713493347168, "step": 59000}
{"episode_reward": 318.24896287695606, "episode": 60.0, "batch_reward": 0.22950538818538188, "critic_loss": 0.42021886789798735, "actor_loss": -30.21386460494995, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.18145513534546, "step": 60000}
{"episode_reward": 109.34969522622553, "episode": 61.0, "batch_reward": 0.23017948918044567, "critic_loss": 0.4070133599191904, "actor_loss": -30.049706897735597, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.877394914627075, "step": 61000}
{"episode_reward": 452.60853992406345, "episode": 62.0, "batch_reward": 0.23180013772845268, "critic_loss": 0.4508979500234127, "actor_loss": -30.0631921005249, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.19343662261963, "step": 62000}
{"episode_reward": 210.01107332529728, "episode": 63.0, "batch_reward": 0.23148911237716674, "critic_loss": 0.5168161168843508, "actor_loss": -29.95147689437866, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89324378967285, "step": 63000}
{"episode_reward": 461.3456077061585, "episode": 64.0, "batch_reward": 0.23647360345721244, "critic_loss": 0.434874768525362, "actor_loss": -30.477436889648438, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.274513721466064, "step": 64000}
{"episode_reward": 417.84035540349464, "episode": 65.0, "batch_reward": 0.23837202157080173, "critic_loss": 0.43278935055434703, "actor_loss": -30.59275801849365, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.319589376449585, "step": 65000}
{"episode_reward": 417.6172198869901, "episode": 66.0, "batch_reward": 0.24252507023513317, "critic_loss": 0.4206747837364674, "actor_loss": -31.19821431350708, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.357703924179077, "step": 66000}
{"episode_reward": 404.65756421656266, "episode": 67.0, "batch_reward": 0.24231813997030258, "critic_loss": 0.4484328033477068, "actor_loss": -31.718480754852294, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.61196732521057, "step": 67000}
{"episode_reward": 122.55207952092039, "episode": 68.0, "batch_reward": 0.2417350337356329, "critic_loss": 0.4182279701679945, "actor_loss": -30.84976668167114, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.250202894210815, "step": 68000}
{"episode_reward": 458.9161569995593, "episode": 69.0, "batch_reward": 0.2445353724360466, "critic_loss": 0.4473584541231394, "actor_loss": -31.479931171417235, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.506110429763794, "step": 69000}
{"episode_reward": 426.0932299100796, "episode": 70.0, "batch_reward": 0.24825278283655644, "critic_loss": 0.44712865620851516, "actor_loss": -31.99911485671997, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.320983171463013, "step": 70000}
{"episode_reward": 446.42678803167826, "episode": 71.0, "batch_reward": 0.25105459347367287, "critic_loss": 0.4313573352098465, "actor_loss": -31.745327293395995, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.873767614364624, "step": 71000}
{"episode_reward": 411.0471374425685, "episode": 72.0, "batch_reward": 0.25318827091157436, "critic_loss": 0.4145164766162634, "actor_loss": -32.07123587799072, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.618793487548828, "step": 72000}
{"episode_reward": 452.4011329674806, "episode": 73.0, "batch_reward": 0.2560032710134983, "critic_loss": 0.4259529779553413, "actor_loss": -32.21706700134278, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.229074716567993, "step": 73000}
{"episode_reward": 443.0426918897395, "episode": 74.0, "batch_reward": 0.25837948931753635, "critic_loss": 0.445512110427022, "actor_loss": -32.898057765960694, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.846890926361084, "step": 74000}
{"episode_reward": 445.6379159152845, "episode": 75.0, "batch_reward": 0.26007977859675885, "critic_loss": 0.4146517191529274, "actor_loss": -33.04460031890869, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.098670959472656, "step": 75000}
{"episode_reward": 229.58498491585266, "episode": 76.0, "batch_reward": 0.26021882763504983, "critic_loss": 0.3915078717619181, "actor_loss": -32.822873497009276, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.546623945236206, "step": 76000}
{"episode_reward": 457.71476633329814, "episode": 77.0, "batch_reward": 0.26332886251807214, "critic_loss": 0.3640182240009308, "actor_loss": -33.12981550598145, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.504559993743896, "step": 77000}
{"episode_reward": 437.8216913675724, "episode": 78.0, "batch_reward": 0.26549350400269034, "critic_loss": 0.36705864414572714, "actor_loss": -33.55164883041382, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.942025423049927, "step": 78000}
{"episode_reward": 451.59919638441824, "episode": 79.0, "batch_reward": 0.26789562119543553, "critic_loss": 0.3576436138898134, "actor_loss": -32.82892000198364, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.827550172805786, "step": 79000}
{"episode_reward": 440.38334795172017, "episode": 80.0, "batch_reward": 0.2706054529249668, "critic_loss": 0.3647953701913357, "actor_loss": -33.682121860504154, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.66658592224121, "step": 80000}
{"episode_reward": 389.7224377895377, "episode": 81.0, "batch_reward": 0.27217821246385576, "critic_loss": 0.40972998091578483, "actor_loss": -33.72898388290405, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.464415311813354, "step": 81000}
{"episode_reward": 427.0297759145874, "episode": 82.0, "batch_reward": 0.27165244330465793, "critic_loss": 0.40551236598193646, "actor_loss": -34.47279597473145, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.00866174697876, "step": 82000}
{"episode_reward": 77.54003384703026, "episode": 83.0, "batch_reward": 0.27082839401066305, "critic_loss": 0.3941312855035067, "actor_loss": -33.5825616607666, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.68051314353943, "step": 83000}
{"episode_reward": 479.2909456456541, "episode": 84.0, "batch_reward": 0.2735739332288504, "critic_loss": 0.3958413784354925, "actor_loss": -34.33103493118286, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.840131282806396, "step": 84000}
{"episode_reward": 411.791395887179, "episode": 85.0, "batch_reward": 0.2741842661648989, "critic_loss": 0.4432899880707264, "actor_loss": -34.28540100860596, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.229715824127197, "step": 85000}
{"episode_reward": 239.99057999851283, "episode": 86.0, "batch_reward": 0.27508563446998596, "critic_loss": 0.420855679705739, "actor_loss": -33.85905626296997, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.092058420181274, "step": 86000}
{"episode_reward": 460.60309687520265, "episode": 87.0, "batch_reward": 0.2767461702525616, "critic_loss": 0.40132423828542235, "actor_loss": -34.471935482025145, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.317566871643066, "step": 87000}
{"episode_reward": 478.65441056582443, "episode": 88.0, "batch_reward": 0.2788288089483976, "critic_loss": 0.42178623539209364, "actor_loss": -34.360022060394286, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.07564616203308, "step": 88000}
{"episode_reward": 465.99408942376874, "episode": 89.0, "batch_reward": 0.2807904646992683, "critic_loss": 0.4451125819683075, "actor_loss": -34.753677181243894, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.82397961616516, "step": 89000}
{"episode_reward": 463.76140427732173, "episode": 90.0, "batch_reward": 0.28329658465087415, "critic_loss": 0.43500892570614813, "actor_loss": -35.25976914215088, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.346471071243286, "step": 90000}
{"episode_reward": 472.3754206153196, "episode": 91.0, "batch_reward": 0.2854743945002556, "critic_loss": 0.40094559180736544, "actor_loss": -34.93409820175171, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.67914700508118, "step": 91000}
{"episode_reward": 436.6815342578638, "episode": 92.0, "batch_reward": 0.2871241757720709, "critic_loss": 0.42555390195548537, "actor_loss": -35.240216468811035, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.554839372634888, "step": 92000}
{"episode_reward": 455.92495372307036, "episode": 93.0, "batch_reward": 0.28791963605582716, "critic_loss": 0.4314388384371996, "actor_loss": -35.33384309768677, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.01506495475769, "step": 93000}
{"episode_reward": 471.8750315679677, "episode": 94.0, "batch_reward": 0.2905591807216406, "critic_loss": 0.42404643051326274, "actor_loss": -35.60126641464233, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.78358817100525, "step": 94000}
{"episode_reward": 471.45157913383963, "episode": 95.0, "batch_reward": 0.2936786105632782, "critic_loss": 0.3980046544224024, "actor_loss": -36.26139821624756, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.01679277420044, "step": 95000}
{"episode_reward": 487.9379657287083, "episode": 96.0, "batch_reward": 0.2946363385915756, "critic_loss": 0.3854226694256067, "actor_loss": -36.150639095306396, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.729175329208374, "step": 96000}
{"episode_reward": 468.7170265663111, "episode": 97.0, "batch_reward": 0.295999117359519, "critic_loss": 0.4033541505336761, "actor_loss": -36.39271251296997, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.782862186431885, "step": 97000}
{"episode_reward": 394.07319804334026, "episode": 98.0, "batch_reward": 0.29764609690010546, "critic_loss": 0.3873688157349825, "actor_loss": -36.156031936645505, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.876325845718384, "step": 98000}
{"episode_reward": 460.5533507968508, "episode": 99.0, "batch_reward": 0.2995031679421663, "critic_loss": 0.3915299602597952, "actor_loss": -36.5596741065979, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.506113052368164, "step": 99000}
{"episode_reward": 473.321902516448, "episode": 100.0, "batch_reward": 0.3021646148711443, "critic_loss": 0.3806172351837158, "actor_loss": -36.33212181091309, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.817330598831177, "step": 100000}
{"episode_reward": 453.0871667073322, "episode": 101.0, "batch_reward": 0.30224368958175185, "critic_loss": 0.41878703485429286, "actor_loss": -36.768912761688235, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.68288040161133, "step": 101000}
{"episode_reward": 469.1497771045329, "episode": 102.0, "batch_reward": 0.3030020513832569, "critic_loss": 0.41762480622529985, "actor_loss": -36.77071000289917, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.81370997428894, "step": 102000}
{"episode_reward": 500.53000119431783, "episode": 103.0, "batch_reward": 0.3049891063272953, "critic_loss": 0.415939625531435, "actor_loss": -36.79181702804566, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.22225856781006, "step": 103000}
{"episode_reward": 463.7259281008418, "episode": 104.0, "batch_reward": 0.3081479920446873, "critic_loss": 0.42538800394535065, "actor_loss": -37.082430572509764, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.85110831260681, "step": 104000}
{"episode_reward": 468.1687790538866, "episode": 105.0, "batch_reward": 0.30922811514139176, "critic_loss": 0.38684791076183317, "actor_loss": -37.15780143356323, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.813034057617188, "step": 105000}
{"episode_reward": 422.3992046811333, "episode": 106.0, "batch_reward": 0.3096920556873083, "critic_loss": 0.4116056999266148, "actor_loss": -37.01311679840088, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.692770957946777, "step": 106000}
{"episode_reward": 478.0623498349243, "episode": 107.0, "batch_reward": 0.31217100244760515, "critic_loss": 0.3848914139717817, "actor_loss": -37.22779914474487, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.08445978164673, "step": 107000}
{"episode_reward": 502.75477499876496, "episode": 108.0, "batch_reward": 0.3133105510026217, "critic_loss": 0.36985668624937534, "actor_loss": -37.37321676635742, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.83542776107788, "step": 108000}
{"episode_reward": 480.60370648142595, "episode": 109.0, "batch_reward": 0.31546018451452257, "critic_loss": 0.3691002103239298, "actor_loss": -37.939915782928466, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.7534077167511, "step": 109000}
{"episode_reward": 442.05184147371705, "episode": 110.0, "batch_reward": 0.3164577776491642, "critic_loss": 0.3906825774759054, "actor_loss": -37.80901793289185, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.61915922164917, "step": 110000}
{"episode_reward": 471.3754509321163, "episode": 111.0, "batch_reward": 0.3174548441171646, "critic_loss": 0.3974549577534199, "actor_loss": -38.20731521224975, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.20768976211548, "step": 111000}
{"episode_reward": 453.7287668354119, "episode": 112.0, "batch_reward": 0.3192315060198307, "critic_loss": 0.4062898361682892, "actor_loss": -37.97821639251709, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.6751229763031, "step": 112000}
{"episode_reward": 459.1553442400364, "episode": 113.0, "batch_reward": 0.3206936556994915, "critic_loss": 0.3942072848379612, "actor_loss": -37.917365116119385, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.054445505142212, "step": 113000}
{"episode_reward": 479.94637763657664, "episode": 114.0, "batch_reward": 0.32048316606879235, "critic_loss": 0.40463286837935447, "actor_loss": -38.75914017105102, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.193028450012207, "step": 114000}
{"episode_reward": 128.79667928795996, "episode": 115.0, "batch_reward": 0.3202688625156879, "critic_loss": 0.41630666072666644, "actor_loss": -38.3232374420166, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.023869276046753, "step": 115000}
{"episode_reward": 497.72897430871126, "episode": 116.0, "batch_reward": 0.32159612542390825, "critic_loss": 0.43439685891568663, "actor_loss": -38.70051546859741, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.888466358184814, "step": 116000}
{"episode_reward": 201.57765329668536, "episode": 117.0, "batch_reward": 0.3198042652606964, "critic_loss": 0.42597918172180654, "actor_loss": -37.75806084442139, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.627265453338623, "step": 117000}
{"episode_reward": 465.6079502535171, "episode": 118.0, "batch_reward": 0.32184081625938415, "critic_loss": 0.40638600584864615, "actor_loss": -38.492544666290286, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.074779510498047, "step": 118000}
{"episode_reward": 510.60302371676397, "episode": 119.0, "batch_reward": 0.3233464592695236, "critic_loss": 0.42780672045052054, "actor_loss": -38.81589433288574, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.37248921394348, "step": 119000}
{"episode_reward": 512.7779504124667, "episode": 120.0, "batch_reward": 0.32410429057478907, "critic_loss": 0.4144112762212753, "actor_loss": -38.439937450408934, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.49482822418213, "step": 120000}
{"episode_reward": 503.30199951126997, "episode": 121.0, "batch_reward": 0.32704518947005273, "critic_loss": 0.4357721490263939, "actor_loss": -38.64157167816162, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.751230001449585, "step": 121000}
{"episode_reward": 490.30267103125493, "episode": 122.0, "batch_reward": 0.3282307190001011, "critic_loss": 0.4215434090346098, "actor_loss": -38.77943612289429, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.904621601104736, "step": 122000}
{"episode_reward": 486.4067643643897, "episode": 123.0, "batch_reward": 0.3297779623866081, "critic_loss": 0.4326301492750645, "actor_loss": -38.272166717529295, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.993452310562134, "step": 123000}
{"episode_reward": 505.13072791977123, "episode": 124.0, "batch_reward": 0.33020239546895025, "critic_loss": 0.43177029472589495, "actor_loss": -38.93807353591919, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.606029510498047, "step": 124000}
{"episode_reward": 464.0868109378401, "episode": 125.0, "batch_reward": 0.33201792201399805, "critic_loss": 0.420513340651989, "actor_loss": -38.93363526153564, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.864997386932373, "step": 125000}
{"episode_reward": 498.2429939960743, "episode": 126.0, "batch_reward": 0.33220079153776166, "critic_loss": 0.3920759833604097, "actor_loss": -39.31417126083374, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.28996229171753, "step": 126000}
{"episode_reward": 483.48621268774724, "episode": 127.0, "batch_reward": 0.33327139937877653, "critic_loss": 0.38204978097975256, "actor_loss": -39.23723999786377, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.153069257736206, "step": 127000}
{"episode_reward": 458.9189268807382, "episode": 128.0, "batch_reward": 0.3353793675303459, "critic_loss": 0.4048860337138176, "actor_loss": -39.419481288909914, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.85630202293396, "step": 128000}
{"episode_reward": 493.691776453589, "episode": 129.0, "batch_reward": 0.33543964061141013, "critic_loss": 0.3920858762562275, "actor_loss": -39.79481620407105, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.08143639564514, "step": 129000}
{"episode_reward": 476.75845473020945, "episode": 130.0, "batch_reward": 0.33765008381009104, "critic_loss": 0.38147303108870984, "actor_loss": -39.93419691467285, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.804429054260254, "step": 130000}
{"episode_reward": 486.8385585688156, "episode": 131.0, "batch_reward": 0.3394532782435417, "critic_loss": 0.3832044420987368, "actor_loss": -40.098189247131344, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.504427909851074, "step": 131000}
{"episode_reward": 495.0672104008836, "episode": 132.0, "batch_reward": 0.339564333409071, "critic_loss": 0.4105516786426306, "actor_loss": -40.034957763671876, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.78475046157837, "step": 132000}
{"episode_reward": 480.9439399963933, "episode": 133.0, "batch_reward": 0.34036177894473074, "critic_loss": 0.3846764974296093, "actor_loss": -39.932831260681155, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.27700710296631, "step": 133000}
{"episode_reward": 507.0077915431798, "episode": 134.0, "batch_reward": 0.34161649954319, "critic_loss": 0.3689515316709876, "actor_loss": -40.23883101272583, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.86552882194519, "step": 134000}
{"episode_reward": 468.5149431846247, "episode": 135.0, "batch_reward": 0.3426675068438053, "critic_loss": 0.37379378551244735, "actor_loss": -40.448473442077635, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.891124725341797, "step": 135000}
{"episode_reward": 479.28614584809134, "episode": 136.0, "batch_reward": 0.3439704258441925, "critic_loss": 0.3906980518549681, "actor_loss": -40.728047821044925, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.22480535507202, "step": 136000}
{"episode_reward": 500.56846409285026, "episode": 137.0, "batch_reward": 0.3445953786075115, "critic_loss": 0.39604481899738314, "actor_loss": -40.43784930419922, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.13892126083374, "step": 137000}
{"episode_reward": 219.914845325572, "episode": 138.0, "batch_reward": 0.3443175908923149, "critic_loss": 0.39778797318041326, "actor_loss": -39.831267303466795, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.467281818389893, "step": 138000}
{"episode_reward": 482.09762981452576, "episode": 139.0, "batch_reward": 0.34550320810079577, "critic_loss": 0.4237263310700655, "actor_loss": -40.0787698135376, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.953558206558228, "step": 139000}
{"episode_reward": 491.68300704017815, "episode": 140.0, "batch_reward": 0.34532882782816887, "critic_loss": 0.37085390017926695, "actor_loss": -39.97790670776367, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.818800687789917, "step": 140000}
{"episode_reward": 493.021693623035, "episode": 141.0, "batch_reward": 0.34757893964648245, "critic_loss": 0.39494485230743887, "actor_loss": -40.05383504867554, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.56921648979187, "step": 141000}
{"episode_reward": 507.39989619416434, "episode": 142.0, "batch_reward": 0.3485447318851948, "critic_loss": 0.3697749881595373, "actor_loss": -40.50950918579102, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.877700805664062, "step": 142000}
{"episode_reward": 358.24579357854225, "episode": 143.0, "batch_reward": 0.34942286294698716, "critic_loss": 0.35295787060260775, "actor_loss": -40.44411391448975, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.29931378364563, "step": 143000}
{"episode_reward": 481.7797190363812, "episode": 144.0, "batch_reward": 0.34966663527488706, "critic_loss": 0.3700614312440157, "actor_loss": -40.885218349456785, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.247397422790527, "step": 144000}
{"episode_reward": 495.25238302687904, "episode": 145.0, "batch_reward": 0.35068761959671974, "critic_loss": 0.3803257196098566, "actor_loss": -40.491218502044674, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.294194221496582, "step": 145000}
{"episode_reward": 500.22383946227524, "episode": 146.0, "batch_reward": 0.3506726670563221, "critic_loss": 0.3582819311320782, "actor_loss": -40.626327907562256, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.601182460784912, "step": 146000}
{"episode_reward": 478.5581851783833, "episode": 147.0, "batch_reward": 0.35181255474686624, "critic_loss": 0.36574376286566257, "actor_loss": -40.95783758163452, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.31132459640503, "step": 147000}
{"episode_reward": 474.99656945325063, "episode": 148.0, "batch_reward": 0.35354580226540566, "critic_loss": 0.37620248706638815, "actor_loss": -40.65777718734741, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.113429069519043, "step": 148000}
{"episode_reward": 496.62602547292823, "episode": 149.0, "batch_reward": 0.35407304140925405, "critic_loss": 0.357143210336566, "actor_loss": -40.77871717453003, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.180677890777588, "step": 149000}
{"episode_reward": 475.60702049587263, "episode": 150.0, "batch_reward": 0.3555643760859966, "critic_loss": 0.34534325057268145, "actor_loss": -41.178696689605715, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
