{"episode_reward": 0.0, "episode": 1.0, "duration": 14.15816330909729, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.2605516910552979, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.2184240861499894, "critic_loss": 0.05513691289984522, "actor_loss": -40.70660179247539, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 70.79964280128479, "step": 3000}
{"episode_reward": 49.679393871954794, "episode": 4.0, "batch_reward": 0.1511703961342573, "critic_loss": 0.06171683714911342, "actor_loss": -33.845001378163694, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.162303686141968, "step": 4000}
{"episode_reward": 34.27942744999002, "episode": 5.0, "batch_reward": 0.13526983062922954, "critic_loss": 0.1014430205784738, "actor_loss": -32.88203856237233, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.799819469451904, "step": 5000}
{"episode_reward": 162.48956868578873, "episode": 6.0, "batch_reward": 0.15127556241303683, "critic_loss": 0.18923978740721942, "actor_loss": -33.131082951530814, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.98619794845581, "step": 6000}
{"episode_reward": 268.78222790913185, "episode": 7.0, "batch_reward": 0.1686188460290432, "critic_loss": 0.18478479127585887, "actor_loss": -32.40699477131665, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.594949960708618, "step": 7000}
{"episode_reward": 223.52398771226788, "episode": 8.0, "batch_reward": 0.16855487602949143, "critic_loss": 0.18056914572417737, "actor_loss": -31.555302610754968, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.995353937149048, "step": 8000}
{"episode_reward": 82.14422866978732, "episode": 9.0, "batch_reward": 0.15785496580600739, "critic_loss": 0.1581699648797512, "actor_loss": -28.417951814651488, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.446588039398193, "step": 9000}
{"episode_reward": 91.06621544914215, "episode": 10.0, "batch_reward": 0.15167893777787686, "critic_loss": 0.1741149901598692, "actor_loss": -27.899742240667344, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.998259782791138, "step": 10000}
{"episode_reward": 89.79445342442357, "episode": 11.0, "batch_reward": 0.1431207084953785, "critic_loss": 0.1668065101839602, "actor_loss": -24.943188469171524, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.38508987426758, "step": 11000}
{"episode_reward": 49.004277677744355, "episode": 12.0, "batch_reward": 0.1353770509660244, "critic_loss": 0.1804145749285817, "actor_loss": -23.62083887720108, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.44528293609619, "step": 12000}
{"episode_reward": 61.47642968850519, "episode": 13.0, "batch_reward": 0.13642095483094455, "critic_loss": 0.19356827444583177, "actor_loss": -23.240870626449585, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.59798312187195, "step": 13000}
{"episode_reward": 196.3707488543995, "episode": 14.0, "batch_reward": 0.13563265068084002, "critic_loss": 0.1835057654455304, "actor_loss": -23.73654473614693, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.99561905860901, "step": 14000}
{"episode_reward": 76.02840757525163, "episode": 15.0, "batch_reward": 0.1327922608628869, "critic_loss": 0.1720305654630065, "actor_loss": -21.684917609214782, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.97199058532715, "step": 15000}
{"episode_reward": 92.60047192589928, "episode": 16.0, "batch_reward": 0.1301187875121832, "critic_loss": 0.18473151277005673, "actor_loss": -20.866763051509857, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.236234426498413, "step": 16000}
{"episode_reward": 112.63650485458518, "episode": 17.0, "batch_reward": 0.1257591954022646, "critic_loss": 0.17562492191046478, "actor_loss": -20.99021178007126, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.06978678703308, "step": 17000}
{"episode_reward": 26.52061947709049, "episode": 18.0, "batch_reward": 0.12069609013199806, "critic_loss": 0.18569916485249996, "actor_loss": -20.402508978366853, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.194738626480103, "step": 18000}
{"episode_reward": 41.64938214196118, "episode": 19.0, "batch_reward": 0.12217906843870878, "critic_loss": 0.22177700805664063, "actor_loss": -18.99914095592499, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.952876329421997, "step": 19000}
{"episode_reward": 291.54435804338874, "episode": 20.0, "batch_reward": 0.12461415214836598, "critic_loss": 0.23248448091000318, "actor_loss": -18.80761323785782, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.38930106163025, "step": 20000}
{"episode_reward": 37.93776433492229, "episode": 21.0, "batch_reward": 0.12731992077082396, "critic_loss": 0.2270098460763693, "actor_loss": -18.666770117759704, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.39035224914551, "step": 21000}
{"episode_reward": 320.2455114846066, "episode": 22.0, "batch_reward": 0.1337963784635067, "critic_loss": 0.24728590252250432, "actor_loss": -19.50426714324951, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.99850034713745, "step": 22000}
{"episode_reward": 139.88542036597687, "episode": 23.0, "batch_reward": 0.13238309531658887, "critic_loss": 0.2904185613691807, "actor_loss": -20.305890152931212, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.066765546798706, "step": 23000}
{"episode_reward": 97.23262418220807, "episode": 24.0, "batch_reward": 0.12991142325103283, "critic_loss": 0.2940391797423363, "actor_loss": -19.507195560455322, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.031296014785767, "step": 24000}
{"episode_reward": 58.31455778172995, "episode": 25.0, "batch_reward": 0.12875280175358056, "critic_loss": 0.26639424097537995, "actor_loss": -19.893661014556884, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.042256355285645, "step": 25000}
{"episode_reward": 101.3477630704909, "episode": 26.0, "batch_reward": 0.12846404546499252, "critic_loss": 0.27032821460068224, "actor_loss": -19.72243904685974, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.5509934425354, "step": 26000}
{"episode_reward": 182.27685650104203, "episode": 27.0, "batch_reward": 0.1291402584835887, "critic_loss": 0.3137038393765688, "actor_loss": -19.458769716262818, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.602327346801758, "step": 27000}
{"episode_reward": 92.32019392935456, "episode": 28.0, "batch_reward": 0.12676752506196498, "critic_loss": 0.32612747613340615, "actor_loss": -19.144525524139404, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.31930685043335, "step": 28000}
{"episode_reward": 63.25646790175443, "episode": 29.0, "batch_reward": 0.12848289392888546, "critic_loss": 0.32476748517900705, "actor_loss": -18.637812864303587, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.975679397583008, "step": 29000}
{"episode_reward": 202.0979082504959, "episode": 30.0, "batch_reward": 0.13047732101380824, "critic_loss": 0.28742822451144456, "actor_loss": -18.921760677337648, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.30739951133728, "step": 30000}
{"episode_reward": 191.54491850586712, "episode": 31.0, "batch_reward": 0.12892770040035248, "critic_loss": 0.2671936269775033, "actor_loss": -18.600981344223023, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.19258713722229, "step": 31000}
{"episode_reward": 26.98547714571348, "episode": 32.0, "batch_reward": 0.12587427557259798, "critic_loss": 0.287474437430501, "actor_loss": -18.26491100692749, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.328056573867798, "step": 32000}
{"episode_reward": 60.78129975212982, "episode": 33.0, "batch_reward": 0.12847932055592537, "critic_loss": 0.2925142041221261, "actor_loss": -18.208312063217164, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.995845079421997, "step": 33000}
{"episode_reward": 374.3049772225945, "episode": 34.0, "batch_reward": 0.13704906052350999, "critic_loss": 0.3179204063564539, "actor_loss": -19.804090463638307, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.998297691345215, "step": 34000}
{"episode_reward": 455.55300086866833, "episode": 35.0, "batch_reward": 0.1454343466758728, "critic_loss": 0.3142046077251434, "actor_loss": -19.70509919166565, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.133668184280396, "step": 35000}
{"episode_reward": 367.44220823104166, "episode": 36.0, "batch_reward": 0.1518196532279253, "critic_loss": 0.3143165756687522, "actor_loss": -20.64515904045105, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.24718475341797, "step": 36000}
{"episode_reward": 457.68748113922794, "episode": 37.0, "batch_reward": 0.15494938583672047, "critic_loss": 0.37701404359936713, "actor_loss": -20.36117272949219, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.489896535873413, "step": 37000}
{"episode_reward": 43.17027728210453, "episode": 38.0, "batch_reward": 0.15688740979135035, "critic_loss": 0.33606645147502423, "actor_loss": -20.135914878845213, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.2741641998291, "step": 38000}
{"episode_reward": 420.428968524435, "episode": 39.0, "batch_reward": 0.16368459441512823, "critic_loss": 0.3605789736062288, "actor_loss": -20.753440315246582, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.212627172470093, "step": 39000}
{"episode_reward": 287.2234682381614, "episode": 40.0, "batch_reward": 0.16447847510874272, "critic_loss": 0.3749953952282667, "actor_loss": -21.507639236450196, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.210244178771973, "step": 40000}
{"episode_reward": 140.04289466700752, "episode": 41.0, "batch_reward": 0.16612125800549984, "critic_loss": 0.3595814981162548, "actor_loss": -22.11946220397949, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.76563882827759, "step": 41000}
{"episode_reward": 411.82151778623756, "episode": 42.0, "batch_reward": 0.17300666248798371, "critic_loss": 0.36992482386529446, "actor_loss": -23.50791131591797, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.68996810913086, "step": 42000}
{"episode_reward": 441.51110566063085, "episode": 43.0, "batch_reward": 0.17888029193878174, "critic_loss": 0.369299315109849, "actor_loss": -23.96889030838013, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.19759202003479, "step": 43000}
{"episode_reward": 354.6156754004663, "episode": 44.0, "batch_reward": 0.179108866751194, "critic_loss": 0.37685082338750364, "actor_loss": -24.072694961547853, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.10283589363098, "step": 44000}
{"episode_reward": 69.87589480419258, "episode": 45.0, "batch_reward": 0.17749028654396534, "critic_loss": 0.3756891453117132, "actor_loss": -23.98351689529419, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.783103227615356, "step": 45000}
{"episode_reward": 65.07083286193861, "episode": 46.0, "batch_reward": 0.17477179379761218, "critic_loss": 0.3335769153088331, "actor_loss": -24.067176277160645, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.149534702301025, "step": 46000}
{"episode_reward": 122.76066079754605, "episode": 47.0, "batch_reward": 0.17520319207012652, "critic_loss": 0.3549889348298311, "actor_loss": -23.75789233016968, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.87852382659912, "step": 47000}
{"episode_reward": 184.41007779142552, "episode": 48.0, "batch_reward": 0.1750680713504553, "critic_loss": 0.35288586147129536, "actor_loss": -23.822033756256104, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.4875431060791, "step": 48000}
{"episode_reward": 257.5895633289021, "episode": 49.0, "batch_reward": 0.174386510707438, "critic_loss": 0.40465209099650384, "actor_loss": -24.202247734069825, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.448566198349, "step": 49000}
{"episode_reward": 19.122683269877626, "episode": 50.0, "batch_reward": 0.17006955660134554, "critic_loss": 0.44557505275309084, "actor_loss": -24.70444060897827, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.357632637023926, "step": 50000}
{"episode_reward": 6.854080541762, "episode": 51.0, "batch_reward": 0.16783182786405088, "critic_loss": 0.4109681272804737, "actor_loss": -25.37384463119507, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.95745301246643, "step": 51000}
{"episode_reward": 8.177322032636724, "episode": 52.0, "batch_reward": 0.16512023361027242, "critic_loss": 0.38938296627998353, "actor_loss": -26.166568801879883, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.44347834587097, "step": 52000}
{"episode_reward": 13.822562532113796, "episode": 53.0, "batch_reward": 0.16197664740681647, "critic_loss": 0.3938277805298567, "actor_loss": -26.72594012069702, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.441776752471924, "step": 53000}
{"episode_reward": 116.39549297435326, "episode": 54.0, "batch_reward": 0.1602580025792122, "critic_loss": 0.42029323238134386, "actor_loss": -27.397971729278563, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.331904649734497, "step": 54000}
{"episode_reward": 9.235909571915114, "episode": 55.0, "batch_reward": 0.1589876866340637, "critic_loss": 0.4252314524650574, "actor_loss": -28.141939151763918, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.34984517097473, "step": 55000}
{"episode_reward": 50.640442516477336, "episode": 56.0, "batch_reward": 0.15591952764242886, "critic_loss": 0.47127372482419017, "actor_loss": -28.47060885620117, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.51571822166443, "step": 56000}
{"episode_reward": 155.31056593426763, "episode": 57.0, "batch_reward": 0.15852545949071645, "critic_loss": 0.5106472277641296, "actor_loss": -29.0110288772583, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.80239224433899, "step": 57000}
{"episode_reward": 277.78815192923554, "episode": 58.0, "batch_reward": 0.1599433505833149, "critic_loss": 0.5297475764751435, "actor_loss": -29.601917449951173, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.884182453155518, "step": 58000}
{"episode_reward": 321.8430726968751, "episode": 59.0, "batch_reward": 0.1644150911718607, "critic_loss": 0.5280373197942972, "actor_loss": -30.49646657180786, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.327799797058105, "step": 59000}
{"episode_reward": 345.9167228611358, "episode": 60.0, "batch_reward": 0.16757238010317088, "critic_loss": 0.49054682375490666, "actor_loss": -31.169064075469972, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.500953435897827, "step": 60000}
{"episode_reward": 402.2637463947778, "episode": 61.0, "batch_reward": 0.1706904999539256, "critic_loss": 0.4958465970903635, "actor_loss": -31.850284519195558, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.513129234313965, "step": 61000}
{"episode_reward": 323.50446560046504, "episode": 62.0, "batch_reward": 0.17187134205549956, "critic_loss": 0.5027202899456025, "actor_loss": -32.28499502944946, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.325220823287964, "step": 62000}
{"episode_reward": 113.65816964483194, "episode": 63.0, "batch_reward": 0.17167517428845167, "critic_loss": 0.5517687319368124, "actor_loss": -32.337973518371584, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.62157440185547, "step": 63000}
{"episode_reward": 265.8677452575817, "episode": 64.0, "batch_reward": 0.1730623785406351, "critic_loss": 0.48604534125328064, "actor_loss": -32.404143383026124, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.763733386993408, "step": 64000}
{"episode_reward": 318.38923948388725, "episode": 65.0, "batch_reward": 0.17601949629187583, "critic_loss": 0.3838168964087963, "actor_loss": -32.551352111816406, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.507129669189453, "step": 65000}
{"episode_reward": 420.3324810350236, "episode": 66.0, "batch_reward": 0.1817589658200741, "critic_loss": 0.36439459247887135, "actor_loss": -32.69025168609619, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.525184631347656, "step": 66000}
{"episode_reward": 419.9243405102213, "episode": 67.0, "batch_reward": 0.18088979123532772, "critic_loss": 0.3176631177216768, "actor_loss": -32.58708344268799, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.09562587738037, "step": 67000}
{"episode_reward": 7.693179498930234, "episode": 68.0, "batch_reward": 0.18091981314122677, "critic_loss": 0.3253048128336668, "actor_loss": -32.58800841140747, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.252634525299072, "step": 68000}
{"episode_reward": 419.6732290756805, "episode": 69.0, "batch_reward": 0.18509452992677689, "critic_loss": 0.3299379886686802, "actor_loss": -32.834796089172364, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.505828857421875, "step": 69000}
{"episode_reward": 476.4185312436401, "episode": 70.0, "batch_reward": 0.1896544910669327, "critic_loss": 0.3154743205308914, "actor_loss": -33.07319643402099, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.438135623931885, "step": 70000}
{"episode_reward": 530.032091388807, "episode": 71.0, "batch_reward": 0.1944008342474699, "critic_loss": 0.3059589310139418, "actor_loss": -33.33712519073487, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.385398626327515, "step": 71000}
{"episode_reward": 505.67388158991673, "episode": 72.0, "batch_reward": 0.19847513659298419, "critic_loss": 0.3147256325632334, "actor_loss": -33.44426556396484, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.627241373062134, "step": 72000}
{"episode_reward": 519.3617392543815, "episode": 73.0, "batch_reward": 0.20345099958777427, "critic_loss": 0.31511451534181834, "actor_loss": -33.60060983276367, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.35450792312622, "step": 73000}
{"episode_reward": 533.7004417091506, "episode": 74.0, "batch_reward": 0.2089090330451727, "critic_loss": 0.3039339743405581, "actor_loss": -33.72124679946899, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.769432306289673, "step": 74000}
{"episode_reward": 526.1621967650009, "episode": 75.0, "batch_reward": 0.2125400101095438, "critic_loss": 0.30514037422835827, "actor_loss": -33.75174124526978, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.429383754730225, "step": 75000}
{"episode_reward": 535.3617719552512, "episode": 76.0, "batch_reward": 0.21599002350866794, "critic_loss": 0.30913226220011714, "actor_loss": -33.9449771270752, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.39496088027954, "step": 76000}
{"episode_reward": 538.4152131892297, "episode": 77.0, "batch_reward": 0.22093674245476722, "critic_loss": 0.2721043342575431, "actor_loss": -34.24179323196411, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.88418173789978, "step": 77000}
{"episode_reward": 575.7644095779607, "episode": 78.0, "batch_reward": 0.22646463951468468, "critic_loss": 0.2838303684964776, "actor_loss": -34.43346078109741, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.59963369369507, "step": 78000}
{"episode_reward": 550.7936392627909, "episode": 79.0, "batch_reward": 0.22911076940596103, "critic_loss": 0.27371033222973346, "actor_loss": -34.64351650619507, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.565515279769897, "step": 79000}
{"episode_reward": 504.2797490991041, "episode": 80.0, "batch_reward": 0.2334569736868143, "critic_loss": 0.2723077191188931, "actor_loss": -35.01070875549316, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.478392839431763, "step": 80000}
{"episode_reward": 554.9762947605676, "episode": 81.0, "batch_reward": 0.23721592378616332, "critic_loss": 0.2814674347937107, "actor_loss": -35.297618251800536, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.802300453186035, "step": 81000}
{"episode_reward": 532.5784963876545, "episode": 82.0, "batch_reward": 0.2408430655002594, "critic_loss": 0.27223981756716964, "actor_loss": -35.54065427017212, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.259993076324463, "step": 82000}
{"episode_reward": 526.8382514785554, "episode": 83.0, "batch_reward": 0.2444321499913931, "critic_loss": 0.2744690944105387, "actor_loss": -35.73218626785278, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.201833963394165, "step": 83000}
{"episode_reward": 545.106337019325, "episode": 84.0, "batch_reward": 0.24750542971491812, "critic_loss": 0.2588074574843049, "actor_loss": -35.72343379974365, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.88769006729126, "step": 84000}
{"episode_reward": 549.7919007873019, "episode": 85.0, "batch_reward": 0.2510212372839451, "critic_loss": 0.2633574295118451, "actor_loss": -35.90411999130249, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.320974826812744, "step": 85000}
{"episode_reward": 559.9594287588645, "episode": 86.0, "batch_reward": 0.25468470154702666, "critic_loss": 0.2705352390781045, "actor_loss": -36.19342106628418, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.854815244674683, "step": 86000}
{"episode_reward": 525.3827735423615, "episode": 87.0, "batch_reward": 0.2575118003189564, "critic_loss": 0.24751205033808946, "actor_loss": -36.473356941223145, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.995795011520386, "step": 87000}
{"episode_reward": 540.123048976704, "episode": 88.0, "batch_reward": 0.2611332637667656, "critic_loss": 0.2578582700267434, "actor_loss": -36.78375806427002, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.127328157424927, "step": 88000}
{"episode_reward": 560.8823142126037, "episode": 89.0, "batch_reward": 0.26452012699842453, "critic_loss": 0.24240313182771206, "actor_loss": -36.875934173583985, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.923141717910767, "step": 89000}
{"episode_reward": 541.2276120490654, "episode": 90.0, "batch_reward": 0.26586894500255587, "critic_loss": 0.2547313128262758, "actor_loss": -36.91241767120361, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.20920419692993, "step": 90000}
{"episode_reward": 85.8783387291486, "episode": 91.0, "batch_reward": 0.2658401957452297, "critic_loss": 0.2578326462879777, "actor_loss": -36.75945207977295, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.38459849357605, "step": 91000}
{"episode_reward": 526.7893999148743, "episode": 92.0, "batch_reward": 0.2687632027566433, "critic_loss": 0.25728163857758046, "actor_loss": -36.96968490600586, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.37946057319641, "step": 92000}
{"episode_reward": 521.5414392619696, "episode": 93.0, "batch_reward": 0.27073568610847, "critic_loss": 0.2585799917504191, "actor_loss": -37.064066207885745, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.41525673866272, "step": 93000}
{"episode_reward": 497.651660567389, "episode": 94.0, "batch_reward": 0.2734509429335594, "critic_loss": 0.27091022666543724, "actor_loss": -37.18419498443603, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.621755361557007, "step": 94000}
{"episode_reward": 559.8245457213891, "episode": 95.0, "batch_reward": 0.2764787794947624, "critic_loss": 0.27632824404537676, "actor_loss": -37.29856174468994, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.332291841506958, "step": 95000}
{"episode_reward": 521.9359046497541, "episode": 96.0, "batch_reward": 0.2783929669260979, "critic_loss": 0.2641533052623272, "actor_loss": -37.335212593078616, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.716527462005615, "step": 96000}
{"episode_reward": 539.6726749195477, "episode": 97.0, "batch_reward": 0.28121745647490026, "critic_loss": 0.25457082775235174, "actor_loss": -37.6221152420044, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.60899305343628, "step": 97000}
{"episode_reward": 519.5341443508999, "episode": 98.0, "batch_reward": 0.2832757086157799, "critic_loss": 0.2535492243617773, "actor_loss": -37.80758040618896, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.71484088897705, "step": 98000}
{"episode_reward": 555.5217785623939, "episode": 99.0, "batch_reward": 0.2880799414366484, "critic_loss": 0.25989073045551775, "actor_loss": -38.42079035186767, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.24073100090027, "step": 99000}
{"episode_reward": 558.9302614000849, "episode": 100.0, "batch_reward": 0.2895153366327286, "critic_loss": 0.2523800990730524, "actor_loss": -38.75283785247803, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.27214741706848, "step": 100000}
{"episode_reward": 529.9321658560013, "episode": 101.0, "batch_reward": 0.29169249822199345, "critic_loss": 0.24522991665452717, "actor_loss": -39.021492614746094, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.24712419509888, "step": 101000}
{"episode_reward": 544.0024596239784, "episode": 102.0, "batch_reward": 0.2928400097340345, "critic_loss": 0.24498110342770815, "actor_loss": -39.14115463256836, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.317313194274902, "step": 102000}
{"episode_reward": 549.8476798291879, "episode": 103.0, "batch_reward": 0.29592803759872915, "critic_loss": 0.22546705681830645, "actor_loss": -39.22547429656982, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.22869896888733, "step": 103000}
{"episode_reward": 574.5357264281099, "episode": 104.0, "batch_reward": 0.29984363715350626, "critic_loss": 0.24041122176498175, "actor_loss": -39.28593223571777, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.106598377227783, "step": 104000}
{"episode_reward": 556.4581929243188, "episode": 105.0, "batch_reward": 0.30263936944305897, "critic_loss": 0.2467121949419379, "actor_loss": -39.458052810668946, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.570947408676147, "step": 105000}
{"episode_reward": 541.8811991455094, "episode": 106.0, "batch_reward": 0.30357283833622933, "critic_loss": 0.24387138172239065, "actor_loss": -39.380171195983884, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.317944049835205, "step": 106000}
{"episode_reward": 523.4184804189446, "episode": 107.0, "batch_reward": 0.3067367179691792, "critic_loss": 0.23728959130495786, "actor_loss": -39.48281205749512, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.467265605926514, "step": 107000}
{"episode_reward": 569.7159393996526, "episode": 108.0, "batch_reward": 0.30880519592761996, "critic_loss": 0.2453812176063657, "actor_loss": -39.54207723236084, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.94014596939087, "step": 108000}
{"episode_reward": 575.2279291047554, "episode": 109.0, "batch_reward": 0.3124644559621811, "critic_loss": 0.27609129694849255, "actor_loss": -39.63583239746094, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.312974452972412, "step": 109000}
{"episode_reward": 568.8087911206534, "episode": 110.0, "batch_reward": 0.31462382182478904, "critic_loss": 0.2510740349367261, "actor_loss": -39.743871353149416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.491532564163208, "step": 110000}
{"episode_reward": 556.948877207685, "episode": 111.0, "batch_reward": 0.3158662165403366, "critic_loss": 0.2671352139934897, "actor_loss": -39.81582773590088, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.754608154296875, "step": 111000}
{"episode_reward": 593.7290583068792, "episode": 112.0, "batch_reward": 0.31930184258520605, "critic_loss": 0.24993612115085126, "actor_loss": -40.05141299438476, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.687376737594604, "step": 112000}
{"episode_reward": 550.3831948238989, "episode": 113.0, "batch_reward": 0.3203899580538273, "critic_loss": 0.24571533412486316, "actor_loss": -39.99236524963379, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.314605951309204, "step": 113000}
{"episode_reward": 569.4870257814723, "episode": 114.0, "batch_reward": 0.3230575830042362, "critic_loss": 0.24656013026088477, "actor_loss": -40.093373001098634, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.33625054359436, "step": 114000}
{"episode_reward": 581.6435461264493, "episode": 115.0, "batch_reward": 0.3249337610304356, "critic_loss": 0.24358039166778325, "actor_loss": -40.29326736450195, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.58755612373352, "step": 115000}
{"episode_reward": 587.5205272131699, "episode": 116.0, "batch_reward": 0.3286598992049694, "critic_loss": 0.2297598074823618, "actor_loss": -40.48087575531006, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.281400203704834, "step": 116000}
{"episode_reward": 581.2249654022432, "episode": 117.0, "batch_reward": 0.33020839643478395, "critic_loss": 0.22916892994195223, "actor_loss": -40.66255628967285, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.23365044593811, "step": 117000}
{"episode_reward": 592.9368883037876, "episode": 118.0, "batch_reward": 0.3311820053756237, "critic_loss": 0.22206048648059368, "actor_loss": -40.66616018676758, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.835077047348022, "step": 118000}
{"episode_reward": 556.9614006314783, "episode": 119.0, "batch_reward": 0.33413005456328393, "critic_loss": 0.2234503652304411, "actor_loss": -40.95282347869873, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.69691777229309, "step": 119000}
{"episode_reward": 562.4926283920156, "episode": 120.0, "batch_reward": 0.33526580142974854, "critic_loss": 0.2360544094890356, "actor_loss": -40.995674026489255, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.24927544593811, "step": 120000}
{"episode_reward": 581.4365120500024, "episode": 121.0, "batch_reward": 0.33852816435694694, "critic_loss": 0.2290920658186078, "actor_loss": -41.247691696166996, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.64417314529419, "step": 121000}
{"episode_reward": 557.1651042772323, "episode": 122.0, "batch_reward": 0.3389143190681934, "critic_loss": 0.24269060732424258, "actor_loss": -41.189902084350585, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.513615131378174, "step": 122000}
{"episode_reward": 434.78159297691934, "episode": 123.0, "batch_reward": 0.34131136628985403, "critic_loss": 0.2464958728775382, "actor_loss": -41.37625509643555, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.34542179107666, "step": 123000}
{"episode_reward": 561.6788965751448, "episode": 124.0, "batch_reward": 0.3420671443045139, "critic_loss": 0.23797465436905624, "actor_loss": -41.41246302032471, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.128777503967285, "step": 124000}
{"episode_reward": 599.2358391850777, "episode": 125.0, "batch_reward": 0.3444959798455238, "critic_loss": 0.2324818205460906, "actor_loss": -41.41760941314697, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.718058824539185, "step": 125000}
{"episode_reward": 584.2425344834888, "episode": 126.0, "batch_reward": 0.3449013373851776, "critic_loss": 0.22499672155827283, "actor_loss": -41.62557865905762, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.329480171203613, "step": 126000}
{"episode_reward": 569.5675140870329, "episode": 127.0, "batch_reward": 0.3478102814257145, "critic_loss": 0.21944838078320025, "actor_loss": -41.557300666809084, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.9021098613739, "step": 127000}
{"episode_reward": 584.4117227665972, "episode": 128.0, "batch_reward": 0.3497293729484081, "critic_loss": 0.2422947614118457, "actor_loss": -41.69321990966797, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.176178455352783, "step": 128000}
{"episode_reward": 569.2472386502218, "episode": 129.0, "batch_reward": 0.35179718598723414, "critic_loss": 0.23328798904269935, "actor_loss": -41.85186742401123, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.60164761543274, "step": 129000}
{"episode_reward": 597.6839417478152, "episode": 130.0, "batch_reward": 0.353522346585989, "critic_loss": 0.2477022703960538, "actor_loss": -41.94439723968506, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.63560724258423, "step": 130000}
{"episode_reward": 591.3245466324554, "episode": 131.0, "batch_reward": 0.3567535980343819, "critic_loss": 0.2362755042091012, "actor_loss": -41.94275277709961, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.31363034248352, "step": 131000}
{"episode_reward": 595.4147930484819, "episode": 132.0, "batch_reward": 0.35764050990343094, "critic_loss": 0.24627515260130167, "actor_loss": -42.14471616363525, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.73140549659729, "step": 132000}
{"episode_reward": 572.5829213860662, "episode": 133.0, "batch_reward": 0.35807813704013824, "critic_loss": 0.26440715716034174, "actor_loss": -42.55193380737305, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.64705514907837, "step": 133000}
{"episode_reward": 567.3522683620558, "episode": 134.0, "batch_reward": 0.35948650655150416, "critic_loss": 0.26098692867159845, "actor_loss": -42.97873486328125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.536951780319214, "step": 134000}
{"episode_reward": 577.8938726578042, "episode": 135.0, "batch_reward": 0.36199938985705377, "critic_loss": 0.26284921397268773, "actor_loss": -43.40992470550537, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.266268730163574, "step": 135000}
{"episode_reward": 590.5951930655247, "episode": 136.0, "batch_reward": 0.36405718034505846, "critic_loss": 0.24259419845044614, "actor_loss": -43.57740177917481, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.522391080856323, "step": 136000}
{"episode_reward": 567.5485075421083, "episode": 137.0, "batch_reward": 0.36462348806858064, "critic_loss": 0.23223717172443867, "actor_loss": -43.54897668457031, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.950087308883667, "step": 137000}
{"episode_reward": 593.1793465330355, "episode": 138.0, "batch_reward": 0.3668209713101387, "critic_loss": 0.21874362616240978, "actor_loss": -43.73250901794434, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.11012077331543, "step": 138000}
{"episode_reward": 563.3156740630496, "episode": 139.0, "batch_reward": 0.36779620227217674, "critic_loss": 0.20997404830902816, "actor_loss": -43.97710948944092, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.423691034317017, "step": 139000}
{"episode_reward": 585.7028220189931, "episode": 140.0, "batch_reward": 0.3684178338944912, "critic_loss": 0.20881253988295795, "actor_loss": -43.91852841949463, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.412521600723267, "step": 140000}
{"episode_reward": 588.8597798739004, "episode": 141.0, "batch_reward": 0.36992229709029195, "critic_loss": 0.2046882887482643, "actor_loss": -44.014407661437986, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.56933093070984, "step": 141000}
{"episode_reward": 586.4442065699154, "episode": 142.0, "batch_reward": 0.3730736207962036, "critic_loss": 0.20559428976476193, "actor_loss": -44.14183349609375, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.217687845230103, "step": 142000}
{"episode_reward": 602.7145797030288, "episode": 143.0, "batch_reward": 0.3751192906200886, "critic_loss": 0.2144257348626852, "actor_loss": -44.16198332977295, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.41469430923462, "step": 143000}
{"episode_reward": 595.0191436075581, "episode": 144.0, "batch_reward": 0.3763031370341778, "critic_loss": 0.21590406207740306, "actor_loss": -44.21394881439209, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.412832736968994, "step": 144000}
{"episode_reward": 584.5688451276034, "episode": 145.0, "batch_reward": 0.3784275472164154, "critic_loss": 0.2231755563467741, "actor_loss": -44.229680671691895, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.295936107635498, "step": 145000}
{"episode_reward": 593.4299922262461, "episode": 146.0, "batch_reward": 0.37816983357071876, "critic_loss": 0.22671275122463702, "actor_loss": -44.38876162719727, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.431005477905273, "step": 146000}
{"episode_reward": 582.009571744345, "episode": 147.0, "batch_reward": 0.3795258746147156, "critic_loss": 0.2129996790289879, "actor_loss": -44.178106315612794, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.505702018737793, "step": 147000}
{"episode_reward": 559.2662545543367, "episode": 148.0, "batch_reward": 0.3822228890657425, "critic_loss": 0.22341870255768298, "actor_loss": -44.35989757537842, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.225719690322876, "step": 148000}
{"episode_reward": 605.4435105279665, "episode": 149.0, "batch_reward": 0.3836518834531307, "critic_loss": 0.22402175710350275, "actor_loss": -44.410739028930664, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.52191400527954, "step": 149000}
{"episode_reward": 591.8591557095745, "episode": 150.0, "batch_reward": 0.385275475859642, "critic_loss": 0.2127419262677431, "actor_loss": -44.54633184051514, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
