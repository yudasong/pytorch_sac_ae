{"episode_reward": 0.0, "episode": 1.0, "duration": 19.34773325920105, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.647711992263794, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.21855561709495416, "critic_loss": 0.09726512136646472, "actor_loss": -36.834662190732026, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 67.23467516899109, "step": 3000}
{"episode_reward": 26.696345346022035, "episode": 4.0, "batch_reward": 0.1411212796792388, "critic_loss": 0.030796344004571437, "actor_loss": -33.63718690633774, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.570456504821777, "step": 4000}
{"episode_reward": 3.620425359309718, "episode": 5.0, "batch_reward": 0.10980737606808544, "critic_loss": 0.0215575205758214, "actor_loss": -30.370104005098344, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.268524885177612, "step": 5000}
{"episode_reward": 11.536771151569292, "episode": 6.0, "batch_reward": 0.09197286203876137, "critic_loss": 0.022885012258775532, "actor_loss": -30.35923468995094, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.984925270080566, "step": 6000}
{"episode_reward": 10.991860948252318, "episode": 7.0, "batch_reward": 0.07962335806712509, "critic_loss": 0.0252010187888518, "actor_loss": -30.145681271314622, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.04039239883423, "step": 7000}
{"episode_reward": 11.411952229910142, "episode": 8.0, "batch_reward": 0.07062776871025563, "critic_loss": 0.026767084409482778, "actor_loss": -28.931877786636353, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.3574161529541, "step": 8000}
{"episode_reward": 8.947351548978338, "episode": 9.0, "batch_reward": 0.06372119749337435, "critic_loss": 0.03975478258915246, "actor_loss": -28.502911532878876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.202702522277832, "step": 9000}
{"episode_reward": 20.465142997724474, "episode": 10.0, "batch_reward": 0.0599836408291012, "critic_loss": 0.05104374752007425, "actor_loss": -28.490750103116035, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.111910104751587, "step": 10000}
{"episode_reward": 39.232461129817985, "episode": 11.0, "batch_reward": 0.05920611929148436, "critic_loss": 0.07062991116568446, "actor_loss": -28.140121968984605, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.34710168838501, "step": 11000}
{"episode_reward": 69.93231534681505, "episode": 12.0, "batch_reward": 0.06033509889245033, "critic_loss": 0.09070048773661256, "actor_loss": -26.684325602531434, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.806379318237305, "step": 12000}
{"episode_reward": 30.99052913309232, "episode": 13.0, "batch_reward": 0.057582378458231685, "critic_loss": 0.11931949666887522, "actor_loss": -25.791472019433975, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.413339376449585, "step": 13000}
{"episode_reward": 31.96153398559311, "episode": 14.0, "batch_reward": 0.059754349488765, "critic_loss": 0.1746064225398004, "actor_loss": -24.394178904533387, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.913702487945557, "step": 14000}
{"episode_reward": 168.8619584420308, "episode": 15.0, "batch_reward": 0.0628654938004911, "critic_loss": 0.21997641514986754, "actor_loss": -27.151788638234137, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.301041841506958, "step": 15000}
{"episode_reward": 24.21060405487329, "episode": 16.0, "batch_reward": 0.06411935660801828, "critic_loss": 0.2574069230109453, "actor_loss": -24.996569263219833, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.357133388519287, "step": 16000}
{"episode_reward": 207.7470756422187, "episode": 17.0, "batch_reward": 0.07403662778437138, "critic_loss": 0.3199811465293169, "actor_loss": -26.297636725008488, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.754952907562256, "step": 17000}
{"episode_reward": 200.94216862872423, "episode": 18.0, "batch_reward": 0.08211581418290734, "critic_loss": 0.3580042826384306, "actor_loss": -26.255835607089104, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.097432851791382, "step": 18000}
{"episode_reward": 198.0323180991899, "episode": 19.0, "batch_reward": 0.08750717316567898, "critic_loss": 0.3554046653211117, "actor_loss": -25.715558042913674, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.08581256866455, "step": 19000}
{"episode_reward": 137.64578581858058, "episode": 20.0, "batch_reward": 0.0896855925321579, "critic_loss": 0.31356181275844575, "actor_loss": -26.92078921800852, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.225013256072998, "step": 20000}
{"episode_reward": 201.54811654687393, "episode": 21.0, "batch_reward": 0.0964143764860928, "critic_loss": 0.2788495244011283, "actor_loss": -27.339191116571428, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.342671155929565, "step": 21000}
{"episode_reward": 213.90670716015774, "episode": 22.0, "batch_reward": 0.0997934517711401, "critic_loss": 0.31462351846694947, "actor_loss": -27.27281086683273, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.322516679763794, "step": 22000}
{"episode_reward": 73.50180370435184, "episode": 23.0, "batch_reward": 0.1000194400884211, "critic_loss": 0.29680196806043385, "actor_loss": -27.68946082496643, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.973389148712158, "step": 23000}
{"episode_reward": 100.76522072520757, "episode": 24.0, "batch_reward": 0.09735919903963804, "critic_loss": 0.298635439068079, "actor_loss": -26.49858757019043, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.106155157089233, "step": 24000}
{"episode_reward": 47.570832606071285, "episode": 25.0, "batch_reward": 0.09696388589590788, "critic_loss": 0.3224701429009438, "actor_loss": -25.661530684232712, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.492305755615234, "step": 25000}
{"episode_reward": 89.07072296311993, "episode": 26.0, "batch_reward": 0.09652595352008939, "critic_loss": 0.3382857871502638, "actor_loss": -26.317206665992735, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.447939157485962, "step": 26000}
{"episode_reward": 98.80163179967639, "episode": 27.0, "batch_reward": 0.09862843894958497, "critic_loss": 0.30673619382083417, "actor_loss": -25.408903457164765, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.18496298789978, "step": 27000}
{"episode_reward": 281.6443114791282, "episode": 28.0, "batch_reward": 0.10629442696273327, "critic_loss": 0.3855144826322794, "actor_loss": -25.689830549716948, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.65255618095398, "step": 28000}
{"episode_reward": 307.11037700549133, "episode": 29.0, "batch_reward": 0.1129545144662261, "critic_loss": 0.345627637013793, "actor_loss": -26.824801633358003, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.562584161758423, "step": 29000}
{"episode_reward": 231.06060781066248, "episode": 30.0, "batch_reward": 0.11660607606172561, "critic_loss": 0.3382919031232595, "actor_loss": -26.642366970062255, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.49592399597168, "step": 30000}
{"episode_reward": 266.0016754910028, "episode": 31.0, "batch_reward": 0.12216205329447985, "critic_loss": 0.30020035518705845, "actor_loss": -27.154337494850157, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.79623222351074, "step": 31000}
{"episode_reward": 301.14376551696637, "episode": 32.0, "batch_reward": 0.12699233499914409, "critic_loss": 0.2825030357316136, "actor_loss": -27.12862135505676, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.604007720947266, "step": 32000}
{"episode_reward": 237.48603211242778, "episode": 33.0, "batch_reward": 0.13113682346791028, "critic_loss": 0.3103465448021889, "actor_loss": -28.180022720336915, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.198221921920776, "step": 33000}
{"episode_reward": 199.02563972130278, "episode": 34.0, "batch_reward": 0.1311817703396082, "critic_loss": 0.3496533637046814, "actor_loss": -27.234855051994323, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.28304648399353, "step": 34000}
{"episode_reward": 112.09088617000808, "episode": 35.0, "batch_reward": 0.13035105919837953, "critic_loss": 0.3592932145223022, "actor_loss": -28.12438815975189, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.52876853942871, "step": 35000}
{"episode_reward": 77.10748120104545, "episode": 36.0, "batch_reward": 0.13072725261747836, "critic_loss": 0.2809378762245178, "actor_loss": -26.777599705696105, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.225457668304443, "step": 36000}
{"episode_reward": 299.84377589417244, "episode": 37.0, "batch_reward": 0.1337159974500537, "critic_loss": 0.27591871208697555, "actor_loss": -28.218926560401915, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.932922840118408, "step": 37000}
{"episode_reward": 133.0274105053982, "episode": 38.0, "batch_reward": 0.1359582231491804, "critic_loss": 0.26111517983675003, "actor_loss": -28.154540024757384, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.442604780197144, "step": 38000}
{"episode_reward": 266.0489145546374, "episode": 39.0, "batch_reward": 0.13937595235556363, "critic_loss": 0.24779924938827752, "actor_loss": -28.531724786758424, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.06682538986206, "step": 39000}
{"episode_reward": 271.5734219609361, "episode": 40.0, "batch_reward": 0.14208225416392087, "critic_loss": 0.23793037429451944, "actor_loss": -29.000298973083495, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.039002895355225, "step": 40000}
{"episode_reward": 302.20886520517536, "episode": 41.0, "batch_reward": 0.14538116230815648, "critic_loss": 0.2509845027923584, "actor_loss": -29.284940757751464, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.92319178581238, "step": 41000}
{"episode_reward": 223.5799017532339, "episode": 42.0, "batch_reward": 0.14716930324584246, "critic_loss": 0.2347397502809763, "actor_loss": -28.519267205238343, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.55441975593567, "step": 42000}
{"episode_reward": 242.36183919745147, "episode": 43.0, "batch_reward": 0.15025323439389468, "critic_loss": 0.2388555149808526, "actor_loss": -29.126499440193175, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.085249423980713, "step": 43000}
{"episode_reward": 230.6615380921453, "episode": 44.0, "batch_reward": 0.15169887048751116, "critic_loss": 0.22639681401848794, "actor_loss": -29.089840087890625, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.62711811065674, "step": 44000}
{"episode_reward": 221.39130898874393, "episode": 45.0, "batch_reward": 0.15453556659072637, "critic_loss": 0.247976373963058, "actor_loss": -29.408035598754882, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.71310043334961, "step": 45000}
{"episode_reward": 334.48438137027784, "episode": 46.0, "batch_reward": 0.15622249356657267, "critic_loss": 0.2627642282247543, "actor_loss": -29.499456194877624, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.157801389694214, "step": 46000}
{"episode_reward": 127.46672973149907, "episode": 47.0, "batch_reward": 0.15842013453692197, "critic_loss": 0.25825978168100117, "actor_loss": -29.907187295913698, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.41332173347473, "step": 47000}
{"episode_reward": 305.40921436950777, "episode": 48.0, "batch_reward": 0.15870407186448574, "critic_loss": 0.31252515864372254, "actor_loss": -29.54964167022705, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.31840229034424, "step": 48000}
{"episode_reward": 92.47269755477902, "episode": 49.0, "batch_reward": 0.15937047450244426, "critic_loss": 0.2947388811483979, "actor_loss": -30.188737033843996, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.096795082092285, "step": 49000}
{"episode_reward": 249.48650827857497, "episode": 50.0, "batch_reward": 0.15962754695117473, "critic_loss": 0.31626447407901287, "actor_loss": -29.453369974136354, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.978578805923462, "step": 50000}
{"episode_reward": 213.17532507919768, "episode": 51.0, "batch_reward": 0.16027634835988283, "critic_loss": 0.30805077018588783, "actor_loss": -29.617133401870728, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.70445489883423, "step": 51000}
{"episode_reward": 83.3812191518022, "episode": 52.0, "batch_reward": 0.15995060362666846, "critic_loss": 0.3275788159519434, "actor_loss": -29.299364852905274, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.270398378372192, "step": 52000}
{"episode_reward": 261.46688410690336, "episode": 53.0, "batch_reward": 0.1627480882704258, "critic_loss": 0.2927915013730526, "actor_loss": -29.792923248291014, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.11971616744995, "step": 53000}
{"episode_reward": 393.4494674646053, "episode": 54.0, "batch_reward": 0.1669666198566556, "critic_loss": 0.32865616017580035, "actor_loss": -29.804853197097778, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.517722606658936, "step": 54000}
{"episode_reward": 340.39678260056735, "episode": 55.0, "batch_reward": 0.17017833538353444, "critic_loss": 0.33516847869753835, "actor_loss": -30.911113843917846, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.851197957992554, "step": 55000}
{"episode_reward": 340.59879537736686, "episode": 56.0, "batch_reward": 0.17127916288375855, "critic_loss": 0.3303877369463444, "actor_loss": -30.702450901031494, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.439348220825195, "step": 56000}
{"episode_reward": 73.83508503256796, "episode": 57.0, "batch_reward": 0.17184853532910346, "critic_loss": 0.35285676704347135, "actor_loss": -29.920009817123415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.632352590560913, "step": 57000}
{"episode_reward": 370.30230742671387, "episode": 58.0, "batch_reward": 0.17517745147645475, "critic_loss": 0.35328612104058266, "actor_loss": -30.506471031188966, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.831204414367676, "step": 58000}
{"episode_reward": 379.8007545440897, "episode": 59.0, "batch_reward": 0.17825648276507855, "critic_loss": 0.3686173576116562, "actor_loss": -30.393442169189452, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.028916597366333, "step": 59000}
{"episode_reward": 334.95987315685943, "episode": 60.0, "batch_reward": 0.1812598735243082, "critic_loss": 0.34372055472433566, "actor_loss": -30.86268699836731, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.30278468132019, "step": 60000}
{"episode_reward": 369.59652390873214, "episode": 61.0, "batch_reward": 0.1844564161747694, "critic_loss": 0.3478997461050749, "actor_loss": -30.8946111907959, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.4109890460968, "step": 61000}
{"episode_reward": 375.28072386909184, "episode": 62.0, "batch_reward": 0.18673577471077443, "critic_loss": 0.34790456074476245, "actor_loss": -32.09102679824829, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.85083770751953, "step": 62000}
{"episode_reward": 339.3565762694511, "episode": 63.0, "batch_reward": 0.18964999055862428, "critic_loss": 0.3569615094959736, "actor_loss": -31.753247707366942, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.685201406478882, "step": 63000}
{"episode_reward": 429.2058569969328, "episode": 64.0, "batch_reward": 0.19293030443787576, "critic_loss": 0.36866973488032817, "actor_loss": -31.955993370056152, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.855304956436157, "step": 64000}
{"episode_reward": 291.24869664678994, "episode": 65.0, "batch_reward": 0.19494328567385674, "critic_loss": 0.35376261864602565, "actor_loss": -31.926507354736327, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.342010259628296, "step": 65000}
{"episode_reward": 404.1935360901861, "episode": 66.0, "batch_reward": 0.19870956601202489, "critic_loss": 0.37032194298505783, "actor_loss": -32.29464160346985, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.47495675086975, "step": 66000}
{"episode_reward": 353.02280765421455, "episode": 67.0, "batch_reward": 0.1999042438417673, "critic_loss": 0.4066738753765822, "actor_loss": -32.641673952102664, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.866697549819946, "step": 67000}
{"episode_reward": 191.31833557235817, "episode": 68.0, "batch_reward": 0.20034663201868533, "critic_loss": 0.3960974887162447, "actor_loss": -32.39888599014282, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.821043491363525, "step": 68000}
{"episode_reward": 421.61742666068915, "episode": 69.0, "batch_reward": 0.20365756219625472, "critic_loss": 0.42417841593921185, "actor_loss": -32.85077323532104, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.532214641571045, "step": 69000}
{"episode_reward": 438.8404631472205, "episode": 70.0, "batch_reward": 0.20663022592663766, "critic_loss": 0.44034857684373857, "actor_loss": -33.19878985214233, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.81459617614746, "step": 70000}
{"episode_reward": 387.775160208139, "episode": 71.0, "batch_reward": 0.20995266424119471, "critic_loss": 0.4307147521674633, "actor_loss": -33.689624032974244, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.63312268257141, "step": 71000}
{"episode_reward": 379.81316707131685, "episode": 72.0, "batch_reward": 0.21191458375751973, "critic_loss": 0.45942288549244403, "actor_loss": -33.976126213073734, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.032443284988403, "step": 72000}
{"episode_reward": 389.4784571757605, "episode": 73.0, "batch_reward": 0.21453602424263954, "critic_loss": 0.4739973576664925, "actor_loss": -33.86278016090393, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.239288091659546, "step": 73000}
{"episode_reward": 324.3603164276133, "episode": 74.0, "batch_reward": 0.2157547022253275, "critic_loss": 0.5352854195535183, "actor_loss": -34.364627014160156, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.065646409988403, "step": 74000}
{"episode_reward": 288.6844846759342, "episode": 75.0, "batch_reward": 0.21778104135394097, "critic_loss": 0.49900344328582286, "actor_loss": -33.95777027130127, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.196629285812378, "step": 75000}
{"episode_reward": 441.99576525436265, "episode": 76.0, "batch_reward": 0.21976529440283776, "critic_loss": 0.5450155905336141, "actor_loss": -34.35876760482788, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.965698719024658, "step": 76000}
{"episode_reward": 313.50452276260603, "episode": 77.0, "batch_reward": 0.22126898834109307, "critic_loss": 0.5634494912028313, "actor_loss": -34.05232073783875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.06332015991211, "step": 77000}
{"episode_reward": 283.82864653784884, "episode": 78.0, "batch_reward": 0.22304671359062195, "critic_loss": 0.6512083979398012, "actor_loss": -34.68396147727967, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.72860026359558, "step": 78000}
{"episode_reward": 407.0328316003957, "episode": 79.0, "batch_reward": 0.2233212846517563, "critic_loss": 0.6745680674761534, "actor_loss": -33.61076372909546, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.355464935302734, "step": 79000}
{"episode_reward": 319.0203928371249, "episode": 80.0, "batch_reward": 0.225561936840415, "critic_loss": 0.6368558308184147, "actor_loss": -34.425916393280026, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.208643913269043, "step": 80000}
{"episode_reward": 393.397457082315, "episode": 81.0, "batch_reward": 0.2280937794148922, "critic_loss": 0.6427387974262238, "actor_loss": -34.5533172454834, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.69613218307495, "step": 81000}
{"episode_reward": 436.05163334184, "episode": 82.0, "batch_reward": 0.23084804280102253, "critic_loss": 0.6240823125839233, "actor_loss": -35.64164782333374, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.43906569480896, "step": 82000}
{"episode_reward": 408.4968297528693, "episode": 83.0, "batch_reward": 0.23354548707604408, "critic_loss": 0.5907643504738808, "actor_loss": -35.02541339492798, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.83807897567749, "step": 83000}
{"episode_reward": 459.61139301128196, "episode": 84.0, "batch_reward": 0.2344692436903715, "critic_loss": 0.5699007538408041, "actor_loss": -36.33379920578003, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.002482175827026, "step": 84000}
{"episode_reward": 347.30903336001677, "episode": 85.0, "batch_reward": 0.23577534314990042, "critic_loss": 0.6043962671309709, "actor_loss": -35.786101573944094, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.454211235046387, "step": 85000}
{"episode_reward": 383.04996629102504, "episode": 86.0, "batch_reward": 0.23788830825686455, "critic_loss": 0.6000885934382677, "actor_loss": -35.80913540649414, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.684168815612793, "step": 86000}
{"episode_reward": 433.4074147829452, "episode": 87.0, "batch_reward": 0.240788275167346, "critic_loss": 0.5682218135893344, "actor_loss": -36.03420224761963, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.594194889068604, "step": 87000}
{"episode_reward": 384.82130954163, "episode": 88.0, "batch_reward": 0.241848225325346, "critic_loss": 0.6125205084830523, "actor_loss": -35.75179903030396, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.989470720291138, "step": 88000}
{"episode_reward": 437.05915257156806, "episode": 89.0, "batch_reward": 0.2447385569512844, "critic_loss": 0.5219837427139282, "actor_loss": -36.466406665802005, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.71705198287964, "step": 89000}
{"episode_reward": 446.1446485881769, "episode": 90.0, "batch_reward": 0.24694258669018745, "critic_loss": 0.5444533538669348, "actor_loss": -36.891762111663816, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.344126224517822, "step": 90000}
{"episode_reward": 415.53891473626317, "episode": 91.0, "batch_reward": 0.24810101854801178, "critic_loss": 0.5978916795998812, "actor_loss": -36.70294972991943, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.3313353061676, "step": 91000}
{"episode_reward": 315.1903020696196, "episode": 92.0, "batch_reward": 0.2495484029352665, "critic_loss": 0.581471294760704, "actor_loss": -36.68013826370239, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.79185652732849, "step": 92000}
{"episode_reward": 416.1366299540181, "episode": 93.0, "batch_reward": 0.2502738451957703, "critic_loss": 0.6172830911278725, "actor_loss": -36.48126108169556, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.595963716506958, "step": 93000}
{"episode_reward": 353.0602652374359, "episode": 94.0, "batch_reward": 0.2519827238768339, "critic_loss": 0.6075666371732951, "actor_loss": -37.03332565307617, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.499733448028564, "step": 94000}
{"episode_reward": 444.3486126755396, "episode": 95.0, "batch_reward": 0.25386932733654977, "critic_loss": 0.6802405079603195, "actor_loss": -37.32872337722778, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.463974952697754, "step": 95000}
{"episode_reward": 404.269293984767, "episode": 96.0, "batch_reward": 0.2548066184222698, "critic_loss": 0.5830953179001808, "actor_loss": -37.52203493118286, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.014244556427002, "step": 96000}
{"episode_reward": 382.6268956266641, "episode": 97.0, "batch_reward": 0.25684158194065093, "critic_loss": 0.5886140832901001, "actor_loss": -37.86189775085449, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.380890607833862, "step": 97000}
{"episode_reward": 358.4572781619479, "episode": 98.0, "batch_reward": 0.2579099710136652, "critic_loss": 0.5642904891967774, "actor_loss": -37.66008681488037, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.536186456680298, "step": 98000}
{"episode_reward": 437.0205977164733, "episode": 99.0, "batch_reward": 0.26018376342952254, "critic_loss": 0.6088702406436205, "actor_loss": -37.3183038520813, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.947648763656616, "step": 99000}
{"episode_reward": 411.98416410153277, "episode": 100.0, "batch_reward": 0.26241983291506765, "critic_loss": 0.5268378184884787, "actor_loss": -37.78826350402832, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.26080584526062, "step": 100000}
{"episode_reward": 394.5076752707997, "episode": 101.0, "batch_reward": 0.2628332418948412, "critic_loss": 0.5700589191913604, "actor_loss": -37.871214065551754, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.063878297805786, "step": 101000}
{"episode_reward": 404.72111885792594, "episode": 102.0, "batch_reward": 0.2630995196849108, "critic_loss": 0.5798549216538668, "actor_loss": -37.633166007995605, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.56918978691101, "step": 102000}
{"episode_reward": 327.33078562506284, "episode": 103.0, "batch_reward": 0.26363355676829814, "critic_loss": 0.5939986161887646, "actor_loss": -38.19198389816284, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.03602361679077, "step": 103000}
{"episode_reward": 344.99008097404766, "episode": 104.0, "batch_reward": 0.26599766390025614, "critic_loss": 0.6136031272262334, "actor_loss": -38.28251764297485, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.66371774673462, "step": 104000}
{"episode_reward": 368.85560739480655, "episode": 105.0, "batch_reward": 0.2666796853989363, "critic_loss": 0.5954686181247234, "actor_loss": -38.22976210021972, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.58496332168579, "step": 105000}
{"episode_reward": 388.91675266700736, "episode": 106.0, "batch_reward": 0.2665194492340088, "critic_loss": 0.6354759925603867, "actor_loss": -38.14257907104492, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.952867031097412, "step": 106000}
{"episode_reward": 121.51841778069578, "episode": 107.0, "batch_reward": 0.26628547579050066, "critic_loss": 0.6845254057943821, "actor_loss": -38.31990992355347, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.25117826461792, "step": 107000}
{"episode_reward": 396.10407895429387, "episode": 108.0, "batch_reward": 0.2672497050464153, "critic_loss": 0.6764156215637922, "actor_loss": -38.229669052124024, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.628780126571655, "step": 108000}
{"episode_reward": 344.4480869030709, "episode": 109.0, "batch_reward": 0.26846886740624903, "critic_loss": 0.7025537672042846, "actor_loss": -39.02364879989624, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.110849380493164, "step": 109000}
{"episode_reward": 421.3358847113613, "episode": 110.0, "batch_reward": 0.269666006475687, "critic_loss": 0.6658347141295672, "actor_loss": -38.753306255340576, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.74601912498474, "step": 110000}
{"episode_reward": 427.3620523948951, "episode": 111.0, "batch_reward": 0.27045706084370613, "critic_loss": 0.6257246590405703, "actor_loss": -38.79277124023437, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.23831915855408, "step": 111000}
{"episode_reward": 376.0627942221124, "episode": 112.0, "batch_reward": 0.2720690630674362, "critic_loss": 0.5985394641458989, "actor_loss": -38.29473188400269, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.228037118911743, "step": 112000}
{"episode_reward": 380.0484454441841, "episode": 113.0, "batch_reward": 0.27211902835965157, "critic_loss": 0.6042858390957118, "actor_loss": -38.78287523269653, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.897505283355713, "step": 113000}
{"episode_reward": 352.5543964907737, "episode": 114.0, "batch_reward": 0.27363491816818714, "critic_loss": 0.5981698018163443, "actor_loss": -39.1828970451355, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.731452465057373, "step": 114000}
{"episode_reward": 418.38471744258175, "episode": 115.0, "batch_reward": 0.27521233570575715, "critic_loss": 0.6027024799287319, "actor_loss": -38.91218922805786, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.4175763130188, "step": 115000}
{"episode_reward": 386.27453646584627, "episode": 116.0, "batch_reward": 0.27580463372170927, "critic_loss": 0.5214062989503145, "actor_loss": -38.86404607009888, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.72759747505188, "step": 116000}
{"episode_reward": 427.0604437199074, "episode": 117.0, "batch_reward": 0.278218686491251, "critic_loss": 0.5793725922852755, "actor_loss": -38.850166149139405, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.77783226966858, "step": 117000}
{"episode_reward": 413.5911029320873, "episode": 118.0, "batch_reward": 0.27707359197735787, "critic_loss": 0.6396752855479717, "actor_loss": -38.932538619995114, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.761029720306396, "step": 118000}
{"episode_reward": 128.82342394211463, "episode": 119.0, "batch_reward": 0.2765902537405491, "critic_loss": 0.5669839803129435, "actor_loss": -39.05041709136963, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.58973217010498, "step": 119000}
{"episode_reward": 188.4623474737345, "episode": 120.0, "batch_reward": 0.27519027958810327, "critic_loss": 0.5754703698754311, "actor_loss": -38.74390814590454, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.50593376159668, "step": 120000}
{"episode_reward": 413.7765109731066, "episode": 121.0, "batch_reward": 0.2774911394715309, "critic_loss": 0.5663535936772823, "actor_loss": -38.59436197662354, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.168198347091675, "step": 121000}
{"episode_reward": 424.06076414803346, "episode": 122.0, "batch_reward": 0.2793175279647112, "critic_loss": 0.6011197621226311, "actor_loss": -38.98725019836426, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.4975483417511, "step": 122000}
{"episode_reward": 237.56364682871865, "episode": 123.0, "batch_reward": 0.2788031649142504, "critic_loss": 0.6585715630948543, "actor_loss": -38.206356540679934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.092705965042114, "step": 123000}
{"episode_reward": 409.3808932542645, "episode": 124.0, "batch_reward": 0.27940096001327036, "critic_loss": 0.5588137705624103, "actor_loss": -38.83002319717407, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.12648105621338, "step": 124000}
{"episode_reward": 376.4266538489739, "episode": 125.0, "batch_reward": 0.2805803210288286, "critic_loss": 0.6009996998459101, "actor_loss": -38.69175968933106, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.521394729614258, "step": 125000}
{"episode_reward": 452.7151025629005, "episode": 126.0, "batch_reward": 0.28125681141018866, "critic_loss": 0.5889742443710566, "actor_loss": -38.56874427032471, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.143061637878418, "step": 126000}
{"episode_reward": 437.0674377194738, "episode": 127.0, "batch_reward": 0.28288611383736134, "critic_loss": 0.6088697049319745, "actor_loss": -39.32604895401001, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.325369834899902, "step": 127000}
{"episode_reward": 429.6971514079674, "episode": 128.0, "batch_reward": 0.28348298417031764, "critic_loss": 0.6347865581065416, "actor_loss": -39.787940753936766, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.258359670639038, "step": 128000}
{"episode_reward": 432.17377824457856, "episode": 129.0, "batch_reward": 0.28546184419095516, "critic_loss": 0.6030792666971684, "actor_loss": -39.62165158843994, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.907674312591553, "step": 129000}
{"episode_reward": 397.8091276524787, "episode": 130.0, "batch_reward": 0.2854940741062164, "critic_loss": 0.5471457644701004, "actor_loss": -39.51682687759399, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.163537979125977, "step": 130000}
{"episode_reward": 431.9595519648771, "episode": 131.0, "batch_reward": 0.28760039791464803, "critic_loss": 0.6301679959297181, "actor_loss": -40.01434657287598, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.683695554733276, "step": 131000}
{"episode_reward": 382.01962120499445, "episode": 132.0, "batch_reward": 0.28809851890802385, "critic_loss": 0.6327874616086483, "actor_loss": -39.9813992729187, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.802018404006958, "step": 132000}
{"episode_reward": 415.61642841384213, "episode": 133.0, "batch_reward": 0.2878636188954115, "critic_loss": 0.6420524289757014, "actor_loss": -39.74253353881836, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.381911754608154, "step": 133000}
{"episode_reward": 398.0113532143797, "episode": 134.0, "batch_reward": 0.28923191049695013, "critic_loss": 0.6546103235036135, "actor_loss": -40.09943797302246, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.693588733673096, "step": 134000}
{"episode_reward": 413.5683840064774, "episode": 135.0, "batch_reward": 0.29059053245186806, "critic_loss": 0.6056077951788902, "actor_loss": -40.0442571144104, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.245403051376343, "step": 135000}
{"episode_reward": 430.6179997326195, "episode": 136.0, "batch_reward": 0.2913655533641577, "critic_loss": 0.5490760038793087, "actor_loss": -40.71467998504639, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.571112632751465, "step": 136000}
{"episode_reward": 422.66721486894085, "episode": 137.0, "batch_reward": 0.29218458591401575, "critic_loss": 0.5471327124238015, "actor_loss": -40.32028875732422, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.641006231307983, "step": 137000}
{"episode_reward": 440.2982060940269, "episode": 138.0, "batch_reward": 0.29370630052685737, "critic_loss": 0.6386624783426523, "actor_loss": -39.572202152252196, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.443787336349487, "step": 138000}
{"episode_reward": 427.8870957271367, "episode": 139.0, "batch_reward": 0.29447035780549047, "critic_loss": 0.5405205824375152, "actor_loss": -39.86952496337891, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.002886056900024, "step": 139000}
{"episode_reward": 406.7758210732735, "episode": 140.0, "batch_reward": 0.29479627595841884, "critic_loss": 0.5675765802711248, "actor_loss": -39.589040344238285, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.95167899131775, "step": 140000}
{"episode_reward": 433.0999312657504, "episode": 141.0, "batch_reward": 0.2961475674808025, "critic_loss": 0.5323093859702349, "actor_loss": -39.96492360305786, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.59366226196289, "step": 141000}
{"episode_reward": 385.46292292645586, "episode": 142.0, "batch_reward": 0.2964545921087265, "critic_loss": 0.6498452697992325, "actor_loss": -40.18574084854126, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.29532814025879, "step": 142000}
{"episode_reward": 422.5362696311916, "episode": 143.0, "batch_reward": 0.2979149619191885, "critic_loss": 0.6018516368716955, "actor_loss": -40.58884959411621, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.44058585166931, "step": 143000}
{"episode_reward": 397.46070237020353, "episode": 144.0, "batch_reward": 0.2989328089356422, "critic_loss": 0.603554701924324, "actor_loss": -40.597349769592284, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.694302082061768, "step": 144000}
{"episode_reward": 418.96458222423354, "episode": 145.0, "batch_reward": 0.29923613822460177, "critic_loss": 0.594091609582305, "actor_loss": -40.44339798355102, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.81768274307251, "step": 145000}
{"episode_reward": 423.1055523547363, "episode": 146.0, "batch_reward": 0.29983431884646417, "critic_loss": 0.5369338220357895, "actor_loss": -40.394230304718015, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.280661821365356, "step": 146000}
{"episode_reward": 457.3430330956246, "episode": 147.0, "batch_reward": 0.3004275520890951, "critic_loss": 0.5499935867041349, "actor_loss": -40.944049900054935, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.340378999710083, "step": 147000}
{"episode_reward": 393.6053695826568, "episode": 148.0, "batch_reward": 0.3023517593741417, "critic_loss": 0.5589287749230861, "actor_loss": -40.68115271377563, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.550607681274414, "step": 148000}
{"episode_reward": 419.53442395872395, "episode": 149.0, "batch_reward": 0.30326679119467737, "critic_loss": 0.5372247536927461, "actor_loss": -40.964403392791745, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.647504091262817, "step": 149000}
{"episode_reward": 430.6894593972161, "episode": 150.0, "batch_reward": 0.3037363484501839, "critic_loss": 0.6104906291663647, "actor_loss": -40.438036670684816, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
