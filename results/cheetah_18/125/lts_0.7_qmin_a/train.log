{"episode_reward": 0.0, "episode": 1.0, "duration": 17.867701530456543, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.5105016231536865, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.22478910585012624, "critic_loss": 0.05115532387941132, "actor_loss": -32.9265135043247, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 61.49242162704468, "step": 3000}
{"episode_reward": 144.65197977543508, "episode": 4.0, "batch_reward": 0.17858565948158503, "critic_loss": 0.045076242342591284, "actor_loss": -30.803389469861983, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.09129309654236, "step": 4000}
{"episode_reward": 30.178437648545753, "episode": 5.0, "batch_reward": 0.15215719990432264, "critic_loss": 0.04576300573721528, "actor_loss": -26.97899832093716, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.262964248657227, "step": 5000}
{"episode_reward": 111.79773922232737, "episode": 6.0, "batch_reward": 0.13919856452196835, "critic_loss": 0.05776936820521951, "actor_loss": -27.740138460993766, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.924838066101074, "step": 6000}
{"episode_reward": 62.61052396182991, "episode": 7.0, "batch_reward": 0.13998776836693286, "critic_loss": 0.08221927402541042, "actor_loss": -30.421857620716096, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.509963750839233, "step": 7000}
{"episode_reward": 222.14042678631873, "episode": 8.0, "batch_reward": 0.15057459211349486, "critic_loss": 0.08464674401283265, "actor_loss": -29.06359879183769, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.12483787536621, "step": 8000}
{"episode_reward": 207.25897345213932, "episode": 9.0, "batch_reward": 0.1577406114190817, "critic_loss": 0.09406344018131495, "actor_loss": -28.997558964729308, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.812317609786987, "step": 9000}
{"episode_reward": 191.50077685062993, "episode": 10.0, "batch_reward": 0.16264758436381818, "critic_loss": 0.12361280046775937, "actor_loss": -29.013739594459533, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.966656923294067, "step": 10000}
{"episode_reward": 172.83314342572146, "episode": 11.0, "batch_reward": 0.16062116315960884, "critic_loss": 0.15600724750757217, "actor_loss": -28.928795097351074, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.08394122123718, "step": 11000}
{"episode_reward": 157.19561410596265, "episode": 12.0, "batch_reward": 0.15963214663416148, "critic_loss": 0.16778443113714456, "actor_loss": -27.71118507051468, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.912684440612793, "step": 12000}
{"episode_reward": 134.8627516277615, "episode": 13.0, "batch_reward": 0.1623115281611681, "critic_loss": 0.20858498135954143, "actor_loss": -27.937560973167418, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.212947845458984, "step": 13000}
{"episode_reward": 265.8963628429152, "episode": 14.0, "batch_reward": 0.1651485215499997, "critic_loss": 0.19110435173660517, "actor_loss": -27.058575573444365, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.793096780776978, "step": 14000}
{"episode_reward": 99.20308897768612, "episode": 15.0, "batch_reward": 0.1582769267782569, "critic_loss": 0.17701160825043916, "actor_loss": -29.03733554935455, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.91516375541687, "step": 15000}
{"episode_reward": 40.27269092401611, "episode": 16.0, "batch_reward": 0.15620126682519914, "critic_loss": 0.19799174635112285, "actor_loss": -27.44980839443207, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.394526481628418, "step": 16000}
{"episode_reward": 249.81690059719335, "episode": 17.0, "batch_reward": 0.1592211219072342, "critic_loss": 0.22558040458709003, "actor_loss": -26.604011470794678, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.32164764404297, "step": 17000}
{"episode_reward": 97.29381355592406, "episode": 18.0, "batch_reward": 0.15949976953864098, "critic_loss": 0.2286008782237768, "actor_loss": -26.788700053215027, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.17485237121582, "step": 18000}
{"episode_reward": 250.62749643776547, "episode": 19.0, "batch_reward": 0.15803753135353327, "critic_loss": 0.2229103131815791, "actor_loss": -26.292482001304627, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.399742364883423, "step": 19000}
{"episode_reward": 33.21316945241724, "episode": 20.0, "batch_reward": 0.15387253341078758, "critic_loss": 0.21017320948839188, "actor_loss": -26.47040326976776, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.410459995269775, "step": 20000}
{"episode_reward": 86.58347566014702, "episode": 21.0, "batch_reward": 0.15586083582043647, "critic_loss": 0.21612867913395167, "actor_loss": -26.73153493499756, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.08105397224426, "step": 21000}
{"episode_reward": 311.9206501237453, "episode": 22.0, "batch_reward": 0.1603807431384921, "critic_loss": 0.22747729325294494, "actor_loss": -26.378692193031313, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.71847105026245, "step": 22000}
{"episode_reward": 160.1318350296499, "episode": 23.0, "batch_reward": 0.1571055141016841, "critic_loss": 0.2525008739680052, "actor_loss": -26.423144817352295, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.73043918609619, "step": 23000}
{"episode_reward": 44.428139777357224, "episode": 24.0, "batch_reward": 0.15512928896397352, "critic_loss": 0.25485463745892045, "actor_loss": -26.1807428150177, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.78761649131775, "step": 24000}
{"episode_reward": 157.8472885175643, "episode": 25.0, "batch_reward": 0.15569263128936292, "critic_loss": 0.25216191762685775, "actor_loss": -25.087605589866637, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.966123580932617, "step": 25000}
{"episode_reward": 170.01424377597417, "episode": 26.0, "batch_reward": 0.1547891805320978, "critic_loss": 0.2811063826978207, "actor_loss": -25.27707710266113, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.384379148483276, "step": 26000}
{"episode_reward": 147.96123840037802, "episode": 27.0, "batch_reward": 0.15687002594023944, "critic_loss": 0.3231317922025919, "actor_loss": -25.3839454164505, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.07861304283142, "step": 27000}
{"episode_reward": 260.680945299608, "episode": 28.0, "batch_reward": 0.15944771237671376, "critic_loss": 0.3513851934671402, "actor_loss": -25.079145817756654, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.21371102333069, "step": 28000}
{"episode_reward": 172.77439409019863, "episode": 29.0, "batch_reward": 0.16223683124035596, "critic_loss": 0.3163680918365717, "actor_loss": -25.81285877609253, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.840528964996338, "step": 29000}
{"episode_reward": 327.8335125439792, "episode": 30.0, "batch_reward": 0.16793945319950582, "critic_loss": 0.3671107241809368, "actor_loss": -25.79705353164673, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.712597846984863, "step": 30000}
{"episode_reward": 339.8604304699617, "episode": 31.0, "batch_reward": 0.17237638429552316, "critic_loss": 0.32920654368400576, "actor_loss": -26.851580465316772, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.52161979675293, "step": 31000}
{"episode_reward": 341.4944432535229, "episode": 32.0, "batch_reward": 0.17839725022017955, "critic_loss": 0.3543821699768305, "actor_loss": -26.926963411331176, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.251909732818604, "step": 32000}
{"episode_reward": 228.8415182351429, "episode": 33.0, "batch_reward": 0.1815084155499935, "critic_loss": 0.36255414701998234, "actor_loss": -27.847870962142945, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.520479679107666, "step": 33000}
{"episode_reward": 405.96356504701527, "episode": 34.0, "batch_reward": 0.18732469302415847, "critic_loss": 0.35929766039550304, "actor_loss": -27.570896558761596, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.22395396232605, "step": 34000}
{"episode_reward": 401.2599655699387, "episode": 35.0, "batch_reward": 0.19325701554119587, "critic_loss": 0.3511434479802847, "actor_loss": -28.742391254425048, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.301598072052002, "step": 35000}
{"episode_reward": 346.0605079855292, "episode": 36.0, "batch_reward": 0.19740569870173932, "critic_loss": 0.3678589096516371, "actor_loss": -28.185827529907225, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.0561306476593, "step": 36000}
{"episode_reward": 374.32489306026383, "episode": 37.0, "batch_reward": 0.2016298106610775, "critic_loss": 0.41228401972353457, "actor_loss": -29.32588726425171, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.61097264289856, "step": 37000}
{"episode_reward": 297.4488047027874, "episode": 38.0, "batch_reward": 0.2056566835194826, "critic_loss": 0.3969423068612814, "actor_loss": -29.875360717773436, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.784987688064575, "step": 38000}
{"episode_reward": 368.9682238790264, "episode": 39.0, "batch_reward": 0.20921986402571202, "critic_loss": 0.3978251207917929, "actor_loss": -30.369402481079103, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.27298641204834, "step": 39000}
{"episode_reward": 371.7691702901434, "episode": 40.0, "batch_reward": 0.21276392771303654, "critic_loss": 0.4174007436186075, "actor_loss": -30.99898369407654, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.102648735046387, "step": 40000}
{"episode_reward": 363.0895640275907, "episode": 41.0, "batch_reward": 0.2177599300444126, "critic_loss": 0.3692763608843088, "actor_loss": -31.09849139404297, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.54595470428467, "step": 41000}
{"episode_reward": 409.56039410192113, "episode": 42.0, "batch_reward": 0.22192954455316066, "critic_loss": 0.3660952815264463, "actor_loss": -31.07940383529663, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.00755500793457, "step": 42000}
{"episode_reward": 417.0534176203998, "episode": 43.0, "batch_reward": 0.22737532116472722, "critic_loss": 0.3708082466423511, "actor_loss": -31.63195789337158, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.78742241859436, "step": 43000}
{"episode_reward": 426.5770405998794, "episode": 44.0, "batch_reward": 0.2306172927170992, "critic_loss": 0.3474443269968033, "actor_loss": -31.77050361251831, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.826483249664307, "step": 44000}
{"episode_reward": 382.82453490792193, "episode": 45.0, "batch_reward": 0.2336340627670288, "critic_loss": 0.3800066850185394, "actor_loss": -32.582839235305784, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.532110452651978, "step": 45000}
{"episode_reward": 310.4753738761515, "episode": 46.0, "batch_reward": 0.23511265480518342, "critic_loss": 0.3974110733419657, "actor_loss": -32.519574275970456, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.05763530731201, "step": 46000}
{"episode_reward": 400.1076115340041, "episode": 47.0, "batch_reward": 0.2404732709825039, "critic_loss": 0.4091586381793022, "actor_loss": -33.3307544708252, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.107383966445923, "step": 47000}
{"episode_reward": 392.8810288904914, "episode": 48.0, "batch_reward": 0.24140915805101396, "critic_loss": 0.4189988845139742, "actor_loss": -32.52625727844238, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.794685125350952, "step": 48000}
{"episode_reward": 142.16863339863878, "episode": 49.0, "batch_reward": 0.2409752258360386, "critic_loss": 0.4164957605153322, "actor_loss": -33.394703586578366, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.82745122909546, "step": 49000}
{"episode_reward": 418.32599661669775, "episode": 50.0, "batch_reward": 0.24208345796167852, "critic_loss": 0.4917640580832958, "actor_loss": -33.47528824615478, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.510364532470703, "step": 50000}
{"episode_reward": 188.69603097837424, "episode": 51.0, "batch_reward": 0.2430969602763653, "critic_loss": 0.4617557678967714, "actor_loss": -33.458257228851316, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.40036058425903, "step": 51000}
{"episode_reward": 388.6597652077031, "episode": 52.0, "batch_reward": 0.24377956104278564, "critic_loss": 0.4907300358265638, "actor_loss": -33.46852845001221, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.247868061065674, "step": 52000}
{"episode_reward": 131.97141472863976, "episode": 53.0, "batch_reward": 0.24375954073667527, "critic_loss": 0.49371407425403596, "actor_loss": -33.24420565032959, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.85181164741516, "step": 53000}
{"episode_reward": 432.06649533517185, "episode": 54.0, "batch_reward": 0.24814083430171013, "critic_loss": 0.522871227607131, "actor_loss": -33.77252569961548, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.27757167816162, "step": 54000}
{"episode_reward": 450.05742833722456, "episode": 55.0, "batch_reward": 0.2518531034290791, "critic_loss": 0.5191695268601179, "actor_loss": -34.210812065124514, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.210386276245117, "step": 55000}
{"episode_reward": 389.3075951873686, "episode": 56.0, "batch_reward": 0.25363863433897493, "critic_loss": 0.5045023231506348, "actor_loss": -34.49731635284424, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.0920467376709, "step": 56000}
{"episode_reward": 443.9064460207728, "episode": 57.0, "batch_reward": 0.258059807524085, "critic_loss": 0.5144783686101436, "actor_loss": -34.76018182754517, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.93281388282776, "step": 57000}
{"episode_reward": 433.88222632870185, "episode": 58.0, "batch_reward": 0.2614719515144825, "critic_loss": 0.5024359266459942, "actor_loss": -34.79252276992798, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.801292419433594, "step": 58000}
{"episode_reward": 428.67816565175804, "episode": 59.0, "batch_reward": 0.263308326035738, "critic_loss": 0.4870883538722992, "actor_loss": -34.85168486022949, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.38197350502014, "step": 59000}
{"episode_reward": 443.68457120633053, "episode": 60.0, "batch_reward": 0.2664330457597971, "critic_loss": 0.5046467029005289, "actor_loss": -35.60813446426392, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.999991416931152, "step": 60000}
{"episode_reward": 457.40675894664366, "episode": 61.0, "batch_reward": 0.2695694947093725, "critic_loss": 0.4696424574553967, "actor_loss": -35.64209079360962, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.03688097000122, "step": 61000}
{"episode_reward": 458.68834507277364, "episode": 62.0, "batch_reward": 0.27210254776477816, "critic_loss": 0.4589633721858263, "actor_loss": -36.189873386383056, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.92348289489746, "step": 62000}
{"episode_reward": 454.3515107601526, "episode": 63.0, "batch_reward": 0.27471457700431345, "critic_loss": 0.45739132530987264, "actor_loss": -36.09750319671631, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.77683186531067, "step": 63000}
{"episode_reward": 439.09668583423, "episode": 64.0, "batch_reward": 0.27815172785520553, "critic_loss": 0.4226478399038315, "actor_loss": -36.55176243591308, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.52753472328186, "step": 64000}
{"episode_reward": 447.55358583915176, "episode": 65.0, "batch_reward": 0.27999668575823305, "critic_loss": 0.45640794913470745, "actor_loss": -36.72244483566284, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.757415771484375, "step": 65000}
{"episode_reward": 425.7430270577727, "episode": 66.0, "batch_reward": 0.2835840553343296, "critic_loss": 0.40496613408625126, "actor_loss": -37.0440085105896, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.77423667907715, "step": 66000}
{"episode_reward": 403.5381985074985, "episode": 67.0, "batch_reward": 0.2847082393467426, "critic_loss": 0.4218126167207956, "actor_loss": -37.29979424285889, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.875425815582275, "step": 67000}
{"episode_reward": 400.89750127693975, "episode": 68.0, "batch_reward": 0.2861974831670523, "critic_loss": 0.44914194229245186, "actor_loss": -36.946180992126465, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.82634401321411, "step": 68000}
{"episode_reward": 429.32029169338324, "episode": 69.0, "batch_reward": 0.2880629585832357, "critic_loss": 0.43522406959533694, "actor_loss": -37.218403442382815, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.813558340072632, "step": 69000}
{"episode_reward": 449.1927167562369, "episode": 70.0, "batch_reward": 0.28954058648645875, "critic_loss": 0.4286485263854265, "actor_loss": -37.86984810256958, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.593060970306396, "step": 70000}
{"episode_reward": 90.4056647089244, "episode": 71.0, "batch_reward": 0.28789808122813704, "critic_loss": 0.4380956392586231, "actor_loss": -37.603130084991456, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.715529441833496, "step": 71000}
{"episode_reward": 436.84584368977073, "episode": 72.0, "batch_reward": 0.2899756618887186, "critic_loss": 0.43911575511097906, "actor_loss": -37.4884174118042, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.919111013412476, "step": 72000}
{"episode_reward": 308.41564231211896, "episode": 73.0, "batch_reward": 0.29071190240979194, "critic_loss": 0.42870969270169734, "actor_loss": -37.6242652130127, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.645496129989624, "step": 73000}
{"episode_reward": 478.073703764629, "episode": 74.0, "batch_reward": 0.29263757744431496, "critic_loss": 0.4329119075089693, "actor_loss": -38.02693476867676, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.778361320495605, "step": 74000}
{"episode_reward": 398.9988139818638, "episode": 75.0, "batch_reward": 0.2946073661744595, "critic_loss": 0.44650401203334333, "actor_loss": -38.16975691223144, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.886685132980347, "step": 75000}
{"episode_reward": 447.38871880856306, "episode": 76.0, "batch_reward": 0.2965937765836716, "critic_loss": 0.42616720889508725, "actor_loss": -38.49099085235596, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.638852834701538, "step": 76000}
{"episode_reward": 436.73617018280413, "episode": 77.0, "batch_reward": 0.2981503006964922, "critic_loss": 0.43132269985973837, "actor_loss": -38.21982883834839, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.795661687850952, "step": 77000}
{"episode_reward": 413.9921491420843, "episode": 78.0, "batch_reward": 0.30013550049066545, "critic_loss": 0.41852876433730124, "actor_loss": -38.617440761566165, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.688358783721924, "step": 78000}
{"episode_reward": 402.38173778591994, "episode": 79.0, "batch_reward": 0.3006827519387007, "critic_loss": 0.4500757015347481, "actor_loss": -37.92412256622315, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.724254846572876, "step": 79000}
{"episode_reward": 452.9824238230387, "episode": 80.0, "batch_reward": 0.3028851759880781, "critic_loss": 0.4428040039241314, "actor_loss": -38.647892639160155, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.953821182250977, "step": 80000}
{"episode_reward": 442.81045143398137, "episode": 81.0, "batch_reward": 0.3054206192493439, "critic_loss": 0.4347798925191164, "actor_loss": -38.81934187698364, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.911765813827515, "step": 81000}
{"episode_reward": 458.81326290059206, "episode": 82.0, "batch_reward": 0.3070266782641411, "critic_loss": 0.42284426786005497, "actor_loss": -39.55942361831665, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.977436304092407, "step": 82000}
{"episode_reward": 438.61706398152353, "episode": 83.0, "batch_reward": 0.3081401236057281, "critic_loss": 0.3994397817403078, "actor_loss": -38.724100063323974, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.28560185432434, "step": 83000}
{"episode_reward": 438.7150467106277, "episode": 84.0, "batch_reward": 0.3097567585706711, "critic_loss": 0.42392640621960165, "actor_loss": -39.49483196640015, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.16402530670166, "step": 84000}
{"episode_reward": 416.3699224831162, "episode": 85.0, "batch_reward": 0.3104578115940094, "critic_loss": 0.39150674080848696, "actor_loss": -39.4482812461853, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.792104482650757, "step": 85000}
{"episode_reward": 404.62223356792646, "episode": 86.0, "batch_reward": 0.3116195811033249, "critic_loss": 0.36250728838145735, "actor_loss": -39.250646217346194, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.063159942626953, "step": 86000}
{"episode_reward": 449.1575557596514, "episode": 87.0, "batch_reward": 0.31308997970819474, "critic_loss": 0.35705089616775515, "actor_loss": -39.34345791244507, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.373342275619507, "step": 87000}
{"episode_reward": 403.79015174895704, "episode": 88.0, "batch_reward": 0.31389706960320474, "critic_loss": 0.34060919895768166, "actor_loss": -39.10277661895752, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.120709896087646, "step": 88000}
{"episode_reward": 452.8758353446702, "episode": 89.0, "batch_reward": 0.3154506722092629, "critic_loss": 0.3455508070886135, "actor_loss": -39.92738976287842, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.115127325057983, "step": 89000}
{"episode_reward": 425.0110281189329, "episode": 90.0, "batch_reward": 0.3168189586997032, "critic_loss": 0.3402573928683996, "actor_loss": -40.36664300918579, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.166221857070923, "step": 90000}
{"episode_reward": 417.9159521259563, "episode": 91.0, "batch_reward": 0.31894813251495363, "critic_loss": 0.3442691114246845, "actor_loss": -39.842695835113524, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.476571559906006, "step": 91000}
{"episode_reward": 457.4230847771931, "episode": 92.0, "batch_reward": 0.3205030396878719, "critic_loss": 0.34069152355194093, "actor_loss": -39.7630306854248, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.6522479057312, "step": 92000}
{"episode_reward": 430.1049353002147, "episode": 93.0, "batch_reward": 0.3203395816981792, "critic_loss": 0.3212711120247841, "actor_loss": -39.77599181747436, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.145777702331543, "step": 93000}
{"episode_reward": 410.13282401461703, "episode": 94.0, "batch_reward": 0.3224255647361279, "critic_loss": 0.3413415798693895, "actor_loss": -40.10072720336914, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.162135362625122, "step": 94000}
{"episode_reward": 405.0226203514043, "episode": 95.0, "batch_reward": 0.32278696647286415, "critic_loss": 0.33325908071547744, "actor_loss": -40.69321698379517, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.572704553604126, "step": 95000}
{"episode_reward": 432.251064304634, "episode": 96.0, "batch_reward": 0.3237966000139713, "critic_loss": 0.3297941378802061, "actor_loss": -40.78864862823486, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.870609283447266, "step": 96000}
{"episode_reward": 421.4744024386309, "episode": 97.0, "batch_reward": 0.3255111550986767, "critic_loss": 0.33248699456453323, "actor_loss": -40.95243857192993, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.147969245910645, "step": 97000}
{"episode_reward": 411.0792356006378, "episode": 98.0, "batch_reward": 0.3261362564563751, "critic_loss": 0.3541829281300306, "actor_loss": -40.304571449279784, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.81478762626648, "step": 98000}
{"episode_reward": 451.75331807333595, "episode": 99.0, "batch_reward": 0.3273202323317528, "critic_loss": 0.32173631721735, "actor_loss": -40.40510837173462, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.162922859191895, "step": 99000}
{"episode_reward": 431.3158667407494, "episode": 100.0, "batch_reward": 0.32890359607338904, "critic_loss": 0.3117408406957984, "actor_loss": -40.62533720779419, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.02754521369934, "step": 100000}
{"episode_reward": 415.18260644598655, "episode": 101.0, "batch_reward": 0.3293457249701023, "critic_loss": 0.3381755855828524, "actor_loss": -40.883439586639405, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.76522421836853, "step": 101000}
{"episode_reward": 435.26390197935734, "episode": 102.0, "batch_reward": 0.3296973400115967, "critic_loss": 0.3193618190735579, "actor_loss": -40.80390243530273, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.878486394882202, "step": 102000}
{"episode_reward": 436.12171082513413, "episode": 103.0, "batch_reward": 0.3305177800655365, "critic_loss": 0.33287639400362967, "actor_loss": -40.876263378143314, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89741277694702, "step": 103000}
{"episode_reward": 413.571117547873, "episode": 104.0, "batch_reward": 0.333136248588562, "critic_loss": 0.3223242998868227, "actor_loss": -41.02985591506958, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.814932823181152, "step": 104000}
{"episode_reward": 410.78249428871607, "episode": 105.0, "batch_reward": 0.3334964355528355, "critic_loss": 0.31560053753852846, "actor_loss": -41.016313430786134, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.045346975326538, "step": 105000}
{"episode_reward": 419.22231202191074, "episode": 106.0, "batch_reward": 0.33297793766856193, "critic_loss": 0.31868698592483996, "actor_loss": -40.56132940292358, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.962092399597168, "step": 106000}
{"episode_reward": 445.4141818720919, "episode": 107.0, "batch_reward": 0.33479437085986136, "critic_loss": 0.3007498926371336, "actor_loss": -41.101878799438474, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.1141197681427, "step": 107000}
{"episode_reward": 447.64439359114664, "episode": 108.0, "batch_reward": 0.3360625278055668, "critic_loss": 0.3167086421251297, "actor_loss": -41.19566897583008, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.414701461791992, "step": 108000}
{"episode_reward": 452.5389446047776, "episode": 109.0, "batch_reward": 0.33706603667140006, "critic_loss": 0.30427616433799265, "actor_loss": -41.70516893005371, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.813403367996216, "step": 109000}
{"episode_reward": 428.9770716983733, "episode": 110.0, "batch_reward": 0.33747909754514693, "critic_loss": 0.307778905287385, "actor_loss": -41.25810432434082, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.10086941719055, "step": 110000}
{"episode_reward": 426.446486285723, "episode": 111.0, "batch_reward": 0.33854170349240303, "critic_loss": 0.33104162618517874, "actor_loss": -42.01278560638428, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.74115490913391, "step": 111000}
{"episode_reward": 432.47453249679796, "episode": 112.0, "batch_reward": 0.33943169251084326, "critic_loss": 0.2953428169041872, "actor_loss": -41.524821773529055, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.04551410675049, "step": 112000}
{"episode_reward": 414.47465667393914, "episode": 113.0, "batch_reward": 0.3402483206987381, "critic_loss": 0.3001892441958189, "actor_loss": -41.57240535736084, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.962597370147705, "step": 113000}
{"episode_reward": 414.79600084450846, "episode": 114.0, "batch_reward": 0.3412056245207787, "critic_loss": 0.31844954177737234, "actor_loss": -42.01244809341431, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.608579635620117, "step": 114000}
{"episode_reward": 417.22725695736506, "episode": 115.0, "batch_reward": 0.3417089698910713, "critic_loss": 0.3560453268736601, "actor_loss": -41.80845679092407, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.09492039680481, "step": 115000}
{"episode_reward": 454.73694676868377, "episode": 116.0, "batch_reward": 0.34237986627221106, "critic_loss": 0.35913463762402537, "actor_loss": -41.9138470916748, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.937358617782593, "step": 116000}
{"episode_reward": 424.46243717700315, "episode": 117.0, "batch_reward": 0.34337740698456765, "critic_loss": 0.3519511452913284, "actor_loss": -41.87636380004883, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.77885890007019, "step": 117000}
{"episode_reward": 447.01901858703934, "episode": 118.0, "batch_reward": 0.3436293041110039, "critic_loss": 0.33330275778472424, "actor_loss": -42.04487110519409, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.417964220046997, "step": 118000}
{"episode_reward": 450.5767328821093, "episode": 119.0, "batch_reward": 0.34505422741174696, "critic_loss": 0.3104466444551945, "actor_loss": -42.305398311614994, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.015448331832886, "step": 119000}
{"episode_reward": 446.921148280621, "episode": 120.0, "batch_reward": 0.34549798145890237, "critic_loss": 0.31991479913890364, "actor_loss": -41.835294967651365, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.980414867401123, "step": 120000}
{"episode_reward": 449.48079343731587, "episode": 121.0, "batch_reward": 0.34681900864839554, "critic_loss": 0.31648292142152784, "actor_loss": -42.04336940002442, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.53148341178894, "step": 121000}
{"episode_reward": 392.73476232754655, "episode": 122.0, "batch_reward": 0.3475312546491623, "critic_loss": 0.3159930858165026, "actor_loss": -42.104760410308835, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.305142402648926, "step": 122000}
{"episode_reward": 447.29012049447806, "episode": 123.0, "batch_reward": 0.34875783529877663, "critic_loss": 0.306362632215023, "actor_loss": -41.395374660491946, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.05367136001587, "step": 123000}
{"episode_reward": 472.4271973653331, "episode": 124.0, "batch_reward": 0.3488080988228321, "critic_loss": 0.2863803691267967, "actor_loss": -42.279457035064695, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.897583723068237, "step": 124000}
{"episode_reward": 429.9514236388406, "episode": 125.0, "batch_reward": 0.3503054144382477, "critic_loss": 0.3303873687684536, "actor_loss": -42.370810638427734, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.337787866592407, "step": 125000}
{"episode_reward": 411.6717512927135, "episode": 126.0, "batch_reward": 0.34931044670939443, "critic_loss": 0.3050113395750523, "actor_loss": -42.39725942230225, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.919689893722534, "step": 126000}
{"episode_reward": 443.45419004087984, "episode": 127.0, "batch_reward": 0.35039175242185594, "critic_loss": 0.3082134375870228, "actor_loss": -42.42742370223999, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.346380710601807, "step": 127000}
{"episode_reward": 438.3648310708797, "episode": 128.0, "batch_reward": 0.35188189369440076, "critic_loss": 0.2997069344967604, "actor_loss": -43.08633973312378, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.343950510025024, "step": 128000}
{"episode_reward": 410.62094382303223, "episode": 129.0, "batch_reward": 0.3516187451481819, "critic_loss": 0.32728900368511676, "actor_loss": -43.09930598831177, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.26083207130432, "step": 129000}
{"episode_reward": 427.7103156414463, "episode": 130.0, "batch_reward": 0.35241272535920143, "critic_loss": 0.34238867537677287, "actor_loss": -42.81572332382202, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.238829612731934, "step": 130000}
{"episode_reward": 427.33621846218256, "episode": 131.0, "batch_reward": 0.3532206851840019, "critic_loss": 0.34232712735235693, "actor_loss": -43.484587593078615, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.7994704246521, "step": 131000}
{"episode_reward": 451.5708448096531, "episode": 132.0, "batch_reward": 0.3545026220679283, "critic_loss": 0.32275916743278504, "actor_loss": -43.02405500411987, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.933823823928833, "step": 132000}
{"episode_reward": 462.78006954272837, "episode": 133.0, "batch_reward": 0.35475350126624106, "critic_loss": 0.32113365218043327, "actor_loss": -43.175597869873044, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.958157777786255, "step": 133000}
{"episode_reward": 457.71374142685704, "episode": 134.0, "batch_reward": 0.3550004200935364, "critic_loss": 0.32149618792533874, "actor_loss": -43.30084703063965, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.533997297286987, "step": 134000}
{"episode_reward": 209.23681756053966, "episode": 135.0, "batch_reward": 0.35389905056357385, "critic_loss": 0.33081942684948445, "actor_loss": -43.194681629180906, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.241305828094482, "step": 135000}
{"episode_reward": 455.62651741257633, "episode": 136.0, "batch_reward": 0.3555262000262737, "critic_loss": 0.3384986415058374, "actor_loss": -43.79763338088989, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.27914047241211, "step": 136000}
{"episode_reward": 442.8178059806794, "episode": 137.0, "batch_reward": 0.3552249599695206, "critic_loss": 0.33524662083387374, "actor_loss": -43.04494329071045, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.813353300094604, "step": 137000}
{"episode_reward": 452.2265484195678, "episode": 138.0, "batch_reward": 0.3569905368089676, "critic_loss": 0.3407443544566631, "actor_loss": -42.90529249191284, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.86672329902649, "step": 138000}
{"episode_reward": 471.6730809891044, "episode": 139.0, "batch_reward": 0.35738667663931845, "critic_loss": 0.32000927402079105, "actor_loss": -43.0324778137207, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.284197568893433, "step": 139000}
{"episode_reward": 474.369902156279, "episode": 140.0, "batch_reward": 0.35802382144331935, "critic_loss": 0.3240317940115929, "actor_loss": -42.96958451461792, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.57225489616394, "step": 140000}
{"episode_reward": 453.57778343841863, "episode": 141.0, "batch_reward": 0.35877409067749977, "critic_loss": 0.3066557862460613, "actor_loss": -42.94999264907837, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.35663104057312, "step": 141000}
{"episode_reward": 472.59488509776145, "episode": 142.0, "batch_reward": 0.359771166652441, "critic_loss": 0.3113819813430309, "actor_loss": -43.45027444839477, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.833076000213623, "step": 142000}
{"episode_reward": 470.65784391093763, "episode": 143.0, "batch_reward": 0.36122082886099816, "critic_loss": 0.31649992398917676, "actor_loss": -43.58647369003296, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.374517917633057, "step": 143000}
{"episode_reward": 484.1139977229556, "episode": 144.0, "batch_reward": 0.360983520925045, "critic_loss": 0.3283123906850815, "actor_loss": -43.70067307662964, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.972867488861084, "step": 144000}
{"episode_reward": 462.06032229086946, "episode": 145.0, "batch_reward": 0.3622130883038044, "critic_loss": 0.30153806507587433, "actor_loss": -43.70317928695679, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.83069133758545, "step": 145000}
{"episode_reward": 474.0500788615259, "episode": 146.0, "batch_reward": 0.36257060173153877, "critic_loss": 0.3017306586802006, "actor_loss": -43.629172088623044, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.227837324142456, "step": 146000}
{"episode_reward": 437.0927017383413, "episode": 147.0, "batch_reward": 0.36316995647549627, "critic_loss": 0.3087449582442641, "actor_loss": -43.922431407928464, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.319299459457397, "step": 147000}
{"episode_reward": 405.90390408660716, "episode": 148.0, "batch_reward": 0.36380767384171486, "critic_loss": 0.2950129590183497, "actor_loss": -43.441323585510254, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.58594822883606, "step": 148000}
{"episode_reward": 483.6555905741581, "episode": 149.0, "batch_reward": 0.36405985525250434, "critic_loss": 0.32186909480392933, "actor_loss": -43.82993614959717, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.629537343978882, "step": 149000}
{"episode_reward": 460.44226771999826, "episode": 150.0, "batch_reward": 0.3656459451913834, "critic_loss": 0.3191968810558319, "actor_loss": -43.820248718261716, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
