{"episode_reward": 0.0, "episode": 1.0, "duration": 13.995110511779785, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.235203504562378, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.2197336912175026, "critic_loss": 0.0942919524308889, "actor_loss": -35.388800683308716, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 76.16844058036804, "step": 3000}
{"episode_reward": 38.48019423619919, "episode": 4.0, "batch_reward": 0.14488514044135808, "critic_loss": 0.040543307177722455, "actor_loss": -27.99918653011322, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.905956268310547, "step": 4000}
{"episode_reward": 6.187217294576205, "episode": 5.0, "batch_reward": 0.11271137957274914, "critic_loss": 0.0312754219500348, "actor_loss": -27.982078166007994, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.77785062789917, "step": 5000}
{"episode_reward": 10.22265870296088, "episode": 6.0, "batch_reward": 0.09431748874112963, "critic_loss": 0.02850559360999614, "actor_loss": -26.065622310638428, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.30509662628174, "step": 6000}
{"episode_reward": 12.744448472895806, "episode": 7.0, "batch_reward": 0.08224468022584915, "critic_loss": 0.02964164878707379, "actor_loss": -24.085510233879088, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.941226482391357, "step": 7000}
{"episode_reward": 21.261632832730452, "episode": 8.0, "batch_reward": 0.07468778180703521, "critic_loss": 0.0380705062802881, "actor_loss": -24.21651627635956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.29807686805725, "step": 8000}
{"episode_reward": 27.710602627779835, "episode": 9.0, "batch_reward": 0.06975725229829549, "critic_loss": 0.05275075595267117, "actor_loss": -21.672698692321777, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.00267243385315, "step": 9000}
{"episode_reward": 29.695208477117912, "episode": 10.0, "batch_reward": 0.06517056059092283, "critic_loss": 0.04499101590551436, "actor_loss": -22.8053727684021, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.895524501800537, "step": 10000}
{"episode_reward": 29.88763772461512, "episode": 11.0, "batch_reward": 0.06415144451707601, "critic_loss": 0.06706414361298084, "actor_loss": -21.19420520877838, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.47944355010986, "step": 11000}
{"episode_reward": 73.14637881514268, "episode": 12.0, "batch_reward": 0.06489397851005196, "critic_loss": 0.10012174382060766, "actor_loss": -21.035217312812804, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.788329601287842, "step": 12000}
{"episode_reward": 84.18805409140211, "episode": 13.0, "batch_reward": 0.0695113010108471, "critic_loss": 0.15927384980395437, "actor_loss": -20.57713775110245, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.88200879096985, "step": 13000}
{"episode_reward": 139.84977268798886, "episode": 14.0, "batch_reward": 0.0712064389847219, "critic_loss": 0.16494114463031292, "actor_loss": -21.444077879905702, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.160383939743042, "step": 14000}
{"episode_reward": 36.20105651319048, "episode": 15.0, "batch_reward": 0.07193686556443572, "critic_loss": 0.15920036877691746, "actor_loss": -18.891800971508026, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.690953016281128, "step": 15000}
{"episode_reward": 161.70638011962617, "episode": 16.0, "batch_reward": 0.07612913380935789, "critic_loss": 0.17215214211493732, "actor_loss": -19.20434707927704, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.34695553779602, "step": 16000}
{"episode_reward": 80.28050858844122, "episode": 17.0, "batch_reward": 0.07533942646160721, "critic_loss": 0.18505681227892637, "actor_loss": -19.43879664206505, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.28447151184082, "step": 17000}
{"episode_reward": 39.5092772127781, "episode": 18.0, "batch_reward": 0.07282173069566489, "critic_loss": 0.1550558721497655, "actor_loss": -18.542121529221536, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.610057830810547, "step": 18000}
{"episode_reward": 26.345161943558512, "episode": 19.0, "batch_reward": 0.07095909972116352, "critic_loss": 0.15095045682415367, "actor_loss": -16.95933545957506, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.95250940322876, "step": 19000}
{"episode_reward": 44.76476433709875, "episode": 20.0, "batch_reward": 0.07264285350590945, "critic_loss": 0.17145360898971557, "actor_loss": -16.719829003244637, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.23851180076599, "step": 20000}
{"episode_reward": 205.22604596290128, "episode": 21.0, "batch_reward": 0.08042941956594586, "critic_loss": 0.16847559683024882, "actor_loss": -16.395104963093996, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.57901668548584, "step": 21000}
{"episode_reward": 247.26294035865072, "episode": 22.0, "batch_reward": 0.08853968288376927, "critic_loss": 0.1556515968106687, "actor_loss": -17.82309673523903, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.512426614761353, "step": 22000}
{"episode_reward": 259.3791322578283, "episode": 23.0, "batch_reward": 0.0950871732160449, "critic_loss": 0.16731309104710818, "actor_loss": -19.037177421092988, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.946717739105225, "step": 23000}
{"episode_reward": 125.5902247899926, "episode": 24.0, "batch_reward": 0.09519911296293139, "critic_loss": 0.16399752534925938, "actor_loss": -17.80266199350357, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.293989658355713, "step": 24000}
{"episode_reward": 115.07155844204706, "episode": 25.0, "batch_reward": 0.09689467068761587, "critic_loss": 0.163798608135432, "actor_loss": -18.505195760726927, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.50396418571472, "step": 25000}
{"episode_reward": 125.51744629511508, "episode": 26.0, "batch_reward": 0.0981823304593563, "critic_loss": 0.15389286393672227, "actor_loss": -18.560294227600096, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.683051347732544, "step": 26000}
{"episode_reward": 144.0934276877918, "episode": 27.0, "batch_reward": 0.10042922622710466, "critic_loss": 0.17025722192972897, "actor_loss": -18.473643659591676, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.809635639190674, "step": 27000}
{"episode_reward": 185.96606511802767, "episode": 28.0, "batch_reward": 0.10275907359272242, "critic_loss": 0.19539079147577285, "actor_loss": -18.47089194583893, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.253681182861328, "step": 28000}
{"episode_reward": 132.58219599647757, "episode": 29.0, "batch_reward": 0.10488717882335186, "critic_loss": 0.18638389918208123, "actor_loss": -17.336212310791016, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.965440273284912, "step": 29000}
{"episode_reward": 143.87731365586194, "episode": 30.0, "batch_reward": 0.1078998056948185, "critic_loss": 0.18871779239177705, "actor_loss": -17.86044094467163, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.60281538963318, "step": 30000}
{"episode_reward": 337.65956247095596, "episode": 31.0, "batch_reward": 0.11194682714343071, "critic_loss": 0.23959846380352973, "actor_loss": -17.451113498687743, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.358890533447266, "step": 31000}
{"episode_reward": 94.8411593712183, "episode": 32.0, "batch_reward": 0.1133511755540967, "critic_loss": 0.19687153147906064, "actor_loss": -17.57158194065094, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.709579706192017, "step": 32000}
{"episode_reward": 164.1208696411399, "episode": 33.0, "batch_reward": 0.1146924542710185, "critic_loss": 0.20729365937411784, "actor_loss": -17.31970814037323, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.16005277633667, "step": 33000}
{"episode_reward": 137.02376561742008, "episode": 34.0, "batch_reward": 0.11281338589638472, "critic_loss": 0.23276995200663805, "actor_loss": -18.365965205192566, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.30776286125183, "step": 34000}
{"episode_reward": 30.372160674299742, "episode": 35.0, "batch_reward": 0.11105932348221541, "critic_loss": 0.25415736309438947, "actor_loss": -16.828802982330323, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.352224111557007, "step": 35000}
{"episode_reward": 58.976650072874584, "episode": 36.0, "batch_reward": 0.10925812693685293, "critic_loss": 0.2702535994052887, "actor_loss": -17.461062514305116, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.658644437789917, "step": 36000}
{"episode_reward": 79.34482290376558, "episode": 37.0, "batch_reward": 0.10804285991936922, "critic_loss": 0.2522884997949004, "actor_loss": -16.616535022735597, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.061517477035522, "step": 37000}
{"episode_reward": 69.5725676175143, "episode": 38.0, "batch_reward": 0.10989115262031555, "critic_loss": 0.2768157905638218, "actor_loss": -16.12558734703064, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.313029527664185, "step": 38000}
{"episode_reward": 194.22872929172726, "episode": 39.0, "batch_reward": 0.10927663014829159, "critic_loss": 0.2581632492020726, "actor_loss": -15.76621375656128, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.587014198303223, "step": 39000}
{"episode_reward": 45.88996165442962, "episode": 40.0, "batch_reward": 0.11148731959611177, "critic_loss": 0.24366202580183743, "actor_loss": -15.932155071258546, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.99374771118164, "step": 40000}
{"episode_reward": 320.15850969058147, "episode": 41.0, "batch_reward": 0.11622445721179248, "critic_loss": 0.2928064596503973, "actor_loss": -16.541513948440553, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.43284630775452, "step": 41000}
{"episode_reward": 195.60372133705218, "episode": 42.0, "batch_reward": 0.11502962099015712, "critic_loss": 0.25121181283891203, "actor_loss": -16.594164375305176, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.736976385116577, "step": 42000}
{"episode_reward": 63.045509616322256, "episode": 43.0, "batch_reward": 0.11457851769775153, "critic_loss": 0.24767111137509346, "actor_loss": -16.25358041381836, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.574963331222534, "step": 43000}
{"episode_reward": 89.97788752798704, "episode": 44.0, "batch_reward": 0.11679744041711092, "critic_loss": 0.27429998138546946, "actor_loss": -16.480586805343627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.752598762512207, "step": 44000}
{"episode_reward": 391.8383016390394, "episode": 45.0, "batch_reward": 0.12216157020628453, "critic_loss": 0.2491922005712986, "actor_loss": -16.621197481155395, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.458513259887695, "step": 45000}
{"episode_reward": 361.975617536616, "episode": 46.0, "batch_reward": 0.12595501200854778, "critic_loss": 0.2707857528552413, "actor_loss": -17.302953691482543, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.978635787963867, "step": 46000}
{"episode_reward": 111.32921117508336, "episode": 47.0, "batch_reward": 0.1275113476589322, "critic_loss": 0.27888788691163063, "actor_loss": -16.583090213775634, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.21269178390503, "step": 47000}
{"episode_reward": 202.625542993409, "episode": 48.0, "batch_reward": 0.12652658212929965, "critic_loss": 0.2557914900034666, "actor_loss": -17.281548969268798, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.75585389137268, "step": 48000}
{"episode_reward": 53.01299982089732, "episode": 49.0, "batch_reward": 0.1277234815955162, "critic_loss": 0.24019519490003585, "actor_loss": -16.65043502616882, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.52190899848938, "step": 49000}
{"episode_reward": 381.45871940892624, "episode": 50.0, "batch_reward": 0.12965008940547704, "critic_loss": 0.26133760358393193, "actor_loss": -17.081978605270386, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.247032642364502, "step": 50000}
{"episode_reward": 69.87586442957024, "episode": 51.0, "batch_reward": 0.12928400943428278, "critic_loss": 0.2613302139788866, "actor_loss": -17.056380266189574, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.795565128326416, "step": 51000}
{"episode_reward": 68.83537394272182, "episode": 52.0, "batch_reward": 0.1300538212880492, "critic_loss": 0.2745537866950035, "actor_loss": -17.35645279121399, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.195958137512207, "step": 52000}
{"episode_reward": 211.30930900895808, "episode": 53.0, "batch_reward": 0.1313736488223076, "critic_loss": 0.2804438584446907, "actor_loss": -17.438132513046266, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.66696286201477, "step": 53000}
{"episode_reward": 366.6742113996373, "episode": 54.0, "batch_reward": 0.1346738391444087, "critic_loss": 0.3155566366314888, "actor_loss": -18.082616207122804, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.297521829605103, "step": 54000}
{"episode_reward": 150.68544372547456, "episode": 55.0, "batch_reward": 0.13496848829835653, "critic_loss": 0.28705719400942326, "actor_loss": -17.714996723175048, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.744929313659668, "step": 55000}
{"episode_reward": 89.97149359982005, "episode": 56.0, "batch_reward": 0.1357991056293249, "critic_loss": 0.29617078487575055, "actor_loss": -18.039357765197753, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.84585475921631, "step": 56000}
{"episode_reward": 380.2922851194428, "episode": 57.0, "batch_reward": 0.14049467550963163, "critic_loss": 0.3294344079270959, "actor_loss": -18.934296787261964, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.324220657348633, "step": 57000}
{"episode_reward": 465.55189841379143, "episode": 58.0, "batch_reward": 0.14634908623993398, "critic_loss": 0.30549610778689384, "actor_loss": -19.586135320663452, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.843114376068115, "step": 58000}
{"episode_reward": 440.0137003715319, "episode": 59.0, "batch_reward": 0.1520149851962924, "critic_loss": 0.29662512384355066, "actor_loss": -20.270317882537842, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.052554607391357, "step": 59000}
{"episode_reward": 463.0917247162707, "episode": 60.0, "batch_reward": 0.15575209231674672, "critic_loss": 0.270303960159421, "actor_loss": -20.696460725784302, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.327274560928345, "step": 60000}
{"episode_reward": 244.95017420240916, "episode": 61.0, "batch_reward": 0.158451781027019, "critic_loss": 0.26610237030684947, "actor_loss": -21.244396718978884, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.73175621032715, "step": 61000}
{"episode_reward": 449.91832449406826, "episode": 62.0, "batch_reward": 0.16268956588953734, "critic_loss": 0.24786233507096767, "actor_loss": -21.145646324157713, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.460065126419067, "step": 62000}
{"episode_reward": 322.6088987346573, "episode": 63.0, "batch_reward": 0.1613960660174489, "critic_loss": 0.2975301454886794, "actor_loss": -21.388510969161988, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.4556303024292, "step": 63000}
{"episode_reward": 30.359271385844824, "episode": 64.0, "batch_reward": 0.16297653336077927, "critic_loss": 0.28477426132559774, "actor_loss": -21.54528981399536, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.349097967147827, "step": 64000}
{"episode_reward": 424.8606309036241, "episode": 65.0, "batch_reward": 0.16727559739351272, "critic_loss": 0.2799540852084756, "actor_loss": -22.249791442871093, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.877056121826172, "step": 65000}
{"episode_reward": 461.94604065621934, "episode": 66.0, "batch_reward": 0.1726098244562745, "critic_loss": 0.31685951045155525, "actor_loss": -22.50931350708008, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.262025117874146, "step": 66000}
{"episode_reward": 413.00480116316936, "episode": 67.0, "batch_reward": 0.17528825218230487, "critic_loss": 0.329190497495234, "actor_loss": -22.585188941955565, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.262216567993164, "step": 67000}
{"episode_reward": 489.52995665906633, "episode": 68.0, "batch_reward": 0.1805177305340767, "critic_loss": 0.3184583892300725, "actor_loss": -23.429252437591554, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.328471660614014, "step": 68000}
{"episode_reward": 456.14130608058696, "episode": 69.0, "batch_reward": 0.18212667244672776, "critic_loss": 0.3169846003502607, "actor_loss": -23.42253364944458, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.116737365722656, "step": 69000}
{"episode_reward": 232.30703701450724, "episode": 70.0, "batch_reward": 0.1847125173062086, "critic_loss": 0.30378660263121127, "actor_loss": -23.60100325012207, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.44065809249878, "step": 70000}
{"episode_reward": 473.46082250408745, "episode": 71.0, "batch_reward": 0.18944149388372897, "critic_loss": 0.2991256465762854, "actor_loss": -23.93854782485962, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.97748947143555, "step": 71000}
{"episode_reward": 505.13094725991454, "episode": 72.0, "batch_reward": 0.19312213635444642, "critic_loss": 0.28866737907379864, "actor_loss": -24.317700542449952, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.572667598724365, "step": 72000}
{"episode_reward": 505.93232469750797, "episode": 73.0, "batch_reward": 0.1977493010610342, "critic_loss": 0.2961545944660902, "actor_loss": -24.831006080627443, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.652682542800903, "step": 73000}
{"episode_reward": 484.77977831100674, "episode": 74.0, "batch_reward": 0.20067563228309154, "critic_loss": 0.2864698460996151, "actor_loss": -24.936027030944825, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.04096531867981, "step": 74000}
{"episode_reward": 484.34547799696577, "episode": 75.0, "batch_reward": 0.2064404990375042, "critic_loss": 0.2840551786497235, "actor_loss": -25.736254238128662, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.719956874847412, "step": 75000}
{"episode_reward": 533.1078154472043, "episode": 76.0, "batch_reward": 0.20912056918442248, "critic_loss": 0.26589868453145027, "actor_loss": -25.846428268432618, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.28241229057312, "step": 76000}
{"episode_reward": 499.5281499519473, "episode": 77.0, "batch_reward": 0.2137150312513113, "critic_loss": 0.2713878310099244, "actor_loss": -26.585551666259764, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.04818868637085, "step": 77000}
{"episode_reward": 532.7801884727388, "episode": 78.0, "batch_reward": 0.21895766961574553, "critic_loss": 0.26391537571698426, "actor_loss": -26.71429181289673, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.703086614608765, "step": 78000}
{"episode_reward": 548.7009257736261, "episode": 79.0, "batch_reward": 0.22095567151904105, "critic_loss": 0.2585926310047507, "actor_loss": -27.573029846191407, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.575563430786133, "step": 79000}
{"episode_reward": 414.75333649998663, "episode": 80.0, "batch_reward": 0.22341483187675476, "critic_loss": 0.2823425465002656, "actor_loss": -27.314715686798095, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.28531289100647, "step": 80000}
{"episode_reward": 512.8931753567914, "episode": 81.0, "batch_reward": 0.22882989740371704, "critic_loss": 0.30951358541846274, "actor_loss": -27.875106727600098, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.149508237838745, "step": 81000}
{"episode_reward": 521.6403052137534, "episode": 82.0, "batch_reward": 0.23267188589274884, "critic_loss": 0.2826569459661841, "actor_loss": -27.837281162261963, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.990694999694824, "step": 82000}
{"episode_reward": 532.6767091013434, "episode": 83.0, "batch_reward": 0.23582601657509802, "critic_loss": 0.30667572885751726, "actor_loss": -28.639444091796875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.597811460494995, "step": 83000}
{"episode_reward": 496.15505981332194, "episode": 84.0, "batch_reward": 0.2389808730483055, "critic_loss": 0.29082473627477884, "actor_loss": -28.251459400177, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.036551475524902, "step": 84000}
{"episode_reward": 519.9219937271648, "episode": 85.0, "batch_reward": 0.23951236295700074, "critic_loss": 0.27752653120458126, "actor_loss": -28.86223512649536, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.239105701446533, "step": 85000}
{"episode_reward": 120.31700200244963, "episode": 86.0, "batch_reward": 0.2387249570041895, "critic_loss": 0.28606546127051113, "actor_loss": -28.833036262512206, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.11562156677246, "step": 86000}
{"episode_reward": 140.8784451906446, "episode": 87.0, "batch_reward": 0.23845466922223568, "critic_loss": 0.2853004627376795, "actor_loss": -28.858764747619627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.176916122436523, "step": 87000}
{"episode_reward": 314.17363844652095, "episode": 88.0, "batch_reward": 0.23993518874049186, "critic_loss": 0.295027751930058, "actor_loss": -29.363646991729738, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.10214924812317, "step": 88000}
{"episode_reward": 424.6780544287683, "episode": 89.0, "batch_reward": 0.24263912066817284, "critic_loss": 0.33985131134092805, "actor_loss": -29.313498134613038, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.582927465438843, "step": 89000}
{"episode_reward": 520.8676396078226, "episode": 90.0, "batch_reward": 0.24529220099747182, "critic_loss": 0.2944421762824059, "actor_loss": -29.33168410873413, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.896510362625122, "step": 90000}
{"episode_reward": 522.338350985267, "episode": 91.0, "batch_reward": 0.24867853538691997, "critic_loss": 0.28397677520662545, "actor_loss": -29.769222919464113, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.79853677749634, "step": 91000}
{"episode_reward": 550.7109822487718, "episode": 92.0, "batch_reward": 0.25219494351744653, "critic_loss": 0.3002306931614876, "actor_loss": -30.02722543334961, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.127046823501587, "step": 92000}
{"episode_reward": 536.2670165014757, "episode": 93.0, "batch_reward": 0.2542915329486132, "critic_loss": 0.2861502245143056, "actor_loss": -30.47241617202759, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.61998677253723, "step": 93000}
{"episode_reward": 550.9986898143351, "episode": 94.0, "batch_reward": 0.25788418506085875, "critic_loss": 0.27118670254945754, "actor_loss": -30.62261368179321, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.860244750976562, "step": 94000}
{"episode_reward": 366.25120059258535, "episode": 95.0, "batch_reward": 0.25838388049602506, "critic_loss": 0.28086897114664316, "actor_loss": -30.700760288238527, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.742594957351685, "step": 95000}
{"episode_reward": 542.4378892189296, "episode": 96.0, "batch_reward": 0.26210627257823943, "critic_loss": 0.2824812185242772, "actor_loss": -31.037744735717773, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.673219919204712, "step": 96000}
{"episode_reward": 462.4086623818202, "episode": 97.0, "batch_reward": 0.26379987540841104, "critic_loss": 0.28882879389077426, "actor_loss": -31.243073947906495, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.37796926498413, "step": 97000}
{"episode_reward": 492.23301357828296, "episode": 98.0, "batch_reward": 0.2665125967860222, "critic_loss": 0.30603968688100575, "actor_loss": -31.57306851196289, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.625649452209473, "step": 98000}
{"episode_reward": 559.483104435938, "episode": 99.0, "batch_reward": 0.2699257984161377, "critic_loss": 0.29279847648739815, "actor_loss": -32.082516063690186, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.655882358551025, "step": 99000}
{"episode_reward": 541.428082394085, "episode": 100.0, "batch_reward": 0.2728777723759413, "critic_loss": 0.29589040584117177, "actor_loss": -32.12702612686157, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.51716661453247, "step": 100000}
{"episode_reward": 524.1025123729282, "episode": 101.0, "batch_reward": 0.27425166752934454, "critic_loss": 0.3085525654181838, "actor_loss": -32.21216189956665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.669313192367554, "step": 101000}
{"episode_reward": 556.7138207867052, "episode": 102.0, "batch_reward": 0.27672161531448364, "critic_loss": 0.2889117218703032, "actor_loss": -32.603818531036374, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.152370929718018, "step": 102000}
{"episode_reward": 571.2191553357212, "episode": 103.0, "batch_reward": 0.2795761580169201, "critic_loss": 0.2957561063915491, "actor_loss": -32.67786343765259, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.128315210342407, "step": 103000}
{"episode_reward": 540.9082943483269, "episode": 104.0, "batch_reward": 0.28358457715809343, "critic_loss": 0.2828790311291814, "actor_loss": -32.910613723754885, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.9979350566864, "step": 104000}
{"episode_reward": 514.0924272539921, "episode": 105.0, "batch_reward": 0.2845466474294662, "critic_loss": 0.26888579834252596, "actor_loss": -33.08005438613892, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.864322423934937, "step": 105000}
{"episode_reward": 525.6925186326582, "episode": 106.0, "batch_reward": 0.28675390338897705, "critic_loss": 0.259805063419044, "actor_loss": -33.42211143112183, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.317181825637817, "step": 106000}
{"episode_reward": 509.5029622578167, "episode": 107.0, "batch_reward": 0.2896393560320139, "critic_loss": 0.2792465262040496, "actor_loss": -33.54173543167114, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.23490309715271, "step": 107000}
{"episode_reward": 535.6659238976341, "episode": 108.0, "batch_reward": 0.29236324697732924, "critic_loss": 0.28002995877712966, "actor_loss": -33.950129737854006, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.84955406188965, "step": 108000}
{"episode_reward": 554.3230296000089, "episode": 109.0, "batch_reward": 0.2946659629791975, "critic_loss": 0.24815387561172247, "actor_loss": -33.752049514770505, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.856630563735962, "step": 109000}
{"episode_reward": 556.8123896582969, "episode": 110.0, "batch_reward": 0.29688041535019877, "critic_loss": 0.26374833308905365, "actor_loss": -34.09710345458984, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.9753201007843, "step": 110000}
{"episode_reward": 553.1501667222203, "episode": 111.0, "batch_reward": 0.2985642714500427, "critic_loss": 0.2741187871694565, "actor_loss": -34.352316246032714, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.4174063205719, "step": 111000}
{"episode_reward": 522.5496662218171, "episode": 112.0, "batch_reward": 0.30076750928163526, "critic_loss": 0.28684063723683356, "actor_loss": -34.746151752471924, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.119483709335327, "step": 112000}
{"episode_reward": 530.0184772805479, "episode": 113.0, "batch_reward": 0.30317016172409056, "critic_loss": 0.26390928391367197, "actor_loss": -34.667304271698, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.618842124938965, "step": 113000}
{"episode_reward": 534.5457908456748, "episode": 114.0, "batch_reward": 0.3058905664384365, "critic_loss": 0.27270065309107305, "actor_loss": -34.88395680999756, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.67579746246338, "step": 114000}
{"episode_reward": 559.6069199005118, "episode": 115.0, "batch_reward": 0.30701430296897886, "critic_loss": 0.2671833811104298, "actor_loss": -35.23958399963379, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.56569528579712, "step": 115000}
{"episode_reward": 435.0202462448286, "episode": 116.0, "batch_reward": 0.3083723828047514, "critic_loss": 0.32635406190156935, "actor_loss": -35.49426736450195, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.656707286834717, "step": 116000}
{"episode_reward": 224.81896855800588, "episode": 117.0, "batch_reward": 0.30941349513828753, "critic_loss": 0.3098938829675317, "actor_loss": -35.70625081634522, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.136316537857056, "step": 117000}
{"episode_reward": 562.5162227178836, "episode": 118.0, "batch_reward": 0.31003167790174485, "critic_loss": 0.28615834680199626, "actor_loss": -35.55059158706665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.583847045898438, "step": 118000}
{"episode_reward": 543.5994515975544, "episode": 119.0, "batch_reward": 0.3124462361037731, "critic_loss": 0.3031628892421722, "actor_loss": -35.82557063293457, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.910605669021606, "step": 119000}
{"episode_reward": 526.8393293295552, "episode": 120.0, "batch_reward": 0.312856264680624, "critic_loss": 0.2884232781380415, "actor_loss": -35.9836911239624, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.538650274276733, "step": 120000}
{"episode_reward": 548.6109810348092, "episode": 121.0, "batch_reward": 0.317065803989768, "critic_loss": 0.31703713893145324, "actor_loss": -36.31602893447876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.46495604515076, "step": 121000}
{"episode_reward": 553.7818261074204, "episode": 122.0, "batch_reward": 0.31737608554959296, "critic_loss": 0.3093745117560029, "actor_loss": -36.25495090103149, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.028637409210205, "step": 122000}
{"episode_reward": 506.6056906333351, "episode": 123.0, "batch_reward": 0.32012064880132673, "critic_loss": 0.32317070569097994, "actor_loss": -36.88680763626099, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.16144037246704, "step": 123000}
{"episode_reward": 508.5589523423598, "episode": 124.0, "batch_reward": 0.32055411763489244, "critic_loss": 0.30518081970512867, "actor_loss": -36.787438152313236, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.401010990142822, "step": 124000}
{"episode_reward": 532.2056445603798, "episode": 125.0, "batch_reward": 0.32262479719519616, "critic_loss": 0.30063059516996143, "actor_loss": -36.95683848190308, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.32771897315979, "step": 125000}
{"episode_reward": 565.6619387634402, "episode": 126.0, "batch_reward": 0.3237335453927517, "critic_loss": 0.3030020500868559, "actor_loss": -37.34721168518067, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.03693985939026, "step": 126000}
{"episode_reward": 518.6882594925779, "episode": 127.0, "batch_reward": 0.32516916254162787, "critic_loss": 0.2879612887650728, "actor_loss": -37.233420356750486, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.020755529403687, "step": 127000}
{"episode_reward": 544.6386912210266, "episode": 128.0, "batch_reward": 0.32775455969572065, "critic_loss": 0.29516103164851665, "actor_loss": -37.194148235321045, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.28060221672058, "step": 128000}
{"episode_reward": 541.5784235876015, "episode": 129.0, "batch_reward": 0.3294637366235256, "critic_loss": 0.2971963185667992, "actor_loss": -37.541236694335936, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.036218404769897, "step": 129000}
{"episode_reward": 573.6869433460649, "episode": 130.0, "batch_reward": 0.3317009229063988, "critic_loss": 0.30690801718086, "actor_loss": -37.67384380722046, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.593563079833984, "step": 130000}
{"episode_reward": 545.3423985131552, "episode": 131.0, "batch_reward": 0.3334622601270676, "critic_loss": 0.2765420226380229, "actor_loss": -37.722217063903805, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.059141635894775, "step": 131000}
{"episode_reward": 561.7183524762261, "episode": 132.0, "batch_reward": 0.33567095825076104, "critic_loss": 0.28579622726142406, "actor_loss": -37.895907150268556, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.50184988975525, "step": 132000}
{"episode_reward": 561.4199282767427, "episode": 133.0, "batch_reward": 0.3356560125648975, "critic_loss": 0.29003235659003257, "actor_loss": -38.03470349502563, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.3565514087677, "step": 133000}
{"episode_reward": 549.6359954114769, "episode": 134.0, "batch_reward": 0.33735283064842225, "critic_loss": 0.2927793581932783, "actor_loss": -37.915692749023435, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.698726415634155, "step": 134000}
{"episode_reward": 543.3057463295836, "episode": 135.0, "batch_reward": 0.3395574425458908, "critic_loss": 0.2847940097898245, "actor_loss": -38.219550132751465, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.777551889419556, "step": 135000}
{"episode_reward": 538.5906290612224, "episode": 136.0, "batch_reward": 0.3410473446547985, "critic_loss": 0.2819241600781679, "actor_loss": -38.01469976043701, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.34684467315674, "step": 136000}
{"episode_reward": 532.9491507621984, "episode": 137.0, "batch_reward": 0.34134005299210546, "critic_loss": 0.27964451908320187, "actor_loss": -38.27905434036255, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.621938705444336, "step": 137000}
{"episode_reward": 557.2383759456154, "episode": 138.0, "batch_reward": 0.34420383408665656, "critic_loss": 0.2869262433350086, "actor_loss": -38.88947483062744, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.533684730529785, "step": 138000}
{"episode_reward": 544.8721581462149, "episode": 139.0, "batch_reward": 0.3451081231832504, "critic_loss": 0.30431495244801043, "actor_loss": -38.78143019104004, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.27485752105713, "step": 139000}
{"episode_reward": 563.3233977946957, "episode": 140.0, "batch_reward": 0.34615761095285413, "critic_loss": 0.276520713955164, "actor_loss": -39.07269720458984, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.19425654411316, "step": 140000}
{"episode_reward": 547.1603603801065, "episode": 141.0, "batch_reward": 0.3475226819217205, "critic_loss": 0.27887139459699395, "actor_loss": -38.94451464080811, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.688586473464966, "step": 141000}
{"episode_reward": 541.7975641088483, "episode": 142.0, "batch_reward": 0.34843308955430985, "critic_loss": 0.2803768700659275, "actor_loss": -38.976468704223635, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.393865823745728, "step": 142000}
{"episode_reward": 559.0369341916602, "episode": 143.0, "batch_reward": 0.35197267627716067, "critic_loss": 0.27555455823987723, "actor_loss": -39.109754020690914, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.582954168319702, "step": 143000}
{"episode_reward": 569.7013589316684, "episode": 144.0, "batch_reward": 0.35227151528000833, "critic_loss": 0.279905154004693, "actor_loss": -39.26860026550293, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.66799783706665, "step": 144000}
{"episode_reward": 516.307184548215, "episode": 145.0, "batch_reward": 0.35449945706129077, "critic_loss": 0.28766275254637, "actor_loss": -39.40111573791504, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.60043478012085, "step": 145000}
{"episode_reward": 547.3295599098478, "episode": 146.0, "batch_reward": 0.3545093161761761, "critic_loss": 0.2663962740004063, "actor_loss": -39.5806406288147, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.367516040802002, "step": 146000}
{"episode_reward": 561.8229241290805, "episode": 147.0, "batch_reward": 0.3561506971120834, "critic_loss": 0.29694647885113956, "actor_loss": -39.29918384552002, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.624885320663452, "step": 147000}
{"episode_reward": 576.1448463841494, "episode": 148.0, "batch_reward": 0.3589813809394836, "critic_loss": 0.2705567618086934, "actor_loss": -39.77669192504883, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.870594263076782, "step": 148000}
{"episode_reward": 565.2651044747519, "episode": 149.0, "batch_reward": 0.3592941602766514, "critic_loss": 0.28165506227314474, "actor_loss": -39.66511138916016, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.134409189224243, "step": 149000}
{"episode_reward": 559.1031329206244, "episode": 150.0, "batch_reward": 0.3617881686985493, "critic_loss": 0.2579391404390335, "actor_loss": -40.14227308654785, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
