{"episode_reward": 0.0, "episode": 1.0, "duration": 17.97037172317505, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.5391218662261963, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.2220421771221695, "critic_loss": 0.18142289517148608, "actor_loss": -44.73108251021356, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 63.230424880981445, "step": 3000}
{"episode_reward": 133.85564327091927, "episode": 4.0, "batch_reward": 0.2025790888518095, "critic_loss": 0.19367843088507652, "actor_loss": -40.551985153198245, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.64424729347229, "step": 4000}
{"episode_reward": 177.23892870354913, "episode": 5.0, "batch_reward": 0.17859838051348925, "critic_loss": 0.1613557166531682, "actor_loss": -35.35589844894409, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.925969123840332, "step": 5000}
{"episode_reward": 40.716297339525944, "episode": 6.0, "batch_reward": 0.15719873984903096, "critic_loss": 0.17484070041030644, "actor_loss": -31.877787384033205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.79467272758484, "step": 6000}
{"episode_reward": 81.63990972480046, "episode": 7.0, "batch_reward": 0.15046387476474046, "critic_loss": 0.21078926675021648, "actor_loss": -30.223168476104735, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.338424921035767, "step": 7000}
{"episode_reward": 115.0829463991823, "episode": 8.0, "batch_reward": 0.13660061064362525, "critic_loss": 0.31321442933380605, "actor_loss": -29.982397289276122, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.840752840042114, "step": 8000}
{"episode_reward": 92.0045845009169, "episode": 9.0, "batch_reward": 0.13112886210530997, "critic_loss": 0.2637631864696741, "actor_loss": -30.54043886947632, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.93961000442505, "step": 9000}
{"episode_reward": 95.13001746537685, "episode": 10.0, "batch_reward": 0.13412212125211953, "critic_loss": 0.26677693712711337, "actor_loss": -31.261721130371093, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.267174243927002, "step": 10000}
{"episode_reward": 104.28698082964604, "episode": 11.0, "batch_reward": 0.12890817241370678, "critic_loss": 0.25035942436754705, "actor_loss": -30.638277027130126, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.91233205795288, "step": 11000}
{"episode_reward": 65.22907263440652, "episode": 12.0, "batch_reward": 0.12446930978447199, "critic_loss": 0.2587501734942198, "actor_loss": -29.564886543273925, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.826488971710205, "step": 12000}
{"episode_reward": 100.6888505298355, "episode": 13.0, "batch_reward": 0.1269553759172559, "critic_loss": 0.25835758592188357, "actor_loss": -29.41099560546875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.533384084701538, "step": 13000}
{"episode_reward": 207.52110329479243, "episode": 14.0, "batch_reward": 0.13411103461682797, "critic_loss": 0.25798792695999145, "actor_loss": -30.09319050216675, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.860110998153687, "step": 14000}
{"episode_reward": 344.44303626375023, "episode": 15.0, "batch_reward": 0.14495033986866473, "critic_loss": 0.2391036727502942, "actor_loss": -30.796896072387696, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.878693342208862, "step": 15000}
{"episode_reward": 238.52035479843036, "episode": 16.0, "batch_reward": 0.1581652345955372, "critic_loss": 0.24593613897264005, "actor_loss": -31.442177249908447, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.51991558074951, "step": 16000}
{"episode_reward": 428.7981480126691, "episode": 17.0, "batch_reward": 0.17393243849277495, "critic_loss": 0.2523749174326658, "actor_loss": -32.02435984039307, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.5951189994812, "step": 17000}
{"episode_reward": 312.3894452848959, "episode": 18.0, "batch_reward": 0.18445400522649288, "critic_loss": 0.2517721701860428, "actor_loss": -32.08320669555664, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.88512873649597, "step": 18000}
{"episode_reward": 454.7957750204094, "episode": 19.0, "batch_reward": 0.19899275986850262, "critic_loss": 0.24088359479606153, "actor_loss": -32.98483522415161, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.65325665473938, "step": 19000}
{"episode_reward": 451.51599411366675, "episode": 20.0, "batch_reward": 0.20323697744309902, "critic_loss": 0.268650678396225, "actor_loss": -32.95464219665527, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.353675365447998, "step": 20000}
{"episode_reward": 79.59902259486738, "episode": 21.0, "batch_reward": 0.20358912394940853, "critic_loss": 0.34160021315515043, "actor_loss": -33.04550424575805, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.45422315597534, "step": 21000}
{"episode_reward": 362.75095429359214, "episode": 22.0, "batch_reward": 0.21083249306678772, "critic_loss": 0.47628046602010726, "actor_loss": -33.16939685821533, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.314170837402344, "step": 22000}
{"episode_reward": 315.96527130655124, "episode": 23.0, "batch_reward": 0.21737350638210773, "critic_loss": 0.5641003394871951, "actor_loss": -33.397613403320314, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.55605983734131, "step": 23000}
{"episode_reward": 445.39553594736435, "episode": 24.0, "batch_reward": 0.22593925458192826, "critic_loss": 0.6696459985822439, "actor_loss": -34.086898933410644, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.859085083007812, "step": 24000}
{"episode_reward": 446.5785977663348, "episode": 25.0, "batch_reward": 0.23461397802829742, "critic_loss": 0.8742547853440046, "actor_loss": -34.92376245498657, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.900357007980347, "step": 25000}
{"episode_reward": 461.91411739470215, "episode": 26.0, "batch_reward": 0.24134965234994887, "critic_loss": 1.1996655063629151, "actor_loss": -35.841698371887205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.335936784744263, "step": 26000}
{"episode_reward": 239.30757175971704, "episode": 27.0, "batch_reward": 0.24431892101466657, "critic_loss": 1.1723935210108758, "actor_loss": -36.62024911499024, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.610639095306396, "step": 27000}
{"episode_reward": 438.5639315021911, "episode": 28.0, "batch_reward": 0.2453436523526907, "critic_loss": 2.1566483352780343, "actor_loss": -37.76772118377686, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.525010585784912, "step": 28000}
{"episode_reward": 60.032435162916215, "episode": 29.0, "batch_reward": 0.23793319772183896, "critic_loss": 3.2381388775110245, "actor_loss": -39.04344889068604, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.34419274330139, "step": 29000}
{"episode_reward": 22.45173390532722, "episode": 30.0, "batch_reward": 0.23084087769687175, "critic_loss": 4.761335848450661, "actor_loss": -41.87848293304443, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.06022357940674, "step": 30000}
{"episode_reward": 10.029859952282836, "episode": 31.0, "batch_reward": 0.223786217212677, "critic_loss": 7.11514975142479, "actor_loss": -46.26296127319336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.87657117843628, "step": 31000}
{"episode_reward": 12.73670457724165, "episode": 32.0, "batch_reward": 0.2164428217560053, "critic_loss": 8.699169051885605, "actor_loss": -52.06232312774658, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.35879898071289, "step": 32000}
{"episode_reward": 11.826005981229184, "episode": 33.0, "batch_reward": 0.2093315635472536, "critic_loss": 10.031338633060455, "actor_loss": -60.87321438980103, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.90893864631653, "step": 33000}
{"episode_reward": 12.282831107518483, "episode": 34.0, "batch_reward": 0.20334262953698634, "critic_loss": 10.443148302078248, "actor_loss": -71.91072731781006, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.85231900215149, "step": 34000}
{"episode_reward": 12.308367584851313, "episode": 35.0, "batch_reward": 0.19766544330120087, "critic_loss": 9.81814643716812, "actor_loss": -76.62804349136353, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.31379771232605, "step": 35000}
{"episode_reward": 9.084517858404926, "episode": 36.0, "batch_reward": 0.19250373624265193, "critic_loss": 8.42947076511383, "actor_loss": -81.69712825012208, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.902894973754883, "step": 36000}
{"episode_reward": 12.984778585663502, "episode": 37.0, "batch_reward": 0.18826826773583888, "critic_loss": 7.722775979995728, "actor_loss": -85.95484973144531, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.06242036819458, "step": 37000}
{"episode_reward": 25.410212404174963, "episode": 38.0, "batch_reward": 0.18483962300419807, "critic_loss": 6.949501172542572, "actor_loss": -89.72687730789184, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.335556030273438, "step": 38000}
{"episode_reward": 35.57346011861906, "episode": 39.0, "batch_reward": 0.17997753839194774, "critic_loss": 5.630742835521698, "actor_loss": -86.3398479385376, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.417053937911987, "step": 39000}
{"episode_reward": 17.317126912627096, "episode": 40.0, "batch_reward": 0.177283160880208, "critic_loss": 4.516972007036209, "actor_loss": -86.41955125427246, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.382650136947632, "step": 40000}
{"episode_reward": 101.97726958449246, "episode": 41.0, "batch_reward": 0.17709859727323055, "critic_loss": 3.9804133040905, "actor_loss": -85.3638614616394, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.06472420692444, "step": 41000}
{"episode_reward": 191.37716720917095, "episode": 42.0, "batch_reward": 0.17825611248612405, "critic_loss": 3.6359021875858306, "actor_loss": -88.225381980896, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.534056663513184, "step": 42000}
{"episode_reward": 318.051153330418, "episode": 43.0, "batch_reward": 0.18079068847745658, "critic_loss": 3.368862184882164, "actor_loss": -86.13732211303711, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.46755838394165, "step": 43000}
{"episode_reward": 374.09032819148416, "episode": 44.0, "batch_reward": 0.18689112909138203, "critic_loss": 3.011120899796486, "actor_loss": -84.71410594177246, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.418226957321167, "step": 44000}
{"episode_reward": 493.19119570260676, "episode": 45.0, "batch_reward": 0.19350213381648063, "critic_loss": 2.8845423481464385, "actor_loss": -82.51101780700684, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.840912342071533, "step": 45000}
{"episode_reward": 316.1837639262738, "episode": 46.0, "batch_reward": 0.19665095610916614, "critic_loss": 2.666950261116028, "actor_loss": -81.08908260345459, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.837865829467773, "step": 46000}
{"episode_reward": 503.4464735256394, "episode": 47.0, "batch_reward": 0.2039018525481224, "critic_loss": 2.2983564368486404, "actor_loss": -82.0115534439087, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.322872638702393, "step": 47000}
{"episode_reward": 490.22058001995896, "episode": 48.0, "batch_reward": 0.20924364790320396, "critic_loss": 2.1274160284399986, "actor_loss": -81.5861826324463, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.854683876037598, "step": 48000}
{"episode_reward": 263.3822597038062, "episode": 49.0, "batch_reward": 0.2103225091844797, "critic_loss": 1.9667746627926825, "actor_loss": -78.55638314056397, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.394782781600952, "step": 49000}
{"episode_reward": 478.29577366495, "episode": 50.0, "batch_reward": 0.2160523334890604, "critic_loss": 1.9674123021364212, "actor_loss": -78.45078789520264, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.299988985061646, "step": 50000}
{"episode_reward": 502.28526311195554, "episode": 51.0, "batch_reward": 0.22067756499350072, "critic_loss": 1.9234473262429237, "actor_loss": -78.53055053710938, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.88156294822693, "step": 51000}
{"episode_reward": 237.67777381935753, "episode": 52.0, "batch_reward": 0.21933661150932313, "critic_loss": 2.175359606027603, "actor_loss": -73.48068420410156, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.470231294631958, "step": 52000}
{"episode_reward": 70.42863176094833, "episode": 53.0, "batch_reward": 0.2151425799280405, "critic_loss": 2.1473037421107293, "actor_loss": -71.80684201049804, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.673410177230835, "step": 53000}
{"episode_reward": 69.57778688683801, "episode": 54.0, "batch_reward": 0.21240872468054295, "critic_loss": 2.895496211528778, "actor_loss": -71.88739652252197, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.77960205078125, "step": 54000}
{"episode_reward": 41.33465769623315, "episode": 55.0, "batch_reward": 0.20897766551375388, "critic_loss": 4.109607074379921, "actor_loss": -71.88788257598877, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.692879676818848, "step": 55000}
{"episode_reward": 34.09266943620849, "episode": 56.0, "batch_reward": 0.20625116673111915, "critic_loss": 4.986038655400276, "actor_loss": -71.20322187042237, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.311492443084717, "step": 56000}
{"episode_reward": 44.50786229690351, "episode": 57.0, "batch_reward": 0.20328280252218248, "critic_loss": 6.1505260181427, "actor_loss": -69.96139344406127, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.44049572944641, "step": 57000}
{"episode_reward": 25.31531132897646, "episode": 58.0, "batch_reward": 0.19995512963831424, "critic_loss": 6.804428989171982, "actor_loss": -73.87718617630004, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.596273183822632, "step": 58000}
{"episode_reward": 23.471007319482734, "episode": 59.0, "batch_reward": 0.19629737462103367, "critic_loss": 5.3186186308860774, "actor_loss": -70.27454233932495, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.335517644882202, "step": 59000}
{"episode_reward": 67.93453187683909, "episode": 60.0, "batch_reward": 0.1958378031551838, "critic_loss": 4.127153898239135, "actor_loss": -71.12012182998657, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.248085021972656, "step": 60000}
{"episode_reward": 44.57697730891723, "episode": 61.0, "batch_reward": 0.19308502963185312, "critic_loss": 3.1780483961105346, "actor_loss": -71.1577611579895, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.51813817024231, "step": 61000}
{"episode_reward": 82.64564132169869, "episode": 62.0, "batch_reward": 0.19032168841362, "critic_loss": 2.7057612224817276, "actor_loss": -71.81962204742432, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.30512523651123, "step": 62000}
{"episode_reward": 36.29870723667964, "episode": 63.0, "batch_reward": 0.18769676303863525, "critic_loss": 2.5495286415815355, "actor_loss": -68.05170551300048, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.464306116104126, "step": 63000}
{"episode_reward": 56.115942219968154, "episode": 64.0, "batch_reward": 0.1852410617917776, "critic_loss": 3.0843295434713363, "actor_loss": -67.57902531814575, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.319586515426636, "step": 64000}
{"episode_reward": 39.31270495975312, "episode": 65.0, "batch_reward": 0.18635500232875346, "critic_loss": 3.8663492205142975, "actor_loss": -67.25412351608276, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.31888175010681, "step": 65000}
{"episode_reward": 386.41677644733653, "episode": 66.0, "batch_reward": 0.18949456778168677, "critic_loss": 4.030017608165741, "actor_loss": -68.05117478561401, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.696741819381714, "step": 66000}
{"episode_reward": 376.1205708050135, "episode": 67.0, "batch_reward": 0.19079108394682406, "critic_loss": 3.4858321924209594, "actor_loss": -66.1490781326294, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.27810025215149, "step": 67000}
{"episode_reward": 163.32047596992066, "episode": 68.0, "batch_reward": 0.191894322052598, "critic_loss": 2.673481112122536, "actor_loss": -68.01365446472168, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.357649326324463, "step": 68000}
{"episode_reward": 430.2219492423656, "episode": 69.0, "batch_reward": 0.19513512754440307, "critic_loss": 2.1910232727527617, "actor_loss": -67.59062311553956, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.292503833770752, "step": 69000}
{"episode_reward": 427.48692871549304, "episode": 70.0, "batch_reward": 0.19981363590061665, "critic_loss": 1.8559458088874816, "actor_loss": -65.47804671859741, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.670295000076294, "step": 70000}
{"episode_reward": 442.3236610784877, "episode": 71.0, "batch_reward": 0.20266925255954266, "critic_loss": 1.5745509576797485, "actor_loss": -65.56577102279662, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.924559354782104, "step": 71000}
{"episode_reward": 459.41953395227, "episode": 72.0, "batch_reward": 0.2061002916842699, "critic_loss": 1.4399003558754921, "actor_loss": -64.42502150726318, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.795972108840942, "step": 72000}
{"episode_reward": 478.2937684458747, "episode": 73.0, "batch_reward": 0.20908952990174293, "critic_loss": 1.2775284187793732, "actor_loss": -63.04396510696411, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.987967014312744, "step": 73000}
{"episode_reward": 437.21833872755536, "episode": 74.0, "batch_reward": 0.21371153995394707, "critic_loss": 1.1691553478240966, "actor_loss": -62.01720525360108, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.34389567375183, "step": 74000}
{"episode_reward": 510.7833423533745, "episode": 75.0, "batch_reward": 0.21744630689918995, "critic_loss": 1.03295059466362, "actor_loss": -61.66767244338989, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.53122353553772, "step": 75000}
{"episode_reward": 544.2628448033843, "episode": 76.0, "batch_reward": 0.22146000662446022, "critic_loss": 0.9201290580034256, "actor_loss": -60.47874905395508, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.418088674545288, "step": 76000}
{"episode_reward": 557.8965719501804, "episode": 77.0, "batch_reward": 0.2271506854593754, "critic_loss": 0.8196955091059208, "actor_loss": -59.742289993286136, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.35050678253174, "step": 77000}
{"episode_reward": 549.4973408204827, "episode": 78.0, "batch_reward": 0.23163382807374, "critic_loss": 0.7553951866328716, "actor_loss": -58.6333238067627, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.517955780029297, "step": 78000}
{"episode_reward": 527.9663067744863, "episode": 79.0, "batch_reward": 0.23379807066917419, "critic_loss": 0.6804068432748318, "actor_loss": -58.144778095245364, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.80192732810974, "step": 79000}
{"episode_reward": 530.9847270964024, "episode": 80.0, "batch_reward": 0.2372801008373499, "critic_loss": 0.6138790398240089, "actor_loss": -57.34636095428467, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.585905075073242, "step": 80000}
{"episode_reward": 555.1614653530594, "episode": 81.0, "batch_reward": 0.24264865539968014, "critic_loss": 0.5670568214654923, "actor_loss": -55.5957018737793, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.890443563461304, "step": 81000}
{"episode_reward": 508.45197308287374, "episode": 82.0, "batch_reward": 0.24479685845971108, "critic_loss": 0.5162308164834977, "actor_loss": -54.91777140045166, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.286837577819824, "step": 82000}
{"episode_reward": 538.8205432278492, "episode": 83.0, "batch_reward": 0.24963720947504042, "critic_loss": 0.47101452764868734, "actor_loss": -53.8254451751709, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.333407402038574, "step": 83000}
{"episode_reward": 534.9258318970782, "episode": 84.0, "batch_reward": 0.25208509534597395, "critic_loss": 0.46004525005817415, "actor_loss": -53.091650032043454, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.697279930114746, "step": 84000}
{"episode_reward": 526.4783294978263, "episode": 85.0, "batch_reward": 0.25514213636517524, "critic_loss": 0.44601283194124697, "actor_loss": -52.67906954193115, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.44168496131897, "step": 85000}
{"episode_reward": 532.9765310645914, "episode": 86.0, "batch_reward": 0.25900641575455663, "critic_loss": 0.4136746938675642, "actor_loss": -51.65064215087891, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.320279836654663, "step": 86000}
{"episode_reward": 543.3830008209969, "episode": 87.0, "batch_reward": 0.261740086555481, "critic_loss": 0.39953800013661384, "actor_loss": -50.99747328186035, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.354864597320557, "step": 87000}
{"episode_reward": 534.1037932488861, "episode": 88.0, "batch_reward": 0.26462565080821515, "critic_loss": 0.3758504955619574, "actor_loss": -50.31514031219483, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.61641263961792, "step": 88000}
{"episode_reward": 549.0180461948024, "episode": 89.0, "batch_reward": 0.2696603311896324, "critic_loss": 0.3545293631851673, "actor_loss": -50.066206390380856, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.664610624313354, "step": 89000}
{"episode_reward": 546.593178914024, "episode": 90.0, "batch_reward": 0.271465411439538, "critic_loss": 0.35635549569129943, "actor_loss": -48.92508561706543, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.688746452331543, "step": 90000}
{"episode_reward": 527.1172259965235, "episode": 91.0, "batch_reward": 0.27383338867127893, "critic_loss": 0.3305090038329363, "actor_loss": -48.70867596435547, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.907567739486694, "step": 91000}
{"episode_reward": 547.0564266333556, "episode": 92.0, "batch_reward": 0.27686775751411913, "critic_loss": 0.33880556435883047, "actor_loss": -47.62671260070801, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.314610242843628, "step": 92000}
{"episode_reward": 534.9376440915702, "episode": 93.0, "batch_reward": 0.2784813886880875, "critic_loss": 0.3116879791021347, "actor_loss": -47.40170743560791, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.796494245529175, "step": 93000}
{"episode_reward": 545.2049831208952, "episode": 94.0, "batch_reward": 0.28342315335571766, "critic_loss": 0.30183675774931906, "actor_loss": -46.8676318435669, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.97330641746521, "step": 94000}
{"episode_reward": 545.0812014559679, "episode": 95.0, "batch_reward": 0.2857294922173023, "critic_loss": 0.2990222758054733, "actor_loss": -46.44671292877197, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.300187349319458, "step": 95000}
{"episode_reward": 533.0660969287699, "episode": 96.0, "batch_reward": 0.28801820616424084, "critic_loss": 0.3090425332188606, "actor_loss": -45.993831611633304, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.293742895126343, "step": 96000}
{"episode_reward": 544.4790151564698, "episode": 97.0, "batch_reward": 0.2903668152838945, "critic_loss": 0.2969728581979871, "actor_loss": -45.69918224334717, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.627145767211914, "step": 97000}
{"episode_reward": 538.1070056744257, "episode": 98.0, "batch_reward": 0.29359662091732025, "critic_loss": 0.28859369187057016, "actor_loss": -45.17285443878174, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.636845350265503, "step": 98000}
{"episode_reward": 535.0452705859265, "episode": 99.0, "batch_reward": 0.29581852586567403, "critic_loss": 0.27421507266908884, "actor_loss": -44.92525178527832, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.712701320648193, "step": 99000}
{"episode_reward": 534.2384830584904, "episode": 100.0, "batch_reward": 0.298742989346385, "critic_loss": 0.26479746104031804, "actor_loss": -44.58869197845459, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.82796311378479, "step": 100000}
{"episode_reward": 517.8667628716645, "episode": 101.0, "batch_reward": 0.30091363298892976, "critic_loss": 0.27776697294414043, "actor_loss": -44.30271904754639, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.07794690132141, "step": 101000}
{"episode_reward": 502.37713294946724, "episode": 102.0, "batch_reward": 0.3016179716587067, "critic_loss": 0.26617965468764304, "actor_loss": -43.85291201782226, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.76306438446045, "step": 102000}
{"episode_reward": 517.2786292434283, "episode": 103.0, "batch_reward": 0.3025887269079685, "critic_loss": 0.25315670489519837, "actor_loss": -43.65675465393066, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.81015706062317, "step": 103000}
{"episode_reward": 554.0919256271113, "episode": 104.0, "batch_reward": 0.30751771514117715, "critic_loss": 0.25440788771957157, "actor_loss": -43.46349490356445, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.58737587928772, "step": 104000}
{"episode_reward": 531.0949303587228, "episode": 105.0, "batch_reward": 0.30922299857437613, "critic_loss": 0.25554331973940136, "actor_loss": -43.39050025177002, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.488492488861084, "step": 105000}
{"episode_reward": 555.3677319761325, "episode": 106.0, "batch_reward": 0.31168646892905233, "critic_loss": 0.24844241274893283, "actor_loss": -43.23047967529297, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.91390037536621, "step": 106000}
{"episode_reward": 535.5658693799969, "episode": 107.0, "batch_reward": 0.3129722965061665, "critic_loss": 0.2412779114767909, "actor_loss": -43.001486206054686, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.569897174835205, "step": 107000}
{"episode_reward": 560.8901733097782, "episode": 108.0, "batch_reward": 0.3159977952539921, "critic_loss": 0.22787835681438445, "actor_loss": -42.9208134765625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.37262463569641, "step": 108000}
{"episode_reward": 532.9143181625687, "episode": 109.0, "batch_reward": 0.3183132299780846, "critic_loss": 0.23964274348318576, "actor_loss": -42.81745024871826, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.225227117538452, "step": 109000}
{"episode_reward": 512.680456929383, "episode": 110.0, "batch_reward": 0.3195133761018515, "critic_loss": 0.2406910709068179, "actor_loss": -42.48256864929199, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.548742532730103, "step": 110000}
{"episode_reward": 510.4811737498141, "episode": 111.0, "batch_reward": 0.32103506088256833, "critic_loss": 0.22788599704951049, "actor_loss": -42.48004203796387, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.142027616500854, "step": 111000}
{"episode_reward": 555.0641529305541, "episode": 112.0, "batch_reward": 0.32305511114001273, "critic_loss": 0.23547206769138573, "actor_loss": -42.41776342773438, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.209537982940674, "step": 112000}
{"episode_reward": 532.726620933342, "episode": 113.0, "batch_reward": 0.32566252613067626, "critic_loss": 0.2438048529922962, "actor_loss": -42.35013359069824, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.437405347824097, "step": 113000}
{"episode_reward": 518.6246192775224, "episode": 114.0, "batch_reward": 0.32713580048084256, "critic_loss": 0.25456700193136933, "actor_loss": -42.19313654327392, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.353875637054443, "step": 114000}
{"episode_reward": 518.9736226450743, "episode": 115.0, "batch_reward": 0.3284996594786644, "critic_loss": 0.24684944247454405, "actor_loss": -41.939485412597655, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.35331153869629, "step": 115000}
{"episode_reward": 555.3259718019301, "episode": 116.0, "batch_reward": 0.33164370715618136, "critic_loss": 0.24674140311032533, "actor_loss": -42.09976750183105, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.62231469154358, "step": 116000}
{"episode_reward": 554.5021274740902, "episode": 117.0, "batch_reward": 0.3329241671562195, "critic_loss": 0.22442335072904826, "actor_loss": -41.9429380569458, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.170803785324097, "step": 117000}
{"episode_reward": 539.1072556696984, "episode": 118.0, "batch_reward": 0.33446239212155343, "critic_loss": 0.22082717652618886, "actor_loss": -42.01974418640137, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.323606491088867, "step": 118000}
{"episode_reward": 544.509221123714, "episode": 119.0, "batch_reward": 0.33631464061141014, "critic_loss": 0.2166361875683069, "actor_loss": -41.80911757659912, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.157007455825806, "step": 119000}
{"episode_reward": 558.3367940254019, "episode": 120.0, "batch_reward": 0.33716534397006037, "critic_loss": 0.22418181642889976, "actor_loss": -41.57433001708984, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.83369779586792, "step": 120000}
{"episode_reward": 520.4669825676262, "episode": 121.0, "batch_reward": 0.3404547890126705, "critic_loss": 0.22817603765428066, "actor_loss": -41.598209831237796, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.06755590438843, "step": 121000}
{"episode_reward": 542.6568625543401, "episode": 122.0, "batch_reward": 0.34134376227855684, "critic_loss": 0.23578664149343967, "actor_loss": -41.57524713134766, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.897215127944946, "step": 122000}
{"episode_reward": 532.4789115706559, "episode": 123.0, "batch_reward": 0.3434067476391792, "critic_loss": 0.23254841946065427, "actor_loss": -41.65977366638184, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.679547548294067, "step": 123000}
{"episode_reward": 539.7822304113166, "episode": 124.0, "batch_reward": 0.3445350941121578, "critic_loss": 0.23269348955899477, "actor_loss": -41.7818928527832, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.36495041847229, "step": 124000}
{"episode_reward": 539.2606760700819, "episode": 125.0, "batch_reward": 0.3466572385430336, "critic_loss": 0.23709429275244476, "actor_loss": -41.61290460968018, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.863662481307983, "step": 125000}
{"episode_reward": 546.7896084098866, "episode": 126.0, "batch_reward": 0.3469703797698021, "critic_loss": 0.24068829277902842, "actor_loss": -41.66387040710449, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.986525297164917, "step": 126000}
{"episode_reward": 534.9309305962558, "episode": 127.0, "batch_reward": 0.34860343992710113, "critic_loss": 0.22351490419358014, "actor_loss": -41.80261724090576, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.29679536819458, "step": 127000}
{"episode_reward": 517.0251973266776, "episode": 128.0, "batch_reward": 0.3501273552775383, "critic_loss": 0.22071093336492778, "actor_loss": -41.84984302520752, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.80980896949768, "step": 128000}
{"episode_reward": 562.3606459404666, "episode": 129.0, "batch_reward": 0.35156378644704817, "critic_loss": 0.23056942295283078, "actor_loss": -42.06948876953125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.152941942214966, "step": 129000}
{"episode_reward": 525.5420501406404, "episode": 130.0, "batch_reward": 0.35321612015366555, "critic_loss": 0.2117393685206771, "actor_loss": -41.67062263488769, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.351343870162964, "step": 130000}
{"episode_reward": 547.1517232804033, "episode": 131.0, "batch_reward": 0.35563239514827727, "critic_loss": 0.21200274130702018, "actor_loss": -41.83497452545166, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.38215947151184, "step": 131000}
{"episode_reward": 551.2082361952974, "episode": 132.0, "batch_reward": 0.3563722107410431, "critic_loss": 0.21155702189356088, "actor_loss": -41.71504367828369, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.94027328491211, "step": 132000}
{"episode_reward": 512.9226670643943, "episode": 133.0, "batch_reward": 0.3574690117239952, "critic_loss": 0.20567258471250535, "actor_loss": -42.06576331329346, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.314950466156006, "step": 133000}
{"episode_reward": 538.3473115003526, "episode": 134.0, "batch_reward": 0.3580493777990341, "critic_loss": 0.221389615803957, "actor_loss": -42.06417428588867, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.224592924118042, "step": 134000}
{"episode_reward": 519.0068185134658, "episode": 135.0, "batch_reward": 0.3597401643693447, "critic_loss": 0.22406021020561456, "actor_loss": -41.879882286071776, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.766660928726196, "step": 135000}
{"episode_reward": 538.0969303159285, "episode": 136.0, "batch_reward": 0.3617387517392635, "critic_loss": 0.21788608284294605, "actor_loss": -41.94094496154785, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.608614206314087, "step": 136000}
{"episode_reward": 554.92560747041, "episode": 137.0, "batch_reward": 0.36252294924855233, "critic_loss": 0.21841737232357264, "actor_loss": -41.732757957458496, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.821841955184937, "step": 137000}
{"episode_reward": 543.3496069540993, "episode": 138.0, "batch_reward": 0.3642073693573475, "critic_loss": 0.21521340169012546, "actor_loss": -41.81585516357422, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.828826904296875, "step": 138000}
{"episode_reward": 510.30725572449313, "episode": 139.0, "batch_reward": 0.3645941868722439, "critic_loss": 0.21167337617278098, "actor_loss": -42.02758963775635, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.33660364151001, "step": 139000}
{"episode_reward": 570.0747990204958, "episode": 140.0, "batch_reward": 0.36602282273769376, "critic_loss": 0.20682261918485165, "actor_loss": -42.081115692138674, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.42885684967041, "step": 140000}
{"episode_reward": 558.5491007134992, "episode": 141.0, "batch_reward": 0.36752610650658607, "critic_loss": 0.2072909128218889, "actor_loss": -41.943469856262205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.56381177902222, "step": 141000}
{"episode_reward": 559.4724809175902, "episode": 142.0, "batch_reward": 0.3688039968013763, "critic_loss": 0.20213047593086958, "actor_loss": -41.964441162109374, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.341904640197754, "step": 142000}
{"episode_reward": 573.3976436528226, "episode": 143.0, "batch_reward": 0.3705891872346401, "critic_loss": 0.21499965979903937, "actor_loss": -42.2222134552002, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.262295484542847, "step": 143000}
{"episode_reward": 560.1611792207046, "episode": 144.0, "batch_reward": 0.3724826290905476, "critic_loss": 0.21593672160059213, "actor_loss": -42.268450340270995, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.57554268836975, "step": 144000}
{"episode_reward": 566.565476686788, "episode": 145.0, "batch_reward": 0.37387924280762674, "critic_loss": 0.2120706105157733, "actor_loss": -42.236640266418455, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.473575592041016, "step": 145000}
{"episode_reward": 569.7730866923138, "episode": 146.0, "batch_reward": 0.37450141113996505, "critic_loss": 0.2190869120284915, "actor_loss": -42.73865198516846, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.297632932662964, "step": 146000}
{"episode_reward": 559.3943650514572, "episode": 147.0, "batch_reward": 0.374815780967474, "critic_loss": 0.18841644364595414, "actor_loss": -42.52587154388428, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.701714277267456, "step": 147000}
{"episode_reward": 560.9032883262107, "episode": 148.0, "batch_reward": 0.37725459510087966, "critic_loss": 0.21409007124602794, "actor_loss": -42.69220149230957, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.09359908103943, "step": 148000}
{"episode_reward": 567.5706264553406, "episode": 149.0, "batch_reward": 0.37871114325523375, "critic_loss": 0.2074345676675439, "actor_loss": -42.73506053924561, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.339043855667114, "step": 149000}
{"episode_reward": 545.0388248546305, "episode": 150.0, "batch_reward": 0.38058642357587813, "critic_loss": 0.20631076712161303, "actor_loss": -43.05261597442627, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
