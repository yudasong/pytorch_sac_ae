{"episode_reward": 0.0, "episode": 1.0, "duration": 19.275203943252563, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.5392777919769287, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.215931670412933, "critic_loss": 0.02312990507109711, "actor_loss": -11.055949404937069, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 69.65190172195435, "step": 3000}
{"episode_reward": 2.7169187303655127, "episode": 4.0, "batch_reward": 0.13401973408460616, "critic_loss": 0.01237988716783002, "actor_loss": -12.24616220998764, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.332429885864258, "step": 4000}
{"episode_reward": 2.157291795614094, "episode": 5.0, "batch_reward": 0.10321847147494555, "critic_loss": 0.010479956810944714, "actor_loss": -10.621728817939758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.564404487609863, "step": 5000}
{"episode_reward": 2.017064694653671, "episode": 6.0, "batch_reward": 0.08451300063729286, "critic_loss": 0.011478501252364368, "actor_loss": -9.868860332012176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.087406396865845, "step": 6000}
{"episode_reward": 2.0600287108553728, "episode": 7.0, "batch_reward": 0.07198198187351226, "critic_loss": 0.013237970674177632, "actor_loss": -10.072743813037873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.69342613220215, "step": 7000}
{"episode_reward": 3.142606497118695, "episode": 8.0, "batch_reward": 0.06314807471446693, "critic_loss": 0.010173682315275073, "actor_loss": -8.980619673252106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.81218385696411, "step": 8000}
{"episode_reward": 2.2777995123788974, "episode": 9.0, "batch_reward": 0.055739336701110004, "critic_loss": 0.009520543484482915, "actor_loss": -9.373177453517913, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.70854091644287, "step": 9000}
{"episode_reward": 2.94318164178489, "episode": 10.0, "batch_reward": 0.050658778293058274, "critic_loss": 0.009324045290297362, "actor_loss": -8.6278626537323, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.930053234100342, "step": 10000}
{"episode_reward": 2.467010810842142, "episode": 11.0, "batch_reward": 0.04606759261339903, "critic_loss": 0.012475551420939155, "actor_loss": -9.930668725967408, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.94930148124695, "step": 11000}
{"episode_reward": 2.3467527197818083, "episode": 12.0, "batch_reward": 0.04247065727226436, "critic_loss": 0.00903895768302027, "actor_loss": -8.77262803053856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.15188694000244, "step": 12000}
{"episode_reward": 2.4863570226343503, "episode": 13.0, "batch_reward": 0.038918027720414104, "critic_loss": 0.009531732837087475, "actor_loss": -8.930968691825866, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.250658750534058, "step": 13000}
{"episode_reward": 2.2395370406222255, "episode": 14.0, "batch_reward": 0.035732142276596275, "critic_loss": 0.010233774800610263, "actor_loss": -8.410705042362213, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.26599645614624, "step": 14000}
{"episode_reward": 1.9095008659795234, "episode": 15.0, "batch_reward": 0.03395229861140251, "critic_loss": 0.014186908260453492, "actor_loss": -8.889102058410645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.68605327606201, "step": 15000}
{"episode_reward": 3.459726999597167, "episode": 16.0, "batch_reward": 0.03156469107232988, "critic_loss": 0.011718542315531521, "actor_loss": -8.99465603709221, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.84353280067444, "step": 16000}
{"episode_reward": 3.1985687952151625, "episode": 17.0, "batch_reward": 0.030019920465536417, "critic_loss": 0.011380834805429913, "actor_loss": -7.850115932226181, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.063333749771118, "step": 17000}
{"episode_reward": 3.757886616089757, "episode": 18.0, "batch_reward": 0.028671360559528694, "critic_loss": 0.008253593509027268, "actor_loss": -7.255863376379013, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.372116088867188, "step": 18000}
{"episode_reward": 3.129854163114871, "episode": 19.0, "batch_reward": 0.027058928531128915, "critic_loss": 0.009313442329817918, "actor_loss": -8.869462368130684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.369787216186523, "step": 19000}
{"episode_reward": 3.468091371429174, "episode": 20.0, "batch_reward": 0.02564821882545948, "critic_loss": 0.00964556527073728, "actor_loss": -8.244219534397125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.272884130477905, "step": 20000}
{"episode_reward": 3.3793638043301106, "episode": 21.0, "batch_reward": 0.02512024690071121, "critic_loss": 0.011201471315056551, "actor_loss": -8.862628732085229, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.90678262710571, "step": 21000}
{"episode_reward": 2.61523994179421, "episode": 22.0, "batch_reward": 0.023807139831129462, "critic_loss": 0.008445908028777921, "actor_loss": -8.202223765730858, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.060494661331177, "step": 22000}
{"episode_reward": 3.2903515611477285, "episode": 23.0, "batch_reward": 0.023362711929017677, "critic_loss": 0.009826406631793362, "actor_loss": -6.877135446071625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.77229118347168, "step": 23000}
{"episode_reward": 4.431929942649668, "episode": 24.0, "batch_reward": 0.021978822906734422, "critic_loss": 0.010103894124709769, "actor_loss": -6.9536179339289665, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.357553958892822, "step": 24000}
{"episode_reward": 3.2478851579445047, "episode": 25.0, "batch_reward": 0.02127207230287604, "critic_loss": 0.009697671713831369, "actor_loss": -7.5086309534907345, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.38965892791748, "step": 25000}
{"episode_reward": 3.191037619080232, "episode": 26.0, "batch_reward": 0.020657775174127892, "critic_loss": 0.008815689084090991, "actor_loss": -7.265398641347885, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.854973554611206, "step": 26000}
{"episode_reward": 3.684856373654017, "episode": 27.0, "batch_reward": 0.020234404685441406, "critic_loss": 0.008363677777495467, "actor_loss": -7.271175459742546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.762914657592773, "step": 27000}
{"episode_reward": 3.0395874378059524, "episode": 28.0, "batch_reward": 0.019424189415527506, "critic_loss": 0.007646607742353808, "actor_loss": -7.324152716457844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.33618426322937, "step": 28000}
{"episode_reward": 4.1256656215464975, "episode": 29.0, "batch_reward": 0.01959924603253603, "critic_loss": 0.007221297824347857, "actor_loss": -7.226063202738762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.896259784698486, "step": 29000}
{"episode_reward": 5.276377035905832, "episode": 30.0, "batch_reward": 0.01830990990088321, "critic_loss": 0.00614000211347593, "actor_loss": -7.375804592490196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.877620458602905, "step": 30000}
{"episode_reward": 2.4554635563004905, "episode": 31.0, "batch_reward": 0.01786822088318877, "critic_loss": 0.006907247338094748, "actor_loss": -7.41449603998661, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.894134521484375, "step": 31000}
{"episode_reward": 3.5208594349355877, "episode": 32.0, "batch_reward": 0.01720465004700236, "critic_loss": 0.0068239527012920005, "actor_loss": -7.598144239068032, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.12233543395996, "step": 32000}
{"episode_reward": 3.2548310530524445, "episode": 33.0, "batch_reward": 0.01698705095727928, "critic_loss": 0.006166311235865578, "actor_loss": -7.5853025962114335, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.442640781402588, "step": 33000}
{"episode_reward": 3.0333493631665585, "episode": 34.0, "batch_reward": 0.016553353895898907, "critic_loss": 0.005884432266902877, "actor_loss": -6.300561877906323, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.48782968521118, "step": 34000}
{"episode_reward": 3.6004522401902674, "episode": 35.0, "batch_reward": 0.016063782618613912, "critic_loss": 0.00602144269621931, "actor_loss": -7.196777215242386, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.263593196868896, "step": 35000}
{"episode_reward": 3.7775093008051397, "episode": 36.0, "batch_reward": 0.015689435199834408, "critic_loss": 0.00474679866914812, "actor_loss": -7.577537442207336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.291260480880737, "step": 36000}
{"episode_reward": 3.1993610993528145, "episode": 37.0, "batch_reward": 0.0154748418063391, "critic_loss": 0.005566392004700902, "actor_loss": -6.548597830533981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.17672562599182, "step": 37000}
{"episode_reward": 2.7606697343216435, "episode": 38.0, "batch_reward": 0.015247454271418975, "critic_loss": 0.005286709642357891, "actor_loss": -6.592152923643589, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.67534875869751, "step": 38000}
{"episode_reward": 3.634035807981592, "episode": 39.0, "batch_reward": 0.014725321270059794, "critic_loss": 0.006533804814884206, "actor_loss": -7.7234469586312775, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.585822820663452, "step": 39000}
{"episode_reward": 4.022577798539095, "episode": 40.0, "batch_reward": 0.014618781807599589, "critic_loss": 0.004980575372610474, "actor_loss": -7.411185717403889, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.125306129455566, "step": 40000}
{"episode_reward": 2.8225528043290096, "episode": 41.0, "batch_reward": 0.014402376344660297, "critic_loss": 0.005843295169659541, "actor_loss": -7.53321842828393, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.00389862060547, "step": 41000}
{"episode_reward": 3.7943735096234175, "episode": 42.0, "batch_reward": 0.013738105923403054, "critic_loss": 0.003754673211500631, "actor_loss": -6.1584738357961175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.546361207962036, "step": 42000}
{"episode_reward": 2.3521799393536917, "episode": 43.0, "batch_reward": 0.013733820367604494, "critic_loss": 0.005164043269462127, "actor_loss": -6.815169015586376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.350857496261597, "step": 43000}
{"episode_reward": 3.8085676282782934, "episode": 44.0, "batch_reward": 0.013443239075131714, "critic_loss": 0.003934895121848967, "actor_loss": -6.855884072452784, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.86344814300537, "step": 44000}
{"episode_reward": 2.9915993903468667, "episode": 45.0, "batch_reward": 0.01343474090169184, "critic_loss": 0.004110118467324355, "actor_loss": -7.647036961138248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.08159613609314, "step": 45000}
{"episode_reward": 3.7878632593876462, "episode": 46.0, "batch_reward": 0.012981939322082326, "critic_loss": 0.00569795965004596, "actor_loss": -8.02913672441244, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.669026613235474, "step": 46000}
{"episode_reward": 3.3928532460011063, "episode": 47.0, "batch_reward": 0.01323877341300249, "critic_loss": 0.0033828580344998044, "actor_loss": -7.179373774230481, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.59080195426941, "step": 47000}
{"episode_reward": 4.298351474383049, "episode": 48.0, "batch_reward": 0.012580788061954081, "critic_loss": 0.0028578001903952098, "actor_loss": -6.443819022327662, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.495025396347046, "step": 48000}
{"episode_reward": 3.9470156957821505, "episode": 49.0, "batch_reward": 0.012737889342242853, "critic_loss": 0.005038244112649409, "actor_loss": -7.537492681503296, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.982734203338623, "step": 49000}
{"episode_reward": 3.4094872132056127, "episode": 50.0, "batch_reward": 0.012137793478090316, "critic_loss": 0.003986341428084415, "actor_loss": -7.2239160445630555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.968734979629517, "step": 50000}
{"episode_reward": 3.7015942233468966, "episode": 51.0, "batch_reward": 0.012062561831204221, "critic_loss": 0.003222329533076845, "actor_loss": -6.508740880817175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.687127113342285, "step": 51000}
{"episode_reward": 3.583191494189614, "episode": 52.0, "batch_reward": 0.01203440226893872, "critic_loss": 0.004416181767097441, "actor_loss": -8.132003992378712, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.688312530517578, "step": 52000}
{"episode_reward": 4.129860211420054, "episode": 53.0, "batch_reward": 0.01203571731771808, "critic_loss": 0.0037909718347000306, "actor_loss": -7.60729452931881, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.28823947906494, "step": 53000}
{"episode_reward": 3.8378606306080396, "episode": 54.0, "batch_reward": 0.01140459198388271, "critic_loss": 0.00444503268396511, "actor_loss": -6.284332501769065, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.107476949691772, "step": 54000}
{"episode_reward": 4.512816919095937, "episode": 55.0, "batch_reward": 0.011665526654105633, "critic_loss": 0.004858881612191908, "actor_loss": -6.339944447755814, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.441165924072266, "step": 55000}
{"episode_reward": 3.7615853490188544, "episode": 56.0, "batch_reward": 0.011479950191220268, "critic_loss": 0.003606023027401534, "actor_loss": -6.410615930378437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.489914178848267, "step": 56000}
{"episode_reward": 3.6654823317758773, "episode": 57.0, "batch_reward": 0.011036762161646039, "critic_loss": 0.0035928910687580357, "actor_loss": -7.578199974000454, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.741048574447632, "step": 57000}
{"episode_reward": 3.316305716865398, "episode": 58.0, "batch_reward": 0.011235579958185554, "critic_loss": 0.0031776525483001024, "actor_loss": -5.872345276653767, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.309791326522827, "step": 58000}
{"episode_reward": 3.3931105947216214, "episode": 59.0, "batch_reward": 0.010707666783127933, "critic_loss": 0.004074887791335641, "actor_loss": -7.604862299501896, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.61712336540222, "step": 59000}
{"episode_reward": 3.4250734046490043, "episode": 60.0, "batch_reward": 0.011023439737735317, "critic_loss": 0.003382025075086858, "actor_loss": -7.832170568063855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.152855157852173, "step": 60000}
{"episode_reward": 4.132129535998168, "episode": 61.0, "batch_reward": 0.010806812286144123, "critic_loss": 0.0034700489373499293, "actor_loss": -6.243369667753577, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.45194935798645, "step": 61000}
{"episode_reward": 3.3103633242070325, "episode": 62.0, "batch_reward": 0.010781410729512572, "critic_loss": 0.002745123155997135, "actor_loss": -5.9028297719806435, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.534550428390503, "step": 62000}
{"episode_reward": 2.7259412131190643, "episode": 63.0, "batch_reward": 0.01055673961318098, "critic_loss": 0.003784416846137901, "actor_loss": -7.263142089009285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.973909378051758, "step": 63000}
{"episode_reward": 3.717665377647329, "episode": 64.0, "batch_reward": 0.010112658380530775, "critic_loss": 0.003317865414217522, "actor_loss": -6.587187727928161, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.274112224578857, "step": 64000}
{"episode_reward": 3.3951582546898105, "episode": 65.0, "batch_reward": 0.0101822626714129, "critic_loss": 0.0025690325583564116, "actor_loss": -6.597182762429118, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.20998501777649, "step": 65000}
{"episode_reward": 2.972370670686407, "episode": 66.0, "batch_reward": 0.01030752938752994, "critic_loss": 0.003191863524640212, "actor_loss": -6.980464970692992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.145163536071777, "step": 66000}
{"episode_reward": 3.485666348357332, "episode": 67.0, "batch_reward": 0.010123815858853049, "critic_loss": 0.0032519110153298243, "actor_loss": -7.215330422408879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.305004358291626, "step": 67000}
{"episode_reward": 4.303038206166036, "episode": 68.0, "batch_reward": 0.010007030225824564, "critic_loss": 0.0031035774895208307, "actor_loss": -6.402579054173082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.290109872817993, "step": 68000}
{"episode_reward": 2.440074443383587, "episode": 69.0, "batch_reward": 0.009692147760652005, "critic_loss": 0.0037187641637792695, "actor_loss": -6.735152700290084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.72723364830017, "step": 69000}
{"episode_reward": 2.902480345394944, "episode": 70.0, "batch_reward": 0.009967333716107533, "critic_loss": 0.002718932595853403, "actor_loss": -6.951095723360777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.444427013397217, "step": 70000}
{"episode_reward": 3.294086608542658, "episode": 71.0, "batch_reward": 0.009943252167664469, "critic_loss": 0.003178538088075584, "actor_loss": -6.566013593494892, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.457523822784424, "step": 71000}
{"episode_reward": 3.047049890498479, "episode": 72.0, "batch_reward": 0.009693795687053353, "critic_loss": 0.0027513737238768956, "actor_loss": -6.946358528196812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.158715963363647, "step": 72000}
{"episode_reward": 3.6012154760877513, "episode": 73.0, "batch_reward": 0.009594398985849694, "critic_loss": 0.0026199213406143825, "actor_loss": -6.926598066821694, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.409738063812256, "step": 73000}
{"episode_reward": 4.486001257747784, "episode": 74.0, "batch_reward": 0.009402707404224202, "critic_loss": 0.0019915535939944674, "actor_loss": -7.00123171132803, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.45469570159912, "step": 74000}
{"episode_reward": 4.525448501771316, "episode": 75.0, "batch_reward": 0.009319006834644825, "critic_loss": 0.002585035770222021, "actor_loss": -6.468243946045638, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.484710931777954, "step": 75000}
{"episode_reward": 2.7440134864695023, "episode": 76.0, "batch_reward": 0.009346463683061301, "critic_loss": 0.0027211436389043228, "actor_loss": -6.013443175584078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.283548831939697, "step": 76000}
{"episode_reward": 3.5103844811864855, "episode": 77.0, "batch_reward": 0.009174740872811527, "critic_loss": 0.0023122795187227895, "actor_loss": -6.855140401184559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.247013568878174, "step": 77000}
{"episode_reward": 2.890689656847097, "episode": 78.0, "batch_reward": 0.009414156438084319, "critic_loss": 0.002595283871589345, "actor_loss": -7.119231437042355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.74166512489319, "step": 78000}
{"episode_reward": 3.896981993408808, "episode": 79.0, "batch_reward": 0.008891495449002832, "critic_loss": 0.0037565644882197376, "actor_loss": -6.515125089928508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.89001703262329, "step": 79000}
{"episode_reward": 3.438202082799391, "episode": 80.0, "batch_reward": 0.008898036891128868, "critic_loss": 0.001825935452761769, "actor_loss": -6.114301816985011, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.145107984542847, "step": 80000}
{"episode_reward": 3.294686257033601, "episode": 81.0, "batch_reward": 0.008737186472164466, "critic_loss": 0.0023039986694493564, "actor_loss": -7.42004588919878, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.69503164291382, "step": 81000}
{"episode_reward": 4.697062381373397, "episode": 82.0, "batch_reward": 0.00901226270524785, "critic_loss": 0.0021180422370744053, "actor_loss": -6.522947063013911, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.658337593078613, "step": 82000}
{"episode_reward": 3.8979832472270433, "episode": 83.0, "batch_reward": 0.008704168386058881, "critic_loss": 0.002025541380608047, "actor_loss": -7.032485072225333, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.33740544319153, "step": 83000}
{"episode_reward": 3.6385234309703898, "episode": 84.0, "batch_reward": 0.008568318446516059, "critic_loss": 0.002190504785743542, "actor_loss": -7.290777988851071, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.366925477981567, "step": 84000}
{"episode_reward": 4.7340695861756386, "episode": 85.0, "batch_reward": 0.008820595999015496, "critic_loss": 0.002201561002737435, "actor_loss": -6.565254379346967, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.430908203125, "step": 85000}
{"episode_reward": 3.955746417067519, "episode": 86.0, "batch_reward": 0.008653870246605948, "critic_loss": 0.002254899024250335, "actor_loss": -6.619706347763539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.598122596740723, "step": 86000}
{"episode_reward": 4.510591529371893, "episode": 87.0, "batch_reward": 0.008681143082911149, "critic_loss": 0.0015972168843072722, "actor_loss": -6.237391009345651, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.311707019805908, "step": 87000}
{"episode_reward": 3.8516581703304666, "episode": 88.0, "batch_reward": 0.008665507091209293, "critic_loss": 0.0022281184945095447, "actor_loss": -6.232275249838829, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.608689546585083, "step": 88000}
{"episode_reward": 3.3282577654169954, "episode": 89.0, "batch_reward": 0.008673938408261165, "critic_loss": 0.001673825647769263, "actor_loss": -6.616391937866807, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.050238609313965, "step": 89000}
{"episode_reward": 3.6674725241656208, "episode": 90.0, "batch_reward": 0.008438525948440656, "critic_loss": 0.0023146471282670974, "actor_loss": -7.012438309252262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.151471376419067, "step": 90000}
{"episode_reward": 3.543254033725881, "episode": 91.0, "batch_reward": 0.008626748593291269, "critic_loss": 0.001694923206785461, "actor_loss": -6.422939757436514, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.99054265022278, "step": 91000}
{"episode_reward": 3.3522168631693114, "episode": 92.0, "batch_reward": 0.008569240875076503, "critic_loss": 0.0022020271431101718, "actor_loss": -6.693459326207638, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.40530300140381, "step": 92000}
{"episode_reward": 5.150765715352484, "episode": 93.0, "batch_reward": 0.008295340914744884, "critic_loss": 0.002389041468326468, "actor_loss": -5.896229084536433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.40519428253174, "step": 93000}
{"episode_reward": 4.565629324646215, "episode": 94.0, "batch_reward": 0.00821921363961883, "critic_loss": 0.0017195349765897845, "actor_loss": -6.609038861170411, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.141627073287964, "step": 94000}
{"episode_reward": 2.996431901760443, "episode": 95.0, "batch_reward": 0.008218562750378624, "critic_loss": 0.002151954827037116, "actor_loss": -7.462768997520208, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.580681562423706, "step": 95000}
{"episode_reward": 2.773151530936261, "episode": 96.0, "batch_reward": 0.008161580557469279, "critic_loss": 0.0018106140889940434, "actor_loss": -6.8613390270620584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.21839737892151, "step": 96000}
{"episode_reward": 3.4896817792947847, "episode": 97.0, "batch_reward": 0.008171432445407845, "critic_loss": 0.0019769938130339143, "actor_loss": -6.873241661094129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.747791290283203, "step": 97000}
{"episode_reward": 3.6165020151882756, "episode": 98.0, "batch_reward": 0.008099542290903627, "critic_loss": 0.0023381694874624374, "actor_loss": -6.985124192789197, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.167412996292114, "step": 98000}
{"episode_reward": 3.2106918770930983, "episode": 99.0, "batch_reward": 0.00792793849017471, "critic_loss": 0.0016946214709278138, "actor_loss": -6.792983301088214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.193762063980103, "step": 99000}
{"episode_reward": 4.235211015612249, "episode": 100.0, "batch_reward": 0.008034028730820864, "critic_loss": 0.0015420372715525446, "actor_loss": -6.795791652977466, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.831803560256958, "step": 100000}
{"episode_reward": 4.772510596328853, "episode": 101.0, "batch_reward": 0.00784497302188538, "critic_loss": 0.0016809710638372053, "actor_loss": -7.106817930743098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.86032319068909, "step": 101000}
{"episode_reward": 3.014796717694396, "episode": 102.0, "batch_reward": 0.007995893399696797, "critic_loss": 0.0015817391527525614, "actor_loss": -7.238212396644056, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.671202659606934, "step": 102000}
{"episode_reward": 3.325007667523145, "episode": 103.0, "batch_reward": 0.008019974914845079, "critic_loss": 0.0015746181705835625, "actor_loss": -7.041273121103645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.788275718688965, "step": 103000}
{"episode_reward": 3.4565837891501765, "episode": 104.0, "batch_reward": 0.00786470921104774, "critic_loss": 0.0014465402456989977, "actor_loss": -6.441308365985751, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.996449947357178, "step": 104000}
{"episode_reward": 3.018948980398935, "episode": 105.0, "batch_reward": 0.007887979580787942, "critic_loss": 0.0016147597582821618, "actor_loss": -6.056508764013648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.339943885803223, "step": 105000}
{"episode_reward": 3.740692872255371, "episode": 106.0, "batch_reward": 0.007815427588997408, "critic_loss": 0.001534215757783386, "actor_loss": -5.531057975038886, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00989007949829, "step": 106000}
{"episode_reward": 3.4520680342590424, "episode": 107.0, "batch_reward": 0.007838983276393265, "critic_loss": 0.0021920862701008447, "actor_loss": -6.182199745651334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.31075167655945, "step": 107000}
{"episode_reward": 3.120927182298982, "episode": 108.0, "batch_reward": 0.007629710793728009, "critic_loss": 0.0016113538422177953, "actor_loss": -7.2176561680585145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.767683744430542, "step": 108000}
{"episode_reward": 2.7336144355426466, "episode": 109.0, "batch_reward": 0.007482882269658148, "critic_loss": 0.0017190191821027838, "actor_loss": -6.893152813330293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.871127605438232, "step": 109000}
{"episode_reward": 2.547710018588123, "episode": 110.0, "batch_reward": 0.0074304364217678085, "critic_loss": 0.0017115455459024815, "actor_loss": -6.8281041566357015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.177817583084106, "step": 110000}
{"episode_reward": 3.5344808713604667, "episode": 111.0, "batch_reward": 0.007473042655852623, "critic_loss": 0.0020212667309460813, "actor_loss": -7.549700806625188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.3413987159729, "step": 111000}
{"episode_reward": 3.3576610520197265, "episode": 112.0, "batch_reward": 0.0075643284623511135, "critic_loss": 0.0013770251572714188, "actor_loss": -6.553258357856422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.378242015838623, "step": 112000}
{"episode_reward": 4.461779346559986, "episode": 113.0, "batch_reward": 0.00731326854287181, "critic_loss": 0.0020742980205723143, "actor_loss": -6.425806994773447, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.483978986740112, "step": 113000}
{"episode_reward": 3.9186286010878932, "episode": 114.0, "batch_reward": 0.0073430763895157725, "critic_loss": 0.0013407290465293044, "actor_loss": -6.8171739446669815, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.284597396850586, "step": 114000}
{"episode_reward": 4.27361855244822, "episode": 115.0, "batch_reward": 0.007409576950594783, "critic_loss": 0.0014184566276016994, "actor_loss": -6.545080887578428, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.49671483039856, "step": 115000}
{"episode_reward": 3.586688299355286, "episode": 116.0, "batch_reward": 0.007365943856188096, "critic_loss": 0.0013498649922439655, "actor_loss": -6.618682678792625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.65631937980652, "step": 116000}
{"episode_reward": 2.8328506492176393, "episode": 117.0, "batch_reward": 0.007518041781731881, "critic_loss": 0.001878417054318561, "actor_loss": -6.760939106881619, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.565468311309814, "step": 117000}
{"episode_reward": 3.6456737928432266, "episode": 118.0, "batch_reward": 0.007484136929502711, "critic_loss": 0.0014655609658148023, "actor_loss": -6.368865493431687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.34656000137329, "step": 118000}
{"episode_reward": 3.3256676868981145, "episode": 119.0, "batch_reward": 0.0072045078107621525, "critic_loss": 0.0015277465264880447, "actor_loss": -6.163838814608753, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.335925817489624, "step": 119000}
{"episode_reward": 3.080587327063001, "episode": 120.0, "batch_reward": 0.007146824991097674, "critic_loss": 0.0012469246455220854, "actor_loss": -5.569283417589962, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.141167163848877, "step": 120000}
{"episode_reward": 3.9183649864267616, "episode": 121.0, "batch_reward": 0.007230873343884014, "critic_loss": 0.0014778787713730708, "actor_loss": -6.414915929719806, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.848483085632324, "step": 121000}
{"episode_reward": 4.607018741765232, "episode": 122.0, "batch_reward": 0.007230061748065055, "critic_loss": 0.0015892865170244476, "actor_loss": -6.349879112243652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.70865273475647, "step": 122000}
{"episode_reward": 3.2011449931085445, "episode": 123.0, "batch_reward": 0.007201259305467829, "critic_loss": 0.002141595874410996, "actor_loss": -6.2074188768938185, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.035817623138428, "step": 123000}
{"episode_reward": 4.654477377049938, "episode": 124.0, "batch_reward": 0.007146620789309964, "critic_loss": 0.0015473635468770226, "actor_loss": -6.15953979434073, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.71589970588684, "step": 124000}
{"episode_reward": 4.04070348064581, "episode": 125.0, "batch_reward": 0.006978036045562476, "critic_loss": 0.0015581667930055119, "actor_loss": -6.484824289985001, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.080819368362427, "step": 125000}
{"episode_reward": 3.3866481115995413, "episode": 126.0, "batch_reward": 0.006922584990505129, "critic_loss": 0.0015595486344682286, "actor_loss": -6.806091731406748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.212783575057983, "step": 126000}
{"episode_reward": 3.2506882520733273, "episode": 127.0, "batch_reward": 0.007072647847933695, "critic_loss": 0.0012010878202527238, "actor_loss": -6.93101676658541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.451971769332886, "step": 127000}
{"episode_reward": 2.6260665955143616, "episode": 128.0, "batch_reward": 0.006975276505807415, "critic_loss": 0.0014703270652826176, "actor_loss": -7.064594310909509, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.964176893234253, "step": 128000}
{"episode_reward": 3.8175711820175824, "episode": 129.0, "batch_reward": 0.007032852243166417, "critic_loss": 0.0014609340672468534, "actor_loss": -7.9097382017746565, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.211925983428955, "step": 129000}
{"episode_reward": 3.915783674362716, "episode": 130.0, "batch_reward": 0.006958412198233418, "critic_loss": 0.0015502778964837489, "actor_loss": -7.261398598022759, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.46142816543579, "step": 130000}
{"episode_reward": 2.898638664996291, "episode": 131.0, "batch_reward": 0.0069480578564107415, "critic_loss": 0.00192938357048115, "actor_loss": -6.9404217732325195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.11840033531189, "step": 131000}
{"episode_reward": 3.160486865622336, "episode": 132.0, "batch_reward": 0.0069891345896758135, "critic_loss": 0.0016877396693562332, "actor_loss": -6.482640954121948, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.04644513130188, "step": 132000}
{"episode_reward": 3.03458700608461, "episode": 133.0, "batch_reward": 0.006903186465264298, "critic_loss": 0.0014483058648147563, "actor_loss": -7.199133009493351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.83710503578186, "step": 133000}
{"episode_reward": 4.33364661735978, "episode": 134.0, "batch_reward": 0.00699582699406892, "critic_loss": 0.001997176839726308, "actor_loss": -7.050959344640374, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.11110520362854, "step": 134000}
{"episode_reward": 4.564203314256974, "episode": 135.0, "batch_reward": 0.006889851318206638, "critic_loss": 0.0012343312827870249, "actor_loss": -6.198012326784432, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.067475080490112, "step": 135000}
{"episode_reward": 2.74534870201248, "episode": 136.0, "batch_reward": 0.0066720996873918925, "critic_loss": 0.0009510703000341892, "actor_loss": -7.510718628406525, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.59766912460327, "step": 136000}
{"episode_reward": 2.8354093821273914, "episode": 137.0, "batch_reward": 0.006843361698556692, "critic_loss": 0.0014185673409738229, "actor_loss": -6.009167249515652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.465187072753906, "step": 137000}
{"episode_reward": 3.0639721249969547, "episode": 138.0, "batch_reward": 0.00696257212292403, "critic_loss": 0.0015372134514764185, "actor_loss": -5.941767337512225, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.60241389274597, "step": 138000}
{"episode_reward": 3.679441501477961, "episode": 139.0, "batch_reward": 0.006842781669460237, "critic_loss": 0.0012263716059023864, "actor_loss": -6.79647915174067, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.80763053894043, "step": 139000}
{"episode_reward": 2.5637444995198697, "episode": 140.0, "batch_reward": 0.0066755976981949065, "critic_loss": 0.001364442150159448, "actor_loss": -6.735962644785642, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.05474829673767, "step": 140000}
{"episode_reward": 2.6481765931428547, "episode": 141.0, "batch_reward": 0.006700104496092535, "critic_loss": 0.0011936092935538908, "actor_loss": -6.406828297644854, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.11952352523804, "step": 141000}
{"episode_reward": 2.5276692609128766, "episode": 142.0, "batch_reward": 0.00668124041846022, "critic_loss": 0.0012957568249912584, "actor_loss": -5.362478983856738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.76223659515381, "step": 142000}
{"episode_reward": 3.6483030747678793, "episode": 143.0, "batch_reward": 0.006631162730744109, "critic_loss": 0.0016137410401861417, "actor_loss": -6.473125451445579, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.83325481414795, "step": 143000}
{"episode_reward": 3.464587282720599, "episode": 144.0, "batch_reward": 0.006797566382330842, "critic_loss": 0.0016998313030780992, "actor_loss": -6.144973806984723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.6496479511261, "step": 144000}
{"episode_reward": 3.3637201942207486, "episode": 145.0, "batch_reward": 0.006539398087654262, "critic_loss": 0.0010828962693885842, "actor_loss": -5.479584600463509, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.95659303665161, "step": 145000}
{"episode_reward": 3.4765721988077103, "episode": 146.0, "batch_reward": 0.006582049837103114, "critic_loss": 0.0011253213181480533, "actor_loss": -5.948944788649678, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.6904079914093, "step": 146000}
{"episode_reward": 4.410842326936252, "episode": 147.0, "batch_reward": 0.0064685853181872515, "critic_loss": 0.001314960122712364, "actor_loss": -6.192299849741161, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.455769538879395, "step": 147000}
{"episode_reward": 3.384428560772939, "episode": 148.0, "batch_reward": 0.006864480448537506, "critic_loss": 0.0014249096211533469, "actor_loss": -6.666153224796057, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.90575361251831, "step": 148000}
{"episode_reward": 2.792054363880303, "episode": 149.0, "batch_reward": 0.006510575704742223, "critic_loss": 0.0010433980439665902, "actor_loss": -5.601659180171787, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.612377882003784, "step": 149000}
{"episode_reward": 4.2287583199779055, "episode": 150.0, "batch_reward": 0.006462520130211488, "critic_loss": 0.0014471247213514288, "actor_loss": -5.934678840301931, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
