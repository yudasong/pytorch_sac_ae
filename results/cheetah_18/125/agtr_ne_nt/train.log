{"episode_reward": 0.0, "episode": 1.0, "duration": 18.17836356163025, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 2.1793596744537354, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.23014523783557692, "critic_loss": 0.19910298694433193, "actor_loss": -47.540758002419715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 97.30959105491638, "step": 3000}
{"episode_reward": 291.2971761527071, "episode": 4.0, "batch_reward": 0.2501246657520533, "critic_loss": 0.1945602209046483, "actor_loss": -45.56545948791504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.808122158050537, "step": 4000}
{"episode_reward": 149.32462556482093, "episode": 5.0, "batch_reward": 0.23983713316917418, "critic_loss": 0.22038434551656247, "actor_loss": -41.216865798950195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.924293041229248, "step": 5000}
{"episode_reward": 369.63523977602534, "episode": 6.0, "batch_reward": 0.26698624208569527, "critic_loss": 0.2507236872315407, "actor_loss": -43.640016693115236, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.63082981109619, "step": 6000}
{"episode_reward": 417.55063094201563, "episode": 7.0, "batch_reward": 0.2813776392787695, "critic_loss": 0.329008447393775, "actor_loss": -44.84977072143555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.77411675453186, "step": 7000}
{"episode_reward": 319.1143531258177, "episode": 8.0, "batch_reward": 0.2930171485543251, "critic_loss": 0.3500009632706642, "actor_loss": -45.72138954925537, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.802783727645874, "step": 8000}
{"episode_reward": 362.4433480703661, "episode": 9.0, "batch_reward": 0.30070468738675116, "critic_loss": 0.4202320929020643, "actor_loss": -46.2962952041626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.757453680038452, "step": 9000}
{"episode_reward": 394.57865506554526, "episode": 10.0, "batch_reward": 0.3119095300137997, "critic_loss": 0.47313333964347837, "actor_loss": -47.213589256286625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.62343668937683, "step": 10000}
{"episode_reward": 404.47384867591586, "episode": 11.0, "batch_reward": 0.3210599177479744, "critic_loss": 0.4704877035617828, "actor_loss": -48.0701752243042, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 50.16166424751282, "step": 11000}
{"episode_reward": 424.8980885188028, "episode": 12.0, "batch_reward": 0.3290995568335056, "critic_loss": 0.4702634359896183, "actor_loss": -48.62370705413819, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.06644129753113, "step": 12000}
{"episode_reward": 428.14214201195966, "episode": 13.0, "batch_reward": 0.33858848601579666, "critic_loss": 0.5033693003058434, "actor_loss": -49.368048690795895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.879299640655518, "step": 13000}
{"episode_reward": 439.19560557302145, "episode": 14.0, "batch_reward": 0.34611000886559484, "critic_loss": 0.5342099658548832, "actor_loss": -49.922559028625486, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.078577518463135, "step": 14000}
{"episode_reward": 445.9290923528779, "episode": 15.0, "batch_reward": 0.3513653155863285, "critic_loss": 0.548024514913559, "actor_loss": -50.31489720153809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.392157316207886, "step": 15000}
{"episode_reward": 402.667126786601, "episode": 16.0, "batch_reward": 0.3565848732590675, "critic_loss": 0.536065761744976, "actor_loss": -50.843734954833984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.769856929779053, "step": 16000}
{"episode_reward": 421.39406990466733, "episode": 17.0, "batch_reward": 0.3589075165390968, "critic_loss": 0.5576191366314888, "actor_loss": -51.001658554077146, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.5772442817688, "step": 17000}
{"episode_reward": 415.1938474825501, "episode": 18.0, "batch_reward": 0.3627628228664398, "critic_loss": 0.5550197665393353, "actor_loss": -51.280381217956545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.053187131881714, "step": 18000}
{"episode_reward": 408.2354680826345, "episode": 19.0, "batch_reward": 0.3644577071070671, "critic_loss": 0.5844297112822533, "actor_loss": -51.47273609161377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.605420112609863, "step": 19000}
{"episode_reward": 394.4612600875738, "episode": 20.0, "batch_reward": 0.366528597921133, "critic_loss": 0.5605750657022, "actor_loss": -51.677668617248536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.18313717842102, "step": 20000}
{"episode_reward": 397.72642874689944, "episode": 21.0, "batch_reward": 0.3673525578379631, "critic_loss": 0.5587366369962692, "actor_loss": -51.81594783782959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 52.30800271034241, "step": 21000}
{"episode_reward": 399.7182727514429, "episode": 22.0, "batch_reward": 0.37010269731283185, "critic_loss": 0.5951721864938736, "actor_loss": -52.09173706817627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.62759304046631, "step": 22000}
{"episode_reward": 395.131138225088, "episode": 23.0, "batch_reward": 0.37155889737606046, "critic_loss": 0.6453578357994556, "actor_loss": -52.19193759155274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.559850931167603, "step": 23000}
{"episode_reward": 406.2784711909237, "episode": 24.0, "batch_reward": 0.3711127273142338, "critic_loss": 0.6938807006180286, "actor_loss": -52.15943315887451, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.433650255203247, "step": 24000}
{"episode_reward": 381.0496147380775, "episode": 25.0, "batch_reward": 0.37058835768699644, "critic_loss": 0.9004303111732006, "actor_loss": -52.18907232666016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.847139358520508, "step": 25000}
{"episode_reward": 382.82836542192564, "episode": 26.0, "batch_reward": 0.37197940281033515, "critic_loss": 0.7796139987707138, "actor_loss": -52.32892211914063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.881820917129517, "step": 26000}
{"episode_reward": 406.74806087756247, "episode": 27.0, "batch_reward": 0.373981166601181, "critic_loss": 0.9168328273892402, "actor_loss": -52.46011507415771, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.566659212112427, "step": 27000}
{"episode_reward": 390.5102095870486, "episode": 28.0, "batch_reward": 0.37501610577106476, "critic_loss": 0.9319984188973903, "actor_loss": -52.589836662292484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.814999103546143, "step": 28000}
{"episode_reward": 391.66419939458626, "episode": 29.0, "batch_reward": 0.3757482956647873, "critic_loss": 2.1988473197817804, "actor_loss": -52.57683576965332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.7839572429657, "step": 29000}
{"episode_reward": 295.11308040335007, "episode": 30.0, "batch_reward": 0.37316854926943777, "critic_loss": 5.012432163625956, "actor_loss": -52.145078498840334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.472907543182373, "step": 30000}
{"episode_reward": 400.1898757343914, "episode": 31.0, "batch_reward": 0.37329254287481306, "critic_loss": 4.642309711277485, "actor_loss": -52.2209774017334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 52.42250943183899, "step": 31000}
{"episode_reward": 345.05122082713325, "episode": 32.0, "batch_reward": 0.37294081315398214, "critic_loss": 6.839964788615704, "actor_loss": -52.25740953063965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.377646446228027, "step": 32000}
{"episode_reward": 380.2829074940997, "episode": 33.0, "batch_reward": 0.37315963035821914, "critic_loss": 4.998792170584202, "actor_loss": -52.23528558349609, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.008638858795166, "step": 33000}
{"episode_reward": 416.99778424101356, "episode": 34.0, "batch_reward": 0.373892095297575, "critic_loss": 5.038027094900608, "actor_loss": -52.36274996185303, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.654411554336548, "step": 34000}
{"episode_reward": 375.5531252631998, "episode": 35.0, "batch_reward": 0.3731078963875771, "critic_loss": 5.4568153948783875, "actor_loss": -52.36328888702393, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.789541006088257, "step": 35000}
{"episode_reward": 384.2842428466495, "episode": 36.0, "batch_reward": 0.3741728681921959, "critic_loss": 4.855174119949341, "actor_loss": -52.45883946990967, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.735787868499756, "step": 36000}
{"episode_reward": 399.44242163133066, "episode": 37.0, "batch_reward": 0.3753768498301506, "critic_loss": 5.110361183524132, "actor_loss": -52.48425939178467, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.208003759384155, "step": 37000}
{"episode_reward": 402.35003096463413, "episode": 38.0, "batch_reward": 0.3755836520791054, "critic_loss": 4.845618264198303, "actor_loss": -52.57275405883789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.756583213806152, "step": 38000}
{"episode_reward": 417.2931041123493, "episode": 39.0, "batch_reward": 0.3769569536149502, "critic_loss": 5.169124889612198, "actor_loss": -52.710406005859376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.390175104141235, "step": 39000}
{"episode_reward": 407.12969345868794, "episode": 40.0, "batch_reward": 0.37699491980671884, "critic_loss": 5.07453017115593, "actor_loss": -52.67389054107666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.136507511138916, "step": 40000}
{"episode_reward": 396.3834326824655, "episode": 41.0, "batch_reward": 0.3781343043744564, "critic_loss": 5.235086760997772, "actor_loss": -52.81775147247315, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 52.86289143562317, "step": 41000}
{"episode_reward": 405.5477090241137, "episode": 42.0, "batch_reward": 0.37904497012495997, "critic_loss": 5.248643275976181, "actor_loss": -52.786256683349606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.741121530532837, "step": 42000}
{"episode_reward": 385.85394133860245, "episode": 43.0, "batch_reward": 0.3755623851120472, "critic_loss": 8.591950891137124, "actor_loss": -52.458077766418455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.982383012771606, "step": 43000}
{"episode_reward": 90.26194827161939, "episode": 44.0, "batch_reward": 0.37216226384043694, "critic_loss": 8.280762641072274, "actor_loss": -51.94318701171875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.782316207885742, "step": 44000}
{"episode_reward": 414.90263381418157, "episode": 45.0, "batch_reward": 0.3732103861272335, "critic_loss": 7.402210032582283, "actor_loss": -52.067991691589356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.719452142715454, "step": 45000}
{"episode_reward": 435.7946391563289, "episode": 46.0, "batch_reward": 0.3746297451555729, "critic_loss": 6.871324276089668, "actor_loss": -52.16568323516846, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.499406814575195, "step": 46000}
{"episode_reward": 430.47907882372857, "episode": 47.0, "batch_reward": 0.37652239021658895, "critic_loss": 6.3230269229412075, "actor_loss": -52.34375161743164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.892768144607544, "step": 47000}
{"episode_reward": 418.39488123832194, "episode": 48.0, "batch_reward": 0.37750693371891975, "critic_loss": 5.930683302998543, "actor_loss": -52.39899546051026, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.837109327316284, "step": 48000}
{"episode_reward": 404.96536725449414, "episode": 49.0, "batch_reward": 0.3768381784558296, "critic_loss": 8.197296597361564, "actor_loss": -52.28232691192627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.521994590759277, "step": 49000}
{"episode_reward": 199.89979565339192, "episode": 50.0, "batch_reward": 0.373479974091053, "critic_loss": 9.029580819368363, "actor_loss": -51.929261192321775, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.510576963424683, "step": 50000}
{"episode_reward": 418.56784837380656, "episode": 51.0, "batch_reward": 0.37163927280902864, "critic_loss": 14.015617728710174, "actor_loss": -51.61869313049316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 53.132227420806885, "step": 51000}
{"episode_reward": 58.253162731968864, "episode": 52.0, "batch_reward": 0.3681853679418564, "critic_loss": 12.84006566977501, "actor_loss": -51.264363929748534, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.389336109161377, "step": 52000}
{"episode_reward": 371.0777526825946, "episode": 53.0, "batch_reward": 0.3686808741390705, "critic_loss": 10.421173937559129, "actor_loss": -51.30271687316895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.708258390426636, "step": 53000}
{"episode_reward": 423.9789096623869, "episode": 54.0, "batch_reward": 0.3692295888364315, "critic_loss": 8.972653731584549, "actor_loss": -51.414844367980955, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.05778956413269, "step": 54000}
{"episode_reward": 383.1405772719204, "episode": 55.0, "batch_reward": 0.3699080169796944, "critic_loss": 9.204013260364533, "actor_loss": -51.42548107147217, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.63305950164795, "step": 55000}
{"episode_reward": 414.29370236809535, "episode": 56.0, "batch_reward": 0.370975291877985, "critic_loss": 9.06893362736702, "actor_loss": -51.50922118377686, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.77770209312439, "step": 56000}
{"episode_reward": 411.8522253219405, "episode": 57.0, "batch_reward": 0.37104684153199197, "critic_loss": 9.244512500762939, "actor_loss": -51.514281272888184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.915191888809204, "step": 57000}
{"episode_reward": 392.8162754692526, "episode": 58.0, "batch_reward": 0.3717301358282566, "critic_loss": 9.247332956314088, "actor_loss": -51.60791237640381, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.799642086029053, "step": 58000}
{"episode_reward": 426.3776758255862, "episode": 59.0, "batch_reward": 0.37290502765774725, "critic_loss": 8.778623030185699, "actor_loss": -51.6919084777832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.037134885787964, "step": 59000}
{"episode_reward": 425.2954496187375, "episode": 60.0, "batch_reward": 0.3740213076174259, "critic_loss": 8.361121072292327, "actor_loss": -51.84420290374756, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.74061894416809, "step": 60000}
{"episode_reward": 429.0210780543296, "episode": 61.0, "batch_reward": 0.3747635645866394, "critic_loss": 7.862987652540207, "actor_loss": -51.86926071929932, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 53.8556010723114, "step": 61000}
{"episode_reward": 419.87632270800196, "episode": 62.0, "batch_reward": 0.3754500063657761, "critic_loss": 7.738937572479248, "actor_loss": -51.998754722595216, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.569112062454224, "step": 62000}
{"episode_reward": 403.0112322784109, "episode": 63.0, "batch_reward": 0.3750651753246784, "critic_loss": 7.407914095878601, "actor_loss": -51.90906341552734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.82917356491089, "step": 63000}
{"episode_reward": 398.1308618378846, "episode": 64.0, "batch_reward": 0.3761825146377087, "critic_loss": 6.605633782863617, "actor_loss": -52.00529446411133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.04919505119324, "step": 64000}
{"episode_reward": 415.9962994969219, "episode": 65.0, "batch_reward": 0.37678951025009155, "critic_loss": 6.6255585403442385, "actor_loss": -52.0272698135376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 35.937546730041504, "step": 65000}
{"episode_reward": 427.82579215274365, "episode": 66.0, "batch_reward": 0.3777047156095505, "critic_loss": 7.012210065841675, "actor_loss": -52.12919348144531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 34.21606159210205, "step": 66000}
{"episode_reward": 407.8509889480483, "episode": 67.0, "batch_reward": 0.37746571627259257, "critic_loss": 6.758847326517105, "actor_loss": -52.0698363494873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.648732900619507, "step": 67000}
{"episode_reward": 388.74704118271785, "episode": 68.0, "batch_reward": 0.3777018954157829, "critic_loss": 7.169319218635559, "actor_loss": -52.17154939270019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.21359872817993, "step": 68000}
{"episode_reward": 404.2475177017623, "episode": 69.0, "batch_reward": 0.37833013650774955, "critic_loss": 6.66775874876976, "actor_loss": -52.199160339355466, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.219077587127686, "step": 69000}
{"episode_reward": 414.63779509261866, "episode": 70.0, "batch_reward": 0.3785226181447506, "critic_loss": 6.793381452560425, "actor_loss": -52.202190330505374, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.41260051727295, "step": 70000}
{"episode_reward": 401.4493065504297, "episode": 71.0, "batch_reward": 0.37903158977627754, "critic_loss": 5.931084979772567, "actor_loss": -52.337534797668454, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 54.900490283966064, "step": 71000}
{"episode_reward": 399.06831375767945, "episode": 72.0, "batch_reward": 0.3795981613993645, "critic_loss": 5.802856900811196, "actor_loss": -52.34684495544433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.4104483127594, "step": 72000}
{"episode_reward": 395.8522323281948, "episode": 73.0, "batch_reward": 0.37927194675803183, "critic_loss": 5.690318408966064, "actor_loss": -52.31840798950196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.857207536697388, "step": 73000}
{"episode_reward": 399.051658710153, "episode": 74.0, "batch_reward": 0.380260373622179, "critic_loss": 5.865659163236618, "actor_loss": -52.44183557891846, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.98042345046997, "step": 74000}
{"episode_reward": 395.3304640299772, "episode": 75.0, "batch_reward": 0.38006928756833075, "critic_loss": 6.31795955657959, "actor_loss": -52.379870025634766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.688354015350342, "step": 75000}
{"episode_reward": 412.86906000559225, "episode": 76.0, "batch_reward": 0.38082995197176933, "critic_loss": 6.142582287549972, "actor_loss": -52.42489768981934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.541643142700195, "step": 76000}
{"episode_reward": 388.7985406852628, "episode": 77.0, "batch_reward": 0.38139213451743126, "critic_loss": 5.604241114854813, "actor_loss": -52.536811080932615, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.779461145401, "step": 77000}
{"episode_reward": 417.49872251722473, "episode": 78.0, "batch_reward": 0.3812303229570389, "critic_loss": 5.682387509822846, "actor_loss": -52.46907973480224, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.39646887779236, "step": 78000}
{"episode_reward": 311.5557250985443, "episode": 79.0, "batch_reward": 0.38040657436847686, "critic_loss": 7.104186665534973, "actor_loss": -52.42876643371582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.52038836479187, "step": 79000}
{"episode_reward": 367.85137537645977, "episode": 80.0, "batch_reward": 0.3800626835227013, "critic_loss": 7.157088831663132, "actor_loss": -52.43772179412842, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.34172773361206, "step": 80000}
{"episode_reward": 393.11135993770415, "episode": 81.0, "batch_reward": 0.3795980006158352, "critic_loss": 7.107298583269119, "actor_loss": -52.45470826721191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 54.61416697502136, "step": 81000}
{"episode_reward": 392.30847531005213, "episode": 82.0, "batch_reward": 0.3805745462477207, "critic_loss": 6.4944255936145785, "actor_loss": -52.452379280090334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.60577893257141, "step": 82000}
{"episode_reward": 398.50198659748804, "episode": 83.0, "batch_reward": 0.3794221468567848, "critic_loss": 7.7971586227417, "actor_loss": -52.45721871948242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.175225973129272, "step": 83000}
{"episode_reward": 253.11249826415386, "episode": 84.0, "batch_reward": 0.3790446329116821, "critic_loss": 7.8018543474674225, "actor_loss": -52.36007537841797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.4803249835968, "step": 84000}
{"episode_reward": 387.26850140933436, "episode": 85.0, "batch_reward": 0.37954263922572135, "critic_loss": 8.106166922926903, "actor_loss": -52.420132804870605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.802982091903687, "step": 85000}
{"episode_reward": 400.24503508067005, "episode": 86.0, "batch_reward": 0.3791747685074806, "critic_loss": 7.63884114408493, "actor_loss": -52.439996177673336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.90139651298523, "step": 86000}
{"episode_reward": 390.63520646301, "episode": 87.0, "batch_reward": 0.37962266224622726, "critic_loss": 7.16696790766716, "actor_loss": -52.446970748901364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.791102170944214, "step": 87000}
{"episode_reward": 408.3607178732839, "episode": 88.0, "batch_reward": 0.37978655576705933, "critic_loss": 7.594439427137375, "actor_loss": -52.43794218444824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.369174480438232, "step": 88000}
{"episode_reward": 419.27462927245887, "episode": 89.0, "batch_reward": 0.38008324792981146, "critic_loss": 7.389288489341736, "actor_loss": -52.547450004577634, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.956584692001343, "step": 89000}
{"episode_reward": 389.3607190139052, "episode": 90.0, "batch_reward": 0.37999035298824313, "critic_loss": 8.101415384292602, "actor_loss": -52.46541586303711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.080869436264038, "step": 90000}
{"episode_reward": 381.1271875935724, "episode": 91.0, "batch_reward": 0.38060366216301916, "critic_loss": 7.0264112944602966, "actor_loss": -52.532925399780275, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 55.08846426010132, "step": 91000}
{"episode_reward": 378.2162929192805, "episode": 92.0, "batch_reward": 0.38076412087678907, "critic_loss": 7.0224610757827755, "actor_loss": -52.60311143493652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.47567343711853, "step": 92000}
{"episode_reward": 388.0643035197992, "episode": 93.0, "batch_reward": 0.38095609122514723, "critic_loss": 7.380496292114258, "actor_loss": -52.59330814361572, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.718562841415405, "step": 93000}
{"episode_reward": 388.17116287659917, "episode": 94.0, "batch_reward": 0.3808931056261063, "critic_loss": 6.8707888190746305, "actor_loss": -52.64473229217529, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.585800170898438, "step": 94000}
{"episode_reward": 408.4527370781151, "episode": 95.0, "batch_reward": 0.3803775445520878, "critic_loss": 7.098880120992661, "actor_loss": -52.56745169067383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.47804307937622, "step": 95000}
{"episode_reward": 394.64146675997506, "episode": 96.0, "batch_reward": 0.3803866867721081, "critic_loss": 6.804288359642029, "actor_loss": -52.52356769561768, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.65202808380127, "step": 96000}
{"episode_reward": 380.44664847555094, "episode": 97.0, "batch_reward": 0.3810027832984924, "critic_loss": 6.520881399154663, "actor_loss": -52.59127607727051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.902580738067627, "step": 97000}
{"episode_reward": 412.2205952487367, "episode": 98.0, "batch_reward": 0.3818471153974533, "critic_loss": 6.230142700195312, "actor_loss": -52.684831985473636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.995035648345947, "step": 98000}
{"episode_reward": 395.8696217786817, "episode": 99.0, "batch_reward": 0.3812950736582279, "critic_loss": 7.14343239569664, "actor_loss": -52.71419059753418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.732785940170288, "step": 99000}
{"episode_reward": 290.2209187546937, "episode": 100.0, "batch_reward": 0.3801853832602501, "critic_loss": 7.20846595954895, "actor_loss": -52.53588957977295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.083948135375977, "step": 100000}
{"episode_reward": 379.69142541243247, "episode": 101.0, "batch_reward": 0.38117552363872526, "critic_loss": 6.847043933153152, "actor_loss": -52.60085307312012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 55.740896224975586, "step": 101000}
{"episode_reward": 375.9926672992047, "episode": 102.0, "batch_reward": 0.3809487749040127, "critic_loss": 8.8151256814003, "actor_loss": -52.57418991088867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.518163442611694, "step": 102000}
{"episode_reward": 401.7847176133758, "episode": 103.0, "batch_reward": 0.3790840031802654, "critic_loss": 7.703447392225265, "actor_loss": -52.43161963653564, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.092649936676025, "step": 103000}
{"episode_reward": 41.76146366703897, "episode": 104.0, "batch_reward": 0.37701771399378775, "critic_loss": 8.868672210931779, "actor_loss": -52.174774932861325, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.925110578536987, "step": 104000}
{"episode_reward": 348.1431777898817, "episode": 105.0, "batch_reward": 0.37764605003595353, "critic_loss": 8.325889892816544, "actor_loss": -52.16545748901367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.120158433914185, "step": 105000}
{"episode_reward": 394.01132339648615, "episode": 106.0, "batch_reward": 0.37829997873306276, "critic_loss": 8.434289048671722, "actor_loss": -52.21516081237793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.84528350830078, "step": 106000}
{"episode_reward": 415.4045215071548, "episode": 107.0, "batch_reward": 0.3782251644432545, "critic_loss": 8.872515519380569, "actor_loss": -52.275624862670895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.880080223083496, "step": 107000}
{"episode_reward": 411.64548632476453, "episode": 108.0, "batch_reward": 0.3786539770066738, "critic_loss": 8.125576199769974, "actor_loss": -52.26818385314942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.03374433517456, "step": 108000}
{"episode_reward": 393.42145147607204, "episode": 109.0, "batch_reward": 0.37866949126124383, "critic_loss": 9.092416158437729, "actor_loss": -52.290788230896, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.334246158599854, "step": 109000}
{"episode_reward": 401.4318300865168, "episode": 110.0, "batch_reward": 0.37766118401288984, "critic_loss": 8.66319710445404, "actor_loss": -52.229168937683106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.551129817962646, "step": 110000}
{"episode_reward": 385.8411512625324, "episode": 111.0, "batch_reward": 0.37798247826099396, "critic_loss": 8.905865794181823, "actor_loss": -52.22292040252685, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 55.62868547439575, "step": 111000}
{"episode_reward": 351.7226852000707, "episode": 112.0, "batch_reward": 0.3765585143268108, "critic_loss": 10.220307337522506, "actor_loss": -52.039778327941896, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.47050166130066, "step": 112000}
{"episode_reward": 31.899725741708707, "episode": 113.0, "batch_reward": 0.3749029502272606, "critic_loss": 10.909504131555558, "actor_loss": -51.834346046447756, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.451428174972534, "step": 113000}
{"episode_reward": 380.9762768367277, "episode": 114.0, "batch_reward": 0.37527935579419136, "critic_loss": 9.741438853263855, "actor_loss": -51.939499031066894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.84238576889038, "step": 114000}
{"episode_reward": 407.30533946204986, "episode": 115.0, "batch_reward": 0.37565249985456467, "critic_loss": 9.672658713579178, "actor_loss": -51.9982733001709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.145368814468384, "step": 115000}
{"episode_reward": 393.84545751585387, "episode": 116.0, "batch_reward": 0.3757905541658402, "critic_loss": 10.685114371776582, "actor_loss": -51.881942916870116, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.744748830795288, "step": 116000}
{"episode_reward": 427.1222617833366, "episode": 117.0, "batch_reward": 0.3762535827755928, "critic_loss": 11.223139748334885, "actor_loss": -52.06575434112549, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.667892932891846, "step": 117000}
{"episode_reward": 420.466092893374, "episode": 118.0, "batch_reward": 0.3761547508239746, "critic_loss": 11.310984616279603, "actor_loss": -52.01649410247803, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.05370593070984, "step": 118000}
{"episode_reward": 396.2009071693539, "episode": 119.0, "batch_reward": 0.3768553654551506, "critic_loss": 10.763383117675781, "actor_loss": -52.038113388061525, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.35066056251526, "step": 119000}
{"episode_reward": 393.8399370078987, "episode": 120.0, "batch_reward": 0.37607678762078284, "critic_loss": 10.709015352487564, "actor_loss": -51.99402758789063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.814111948013306, "step": 120000}
{"episode_reward": 390.8766057651467, "episode": 121.0, "batch_reward": 0.37692976596951483, "critic_loss": 10.290832780361175, "actor_loss": -52.11348634338379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 55.82006072998047, "step": 121000}
{"episode_reward": 396.2392108528862, "episode": 122.0, "batch_reward": 0.3775605971813202, "critic_loss": 9.455393142223357, "actor_loss": -52.10565853881836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.692381858825684, "step": 122000}
{"episode_reward": 376.386777421601, "episode": 123.0, "batch_reward": 0.3771020288467407, "critic_loss": 9.181188718795777, "actor_loss": -52.10409307861328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.60244369506836, "step": 123000}
{"episode_reward": 412.7159096397202, "episode": 124.0, "batch_reward": 0.3777610383331776, "critic_loss": 9.136435568332672, "actor_loss": -52.132984077453614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.399662494659424, "step": 124000}
{"episode_reward": 388.8537235322948, "episode": 125.0, "batch_reward": 0.3774826267063618, "critic_loss": 9.291730631113053, "actor_loss": -52.24226982116699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.587990283966064, "step": 125000}
{"episode_reward": 380.2447418045943, "episode": 126.0, "batch_reward": 0.37709436601400376, "critic_loss": 8.985885960817336, "actor_loss": -52.14606604003906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.574066877365112, "step": 126000}
{"episode_reward": 283.9554168990755, "episode": 127.0, "batch_reward": 0.3760347615480423, "critic_loss": 9.258748971939086, "actor_loss": -51.933265007019045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.09279465675354, "step": 127000}
{"episode_reward": 405.696229471509, "episode": 128.0, "batch_reward": 0.37703807061910627, "critic_loss": 9.374784704208373, "actor_loss": -52.09652591705322, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.452138662338257, "step": 128000}
{"episode_reward": 409.9090965756537, "episode": 129.0, "batch_reward": 0.377157915532589, "critic_loss": 9.29502542090416, "actor_loss": -51.95906636810303, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.8721661567688, "step": 129000}
{"episode_reward": 419.59972637323915, "episode": 130.0, "batch_reward": 0.3773446415066719, "critic_loss": 8.448290663003922, "actor_loss": -52.131902885437015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.338430881500244, "step": 130000}
{"episode_reward": 369.0692453067335, "episode": 131.0, "batch_reward": 0.37700835639238356, "critic_loss": 7.691393438100815, "actor_loss": -52.12669888305664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 55.87288308143616, "step": 131000}
{"episode_reward": 416.1734080509259, "episode": 132.0, "batch_reward": 0.3774824914932251, "critic_loss": 7.757959037065506, "actor_loss": -52.129746002197265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.811561822891235, "step": 132000}
{"episode_reward": 361.3620290609118, "episode": 133.0, "batch_reward": 0.37764744547009466, "critic_loss": 7.063014914274215, "actor_loss": -52.20295989227295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.545960426330566, "step": 133000}
{"episode_reward": 398.44763944870357, "episode": 134.0, "batch_reward": 0.37802357813715937, "critic_loss": 7.285455446958542, "actor_loss": -52.225256690979, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.098759412765503, "step": 134000}
{"episode_reward": 414.56921991490975, "episode": 135.0, "batch_reward": 0.3780184910297394, "critic_loss": 7.052971176862717, "actor_loss": -52.194057266235355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.88373565673828, "step": 135000}
{"episode_reward": 382.8075153785301, "episode": 136.0, "batch_reward": 0.37865432432293894, "critic_loss": 6.6644548969268795, "actor_loss": -52.27712511444092, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.88155460357666, "step": 136000}
{"episode_reward": 394.3852461482371, "episode": 137.0, "batch_reward": 0.3777695213854313, "critic_loss": 5.579673319935798, "actor_loss": -52.215649925231936, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.75902771949768, "step": 137000}
{"episode_reward": 402.29254445843065, "episode": 138.0, "batch_reward": 0.37832552257180213, "critic_loss": 5.726325147271156, "actor_loss": -52.247394134521485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.076076984405518, "step": 138000}
{"episode_reward": 411.6318092314346, "episode": 139.0, "batch_reward": 0.3786202632188797, "critic_loss": 4.960277879357338, "actor_loss": -52.26100918579102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.7155921459198, "step": 139000}
{"episode_reward": 349.88018806788307, "episode": 140.0, "batch_reward": 0.3782537613213062, "critic_loss": 4.57993921148777, "actor_loss": -52.22451232147217, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.91627526283264, "step": 140000}
{"episode_reward": 406.3723923601322, "episode": 141.0, "batch_reward": 0.37872993111610415, "critic_loss": 4.920402056932449, "actor_loss": -52.227758430480954, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 56.52981233596802, "step": 141000}
{"episode_reward": 420.35330216254346, "episode": 142.0, "batch_reward": 0.3785622372329235, "critic_loss": 4.828175067663193, "actor_loss": -52.16248117828369, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.62030601501465, "step": 142000}
{"episode_reward": 391.6577812556607, "episode": 143.0, "batch_reward": 0.3790828606784344, "critic_loss": 4.759936367750168, "actor_loss": -52.31360652923584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.221200704574585, "step": 143000}
{"episode_reward": 385.35745901327545, "episode": 144.0, "batch_reward": 0.3795362347066402, "critic_loss": 4.614266710162163, "actor_loss": -52.37263079833984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.265886783599854, "step": 144000}
{"episode_reward": 422.6525642774771, "episode": 145.0, "batch_reward": 0.3796634854078293, "critic_loss": 5.658507743835449, "actor_loss": -52.39889029693604, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.836039543151855, "step": 145000}
{"episode_reward": 405.26527563535114, "episode": 146.0, "batch_reward": 0.3794106149673462, "critic_loss": 5.1903270448446275, "actor_loss": -52.27324166107178, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.78673553466797, "step": 146000}
{"episode_reward": 419.5428945060493, "episode": 147.0, "batch_reward": 0.3794899927973747, "critic_loss": 5.118840687394142, "actor_loss": -52.357966735839845, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.031912803649902, "step": 147000}
{"episode_reward": 425.2425838661879, "episode": 148.0, "batch_reward": 0.3801981354653835, "critic_loss": 6.020710005521774, "actor_loss": -52.33387940216065, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.858445405960083, "step": 148000}
{"episode_reward": 377.96887441789556, "episode": 149.0, "batch_reward": 0.3808705461025238, "critic_loss": 4.695573577046394, "actor_loss": -52.449514656066896, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.505099296569824, "step": 149000}
{"episode_reward": 424.3665761147582, "episode": 150.0, "batch_reward": 0.3802577451467514, "critic_loss": 4.541177963674069, "actor_loss": -52.401878845214846, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
