{"episode_reward": 0.0, "episode": 1.0, "duration": 18.080299139022827, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.6432085037231445, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.21713062763591734, "critic_loss": 0.04653801310406243, "actor_loss": -14.099448124346669, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 68.13818383216858, "step": 3000}
{"episode_reward": 20.374718330379448, "episode": 4.0, "batch_reward": 0.1416788028255105, "critic_loss": 0.037648543417453766, "actor_loss": -15.497323377609252, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.12971305847168, "step": 4000}
{"episode_reward": 15.895254951363757, "episode": 5.0, "batch_reward": 0.11516229486465454, "critic_loss": 0.03369057471118867, "actor_loss": -12.787104352474213, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.753304481506348, "step": 5000}
{"episode_reward": 65.49598670464151, "episode": 6.0, "batch_reward": 0.10480583322793245, "critic_loss": 0.03987924349308014, "actor_loss": -13.13587463569641, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.535698652267456, "step": 6000}
{"episode_reward": 25.53217931922338, "episode": 7.0, "batch_reward": 0.10388070563226938, "critic_loss": 0.07144117358420045, "actor_loss": -13.935108221054078, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.84650444984436, "step": 7000}
{"episode_reward": 177.55417313290056, "episode": 8.0, "batch_reward": 0.10773819740489125, "critic_loss": 0.08689220689237118, "actor_loss": -13.797930312633515, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.031694173812866, "step": 8000}
{"episode_reward": 56.24931485935967, "episode": 9.0, "batch_reward": 0.09853591584786772, "critic_loss": 0.08367727556824685, "actor_loss": -14.702674732208251, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.540437698364258, "step": 9000}
{"episode_reward": 20.838024039892986, "episode": 10.0, "batch_reward": 0.09232675212621688, "critic_loss": 0.08899012472108006, "actor_loss": -13.425706088066102, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.35185694694519, "step": 10000}
{"episode_reward": 69.58828269332827, "episode": 11.0, "batch_reward": 0.09404621585085988, "critic_loss": 0.1245481782220304, "actor_loss": -14.865380724906922, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.50576043128967, "step": 11000}
{"episode_reward": 104.88520724781533, "episode": 12.0, "batch_reward": 0.09152614457905292, "critic_loss": 0.12788544435054064, "actor_loss": -14.518213047027588, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.528324365615845, "step": 12000}
{"episode_reward": 53.12371760658924, "episode": 13.0, "batch_reward": 0.08804588778316974, "critic_loss": 0.1444624920040369, "actor_loss": -14.388310450553893, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.453993797302246, "step": 13000}
{"episode_reward": 90.55951124045197, "episode": 14.0, "batch_reward": 0.08944349784404039, "critic_loss": 0.1732324162647128, "actor_loss": -14.226433660507203, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.5114266872406, "step": 14000}
{"episode_reward": 61.708865274827595, "episode": 15.0, "batch_reward": 0.08825079382956028, "critic_loss": 0.17725617477297784, "actor_loss": -15.616938903808594, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.421553134918213, "step": 15000}
{"episode_reward": 83.10758878235451, "episode": 16.0, "batch_reward": 0.08638168447837234, "critic_loss": 0.1742509305998683, "actor_loss": -15.475615947723389, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.065444231033325, "step": 16000}
{"episode_reward": 45.794007979383856, "episode": 17.0, "batch_reward": 0.08792121241986751, "critic_loss": 0.1964881933182478, "actor_loss": -15.154356624603272, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.37806534767151, "step": 17000}
{"episode_reward": 147.128473211839, "episode": 18.0, "batch_reward": 0.09192017672583461, "critic_loss": 0.2570294820740819, "actor_loss": -15.061065723419189, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.7241051197052, "step": 18000}
{"episode_reward": 172.145057025523, "episode": 19.0, "batch_reward": 0.09167119347676635, "critic_loss": 0.2559920011535287, "actor_loss": -16.286391376495363, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.14012312889099, "step": 19000}
{"episode_reward": 27.78536810022787, "episode": 20.0, "batch_reward": 0.08825912784785032, "critic_loss": 0.2634539570137858, "actor_loss": -15.876323776245117, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.833640336990356, "step": 20000}
{"episode_reward": 32.623547245133324, "episode": 21.0, "batch_reward": 0.08961696749925613, "critic_loss": 0.25152001339942215, "actor_loss": -16.43384983253479, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.95972228050232, "step": 21000}
{"episode_reward": 193.40410700312302, "episode": 22.0, "batch_reward": 0.09460954210162163, "critic_loss": 0.29206493723392485, "actor_loss": -16.245905618667603, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.040299654006958, "step": 22000}
{"episode_reward": 207.81123251714237, "episode": 23.0, "batch_reward": 0.09653530447930098, "critic_loss": 0.3045303936675191, "actor_loss": -15.764699178695679, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.417282819747925, "step": 23000}
{"episode_reward": 39.55923915502892, "episode": 24.0, "batch_reward": 0.09549211103469134, "critic_loss": 0.3102791536226869, "actor_loss": -16.503657537460327, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.121686697006226, "step": 24000}
{"episode_reward": 112.54861345681323, "episode": 25.0, "batch_reward": 0.09515388339012862, "critic_loss": 0.2805800715982914, "actor_loss": -16.409904762268066, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.91577172279358, "step": 25000}
{"episode_reward": 48.61311618943266, "episode": 26.0, "batch_reward": 0.0941143873333931, "critic_loss": 0.3291309076845646, "actor_loss": -16.434574214935303, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.267428874969482, "step": 26000}
{"episode_reward": 103.92173838294465, "episode": 27.0, "batch_reward": 0.09392697314172983, "critic_loss": 0.30584060449153183, "actor_loss": -16.311069444656372, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.622058629989624, "step": 27000}
{"episode_reward": 53.36402773369518, "episode": 28.0, "batch_reward": 0.09305747865140437, "critic_loss": 0.3174002588838339, "actor_loss": -16.29532731819153, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.73318362236023, "step": 28000}
{"episode_reward": 86.00098819803716, "episode": 29.0, "batch_reward": 0.09491941878199578, "critic_loss": 0.31588750902563334, "actor_loss": -16.436556728363037, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.211106061935425, "step": 29000}
{"episode_reward": 149.37201335448677, "episode": 30.0, "batch_reward": 0.09536851778626441, "critic_loss": 0.3438208978623152, "actor_loss": -16.406921667099, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.949012279510498, "step": 30000}
{"episode_reward": 110.22077642508941, "episode": 31.0, "batch_reward": 0.09431026089563965, "critic_loss": 0.36282368044555185, "actor_loss": -16.307824321746825, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.74029350280762, "step": 31000}
{"episode_reward": 50.13310466886097, "episode": 32.0, "batch_reward": 0.09281637996435166, "critic_loss": 0.39602977912127973, "actor_loss": -16.757919605255125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.20911169052124, "step": 32000}
{"episode_reward": 34.477345973480475, "episode": 33.0, "batch_reward": 0.090389809332788, "critic_loss": 0.39539452551305293, "actor_loss": -16.131321937561037, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.46427583694458, "step": 33000}
{"episode_reward": 26.46579746025759, "episode": 34.0, "batch_reward": 0.09029834402352571, "critic_loss": 0.4069042016789317, "actor_loss": -15.663554689407349, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.098285913467407, "step": 34000}
{"episode_reward": 117.64309962038504, "episode": 35.0, "batch_reward": 0.0920775642246008, "critic_loss": 0.4168479073792696, "actor_loss": -16.42931077003479, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.497986793518066, "step": 35000}
{"episode_reward": 162.76999333057992, "episode": 36.0, "batch_reward": 0.09139720234647393, "critic_loss": 0.4688970034122467, "actor_loss": -16.337231309890747, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.964522123336792, "step": 36000}
{"episode_reward": 26.028389447825955, "episode": 37.0, "batch_reward": 0.09050719578936696, "critic_loss": 0.4791317584142089, "actor_loss": -16.082231843948364, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.6294207572937, "step": 37000}
{"episode_reward": 75.68238638716342, "episode": 38.0, "batch_reward": 0.0902606348618865, "critic_loss": 0.4338267664164305, "actor_loss": -15.870648181915284, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.36871600151062, "step": 38000}
{"episode_reward": 70.9582102036633, "episode": 39.0, "batch_reward": 0.09138901849091054, "critic_loss": 0.43801212166249753, "actor_loss": -16.5906042098999, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.182602167129517, "step": 39000}
{"episode_reward": 155.03247777197038, "episode": 40.0, "batch_reward": 0.09065696248039604, "critic_loss": 0.428885223031044, "actor_loss": -16.358317893981933, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.751917123794556, "step": 40000}
{"episode_reward": 45.744061397948904, "episode": 41.0, "batch_reward": 0.0905347025282681, "critic_loss": 0.42981483530253173, "actor_loss": -16.32652047920227, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.807156801223755, "step": 41000}
{"episode_reward": 50.58272791870698, "episode": 42.0, "batch_reward": 0.09103201013430953, "critic_loss": 0.47135805802047254, "actor_loss": -15.82977725791931, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.05142378807068, "step": 42000}
{"episode_reward": 227.49517221948548, "episode": 43.0, "batch_reward": 0.09270694731920957, "critic_loss": 0.43201249715685847, "actor_loss": -16.275964973449707, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.613290309906006, "step": 43000}
{"episode_reward": 93.24970154348243, "episode": 44.0, "batch_reward": 0.093953885525465, "critic_loss": 0.45511739772558213, "actor_loss": -16.395699447631834, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.136658906936646, "step": 44000}
{"episode_reward": 135.25323173419778, "episode": 45.0, "batch_reward": 0.09660722463577985, "critic_loss": 0.44783894495666027, "actor_loss": -16.829140264511107, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.14346933364868, "step": 45000}
{"episode_reward": 295.3817874443553, "episode": 46.0, "batch_reward": 0.09999517969787121, "critic_loss": 0.5001383849084378, "actor_loss": -17.378781536102295, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.37433362007141, "step": 46000}
{"episode_reward": 261.4835977833186, "episode": 47.0, "batch_reward": 0.10348043245077133, "critic_loss": 0.518681985065341, "actor_loss": -17.269808616638183, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.243473768234253, "step": 47000}
{"episode_reward": 186.22527391529457, "episode": 48.0, "batch_reward": 0.10453598362952471, "critic_loss": 0.5529399287551642, "actor_loss": -17.123687154769897, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.35970950126648, "step": 48000}
{"episode_reward": 102.5228078535168, "episode": 49.0, "batch_reward": 0.10345318814367056, "critic_loss": 0.5679443479776383, "actor_loss": -17.3011823387146, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.326165199279785, "step": 49000}
{"episode_reward": 46.686719316870025, "episode": 50.0, "batch_reward": 0.10213251774013042, "critic_loss": 0.6400981933176517, "actor_loss": -16.88550275039673, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.6413996219635, "step": 50000}
{"episode_reward": 119.83778780590325, "episode": 51.0, "batch_reward": 0.10363692805171013, "critic_loss": 0.5249681580662727, "actor_loss": -16.77618838310242, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.357927322387695, "step": 51000}
{"episode_reward": 132.16355170415932, "episode": 52.0, "batch_reward": 0.10464203280210495, "critic_loss": 0.5437689604610205, "actor_loss": -17.461257345199584, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.052420616149902, "step": 52000}
{"episode_reward": 129.01690386071195, "episode": 53.0, "batch_reward": 0.10427777778357267, "critic_loss": 0.6534246066659689, "actor_loss": -17.242648569107054, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.62940502166748, "step": 53000}
{"episode_reward": 142.62725895795802, "episode": 54.0, "batch_reward": 0.10387281903624535, "critic_loss": 0.5399754898548126, "actor_loss": -16.940243431091307, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.541876554489136, "step": 54000}
{"episode_reward": 69.5609015808395, "episode": 55.0, "batch_reward": 0.10636452074348926, "critic_loss": 0.5405407081693411, "actor_loss": -16.953486392974852, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.0078706741333, "step": 55000}
{"episode_reward": 397.82463943327605, "episode": 56.0, "batch_reward": 0.1097369929626584, "critic_loss": 0.580215109422803, "actor_loss": -17.38178186416626, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.92829394340515, "step": 56000}
{"episode_reward": 94.6620578067432, "episode": 57.0, "batch_reward": 0.1093253109678626, "critic_loss": 0.5309059570282698, "actor_loss": -17.622461908340455, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.677096843719482, "step": 57000}
{"episode_reward": 137.91151612101183, "episode": 58.0, "batch_reward": 0.11161139176040888, "critic_loss": 0.6020408572852611, "actor_loss": -17.264898992538452, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.44556736946106, "step": 58000}
{"episode_reward": 238.12295853200507, "episode": 59.0, "batch_reward": 0.1138861218765378, "critic_loss": 0.6425107695907354, "actor_loss": -18.263404232025145, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.075785160064697, "step": 59000}
{"episode_reward": 398.16631165515577, "episode": 60.0, "batch_reward": 0.11815801633894443, "critic_loss": 0.6622668722718954, "actor_loss": -18.47617858695984, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.310218572616577, "step": 60000}
{"episode_reward": 193.81242966584563, "episode": 61.0, "batch_reward": 0.11766480045765638, "critic_loss": 0.6323956443667412, "actor_loss": -18.22896167755127, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.76595139503479, "step": 61000}
{"episode_reward": 77.05324465644514, "episode": 62.0, "batch_reward": 0.11758671797811986, "critic_loss": 0.6264332371801138, "actor_loss": -17.82816133117676, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.47901940345764, "step": 62000}
{"episode_reward": 133.1918095538378, "episode": 63.0, "batch_reward": 0.1194272179827094, "critic_loss": 0.6518721524327994, "actor_loss": -18.34213994216919, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.198424339294434, "step": 63000}
{"episode_reward": 389.24774129134414, "episode": 64.0, "batch_reward": 0.12334745333343744, "critic_loss": 0.6326218758672476, "actor_loss": -18.74946343803406, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.038105964660645, "step": 64000}
{"episode_reward": 323.08947483422077, "episode": 65.0, "batch_reward": 0.12654144410789012, "critic_loss": 0.6162904302179814, "actor_loss": -19.215925010681154, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.412492275238037, "step": 65000}
{"episode_reward": 388.4812955816955, "episode": 66.0, "batch_reward": 0.13077947081625463, "critic_loss": 0.7026953018307686, "actor_loss": -19.59934042930603, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.011314868927002, "step": 66000}
{"episode_reward": 146.8641788031629, "episode": 67.0, "batch_reward": 0.13150350004434586, "critic_loss": 0.6263977471292019, "actor_loss": -19.998272123336793, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.457600593566895, "step": 67000}
{"episode_reward": 428.91861539426566, "episode": 68.0, "batch_reward": 0.13539431138336658, "critic_loss": 0.5970235126018524, "actor_loss": -19.962816745758058, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.129604816436768, "step": 68000}
{"episode_reward": 431.362308151033, "episode": 69.0, "batch_reward": 0.1392845977842808, "critic_loss": 0.5647804391682147, "actor_loss": -20.28966450881958, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.23604679107666, "step": 69000}
{"episode_reward": 453.17804803060426, "episode": 70.0, "batch_reward": 0.1448898303359747, "critic_loss": 0.54111372423172, "actor_loss": -21.132147260665892, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.757689237594604, "step": 70000}
{"episode_reward": 466.5240604701332, "episode": 71.0, "batch_reward": 0.14871026495099068, "critic_loss": 0.5468794669955969, "actor_loss": -21.27439095878601, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.8691680431366, "step": 71000}
{"episode_reward": 459.57959918635004, "episode": 72.0, "batch_reward": 0.15330431056022645, "critic_loss": 0.5124589192718267, "actor_loss": -21.748695249557496, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.738394737243652, "step": 72000}
{"episode_reward": 455.0455641284877, "episode": 73.0, "batch_reward": 0.1576710015758872, "critic_loss": 0.5151267271190881, "actor_loss": -22.27165414428711, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.91312837600708, "step": 73000}
{"episode_reward": 442.74400825426784, "episode": 74.0, "batch_reward": 0.16118973886966706, "critic_loss": 0.4798269610255957, "actor_loss": -22.567459133148194, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.90483260154724, "step": 74000}
{"episode_reward": 449.55198614947574, "episode": 75.0, "batch_reward": 0.16593691837787627, "critic_loss": 0.5008220567107201, "actor_loss": -22.874390718460084, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.15140724182129, "step": 75000}
{"episode_reward": 433.28130560372693, "episode": 76.0, "batch_reward": 0.16860329281538725, "critic_loss": 0.47233091334998606, "actor_loss": -23.244115203857422, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.295729875564575, "step": 76000}
{"episode_reward": 371.1962802911441, "episode": 77.0, "batch_reward": 0.17144795590639114, "critic_loss": 0.4735637289881706, "actor_loss": -24.009717761993407, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.363762140274048, "step": 77000}
{"episode_reward": 461.1484514208833, "episode": 78.0, "batch_reward": 0.17551618510484696, "critic_loss": 0.4953238244354725, "actor_loss": -24.753595500946044, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.2952721118927, "step": 78000}
{"episode_reward": 458.73548188328493, "episode": 79.0, "batch_reward": 0.17799577382951975, "critic_loss": 0.5086140081435442, "actor_loss": -25.315727287292482, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.551896810531616, "step": 79000}
{"episode_reward": 471.30037087644035, "episode": 80.0, "batch_reward": 0.18187149433791638, "critic_loss": 0.504811576128006, "actor_loss": -26.542848545074463, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.46878457069397, "step": 80000}
{"episode_reward": 335.8862721683739, "episode": 81.0, "batch_reward": 0.18461684856563806, "critic_loss": 0.5173617617636919, "actor_loss": -27.710592842102052, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.766364097595215, "step": 81000}
{"episode_reward": 429.89283995974154, "episode": 82.0, "batch_reward": 0.1881615567356348, "critic_loss": 0.4562291429638863, "actor_loss": -28.426458366394044, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.91073989868164, "step": 82000}
{"episode_reward": 370.8191138364843, "episode": 83.0, "batch_reward": 0.1900484636425972, "critic_loss": 0.446404949888587, "actor_loss": -28.518646015167235, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.5281982421875, "step": 83000}
{"episode_reward": 408.1483443619718, "episode": 84.0, "batch_reward": 0.192584931910038, "critic_loss": 0.4664191366881132, "actor_loss": -28.640368114471435, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.665565490722656, "step": 84000}
{"episode_reward": 444.2496452929145, "episode": 85.0, "batch_reward": 0.1951146115809679, "critic_loss": 0.47788495291769506, "actor_loss": -28.685466804504394, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.529686212539673, "step": 85000}
{"episode_reward": 474.5325609170641, "episode": 86.0, "batch_reward": 0.19897358731925488, "critic_loss": 0.46099389116466044, "actor_loss": -28.948379470825195, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.567758083343506, "step": 86000}
{"episode_reward": 500.1527838466023, "episode": 87.0, "batch_reward": 0.20192009061574936, "critic_loss": 0.4090088465213776, "actor_loss": -28.96409848022461, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.160954475402832, "step": 87000}
{"episode_reward": 478.1133537061337, "episode": 88.0, "batch_reward": 0.20508145222067833, "critic_loss": 0.42038814052939416, "actor_loss": -29.115236305236817, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.54031729698181, "step": 88000}
{"episode_reward": 493.1452663550853, "episode": 89.0, "batch_reward": 0.20740808075666428, "critic_loss": 0.4047446054667234, "actor_loss": -29.02934284210205, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.055943727493286, "step": 89000}
{"episode_reward": 160.3787877916616, "episode": 90.0, "batch_reward": 0.2079329850822687, "critic_loss": 0.38714491621404884, "actor_loss": -29.081581283569335, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.50443124771118, "step": 90000}
{"episode_reward": 463.7238168678796, "episode": 91.0, "batch_reward": 0.21110733860731126, "critic_loss": 0.36437156197428705, "actor_loss": -29.034191513061522, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.108428716659546, "step": 91000}
{"episode_reward": 494.51133396335035, "episode": 92.0, "batch_reward": 0.21406730102002622, "critic_loss": 0.38047387421131135, "actor_loss": -29.41393579864502, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.326701879501343, "step": 92000}
{"episode_reward": 511.70497200039586, "episode": 93.0, "batch_reward": 0.21696190889179706, "critic_loss": 0.3651646587774158, "actor_loss": -29.18195972442627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.393192529678345, "step": 93000}
{"episode_reward": 506.5386837774377, "episode": 94.0, "batch_reward": 0.22012111070752144, "critic_loss": 0.37830746147036554, "actor_loss": -29.51345972061157, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.668038845062256, "step": 94000}
{"episode_reward": 391.9562280914413, "episode": 95.0, "batch_reward": 0.22226455283164978, "critic_loss": 0.386546882212162, "actor_loss": -29.61061034011841, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.111543893814087, "step": 95000}
{"episode_reward": 523.7147026897558, "episode": 96.0, "batch_reward": 0.2244731444865465, "critic_loss": 0.3800057430267334, "actor_loss": -29.570429191589355, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.69069266319275, "step": 96000}
{"episode_reward": 476.9862554922872, "episode": 97.0, "batch_reward": 0.2276790520399809, "critic_loss": 0.4011689203083515, "actor_loss": -29.770679306030274, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.60973286628723, "step": 97000}
{"episode_reward": 461.92258720382955, "episode": 98.0, "batch_reward": 0.23049354365468025, "critic_loss": 0.3898211306780577, "actor_loss": -29.852113288879394, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.185359954833984, "step": 98000}
{"episode_reward": 519.8068511559845, "episode": 99.0, "batch_reward": 0.23248978744447232, "critic_loss": 0.386020228639245, "actor_loss": -29.954467685699463, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.25235652923584, "step": 99000}
{"episode_reward": 113.86445713714045, "episode": 100.0, "batch_reward": 0.23280092771351338, "critic_loss": 0.3859501297324896, "actor_loss": -29.626967739105226, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.504460096359253, "step": 100000}
{"episode_reward": 498.41991792996714, "episode": 101.0, "batch_reward": 0.23383289921283723, "critic_loss": 0.3692568292170763, "actor_loss": -29.89715888977051, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.67338585853577, "step": 101000}
{"episode_reward": 504.353423762457, "episode": 102.0, "batch_reward": 0.23686380359530448, "critic_loss": 0.3765849289298058, "actor_loss": -30.088150691986083, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.281922817230225, "step": 102000}
{"episode_reward": 542.6147452800897, "episode": 103.0, "batch_reward": 0.23920833119750023, "critic_loss": 0.3804803763180971, "actor_loss": -30.090067943572997, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.444307327270508, "step": 103000}
{"episode_reward": 494.90239238670745, "episode": 104.0, "batch_reward": 0.24398253233730793, "critic_loss": 0.3773718263059854, "actor_loss": -30.266444896697998, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.56651496887207, "step": 104000}
{"episode_reward": 517.5707804798456, "episode": 105.0, "batch_reward": 0.24572172835469247, "critic_loss": 0.332016923867166, "actor_loss": -30.176127346038818, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.84354281425476, "step": 105000}
{"episode_reward": 529.7490516645495, "episode": 106.0, "batch_reward": 0.24774493741989137, "critic_loss": 0.3710757748931646, "actor_loss": -30.181996994018554, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.122478485107422, "step": 106000}
{"episode_reward": 529.8259786262897, "episode": 107.0, "batch_reward": 0.25063604475557805, "critic_loss": 0.3732762049138546, "actor_loss": -30.529203289031983, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.901066780090332, "step": 107000}
{"episode_reward": 567.6753237008072, "episode": 108.0, "batch_reward": 0.2531451609134674, "critic_loss": 0.3629484100863338, "actor_loss": -30.877928592681886, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.888131618499756, "step": 108000}
{"episode_reward": 540.4155427329789, "episode": 109.0, "batch_reward": 0.25725114640593527, "critic_loss": 0.3847913866788149, "actor_loss": -31.174768074035644, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.88590955734253, "step": 109000}
{"episode_reward": 508.17301601196056, "episode": 110.0, "batch_reward": 0.25917542949318884, "critic_loss": 0.35582833683490755, "actor_loss": -31.127840679168703, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.241058349609375, "step": 110000}
{"episode_reward": 551.8701482107064, "episode": 111.0, "batch_reward": 0.26157101821899414, "critic_loss": 0.37980979031324386, "actor_loss": -31.41973917388916, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.33721399307251, "step": 111000}
{"episode_reward": 515.3842690537859, "episode": 112.0, "batch_reward": 0.26377080237865447, "critic_loss": 0.3660330799818039, "actor_loss": -31.49333013153076, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.411406755447388, "step": 112000}
{"episode_reward": 514.3440000847568, "episode": 113.0, "batch_reward": 0.2647889191955328, "critic_loss": 0.3844225876480341, "actor_loss": -31.5005408744812, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.864525079727173, "step": 113000}
{"episode_reward": 257.49349460942136, "episode": 114.0, "batch_reward": 0.26498902136087416, "critic_loss": 0.4011566694378853, "actor_loss": -31.69068569946289, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.399789810180664, "step": 114000}
{"episode_reward": 231.04440414739182, "episode": 115.0, "batch_reward": 0.26590051509439944, "critic_loss": 0.3791844473779202, "actor_loss": -31.39780444717407, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.183069467544556, "step": 115000}
{"episode_reward": 534.8244536189729, "episode": 116.0, "batch_reward": 0.2692835318595171, "critic_loss": 0.38768761441111566, "actor_loss": -31.760676513671875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.650510787963867, "step": 116000}
{"episode_reward": 533.2581231277684, "episode": 117.0, "batch_reward": 0.27046945166587827, "critic_loss": 0.39350630474090575, "actor_loss": -31.956085014343262, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.780134916305542, "step": 117000}
{"episode_reward": 539.6209267422282, "episode": 118.0, "batch_reward": 0.2717597805559635, "critic_loss": 0.4120642898082733, "actor_loss": -32.095480533599854, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.78347682952881, "step": 118000}
{"episode_reward": 509.0734817707197, "episode": 119.0, "batch_reward": 0.27506104719638824, "critic_loss": 0.3790794761776924, "actor_loss": -32.01460962295532, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.874820947647095, "step": 119000}
{"episode_reward": 522.6033202686946, "episode": 120.0, "batch_reward": 0.2762646344304085, "critic_loss": 0.4191939698010683, "actor_loss": -31.980832763671874, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.793894290924072, "step": 120000}
{"episode_reward": 547.4231133078673, "episode": 121.0, "batch_reward": 0.2797623633146286, "critic_loss": 0.41463531425595285, "actor_loss": -32.1527964553833, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.05753493309021, "step": 121000}
{"episode_reward": 540.7429330004827, "episode": 122.0, "batch_reward": 0.28125913940370084, "critic_loss": 0.4140702736079693, "actor_loss": -32.40615837097168, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.591733932495117, "step": 122000}
{"episode_reward": 513.3044739764034, "episode": 123.0, "batch_reward": 0.2832960700392723, "critic_loss": 0.40277463431656363, "actor_loss": -32.710615795135496, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.128682136535645, "step": 123000}
{"episode_reward": 537.2822175841167, "episode": 124.0, "batch_reward": 0.28506347952783107, "critic_loss": 0.4054984289705753, "actor_loss": -32.97611437225342, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.83949327468872, "step": 124000}
{"episode_reward": 548.0988592426676, "episode": 125.0, "batch_reward": 0.2878283050507307, "critic_loss": 0.39622219601273534, "actor_loss": -32.95400383377075, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.588636875152588, "step": 125000}
{"episode_reward": 541.7462411210892, "episode": 126.0, "batch_reward": 0.2885051464885473, "critic_loss": 0.3981655623167753, "actor_loss": -33.17924069213867, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.116676330566406, "step": 126000}
{"episode_reward": 538.3384218710656, "episode": 127.0, "batch_reward": 0.29062183336913583, "critic_loss": 0.4260220104604959, "actor_loss": -33.56452241897583, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.935152053833008, "step": 127000}
{"episode_reward": 542.0105485353877, "episode": 128.0, "batch_reward": 0.2927849227041006, "critic_loss": 0.3564136195331812, "actor_loss": -33.826499954223635, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.23673152923584, "step": 128000}
{"episode_reward": 573.335951552865, "episode": 129.0, "batch_reward": 0.29494239984452725, "critic_loss": 0.3839327421933413, "actor_loss": -34.2664239730835, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.239763498306274, "step": 129000}
{"episode_reward": 559.2057405486249, "episode": 130.0, "batch_reward": 0.2971198411732912, "critic_loss": 0.3538991053625941, "actor_loss": -33.87133638381958, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.39739966392517, "step": 130000}
{"episode_reward": 553.9161059619977, "episode": 131.0, "batch_reward": 0.2999638906866312, "critic_loss": 0.3741152810156345, "actor_loss": -34.32906033325195, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.08863830566406, "step": 131000}
{"episode_reward": 541.5274814474805, "episode": 132.0, "batch_reward": 0.30122361494600775, "critic_loss": 0.38027957785129546, "actor_loss": -34.13074703598023, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.35860252380371, "step": 132000}
{"episode_reward": 500.0366405168742, "episode": 133.0, "batch_reward": 0.3020899275392294, "critic_loss": 0.38274880483746526, "actor_loss": -34.715452529907225, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.95523452758789, "step": 133000}
{"episode_reward": 538.2048585660556, "episode": 134.0, "batch_reward": 0.3044581814706325, "critic_loss": 0.40612238147854807, "actor_loss": -34.871117336273194, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.34987759590149, "step": 134000}
{"episode_reward": 541.7775202673189, "episode": 135.0, "batch_reward": 0.3051896132081747, "critic_loss": 0.38440140265226364, "actor_loss": -34.71470195388794, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.010815620422363, "step": 135000}
{"episode_reward": 530.2553153292824, "episode": 136.0, "batch_reward": 0.30806152778863904, "critic_loss": 0.39952162076532843, "actor_loss": -34.9653176612854, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.144591808319092, "step": 136000}
{"episode_reward": 538.0192781797323, "episode": 137.0, "batch_reward": 0.3092216279655695, "critic_loss": 0.4177924546673894, "actor_loss": -34.86621615982056, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.552108764648438, "step": 137000}
{"episode_reward": 546.851765535615, "episode": 138.0, "batch_reward": 0.3108983985632658, "critic_loss": 0.40622776877880096, "actor_loss": -34.93004201126099, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.23954963684082, "step": 138000}
{"episode_reward": 539.3405399791357, "episode": 139.0, "batch_reward": 0.3125833592861891, "critic_loss": 0.36581324411183597, "actor_loss": -35.32141902923584, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.785799026489258, "step": 139000}
{"episode_reward": 559.9376723415536, "episode": 140.0, "batch_reward": 0.3137401230931282, "critic_loss": 0.40321559365838766, "actor_loss": -35.35319543075561, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.595497608184814, "step": 140000}
{"episode_reward": 559.9936556142765, "episode": 141.0, "batch_reward": 0.3158215775489807, "critic_loss": 0.40954735643416645, "actor_loss": -35.47927757263184, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.83681797981262, "step": 141000}
{"episode_reward": 549.8288032516526, "episode": 142.0, "batch_reward": 0.3171955372840166, "critic_loss": 0.39047091083228586, "actor_loss": -35.577978500366214, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.212127447128296, "step": 142000}
{"episode_reward": 559.2203453148929, "episode": 143.0, "batch_reward": 0.32047837603092194, "critic_loss": 0.3727950599193573, "actor_loss": -36.114028743743894, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.56877565383911, "step": 143000}
{"episode_reward": 580.2032995114922, "episode": 144.0, "batch_reward": 0.3221375606954098, "critic_loss": 0.37011686016619205, "actor_loss": -36.22356620407105, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.89552354812622, "step": 144000}
{"episode_reward": 553.6826481358678, "episode": 145.0, "batch_reward": 0.3234552545845509, "critic_loss": 0.3822249103486538, "actor_loss": -36.12337385177612, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.13259243965149, "step": 145000}
{"episode_reward": 569.1336773709164, "episode": 146.0, "batch_reward": 0.32523314049839974, "critic_loss": 0.36599542742967606, "actor_loss": -36.73833017349243, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.999475955963135, "step": 146000}
{"episode_reward": 557.6533103077587, "episode": 147.0, "batch_reward": 0.3248480532765389, "critic_loss": 0.3852236956059933, "actor_loss": -36.72207495117188, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.438713312149048, "step": 147000}
{"episode_reward": 544.1370440528345, "episode": 148.0, "batch_reward": 0.32907273414731025, "critic_loss": 0.37520376771688463, "actor_loss": -37.08705902481079, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.609741926193237, "step": 148000}
{"episode_reward": 571.7410522479519, "episode": 149.0, "batch_reward": 0.3299161067008972, "critic_loss": 0.4003802125006914, "actor_loss": -37.07590634155274, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.801371812820435, "step": 149000}
{"episode_reward": 572.5363400739031, "episode": 150.0, "batch_reward": 0.33188046568632124, "critic_loss": 0.3967418477088213, "actor_loss": -37.53652683639526, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
