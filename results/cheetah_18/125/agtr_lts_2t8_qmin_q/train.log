{"episode_reward": 0.0, "episode": 1.0, "duration": 13.156426668167114, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.1308112144470215, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.2184991276524551, "critic_loss": 0.2336781674194193, "actor_loss": -44.43436653073095, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 71.61875867843628, "step": 3000}
{"episode_reward": 58.08290445536302, "episode": 4.0, "batch_reward": 0.1635677876919508, "critic_loss": 0.18120333874225616, "actor_loss": -39.36695510864258, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.63485050201416, "step": 4000}
{"episode_reward": 114.43314137571417, "episode": 5.0, "batch_reward": 0.1559876813367009, "critic_loss": 0.19021316818892955, "actor_loss": -38.11225377655029, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.648531913757324, "step": 5000}
{"episode_reward": 109.40881338554847, "episode": 6.0, "batch_reward": 0.14926712244004012, "critic_loss": 0.19749284764379263, "actor_loss": -35.81560039138794, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.85844349861145, "step": 6000}
{"episode_reward": 172.7463052483936, "episode": 7.0, "batch_reward": 0.15806499026715756, "critic_loss": 0.21246151477843522, "actor_loss": -35.688680458068845, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.423463344573975, "step": 7000}
{"episode_reward": 221.67195920522872, "episode": 8.0, "batch_reward": 0.16813447798788547, "critic_loss": 0.22509568985551595, "actor_loss": -35.79947184371948, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.66651940345764, "step": 8000}
{"episode_reward": 224.68252209377704, "episode": 9.0, "batch_reward": 0.16927725449204445, "critic_loss": 0.23416495890915393, "actor_loss": -33.92697017288208, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.34303379058838, "step": 9000}
{"episode_reward": 96.0390099210262, "episode": 10.0, "batch_reward": 0.16473244214802982, "critic_loss": 0.24298078405112028, "actor_loss": -32.962273780822755, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.633880615234375, "step": 10000}
{"episode_reward": 138.24630476469804, "episode": 11.0, "batch_reward": 0.15341606646031142, "critic_loss": 0.18972382301092147, "actor_loss": -30.440075019836424, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.95597171783447, "step": 11000}
{"episode_reward": 21.730554514583215, "episode": 12.0, "batch_reward": 0.1431177771091461, "critic_loss": 0.16548337857425213, "actor_loss": -28.587305187225343, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.370464086532593, "step": 12000}
{"episode_reward": 33.408971073649724, "episode": 13.0, "batch_reward": 0.14196512685716153, "critic_loss": 0.15814843229949474, "actor_loss": -27.602181610107422, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.663174152374268, "step": 13000}
{"episode_reward": 188.216037969849, "episode": 14.0, "batch_reward": 0.14552255392819644, "critic_loss": 0.18778022381663323, "actor_loss": -28.013819187164305, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.530822038650513, "step": 14000}
{"episode_reward": 265.8254894112712, "episode": 15.0, "batch_reward": 0.14935083726793527, "critic_loss": 0.1989592368081212, "actor_loss": -26.99346538925171, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.498737812042236, "step": 15000}
{"episode_reward": 60.74175109411678, "episode": 16.0, "batch_reward": 0.1517311554476619, "critic_loss": 0.17872789107263087, "actor_loss": -26.734330097198487, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.472643852233887, "step": 16000}
{"episode_reward": 371.76824034561116, "episode": 17.0, "batch_reward": 0.16482866960018874, "critic_loss": 0.17267859414219855, "actor_loss": -27.886935707092285, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.514710426330566, "step": 17000}
{"episode_reward": 376.11754726555455, "episode": 18.0, "batch_reward": 0.17533327186107636, "critic_loss": 0.17101907536387442, "actor_loss": -28.15641064071655, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.709266424179077, "step": 18000}
{"episode_reward": 212.4358665035265, "episode": 19.0, "batch_reward": 0.17632267153263093, "critic_loss": 0.18694752691686153, "actor_loss": -27.33847162055969, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.33336615562439, "step": 19000}
{"episode_reward": 191.88916208337014, "episode": 20.0, "batch_reward": 0.17916682349145413, "critic_loss": 0.18720413306355477, "actor_loss": -27.038609237670897, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.723707675933838, "step": 20000}
{"episode_reward": 405.8978960193102, "episode": 21.0, "batch_reward": 0.1905992034226656, "critic_loss": 0.2019571372270584, "actor_loss": -27.17876756286621, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.19725704193115, "step": 21000}
{"episode_reward": 270.32099795560094, "episode": 22.0, "batch_reward": 0.19471413381397723, "critic_loss": 0.19347551000863314, "actor_loss": -27.65344910812378, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.52136993408203, "step": 22000}
{"episode_reward": 403.3060029685965, "episode": 23.0, "batch_reward": 0.20256734642386437, "critic_loss": 0.18686573612689972, "actor_loss": -28.411051761627196, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.735123872756958, "step": 23000}
{"episode_reward": 215.60760852324648, "episode": 24.0, "batch_reward": 0.204679713845253, "critic_loss": 0.1956975618004799, "actor_loss": -27.80651491546631, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.69583797454834, "step": 24000}
{"episode_reward": 380.5002162828181, "episode": 25.0, "batch_reward": 0.21219863049685955, "critic_loss": 0.2251779144182801, "actor_loss": -28.678536613464356, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.596839427947998, "step": 25000}
{"episode_reward": 383.45135463421514, "episode": 26.0, "batch_reward": 0.21725071340799332, "critic_loss": 0.21483849626779555, "actor_loss": -28.9913247795105, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.51893186569214, "step": 26000}
{"episode_reward": 406.72978894670683, "episode": 27.0, "batch_reward": 0.22586155459284782, "critic_loss": 0.22236393799632787, "actor_loss": -29.43904525375366, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.633883714675903, "step": 27000}
{"episode_reward": 443.1987845169297, "episode": 28.0, "batch_reward": 0.23239083904027938, "critic_loss": 0.20746397431194782, "actor_loss": -29.584338500976564, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.99449610710144, "step": 28000}
{"episode_reward": 228.19495838564603, "episode": 29.0, "batch_reward": 0.2350329363644123, "critic_loss": 0.19970438704639673, "actor_loss": -28.620940494537354, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.7159743309021, "step": 29000}
{"episode_reward": 467.82805590706994, "episode": 30.0, "batch_reward": 0.241415077611804, "critic_loss": 0.20448297280818223, "actor_loss": -29.35683324432373, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.087303400039673, "step": 30000}
{"episode_reward": 353.0785361635786, "episode": 31.0, "batch_reward": 0.24588651804625988, "critic_loss": 0.2018030016645789, "actor_loss": -29.061428134918213, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 34.94336748123169, "step": 31000}
{"episode_reward": 439.7599627719701, "episode": 32.0, "batch_reward": 0.25014953699707987, "critic_loss": 0.2006536094248295, "actor_loss": -29.279969329833985, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.315404891967773, "step": 32000}
{"episode_reward": 218.3346096253622, "episode": 33.0, "batch_reward": 0.25145316711068155, "critic_loss": 0.2094722307920456, "actor_loss": -28.913397720336913, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.59260392189026, "step": 33000}
{"episode_reward": 458.6646444763344, "episode": 34.0, "batch_reward": 0.25770306228101253, "critic_loss": 0.20342137515544892, "actor_loss": -30.30556280899048, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.7125027179718, "step": 34000}
{"episode_reward": 468.1353795529337, "episode": 35.0, "batch_reward": 0.26349809500575067, "critic_loss": 0.19258264842629433, "actor_loss": -29.635710266113282, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.066294193267822, "step": 35000}
{"episode_reward": 337.6560474327011, "episode": 36.0, "batch_reward": 0.2648498920053244, "critic_loss": 0.19407643633335828, "actor_loss": -30.35059508895874, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.147186994552612, "step": 36000}
{"episode_reward": 438.30909950347404, "episode": 37.0, "batch_reward": 0.26827359192073347, "critic_loss": 0.18010491071641446, "actor_loss": -30.130904926300047, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.982110500335693, "step": 37000}
{"episode_reward": 496.64196601122705, "episode": 38.0, "batch_reward": 0.2760102831423283, "critic_loss": 0.17333020878583194, "actor_loss": -30.141464824676515, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.75757670402527, "step": 38000}
{"episode_reward": 452.23700468899193, "episode": 39.0, "batch_reward": 0.2804703215956688, "critic_loss": 0.18638939570635557, "actor_loss": -30.287393112182617, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.80622172355652, "step": 39000}
{"episode_reward": 473.89044651643286, "episode": 40.0, "batch_reward": 0.2862092350572348, "critic_loss": 0.20016335014253855, "actor_loss": -30.549171504974364, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.053709983825684, "step": 40000}
{"episode_reward": 491.6707302113495, "episode": 41.0, "batch_reward": 0.2914033100306988, "critic_loss": 0.2547737629115582, "actor_loss": -31.21669962692261, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.36793875694275, "step": 41000}
{"episode_reward": 494.10171833158523, "episode": 42.0, "batch_reward": 0.2968643066883087, "critic_loss": 0.3688096482902765, "actor_loss": -32.66820052337646, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.747840881347656, "step": 42000}
{"episode_reward": 531.5308334408976, "episode": 43.0, "batch_reward": 0.3012773018330336, "critic_loss": 0.4540760912448168, "actor_loss": -33.81822762298584, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.179616451263428, "step": 43000}
{"episode_reward": 471.0561418098877, "episode": 44.0, "batch_reward": 0.30529232093691827, "critic_loss": 0.5630391197949648, "actor_loss": -34.87837142944336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.6833176612854, "step": 44000}
{"episode_reward": 483.6602963849588, "episode": 45.0, "batch_reward": 0.3095308585464954, "critic_loss": 0.6911545355170965, "actor_loss": -35.50594051361084, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.105560779571533, "step": 45000}
{"episode_reward": 510.4407015934551, "episode": 46.0, "batch_reward": 0.3134050931036472, "critic_loss": 0.8669086262136698, "actor_loss": -36.9052480545044, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.023305416107178, "step": 46000}
{"episode_reward": 509.0137502439986, "episode": 47.0, "batch_reward": 0.31808203756809234, "critic_loss": 1.243344431579113, "actor_loss": -37.743845001220706, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.818084955215454, "step": 47000}
{"episode_reward": 354.5681962511803, "episode": 48.0, "batch_reward": 0.31389212054014204, "critic_loss": 2.5733080392479897, "actor_loss": -39.381046028137206, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.61490511894226, "step": 48000}
{"episode_reward": 42.29479702925905, "episode": 49.0, "batch_reward": 0.30913995122909543, "critic_loss": 6.683271892547608, "actor_loss": -42.37064013671875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.161104202270508, "step": 49000}
{"episode_reward": 12.162309208888006, "episode": 50.0, "batch_reward": 0.3008740372359753, "critic_loss": 9.41188571214676, "actor_loss": -50.009340774536135, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.020591259002686, "step": 50000}
{"episode_reward": 19.196922059776558, "episode": 51.0, "batch_reward": 0.2971603636443615, "critic_loss": 8.195016575336457, "actor_loss": -62.82338020324707, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.15949082374573, "step": 51000}
{"episode_reward": 10.277049938486416, "episode": 52.0, "batch_reward": 0.2910368245244026, "critic_loss": 6.950305357933044, "actor_loss": -74.4047469406128, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.884384393692017, "step": 52000}
{"episode_reward": 13.073577649193114, "episode": 53.0, "batch_reward": 0.28570822279155256, "critic_loss": 5.424375339508057, "actor_loss": -80.50033799743652, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.992090463638306, "step": 53000}
{"episode_reward": 9.256662170522418, "episode": 54.0, "batch_reward": 0.28053726686537267, "critic_loss": 3.384483932375908, "actor_loss": -81.85050296783447, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.78158187866211, "step": 54000}
{"episode_reward": 11.877797913777192, "episode": 55.0, "batch_reward": 0.27532122561335565, "critic_loss": 2.3064904345273973, "actor_loss": -83.65851596832276, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.17190432548523, "step": 55000}
{"episode_reward": 18.603542041235638, "episode": 56.0, "batch_reward": 0.2707781056314707, "critic_loss": 1.8218595250844956, "actor_loss": -82.16159925842285, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.10599660873413, "step": 56000}
{"episode_reward": 141.2871956501037, "episode": 57.0, "batch_reward": 0.27044716803729535, "critic_loss": 1.7997270796895026, "actor_loss": -79.45691932678223, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.154897689819336, "step": 57000}
{"episode_reward": 121.60287855074024, "episode": 58.0, "batch_reward": 0.26714541263878344, "critic_loss": 1.7339369297027587, "actor_loss": -78.06983199310302, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.905067205429077, "step": 58000}
{"episode_reward": 88.55600198581074, "episode": 59.0, "batch_reward": 0.2652075539380312, "critic_loss": 1.497576460659504, "actor_loss": -75.83298091888427, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.007718563079834, "step": 59000}
{"episode_reward": 91.40246185746065, "episode": 60.0, "batch_reward": 0.26297940766811373, "critic_loss": 1.161185602068901, "actor_loss": -74.46744178771972, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.83175563812256, "step": 60000}
{"episode_reward": 438.3943888705347, "episode": 61.0, "batch_reward": 0.26565343467891217, "critic_loss": 0.9909189048409462, "actor_loss": -72.9743752822876, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.101590633392334, "step": 61000}
{"episode_reward": 390.26768584083135, "episode": 62.0, "batch_reward": 0.2686620577275753, "critic_loss": 0.8480529075860977, "actor_loss": -73.41178963470459, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.05963397026062, "step": 62000}
{"episode_reward": 461.5306459703842, "episode": 63.0, "batch_reward": 0.2709189373999834, "critic_loss": 0.7639594616889953, "actor_loss": -71.08937394714356, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.147072553634644, "step": 63000}
{"episode_reward": 386.9031120565521, "episode": 64.0, "batch_reward": 0.27403804613649846, "critic_loss": 0.6729144214987755, "actor_loss": -70.18881800079346, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.790268182754517, "step": 64000}
{"episode_reward": 515.9307911573256, "episode": 65.0, "batch_reward": 0.27735172310471534, "critic_loss": 0.5587428138554096, "actor_loss": -68.62606262207031, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.21814250946045, "step": 65000}
{"episode_reward": 371.09824667667, "episode": 66.0, "batch_reward": 0.27874634021520617, "critic_loss": 0.513186621248722, "actor_loss": -67.52362508392333, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.804035902023315, "step": 66000}
{"episode_reward": 497.0956586743022, "episode": 67.0, "batch_reward": 0.2821643248349428, "critic_loss": 0.4514134208112955, "actor_loss": -66.65313314056397, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.1019926071167, "step": 67000}
{"episode_reward": 490.40169135364624, "episode": 68.0, "batch_reward": 0.28503305788338185, "critic_loss": 0.46121342544257643, "actor_loss": -65.26718679809571, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.129964351654053, "step": 68000}
{"episode_reward": 527.6284019110961, "episode": 69.0, "batch_reward": 0.28947341720759867, "critic_loss": 0.43754695013165473, "actor_loss": -64.68221367645263, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.018625497817993, "step": 69000}
{"episode_reward": 526.8808666388068, "episode": 70.0, "batch_reward": 0.292193235591054, "critic_loss": 0.42184699030220507, "actor_loss": -64.08212455749512, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.187824487686157, "step": 70000}
{"episode_reward": 525.8144445875328, "episode": 71.0, "batch_reward": 0.2959254969060421, "critic_loss": 0.3847746054530144, "actor_loss": -63.4309375, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.26981806755066, "step": 71000}
{"episode_reward": 526.5195270771341, "episode": 72.0, "batch_reward": 0.2964157848805189, "critic_loss": 0.37507800506055355, "actor_loss": -62.421227935791016, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.17151975631714, "step": 72000}
{"episode_reward": 107.14310279587595, "episode": 73.0, "batch_reward": 0.29687976087629797, "critic_loss": 0.352978095471859, "actor_loss": -60.79566877746582, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.79974341392517, "step": 73000}
{"episode_reward": 559.9010303052268, "episode": 74.0, "batch_reward": 0.2976266958415508, "critic_loss": 0.32233980102837084, "actor_loss": -60.39753189086914, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.005759954452515, "step": 74000}
{"episode_reward": 12.820396613671203, "episode": 75.0, "batch_reward": 0.29259812852740286, "critic_loss": 0.2961981361210346, "actor_loss": -58.77552136230469, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.928142547607422, "step": 75000}
{"episode_reward": 9.220129653916898, "episode": 76.0, "batch_reward": 0.29287216648459435, "critic_loss": 0.2646968266218901, "actor_loss": -57.958837135314944, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.035500288009644, "step": 76000}
{"episode_reward": 562.1948564524287, "episode": 77.0, "batch_reward": 0.296711472555995, "critic_loss": 0.23112695090472699, "actor_loss": -56.81624085998535, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.38581109046936, "step": 77000}
{"episode_reward": 545.67622916582, "episode": 78.0, "batch_reward": 0.29917484885454176, "critic_loss": 0.22051023001223802, "actor_loss": -56.319028221130374, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.964811086654663, "step": 78000}
{"episode_reward": 547.7621032381566, "episode": 79.0, "batch_reward": 0.3032706292271614, "critic_loss": 0.22011304030567408, "actor_loss": -54.70397177886963, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.869022130966187, "step": 79000}
{"episode_reward": 508.26831901513003, "episode": 80.0, "batch_reward": 0.30531018640100954, "critic_loss": 0.2077220993861556, "actor_loss": -54.39929288482666, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.933521270751953, "step": 80000}
{"episode_reward": 561.9450837537298, "episode": 81.0, "batch_reward": 0.3090425900220871, "critic_loss": 0.20416870360821485, "actor_loss": -53.76640779876709, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.103832483291626, "step": 81000}
{"episode_reward": 565.3804821614737, "episode": 82.0, "batch_reward": 0.3115447673797607, "critic_loss": 0.19865369211882353, "actor_loss": -53.71297814178467, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.089996576309204, "step": 82000}
{"episode_reward": 469.1568880055688, "episode": 83.0, "batch_reward": 0.3129689213037491, "critic_loss": 0.18500979723781347, "actor_loss": -52.60984118652344, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.543571710586548, "step": 83000}
{"episode_reward": 516.9372810428272, "episode": 84.0, "batch_reward": 0.31612175005674364, "critic_loss": 0.19046011544018984, "actor_loss": -52.51244162750244, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.265089750289917, "step": 84000}
{"episode_reward": 560.8965037130538, "episode": 85.0, "batch_reward": 0.31694325736165047, "critic_loss": 0.17527951123565436, "actor_loss": -51.556148857116696, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.653207778930664, "step": 85000}
{"episode_reward": 432.7111958093637, "episode": 86.0, "batch_reward": 0.3203776468038559, "critic_loss": 0.17261046823859214, "actor_loss": -51.05366891479492, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.907180309295654, "step": 86000}
{"episode_reward": 558.4623821006594, "episode": 87.0, "batch_reward": 0.322989590972662, "critic_loss": 0.1635101898983121, "actor_loss": -50.51162184143067, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.47372269630432, "step": 87000}
{"episode_reward": 573.9092031912913, "episode": 88.0, "batch_reward": 0.32302958925068376, "critic_loss": 0.16661363527178763, "actor_loss": -49.81183236694336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.03410506248474, "step": 88000}
{"episode_reward": 170.46816073943762, "episode": 89.0, "batch_reward": 0.3236736519038677, "critic_loss": 0.16387802536040544, "actor_loss": -49.31426304626465, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.644524812698364, "step": 89000}
{"episode_reward": 556.8007288990128, "episode": 90.0, "batch_reward": 0.3255443447828293, "critic_loss": 0.17136982116103172, "actor_loss": -48.93480569458008, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.191298723220825, "step": 90000}
{"episode_reward": 563.7333400493702, "episode": 91.0, "batch_reward": 0.3293064882457256, "critic_loss": 0.1899668983966112, "actor_loss": -48.42557514190674, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.28633451461792, "step": 91000}
{"episode_reward": 559.8889038752833, "episode": 92.0, "batch_reward": 0.3322972020208836, "critic_loss": 0.18770364889502525, "actor_loss": -48.16188744354248, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.01549196243286, "step": 92000}
{"episode_reward": 412.2968123682296, "episode": 93.0, "batch_reward": 0.3318809784054756, "critic_loss": 0.21295749301463365, "actor_loss": -47.52252899169922, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.655258417129517, "step": 93000}
{"episode_reward": 329.0005379366656, "episode": 94.0, "batch_reward": 0.3332807006835937, "critic_loss": 0.2061574095785618, "actor_loss": -47.240796806335446, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.934471368789673, "step": 94000}
{"episode_reward": 555.9947894134467, "episode": 95.0, "batch_reward": 0.33461421501636507, "critic_loss": 0.20231082867085934, "actor_loss": -46.91878343963623, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.952179670333862, "step": 95000}
{"episode_reward": 561.6014042815783, "episode": 96.0, "batch_reward": 0.3374580239355564, "critic_loss": 0.2094908280596137, "actor_loss": -46.66946335601806, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.06551456451416, "step": 96000}
{"episode_reward": 566.761195537565, "episode": 97.0, "batch_reward": 0.3384429095387459, "critic_loss": 0.18977817326784133, "actor_loss": -46.32275330352783, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.00763487815857, "step": 97000}
{"episode_reward": 551.3005368055914, "episode": 98.0, "batch_reward": 0.34131366366147997, "critic_loss": 0.18429312627762556, "actor_loss": -46.09060292053223, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.074726819992065, "step": 98000}
{"episode_reward": 546.8528986975159, "episode": 99.0, "batch_reward": 0.3443899243474007, "critic_loss": 0.19273067416250705, "actor_loss": -46.00576471710205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.596338987350464, "step": 99000}
{"episode_reward": 570.7621141182301, "episode": 100.0, "batch_reward": 0.34670285230875014, "critic_loss": 0.19760288763046266, "actor_loss": -45.74545916748047, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.950334787368774, "step": 100000}
{"episode_reward": 544.2718567624206, "episode": 101.0, "batch_reward": 0.34890983131527903, "critic_loss": 0.18940885917842387, "actor_loss": -45.59958113861084, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.48331356048584, "step": 101000}
{"episode_reward": 570.2689823977513, "episode": 102.0, "batch_reward": 0.34955275559425353, "critic_loss": 0.18104044627398252, "actor_loss": -45.45736771392822, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.765092611312866, "step": 102000}
{"episode_reward": 586.721488451852, "episode": 103.0, "batch_reward": 0.3519441269040108, "critic_loss": 0.18019941914826632, "actor_loss": -45.287002410888675, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.68816614151001, "step": 103000}
{"episode_reward": 580.6301310148496, "episode": 104.0, "batch_reward": 0.3547773209512234, "critic_loss": 0.1948861960619688, "actor_loss": -45.162718505859374, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.055388689041138, "step": 104000}
{"episode_reward": 578.8427483603693, "episode": 105.0, "batch_reward": 0.3565631696581841, "critic_loss": 0.178130627065897, "actor_loss": -45.06230181121826, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.652015686035156, "step": 105000}
{"episode_reward": 570.0912037823082, "episode": 106.0, "batch_reward": 0.3587270256280899, "critic_loss": 0.1734768475294113, "actor_loss": -45.04582138061524, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.155994415283203, "step": 106000}
{"episode_reward": 410.349838792726, "episode": 107.0, "batch_reward": 0.3589553101658821, "critic_loss": 0.17772471828013658, "actor_loss": -44.790600730895996, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.34276056289673, "step": 107000}
{"episode_reward": 587.3393648556251, "episode": 108.0, "batch_reward": 0.36160904306173325, "critic_loss": 0.20591603212058543, "actor_loss": -44.78251130676269, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.77639150619507, "step": 108000}
{"episode_reward": 580.3096610758028, "episode": 109.0, "batch_reward": 0.36383593872189524, "critic_loss": 0.18170609916746616, "actor_loss": -44.56128185272217, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.91005778312683, "step": 109000}
{"episode_reward": 598.3651601857414, "episode": 110.0, "batch_reward": 0.3662981414794922, "critic_loss": 0.18762542920559644, "actor_loss": -44.510840156555176, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.992143630981445, "step": 110000}
{"episode_reward": 590.6014099861209, "episode": 111.0, "batch_reward": 0.36680062955617904, "critic_loss": 0.1959585202485323, "actor_loss": -44.54209924316406, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.70177912712097, "step": 111000}
{"episode_reward": 567.6020436968652, "episode": 112.0, "batch_reward": 0.3700439237654209, "critic_loss": 0.19991242200881243, "actor_loss": -44.70505654907227, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.828084468841553, "step": 112000}
{"episode_reward": 582.8715630971233, "episode": 113.0, "batch_reward": 0.3719949640035629, "critic_loss": 0.19381275387853383, "actor_loss": -44.64895245361328, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.002812385559082, "step": 113000}
{"episode_reward": 590.812664390543, "episode": 114.0, "batch_reward": 0.3742876615524292, "critic_loss": 0.19788650514930486, "actor_loss": -44.43434432983398, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.78227972984314, "step": 114000}
{"episode_reward": 571.5792281290852, "episode": 115.0, "batch_reward": 0.37529263842105864, "critic_loss": 0.19047913996875285, "actor_loss": -44.633098655700685, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.798250436782837, "step": 115000}
{"episode_reward": 581.4789263959489, "episode": 116.0, "batch_reward": 0.37748184356093406, "critic_loss": 0.17217710739374162, "actor_loss": -44.67944998168945, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.123385190963745, "step": 116000}
{"episode_reward": 593.1411289271413, "episode": 117.0, "batch_reward": 0.37917984095215795, "critic_loss": 0.18547834993898868, "actor_loss": -44.65495980072021, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.60975217819214, "step": 117000}
{"episode_reward": 295.58049673152914, "episode": 118.0, "batch_reward": 0.37764835119247436, "critic_loss": 0.1918704390078783, "actor_loss": -44.344669136047365, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.979508638381958, "step": 118000}
{"episode_reward": 571.4353063602057, "episode": 119.0, "batch_reward": 0.38082069885730746, "critic_loss": 0.18777305230498315, "actor_loss": -44.5118864440918, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.520278453826904, "step": 119000}
{"episode_reward": 573.2039896321354, "episode": 120.0, "batch_reward": 0.3805200002491474, "critic_loss": 0.18540266478806733, "actor_loss": -44.42683627319336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.836660385131836, "step": 120000}
{"episode_reward": 566.0936393988659, "episode": 121.0, "batch_reward": 0.38263970518112184, "critic_loss": 0.18650127422064544, "actor_loss": -44.534965621948245, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.150365114212036, "step": 121000}
{"episode_reward": 566.7207388099406, "episode": 122.0, "batch_reward": 0.3849108617901802, "critic_loss": 0.2017538569048047, "actor_loss": -44.60604627227783, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.128031253814697, "step": 122000}
{"episode_reward": 569.2266433979001, "episode": 123.0, "batch_reward": 0.38690339878201485, "critic_loss": 0.19099242495000363, "actor_loss": -44.80162465667725, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.6873562335968, "step": 123000}
{"episode_reward": 579.3678176728951, "episode": 124.0, "batch_reward": 0.3869648106098175, "critic_loss": 0.18500523591786622, "actor_loss": -44.68365575408936, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.9630925655365, "step": 124000}
{"episode_reward": 571.1561664336966, "episode": 125.0, "batch_reward": 0.38890787145495415, "critic_loss": 0.19551776003837584, "actor_loss": -44.623642387390134, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.858802556991577, "step": 125000}
{"episode_reward": 591.1050626502541, "episode": 126.0, "batch_reward": 0.3898087419867516, "critic_loss": 0.20399702936410904, "actor_loss": -44.951828483581544, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.936866998672485, "step": 126000}
{"episode_reward": 578.7834366927289, "episode": 127.0, "batch_reward": 0.3920979850590229, "critic_loss": 0.18954234476387502, "actor_loss": -44.893042388916015, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.90233612060547, "step": 127000}
{"episode_reward": 563.432656267202, "episode": 128.0, "batch_reward": 0.3925971402525902, "critic_loss": 0.18911704777926205, "actor_loss": -44.66870919036865, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.641061067581177, "step": 128000}
{"episode_reward": 583.589985627613, "episode": 129.0, "batch_reward": 0.394782394528389, "critic_loss": 0.19803264389932157, "actor_loss": -45.05330641937256, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.235156774520874, "step": 129000}
{"episode_reward": 583.0656330765689, "episode": 130.0, "batch_reward": 0.39683192935585976, "critic_loss": 0.19492720665037633, "actor_loss": -45.25694457244873, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.761523723602295, "step": 130000}
{"episode_reward": 575.7168241713788, "episode": 131.0, "batch_reward": 0.3984448679983616, "critic_loss": 0.19966516087949276, "actor_loss": -45.21597154998779, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.14765286445618, "step": 131000}
{"episode_reward": 595.8665032444139, "episode": 132.0, "batch_reward": 0.4001523589193821, "critic_loss": 0.2031474769115448, "actor_loss": -45.38487162780762, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.980789184570312, "step": 132000}
{"episode_reward": 576.0282529893207, "episode": 133.0, "batch_reward": 0.39918406334519385, "critic_loss": 0.19145084248483182, "actor_loss": -45.4400129699707, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.829242944717407, "step": 133000}
{"episode_reward": 423.5690599849786, "episode": 134.0, "batch_reward": 0.40119746229052544, "critic_loss": 0.19431966648995877, "actor_loss": -45.47799622344971, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.58659839630127, "step": 134000}
{"episode_reward": 569.7291859882857, "episode": 135.0, "batch_reward": 0.40269037717580797, "critic_loss": 0.19008912132680417, "actor_loss": -45.565280967712404, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.793012619018555, "step": 135000}
{"episode_reward": 593.6074456486446, "episode": 136.0, "batch_reward": 0.4037593244314194, "critic_loss": 0.22361382880806924, "actor_loss": -45.44178505706787, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.495370388031006, "step": 136000}
{"episode_reward": 608.587865886492, "episode": 137.0, "batch_reward": 0.4042666536569595, "critic_loss": 0.18756396132707595, "actor_loss": -45.66004237365723, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.78013825416565, "step": 137000}
{"episode_reward": 570.8751485969668, "episode": 138.0, "batch_reward": 0.40609506583213806, "critic_loss": 0.18815038307756185, "actor_loss": -46.07252853393555, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.89734721183777, "step": 138000}
{"episode_reward": 560.1332095136388, "episode": 139.0, "batch_reward": 0.4071413771808147, "critic_loss": 0.18539222408086062, "actor_loss": -45.96179721069336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.348557472229004, "step": 139000}
{"episode_reward": 569.7426280754039, "episode": 140.0, "batch_reward": 0.4085734566450119, "critic_loss": 0.19908549044281243, "actor_loss": -46.049037200927735, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.019357681274414, "step": 140000}
{"episode_reward": 582.1082410857382, "episode": 141.0, "batch_reward": 0.40885615968704225, "critic_loss": 0.18970274939388038, "actor_loss": -45.978960098266604, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 35.088987827301025, "step": 141000}
{"episode_reward": 599.2648309394006, "episode": 142.0, "batch_reward": 0.4107307650446892, "critic_loss": 0.19287151060253382, "actor_loss": -45.88104177856445, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.948134183883667, "step": 142000}
{"episode_reward": 605.4674937300683, "episode": 143.0, "batch_reward": 0.4123269872069359, "critic_loss": 0.1845325028821826, "actor_loss": -45.87500028991699, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.295695781707764, "step": 143000}
{"episode_reward": 593.8889088354539, "episode": 144.0, "batch_reward": 0.41449069991707804, "critic_loss": 0.19268321186304094, "actor_loss": -46.183632972717284, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.126002073287964, "step": 144000}
{"episode_reward": 563.8190916526045, "episode": 145.0, "batch_reward": 0.41482485955953596, "critic_loss": 0.18575348372012376, "actor_loss": -46.06466630554199, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.336947202682495, "step": 145000}
{"episode_reward": 598.0681168798695, "episode": 146.0, "batch_reward": 0.41474563163518907, "critic_loss": 0.17557500799000264, "actor_loss": -46.0979624786377, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.414459466934204, "step": 146000}
{"episode_reward": 563.2446420050095, "episode": 147.0, "batch_reward": 0.41610650941729543, "critic_loss": 0.17088360888510942, "actor_loss": -46.0843358001709, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.127570629119873, "step": 147000}
{"episode_reward": 576.5668712812569, "episode": 148.0, "batch_reward": 0.4178801301419735, "critic_loss": 0.17308184837177396, "actor_loss": -46.24656997680664, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.1450035572052, "step": 148000}
{"episode_reward": 573.5140882795193, "episode": 149.0, "batch_reward": 0.4197857291698456, "critic_loss": 0.16552885355055333, "actor_loss": -46.2980163192749, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.20042657852173, "step": 149000}
{"episode_reward": 582.2091511055279, "episode": 150.0, "batch_reward": 0.42091343757510186, "critic_loss": 0.1686978739351034, "actor_loss": -46.589290145874024, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
