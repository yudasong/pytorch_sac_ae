{"episode_reward": 0.0, "episode": 1.0, "duration": 17.489940643310547, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.5113584995269775, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.21874170922048491, "critic_loss": 0.1867078336222186, "actor_loss": -44.25041236740057, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 62.810810804367065, "step": 3000}
{"episode_reward": 73.10337024904042, "episode": 4.0, "batch_reward": 0.17711051604896783, "critic_loss": 0.1683748000487685, "actor_loss": -38.78070627593994, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.924953937530518, "step": 4000}
{"episode_reward": 118.30476191746874, "episode": 5.0, "batch_reward": 0.16010222638398408, "critic_loss": 0.1957177174538374, "actor_loss": -34.22270571899414, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.603490352630615, "step": 5000}
{"episode_reward": 130.42708990239345, "episode": 6.0, "batch_reward": 0.14754940573126077, "critic_loss": 0.18743380223214626, "actor_loss": -31.54750008010864, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.85999321937561, "step": 6000}
{"episode_reward": 40.34903737645493, "episode": 7.0, "batch_reward": 0.13780593250691892, "critic_loss": 0.20458115282654762, "actor_loss": -29.366972976684572, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.522602081298828, "step": 7000}
{"episode_reward": 102.45429627885105, "episode": 8.0, "batch_reward": 0.14320758525282146, "critic_loss": 0.19168366312980653, "actor_loss": -28.817273052215576, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.8886821269989, "step": 8000}
{"episode_reward": 298.2146555361674, "episode": 9.0, "batch_reward": 0.15092654979974032, "critic_loss": 0.22341142605990172, "actor_loss": -29.316035942077637, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.179526567459106, "step": 9000}
{"episode_reward": 78.7995089700378, "episode": 10.0, "batch_reward": 0.15749824648350477, "critic_loss": 0.2397640559822321, "actor_loss": -29.468103218078614, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.78112006187439, "step": 10000}
{"episode_reward": 412.736580075434, "episode": 11.0, "batch_reward": 0.18142112264037133, "critic_loss": 0.25155660420656206, "actor_loss": -31.40133473587036, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.206790924072266, "step": 11000}
{"episode_reward": 390.8754277494845, "episode": 12.0, "batch_reward": 0.19906450834870337, "critic_loss": 0.2787130805850029, "actor_loss": -32.45566759872437, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.267496585845947, "step": 12000}
{"episode_reward": 388.05325909264485, "episode": 13.0, "batch_reward": 0.21546368123590945, "critic_loss": 0.320689847484231, "actor_loss": -33.526597717285156, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.022328853607178, "step": 13000}
{"episode_reward": 421.71197025848477, "episode": 14.0, "batch_reward": 0.2224556512236595, "critic_loss": 0.32063218514621256, "actor_loss": -33.492582069396974, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91462802886963, "step": 14000}
{"episode_reward": 105.69459290054937, "episode": 15.0, "batch_reward": 0.22306413498520852, "critic_loss": 0.30296814543008804, "actor_loss": -33.550885704040525, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.24067234992981, "step": 15000}
{"episode_reward": 443.2234619979613, "episode": 16.0, "batch_reward": 0.23804046900570391, "critic_loss": 0.3051681140512228, "actor_loss": -34.61458639526367, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.330021142959595, "step": 16000}
{"episode_reward": 462.8789086755265, "episode": 17.0, "batch_reward": 0.24926177294552326, "critic_loss": 0.3283997575044632, "actor_loss": -35.082518474578855, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.386937618255615, "step": 17000}
{"episode_reward": 309.59838335170775, "episode": 18.0, "batch_reward": 0.2535874702781439, "critic_loss": 0.31310458460450175, "actor_loss": -35.1087781829834, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.931326866149902, "step": 18000}
{"episode_reward": 339.69440600722345, "episode": 19.0, "batch_reward": 0.2588807139247656, "critic_loss": 0.33118243837356565, "actor_loss": -35.48285554504395, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.719523668289185, "step": 19000}
{"episode_reward": 436.384623104876, "episode": 20.0, "batch_reward": 0.2600361715257168, "critic_loss": 0.363708328589797, "actor_loss": -35.627250267028806, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.982835054397583, "step": 20000}
{"episode_reward": 82.6891884416502, "episode": 21.0, "batch_reward": 0.2568894082605839, "critic_loss": 0.3876941015869379, "actor_loss": -35.43603688430786, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.8049693107605, "step": 21000}
{"episode_reward": 270.00874551541773, "episode": 22.0, "batch_reward": 0.2581120455265045, "critic_loss": 0.3976865909397602, "actor_loss": -35.22053889465332, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.27115821838379, "step": 22000}
{"episode_reward": 280.20104366643216, "episode": 23.0, "batch_reward": 0.2615400075316429, "critic_loss": 0.3550592229217291, "actor_loss": -35.28843447113037, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.20090103149414, "step": 23000}
{"episode_reward": 375.0582032644041, "episode": 24.0, "batch_reward": 0.2651710015982389, "critic_loss": 0.3437668863385916, "actor_loss": -35.76876945495606, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.897499322891235, "step": 24000}
{"episode_reward": 472.06944746106313, "episode": 25.0, "batch_reward": 0.2727544887363911, "critic_loss": 0.3190150318294764, "actor_loss": -35.945906280517576, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.074360609054565, "step": 25000}
{"episode_reward": 479.8294351045989, "episode": 26.0, "batch_reward": 0.2813852832019329, "critic_loss": 0.2861727895587683, "actor_loss": -36.36812607192993, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.46916627883911, "step": 26000}
{"episode_reward": 499.98914433339775, "episode": 27.0, "batch_reward": 0.29158266505599023, "critic_loss": 0.28338978372514245, "actor_loss": -36.789380973815916, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93008303642273, "step": 27000}
{"episode_reward": 484.37574985139685, "episode": 28.0, "batch_reward": 0.29703815892338753, "critic_loss": 0.29908371974527836, "actor_loss": -36.90453014755249, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.334824085235596, "step": 28000}
{"episode_reward": 258.9773549389238, "episode": 29.0, "batch_reward": 0.29516824811697007, "critic_loss": 0.2732999701201916, "actor_loss": -37.02302535247803, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.243929862976074, "step": 29000}
{"episode_reward": 440.9437272747138, "episode": 30.0, "batch_reward": 0.3020154348313808, "critic_loss": 0.2803723621368408, "actor_loss": -37.258829578399656, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.22585654258728, "step": 30000}
{"episode_reward": 498.1991127324761, "episode": 31.0, "batch_reward": 0.307120871424675, "critic_loss": 0.27483829979598523, "actor_loss": -37.571024364471434, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.2107367515564, "step": 31000}
{"episode_reward": 470.51167699868694, "episode": 32.0, "batch_reward": 0.31213618099689483, "critic_loss": 0.30060070149600504, "actor_loss": -37.89794790267944, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.241161108016968, "step": 32000}
{"episode_reward": 429.6270953801064, "episode": 33.0, "batch_reward": 0.31631657433509824, "critic_loss": 0.3158857267349958, "actor_loss": -38.06503930282593, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.973005771636963, "step": 33000}
{"episode_reward": 475.69426482745075, "episode": 34.0, "batch_reward": 0.32186169642210005, "critic_loss": 0.29822772786021234, "actor_loss": -38.00781383895874, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.29240083694458, "step": 34000}
{"episode_reward": 493.4655205902593, "episode": 35.0, "batch_reward": 0.32647485077381133, "critic_loss": 0.31508485521376134, "actor_loss": -39.00040871429444, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.213093519210815, "step": 35000}
{"episode_reward": 486.02162327004106, "episode": 36.0, "batch_reward": 0.32881759575009345, "critic_loss": 0.306384257376194, "actor_loss": -38.929694358825685, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.13148260116577, "step": 36000}
{"episode_reward": 417.5564262167845, "episode": 37.0, "batch_reward": 0.33246243247389795, "critic_loss": 0.32872974084317685, "actor_loss": -39.123856101989745, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91868829727173, "step": 37000}
{"episode_reward": 500.79032184561163, "episode": 38.0, "batch_reward": 0.3375968436896801, "critic_loss": 0.3636324597001076, "actor_loss": -39.89844635772705, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.431567907333374, "step": 38000}
{"episode_reward": 453.8046088927329, "episode": 39.0, "batch_reward": 0.339299466252327, "critic_loss": 0.3607967069000006, "actor_loss": -40.53365667724609, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.64638924598694, "step": 39000}
{"episode_reward": 476.77088596488295, "episode": 40.0, "batch_reward": 0.34379901638627053, "critic_loss": 0.3368199599832296, "actor_loss": -40.896784172058105, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.87797784805298, "step": 40000}
{"episode_reward": 457.83839269771977, "episode": 41.0, "batch_reward": 0.34670125102996824, "critic_loss": 0.3620965038239956, "actor_loss": -41.123219680786136, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.93940305709839, "step": 41000}
{"episode_reward": 417.1494884561037, "episode": 42.0, "batch_reward": 0.34593000146746633, "critic_loss": 0.4409690444767475, "actor_loss": -40.944810943603514, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.24120807647705, "step": 42000}
{"episode_reward": 168.2029266910834, "episode": 43.0, "batch_reward": 0.34385871601104734, "critic_loss": 0.41201314197480676, "actor_loss": -40.96841000366211, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.919222116470337, "step": 43000}
{"episode_reward": 435.37323910409293, "episode": 44.0, "batch_reward": 0.3458006291091442, "critic_loss": 0.40426235522329806, "actor_loss": -41.05818583679199, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.250932455062866, "step": 44000}
{"episode_reward": 470.919213247469, "episode": 45.0, "batch_reward": 0.348236075848341, "critic_loss": 0.38269500932097433, "actor_loss": -41.571254722595214, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.090001344680786, "step": 45000}
{"episode_reward": 456.6926383611394, "episode": 46.0, "batch_reward": 0.35125385037064555, "critic_loss": 0.3869422336667776, "actor_loss": -41.83825066375732, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.90392017364502, "step": 46000}
{"episode_reward": 488.1685834585874, "episode": 47.0, "batch_reward": 0.3547729827165604, "critic_loss": 0.3765034563392401, "actor_loss": -41.83071460723877, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.44299817085266, "step": 47000}
{"episode_reward": 430.29979663881784, "episode": 48.0, "batch_reward": 0.35640921333432196, "critic_loss": 0.3738038171380758, "actor_loss": -41.7626139755249, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.291303157806396, "step": 48000}
{"episode_reward": 504.2896248065099, "episode": 49.0, "batch_reward": 0.3590011211335659, "critic_loss": 0.372580831900239, "actor_loss": -42.075984069824216, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.17802405357361, "step": 49000}
{"episode_reward": 483.9415822612236, "episode": 50.0, "batch_reward": 0.36139411908388136, "critic_loss": 0.4002507144212723, "actor_loss": -42.428909439086915, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.93990921974182, "step": 50000}
{"episode_reward": 488.8999470447114, "episode": 51.0, "batch_reward": 0.3649901629984379, "critic_loss": 0.380995499804616, "actor_loss": -42.271597160339354, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.212562084198, "step": 51000}
{"episode_reward": 463.8818748859986, "episode": 52.0, "batch_reward": 0.3655980268120766, "critic_loss": 0.4005355684459209, "actor_loss": -42.884491050720214, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.951111316680908, "step": 52000}
{"episode_reward": 476.29987973502256, "episode": 53.0, "batch_reward": 0.3680719799101353, "critic_loss": 0.4550709122121334, "actor_loss": -43.0183719329834, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.988545179367065, "step": 53000}
{"episode_reward": 482.3771378192951, "episode": 54.0, "batch_reward": 0.37052276569604875, "critic_loss": 0.5198669606745243, "actor_loss": -43.29091251373291, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.3698308467865, "step": 54000}
{"episode_reward": 474.9152822225386, "episode": 55.0, "batch_reward": 0.37196334436535833, "critic_loss": 0.6994533093571663, "actor_loss": -43.31480630493164, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.000484704971313, "step": 55000}
{"episode_reward": 446.30326584088107, "episode": 56.0, "batch_reward": 0.37334173935651777, "critic_loss": 1.0040244083404541, "actor_loss": -44.088881660461425, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.921383142471313, "step": 56000}
{"episode_reward": 358.1611454551209, "episode": 57.0, "batch_reward": 0.3729877921938896, "critic_loss": 1.5942678898274898, "actor_loss": -44.31196131134033, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.698781490325928, "step": 57000}
{"episode_reward": 288.31881575432357, "episode": 58.0, "batch_reward": 0.3687643350660801, "critic_loss": 2.950518833577633, "actor_loss": -44.57662857055664, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.25079870223999, "step": 58000}
{"episode_reward": 39.74363597461671, "episode": 59.0, "batch_reward": 0.36216399431228635, "critic_loss": 4.042260308384895, "actor_loss": -45.53855480194092, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.927541732788086, "step": 59000}
{"episode_reward": 23.94296234843517, "episode": 60.0, "batch_reward": 0.3571968209147453, "critic_loss": 5.41756873190403, "actor_loss": -46.78674781799317, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.03448748588562, "step": 60000}
{"episode_reward": 27.117581839131677, "episode": 61.0, "batch_reward": 0.3513383071124554, "critic_loss": 7.212007133483887, "actor_loss": -48.54518627166748, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.83662939071655, "step": 61000}
{"episode_reward": 41.96840181283737, "episode": 62.0, "batch_reward": 0.34583334949612615, "critic_loss": 8.709607959985734, "actor_loss": -50.4698125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.905375480651855, "step": 62000}
{"episode_reward": 23.87962897314155, "episode": 63.0, "batch_reward": 0.34050512725114823, "critic_loss": 8.741036681890488, "actor_loss": -52.252528594970705, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.01179552078247, "step": 63000}
{"episode_reward": 18.188935970138786, "episode": 64.0, "batch_reward": 0.3361589665412903, "critic_loss": 9.843443283557892, "actor_loss": -55.587842376708984, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.91618824005127, "step": 64000}
{"episode_reward": 28.182467341781326, "episode": 65.0, "batch_reward": 0.3317892804145813, "critic_loss": 11.878351523399353, "actor_loss": -58.793920532226565, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.245503664016724, "step": 65000}
{"episode_reward": 70.8119547400912, "episode": 66.0, "batch_reward": 0.3282498327195644, "critic_loss": 15.978436003208161, "actor_loss": -63.318504165649415, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.274876356124878, "step": 66000}
{"episode_reward": 52.157331047440316, "episode": 67.0, "batch_reward": 0.3234839245378971, "critic_loss": 19.35311386823654, "actor_loss": -65.89457082366944, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.357036590576172, "step": 67000}
{"episode_reward": 54.47671083833982, "episode": 68.0, "batch_reward": 0.31946237456798554, "critic_loss": 17.288865170001984, "actor_loss": -73.12848200988769, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.09559154510498, "step": 68000}
{"episode_reward": 177.29866997789168, "episode": 69.0, "batch_reward": 0.3184754555523396, "critic_loss": 15.64046107006073, "actor_loss": -73.04028155517578, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.944857597351074, "step": 69000}
{"episode_reward": 249.34051863381242, "episode": 70.0, "batch_reward": 0.3174864395558834, "critic_loss": 12.182914601325988, "actor_loss": -73.64201318359375, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.51831316947937, "step": 70000}
{"episode_reward": 268.11631795456685, "episode": 71.0, "batch_reward": 0.3166875491142273, "critic_loss": 9.401291695356369, "actor_loss": -77.26249909210205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.76417422294617, "step": 71000}
{"episode_reward": 104.15747439468612, "episode": 72.0, "batch_reward": 0.31344471004605295, "critic_loss": 7.7525787625312805, "actor_loss": -76.1481416015625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.945496797561646, "step": 72000}
{"episode_reward": 12.413316953616308, "episode": 73.0, "batch_reward": 0.30845061430335047, "critic_loss": 5.62887281537056, "actor_loss": -74.78989781188965, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.708088159561157, "step": 73000}
{"episode_reward": 12.451443919195551, "episode": 74.0, "batch_reward": 0.30484657596051695, "critic_loss": 4.2654097936153414, "actor_loss": -71.69755867004395, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.288772106170654, "step": 74000}
{"episode_reward": 86.67681531517432, "episode": 75.0, "batch_reward": 0.3006196009069681, "critic_loss": 3.5901081055402755, "actor_loss": -71.11434464263915, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.404486417770386, "step": 75000}
{"episode_reward": 59.421612432327436, "episode": 76.0, "batch_reward": 0.29948828428983687, "critic_loss": 3.2970201513767243, "actor_loss": -70.34747175598145, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.043376684188843, "step": 76000}
{"episode_reward": 266.1528594840939, "episode": 77.0, "batch_reward": 0.29902396687865257, "critic_loss": 3.8611935539245605, "actor_loss": -69.52852767181396, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.424289226531982, "step": 77000}
{"episode_reward": 181.1794445879984, "episode": 78.0, "batch_reward": 0.2953521883189678, "critic_loss": 3.9406500172615053, "actor_loss": -66.73584149169922, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.284018516540527, "step": 78000}
{"episode_reward": 153.46144297317096, "episode": 79.0, "batch_reward": 0.297434194535017, "critic_loss": 3.488041572213173, "actor_loss": -68.62634022521972, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.89183211326599, "step": 79000}
{"episode_reward": 447.0544607189227, "episode": 80.0, "batch_reward": 0.2967997409403324, "critic_loss": 3.1517797212600707, "actor_loss": -67.20846181488037, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.985295295715332, "step": 80000}
{"episode_reward": 138.35921465115638, "episode": 81.0, "batch_reward": 0.294975084617734, "critic_loss": 2.995880785703659, "actor_loss": -64.87738005828858, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.184847831726074, "step": 81000}
{"episode_reward": 5.059252784757251, "episode": 82.0, "batch_reward": 0.29006224942207337, "critic_loss": 3.1402634917497636, "actor_loss": -62.00825673675537, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.952304124832153, "step": 82000}
{"episode_reward": 4.523419507085366, "episode": 83.0, "batch_reward": 0.2875998121649027, "critic_loss": 3.108226417303085, "actor_loss": -62.59114604187012, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.377875804901123, "step": 83000}
{"episode_reward": 3.8131684761056657, "episode": 84.0, "batch_reward": 0.28325984148681166, "critic_loss": 2.8891761362552644, "actor_loss": -61.63550828552246, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.67976999282837, "step": 84000}
{"episode_reward": 7.882384812700821, "episode": 85.0, "batch_reward": 0.28054747492074966, "critic_loss": 2.66139507997036, "actor_loss": -60.27239392089844, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.922825813293457, "step": 85000}
{"episode_reward": 25.740938040378904, "episode": 86.0, "batch_reward": 0.2771067023426294, "critic_loss": 2.5311449365615846, "actor_loss": -60.552439498901364, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.214365482330322, "step": 86000}
{"episode_reward": 10.558632205394751, "episode": 87.0, "batch_reward": 0.27443152423202993, "critic_loss": 2.5496781148910523, "actor_loss": -59.69942269134521, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.345622301101685, "step": 87000}
{"episode_reward": 13.588589697054008, "episode": 88.0, "batch_reward": 0.27251390646398066, "critic_loss": 2.6640665056705477, "actor_loss": -60.23932448577881, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.3447322845459, "step": 88000}
{"episode_reward": 7.742134014484395, "episode": 89.0, "batch_reward": 0.26794533610343935, "critic_loss": 2.779351197361946, "actor_loss": -59.051399574279785, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.913907289505005, "step": 89000}
{"episode_reward": 8.856245264966306, "episode": 90.0, "batch_reward": 0.2651851510554552, "critic_loss": 2.6551658560037614, "actor_loss": -57.50968312835693, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.390804529190063, "step": 90000}
{"episode_reward": 7.288771575631041, "episode": 91.0, "batch_reward": 0.26323978389799596, "critic_loss": 2.2012258655428885, "actor_loss": -57.9071171798706, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.784194469451904, "step": 91000}
{"episode_reward": 13.136888611900021, "episode": 92.0, "batch_reward": 0.26118158268928526, "critic_loss": 2.03670384812355, "actor_loss": -57.46749166870117, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.51951241493225, "step": 92000}
{"episode_reward": 10.609729139332293, "episode": 93.0, "batch_reward": 0.25670894603431227, "critic_loss": 1.8228514714837074, "actor_loss": -57.02998813629151, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.36025333404541, "step": 93000}
{"episode_reward": 14.038600164636124, "episode": 94.0, "batch_reward": 0.2550761992186308, "critic_loss": 1.6647752512097358, "actor_loss": -56.88829741668701, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.471123456954956, "step": 94000}
{"episode_reward": 13.444575085236746, "episode": 95.0, "batch_reward": 0.2519403857588768, "critic_loss": 1.6011432503461838, "actor_loss": -54.62532220458984, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91677165031433, "step": 95000}
{"episode_reward": 9.604371099430898, "episode": 96.0, "batch_reward": 0.24989447425305844, "critic_loss": 1.4660499104857445, "actor_loss": -54.6567461013794, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.19356107711792, "step": 96000}
{"episode_reward": 10.097407511276916, "episode": 97.0, "batch_reward": 0.2482744062691927, "critic_loss": 1.2757548298239707, "actor_loss": -53.74151411437988, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.828470945358276, "step": 97000}
{"episode_reward": 10.431396826819316, "episode": 98.0, "batch_reward": 0.24459479868412018, "critic_loss": 1.0922628398537635, "actor_loss": -53.16482884216309, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.90720772743225, "step": 98000}
{"episode_reward": 21.866666873175333, "episode": 99.0, "batch_reward": 0.2418436224013567, "critic_loss": 0.9189171086251736, "actor_loss": -52.43875708770752, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.608396530151367, "step": 99000}
{"episode_reward": 17.803869185023608, "episode": 100.0, "batch_reward": 0.24057261882722378, "critic_loss": 0.7847098388969899, "actor_loss": -52.12435261535644, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.263511180877686, "step": 100000}
{"episode_reward": 28.424861953284303, "episode": 101.0, "batch_reward": 0.23920860590040685, "critic_loss": 0.7011156026124954, "actor_loss": -50.54840061187744, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.61237692832947, "step": 101000}
{"episode_reward": 18.147023738830082, "episode": 102.0, "batch_reward": 0.23881705071032047, "critic_loss": 0.6045674069523811, "actor_loss": -50.01973132324219, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.753491401672363, "step": 102000}
{"episode_reward": 450.1973833670778, "episode": 103.0, "batch_reward": 0.2399993789792061, "critic_loss": 0.5551514075100422, "actor_loss": -49.42144381713867, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.068735599517822, "step": 103000}
{"episode_reward": 305.3155437542555, "episode": 104.0, "batch_reward": 0.24043363671004772, "critic_loss": 0.5191142916381359, "actor_loss": -48.55883879852295, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.896060705184937, "step": 104000}
{"episode_reward": 406.4887458558982, "episode": 105.0, "batch_reward": 0.2424102861136198, "critic_loss": 0.48365062722563745, "actor_loss": -47.72269081115723, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.896013021469116, "step": 105000}
{"episode_reward": 315.4099972079186, "episode": 106.0, "batch_reward": 0.243389158770442, "critic_loss": 0.4416789305061102, "actor_loss": -47.3203219833374, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.313075304031372, "step": 106000}
{"episode_reward": 485.0395732541254, "episode": 107.0, "batch_reward": 0.24496675880253316, "critic_loss": 0.4087292921096087, "actor_loss": -46.323334686279296, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.74663209915161, "step": 107000}
{"episode_reward": 517.8784838679491, "episode": 108.0, "batch_reward": 0.2471135641783476, "critic_loss": 0.40805202032625676, "actor_loss": -45.685982688903806, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.90091562271118, "step": 108000}
{"episode_reward": 389.86248091329304, "episode": 109.0, "batch_reward": 0.24858867126703263, "critic_loss": 0.38593376706540583, "actor_loss": -44.98093057250976, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.271541357040405, "step": 109000}
{"episode_reward": 482.72641426932177, "episode": 110.0, "batch_reward": 0.2505468565672636, "critic_loss": 0.3945323426872492, "actor_loss": -44.20885417938232, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.21639084815979, "step": 110000}
{"episode_reward": 213.88138654153846, "episode": 111.0, "batch_reward": 0.2505328288376331, "critic_loss": 0.39276872207224367, "actor_loss": -43.66398857116699, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.47912883758545, "step": 111000}
{"episode_reward": 486.7946587234449, "episode": 112.0, "batch_reward": 0.25315853449702264, "critic_loss": 0.37428925313055517, "actor_loss": -43.37919017791748, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.015647888183594, "step": 112000}
{"episode_reward": 504.98359063922413, "episode": 113.0, "batch_reward": 0.2564302564412355, "critic_loss": 0.38840648382902143, "actor_loss": -43.16702820587158, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.59679365158081, "step": 113000}
{"episode_reward": 501.1689026571937, "episode": 114.0, "batch_reward": 0.25908390471339227, "critic_loss": 0.3597208600342274, "actor_loss": -42.49571199035645, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.943502187728882, "step": 114000}
{"episode_reward": 464.190110292656, "episode": 115.0, "batch_reward": 0.2592920324504375, "critic_loss": 0.35751905147731305, "actor_loss": -42.191757926940916, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.232280492782593, "step": 115000}
{"episode_reward": 492.67877370875334, "episode": 116.0, "batch_reward": 0.26127608202397823, "critic_loss": 0.3802541344165802, "actor_loss": -41.79264730072021, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.375550985336304, "step": 116000}
{"episode_reward": 472.88315711159385, "episode": 117.0, "batch_reward": 0.2624948836863041, "critic_loss": 0.3835826862603426, "actor_loss": -41.440302215576175, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.541396856307983, "step": 117000}
{"episode_reward": 468.0359636073081, "episode": 118.0, "batch_reward": 0.26516807813942433, "critic_loss": 0.3825022038221359, "actor_loss": -41.440577812194825, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.94582486152649, "step": 118000}
{"episode_reward": 481.04688734712806, "episode": 119.0, "batch_reward": 0.26655365838110445, "critic_loss": 0.36056750966608525, "actor_loss": -41.24651261138916, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.885550022125244, "step": 119000}
{"episode_reward": 516.5939253824621, "episode": 120.0, "batch_reward": 0.2687857428193092, "critic_loss": 0.3697340950965881, "actor_loss": -40.91841367340088, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.27580165863037, "step": 120000}
{"episode_reward": 484.0811119884194, "episode": 121.0, "batch_reward": 0.27063465139269827, "critic_loss": 0.35641017691791055, "actor_loss": -40.867857872009274, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.76820349693298, "step": 121000}
{"episode_reward": 456.1867821158216, "episode": 122.0, "batch_reward": 0.271959091797471, "critic_loss": 0.36565736778080465, "actor_loss": -40.71706674194336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.178050994873047, "step": 122000}
{"episode_reward": 474.99068265035885, "episode": 123.0, "batch_reward": 0.27405510894954205, "critic_loss": 0.3553868285417557, "actor_loss": -40.45963527679444, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.89269518852234, "step": 123000}
{"episode_reward": 473.1922467913372, "episode": 124.0, "batch_reward": 0.27472128708660604, "critic_loss": 0.3465168846696615, "actor_loss": -40.44905446624756, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.944807052612305, "step": 124000}
{"episode_reward": 459.3922886524993, "episode": 125.0, "batch_reward": 0.2772726154178381, "critic_loss": 0.3520307778865099, "actor_loss": -40.29813321685791, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.696302890777588, "step": 125000}
{"episode_reward": 492.3831498523559, "episode": 126.0, "batch_reward": 0.27904658365249635, "critic_loss": 0.3490000982880592, "actor_loss": -40.42448277282715, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.002925872802734, "step": 126000}
{"episode_reward": 475.74261743409755, "episode": 127.0, "batch_reward": 0.2805127557218075, "critic_loss": 0.35714930357038976, "actor_loss": -40.23603182983398, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.939542055130005, "step": 127000}
{"episode_reward": 498.48653527390024, "episode": 128.0, "batch_reward": 0.2814348576515913, "critic_loss": 0.3382796094343066, "actor_loss": -40.09048117828369, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.226982593536377, "step": 128000}
{"episode_reward": 506.3425018422738, "episode": 129.0, "batch_reward": 0.2830715133547783, "critic_loss": 0.34765845200419426, "actor_loss": -40.06250807952881, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.33768391609192, "step": 129000}
{"episode_reward": 470.4575837716213, "episode": 130.0, "batch_reward": 0.28615946738421916, "critic_loss": 0.339739173963666, "actor_loss": -39.96752889251709, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.613166332244873, "step": 130000}
{"episode_reward": 485.33608442886555, "episode": 131.0, "batch_reward": 0.2868551718890667, "critic_loss": 0.3458557612746954, "actor_loss": -39.747489280700684, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.74920988082886, "step": 131000}
{"episode_reward": 486.5962042079878, "episode": 132.0, "batch_reward": 0.2876478611528873, "critic_loss": 0.333597936168313, "actor_loss": -39.594605506896976, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.16160774230957, "step": 132000}
{"episode_reward": 504.3478408594353, "episode": 133.0, "batch_reward": 0.2911787977218628, "critic_loss": 0.3381084512472153, "actor_loss": -39.84968295288086, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.025612115859985, "step": 133000}
{"episode_reward": 481.6868163589271, "episode": 134.0, "batch_reward": 0.2912619298994541, "critic_loss": 0.3424522906541824, "actor_loss": -39.816115589141845, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.584996223449707, "step": 134000}
{"episode_reward": 471.0615086403433, "episode": 135.0, "batch_reward": 0.29208066160976887, "critic_loss": 0.3334940101802349, "actor_loss": -39.59666510772705, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.339962244033813, "step": 135000}
{"episode_reward": 487.73725579332887, "episode": 136.0, "batch_reward": 0.2930316146761179, "critic_loss": 0.32631923966109755, "actor_loss": -39.679394660949704, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.324600219726562, "step": 136000}
{"episode_reward": 507.4131032107594, "episode": 137.0, "batch_reward": 0.29533842009305955, "critic_loss": 0.3470150601491332, "actor_loss": -39.558118476867676, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.8888156414032, "step": 137000}
{"episode_reward": 497.0525588985671, "episode": 138.0, "batch_reward": 0.29850823833048346, "critic_loss": 0.32681058457493783, "actor_loss": -39.406991958618164, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.889524698257446, "step": 138000}
{"episode_reward": 498.5700571592616, "episode": 139.0, "batch_reward": 0.29935499183833597, "critic_loss": 0.31308831880986693, "actor_loss": -39.4346297454834, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.163538932800293, "step": 139000}
{"episode_reward": 506.98062077207834, "episode": 140.0, "batch_reward": 0.30052648827433587, "critic_loss": 0.2925800557434559, "actor_loss": -39.23630643844604, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.971434116363525, "step": 140000}
{"episode_reward": 499.46936031212476, "episode": 141.0, "batch_reward": 0.3024864786863327, "critic_loss": 0.28900008883327244, "actor_loss": -39.106834590911866, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.06469941139221, "step": 141000}
{"episode_reward": 509.6162973280215, "episode": 142.0, "batch_reward": 0.3019873332977295, "critic_loss": 0.2960568545460701, "actor_loss": -39.441945209503174, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.146418809890747, "step": 142000}
{"episode_reward": 525.3146554635741, "episode": 143.0, "batch_reward": 0.30465245416760445, "critic_loss": 0.3059723667353392, "actor_loss": -39.32824429702759, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.925943613052368, "step": 143000}
{"episode_reward": 462.79106248502654, "episode": 144.0, "batch_reward": 0.30532844856381414, "critic_loss": 0.2994235511571169, "actor_loss": -39.48786640930176, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.30366063117981, "step": 144000}
{"episode_reward": 518.7557592429077, "episode": 145.0, "batch_reward": 0.30813945473730564, "critic_loss": 0.28257237661629914, "actor_loss": -39.4210161819458, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.22481107711792, "step": 145000}
{"episode_reward": 493.37020332639764, "episode": 146.0, "batch_reward": 0.30768878903985025, "critic_loss": 0.2749353331029415, "actor_loss": -39.781176879882814, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.207467317581177, "step": 146000}
{"episode_reward": 476.0547269216796, "episode": 147.0, "batch_reward": 0.30960015311837197, "critic_loss": 0.2792876413092017, "actor_loss": -39.50576764297485, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.889241456985474, "step": 147000}
{"episode_reward": 517.2139771981141, "episode": 148.0, "batch_reward": 0.3106375014781952, "critic_loss": 0.27175642266869543, "actor_loss": -39.61637309646606, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.795064210891724, "step": 148000}
{"episode_reward": 501.741790395573, "episode": 149.0, "batch_reward": 0.31272575874626635, "critic_loss": 0.2637867477312684, "actor_loss": -39.7906685218811, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.309896230697632, "step": 149000}
{"episode_reward": 509.2616731819892, "episode": 150.0, "batch_reward": 0.31394596382975576, "critic_loss": 0.28215777198970315, "actor_loss": -39.973092761993406, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
