{"episode_reward": 0.0, "episode": 1.0, "duration": 17.162222623825073, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.4884858131408691, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.2351799682900682, "critic_loss": 0.19481316777508273, "actor_loss": -45.957146495377934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.97322487831116, "step": 3000}
{"episode_reward": 365.95880184843463, "episode": 4.0, "batch_reward": 0.29386788968741895, "critic_loss": 0.24432987490296365, "actor_loss": -47.93067768096924, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.985610008239746, "step": 4000}
{"episode_reward": 368.7683381853137, "episode": 5.0, "batch_reward": 0.31091587217152117, "critic_loss": 0.260073652818799, "actor_loss": -47.02910462188721, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.026394844055176, "step": 5000}
{"episode_reward": 450.20983341189316, "episode": 6.0, "batch_reward": 0.3373187174797058, "critic_loss": 0.3189495289474726, "actor_loss": -48.528543579101566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99582290649414, "step": 6000}
{"episode_reward": 457.13580620045605, "episode": 7.0, "batch_reward": 0.34494171699881554, "critic_loss": 0.34443074937164786, "actor_loss": -48.94329968261719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.007245302200317, "step": 7000}
{"episode_reward": 356.06566633410654, "episode": 8.0, "batch_reward": 0.354896135032177, "critic_loss": 0.3698606373220682, "actor_loss": -49.32659545898437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01331067085266, "step": 8000}
{"episode_reward": 360.3107788206442, "episode": 9.0, "batch_reward": 0.35635067510604856, "critic_loss": 0.37464285802841185, "actor_loss": -48.87411352539063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99924945831299, "step": 9000}
{"episode_reward": 462.37817797877574, "episode": 10.0, "batch_reward": 0.3697657309770584, "critic_loss": 0.3765295644849539, "actor_loss": -49.609737312316895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.023194313049316, "step": 10000}
{"episode_reward": 478.69403937325154, "episode": 11.0, "batch_reward": 0.38101117160916326, "critic_loss": 0.37053202943503855, "actor_loss": -50.22652894592285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.208970069885254, "step": 11000}
{"episode_reward": 491.8281026537842, "episode": 12.0, "batch_reward": 0.38959626361727717, "critic_loss": 0.33058001182973384, "actor_loss": -50.5666923751831, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.972848653793335, "step": 12000}
{"episode_reward": 508.9478493415129, "episode": 13.0, "batch_reward": 0.39844524425268174, "critic_loss": 0.31195065312087533, "actor_loss": -51.20955162811279, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01630163192749, "step": 13000}
{"episode_reward": 476.54203582121585, "episode": 14.0, "batch_reward": 0.40363875767588614, "critic_loss": 0.31019455768167975, "actor_loss": -51.25922431182861, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02264952659607, "step": 14000}
{"episode_reward": 474.48109845810933, "episode": 15.0, "batch_reward": 0.4079333304166794, "critic_loss": 0.2801492867171764, "actor_loss": -51.89172624206543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04445767402649, "step": 15000}
{"episode_reward": 459.5789098829342, "episode": 16.0, "batch_reward": 0.41315072137117387, "critic_loss": 0.2812239571362734, "actor_loss": -51.82452262878418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.303186655044556, "step": 16000}
{"episode_reward": 464.978722486457, "episode": 17.0, "batch_reward": 0.414282137542963, "critic_loss": 0.28289929166436195, "actor_loss": -52.005458671569826, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.988494396209717, "step": 17000}
{"episode_reward": 454.2161735865685, "episode": 18.0, "batch_reward": 0.41842546314001083, "critic_loss": 0.2842520014345646, "actor_loss": -52.06634294128418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.029142379760742, "step": 18000}
{"episode_reward": 461.3320841345584, "episode": 19.0, "batch_reward": 0.42054771465063095, "critic_loss": 0.2840187174677849, "actor_loss": -51.94004414367676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.24131441116333, "step": 19000}
{"episode_reward": 469.87959544440525, "episode": 20.0, "batch_reward": 0.42298908963799475, "critic_loss": 0.28343764224648477, "actor_loss": -52.23251474761963, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.999733448028564, "step": 20000}
{"episode_reward": 480.28982984925824, "episode": 21.0, "batch_reward": 0.42563236492872236, "critic_loss": 0.30406667704880236, "actor_loss": -52.36933458709717, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.18391299247742, "step": 21000}
{"episode_reward": 470.44298637807685, "episode": 22.0, "batch_reward": 0.42874200975894927, "critic_loss": 0.2996956070661545, "actor_loss": -52.41312099456787, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.005128622055054, "step": 22000}
{"episode_reward": 473.59548946901185, "episode": 23.0, "batch_reward": 0.430558458507061, "critic_loss": 0.305663325086236, "actor_loss": -52.735845947265624, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.976596355438232, "step": 23000}
{"episode_reward": 467.4488566215024, "episode": 24.0, "batch_reward": 0.43152808654308317, "critic_loss": 0.30659249326586724, "actor_loss": -52.58014638519287, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.955809831619263, "step": 24000}
{"episode_reward": 459.8013317825923, "episode": 25.0, "batch_reward": 0.432460958391428, "critic_loss": 0.31127782055735587, "actor_loss": -52.440044540405275, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95903468132019, "step": 25000}
{"episode_reward": 503.25378794218256, "episode": 26.0, "batch_reward": 0.4339611734747887, "critic_loss": 0.32430482539534566, "actor_loss": -52.770534507751464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.974880695343018, "step": 26000}
{"episode_reward": 422.97915984230156, "episode": 27.0, "batch_reward": 0.434654024541378, "critic_loss": 0.32930691446363924, "actor_loss": -52.501196029663085, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.025868892669678, "step": 27000}
{"episode_reward": 460.75597510937837, "episode": 28.0, "batch_reward": 0.43664183032512666, "critic_loss": 0.3064021700322628, "actor_loss": -52.46150534820556, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.003319263458252, "step": 28000}
{"episode_reward": 460.8139802274319, "episode": 29.0, "batch_reward": 0.4368420462012291, "critic_loss": 0.32680153019726277, "actor_loss": -52.60320859527588, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.004770517349243, "step": 29000}
{"episode_reward": 458.6915108082497, "episode": 30.0, "batch_reward": 0.4380839407145977, "critic_loss": 0.31660834059119225, "actor_loss": -52.50394497680664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.008601903915405, "step": 30000}
{"episode_reward": 485.3112902354701, "episode": 31.0, "batch_reward": 0.4388673259913921, "critic_loss": 0.3018178418278694, "actor_loss": -52.58016635131836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.207258462905884, "step": 31000}
{"episode_reward": 457.93448835412624, "episode": 32.0, "batch_reward": 0.43967397344112397, "critic_loss": 0.3109177035689354, "actor_loss": -52.370919998168944, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99966073036194, "step": 32000}
{"episode_reward": 475.8791074855606, "episode": 33.0, "batch_reward": 0.4411380008459091, "critic_loss": 0.3226695749312639, "actor_loss": -52.78515753173828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.981621026992798, "step": 33000}
{"episode_reward": 479.94392428679674, "episode": 34.0, "batch_reward": 0.44151198196411134, "critic_loss": 0.3149013566970825, "actor_loss": -52.46607516479492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.995922565460205, "step": 34000}
{"episode_reward": 478.8683931767673, "episode": 35.0, "batch_reward": 0.44284365910291673, "critic_loss": 0.3098186106532812, "actor_loss": -53.02305744934082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.981705904006958, "step": 35000}
{"episode_reward": 477.7179212249613, "episode": 36.0, "batch_reward": 0.44377810204029083, "critic_loss": 0.28994715183973313, "actor_loss": -52.508183723449704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.014439821243286, "step": 36000}
{"episode_reward": 482.9463907826043, "episode": 37.0, "batch_reward": 0.4450895251631737, "critic_loss": 0.2960725709348917, "actor_loss": -53.05332409667969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.020992517471313, "step": 37000}
{"episode_reward": 499.03198999184264, "episode": 38.0, "batch_reward": 0.44694423243403436, "critic_loss": 0.2995360862612724, "actor_loss": -53.08459158325196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.017741203308105, "step": 38000}
{"episode_reward": 516.8429747213169, "episode": 39.0, "batch_reward": 0.44502151623368263, "critic_loss": 0.3249484564960003, "actor_loss": -52.83483938598633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.027413845062256, "step": 39000}
{"episode_reward": 132.41504471261575, "episode": 40.0, "batch_reward": 0.43948613306879997, "critic_loss": 0.3239956374168396, "actor_loss": -52.3335080947876, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.022429704666138, "step": 40000}
{"episode_reward": 450.32585259220093, "episode": 41.0, "batch_reward": 0.44156393736600874, "critic_loss": 0.3117992128878832, "actor_loss": -52.565077415466305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.19585466384888, "step": 41000}
{"episode_reward": 499.9595502497094, "episode": 42.0, "batch_reward": 0.44266883584856986, "critic_loss": 0.31238361163437367, "actor_loss": -52.1878350982666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9857280254364, "step": 42000}
{"episode_reward": 515.3929430853, "episode": 43.0, "batch_reward": 0.4430411982536316, "critic_loss": 0.3004138363748789, "actor_loss": -52.363015312194825, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.971471786499023, "step": 43000}
{"episode_reward": 484.5286731379642, "episode": 44.0, "batch_reward": 0.4448343632221222, "critic_loss": 0.2993965725004673, "actor_loss": -52.36099230194092, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00245761871338, "step": 44000}
{"episode_reward": 478.0134920593907, "episode": 45.0, "batch_reward": 0.4457382784485817, "critic_loss": 0.3148928085118532, "actor_loss": -52.51213555908203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00104522705078, "step": 45000}
{"episode_reward": 493.03438155845436, "episode": 46.0, "batch_reward": 0.44550182223320006, "critic_loss": 0.33697175759077075, "actor_loss": -52.460805053710935, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.019195795059204, "step": 46000}
{"episode_reward": 451.7350456297341, "episode": 47.0, "batch_reward": 0.44708029624819756, "critic_loss": 0.32986937868595123, "actor_loss": -52.76546183013916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.028409719467163, "step": 47000}
{"episode_reward": 499.02299702436653, "episode": 48.0, "batch_reward": 0.4468278132379055, "critic_loss": 0.36814138720929623, "actor_loss": -52.52702281951904, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.014946937561035, "step": 48000}
{"episode_reward": 444.0903435941769, "episode": 49.0, "batch_reward": 0.4479070608913899, "critic_loss": 0.3688409860134125, "actor_loss": -52.938146751403806, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.016836404800415, "step": 49000}
{"episode_reward": 507.5447619312193, "episode": 50.0, "batch_reward": 0.4463828603625298, "critic_loss": 0.38837772043049335, "actor_loss": -52.37742143249512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.021578788757324, "step": 50000}
{"episode_reward": 140.25261909880325, "episode": 51.0, "batch_reward": 0.4430799055397511, "critic_loss": 0.3945261862874031, "actor_loss": -52.07665704345703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.234753131866455, "step": 51000}
{"episode_reward": 475.251478052044, "episode": 52.0, "batch_reward": 0.4435769165158272, "critic_loss": 0.40280066107213497, "actor_loss": -52.07291111755371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00295090675354, "step": 52000}
{"episode_reward": 468.41581429129, "episode": 53.0, "batch_reward": 0.4436509456932545, "critic_loss": 0.39559475603699684, "actor_loss": -52.22140936279297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.003649950027466, "step": 53000}
{"episode_reward": 458.36416084209856, "episode": 54.0, "batch_reward": 0.4437414267063141, "critic_loss": 0.3967127292305231, "actor_loss": -52.071182411193845, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99591040611267, "step": 54000}
{"episode_reward": 477.3804218411832, "episode": 55.0, "batch_reward": 0.4449193162918091, "critic_loss": 0.3865072855055332, "actor_loss": -52.550540077209476, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99659276008606, "step": 55000}
{"episode_reward": 463.18364393348367, "episode": 56.0, "batch_reward": 0.4453080796003342, "critic_loss": 0.4186172055900097, "actor_loss": -52.486969734191895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99172282218933, "step": 56000}
{"episode_reward": 477.0974663113456, "episode": 57.0, "batch_reward": 0.44598239904642106, "critic_loss": 0.40714220644533633, "actor_loss": -52.07133483123779, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.027652978897095, "step": 57000}
{"episode_reward": 479.8771803873436, "episode": 58.0, "batch_reward": 0.4461335091292858, "critic_loss": 0.3994893971383572, "actor_loss": -52.23564249420166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00672960281372, "step": 58000}
{"episode_reward": 457.6402939302869, "episode": 59.0, "batch_reward": 0.4470687288939953, "critic_loss": 0.4022948765009642, "actor_loss": -52.21030188751221, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02088236808777, "step": 59000}
{"episode_reward": 522.1992669954775, "episode": 60.0, "batch_reward": 0.4475778731405735, "critic_loss": 0.4011932331323624, "actor_loss": -52.26141079711914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.007646799087524, "step": 60000}
{"episode_reward": 463.0274222113844, "episode": 61.0, "batch_reward": 0.44810588800907136, "critic_loss": 0.38669513529539107, "actor_loss": -52.102053939819335, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.24091958999634, "step": 61000}
{"episode_reward": 461.18544805789566, "episode": 62.0, "batch_reward": 0.4474282288849354, "critic_loss": 0.39614456382393837, "actor_loss": -52.60956502532959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997992515563965, "step": 62000}
{"episode_reward": 468.29461735198527, "episode": 63.0, "batch_reward": 0.4477972971200943, "critic_loss": 0.40084737886488436, "actor_loss": -52.29978685760498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.984785079956055, "step": 63000}
{"episode_reward": 493.04394861026964, "episode": 64.0, "batch_reward": 0.4484538984298706, "critic_loss": 0.4011009572893381, "actor_loss": -52.457689750671385, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.002391815185547, "step": 64000}
{"episode_reward": 456.3774861129412, "episode": 65.0, "batch_reward": 0.4497271722853184, "critic_loss": 0.3946138919889927, "actor_loss": -52.32244549560547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.007082223892212, "step": 65000}
{"episode_reward": 475.11183725709697, "episode": 66.0, "batch_reward": 0.44961233472824097, "critic_loss": 0.38545904149115084, "actor_loss": -52.40188729095459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.022684335708618, "step": 66000}
{"episode_reward": 495.4635175807339, "episode": 67.0, "batch_reward": 0.4490452337563038, "critic_loss": 0.37851672208309173, "actor_loss": -52.42906604003906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0282301902771, "step": 67000}
{"episode_reward": 443.11981694890216, "episode": 68.0, "batch_reward": 0.4506995800435543, "critic_loss": 0.39669678576290607, "actor_loss": -52.39426998138428, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.028730392456055, "step": 68000}
{"episode_reward": 505.02397211135974, "episode": 69.0, "batch_reward": 0.4505096904337406, "critic_loss": 0.39117940141260626, "actor_loss": -52.462428192138674, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.003692388534546, "step": 69000}
{"episode_reward": 505.8953715237723, "episode": 70.0, "batch_reward": 0.45234337261319163, "critic_loss": 0.3843633797168732, "actor_loss": -52.73782738494873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.987418174743652, "step": 70000}
{"episode_reward": 533.5851017834059, "episode": 71.0, "batch_reward": 0.4524437840878964, "critic_loss": 0.38917294853925705, "actor_loss": -52.800304847717285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.22944116592407, "step": 71000}
{"episode_reward": 484.62177171883815, "episode": 72.0, "batch_reward": 0.4531684653759003, "critic_loss": 0.3749272871017456, "actor_loss": -52.86669580078125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.998079776763916, "step": 72000}
{"episode_reward": 484.3211650980996, "episode": 73.0, "batch_reward": 0.4539088075757027, "critic_loss": 0.3872733256071806, "actor_loss": -52.73671401977539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99886989593506, "step": 73000}
{"episode_reward": 513.8837335736281, "episode": 74.0, "batch_reward": 0.45456799706816675, "critic_loss": 0.37214727322757246, "actor_loss": -52.99929140472412, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00339365005493, "step": 74000}
{"episode_reward": 461.8089888129212, "episode": 75.0, "batch_reward": 0.45518098416924474, "critic_loss": 0.36067774108052253, "actor_loss": -52.76086380767822, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01391887664795, "step": 75000}
{"episode_reward": 528.0939409508442, "episode": 76.0, "batch_reward": 0.45667771169543264, "critic_loss": 0.3696739817559719, "actor_loss": -52.951385375976564, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.010549783706665, "step": 76000}
{"episode_reward": 501.59466701824823, "episode": 77.0, "batch_reward": 0.45583611315488815, "critic_loss": 0.383140761077404, "actor_loss": -52.70061563110352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01534104347229, "step": 77000}
{"episode_reward": 499.1072151923657, "episode": 78.0, "batch_reward": 0.45757139337062835, "critic_loss": 0.3628495140969753, "actor_loss": -53.085084602355955, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.018769025802612, "step": 78000}
{"episode_reward": 478.3985819114233, "episode": 79.0, "batch_reward": 0.4570775214731693, "critic_loss": 0.3521420338600874, "actor_loss": -52.420004234313964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.989667654037476, "step": 79000}
{"episode_reward": 528.5771323452911, "episode": 80.0, "batch_reward": 0.45824255925416946, "critic_loss": 0.33851238863170147, "actor_loss": -52.87155729675293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.020482540130615, "step": 80000}
{"episode_reward": 527.9572396815537, "episode": 81.0, "batch_reward": 0.4588843484818935, "critic_loss": 0.3357018606066704, "actor_loss": -52.87348377227783, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.23422622680664, "step": 81000}
{"episode_reward": 480.7865025898223, "episode": 82.0, "batch_reward": 0.4589528854191303, "critic_loss": 0.3155807575583458, "actor_loss": -53.41393486022949, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997171878814697, "step": 82000}
{"episode_reward": 519.3153386883087, "episode": 83.0, "batch_reward": 0.46036583665013314, "critic_loss": 0.33872168807685377, "actor_loss": -53.03348246002197, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99561595916748, "step": 83000}
{"episode_reward": 502.38006391602323, "episode": 84.0, "batch_reward": 0.46058029824495317, "critic_loss": 0.3367685548067093, "actor_loss": -53.74912162017822, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01647973060608, "step": 84000}
{"episode_reward": 474.8720311647295, "episode": 85.0, "batch_reward": 0.46017546942830084, "critic_loss": 0.32558988535404204, "actor_loss": -53.256222885131834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.988187074661255, "step": 85000}
{"episode_reward": 469.3742455753554, "episode": 86.0, "batch_reward": 0.46015161111950875, "critic_loss": 0.34882252137362957, "actor_loss": -53.20092854309082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.014793634414673, "step": 86000}
{"episode_reward": 478.8403250847432, "episode": 87.0, "batch_reward": 0.4614360429346561, "critic_loss": 0.33351317305862904, "actor_loss": -53.31274685668945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.008935689926147, "step": 87000}
{"episode_reward": 509.8398019976751, "episode": 88.0, "batch_reward": 0.4616603596806526, "critic_loss": 0.32413816902041437, "actor_loss": -53.03284359741211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.014998197555542, "step": 88000}
{"episode_reward": 480.16569131524477, "episode": 89.0, "batch_reward": 0.4608585344851017, "critic_loss": 0.3575266911834478, "actor_loss": -53.355323585510256, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00206685066223, "step": 89000}
{"episode_reward": 494.6305664599868, "episode": 90.0, "batch_reward": 0.4624699089229107, "critic_loss": 0.34403275516629217, "actor_loss": -53.572235565185544, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.996110916137695, "step": 90000}
{"episode_reward": 460.6246104909704, "episode": 91.0, "batch_reward": 0.4618403176367283, "critic_loss": 0.3520404935181141, "actor_loss": -53.40164968109131, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.192001819610596, "step": 91000}
{"episode_reward": 515.2397718386237, "episode": 92.0, "batch_reward": 0.46338600444793704, "critic_loss": 0.345372173294425, "actor_loss": -53.45916443634033, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997507095336914, "step": 92000}
{"episode_reward": 496.74952320985045, "episode": 93.0, "batch_reward": 0.4622170060575008, "critic_loss": 0.3457375310957432, "actor_loss": -53.18683651733399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.000591278076172, "step": 93000}
{"episode_reward": 493.8028356495401, "episode": 94.0, "batch_reward": 0.4630751058459282, "critic_loss": 0.3455149995535612, "actor_loss": -53.46653018951416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98337984085083, "step": 94000}
{"episode_reward": 479.256013846807, "episode": 95.0, "batch_reward": 0.46319930016994476, "critic_loss": 0.35248130016028884, "actor_loss": -53.58620008850097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.010022163391113, "step": 95000}
{"episode_reward": 470.6301185094682, "episode": 96.0, "batch_reward": 0.46356975942850115, "critic_loss": 0.35415222561359405, "actor_loss": -53.72037538146973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01259207725525, "step": 96000}
{"episode_reward": 492.1167924019757, "episode": 97.0, "batch_reward": 0.46404664051532746, "critic_loss": 0.3574230707883835, "actor_loss": -53.880762268066405, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00207209587097, "step": 97000}
{"episode_reward": 493.56577487743493, "episode": 98.0, "batch_reward": 0.4641502776145935, "critic_loss": 0.3628927914351225, "actor_loss": -53.64999656677246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.005582332611084, "step": 98000}
{"episode_reward": 505.0639716502657, "episode": 99.0, "batch_reward": 0.46447390162944796, "critic_loss": 0.372388916566968, "actor_loss": -53.47030549621582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01032829284668, "step": 99000}
{"episode_reward": 512.0997136018623, "episode": 100.0, "batch_reward": 0.4655260434150696, "critic_loss": 0.3665980248004198, "actor_loss": -53.673683227539065, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.002424240112305, "step": 100000}
{"episode_reward": 484.9991978740358, "episode": 101.0, "batch_reward": 0.4653172086775303, "critic_loss": 0.36348939962685106, "actor_loss": -53.738286735534665, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.194828748703, "step": 101000}
{"episode_reward": 509.85506012237647, "episode": 102.0, "batch_reward": 0.4659530773460865, "critic_loss": 0.376676397010684, "actor_loss": -53.53397212982178, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.003495931625366, "step": 102000}
{"episode_reward": 504.2992496725973, "episode": 103.0, "batch_reward": 0.4659260372519493, "critic_loss": 0.3643543990403414, "actor_loss": -53.88259593963623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.015676259994507, "step": 103000}
{"episode_reward": 506.7524114040041, "episode": 104.0, "batch_reward": 0.4671708003282547, "critic_loss": 0.3757052255868912, "actor_loss": -53.96890732574463, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00576949119568, "step": 104000}
{"episode_reward": 486.0547039641978, "episode": 105.0, "batch_reward": 0.46722443619370463, "critic_loss": 0.3755591881126165, "actor_loss": -53.925742301940915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01720666885376, "step": 105000}
{"episode_reward": 491.433542888147, "episode": 106.0, "batch_reward": 0.4673474596440792, "critic_loss": 0.35401314428448677, "actor_loss": -53.792963310241696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.026110649108887, "step": 106000}
{"episode_reward": 502.0771163025797, "episode": 107.0, "batch_reward": 0.46706927078962324, "critic_loss": 0.35759533047676084, "actor_loss": -53.99938848876953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.007972955703735, "step": 107000}
{"episode_reward": 488.1020411094474, "episode": 108.0, "batch_reward": 0.46780468225479127, "critic_loss": 0.357956576526165, "actor_loss": -53.9056251449585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.017487049102783, "step": 108000}
{"episode_reward": 495.8256768445172, "episode": 109.0, "batch_reward": 0.46800419574975965, "critic_loss": 0.36373858273029325, "actor_loss": -54.32169402313232, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01227307319641, "step": 109000}
{"episode_reward": 500.88643553566817, "episode": 110.0, "batch_reward": 0.46787809339165687, "critic_loss": 0.357280449450016, "actor_loss": -54.129085006713865, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.994725942611694, "step": 110000}
{"episode_reward": 489.7737534075372, "episode": 111.0, "batch_reward": 0.4677757244706154, "critic_loss": 0.36511439497768877, "actor_loss": -54.10872933959961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.190146684646606, "step": 111000}
{"episode_reward": 504.0802077398853, "episode": 112.0, "batch_reward": 0.46809370601177214, "critic_loss": 0.3672224210053682, "actor_loss": -53.746262466430665, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.008509159088135, "step": 112000}
{"episode_reward": 492.68804135644353, "episode": 113.0, "batch_reward": 0.4692202568948269, "critic_loss": 0.37611760568618774, "actor_loss": -54.12048049163818, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.995423078536987, "step": 113000}
{"episode_reward": 499.6018095549113, "episode": 114.0, "batch_reward": 0.46922600388526914, "critic_loss": 0.3770650855749845, "actor_loss": -54.297283416748044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01400327682495, "step": 114000}
{"episode_reward": 493.09824334794774, "episode": 115.0, "batch_reward": 0.4695438804328442, "critic_loss": 0.37107663476467134, "actor_loss": -54.01394406890869, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01650857925415, "step": 115000}
{"episode_reward": 508.6812553307253, "episode": 116.0, "batch_reward": 0.4698475087583065, "critic_loss": 0.38826093155145647, "actor_loss": -54.03616000366211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.011369466781616, "step": 116000}
{"episode_reward": 498.54409343110376, "episode": 117.0, "batch_reward": 0.46999989679455756, "critic_loss": 0.3916809661537409, "actor_loss": -53.891592872619626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00493860244751, "step": 117000}
{"episode_reward": 472.25425210086223, "episode": 118.0, "batch_reward": 0.469636684268713, "critic_loss": 0.40254756148159504, "actor_loss": -54.1025511932373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.011826276779175, "step": 118000}
{"episode_reward": 475.6930035990772, "episode": 119.0, "batch_reward": 0.47033735263347626, "critic_loss": 0.39746956814825535, "actor_loss": -54.18754552459717, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.013206243515015, "step": 119000}
{"episode_reward": 491.62664174525906, "episode": 120.0, "batch_reward": 0.4698363107144833, "critic_loss": 0.3765657117366791, "actor_loss": -54.089572257995606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.958088159561157, "step": 120000}
{"episode_reward": 494.113472359875, "episode": 121.0, "batch_reward": 0.4704176429510117, "critic_loss": 0.37208587358891965, "actor_loss": -53.88800951385498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.17799234390259, "step": 121000}
{"episode_reward": 498.35330180878736, "episode": 122.0, "batch_reward": 0.4702593306601047, "critic_loss": 0.3574459576308727, "actor_loss": -54.075106300354, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9941828250885, "step": 122000}
{"episode_reward": 505.2277944850986, "episode": 123.0, "batch_reward": 0.4707033381164074, "critic_loss": 0.37313831235468387, "actor_loss": -53.709706497192386, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.995959043502808, "step": 123000}
{"episode_reward": 469.08815625069815, "episode": 124.0, "batch_reward": 0.4703674976825714, "critic_loss": 0.3932333937138319, "actor_loss": -53.98725106048584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0118350982666, "step": 124000}
{"episode_reward": 503.4487605695965, "episode": 125.0, "batch_reward": 0.4712588331699371, "critic_loss": 0.3632446112036705, "actor_loss": -53.95993187713623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.982091903686523, "step": 125000}
{"episode_reward": 526.2679996722827, "episode": 126.0, "batch_reward": 0.4713400500714779, "critic_loss": 0.3506084278970957, "actor_loss": -53.810036979675296, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.006254196166992, "step": 126000}
{"episode_reward": 517.5378767985522, "episode": 127.0, "batch_reward": 0.4712800318300724, "critic_loss": 0.3473349947780371, "actor_loss": -54.23043795013428, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.983924388885498, "step": 127000}
{"episode_reward": 150.84797778161789, "episode": 128.0, "batch_reward": 0.4692216612100601, "critic_loss": 0.3586132303774357, "actor_loss": -54.357049789428714, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03561043739319, "step": 128000}
{"episode_reward": 502.7590257266894, "episode": 129.0, "batch_reward": 0.46986489653587343, "critic_loss": 0.36525672547519206, "actor_loss": -54.09499444580078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98398995399475, "step": 129000}
{"episode_reward": 492.5262724094649, "episode": 130.0, "batch_reward": 0.4700551129281521, "critic_loss": 0.3990734045058489, "actor_loss": -54.05986612701416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02639079093933, "step": 130000}
{"episode_reward": 503.33844918381396, "episode": 131.0, "batch_reward": 0.46944926244020463, "critic_loss": 0.3952968118339777, "actor_loss": -54.20918704223633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.208617210388184, "step": 131000}
{"episode_reward": 482.28309799064397, "episode": 132.0, "batch_reward": 0.4700382130742073, "critic_loss": 0.3803550753593445, "actor_loss": -54.18729844665528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.013190746307373, "step": 132000}
{"episode_reward": 480.1245842657325, "episode": 133.0, "batch_reward": 0.4702112456858158, "critic_loss": 0.38783146512508393, "actor_loss": -54.136560813903806, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01425313949585, "step": 133000}
{"episode_reward": 453.45786739367105, "episode": 134.0, "batch_reward": 0.47052851340174673, "critic_loss": 0.41730571492016316, "actor_loss": -54.24285059356689, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.013059616088867, "step": 134000}
{"episode_reward": 442.41963195501705, "episode": 135.0, "batch_reward": 0.4700273461341858, "critic_loss": 0.4039576467871666, "actor_loss": -54.10719394683838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.024906158447266, "step": 135000}
{"episode_reward": 484.91025628724174, "episode": 136.0, "batch_reward": 0.4699024671018124, "critic_loss": 0.41907883404195306, "actor_loss": -54.40036573791504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.026803016662598, "step": 136000}
{"episode_reward": 490.71999740263203, "episode": 137.0, "batch_reward": 0.46948003593087195, "critic_loss": 0.4206206609457731, "actor_loss": -54.197523109436034, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.023131608963013, "step": 137000}
{"episode_reward": 501.2494381071977, "episode": 138.0, "batch_reward": 0.47049918869137763, "critic_loss": 0.41279300051927564, "actor_loss": -53.70968724822998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.015065908432007, "step": 138000}
{"episode_reward": 530.6941016047869, "episode": 139.0, "batch_reward": 0.47081661778688433, "critic_loss": 0.41350722913444043, "actor_loss": -53.94834154510498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.011431455612183, "step": 139000}
{"episode_reward": 503.92941634436437, "episode": 140.0, "batch_reward": 0.4714738978147507, "critic_loss": 0.3991908841133118, "actor_loss": -53.7711428527832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.989861249923706, "step": 140000}
{"episode_reward": 539.6746719219637, "episode": 141.0, "batch_reward": 0.471218878954649, "critic_loss": 0.4196612271517515, "actor_loss": -53.95716206359863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.22676467895508, "step": 141000}
{"episode_reward": 543.8146341902442, "episode": 142.0, "batch_reward": 0.4721845608353615, "critic_loss": 0.4122563827782869, "actor_loss": -54.09978295135498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03469467163086, "step": 142000}
{"episode_reward": 511.6859667471694, "episode": 143.0, "batch_reward": 0.4725840372443199, "critic_loss": 0.40264802588522436, "actor_loss": -54.275558143615726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.988033056259155, "step": 143000}
{"episode_reward": 515.9931958474808, "episode": 144.0, "batch_reward": 0.47221954047679904, "critic_loss": 0.37932638593018053, "actor_loss": -54.27459027862549, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997114658355713, "step": 144000}
{"episode_reward": 494.902744547452, "episode": 145.0, "batch_reward": 0.4729186772704124, "critic_loss": 0.3930534800291061, "actor_loss": -54.19802783203125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.011563301086426, "step": 145000}
{"episode_reward": 516.7445258265012, "episode": 146.0, "batch_reward": 0.47307457491755484, "critic_loss": 0.3775036879479885, "actor_loss": -54.1388355178833, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.024503231048584, "step": 146000}
{"episode_reward": 517.4638697737001, "episode": 147.0, "batch_reward": 0.4732942568063736, "critic_loss": 0.3707297903895378, "actor_loss": -54.54197624206543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.007872104644775, "step": 147000}
{"episode_reward": 492.01786218610056, "episode": 148.0, "batch_reward": 0.47413477656245234, "critic_loss": 0.36313460844755174, "actor_loss": -54.318720535278324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.05349588394165, "step": 148000}
{"episode_reward": 529.6897443265264, "episode": 149.0, "batch_reward": 0.47350956413149836, "critic_loss": 0.36144343777000904, "actor_loss": -54.390306358337405, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.358633041381836, "step": 149000}
{"episode_reward": 528.6369964584976, "episode": 150.0, "batch_reward": 0.47390429055690764, "critic_loss": 0.37943927189707755, "actor_loss": -54.12298770904541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
