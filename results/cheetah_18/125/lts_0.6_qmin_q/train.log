{"episode_reward": 0.0, "episode": 1.0, "duration": 18.125202417373657, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.5225775241851807, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.2178618474408522, "critic_loss": 0.19462381667144182, "actor_loss": -44.2529648471327, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 61.91612768173218, "step": 3000}
{"episode_reward": 41.790090980956954, "episode": 4.0, "batch_reward": 0.16106193853169679, "critic_loss": 0.15188673139363526, "actor_loss": -39.65073239135742, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.56493043899536, "step": 4000}
{"episode_reward": 155.07034151466357, "episode": 5.0, "batch_reward": 0.15584394804388285, "critic_loss": 0.15190166259557009, "actor_loss": -36.90830271530152, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.85154891014099, "step": 5000}
{"episode_reward": 54.60914661186165, "episode": 6.0, "batch_reward": 0.14305416157841683, "critic_loss": 0.1733232716396451, "actor_loss": -32.8509557762146, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.454367637634277, "step": 6000}
{"episode_reward": 100.21063377741247, "episode": 7.0, "batch_reward": 0.1404277216643095, "critic_loss": 0.18463711428642274, "actor_loss": -31.29313409423828, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.504302263259888, "step": 7000}
{"episode_reward": 225.28777224953504, "episode": 8.0, "batch_reward": 0.1487531945630908, "critic_loss": 0.21973257156461476, "actor_loss": -31.79529000854492, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.039853811264038, "step": 8000}
{"episode_reward": 119.99795339596157, "episode": 9.0, "batch_reward": 0.1384694892242551, "critic_loss": 0.18549670574069024, "actor_loss": -29.83411852645874, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.807318210601807, "step": 9000}
{"episode_reward": 19.977389270771088, "episode": 10.0, "batch_reward": 0.13865084483474494, "critic_loss": 0.21765874981880187, "actor_loss": -29.410311851501465, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.94619059562683, "step": 10000}
{"episode_reward": 306.0813180406227, "episode": 11.0, "batch_reward": 0.1568909190222621, "critic_loss": 0.22805847810208799, "actor_loss": -30.854648963928224, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.346383571624756, "step": 11000}
{"episode_reward": 346.89951429029554, "episode": 12.0, "batch_reward": 0.17557531540095805, "critic_loss": 0.2160970638990402, "actor_loss": -31.589469562530518, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.64648938179016, "step": 12000}
{"episode_reward": 394.1947400446642, "episode": 13.0, "batch_reward": 0.18861856864392756, "critic_loss": 0.22967707136273385, "actor_loss": -32.395141319274906, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.322895526885986, "step": 13000}
{"episode_reward": 217.20170223320804, "episode": 14.0, "batch_reward": 0.19216158214211465, "critic_loss": 0.22210521636903285, "actor_loss": -31.846644073486328, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.26609492301941, "step": 14000}
{"episode_reward": 295.5453915622035, "episode": 15.0, "batch_reward": 0.20187857729196548, "critic_loss": 0.24161140778660775, "actor_loss": -33.33017371368408, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.021350622177124, "step": 15000}
{"episode_reward": 397.2860014780099, "episode": 16.0, "batch_reward": 0.21590682470798492, "critic_loss": 0.24291910008341075, "actor_loss": -34.04099778747558, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.222519874572754, "step": 16000}
{"episode_reward": 455.5910487603244, "episode": 17.0, "batch_reward": 0.22369906534254552, "critic_loss": 0.25165538996458053, "actor_loss": -33.896460891723635, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.37540578842163, "step": 17000}
{"episode_reward": 136.07670674361418, "episode": 18.0, "batch_reward": 0.2244821417480707, "critic_loss": 0.2372627026811242, "actor_loss": -33.51643532943726, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.84651803970337, "step": 18000}
{"episode_reward": 427.18511695363634, "episode": 19.0, "batch_reward": 0.23600131560862064, "critic_loss": 0.2442163737937808, "actor_loss": -33.95669603729248, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.176055431365967, "step": 19000}
{"episode_reward": 435.7741641505969, "episode": 20.0, "batch_reward": 0.2445311006307602, "critic_loss": 0.24919386219978332, "actor_loss": -35.22314269638061, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.030479192733765, "step": 20000}
{"episode_reward": 390.42443596543063, "episode": 21.0, "batch_reward": 0.2509094029515982, "critic_loss": 0.25054289957880976, "actor_loss": -35.67561602783203, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.41453838348389, "step": 21000}
{"episode_reward": 388.0772874300489, "episode": 22.0, "batch_reward": 0.26013602162897587, "critic_loss": 0.2472661977559328, "actor_loss": -35.86386418914795, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.36966633796692, "step": 22000}
{"episode_reward": 406.2315405009964, "episode": 23.0, "batch_reward": 0.26571134534478186, "critic_loss": 0.2456015595421195, "actor_loss": -36.07428718948364, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.609169960021973, "step": 23000}
{"episode_reward": 396.20610743024645, "episode": 24.0, "batch_reward": 0.2708221775740385, "critic_loss": 0.23854879030585288, "actor_loss": -36.74627337646484, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.78546404838562, "step": 24000}
{"episode_reward": 434.48994653802094, "episode": 25.0, "batch_reward": 0.27608279091119764, "critic_loss": 0.2320572895631194, "actor_loss": -36.63584893035889, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.875813722610474, "step": 25000}
{"episode_reward": 374.1011663640992, "episode": 26.0, "batch_reward": 0.28124379163980484, "critic_loss": 0.2505749423056841, "actor_loss": -36.97172897338867, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.22242784500122, "step": 26000}
{"episode_reward": 439.1510491900004, "episode": 27.0, "batch_reward": 0.28907578663527966, "critic_loss": 0.23655663616210224, "actor_loss": -37.698963367462156, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.026196002960205, "step": 27000}
{"episode_reward": 461.67182997629914, "episode": 28.0, "batch_reward": 0.2952198697179556, "critic_loss": 0.23015886548906564, "actor_loss": -37.617497726440426, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.924647331237793, "step": 28000}
{"episode_reward": 447.8524096741568, "episode": 29.0, "batch_reward": 0.30013403932750227, "critic_loss": 0.22661561005562544, "actor_loss": -38.327757766723636, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.226763486862183, "step": 29000}
{"episode_reward": 417.8012144104561, "episode": 30.0, "batch_reward": 0.3044419347941875, "critic_loss": 0.2178554442897439, "actor_loss": -38.33507487869263, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.040459394454956, "step": 30000}
{"episode_reward": 437.88395213639126, "episode": 31.0, "batch_reward": 0.308211814314127, "critic_loss": 0.2015836374461651, "actor_loss": -38.77378363037109, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.097487449645996, "step": 31000}
{"episode_reward": 469.36891639215327, "episode": 32.0, "batch_reward": 0.31284044566750524, "critic_loss": 0.20214849188178777, "actor_loss": -39.180894470214845, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.203563690185547, "step": 32000}
{"episode_reward": 407.49348165625014, "episode": 33.0, "batch_reward": 0.31558618852496145, "critic_loss": 0.2108297523111105, "actor_loss": -39.42387641143799, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.14436626434326, "step": 33000}
{"episode_reward": 275.4038732122654, "episode": 34.0, "batch_reward": 0.3143586036860943, "critic_loss": 0.1990787264034152, "actor_loss": -38.332587547302246, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.795913696289062, "step": 34000}
{"episode_reward": 459.33308958774285, "episode": 35.0, "batch_reward": 0.3200761828124523, "critic_loss": 0.21396938879042865, "actor_loss": -39.56888569259644, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.882900714874268, "step": 35000}
{"episode_reward": 456.81000998448775, "episode": 36.0, "batch_reward": 0.3218474209904671, "critic_loss": 0.21479544657468796, "actor_loss": -38.71405619430542, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.706453561782837, "step": 36000}
{"episode_reward": 453.27282273690923, "episode": 37.0, "batch_reward": 0.3264716769754887, "critic_loss": 0.22217171758413315, "actor_loss": -39.255146606445315, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.85249161720276, "step": 37000}
{"episode_reward": 492.94348901889776, "episode": 38.0, "batch_reward": 0.33158499097824096, "critic_loss": 0.2211508680805564, "actor_loss": -39.76909078979492, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.217101335525513, "step": 38000}
{"episode_reward": 477.27882587909164, "episode": 39.0, "batch_reward": 0.3312873158454895, "critic_loss": 0.22990779040008782, "actor_loss": -40.19429177093506, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.290430068969727, "step": 39000}
{"episode_reward": 98.8641192682707, "episode": 40.0, "batch_reward": 0.3280090124607086, "critic_loss": 0.23913688311725856, "actor_loss": -39.7707311668396, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.221211433410645, "step": 40000}
{"episode_reward": 418.2203052439772, "episode": 41.0, "batch_reward": 0.33182487899065016, "critic_loss": 0.25973595982789993, "actor_loss": -39.99635761642456, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 36.733131885528564, "step": 41000}
{"episode_reward": 450.55749253035145, "episode": 42.0, "batch_reward": 0.33494550159573555, "critic_loss": 0.26350134510546924, "actor_loss": -39.798749122619625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.208757400512695, "step": 42000}
{"episode_reward": 484.0000840110274, "episode": 43.0, "batch_reward": 0.3380925752520561, "critic_loss": 0.26490100276470185, "actor_loss": -40.15264715194702, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.923285961151123, "step": 43000}
{"episode_reward": 462.07133794459963, "episode": 44.0, "batch_reward": 0.3402963011562824, "critic_loss": 0.2493178904801607, "actor_loss": -39.82008260345459, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.846124172210693, "step": 44000}
{"episode_reward": 473.14553102863124, "episode": 45.0, "batch_reward": 0.34365112060308456, "critic_loss": 0.2589945930168033, "actor_loss": -40.89795827484131, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.972442626953125, "step": 45000}
{"episode_reward": 475.13114161524476, "episode": 46.0, "batch_reward": 0.3455086693763733, "critic_loss": 0.25765526678413153, "actor_loss": -40.60550156784058, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.655096292495728, "step": 46000}
{"episode_reward": 447.07455628540976, "episode": 47.0, "batch_reward": 0.3492712630033493, "critic_loss": 0.2729617272913456, "actor_loss": -40.820161148071286, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.87773084640503, "step": 47000}
{"episode_reward": 483.0989081905972, "episode": 48.0, "batch_reward": 0.35168849992752077, "critic_loss": 0.25851759520918133, "actor_loss": -40.58210229110718, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.55355715751648, "step": 48000}
{"episode_reward": 490.51962439914, "episode": 49.0, "batch_reward": 0.35433669888973235, "critic_loss": 0.255002757884562, "actor_loss": -41.517156425476074, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.974385261535645, "step": 49000}
{"episode_reward": 442.2458797211642, "episode": 50.0, "batch_reward": 0.3556357883512974, "critic_loss": 0.2665548124536872, "actor_loss": -41.30500074386597, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.91547989845276, "step": 50000}
{"episode_reward": 456.4896252668305, "episode": 51.0, "batch_reward": 0.35805293077230455, "critic_loss": 0.2587533772215247, "actor_loss": -41.19215647125244, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.670701026916504, "step": 51000}
{"episode_reward": 423.08159219524237, "episode": 52.0, "batch_reward": 0.35926020368933675, "critic_loss": 0.24897299817204474, "actor_loss": -42.18939387893677, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.10150408744812, "step": 52000}
{"episode_reward": 493.2417809006054, "episode": 53.0, "batch_reward": 0.361368821978569, "critic_loss": 0.2540902348831296, "actor_loss": -41.87025331115723, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.241816997528076, "step": 53000}
{"episode_reward": 454.94960905539284, "episode": 54.0, "batch_reward": 0.36332025787234307, "critic_loss": 0.2416057656109333, "actor_loss": -42.32548400878906, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.85137176513672, "step": 54000}
{"episode_reward": 448.001806216583, "episode": 55.0, "batch_reward": 0.36595347836613656, "critic_loss": 0.23665287923067807, "actor_loss": -42.119810745239256, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.69548988342285, "step": 55000}
{"episode_reward": 456.9354488560538, "episode": 56.0, "batch_reward": 0.3669707795381546, "critic_loss": 0.23344976256787778, "actor_loss": -42.772139190673826, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.026055574417114, "step": 56000}
{"episode_reward": 453.427785777802, "episode": 57.0, "batch_reward": 0.36935549581050875, "critic_loss": 0.2480949203595519, "actor_loss": -42.530138996124265, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.82064127922058, "step": 57000}
{"episode_reward": 480.97824802782486, "episode": 58.0, "batch_reward": 0.3701121483445168, "critic_loss": 0.23363384050130845, "actor_loss": -42.17125804519653, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.45805788040161, "step": 58000}
{"episode_reward": 491.7895732159876, "episode": 59.0, "batch_reward": 0.3729990977346897, "critic_loss": 0.23183171854913234, "actor_loss": -42.511063808441165, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.114251375198364, "step": 59000}
{"episode_reward": 475.31266947623044, "episode": 60.0, "batch_reward": 0.3743391549885273, "critic_loss": 0.22202477068454027, "actor_loss": -43.08159659194946, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.954519033432007, "step": 60000}
{"episode_reward": 472.48625080946573, "episode": 61.0, "batch_reward": 0.37525872051715853, "critic_loss": 0.24799015664309262, "actor_loss": -42.99197089767456, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.37214112281799, "step": 61000}
{"episode_reward": 397.7808896085334, "episode": 62.0, "batch_reward": 0.375824017137289, "critic_loss": 0.2535201422944665, "actor_loss": -42.80168106842041, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.89890146255493, "step": 62000}
{"episode_reward": 468.3445201680031, "episode": 63.0, "batch_reward": 0.37719381535053254, "critic_loss": 0.22823722352087497, "actor_loss": -42.79872702026367, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.805562734603882, "step": 63000}
{"episode_reward": 489.05260887277757, "episode": 64.0, "batch_reward": 0.37889408659935, "critic_loss": 0.2302433538362384, "actor_loss": -43.15949893188476, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.482407093048096, "step": 64000}
{"episode_reward": 465.68384752611536, "episode": 65.0, "batch_reward": 0.3805372667014599, "critic_loss": 0.23129848359525204, "actor_loss": -43.18574193191528, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.180719137191772, "step": 65000}
{"episode_reward": 471.9179127678141, "episode": 66.0, "batch_reward": 0.3818905375301838, "critic_loss": 0.2239446384087205, "actor_loss": -43.588306640625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.38429832458496, "step": 66000}
{"episode_reward": 454.2515455503221, "episode": 67.0, "batch_reward": 0.3819020591080189, "critic_loss": 0.2252690456882119, "actor_loss": -44.20833982849121, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.842808485031128, "step": 67000}
{"episode_reward": 424.22447786302286, "episode": 68.0, "batch_reward": 0.38380912637710574, "critic_loss": 0.24517894996702672, "actor_loss": -43.37123515319824, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.304872512817383, "step": 68000}
{"episode_reward": 496.9450667668344, "episode": 69.0, "batch_reward": 0.3845023487210274, "critic_loss": 0.22807048580050468, "actor_loss": -43.83692239379883, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.237837314605713, "step": 69000}
{"episode_reward": 481.8461974349638, "episode": 70.0, "batch_reward": 0.38645296421647074, "critic_loss": 0.22485761538892984, "actor_loss": -44.27310678100586, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.822482585906982, "step": 70000}
{"episode_reward": 448.90588733196296, "episode": 71.0, "batch_reward": 0.3873346820771694, "critic_loss": 0.2202374107092619, "actor_loss": -43.668486400604245, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.50174832344055, "step": 71000}
{"episode_reward": 487.1082570029174, "episode": 72.0, "batch_reward": 0.3896096828877926, "critic_loss": 0.23916740997880698, "actor_loss": -44.011205604553226, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.68456721305847, "step": 72000}
{"episode_reward": 482.69275295815146, "episode": 73.0, "batch_reward": 0.3896932241618633, "critic_loss": 0.2449334991797805, "actor_loss": -43.84966443634033, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.842342138290405, "step": 73000}
{"episode_reward": 491.6369278926908, "episode": 74.0, "batch_reward": 0.3924034264087677, "critic_loss": 0.21738116013258696, "actor_loss": -44.65168454360962, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.60219645500183, "step": 74000}
{"episode_reward": 472.71563112608584, "episode": 75.0, "batch_reward": 0.39294037118554115, "critic_loss": 0.22626353231072427, "actor_loss": -44.74056135940552, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.771463871002197, "step": 75000}
{"episode_reward": 486.9191399016743, "episode": 76.0, "batch_reward": 0.3946525647342205, "critic_loss": 0.22151793816685678, "actor_loss": -44.65552897262573, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.823837757110596, "step": 76000}
{"episode_reward": 490.5255176768286, "episode": 77.0, "batch_reward": 0.39426274186372756, "critic_loss": 0.21610108236968517, "actor_loss": -44.5453669128418, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 19.95047879219055, "step": 77000}
{"episode_reward": 453.0725264884282, "episode": 78.0, "batch_reward": 0.39660520023107526, "critic_loss": 0.22881549710780383, "actor_loss": -44.920388793945314, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.479105472564697, "step": 78000}
{"episode_reward": 481.79299453658666, "episode": 79.0, "batch_reward": 0.3973108836710453, "critic_loss": 0.22766256369650364, "actor_loss": -43.886477478027345, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.105048418045044, "step": 79000}
{"episode_reward": 460.33597675777287, "episode": 80.0, "batch_reward": 0.39790372651815414, "critic_loss": 0.22892354756593705, "actor_loss": -44.59054876708984, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.115774393081665, "step": 80000}
{"episode_reward": 477.75175066469563, "episode": 81.0, "batch_reward": 0.399676170527935, "critic_loss": 0.21290096800774336, "actor_loss": -44.816829181671146, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.77049922943115, "step": 81000}
{"episode_reward": 474.8537292948217, "episode": 82.0, "batch_reward": 0.40053633257746696, "critic_loss": 0.2455918586999178, "actor_loss": -45.68998847961426, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.31023645401001, "step": 82000}
{"episode_reward": 476.7015208558703, "episode": 83.0, "batch_reward": 0.4011204782128334, "critic_loss": 0.22596407955884934, "actor_loss": -44.83605999755859, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.383466720581055, "step": 83000}
{"episode_reward": 465.47406132208914, "episode": 84.0, "batch_reward": 0.40216792181134225, "critic_loss": 0.23629345536977053, "actor_loss": -45.598626037597654, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.440002918243408, "step": 84000}
{"episode_reward": 455.4130963679658, "episode": 85.0, "batch_reward": 0.4009676843583584, "critic_loss": 0.2219565242752433, "actor_loss": -45.3933020324707, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.417505741119385, "step": 85000}
{"episode_reward": 256.36303889198, "episode": 86.0, "batch_reward": 0.3999547017812729, "critic_loss": 0.24733272501081227, "actor_loss": -44.4216849861145, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.8211932182312, "step": 86000}
{"episode_reward": 464.74539329955144, "episode": 87.0, "batch_reward": 0.4012084969878197, "critic_loss": 0.24175821894407273, "actor_loss": -45.139205646514895, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.842939376831055, "step": 87000}
{"episode_reward": 454.61470288446844, "episode": 88.0, "batch_reward": 0.40164542934298514, "critic_loss": 0.25601024586707355, "actor_loss": -44.85023597717285, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.285510301589966, "step": 88000}
{"episode_reward": 444.7897682966466, "episode": 89.0, "batch_reward": 0.40237021550536156, "critic_loss": 0.24894521889090537, "actor_loss": -45.19057884979248, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.421059370040894, "step": 89000}
{"episode_reward": 478.59219037525276, "episode": 90.0, "batch_reward": 0.40257155951857565, "critic_loss": 0.259269392542541, "actor_loss": -45.41597031402588, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.131840229034424, "step": 90000}
{"episode_reward": 283.2359700602384, "episode": 91.0, "batch_reward": 0.4019465362429619, "critic_loss": 0.2904504982307553, "actor_loss": -44.77028849029541, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.8332896232605, "step": 91000}
{"episode_reward": 498.13682541041794, "episode": 92.0, "batch_reward": 0.4034631116986275, "critic_loss": 0.2653116312772036, "actor_loss": -45.105497047424315, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.540995836257935, "step": 92000}
{"episode_reward": 463.6554971869867, "episode": 93.0, "batch_reward": 0.4032726350724697, "critic_loss": 0.2718172828257084, "actor_loss": -45.04660022735596, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.136886596679688, "step": 93000}
{"episode_reward": 483.81003487657864, "episode": 94.0, "batch_reward": 0.4041919539868832, "critic_loss": 0.27703623559325935, "actor_loss": -45.216330139160156, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.189754247665405, "step": 94000}
{"episode_reward": 460.4785799240745, "episode": 95.0, "batch_reward": 0.4046770841181278, "critic_loss": 0.27109796583652496, "actor_loss": -45.646756729125975, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.8548686504364, "step": 95000}
{"episode_reward": 474.83463110169964, "episode": 96.0, "batch_reward": 0.40522341898083686, "critic_loss": 0.2664953458532691, "actor_loss": -45.48640490341187, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.455419540405273, "step": 96000}
{"episode_reward": 488.6896088499719, "episode": 97.0, "batch_reward": 0.4064601947963238, "critic_loss": 0.24320163475722076, "actor_loss": -45.79220629119873, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.624258279800415, "step": 97000}
{"episode_reward": 491.70691574532094, "episode": 98.0, "batch_reward": 0.40750823628902433, "critic_loss": 0.2528205042630434, "actor_loss": -45.399390869140625, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.119059324264526, "step": 98000}
{"episode_reward": 501.1441278731011, "episode": 99.0, "batch_reward": 0.4082499358654022, "critic_loss": 0.24171230007708072, "actor_loss": -45.647515670776365, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.822073221206665, "step": 99000}
{"episode_reward": 476.8800328399036, "episode": 100.0, "batch_reward": 0.4098218822479248, "critic_loss": 0.24723963360488416, "actor_loss": -45.43525482940674, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.63698935508728, "step": 100000}
{"episode_reward": 468.65397356644826, "episode": 101.0, "batch_reward": 0.41010026109218595, "critic_loss": 0.24767986860871316, "actor_loss": -45.85821461486817, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.88428568840027, "step": 101000}
{"episode_reward": 493.0811669457057, "episode": 102.0, "batch_reward": 0.4106689382791519, "critic_loss": 0.23878921158611774, "actor_loss": -45.68317540740967, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.342777013778687, "step": 102000}
{"episode_reward": 489.8484527880837, "episode": 103.0, "batch_reward": 0.4105160922110081, "critic_loss": 0.24692159543931486, "actor_loss": -45.66906520843506, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.674144744873047, "step": 103000}
{"episode_reward": 474.20843011097793, "episode": 104.0, "batch_reward": 0.4123249228596687, "critic_loss": 0.2516293632909656, "actor_loss": -45.851064292907715, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.10947036743164, "step": 104000}
{"episode_reward": 481.4689447928916, "episode": 105.0, "batch_reward": 0.4135890329182148, "critic_loss": 0.23915527135133743, "actor_loss": -45.907294647216794, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.90354824066162, "step": 105000}
{"episode_reward": 476.2999664637532, "episode": 106.0, "batch_reward": 0.41279545992612837, "critic_loss": 0.235291183963418, "actor_loss": -45.67164556884766, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.709054470062256, "step": 106000}
{"episode_reward": 479.82097266750725, "episode": 107.0, "batch_reward": 0.4137322433888912, "critic_loss": 0.23746737133711576, "actor_loss": -45.71735033416748, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.94931125640869, "step": 107000}
{"episode_reward": 501.1873476468141, "episode": 108.0, "batch_reward": 0.4153826319873333, "critic_loss": 0.25975997215509417, "actor_loss": -45.97578847503662, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.392651319503784, "step": 108000}
{"episode_reward": 480.3187150856435, "episode": 109.0, "batch_reward": 0.415545376598835, "critic_loss": 0.2600746401324868, "actor_loss": -46.40441548919678, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.960720777511597, "step": 109000}
{"episode_reward": 473.3937931663534, "episode": 110.0, "batch_reward": 0.4158706206083298, "critic_loss": 0.2518754209131002, "actor_loss": -46.17826551055908, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.613362073898315, "step": 110000}
{"episode_reward": 481.35793979067654, "episode": 111.0, "batch_reward": 0.41618067294359207, "critic_loss": 0.24139817787706852, "actor_loss": -46.5491030960083, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.69739627838135, "step": 111000}
{"episode_reward": 346.8671977739816, "episode": 112.0, "batch_reward": 0.4162946999669075, "critic_loss": 0.23865776880085468, "actor_loss": -46.14244089508057, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.608417510986328, "step": 112000}
{"episode_reward": 491.84309102994774, "episode": 113.0, "batch_reward": 0.41665869930386545, "critic_loss": 0.24886725303530693, "actor_loss": -45.90665956878662, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.600399017333984, "step": 113000}
{"episode_reward": 505.1871344681691, "episode": 114.0, "batch_reward": 0.4174166261851788, "critic_loss": 0.27383978370577094, "actor_loss": -46.95584804534912, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.443848371505737, "step": 114000}
{"episode_reward": 472.0977020625295, "episode": 115.0, "batch_reward": 0.41753492653369906, "critic_loss": 0.2608790044039488, "actor_loss": -46.42810425567627, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.48604989051819, "step": 115000}
{"episode_reward": 414.29791322533424, "episode": 116.0, "batch_reward": 0.41790123099088666, "critic_loss": 0.25980131611973045, "actor_loss": -46.88277555847168, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.73801565170288, "step": 116000}
{"episode_reward": 489.0881735064626, "episode": 117.0, "batch_reward": 0.41835804492235185, "critic_loss": 0.2596138148754835, "actor_loss": -46.046776023864744, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.958449125289917, "step": 117000}
{"episode_reward": 481.4372160801051, "episode": 118.0, "batch_reward": 0.41847420400381086, "critic_loss": 0.25552842478454113, "actor_loss": -46.74186483001709, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.309886932373047, "step": 118000}
{"episode_reward": 503.5331518148253, "episode": 119.0, "batch_reward": 0.419703526198864, "critic_loss": 0.2383226767256856, "actor_loss": -46.91356258392334, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.933481216430664, "step": 119000}
{"episode_reward": 472.4841159656591, "episode": 120.0, "batch_reward": 0.4187507044672966, "critic_loss": 0.24680244953930378, "actor_loss": -46.449806114196775, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.66027331352234, "step": 120000}
{"episode_reward": 509.9432432818443, "episode": 121.0, "batch_reward": 0.4210902663767338, "critic_loss": 0.25818257350474594, "actor_loss": -46.655551330566404, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.185161113739014, "step": 121000}
{"episode_reward": 485.2878214411097, "episode": 122.0, "batch_reward": 0.42126034811139107, "critic_loss": 0.2696842954233289, "actor_loss": -46.75852172088623, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.355602741241455, "step": 122000}
{"episode_reward": 475.99626916277884, "episode": 123.0, "batch_reward": 0.4224407071769237, "critic_loss": 0.27328956251591446, "actor_loss": -46.04807776641846, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.751261949539185, "step": 123000}
{"episode_reward": 496.72834572716476, "episode": 124.0, "batch_reward": 0.4222171732485294, "critic_loss": 0.2516032024100423, "actor_loss": -46.81444947052002, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.031652688980103, "step": 124000}
{"episode_reward": 499.00495630036124, "episode": 125.0, "batch_reward": 0.42329034399986265, "critic_loss": 0.27193231440335514, "actor_loss": -46.661561653137205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.897818088531494, "step": 125000}
{"episode_reward": 496.7094444762211, "episode": 126.0, "batch_reward": 0.4228728531897068, "critic_loss": 0.2674590832814574, "actor_loss": -47.08187917327881, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.965659618377686, "step": 126000}
{"episode_reward": 483.0023004557836, "episode": 127.0, "batch_reward": 0.42386425685882567, "critic_loss": 0.2975599720850587, "actor_loss": -46.906459548950195, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.66640615463257, "step": 127000}
{"episode_reward": 502.3123863952589, "episode": 128.0, "batch_reward": 0.4245818542838097, "critic_loss": 0.25739681667089465, "actor_loss": -47.09065473175049, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.833154678344727, "step": 128000}
{"episode_reward": 508.3480833593361, "episode": 129.0, "batch_reward": 0.4248932205140591, "critic_loss": 0.26176002534478904, "actor_loss": -47.372750984191896, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.461299180984497, "step": 129000}
{"episode_reward": 511.35117737163455, "episode": 130.0, "batch_reward": 0.4265566792488098, "critic_loss": 0.23546310272067786, "actor_loss": -47.49761468505859, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.616451740264893, "step": 130000}
{"episode_reward": 497.5004237151423, "episode": 131.0, "batch_reward": 0.42633490443229677, "critic_loss": 0.2631642916202545, "actor_loss": -47.46927111816406, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.15279197692871, "step": 131000}
{"episode_reward": 442.352044943659, "episode": 132.0, "batch_reward": 0.42719690430164337, "critic_loss": 0.24826251393556595, "actor_loss": -47.52408935546875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.715160846710205, "step": 132000}
{"episode_reward": 488.0878401745426, "episode": 133.0, "batch_reward": 0.4270496779084206, "critic_loss": 0.23723379438370465, "actor_loss": -47.2412002029419, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.693708896636963, "step": 133000}
{"episode_reward": 510.6018013851535, "episode": 134.0, "batch_reward": 0.42735640504956246, "critic_loss": 0.252825965590775, "actor_loss": -47.596922355651856, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.320979118347168, "step": 134000}
{"episode_reward": 460.88329563516066, "episode": 135.0, "batch_reward": 0.4278084295392036, "critic_loss": 0.24356901851296425, "actor_loss": -47.64466641998291, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.23856544494629, "step": 135000}
{"episode_reward": 445.723004799586, "episode": 136.0, "batch_reward": 0.4279634897112846, "critic_loss": 0.24630740901082754, "actor_loss": -47.84304793548584, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.690590381622314, "step": 136000}
{"episode_reward": 489.5817408536072, "episode": 137.0, "batch_reward": 0.42885470667481423, "critic_loss": 0.2491549886390567, "actor_loss": -47.576481338500976, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.68077802658081, "step": 137000}
{"episode_reward": 496.29350967824786, "episode": 138.0, "batch_reward": 0.4297906156480312, "critic_loss": 0.24939215380698443, "actor_loss": -47.08420796203613, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.36543297767639, "step": 138000}
{"episode_reward": 501.42344986100863, "episode": 139.0, "batch_reward": 0.4297102970480919, "critic_loss": 0.23704375620931387, "actor_loss": -47.27936364746094, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.869280099868774, "step": 139000}
{"episode_reward": 503.66882851054726, "episode": 140.0, "batch_reward": 0.4303723495900631, "critic_loss": 0.2478889097198844, "actor_loss": -47.252082778930664, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.81733274459839, "step": 140000}
{"episode_reward": 484.7611364080218, "episode": 141.0, "batch_reward": 0.43028645715117453, "critic_loss": 0.2611507635861635, "actor_loss": -47.00343016052246, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 38.41599631309509, "step": 141000}
{"episode_reward": 512.3313049208872, "episode": 142.0, "batch_reward": 0.4314090496003628, "critic_loss": 0.22700521655380726, "actor_loss": -47.5518950805664, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.576013326644897, "step": 142000}
{"episode_reward": 493.47229448486434, "episode": 143.0, "batch_reward": 0.4320477175116539, "critic_loss": 0.2294520509764552, "actor_loss": -47.53005084991455, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.728164672851562, "step": 143000}
{"episode_reward": 501.5945762428402, "episode": 144.0, "batch_reward": 0.4316169836819172, "critic_loss": 0.21790918304771184, "actor_loss": -47.884241333007814, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.422897338867188, "step": 144000}
{"episode_reward": 465.8489545418319, "episode": 145.0, "batch_reward": 0.43218470087647437, "critic_loss": 0.22128662549704314, "actor_loss": -47.417831382751466, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.76798725128174, "step": 145000}
{"episode_reward": 496.1999402208145, "episode": 146.0, "batch_reward": 0.4322972459197044, "critic_loss": 0.21956463296711445, "actor_loss": -47.62791352081299, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.60947036743164, "step": 146000}
{"episode_reward": 483.60029090488007, "episode": 147.0, "batch_reward": 0.4330407322347164, "critic_loss": 0.22069964830577374, "actor_loss": -48.01079548645019, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.082608222961426, "step": 147000}
{"episode_reward": 480.05596161988757, "episode": 148.0, "batch_reward": 0.43405994322896, "critic_loss": 0.22082831259071828, "actor_loss": -47.66954640960693, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.428879499435425, "step": 148000}
{"episode_reward": 493.94020492732466, "episode": 149.0, "batch_reward": 0.43365621224045753, "critic_loss": 0.2304480773806572, "actor_loss": -47.60941345214844, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.90869140625, "step": 149000}
{"episode_reward": 469.2237414751363, "episode": 150.0, "batch_reward": 0.43398084107041357, "critic_loss": 0.21834905740618707, "actor_loss": -47.972106735229495, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
