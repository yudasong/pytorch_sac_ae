{"episode_reward": 0.0, "episode": 1.0, "duration": 19.580390453338623, "step": 1000}
{"episode_reward": 5.1931688606333894, "episode": 2.0, "duration": 1.5301203727722168, "step": 2000}
{"episode_reward": 454.7514538707513, "episode": 3.0, "batch_reward": 0.21841909440508203, "critic_loss": 0.0403582495759903, "actor_loss": -18.360296968235954, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 67.83033919334412, "step": 3000}
{"episode_reward": 32.27845197994263, "episode": 4.0, "batch_reward": 0.14400769767910243, "critic_loss": 0.027719911815598606, "actor_loss": -18.755693165302276, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.163042068481445, "step": 4000}
{"episode_reward": 9.352836451741537, "episode": 5.0, "batch_reward": 0.11225343662872911, "critic_loss": 0.0220373420631513, "actor_loss": -14.140374169260264, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.544829845428467, "step": 5000}
{"episode_reward": 8.983433616129467, "episode": 6.0, "batch_reward": 0.09312262592464686, "critic_loss": 0.026727712233550846, "actor_loss": -15.404105856508016, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.520479202270508, "step": 6000}
{"episode_reward": 7.811461300083946, "episode": 7.0, "batch_reward": 0.08004093708842992, "critic_loss": 0.026058797930832954, "actor_loss": -15.452118120506405, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.088674068450928, "step": 7000}
{"episode_reward": 8.54224786800082, "episode": 8.0, "batch_reward": 0.0715923486687243, "critic_loss": 0.026167487667873503, "actor_loss": -14.38085572527349, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.012722969055176, "step": 8000}
{"episode_reward": 14.772075014395913, "episode": 9.0, "batch_reward": 0.07166574488580227, "critic_loss": 0.07338702107034624, "actor_loss": -16.20158263333142, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.970584392547607, "step": 9000}
{"episode_reward": 112.38664852041597, "episode": 10.0, "batch_reward": 0.07678922149911523, "critic_loss": 0.10006776315718889, "actor_loss": -15.746797698497772, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.110060453414917, "step": 10000}
{"episode_reward": 149.3571760706286, "episode": 11.0, "batch_reward": 0.07892677756771445, "critic_loss": 0.11897486085817217, "actor_loss": -16.223082740783692, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.877112865448, "step": 11000}
{"episode_reward": 26.13713128011736, "episode": 12.0, "batch_reward": 0.07971653919667006, "critic_loss": 0.12044732020050287, "actor_loss": -16.33661676645279, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.878975868225098, "step": 12000}
{"episode_reward": 160.32191008373306, "episode": 13.0, "batch_reward": 0.08672396967560053, "critic_loss": 0.15691277547180651, "actor_loss": -16.810951406002044, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.37934374809265, "step": 13000}
{"episode_reward": 125.70806608421981, "episode": 14.0, "batch_reward": 0.08952477635070681, "critic_loss": 0.18464219045639038, "actor_loss": -16.00516591358185, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.593689441680908, "step": 14000}
{"episode_reward": 138.05900466263407, "episode": 15.0, "batch_reward": 0.08852075632661581, "critic_loss": 0.1786821342371404, "actor_loss": -17.940808386802672, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.076361894607544, "step": 15000}
{"episode_reward": 36.46479006470513, "episode": 16.0, "batch_reward": 0.08425457342714071, "critic_loss": 0.18060687951743604, "actor_loss": -17.560771757125856, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.64759087562561, "step": 16000}
{"episode_reward": 28.576313604954628, "episode": 17.0, "batch_reward": 0.08145606178045273, "critic_loss": 0.18624775405973196, "actor_loss": -16.03802000331879, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.013125896453857, "step": 17000}
{"episode_reward": 31.763204271485726, "episode": 18.0, "batch_reward": 0.08036045935750008, "critic_loss": 0.2241450861096382, "actor_loss": -15.974166589736939, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.705702781677246, "step": 18000}
{"episode_reward": 57.99000836880031, "episode": 19.0, "batch_reward": 0.0798385007493198, "critic_loss": 0.22656241578608752, "actor_loss": -16.859015906333923, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.20072102546692, "step": 19000}
{"episode_reward": 86.7483570906354, "episode": 20.0, "batch_reward": 0.08093190252035856, "critic_loss": 0.24438135363161564, "actor_loss": -17.148261549949645, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.087401866912842, "step": 20000}
{"episode_reward": 120.88853898412393, "episode": 21.0, "batch_reward": 0.08270302268117666, "critic_loss": 0.2621575099751353, "actor_loss": -17.331333278656007, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.675052642822266, "step": 21000}
{"episode_reward": 87.14300838806221, "episode": 22.0, "batch_reward": 0.08125313705205918, "critic_loss": 0.2919490312561393, "actor_loss": -16.815785383224487, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.49869155883789, "step": 22000}
{"episode_reward": 49.973215149322144, "episode": 23.0, "batch_reward": 0.0819932906292379, "critic_loss": 0.23824773230403662, "actor_loss": -16.04551029109955, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.84806752204895, "step": 23000}
{"episode_reward": 93.78402889341132, "episode": 24.0, "batch_reward": 0.08070485575869679, "critic_loss": 0.2665710787847638, "actor_loss": -16.715836499214173, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.857621669769287, "step": 24000}
{"episode_reward": 77.38725452364521, "episode": 25.0, "batch_reward": 0.08044859596714378, "critic_loss": 0.23836679569631816, "actor_loss": -16.02434614944458, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.934566020965576, "step": 25000}
{"episode_reward": 53.3230983085659, "episode": 26.0, "batch_reward": 0.07891905623301863, "critic_loss": 0.2935668634623289, "actor_loss": -16.186833611488343, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.5634663105011, "step": 26000}
{"episode_reward": 45.46972126262108, "episode": 27.0, "batch_reward": 0.07861394647881388, "critic_loss": 0.2805669957175851, "actor_loss": -16.07194832420349, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.47284245491028, "step": 27000}
{"episode_reward": 65.41715545240561, "episode": 28.0, "batch_reward": 0.07740770642086864, "critic_loss": 0.2699407805129886, "actor_loss": -15.744758636474609, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.392503023147583, "step": 28000}
{"episode_reward": 59.922667580213606, "episode": 29.0, "batch_reward": 0.07917573758214712, "critic_loss": 0.324614585518837, "actor_loss": -16.192901149749755, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.27314591407776, "step": 29000}
{"episode_reward": 134.80049458933735, "episode": 30.0, "batch_reward": 0.0796940572373569, "critic_loss": 0.33279425482451913, "actor_loss": -15.873007616043092, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.30032181739807, "step": 30000}
{"episode_reward": 88.1685023922531, "episode": 31.0, "batch_reward": 0.08107123808190227, "critic_loss": 0.3174061142131686, "actor_loss": -15.968668926239014, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.648483753204346, "step": 31000}
{"episode_reward": 130.43799861814162, "episode": 32.0, "batch_reward": 0.08441079162806273, "critic_loss": 0.3497781267911196, "actor_loss": -16.926714767456055, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.580196142196655, "step": 32000}
{"episode_reward": 325.9837887580138, "episode": 33.0, "batch_reward": 0.0900476577207446, "critic_loss": 0.3226698108315468, "actor_loss": -17.281079835891724, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.63521122932434, "step": 33000}
{"episode_reward": 110.34366642236554, "episode": 34.0, "batch_reward": 0.08848065426200628, "critic_loss": 0.4532534660995007, "actor_loss": -16.40793960762024, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.48886513710022, "step": 34000}
{"episode_reward": 76.85338417021974, "episode": 35.0, "batch_reward": 0.08965182544663548, "critic_loss": 0.6264801503866911, "actor_loss": -17.796348680496216, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.626646995544434, "step": 35000}
{"episode_reward": 128.38827480063674, "episode": 36.0, "batch_reward": 0.09039539440348744, "critic_loss": 0.8707228640019894, "actor_loss": -18.31842236709595, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.7384991645813, "step": 36000}
{"episode_reward": 158.7897455942983, "episode": 37.0, "batch_reward": 0.0929737781099975, "critic_loss": 0.9643070445358753, "actor_loss": -18.786131061553956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.637094736099243, "step": 37000}
{"episode_reward": 251.5057139915226, "episode": 38.0, "batch_reward": 0.09887880083918571, "critic_loss": 0.8625473566651344, "actor_loss": -19.68236944961548, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.244659900665283, "step": 38000}
{"episode_reward": 304.59798584788945, "episode": 39.0, "batch_reward": 0.10219000692665577, "critic_loss": 0.8095137671530247, "actor_loss": -21.194145751953126, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.068902015686035, "step": 39000}
{"episode_reward": 109.63027101002147, "episode": 40.0, "batch_reward": 0.10195028037577868, "critic_loss": 0.7716701828837395, "actor_loss": -21.530839712142946, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.347126960754395, "step": 40000}
{"episode_reward": 70.86639727594842, "episode": 41.0, "batch_reward": 0.10128932646661996, "critic_loss": 0.804720624089241, "actor_loss": -21.912498552322386, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.32766318321228, "step": 41000}
{"episode_reward": 61.39553669488673, "episode": 42.0, "batch_reward": 0.1026102882400155, "critic_loss": 0.8835677688419818, "actor_loss": -22.670409282684325, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.721563577651978, "step": 42000}
{"episode_reward": 345.6035256256158, "episode": 43.0, "batch_reward": 0.10752382498979568, "critic_loss": 0.7725491392910481, "actor_loss": -23.64868598937988, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.191442728042603, "step": 43000}
{"episode_reward": 146.93498541052085, "episode": 44.0, "batch_reward": 0.10691046176850796, "critic_loss": 0.5901777732670307, "actor_loss": -23.999224380493164, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.954676389694214, "step": 44000}
{"episode_reward": 178.06375519834768, "episode": 45.0, "batch_reward": 0.11154433008283376, "critic_loss": 0.4813334890604019, "actor_loss": -24.689253704071046, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.70317316055298, "step": 45000}
{"episode_reward": 343.83949237201136, "episode": 46.0, "batch_reward": 0.11501561000198125, "critic_loss": 0.4290333810001612, "actor_loss": -24.84461665725708, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.3440523147583, "step": 46000}
{"episode_reward": 319.01186722518474, "episode": 47.0, "batch_reward": 0.12057783358544111, "critic_loss": 0.45532334688305853, "actor_loss": -25.00248101425171, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.88075828552246, "step": 47000}
{"episode_reward": 332.2960030437466, "episode": 48.0, "batch_reward": 0.12523771780729293, "critic_loss": 0.3820384055972099, "actor_loss": -25.42567515563965, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.807060956954956, "step": 48000}
{"episode_reward": 399.23009199943317, "episode": 49.0, "batch_reward": 0.13144012112170458, "critic_loss": 0.39408232866227627, "actor_loss": -26.121612030029297, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.641486167907715, "step": 49000}
{"episode_reward": 375.7442649293204, "episode": 50.0, "batch_reward": 0.13504308123141529, "critic_loss": 0.37289557287096975, "actor_loss": -26.4316995010376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.142855167388916, "step": 50000}
{"episode_reward": 352.49350758519444, "episode": 51.0, "batch_reward": 0.14090280257165433, "critic_loss": 0.3446497142016888, "actor_loss": -26.628960975646972, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.06131315231323, "step": 51000}
{"episode_reward": 397.91319424356305, "episode": 52.0, "batch_reward": 0.1446123268082738, "critic_loss": 0.38661013534665106, "actor_loss": -27.110083614349364, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.680498600006104, "step": 52000}
{"episode_reward": 209.7384555052938, "episode": 53.0, "batch_reward": 0.14602135919779538, "critic_loss": 0.37464916444569824, "actor_loss": -26.9535001411438, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.303301572799683, "step": 53000}
{"episode_reward": 207.8146764909224, "episode": 54.0, "batch_reward": 0.14567752941697837, "critic_loss": 0.3449459204748273, "actor_loss": -26.640251964569092, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.492181301116943, "step": 54000}
{"episode_reward": 159.13385515419495, "episode": 55.0, "batch_reward": 0.14832764043658972, "critic_loss": 0.35152110950648785, "actor_loss": -26.33425122451782, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.404045343399048, "step": 55000}
{"episode_reward": 403.79559206697456, "episode": 56.0, "batch_reward": 0.15224904479831458, "critic_loss": 0.40768208660185334, "actor_loss": -26.685639072418212, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.57589602470398, "step": 56000}
{"episode_reward": 221.0783304771004, "episode": 57.0, "batch_reward": 0.15463270872086288, "critic_loss": 0.38422578321397305, "actor_loss": -26.808846393585206, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.530715465545654, "step": 57000}
{"episode_reward": 428.8690651443494, "episode": 58.0, "batch_reward": 0.15809278263896703, "critic_loss": 0.38200925981998446, "actor_loss": -26.568679790496827, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.3094642162323, "step": 58000}
{"episode_reward": 348.94847226479965, "episode": 59.0, "batch_reward": 0.16116275223344564, "critic_loss": 0.45162176275253296, "actor_loss": -26.909814121246338, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.24825382232666, "step": 59000}
{"episode_reward": 212.91961117196854, "episode": 60.0, "batch_reward": 0.16248244133591652, "critic_loss": 0.41940147218108176, "actor_loss": -27.020530570983887, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.023279190063477, "step": 60000}
{"episode_reward": 216.75902597437718, "episode": 61.0, "batch_reward": 0.16240925574302673, "critic_loss": 0.47763624219596384, "actor_loss": -26.53123403930664, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.97184228897095, "step": 61000}
{"episode_reward": 99.97061394296954, "episode": 62.0, "batch_reward": 0.1629832648411393, "critic_loss": 0.49527735623717306, "actor_loss": -26.3577822265625, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.362224102020264, "step": 62000}
{"episode_reward": 462.97560175386246, "episode": 63.0, "batch_reward": 0.167364468164742, "critic_loss": 0.43800241336226464, "actor_loss": -26.739508510589598, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.125750064849854, "step": 63000}
{"episode_reward": 490.14695830512386, "episode": 64.0, "batch_reward": 0.17227644316852092, "critic_loss": 0.44113769233226774, "actor_loss": -27.038950031280518, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.232483386993408, "step": 64000}
{"episode_reward": 412.6601566802408, "episode": 65.0, "batch_reward": 0.17611072877049447, "critic_loss": 0.41300568062067033, "actor_loss": -27.380549377441405, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.86810326576233, "step": 65000}
{"episode_reward": 468.61975831260764, "episode": 66.0, "batch_reward": 0.18134373538196086, "critic_loss": 0.40885166290402414, "actor_loss": -27.779943855285644, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.216139793395996, "step": 66000}
{"episode_reward": 412.10004797115636, "episode": 67.0, "batch_reward": 0.18347438518702983, "critic_loss": 0.397443700581789, "actor_loss": -28.369482864379883, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.7298686504364, "step": 67000}
{"episode_reward": 361.6077607421372, "episode": 68.0, "batch_reward": 0.1869624844789505, "critic_loss": 0.41030596852302553, "actor_loss": -28.17889619445801, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.098779439926147, "step": 68000}
{"episode_reward": 473.9133581459415, "episode": 69.0, "batch_reward": 0.19058063232898712, "critic_loss": 0.4256363762319088, "actor_loss": -28.827321250915528, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.35038185119629, "step": 69000}
{"episode_reward": 469.76241633606605, "episode": 70.0, "batch_reward": 0.19548636344075204, "critic_loss": 0.3930004023015499, "actor_loss": -29.276172588348388, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.698317766189575, "step": 70000}
{"episode_reward": 473.90686684770037, "episode": 71.0, "batch_reward": 0.1983706806898117, "critic_loss": 0.39990027450025084, "actor_loss": -29.12477928161621, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.80053758621216, "step": 71000}
{"episode_reward": 251.01672501548057, "episode": 72.0, "batch_reward": 0.19975051113963127, "critic_loss": 0.3770487108230591, "actor_loss": -29.31973078918457, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.261390924453735, "step": 72000}
{"episode_reward": 489.12099879050004, "episode": 73.0, "batch_reward": 0.20340964755415916, "critic_loss": 0.365332751840353, "actor_loss": -29.631497650146486, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.99040961265564, "step": 73000}
{"episode_reward": 489.0664976235842, "episode": 74.0, "batch_reward": 0.20837027509510517, "critic_loss": 0.35015238376706836, "actor_loss": -30.136668838500977, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.351024866104126, "step": 74000}
{"episode_reward": 469.3897507373954, "episode": 75.0, "batch_reward": 0.21151009555161, "critic_loss": 0.38227020782232285, "actor_loss": -30.16543102645874, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.01827335357666, "step": 75000}
{"episode_reward": 476.56407798934293, "episode": 76.0, "batch_reward": 0.21396600954234601, "critic_loss": 0.34421921300888064, "actor_loss": -30.282741020202636, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.15506935119629, "step": 76000}
{"episode_reward": 443.61357153004906, "episode": 77.0, "batch_reward": 0.21801898315548895, "critic_loss": 0.320248202227056, "actor_loss": -30.691420169830323, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.31118392944336, "step": 77000}
{"episode_reward": 518.3647781602574, "episode": 78.0, "batch_reward": 0.2223313748538494, "critic_loss": 0.3309077049344778, "actor_loss": -31.150974029541015, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.39164090156555, "step": 78000}
{"episode_reward": 490.98157384640626, "episode": 79.0, "batch_reward": 0.22427440030872822, "critic_loss": 0.32134442794322965, "actor_loss": -30.977997467041014, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.18152379989624, "step": 79000}
{"episode_reward": 451.2379552984204, "episode": 80.0, "batch_reward": 0.22877957993745804, "critic_loss": 0.3185956778600812, "actor_loss": -31.311726364135744, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.271306037902832, "step": 80000}
{"episode_reward": 503.1661788927006, "episode": 81.0, "batch_reward": 0.23267558784782885, "critic_loss": 0.3263684692382812, "actor_loss": -31.74394538497925, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.87886667251587, "step": 81000}
{"episode_reward": 481.2013936795724, "episode": 82.0, "batch_reward": 0.235366096585989, "critic_loss": 0.3172808586806059, "actor_loss": -32.04551111984253, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.63090753555298, "step": 82000}
{"episode_reward": 493.98707060299, "episode": 83.0, "batch_reward": 0.2377058079391718, "critic_loss": 0.3257915478646755, "actor_loss": -31.99940319442749, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.190625190734863, "step": 83000}
{"episode_reward": 480.7028777773534, "episode": 84.0, "batch_reward": 0.24137815436720847, "critic_loss": 0.3397125931084156, "actor_loss": -32.39588730621338, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.502102375030518, "step": 84000}
{"episode_reward": 443.3775872089153, "episode": 85.0, "batch_reward": 0.24186513823270797, "critic_loss": 0.3379363580793142, "actor_loss": -32.26024515914917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.02325439453125, "step": 85000}
{"episode_reward": 237.96271505252545, "episode": 86.0, "batch_reward": 0.24291328094899656, "critic_loss": 0.33857231712341307, "actor_loss": -32.118067512512205, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.056864738464355, "step": 86000}
{"episode_reward": 475.7413466212442, "episode": 87.0, "batch_reward": 0.24540362003445626, "critic_loss": 0.34268658576905725, "actor_loss": -32.085397369384765, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.070786714553833, "step": 87000}
{"episode_reward": 483.0902364533725, "episode": 88.0, "batch_reward": 0.2482505671530962, "critic_loss": 0.3273298280313611, "actor_loss": -32.219420120239256, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.987161874771118, "step": 88000}
{"episode_reward": 482.31243518531414, "episode": 89.0, "batch_reward": 0.2498366611748934, "critic_loss": 0.3075401246845722, "actor_loss": -32.476640617370606, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.547682523727417, "step": 89000}
{"episode_reward": 244.0660190678885, "episode": 90.0, "batch_reward": 0.25039102540910246, "critic_loss": 0.33651742374151944, "actor_loss": -32.541200466156006, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.647924423217773, "step": 90000}
{"episode_reward": 481.3937776866839, "episode": 91.0, "batch_reward": 0.2526374504864216, "critic_loss": 0.3576928547769785, "actor_loss": -32.47152769470215, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.463231325149536, "step": 91000}
{"episode_reward": 461.1472740473298, "episode": 92.0, "batch_reward": 0.2560421039313078, "critic_loss": 0.32165346696227787, "actor_loss": -32.914622356414796, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.655789375305176, "step": 92000}
{"episode_reward": 474.55370849013167, "episode": 93.0, "batch_reward": 0.25795724701881406, "critic_loss": 0.31410887696594, "actor_loss": -32.77596748352051, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.306559801101685, "step": 93000}
{"episode_reward": 499.51475842391625, "episode": 94.0, "batch_reward": 0.2604609554708004, "critic_loss": 0.2911572187691927, "actor_loss": -33.05005886077881, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.27759623527527, "step": 94000}
{"episode_reward": 471.6059788096934, "episode": 95.0, "batch_reward": 0.26323283234238626, "critic_loss": 0.29969278413802386, "actor_loss": -33.537939868927005, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.18962264060974, "step": 95000}
{"episode_reward": 474.33285842111036, "episode": 96.0, "batch_reward": 0.2641531698256731, "critic_loss": 0.2973419396132231, "actor_loss": -33.34626568603515, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.492883920669556, "step": 96000}
{"episode_reward": 452.1703337838382, "episode": 97.0, "batch_reward": 0.2670532699674368, "critic_loss": 0.33180122315883637, "actor_loss": -33.701123481750486, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.544105529785156, "step": 97000}
{"episode_reward": 501.9224276952281, "episode": 98.0, "batch_reward": 0.2696908435076475, "critic_loss": 0.3036726735904813, "actor_loss": -33.63082344055176, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.523820161819458, "step": 98000}
{"episode_reward": 494.1197066725587, "episode": 99.0, "batch_reward": 0.27171019564569, "critic_loss": 0.29286244317889215, "actor_loss": -33.77504856109619, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.349151849746704, "step": 99000}
{"episode_reward": 490.7884633436193, "episode": 100.0, "batch_reward": 0.27443760545551776, "critic_loss": 0.2822962797731161, "actor_loss": -33.70687087249756, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.681501865386963, "step": 100000}
{"episode_reward": 460.0891389110255, "episode": 101.0, "batch_reward": 0.2748292758464813, "critic_loss": 0.31516329550743105, "actor_loss": -34.178634605407716, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.398120403289795, "step": 101000}
{"episode_reward": 481.9530338739982, "episode": 102.0, "batch_reward": 0.27620371168851854, "critic_loss": 0.2901519064903259, "actor_loss": -34.26171355056763, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.4382746219635, "step": 102000}
{"episode_reward": 323.23419351196674, "episode": 103.0, "batch_reward": 0.27672907365858557, "critic_loss": 0.3075245938524604, "actor_loss": -34.2008694190979, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.037975788116455, "step": 103000}
{"episode_reward": 493.0458588422157, "episode": 104.0, "batch_reward": 0.2813345903605223, "critic_loss": 0.3078390232697129, "actor_loss": -34.34032141113281, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.659879207611084, "step": 104000}
{"episode_reward": 468.3161475640997, "episode": 105.0, "batch_reward": 0.28184684266149995, "critic_loss": 0.3248956030011177, "actor_loss": -33.99972927856445, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.792287588119507, "step": 105000}
{"episode_reward": 474.7436877278859, "episode": 106.0, "batch_reward": 0.28299705730378627, "critic_loss": 0.3461304784044623, "actor_loss": -33.908905933380126, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.89413022994995, "step": 106000}
{"episode_reward": 464.54208760526944, "episode": 107.0, "batch_reward": 0.2859491395205259, "critic_loss": 0.28211926456540826, "actor_loss": -34.65970090866089, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.670008420944214, "step": 107000}
{"episode_reward": 505.85919748266633, "episode": 108.0, "batch_reward": 0.28800958780944347, "critic_loss": 0.2743824648335576, "actor_loss": -34.954908321380614, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.102683544158936, "step": 108000}
{"episode_reward": 495.96780986846767, "episode": 109.0, "batch_reward": 0.29050845754146576, "critic_loss": 0.33252618173509835, "actor_loss": -34.94303639602661, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.37083101272583, "step": 109000}
{"episode_reward": 510.274733715434, "episode": 110.0, "batch_reward": 0.29177492010593414, "critic_loss": 0.31468441596627234, "actor_loss": -35.31010541534424, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.981985092163086, "step": 110000}
{"episode_reward": 394.84787271266555, "episode": 111.0, "batch_reward": 0.29354114596545694, "critic_loss": 0.3154668179154396, "actor_loss": -35.34155953979492, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.96136832237244, "step": 111000}
{"episode_reward": 457.383885399222, "episode": 112.0, "batch_reward": 0.29437912367284297, "critic_loss": 0.31659022799134257, "actor_loss": -35.1988769493103, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.554866313934326, "step": 112000}
{"episode_reward": 457.18885413326194, "episode": 113.0, "batch_reward": 0.29474071410298347, "critic_loss": 0.36973730646818875, "actor_loss": -35.23138751220703, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.54127788543701, "step": 113000}
{"episode_reward": 468.5509886325321, "episode": 114.0, "batch_reward": 0.296752410158515, "critic_loss": 0.32597998464852573, "actor_loss": -35.84508038330078, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.34183096885681, "step": 114000}
{"episode_reward": 496.8813420816415, "episode": 115.0, "batch_reward": 0.29901627789437774, "critic_loss": 0.31852033757418396, "actor_loss": -35.677525199890134, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.683716773986816, "step": 115000}
{"episode_reward": 462.041094627125, "episode": 116.0, "batch_reward": 0.30112358017265795, "critic_loss": 0.2932684041708708, "actor_loss": -36.08851642608643, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.148858785629272, "step": 116000}
{"episode_reward": 424.3890070830787, "episode": 117.0, "batch_reward": 0.3021266307681799, "critic_loss": 0.323599056199193, "actor_loss": -35.885993396759034, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.42655634880066, "step": 117000}
{"episode_reward": 478.8144006405513, "episode": 118.0, "batch_reward": 0.3029180148690939, "critic_loss": 0.31704951778799295, "actor_loss": -36.24627569961548, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.886574506759644, "step": 118000}
{"episode_reward": 464.7158304817318, "episode": 119.0, "batch_reward": 0.3043056662082672, "critic_loss": 0.3199297271370888, "actor_loss": -35.959021724700925, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.41338562965393, "step": 119000}
{"episode_reward": 490.2006903768148, "episode": 120.0, "batch_reward": 0.3045542027652264, "critic_loss": 0.32796627581864596, "actor_loss": -35.70193850708008, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.74094009399414, "step": 120000}
{"episode_reward": 495.82397309516716, "episode": 121.0, "batch_reward": 0.3075630068033934, "critic_loss": 0.3110205877497792, "actor_loss": -36.11190319442749, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.1040313243866, "step": 121000}
{"episode_reward": 461.23905381408997, "episode": 122.0, "batch_reward": 0.30850077015161514, "critic_loss": 0.3756672963500023, "actor_loss": -36.29258281326294, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.914341688156128, "step": 122000}
{"episode_reward": 477.4504209615675, "episode": 123.0, "batch_reward": 0.31110329163074496, "critic_loss": 0.2888219094276428, "actor_loss": -36.187423812866214, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.293241024017334, "step": 123000}
{"episode_reward": 483.35230380335173, "episode": 124.0, "batch_reward": 0.31158794814348223, "critic_loss": 0.31032789263874294, "actor_loss": -36.721871089935306, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.584609508514404, "step": 124000}
{"episode_reward": 452.63669594737075, "episode": 125.0, "batch_reward": 0.3122731670439243, "critic_loss": 0.33171875808387996, "actor_loss": -36.37619512939453, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.6735258102417, "step": 125000}
{"episode_reward": 502.1472567949919, "episode": 126.0, "batch_reward": 0.3134582191258669, "critic_loss": 0.31291873878985643, "actor_loss": -36.864301540374754, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.02989935874939, "step": 126000}
{"episode_reward": 495.4705881321835, "episode": 127.0, "batch_reward": 0.3149142109155655, "critic_loss": 0.32770866189152004, "actor_loss": -37.04078902816772, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.428056478500366, "step": 127000}
{"episode_reward": 491.12834389348404, "episode": 128.0, "batch_reward": 0.31733718755841256, "critic_loss": 0.33551060475409034, "actor_loss": -37.30889443206787, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.362651824951172, "step": 128000}
{"episode_reward": 470.46202890380454, "episode": 129.0, "batch_reward": 0.3172154375016689, "critic_loss": 0.3087823690548539, "actor_loss": -37.45638004684448, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.332582473754883, "step": 129000}
{"episode_reward": 479.44703442989334, "episode": 130.0, "batch_reward": 0.3192437062859535, "critic_loss": 0.30565771740674974, "actor_loss": -37.13619770050049, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.07922649383545, "step": 130000}
{"episode_reward": 465.06454891286893, "episode": 131.0, "batch_reward": 0.32077157416939733, "critic_loss": 0.3138956401869655, "actor_loss": -37.32040925216675, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.1339430809021, "step": 131000}
{"episode_reward": 477.76684349108933, "episode": 132.0, "batch_reward": 0.321915543705225, "critic_loss": 0.32955625385791065, "actor_loss": -37.3498317489624, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.209925174713135, "step": 132000}
{"episode_reward": 492.51992325177855, "episode": 133.0, "batch_reward": 0.322489617317915, "critic_loss": 0.3176057234853506, "actor_loss": -37.89638866043091, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.778165817260742, "step": 133000}
{"episode_reward": 463.7020815849251, "episode": 134.0, "batch_reward": 0.3237749871015549, "critic_loss": 0.31588487711548807, "actor_loss": -38.12577042388916, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.599355697631836, "step": 134000}
{"episode_reward": 477.3946323204519, "episode": 135.0, "batch_reward": 0.3251237596571446, "critic_loss": 0.3141908501237631, "actor_loss": -37.77007486724853, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.14525818824768, "step": 135000}
{"episode_reward": 508.6328183507135, "episode": 136.0, "batch_reward": 0.32658199125528337, "critic_loss": 0.28851190204173327, "actor_loss": -38.07235190200806, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.42165207862854, "step": 136000}
{"episode_reward": 488.6327638516378, "episode": 137.0, "batch_reward": 0.32712259942293165, "critic_loss": 0.2771904305294156, "actor_loss": -37.976905418395994, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.726673126220703, "step": 137000}
{"episode_reward": 515.0985587135016, "episode": 138.0, "batch_reward": 0.3294667308032513, "critic_loss": 0.2708921209648252, "actor_loss": -37.93629177856445, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.837135076522827, "step": 138000}
{"episode_reward": 499.62675004244807, "episode": 139.0, "batch_reward": 0.33042064240574837, "critic_loss": 0.2701497660651803, "actor_loss": -38.1479589881897, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.9649178981781, "step": 139000}
{"episode_reward": 503.3904077860934, "episode": 140.0, "batch_reward": 0.33076730474829674, "critic_loss": 0.261963499546051, "actor_loss": -37.99596474075317, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.73862862586975, "step": 140000}
{"episode_reward": 508.92103585117763, "episode": 141.0, "batch_reward": 0.3330128670334816, "critic_loss": 0.29544898071885106, "actor_loss": -38.24812387466431, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.58221650123596, "step": 141000}
{"episode_reward": 508.0460676655872, "episode": 142.0, "batch_reward": 0.33338059097528455, "critic_loss": 0.2527154246866703, "actor_loss": -38.4308826675415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.808709859848022, "step": 142000}
{"episode_reward": 518.2946431787634, "episode": 143.0, "batch_reward": 0.3357266751825809, "critic_loss": 0.26870171155780553, "actor_loss": -38.46349210739136, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.771615982055664, "step": 143000}
{"episode_reward": 485.9622809508949, "episode": 144.0, "batch_reward": 0.3365009558200836, "critic_loss": 0.25936400905251505, "actor_loss": -38.595986503601075, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.785572290420532, "step": 144000}
{"episode_reward": 494.8045768887783, "episode": 145.0, "batch_reward": 0.3385667872130871, "critic_loss": 0.2518616903051734, "actor_loss": -38.74449686431885, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.196035623550415, "step": 145000}
{"episode_reward": 518.3867840621515, "episode": 146.0, "batch_reward": 0.3376140956580639, "critic_loss": 0.2507491107732058, "actor_loss": -39.062852111816404, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.73277187347412, "step": 146000}
{"episode_reward": 473.7189881343231, "episode": 147.0, "batch_reward": 0.33897515809535983, "critic_loss": 0.2619592702314258, "actor_loss": -38.97247668075561, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.159226417541504, "step": 147000}
{"episode_reward": 495.54567288996645, "episode": 148.0, "batch_reward": 0.3407758786082268, "critic_loss": 0.26132144913077354, "actor_loss": -39.00418387985229, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.748826026916504, "step": 148000}
{"episode_reward": 492.92132182087283, "episode": 149.0, "batch_reward": 0.3419767873883247, "critic_loss": 0.2782009472474456, "actor_loss": -39.153307094573975, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.871991634368896, "step": 149000}
{"episode_reward": 456.61321099637877, "episode": 150.0, "batch_reward": 0.34349417051672937, "critic_loss": 0.26904043482244017, "actor_loss": -39.25480216217041, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
