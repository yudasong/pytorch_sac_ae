{"episode_reward": 0.0, "episode": 1.0, "duration": 18.670620918273926, "step": 1000}
{"episode_reward": 4.231880753996205, "episode": 2.0, "duration": 1.7238004207611084, "step": 2000}
{"episode_reward": 395.1450543749875, "episode": 3.0, "batch_reward": 0.19103828685189853, "critic_loss": 0.04749228352529878, "actor_loss": -28.8779335010524, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 67.47516107559204, "step": 3000}
{"episode_reward": 55.99479865264776, "episode": 4.0, "batch_reward": 0.13272332476824522, "critic_loss": 0.03863096721097827, "actor_loss": -22.876707679986954, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.667133569717407, "step": 4000}
{"episode_reward": 6.608915375523087, "episode": 5.0, "batch_reward": 0.10639772217720747, "critic_loss": 0.030774845115840437, "actor_loss": -22.01659854197502, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.33782410621643, "step": 5000}
{"episode_reward": 20.928501325696292, "episode": 6.0, "batch_reward": 0.09112413012981414, "critic_loss": 0.022356150314211846, "actor_loss": -21.28093292117119, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.84713053703308, "step": 6000}
{"episode_reward": 28.89061340021068, "episode": 7.0, "batch_reward": 0.08164723316207528, "critic_loss": 0.027197762834839524, "actor_loss": -20.263498881578446, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.576422214508057, "step": 7000}
{"episode_reward": 39.89224946970194, "episode": 8.0, "batch_reward": 0.0780397536084056, "critic_loss": 0.03236895948089659, "actor_loss": -21.933110862493514, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.34562611579895, "step": 8000}
{"episode_reward": 58.97812335572948, "episode": 9.0, "batch_reward": 0.07850032015889884, "critic_loss": 0.0419535208158195, "actor_loss": -20.977704634428026, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.418965816497803, "step": 9000}
{"episode_reward": 107.58908057712645, "episode": 10.0, "batch_reward": 0.07881640223413706, "critic_loss": 0.04697846777923405, "actor_loss": -21.19952721309662, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.63826036453247, "step": 10000}
{"episode_reward": 86.22016230254917, "episode": 11.0, "batch_reward": 0.08560741678625346, "critic_loss": 0.06689987155795098, "actor_loss": -21.877442601978778, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.84667634963989, "step": 11000}
{"episode_reward": 182.8004405674152, "episode": 12.0, "batch_reward": 0.08982652558013797, "critic_loss": 0.06632619231939316, "actor_loss": -21.888926529586314, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.70477056503296, "step": 12000}
{"episode_reward": 67.21359226949627, "episode": 13.0, "batch_reward": 0.08777001487836242, "critic_loss": 0.0651298963651061, "actor_loss": -21.308729048132896, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.1515109539032, "step": 13000}
{"episode_reward": 43.29848544184828, "episode": 14.0, "batch_reward": 0.08626682632789016, "critic_loss": 0.07626509891077876, "actor_loss": -20.509257922127844, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.248579740524292, "step": 14000}
{"episode_reward": 98.83184892340644, "episode": 15.0, "batch_reward": 0.08517641035094857, "critic_loss": 0.10069694513082504, "actor_loss": -18.585190067380665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.915465831756592, "step": 15000}
{"episode_reward": 45.28309022445654, "episode": 16.0, "batch_reward": 0.08189180175587535, "critic_loss": 0.11402537654340267, "actor_loss": -20.92057440721989, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.52433156967163, "step": 16000}
{"episode_reward": 39.255872184895395, "episode": 17.0, "batch_reward": 0.08004407136142254, "critic_loss": 0.1231510624922812, "actor_loss": -19.72887624657154, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.913702249526978, "step": 17000}
{"episode_reward": 47.332793471337666, "episode": 18.0, "batch_reward": 0.07827632014453412, "critic_loss": 0.12617250017821788, "actor_loss": -19.336387262061237, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.041800260543823, "step": 18000}
{"episode_reward": 52.69488624591855, "episode": 19.0, "batch_reward": 0.07609011184424162, "critic_loss": 0.11474722799286247, "actor_loss": -18.87852680028975, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.4880051612854, "step": 19000}
{"episode_reward": 24.820698939645286, "episode": 20.0, "batch_reward": 0.07539678335562348, "critic_loss": 0.1318425779156387, "actor_loss": -17.37591461786628, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.58164358139038, "step": 20000}
{"episode_reward": 63.689223741246906, "episode": 21.0, "batch_reward": 0.074754923325032, "critic_loss": 0.12836504466086626, "actor_loss": -17.623670741274953, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.671807050704956, "step": 21000}
{"episode_reward": 90.52927445742975, "episode": 22.0, "batch_reward": 0.07725503339990973, "critic_loss": 0.12338899476081133, "actor_loss": -17.493596695914864, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.752674341201782, "step": 22000}
{"episode_reward": 157.89639500384706, "episode": 23.0, "batch_reward": 0.08195061077922583, "critic_loss": 0.12491749980673193, "actor_loss": -18.33401583236456, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.394009828567505, "step": 23000}
{"episode_reward": 257.8586513798302, "episode": 24.0, "batch_reward": 0.08952782064676285, "critic_loss": 0.1321995507478714, "actor_loss": -19.357998162567615, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.002994060516357, "step": 24000}
{"episode_reward": 264.489067235109, "episode": 25.0, "batch_reward": 0.09496915515512228, "critic_loss": 0.135834232468158, "actor_loss": -19.36646098923683, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.15802025794983, "step": 25000}
{"episode_reward": 205.17525684787404, "episode": 26.0, "batch_reward": 0.09954551922529936, "critic_loss": 0.1407136669382453, "actor_loss": -19.6930461063385, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.976431131362915, "step": 26000}
{"episode_reward": 110.8938454574937, "episode": 27.0, "batch_reward": 0.09808650400489569, "critic_loss": 0.1511295672208071, "actor_loss": -19.03815110039711, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.62688374519348, "step": 27000}
{"episode_reward": 39.34931501291345, "episode": 28.0, "batch_reward": 0.09525359251722694, "critic_loss": 0.1570960894562304, "actor_loss": -19.378453340291976, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.800710678100586, "step": 28000}
{"episode_reward": 58.33340214868347, "episode": 29.0, "batch_reward": 0.096299671523273, "critic_loss": 0.1824400044940412, "actor_loss": -18.67278234529495, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.62329363822937, "step": 29000}
{"episode_reward": 180.2573483643614, "episode": 30.0, "batch_reward": 0.09704703213274479, "critic_loss": 0.1630485301427543, "actor_loss": -18.586145716667176, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.70093059539795, "step": 30000}
{"episode_reward": 41.941787154625494, "episode": 31.0, "batch_reward": 0.09840068791434169, "critic_loss": 0.16377178752422333, "actor_loss": -19.289651182651518, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.81951880455017, "step": 31000}
{"episode_reward": 177.2427911258542, "episode": 32.0, "batch_reward": 0.09863723348081112, "critic_loss": 0.19321105813235046, "actor_loss": -18.989578897476196, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.561739444732666, "step": 32000}
{"episode_reward": 70.67568290562194, "episode": 33.0, "batch_reward": 0.10024428754299879, "critic_loss": 0.20078436516597867, "actor_loss": -18.77374189376831, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.42859196662903, "step": 33000}
{"episode_reward": 145.9529439688238, "episode": 34.0, "batch_reward": 0.09847741421312094, "critic_loss": 0.18956926409900188, "actor_loss": -19.2073426527977, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.45474147796631, "step": 34000}
{"episode_reward": 59.90030103369882, "episode": 35.0, "batch_reward": 0.10057129261642694, "critic_loss": 0.17951248258724808, "actor_loss": -18.72426692676544, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.691717386245728, "step": 35000}
{"episode_reward": 298.6474178694245, "episode": 36.0, "batch_reward": 0.10374705924838781, "critic_loss": 0.21731470814347267, "actor_loss": -20.08890425634384, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.754916191101074, "step": 36000}
{"episode_reward": 62.78508466449361, "episode": 37.0, "batch_reward": 0.10486548745632171, "critic_loss": 0.23500054977089166, "actor_loss": -19.52028994178772, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.93817663192749, "step": 37000}
{"episode_reward": 269.99549456728477, "episode": 38.0, "batch_reward": 0.1079336090311408, "critic_loss": 0.22522281762212515, "actor_loss": -18.972114514350892, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.233012676239014, "step": 38000}
{"episode_reward": 115.91651738721232, "episode": 39.0, "batch_reward": 0.11041203337162733, "critic_loss": 0.2502207641080022, "actor_loss": -19.820210499286652, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.46723246574402, "step": 39000}
{"episode_reward": 319.3010485028821, "episode": 40.0, "batch_reward": 0.11478154355287552, "critic_loss": 0.27069945669174195, "actor_loss": -20.347676871299743, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.353171586990356, "step": 40000}
{"episode_reward": 324.0775167359082, "episode": 41.0, "batch_reward": 0.1202131400257349, "critic_loss": 0.2615803685262799, "actor_loss": -21.25050520515442, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.010443687438965, "step": 41000}
{"episode_reward": 277.74256248221695, "episode": 42.0, "batch_reward": 0.12376271213591099, "critic_loss": 0.2723370083197951, "actor_loss": -20.864962728500366, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.33462429046631, "step": 42000}
{"episode_reward": 241.28097016290806, "episode": 43.0, "batch_reward": 0.12556523441523312, "critic_loss": 0.29106239196658135, "actor_loss": -21.475977299690246, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.818073272705078, "step": 43000}
{"episode_reward": 123.39554375125812, "episode": 44.0, "batch_reward": 0.12676816107332706, "critic_loss": 0.28497860991954804, "actor_loss": -20.913705223083497, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.594183921813965, "step": 44000}
{"episode_reward": 281.41469274541095, "episode": 45.0, "batch_reward": 0.12826436872035266, "critic_loss": 0.2963578464016318, "actor_loss": -20.86198091983795, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.769551992416382, "step": 45000}
{"episode_reward": 76.61535108587445, "episode": 46.0, "batch_reward": 0.128686714977026, "critic_loss": 0.3261664195731282, "actor_loss": -21.25261723232269, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.70694375038147, "step": 46000}
{"episode_reward": 302.0664547295368, "episode": 47.0, "batch_reward": 0.13293252734839917, "critic_loss": 0.31914315780997277, "actor_loss": -21.87829240703583, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.33673357963562, "step": 47000}
{"episode_reward": 330.08878000492746, "episode": 48.0, "batch_reward": 0.13585362266749143, "critic_loss": 0.3288529810160398, "actor_loss": -22.03329783344269, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.171648263931274, "step": 48000}
{"episode_reward": 110.21790668666783, "episode": 49.0, "batch_reward": 0.1355410181954503, "critic_loss": 0.3380169844031334, "actor_loss": -22.010800985336303, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.096574544906616, "step": 49000}
{"episode_reward": 100.05758706096455, "episode": 50.0, "batch_reward": 0.135857227422297, "critic_loss": 0.3289453578293324, "actor_loss": -21.459594774246217, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.43951392173767, "step": 50000}
{"episode_reward": 333.86170078274233, "episode": 51.0, "batch_reward": 0.13825446695834398, "critic_loss": 0.303074371740222, "actor_loss": -21.975688009262086, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.29721426963806, "step": 51000}
{"episode_reward": 115.90090384621766, "episode": 52.0, "batch_reward": 0.14046629239618777, "critic_loss": 0.3037045100778341, "actor_loss": -22.583350257873533, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.117998361587524, "step": 52000}
{"episode_reward": 359.8523149648704, "episode": 53.0, "batch_reward": 0.14375112543255092, "critic_loss": 0.27617915734648707, "actor_loss": -21.74373926925659, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.80332922935486, "step": 53000}
{"episode_reward": 345.67741384775996, "episode": 54.0, "batch_reward": 0.147061696767807, "critic_loss": 0.26444196608662607, "actor_loss": -23.627748439788817, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.037882089614868, "step": 54000}
{"episode_reward": 265.21512869273744, "episode": 55.0, "batch_reward": 0.14912009255588055, "critic_loss": 0.2574828096628189, "actor_loss": -23.323082702636718, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.892489433288574, "step": 55000}
{"episode_reward": 277.82778854219754, "episode": 56.0, "batch_reward": 0.15157498979568482, "critic_loss": 0.24911440440267324, "actor_loss": -22.59033840942383, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.090012550354004, "step": 56000}
{"episode_reward": 267.19143702975293, "episode": 57.0, "batch_reward": 0.15356607414782047, "critic_loss": 0.2665797600671649, "actor_loss": -23.531653580665587, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.55437469482422, "step": 57000}
{"episode_reward": 356.041780277727, "episode": 58.0, "batch_reward": 0.1570281143411994, "critic_loss": 0.24635624384880067, "actor_loss": -23.572500038146973, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.53411030769348, "step": 58000}
{"episode_reward": 308.3574416255667, "episode": 59.0, "batch_reward": 0.15923092598468067, "critic_loss": 0.2814942320510745, "actor_loss": -24.20559201622009, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.875225067138672, "step": 59000}
{"episode_reward": 290.36359281033305, "episode": 60.0, "batch_reward": 0.16284259910881518, "critic_loss": 0.2559031680226326, "actor_loss": -23.916061267852783, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.96750807762146, "step": 60000}
{"episode_reward": 344.72413578352746, "episode": 61.0, "batch_reward": 0.16533537635952233, "critic_loss": 0.25271439053863287, "actor_loss": -24.825185302734376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.735700845718384, "step": 61000}
{"episode_reward": 292.1650059556445, "episode": 62.0, "batch_reward": 0.16775055841356515, "critic_loss": 0.26950572010874746, "actor_loss": -24.1419487991333, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.968077898025513, "step": 62000}
{"episode_reward": 353.909094380506, "episode": 63.0, "batch_reward": 0.16966037634015083, "critic_loss": 0.256742906562984, "actor_loss": -24.678262786865233, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.77328658103943, "step": 63000}
{"episode_reward": 359.308315988351, "episode": 64.0, "batch_reward": 0.17338769522309302, "critic_loss": 0.2553559559136629, "actor_loss": -25.45262074279785, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.980604887008667, "step": 64000}
{"episode_reward": 336.56423729395976, "episode": 65.0, "batch_reward": 0.17715678776800634, "critic_loss": 0.25184397370368244, "actor_loss": -25.052475048065187, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.09428381919861, "step": 65000}
{"episode_reward": 366.40372948242043, "episode": 66.0, "batch_reward": 0.1787308733165264, "critic_loss": 0.26805779585987327, "actor_loss": -25.454962047576906, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.20200800895691, "step": 66000}
{"episode_reward": 358.35472921246645, "episode": 67.0, "batch_reward": 0.18123942579329014, "critic_loss": 0.2627133458480239, "actor_loss": -25.34932597732544, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.451422691345215, "step": 67000}
{"episode_reward": 252.87989265288863, "episode": 68.0, "batch_reward": 0.1827515996992588, "critic_loss": 0.2626447551846504, "actor_loss": -26.359465293884277, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.68976640701294, "step": 68000}
{"episode_reward": 372.8337534990785, "episode": 69.0, "batch_reward": 0.18637640342116357, "critic_loss": 0.2859232053607702, "actor_loss": -26.429650527954102, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.967380046844482, "step": 69000}
{"episode_reward": 380.14615768186513, "episode": 70.0, "batch_reward": 0.1876960138976574, "critic_loss": 0.2670099810436368, "actor_loss": -26.893647424697875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.266053915023804, "step": 70000}
{"episode_reward": 382.5346217421491, "episode": 71.0, "batch_reward": 0.1903864947259426, "critic_loss": 0.2760503393188119, "actor_loss": -25.97686748313904, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.38305902481079, "step": 71000}
{"episode_reward": 409.54855530470985, "episode": 72.0, "batch_reward": 0.19393901620805262, "critic_loss": 0.2869877699315548, "actor_loss": -27.180113817214966, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.489571809768677, "step": 72000}
{"episode_reward": 365.12106027595854, "episode": 73.0, "batch_reward": 0.19583973973989488, "critic_loss": 0.25764221069961785, "actor_loss": -27.528981578826905, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.653737783432007, "step": 73000}
{"episode_reward": 390.5669525754646, "episode": 74.0, "batch_reward": 0.1993766252398491, "critic_loss": 0.2637238989472389, "actor_loss": -27.660901760101318, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.38541316986084, "step": 74000}
{"episode_reward": 391.0988027133995, "episode": 75.0, "batch_reward": 0.20183980712294577, "critic_loss": 0.29274926594644785, "actor_loss": -28.146787567138674, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.9808452129364, "step": 75000}
{"episode_reward": 366.25730514464476, "episode": 76.0, "batch_reward": 0.20412651808559895, "critic_loss": 0.28335698502510787, "actor_loss": -28.253093532562257, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.290969610214233, "step": 76000}
{"episode_reward": 416.2204410265708, "episode": 77.0, "batch_reward": 0.2063558752089739, "critic_loss": 0.284653832629323, "actor_loss": -28.180029865264892, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.424222469329834, "step": 77000}
{"episode_reward": 404.3178734042236, "episode": 78.0, "batch_reward": 0.20896226665377618, "critic_loss": 0.2696331967636943, "actor_loss": -28.572003398895262, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.217488765716553, "step": 78000}
{"episode_reward": 415.81192123934153, "episode": 79.0, "batch_reward": 0.21174520222842694, "critic_loss": 0.2802212060242891, "actor_loss": -28.716307796478272, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.44434404373169, "step": 79000}
{"episode_reward": 394.57912876257603, "episode": 80.0, "batch_reward": 0.21392677886784076, "critic_loss": 0.2697819905951619, "actor_loss": -29.113753387451172, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.698336124420166, "step": 80000}
{"episode_reward": 396.55857647756443, "episode": 81.0, "batch_reward": 0.21674175873398782, "critic_loss": 0.2581010087132454, "actor_loss": -28.809616144180296, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.88022994995117, "step": 81000}
{"episode_reward": 384.3594222257376, "episode": 82.0, "batch_reward": 0.21784135182201864, "critic_loss": 0.2584154657199979, "actor_loss": -29.15416752052307, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.847220182418823, "step": 82000}
{"episode_reward": 427.592650476283, "episode": 83.0, "batch_reward": 0.21984108710289002, "critic_loss": 0.25895245183259247, "actor_loss": -30.097589673995973, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.604441165924072, "step": 83000}
{"episode_reward": 368.3207194559385, "episode": 84.0, "batch_reward": 0.2225119767040014, "critic_loss": 0.26379114636033774, "actor_loss": -30.4367493724823, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.51174020767212, "step": 84000}
{"episode_reward": 403.23066435198814, "episode": 85.0, "batch_reward": 0.22457172639667988, "critic_loss": 0.2665753165706992, "actor_loss": -29.782678804397584, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.75849175453186, "step": 85000}
{"episode_reward": 392.6417699160228, "episode": 86.0, "batch_reward": 0.2274140970259905, "critic_loss": 0.2549271607473493, "actor_loss": -30.308746618270874, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.917053699493408, "step": 86000}
{"episode_reward": 415.3536225709112, "episode": 87.0, "batch_reward": 0.22943418231606483, "critic_loss": 0.27628643419593574, "actor_loss": -30.74537656402588, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.477209091186523, "step": 87000}
{"episode_reward": 316.72074696513874, "episode": 88.0, "batch_reward": 0.23081043538451196, "critic_loss": 0.28602139534056187, "actor_loss": -31.150338401794432, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.737560749053955, "step": 88000}
{"episode_reward": 420.04924544659025, "episode": 89.0, "batch_reward": 0.23316416300833226, "critic_loss": 0.27612222081422805, "actor_loss": -30.735175535202025, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.80626940727234, "step": 89000}
{"episode_reward": 414.8586098180221, "episode": 90.0, "batch_reward": 0.2347245347648859, "critic_loss": 0.26956904484331606, "actor_loss": -31.388184616088868, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.266968250274658, "step": 90000}
{"episode_reward": 417.31573053811417, "episode": 91.0, "batch_reward": 0.23657676059007646, "critic_loss": 0.2681880259513855, "actor_loss": -31.09977208709717, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.651981592178345, "step": 91000}
{"episode_reward": 421.95233869966006, "episode": 92.0, "batch_reward": 0.23881414794921876, "critic_loss": 0.2780957389101386, "actor_loss": -31.567232070922852, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.998992204666138, "step": 92000}
{"episode_reward": 427.05022858114916, "episode": 93.0, "batch_reward": 0.2403441180586815, "critic_loss": 0.27547216978669165, "actor_loss": -31.91644256210327, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.197278261184692, "step": 93000}
{"episode_reward": 388.35610602455483, "episode": 94.0, "batch_reward": 0.2421522468626499, "critic_loss": 0.28478294420987366, "actor_loss": -32.725612052917484, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.52486562728882, "step": 94000}
{"episode_reward": 394.01447983778695, "episode": 95.0, "batch_reward": 0.2432881169617176, "critic_loss": 0.2956014283746481, "actor_loss": -32.67032596206665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.05679178237915, "step": 95000}
{"episode_reward": 402.29746468284503, "episode": 96.0, "batch_reward": 0.24502057826519014, "critic_loss": 0.2834395599365234, "actor_loss": -32.59222453689575, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.299753427505493, "step": 96000}
{"episode_reward": 404.0363046341429, "episode": 97.0, "batch_reward": 0.24618625245988368, "critic_loss": 0.27851748547703026, "actor_loss": -32.58219633483887, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.078654766082764, "step": 97000}
{"episode_reward": 424.0083922349345, "episode": 98.0, "batch_reward": 0.2492533373683691, "critic_loss": 0.2824939918667078, "actor_loss": -32.64780297851563, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.942357540130615, "step": 98000}
{"episode_reward": 425.39440412252634, "episode": 99.0, "batch_reward": 0.2511339564472437, "critic_loss": 0.2761421531066299, "actor_loss": -33.07182538986206, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.418639183044434, "step": 99000}
{"episode_reward": 417.94509376225056, "episode": 100.0, "batch_reward": 0.2516177234351635, "critic_loss": 0.2724634317755699, "actor_loss": -33.15757995223999, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.659316539764404, "step": 100000}
{"episode_reward": 422.06749439974317, "episode": 101.0, "batch_reward": 0.25440112298727036, "critic_loss": 0.27114613182842734, "actor_loss": -33.288490440368655, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.841402769088745, "step": 101000}
{"episode_reward": 450.4189611617064, "episode": 102.0, "batch_reward": 0.2564377068132162, "critic_loss": 0.2718348427638412, "actor_loss": -34.171517581939696, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.922176599502563, "step": 102000}
{"episode_reward": 418.1369227538317, "episode": 103.0, "batch_reward": 0.25771241541206835, "critic_loss": 0.2646572784408927, "actor_loss": -33.448050819396975, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.807119846343994, "step": 103000}
{"episode_reward": 445.50077224588, "episode": 104.0, "batch_reward": 0.2584905693978071, "critic_loss": 0.27650229108333585, "actor_loss": -33.93057893753052, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.79242968559265, "step": 104000}
{"episode_reward": 442.46470571614793, "episode": 105.0, "batch_reward": 0.2616732991784811, "critic_loss": 0.27271752019226553, "actor_loss": -33.667621326446536, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.987653255462646, "step": 105000}
{"episode_reward": 435.7302783318463, "episode": 106.0, "batch_reward": 0.2624539192020893, "critic_loss": 0.2680244080796838, "actor_loss": -34.64214022827149, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.683138847351074, "step": 106000}
{"episode_reward": 424.87233202418497, "episode": 107.0, "batch_reward": 0.26412761798501017, "critic_loss": 0.2612238809093833, "actor_loss": -34.29705571746826, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.50468158721924, "step": 107000}
{"episode_reward": 411.36837856574334, "episode": 108.0, "batch_reward": 0.26494854560494424, "critic_loss": 0.25628015959262845, "actor_loss": -33.703175678253174, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.95637083053589, "step": 108000}
{"episode_reward": 415.50151702687793, "episode": 109.0, "batch_reward": 0.2670558560192585, "critic_loss": 0.2475783168077469, "actor_loss": -34.828630241394045, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.50534415245056, "step": 109000}
{"episode_reward": 427.7673982835191, "episode": 110.0, "batch_reward": 0.2690149779319763, "critic_loss": 0.24845620773732663, "actor_loss": -34.58443712615967, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.19806218147278, "step": 110000}
{"episode_reward": 425.36972681861107, "episode": 111.0, "batch_reward": 0.26940019318461417, "critic_loss": 0.2647972366809845, "actor_loss": -34.251508380889895, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.755526065826416, "step": 111000}
{"episode_reward": 407.7868115047886, "episode": 112.0, "batch_reward": 0.27119086883962157, "critic_loss": 0.25235471861064435, "actor_loss": -35.055461875915526, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.511763095855713, "step": 112000}
{"episode_reward": 409.28707704605495, "episode": 113.0, "batch_reward": 0.2723512450903654, "critic_loss": 0.2649888989776373, "actor_loss": -34.9872105140686, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.949936151504517, "step": 113000}
{"episode_reward": 402.88788081923235, "episode": 114.0, "batch_reward": 0.2729541890770197, "critic_loss": 0.2609144232347608, "actor_loss": -35.474670997619626, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.745318174362183, "step": 114000}
{"episode_reward": 380.6213761741259, "episode": 115.0, "batch_reward": 0.273460951924324, "critic_loss": 0.26521073710918425, "actor_loss": -35.097403495788576, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.805341958999634, "step": 115000}
{"episode_reward": 421.7387482729481, "episode": 116.0, "batch_reward": 0.27654486101865766, "critic_loss": 0.26040727049857376, "actor_loss": -35.53074600219727, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.71391201019287, "step": 116000}
{"episode_reward": 411.99260684363446, "episode": 117.0, "batch_reward": 0.27655447977781294, "critic_loss": 0.25463063599169256, "actor_loss": -34.844688720703125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.282434701919556, "step": 117000}
{"episode_reward": 429.8341076983284, "episode": 118.0, "batch_reward": 0.2779894459396601, "critic_loss": 0.2577385095357895, "actor_loss": -35.44030118560791, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.502140283584595, "step": 118000}
{"episode_reward": 424.9960082369918, "episode": 119.0, "batch_reward": 0.2794023925513029, "critic_loss": 0.2599119116067886, "actor_loss": -35.59360546875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.600796937942505, "step": 119000}
{"episode_reward": 425.8529362488879, "episode": 120.0, "batch_reward": 0.2800051890313625, "critic_loss": 0.24807279469072818, "actor_loss": -35.30474750137329, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.987351894378662, "step": 120000}
{"episode_reward": 413.4674513383153, "episode": 121.0, "batch_reward": 0.28060727897286414, "critic_loss": 0.24239300870895386, "actor_loss": -35.31350690460205, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.14314889907837, "step": 121000}
{"episode_reward": 356.26557502186745, "episode": 122.0, "batch_reward": 0.2833457654863596, "critic_loss": 0.2594324761405587, "actor_loss": -35.71271176147461, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.818409204483032, "step": 122000}
{"episode_reward": 422.9206450169288, "episode": 123.0, "batch_reward": 0.2830365295857191, "critic_loss": 0.2579760258495808, "actor_loss": -36.32312850952148, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.1760995388031, "step": 123000}
{"episode_reward": 405.4044622713578, "episode": 124.0, "batch_reward": 0.2834898580908775, "critic_loss": 0.2488474921286106, "actor_loss": -36.15611093902588, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.403829336166382, "step": 124000}
{"episode_reward": 417.9879772593547, "episode": 125.0, "batch_reward": 0.2851542554050684, "critic_loss": 0.25736936742812394, "actor_loss": -36.164326152801515, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.795595169067383, "step": 125000}
{"episode_reward": 368.8083599027579, "episode": 126.0, "batch_reward": 0.2864397962540388, "critic_loss": 0.23841126592457296, "actor_loss": -35.89883316421509, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.874685287475586, "step": 126000}
{"episode_reward": 416.3769639042447, "episode": 127.0, "batch_reward": 0.2863168254941702, "critic_loss": 0.24970731456577777, "actor_loss": -35.95508577728271, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.576666831970215, "step": 127000}
{"episode_reward": 438.05471569490066, "episode": 128.0, "batch_reward": 0.28784859958291054, "critic_loss": 0.2406922277957201, "actor_loss": -36.39104537200928, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.861743688583374, "step": 128000}
{"episode_reward": 429.3366617225478, "episode": 129.0, "batch_reward": 0.28911120614409447, "critic_loss": 0.2624346450716257, "actor_loss": -36.116778141021726, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.178617477416992, "step": 129000}
{"episode_reward": 440.8199026141795, "episode": 130.0, "batch_reward": 0.2908746151328087, "critic_loss": 0.252063316680491, "actor_loss": -36.380636657714845, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.691790342330933, "step": 130000}
{"episode_reward": 445.9781292891699, "episode": 131.0, "batch_reward": 0.2922185724973679, "critic_loss": 0.24739904199540616, "actor_loss": -36.57776245498657, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.46662902832031, "step": 131000}
{"episode_reward": 427.7675432128529, "episode": 132.0, "batch_reward": 0.29208353435993195, "critic_loss": 0.25771084006130696, "actor_loss": -36.91813762283325, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.354658603668213, "step": 132000}
{"episode_reward": 438.8395621221098, "episode": 133.0, "batch_reward": 0.2947391402721405, "critic_loss": 0.26154689960181715, "actor_loss": -36.80145739364624, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.713724613189697, "step": 133000}
{"episode_reward": 424.7778287792152, "episode": 134.0, "batch_reward": 0.2951168974786997, "critic_loss": 0.262406382150948, "actor_loss": -36.53210868835449, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.728153705596924, "step": 134000}
{"episode_reward": 425.74821710703134, "episode": 135.0, "batch_reward": 0.29622803030908107, "critic_loss": 0.24774224855005741, "actor_loss": -36.93027791976929, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.14452314376831, "step": 135000}
{"episode_reward": 442.36523168971945, "episode": 136.0, "batch_reward": 0.2964201318323612, "critic_loss": 0.2453962832391262, "actor_loss": -36.05202694702148, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.61120915412903, "step": 136000}
{"episode_reward": 419.6794696717891, "episode": 137.0, "batch_reward": 0.29752838832139966, "critic_loss": 0.23105067129433154, "actor_loss": -37.34506951141358, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.191449642181396, "step": 137000}
{"episode_reward": 442.71801228250547, "episode": 138.0, "batch_reward": 0.29938837099075316, "critic_loss": 0.24064415238797665, "actor_loss": -37.58719035339355, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.746883392333984, "step": 138000}
{"episode_reward": 420.33383382563795, "episode": 139.0, "batch_reward": 0.30011179293692114, "critic_loss": 0.24521343329548836, "actor_loss": -37.34149648666382, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.325405836105347, "step": 139000}
{"episode_reward": 263.37627355461535, "episode": 140.0, "batch_reward": 0.3000511457920074, "critic_loss": 0.2527929069176316, "actor_loss": -37.13537508392334, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.50691533088684, "step": 140000}
{"episode_reward": 406.53814594614846, "episode": 141.0, "batch_reward": 0.29995407386124134, "critic_loss": 0.25353841079771516, "actor_loss": -37.176679817199705, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.474613666534424, "step": 141000}
{"episode_reward": 425.4383924446706, "episode": 142.0, "batch_reward": 0.3005156880617142, "critic_loss": 0.2576753725409508, "actor_loss": -36.709205421447756, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.30027198791504, "step": 142000}
{"episode_reward": 430.5707331167009, "episode": 143.0, "batch_reward": 0.3015658491551876, "critic_loss": 0.2496947102546692, "actor_loss": -37.198995391845706, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.489866018295288, "step": 143000}
{"episode_reward": 413.3212549375552, "episode": 144.0, "batch_reward": 0.3035605197548866, "critic_loss": 0.25027168986201287, "actor_loss": -37.52736547851563, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.791890144348145, "step": 144000}
{"episode_reward": 436.2855814319076, "episode": 145.0, "batch_reward": 0.3039306657612324, "critic_loss": 0.25155187987536193, "actor_loss": -37.863884578704834, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.1069118976593, "step": 145000}
{"episode_reward": 435.3580617782121, "episode": 146.0, "batch_reward": 0.30417515963315966, "critic_loss": 0.251311255171895, "actor_loss": -38.021361598968504, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.672832489013672, "step": 146000}
{"episode_reward": 419.67836966491876, "episode": 147.0, "batch_reward": 0.3051696064770222, "critic_loss": 0.2675784168243408, "actor_loss": -37.95464384841919, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.522080183029175, "step": 147000}
{"episode_reward": 415.8076332715378, "episode": 148.0, "batch_reward": 0.30658529725670813, "critic_loss": 0.2647332791760564, "actor_loss": -38.34048343276977, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.773918390274048, "step": 148000}
{"episode_reward": 430.6910293656199, "episode": 149.0, "batch_reward": 0.3069440157413483, "critic_loss": 0.2585427653044462, "actor_loss": -37.647141189575194, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.862125396728516, "step": 149000}
{"episode_reward": 427.23786132746494, "episode": 150.0, "batch_reward": 0.3079477518796921, "critic_loss": 0.26344688817858697, "actor_loss": -38.10666953277588, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
