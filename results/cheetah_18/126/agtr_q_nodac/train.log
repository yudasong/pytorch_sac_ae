{"episode": 1.0, "duration": 19.53516173362732, "episode_reward": 4.231880753996205, "step": 1000}
{"episode": 2.0, "duration": 1.9110784530639648, "episode_reward": 395.1450543749875, "step": 2000}
{"episode": 3.0, "batch_reward": 0.19485469228051114, "actor_loss": -40.899157706906, "actor_target_entropy": -6.0, "alpha_value": 0.010699999250839183, "duration": 69.85250854492188, "episode_reward": 147.87161449728566, "step": 3000}
{"episode": 4.0, "batch_reward": 0.185363477319479, "actor_loss": -39.64699765014648, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.84304189682007, "episode_reward": 209.4960228528345, "step": 4000}
{"episode": 5.0, "batch_reward": 0.19033226546645166, "actor_loss": -39.705986526489255, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.77606987953186, "episode_reward": 202.12547639381918, "step": 5000}
{"episode": 6.0, "batch_reward": 0.19656572695076466, "actor_loss": -39.890616264343265, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.45688772201538, "episode_reward": 239.23193565632346, "step": 6000}
{"episode": 7.0, "batch_reward": 0.20289858569204808, "actor_loss": -40.12521994781494, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.981755018234253, "episode_reward": 238.56220164156656, "step": 7000}
{"episode": 8.0, "batch_reward": 0.20869213491678237, "actor_loss": -40.37031526184082, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.261879682540894, "episode_reward": 266.9403483774308, "step": 8000}
{"episode": 9.0, "batch_reward": 0.21257691019773484, "actor_loss": -40.435897506713864, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.46750020980835, "episode_reward": 218.78116476829663, "step": 9000}
{"episode": 10.0, "batch_reward": 0.21372088304162026, "actor_loss": -40.2864116897583, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.975143671035767, "episode_reward": 194.9203548411911, "step": 10000}
{"episode": 11.0, "batch_reward": 0.20946385645866394, "actor_loss": -39.622020851135254, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 41.494446992874146, "episode_reward": 99.39554019616595, "step": 11000}
{"episode": 12.0, "batch_reward": 0.20361469155550002, "actor_loss": -38.62809970855713, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.3399715423584, "episode_reward": 238.9704168261083, "step": 12000}
{"episode": 13.0, "batch_reward": 0.20411972534656525, "actor_loss": -38.51693016815186, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.551117658615112, "episode_reward": 136.61872326512471, "step": 13000}
{"episode": 14.0, "batch_reward": 0.1949501642137766, "actor_loss": -37.02997284698486, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.351061820983887, "episode_reward": 59.9852909755488, "step": 14000}
{"episode": 15.0, "batch_reward": 0.19237685464322568, "actor_loss": -36.3809182510376, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.43211054801941, "episode_reward": 279.7135532450006, "step": 15000}
{"episode": 16.0, "batch_reward": 0.19767506596446038, "actor_loss": -36.892274360656735, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.658238172531128, "episode_reward": 263.0061438393588, "step": 16000}
{"episode": 17.0, "batch_reward": 0.19766713470220565, "actor_loss": -36.66209043121338, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.554766178131104, "episode_reward": 78.74836580477701, "step": 17000}
{"episode": 18.0, "batch_reward": 0.19344827742874623, "actor_loss": -36.07790831756592, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.399003744125366, "episode_reward": 237.01944700469954, "step": 18000}
{"episode": 19.0, "batch_reward": 0.19543519777059554, "actor_loss": -36.32920306396484, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.89349627494812, "episode_reward": 213.98046573219452, "step": 19000}
{"episode": 20.0, "batch_reward": 0.1987669217735529, "actor_loss": -36.6135203704834, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.018515586853027, "episode_reward": 301.7567440930622, "step": 20000}
{"episode": 21.0, "batch_reward": 0.20305909526348115, "actor_loss": -37.044778381347655, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 40.95812726020813, "episode_reward": 286.7425746277189, "step": 21000}
{"episode": 22.0, "batch_reward": 0.2071800280213356, "actor_loss": -37.338916877746584, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.570221185684204, "episode_reward": 283.06023083810646, "step": 22000}
{"episode": 23.0, "batch_reward": 0.210167709633708, "actor_loss": -37.64225146484375, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.579705953598022, "episode_reward": 247.50324293522607, "step": 23000}
{"episode": 24.0, "batch_reward": 0.2098618665188551, "actor_loss": -37.755725242614744, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.481186151504517, "episode_reward": 169.61069985421307, "step": 24000}
{"episode": 25.0, "batch_reward": 0.20624895738065244, "actor_loss": -37.32595206451416, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.769756078720093, "episode_reward": 43.67484018331145, "step": 25000}
{"episode": 26.0, "batch_reward": 0.20395740535855295, "actor_loss": -36.893152465820314, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.844847679138184, "episode_reward": 266.54008053345774, "step": 26000}
{"episode": 27.0, "batch_reward": 0.2030176255851984, "actor_loss": -37.01190518951416, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.379652976989746, "episode_reward": 50.895047551541765, "step": 27000}
{"episode": 28.0, "batch_reward": 0.19586730493605137, "actor_loss": -36.64721240234375, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.204697132110596, "episode_reward": 18.374984594808364, "step": 28000}
{"episode": 29.0, "batch_reward": 0.19180377638339996, "actor_loss": -36.591686149597166, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.094571590423584, "episode_reward": 89.22895712647217, "step": 29000}
{"episode": 30.0, "batch_reward": 0.18962185569107531, "actor_loss": -36.386631126403806, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.00234603881836, "episode_reward": 142.16837382967842, "step": 30000}
{"episode": 31.0, "batch_reward": 0.18951879139244557, "actor_loss": -36.27852592468262, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 40.84890842437744, "episode_reward": 304.37546558617083, "step": 31000}
{"episode": 32.0, "batch_reward": 0.18984615984559058, "actor_loss": -36.274375274658205, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.90593647956848, "episode_reward": 141.89195925528273, "step": 32000}
{"episode": 33.0, "batch_reward": 0.19105364066362382, "actor_loss": -36.380043586730956, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.51097321510315, "episode_reward": 253.47050194319866, "step": 33000}
{"episode": 34.0, "batch_reward": 0.19255050957202913, "actor_loss": -36.39483962249756, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.555585145950317, "episode_reward": 240.5244167049298, "step": 34000}
{"episode": 35.0, "batch_reward": 0.19430670084059237, "actor_loss": -36.5394065322876, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.359676837921143, "episode_reward": 214.37606981693088, "step": 35000}
{"episode": 36.0, "batch_reward": 0.19554687868058682, "actor_loss": -36.44949490356446, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.7286217212677, "episode_reward": 312.1451274800885, "step": 36000}
{"episode": 37.0, "batch_reward": 0.19837990137934686, "actor_loss": -36.72148435974121, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.424756050109863, "episode_reward": 309.82337160126923, "step": 37000}
{"episode": 38.0, "batch_reward": 0.20097198240458966, "actor_loss": -36.99119785308838, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.332783937454224, "episode_reward": 326.3662708197382, "step": 38000}
{"episode": 39.0, "batch_reward": 0.2046700482070446, "actor_loss": -37.273433433532716, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.30858826637268, "episode_reward": 310.98237032297146, "step": 39000}
{"episode": 40.0, "batch_reward": 0.20754928843677045, "actor_loss": -37.372191444396975, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.944321870803833, "episode_reward": 265.1320218120197, "step": 40000}
{"episode": 41.0, "batch_reward": 0.20878847105801104, "actor_loss": -37.4988680267334, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 40.51084351539612, "episode_reward": 354.48314859482906, "step": 41000}
{"episode": 42.0, "batch_reward": 0.2124686379432678, "actor_loss": -37.73541619110107, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.257433891296387, "episode_reward": 306.8304615030136, "step": 42000}
{"episode": 43.0, "batch_reward": 0.21430595825612545, "actor_loss": -37.812801361083984, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.47212862968445, "episode_reward": 292.8610832395261, "step": 43000}
{"episode": 44.0, "batch_reward": 0.21695212726294993, "actor_loss": -38.07917433166504, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.633577585220337, "episode_reward": 339.0236044933347, "step": 44000}
{"episode": 45.0, "batch_reward": 0.2189641960710287, "actor_loss": -38.1074896774292, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 26.81016969680786, "episode_reward": 206.60562347949562, "step": 45000}
{"episode": 46.0, "batch_reward": 0.21901997044682503, "actor_loss": -38.018442253112795, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.433511972427368, "episode_reward": 336.91050657243505, "step": 46000}
{"episode": 47.0, "batch_reward": 0.22187857343256473, "actor_loss": -38.24664618682861, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.559574842453003, "episode_reward": 331.7245842857784, "step": 47000}
{"episode": 48.0, "batch_reward": 0.22346599377691745, "actor_loss": -38.26169646453857, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.07851219177246, "episode_reward": 297.8902042506545, "step": 48000}
{"episode": 49.0, "batch_reward": 0.2257958384156227, "actor_loss": -38.48832465362549, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.009130477905273, "episode_reward": 292.46777325357425, "step": 49000}
{"episode": 50.0, "batch_reward": 0.22759010395407678, "actor_loss": -38.54393367004395, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.45756244659424, "episode_reward": 314.4834106749344, "step": 50000}
{"episode": 51.0, "batch_reward": 0.22848209619522095, "actor_loss": -38.67788126373291, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 40.85081171989441, "episode_reward": 296.35273947144424, "step": 51000}
{"episode": 52.0, "batch_reward": 0.22991165566444396, "actor_loss": -38.77542711639404, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.265393018722534, "episode_reward": 343.5852427034959, "step": 52000}
{"episode": 53.0, "batch_reward": 0.22933075323700905, "actor_loss": -38.65324645996094, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.288137674331665, "episode_reward": 58.2786508056883, "step": 53000}
{"episode": 54.0, "batch_reward": 0.2288424898982048, "actor_loss": -38.507436752319336, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.775572776794434, "episode_reward": 347.0405920510053, "step": 54000}
{"episode": 55.0, "batch_reward": 0.2302570354938507, "actor_loss": -38.61346082305908, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.586400747299194, "episode_reward": 292.0976840893129, "step": 55000}
{"episode": 56.0, "batch_reward": 0.23233538614213467, "actor_loss": -38.72065818786621, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.622076988220215, "episode_reward": 344.0347901584481, "step": 56000}
{"episode": 57.0, "batch_reward": 0.23388107268512248, "actor_loss": -38.98623829650879, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.671900749206543, "episode_reward": 311.9827075482478, "step": 57000}
{"episode": 58.0, "batch_reward": 0.23610864186286926, "actor_loss": -38.913013870239254, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.13877034187317, "episode_reward": 351.4408837502672, "step": 58000}
{"episode": 59.0, "batch_reward": 0.2373652998059988, "actor_loss": -39.053978355407715, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.819268465042114, "episode_reward": 331.0618558357598, "step": 59000}
{"episode": 60.0, "batch_reward": 0.23784389925003052, "actor_loss": -39.028763679504394, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.9022479057312, "episode_reward": 101.06355514603938, "step": 60000}
{"episode": 61.0, "batch_reward": 0.2359026685208082, "actor_loss": -38.835460525512694, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 44.98263359069824, "episode_reward": 158.6460154394401, "step": 61000}
{"episode": 62.0, "batch_reward": 0.23492897011339664, "actor_loss": -38.619083877563476, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.63105034828186, "episode_reward": 323.51207890415486, "step": 62000}
{"episode": 63.0, "batch_reward": 0.2356115532964468, "actor_loss": -38.622661361694334, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.72305154800415, "episode_reward": 111.11174944093462, "step": 63000}
{"episode": 64.0, "batch_reward": 0.2345097444653511, "actor_loss": -38.32336884307861, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.688750743865967, "episode_reward": 203.3728009974314, "step": 64000}
{"episode": 65.0, "batch_reward": 0.2335508813858032, "actor_loss": -38.2752146987915, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.43375539779663, "episode_reward": 316.5784261905141, "step": 65000}
{"episode": 66.0, "batch_reward": 0.23629009845852852, "actor_loss": -38.449965476989746, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.323968172073364, "episode_reward": 335.67023834555215, "step": 66000}
{"episode": 67.0, "batch_reward": 0.23698275907337665, "actor_loss": -38.49140938568115, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.050352334976196, "episode_reward": 347.1077812834123, "step": 67000}
{"episode": 68.0, "batch_reward": 0.238842410415411, "actor_loss": -38.71416298675537, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.66949439048767, "episode_reward": 340.7220321943933, "step": 68000}
{"episode": 69.0, "batch_reward": 0.24067364436388017, "actor_loss": -38.8411365737915, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.991605043411255, "episode_reward": 364.1421951830663, "step": 69000}
{"episode": 70.0, "batch_reward": 0.2421021712869406, "actor_loss": -38.96390795898437, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.339129209518433, "episode_reward": 331.13887796498926, "step": 70000}
{"episode": 71.0, "batch_reward": 0.2433910819143057, "actor_loss": -39.02662998962403, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 41.252047061920166, "episode_reward": 352.2918542634293, "step": 71000}
{"episode": 72.0, "batch_reward": 0.24477695325016977, "actor_loss": -39.06197557830811, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.70961856842041, "episode_reward": 327.678626617802, "step": 72000}
{"episode": 73.0, "batch_reward": 0.2460877738595009, "actor_loss": -39.181269302368165, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.324211359024048, "episode_reward": 355.9311003015487, "step": 73000}
{"episode": 74.0, "batch_reward": 0.2477784501761198, "actor_loss": -39.4217533493042, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.585185527801514, "episode_reward": 373.9295202297106, "step": 74000}
{"episode": 75.0, "batch_reward": 0.24885630314052104, "actor_loss": -39.45747798156738, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.49742555618286, "episode_reward": 324.7569231264063, "step": 75000}
{"episode": 76.0, "batch_reward": 0.2508867662400007, "actor_loss": -39.686277145385745, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.5281765460968, "episode_reward": 342.23157738569824, "step": 76000}
{"episode": 77.0, "batch_reward": 0.25179636038839814, "actor_loss": -39.77864095306396, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.8635036945343, "episode_reward": 340.44453285689934, "step": 77000}
{"episode": 78.0, "batch_reward": 0.251743723705411, "actor_loss": -39.65444947814942, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.581361532211304, "episode_reward": 266.3301347691106, "step": 78000}
{"episode": 79.0, "batch_reward": 0.2508141116052866, "actor_loss": -39.62045560455322, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.571103811264038, "episode_reward": 85.44636265765234, "step": 79000}
{"episode": 80.0, "batch_reward": 0.25082610225677493, "actor_loss": -39.449511695861815, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.78984236717224, "episode_reward": 357.39382125810556, "step": 80000}
{"episode": 81.0, "batch_reward": 0.2523885964155197, "actor_loss": -39.64572235107422, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 41.50668931007385, "episode_reward": 353.4375985499779, "step": 81000}
{"episode": 82.0, "batch_reward": 0.2533125823587179, "actor_loss": -39.66903592681885, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.47992753982544, "episode_reward": 327.1122380596962, "step": 82000}
{"episode": 83.0, "batch_reward": 0.25388745772838595, "actor_loss": -39.748564094543454, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.468326330184937, "episode_reward": 362.7729945384552, "step": 83000}
{"episode": 84.0, "batch_reward": 0.25521877463161946, "actor_loss": -39.89843295288086, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.80846643447876, "episode_reward": 362.74340918749806, "step": 84000}
{"episode": 85.0, "batch_reward": 0.2564313012510538, "actor_loss": -39.95693293762207, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.62253761291504, "episode_reward": 299.85662096890013, "step": 85000}
{"episode": 86.0, "batch_reward": 0.25595745819807053, "actor_loss": -39.894121971130375, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.72810649871826, "episode_reward": 344.76200464506815, "step": 86000}
{"episode": 87.0, "batch_reward": 0.2583995399326086, "actor_loss": -40.14301313018799, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.118107318878174, "episode_reward": 381.09975166584064, "step": 87000}
{"episode": 88.0, "batch_reward": 0.2598681519627571, "actor_loss": -40.2072689743042, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.665297985076904, "episode_reward": 377.3469523866114, "step": 88000}
{"episode": 89.0, "batch_reward": 0.26077336698770526, "actor_loss": -40.25556784057617, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.847814321517944, "episode_reward": 188.5354307840768, "step": 89000}
{"episode": 90.0, "batch_reward": 0.2605370060354471, "actor_loss": -40.246719413757326, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.33953332901001, "episode_reward": 364.68387360738774, "step": 90000}
{"episode": 91.0, "batch_reward": 0.26107463209331033, "actor_loss": -40.2079652633667, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 41.4244065284729, "episode_reward": 336.3847375185076, "step": 91000}
{"episode": 92.0, "batch_reward": 0.2620970567762852, "actor_loss": -40.39930066680908, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.75524353981018, "episode_reward": 359.0993410955523, "step": 92000}
{"episode": 93.0, "batch_reward": 0.26299581983685494, "actor_loss": -40.41407801055908, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.401673793792725, "episode_reward": 369.7088512157427, "step": 93000}
{"episode": 94.0, "batch_reward": 0.26403892834484577, "actor_loss": -40.49553336334228, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.637022733688354, "episode_reward": 312.8973952387002, "step": 94000}
{"episode": 95.0, "batch_reward": 0.2648066693395376, "actor_loss": -40.54905712127685, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.621060371398926, "episode_reward": 375.67292192827745, "step": 95000}
{"episode": 96.0, "batch_reward": 0.26674637554585934, "actor_loss": -40.714599609375, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.542863368988037, "episode_reward": 312.741302749693, "step": 96000}
{"episode": 97.0, "batch_reward": 0.26672290605306626, "actor_loss": -40.70387368011475, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.754105806350708, "episode_reward": 371.2573014387297, "step": 97000}
{"episode": 98.0, "batch_reward": 0.2670572062432766, "actor_loss": -40.79229640197754, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.51522660255432, "episode_reward": 391.41797623212483, "step": 98000}
{"episode": 99.0, "batch_reward": 0.2681169444322586, "actor_loss": -40.75241896057129, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.84714674949646, "episode_reward": 375.1402089081753, "step": 99000}
{"episode": 100.0, "batch_reward": 0.2698206735402346, "actor_loss": -40.92584568023682, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.57729935646057, "episode_reward": 386.1281564677685, "step": 100000}
{"episode": 101.0, "batch_reward": 0.27028113897144795, "actor_loss": -41.02928987121582, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 40.96137833595276, "episode_reward": 254.66147791073985, "step": 101000}
{"episode": 102.0, "batch_reward": 0.270728781953454, "actor_loss": -41.044683319091796, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 23.337458848953247, "episode_reward": 368.8866057594169, "step": 102000}
{"episode": 103.0, "batch_reward": 0.2720933695435524, "actor_loss": -41.134903030395506, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.541306018829346, "episode_reward": 359.77881178978197, "step": 103000}
{"episode": 104.0, "batch_reward": 0.2724885780066252, "actor_loss": -41.16860376739502, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.562238216400146, "episode_reward": 350.65672706538464, "step": 104000}
{"episode": 105.0, "batch_reward": 0.27322831298410893, "actor_loss": -41.21149120330811, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.568655729293823, "episode_reward": 329.72576900595885, "step": 105000}
{"episode": 106.0, "batch_reward": 0.27355050067603587, "actor_loss": -41.350619522094725, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.19478940963745, "episode_reward": 330.1281522810195, "step": 106000}
{"episode": 107.0, "batch_reward": 0.27411212672293184, "actor_loss": -41.36276891326904, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.625011205673218, "episode_reward": 359.6632818824795, "step": 107000}
{"episode": 108.0, "batch_reward": 0.27556705877184867, "actor_loss": -41.407081665039065, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.072990655899048, "episode_reward": 349.36848898624953, "step": 108000}
{"episode": 109.0, "batch_reward": 0.2753840965628624, "actor_loss": -41.40543617248535, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.30940008163452, "episode_reward": 363.54013448688954, "step": 109000}
{"episode": 110.0, "batch_reward": 0.27663586144149305, "actor_loss": -41.537965438842775, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.570123195648193, "episode_reward": 346.0415650793448, "step": 110000}
{"episode": 111.0, "batch_reward": 0.27716997753083705, "actor_loss": -41.54751826477051, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 41.295629262924194, "episode_reward": 371.75635062389546, "step": 111000}
{"episode": 112.0, "batch_reward": 0.27829905293881896, "actor_loss": -41.64812838745117, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.634744882583618, "episode_reward": 362.6845699363905, "step": 112000}
{"episode": 113.0, "batch_reward": 0.2789318626374006, "actor_loss": -41.74230290222168, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.938220262527466, "episode_reward": 355.0414308542894, "step": 113000}
{"episode": 114.0, "batch_reward": 0.2802305919677019, "actor_loss": -41.86445007324219, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.50859308242798, "episode_reward": 370.8669392135884, "step": 114000}
{"episode": 115.0, "batch_reward": 0.28012624686956406, "actor_loss": -41.8317067565918, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.940696477890015, "episode_reward": 387.37991210554185, "step": 115000}
{"episode": 116.0, "batch_reward": 0.28170753198862075, "actor_loss": -41.93724423980713, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.313024044036865, "episode_reward": 387.53634978368035, "step": 116000}
{"episode": 117.0, "batch_reward": 0.28288452948629855, "actor_loss": -42.05704872131348, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.255534648895264, "episode_reward": 350.36790757251737, "step": 117000}
{"episode": 118.0, "batch_reward": 0.282427672713995, "actor_loss": -41.99957010650635, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.16191077232361, "episode_reward": 330.43105909786976, "step": 118000}
{"episode": 119.0, "batch_reward": 0.2832147686481476, "actor_loss": -42.14534812164307, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.619897603988647, "episode_reward": 346.16677573282726, "step": 119000}
{"episode": 120.0, "batch_reward": 0.2838479115664959, "actor_loss": -42.091806411743164, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.877150058746338, "episode_reward": 380.80431433504555, "step": 120000}
{"episode": 121.0, "batch_reward": 0.28471855418384073, "actor_loss": -42.165481811523435, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 41.29628872871399, "episode_reward": 344.0819208432618, "step": 121000}
{"episode": 122.0, "batch_reward": 0.28488603661954404, "actor_loss": -42.18335774993896, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.607837200164795, "episode_reward": 307.680582487779, "step": 122000}
{"episode": 123.0, "batch_reward": 0.28529960358142853, "actor_loss": -42.25886615753174, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.523366928100586, "episode_reward": 371.3486764561778, "step": 123000}
{"episode": 124.0, "batch_reward": 0.2856094887852669, "actor_loss": -42.18863010406494, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.68511462211609, "episode_reward": 298.20809123233795, "step": 124000}
{"episode": 125.0, "batch_reward": 0.2854299491941929, "actor_loss": -42.26673812866211, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.565415382385254, "episode_reward": 240.8532285554582, "step": 125000}
{"episode": 126.0, "batch_reward": 0.2858337662816048, "actor_loss": -42.28197413635254, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.98551344871521, "episode_reward": 389.5866255554702, "step": 126000}
{"episode": 127.0, "batch_reward": 0.2869864014685154, "actor_loss": -42.383793601989744, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.417739629745483, "episode_reward": 377.1897135034564, "step": 127000}
{"episode": 128.0, "batch_reward": 0.2871078670024872, "actor_loss": -42.41632532501221, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.425793170928955, "episode_reward": 400.9480226742935, "step": 128000}
{"episode": 129.0, "batch_reward": 0.28831077814102174, "actor_loss": -42.47016137695312, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.841786861419678, "episode_reward": 386.5689071331745, "step": 129000}
{"episode": 130.0, "batch_reward": 0.2889011174440384, "actor_loss": -42.520505149841306, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.00467824935913, "episode_reward": 338.09414908506335, "step": 130000}
{"episode": 131.0, "batch_reward": 0.2890845097601414, "actor_loss": -42.46796899414063, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 41.109601974487305, "episode_reward": 333.49929964735986, "step": 131000}
{"episode": 132.0, "batch_reward": 0.2898646633028984, "actor_loss": -42.565561599731446, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.291107654571533, "episode_reward": 327.2022725836214, "step": 132000}
{"episode": 133.0, "batch_reward": 0.28964656016230583, "actor_loss": -42.61233406829834, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.691664457321167, "episode_reward": 363.7048280017781, "step": 133000}
{"episode": 134.0, "batch_reward": 0.2901187731325626, "actor_loss": -42.672383209228514, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.866644620895386, "episode_reward": 233.46203776691067, "step": 134000}
{"episode": 135.0, "batch_reward": 0.290354941368103, "actor_loss": -42.69435897064209, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.09822106361389, "episode_reward": 332.8465846815797, "step": 135000}
{"episode": 136.0, "batch_reward": 0.29016559579968454, "actor_loss": -42.60624741363525, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.455962419509888, "episode_reward": 303.9202544525236, "step": 136000}
{"episode": 137.0, "batch_reward": 0.2900028658211231, "actor_loss": -42.687180450439456, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.877283811569214, "episode_reward": 360.47809953490554, "step": 137000}
{"episode": 138.0, "batch_reward": 0.2906181289553642, "actor_loss": -42.71620038604736, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.369765520095825, "episode_reward": 352.3360652708105, "step": 138000}
{"episode": 139.0, "batch_reward": 0.2916243638247252, "actor_loss": -42.819010383605956, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.3933584690094, "episode_reward": 362.2249876214713, "step": 139000}
{"episode": 140.0, "batch_reward": 0.29176268818974493, "actor_loss": -42.84475452423096, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.96850848197937, "episode_reward": 333.26076236729165, "step": 140000}
{"episode": 141.0, "batch_reward": 0.29209522023797035, "actor_loss": -42.86810648345947, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 40.27275061607361, "episode_reward": 364.90022487980957, "step": 141000}
{"episode": 142.0, "batch_reward": 0.2910436506271362, "actor_loss": -42.740006950378415, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.638559818267822, "episode_reward": 105.4842391765464, "step": 142000}
{"episode": 143.0, "batch_reward": 0.29073132562637327, "actor_loss": -42.74997043609619, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.630569458007812, "episode_reward": 405.35896128239875, "step": 143000}
{"episode": 144.0, "batch_reward": 0.29237639892101286, "actor_loss": -42.892999313354494, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.97612237930298, "episode_reward": 322.4509420657108, "step": 144000}
{"episode": 145.0, "batch_reward": 0.29242033112049104, "actor_loss": -42.96529618835449, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.018281936645508, "episode_reward": 378.1913007127265, "step": 145000}
{"episode": 146.0, "batch_reward": 0.293118307441473, "actor_loss": -42.91498448944092, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 20.108332633972168, "episode_reward": 378.4408508736151, "step": 146000}
{"episode": 147.0, "batch_reward": 0.2922462036907673, "actor_loss": -42.91470002746582, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.298675060272217, "episode_reward": 93.78659031977956, "step": 147000}
{"episode": 148.0, "batch_reward": 0.2921319158673286, "actor_loss": -42.87883387756348, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 22.855053663253784, "episode_reward": 372.4893241717725, "step": 148000}
{"episode": 149.0, "batch_reward": 0.29170713359117506, "actor_loss": -42.87134976196289, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 21.03750491142273, "episode_reward": 306.0545796319981, "step": 149000}
{"episode": 150.0, "batch_reward": 0.2932777159810066, "actor_loss": -42.96910653686523, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "step": 150000}
