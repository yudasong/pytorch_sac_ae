{"episode_reward": 0.0, "episode": 1.0, "duration": 13.049066543579102, "step": 1000}
{"episode_reward": 4.231880753996205, "episode": 2.0, "duration": 1.1094970703125, "step": 2000}
{"episode_reward": 395.1450543749875, "episode": 3.0, "batch_reward": 0.18846339745078733, "critic_loss": 0.05169185915220903, "actor_loss": -36.376948441384364, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 71.8878493309021, "step": 3000}
{"episode_reward": 16.30217752693598, "episode": 4.0, "batch_reward": 0.12711248341202736, "critic_loss": 0.06570318284444511, "actor_loss": -30.76555269527435, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.747915267944336, "step": 4000}
{"episode_reward": 48.706484363522335, "episode": 5.0, "batch_reward": 0.10849832379072905, "critic_loss": 0.04553189305961132, "actor_loss": -28.306309686660768, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.165637731552124, "step": 5000}
{"episode_reward": 40.94740986298407, "episode": 6.0, "batch_reward": 0.09509522357210518, "critic_loss": 0.04068143919669092, "actor_loss": -27.713231077194212, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.818202018737793, "step": 6000}
{"episode_reward": 17.942936908343885, "episode": 7.0, "batch_reward": 0.08502580482512713, "critic_loss": 0.038367595890536906, "actor_loss": -27.63521166086197, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.308406591415405, "step": 7000}
{"episode_reward": 31.062622581418644, "episode": 8.0, "batch_reward": 0.07544200725108385, "critic_loss": 0.035799949211999776, "actor_loss": -23.935081535339357, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.161154747009277, "step": 8000}
{"episode_reward": 14.369346369473769, "episode": 9.0, "batch_reward": 0.06907635600492358, "critic_loss": 0.04847760415636003, "actor_loss": -22.872511679649353, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.94953155517578, "step": 9000}
{"episode_reward": 24.781446778635154, "episode": 10.0, "batch_reward": 0.06678030067682267, "critic_loss": 0.07291929427720606, "actor_loss": -21.266877046585083, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.50488829612732, "step": 10000}
{"episode_reward": 79.1531598829451, "episode": 11.0, "batch_reward": 0.06759803760424256, "critic_loss": 0.09012267460674048, "actor_loss": -20.55000643157959, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.28992986679077, "step": 11000}
{"episode_reward": 49.23376881840228, "episode": 12.0, "batch_reward": 0.06944191031903028, "critic_loss": 0.0953037253767252, "actor_loss": -18.002176899909973, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.301182985305786, "step": 12000}
{"episode_reward": 150.63904778633903, "episode": 13.0, "batch_reward": 0.07298343368619681, "critic_loss": 0.10713334387168288, "actor_loss": -19.512539425373078, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.903956413269043, "step": 13000}
{"episode_reward": 50.498951933998526, "episode": 14.0, "batch_reward": 0.07502012642100453, "critic_loss": 0.11168471759557724, "actor_loss": -18.429896817207336, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.49859881401062, "step": 14000}
{"episode_reward": 170.02968918411182, "episode": 15.0, "batch_reward": 0.07689508223533631, "critic_loss": 0.13158547716587782, "actor_loss": -19.542960820674896, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.101988554000854, "step": 15000}
{"episode_reward": 26.966614052400594, "episode": 16.0, "batch_reward": 0.0785150109604001, "critic_loss": 0.1494495829641819, "actor_loss": -14.995280071258545, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.783975839614868, "step": 16000}
{"episode_reward": 141.99832409688855, "episode": 17.0, "batch_reward": 0.08098313656821847, "critic_loss": 0.1644091433957219, "actor_loss": -15.516900185585023, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.26670742034912, "step": 17000}
{"episode_reward": 112.33972218007966, "episode": 18.0, "batch_reward": 0.08338677835464478, "critic_loss": 0.16773243436962365, "actor_loss": -15.545583887964487, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.898828983306885, "step": 18000}
{"episode_reward": 121.47801351469722, "episode": 19.0, "batch_reward": 0.08843679320439696, "critic_loss": 0.1870656511709094, "actor_loss": -15.294668176285922, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.835431814193726, "step": 19000}
{"episode_reward": 233.75664227738304, "episode": 20.0, "batch_reward": 0.09160276626050472, "critic_loss": 0.23355533807724715, "actor_loss": -16.460674958512186, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.153801441192627, "step": 20000}
{"episode_reward": 92.68325842153952, "episode": 21.0, "batch_reward": 0.0913600892573595, "critic_loss": 0.23914994918555021, "actor_loss": -15.339391904696821, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.06568169593811, "step": 21000}
{"episode_reward": 80.19583996953791, "episode": 22.0, "batch_reward": 0.0920354856401682, "critic_loss": 0.2503572805970907, "actor_loss": -15.768394005939365, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.00015139579773, "step": 22000}
{"episode_reward": 142.96685209629268, "episode": 23.0, "batch_reward": 0.09223965350165964, "critic_loss": 0.2270668835118413, "actor_loss": -14.919387684613467, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.96155095100403, "step": 23000}
{"episode_reward": 62.74688314121423, "episode": 24.0, "batch_reward": 0.09436229652911425, "critic_loss": 0.26526819333434104, "actor_loss": -14.96086404171586, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.91668725013733, "step": 24000}
{"episode_reward": 177.26636087061962, "episode": 25.0, "batch_reward": 0.09477240054309369, "critic_loss": 0.22847944087535144, "actor_loss": -14.596433856368066, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.426697731018066, "step": 25000}
{"episode_reward": 67.04759561464662, "episode": 26.0, "batch_reward": 0.09413976556807756, "critic_loss": 0.22236025749891997, "actor_loss": -13.591183332562446, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.90687584877014, "step": 26000}
{"episode_reward": 72.10104267960516, "episode": 27.0, "batch_reward": 0.09539091975986957, "critic_loss": 0.21372208777815105, "actor_loss": -14.24091809272766, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.171279907226562, "step": 27000}
{"episode_reward": 105.04215450494532, "episode": 28.0, "batch_reward": 0.0960827544927597, "critic_loss": 0.26752512270212175, "actor_loss": -13.396686854839325, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.4821994304657, "step": 28000}
{"episode_reward": 240.20957574034978, "episode": 29.0, "batch_reward": 0.09821745948493481, "critic_loss": 0.2547197526022792, "actor_loss": -14.25929718208313, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.448129177093506, "step": 29000}
{"episode_reward": 51.01206892301597, "episode": 30.0, "batch_reward": 0.09775065801292658, "critic_loss": 0.2645946213454008, "actor_loss": -13.79943993139267, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.10011100769043, "step": 30000}
{"episode_reward": 56.099451241242356, "episode": 31.0, "batch_reward": 0.09659442564100026, "critic_loss": 0.2842639522254467, "actor_loss": -13.032389975070954, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.857325077056885, "step": 31000}
{"episode_reward": 82.02194796127601, "episode": 32.0, "batch_reward": 0.09767891059815884, "critic_loss": 0.24964528269320727, "actor_loss": -13.177467008590698, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.61343550682068, "step": 32000}
{"episode_reward": 152.17000046958805, "episode": 33.0, "batch_reward": 0.09692431090772152, "critic_loss": 0.2606182791367173, "actor_loss": -13.128798236370086, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.300015926361084, "step": 33000}
{"episode_reward": 53.85664883451352, "episode": 34.0, "batch_reward": 0.09514906752854585, "critic_loss": 0.25724372412264346, "actor_loss": -11.824706969738006, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.805201292037964, "step": 34000}
{"episode_reward": 43.36180138236907, "episode": 35.0, "batch_reward": 0.09502033542096615, "critic_loss": 0.26835399272292854, "actor_loss": -12.485509540557862, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.40343689918518, "step": 35000}
{"episode_reward": 89.97286797990147, "episode": 36.0, "batch_reward": 0.09643870390951634, "critic_loss": 0.2849858405739069, "actor_loss": -11.453338878631591, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.048990488052368, "step": 36000}
{"episode_reward": 180.16766528288153, "episode": 37.0, "batch_reward": 0.0974160113632679, "critic_loss": 0.25768767439574003, "actor_loss": -11.946094938278199, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.867084741592407, "step": 37000}
{"episode_reward": 106.89599481862308, "episode": 38.0, "batch_reward": 0.09847979228198528, "critic_loss": 0.2915191946774721, "actor_loss": -12.556134029388428, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.017375707626343, "step": 38000}
{"episode_reward": 149.0859826381708, "episode": 39.0, "batch_reward": 0.09968023390322923, "critic_loss": 0.29145700799673796, "actor_loss": -11.95773350429535, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.134289264678955, "step": 39000}
{"episode_reward": 113.59719948832418, "episode": 40.0, "batch_reward": 0.0988379054442048, "critic_loss": 0.2596019586250186, "actor_loss": -11.827796063423158, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.207284927368164, "step": 40000}
{"episode_reward": 65.38938715481389, "episode": 41.0, "batch_reward": 0.09931500103324652, "critic_loss": 0.25850414516031744, "actor_loss": -11.25604813194275, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.95178484916687, "step": 41000}
{"episode_reward": 118.86468888488638, "episode": 42.0, "batch_reward": 0.10058549582958222, "critic_loss": 0.26988735439628364, "actor_loss": -12.111717561721802, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.19009232521057, "step": 42000}
{"episode_reward": 181.15492514451924, "episode": 43.0, "batch_reward": 0.10390708304941654, "critic_loss": 0.2510662414059043, "actor_loss": -11.538857109069824, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.047807216644287, "step": 43000}
{"episode_reward": 331.7370937371635, "episode": 44.0, "batch_reward": 0.10643473877757788, "critic_loss": 0.2554446023702621, "actor_loss": -11.870258101463318, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.106272220611572, "step": 44000}
{"episode_reward": 116.80755648602168, "episode": 45.0, "batch_reward": 0.10663954105228185, "critic_loss": 0.23284785109758377, "actor_loss": -12.032966453552246, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.26899766921997, "step": 45000}
{"episode_reward": 127.21917840229716, "episode": 46.0, "batch_reward": 0.10728659238666297, "critic_loss": 0.2361050845757127, "actor_loss": -12.243707675933837, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.209952354431152, "step": 46000}
{"episode_reward": 215.68788220279754, "episode": 47.0, "batch_reward": 0.10995895478129387, "critic_loss": 0.2574892132133245, "actor_loss": -12.078250588417053, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.302098274230957, "step": 47000}
{"episode_reward": 163.9241010801342, "episode": 48.0, "batch_reward": 0.11145859549939632, "critic_loss": 0.25111032198369504, "actor_loss": -12.126458335876466, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.222869157791138, "step": 48000}
{"episode_reward": 141.804562596348, "episode": 49.0, "batch_reward": 0.11096059606224298, "critic_loss": 0.2775077632665634, "actor_loss": -12.06398583984375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.28098702430725, "step": 49000}
{"episode_reward": 71.90129869151777, "episode": 50.0, "batch_reward": 0.11142090332508087, "critic_loss": 0.26093438487499954, "actor_loss": -12.395830479621887, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.383511066436768, "step": 50000}
{"episode_reward": 169.64971890912793, "episode": 51.0, "batch_reward": 0.11183736767619848, "critic_loss": 0.2500846419781447, "actor_loss": -12.233605757713319, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.63802981376648, "step": 51000}
{"episode_reward": 95.24056076945845, "episode": 52.0, "batch_reward": 0.11308580760657787, "critic_loss": 0.2562475007027388, "actor_loss": -12.527589836120605, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.542497158050537, "step": 52000}
{"episode_reward": 243.55005683426108, "episode": 53.0, "batch_reward": 0.1133188455030322, "critic_loss": 0.29568800795078276, "actor_loss": -13.070602491378784, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.625120878219604, "step": 53000}
{"episode_reward": 104.44275944675819, "episode": 54.0, "batch_reward": 0.11422567151486873, "critic_loss": 0.2883838998749852, "actor_loss": -12.954093797683715, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.557587385177612, "step": 54000}
{"episode_reward": 124.18444141336128, "episode": 55.0, "batch_reward": 0.11348879981040955, "critic_loss": 0.268341825298965, "actor_loss": -13.348960832595825, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.516749620437622, "step": 55000}
{"episode_reward": 189.47870831630473, "episode": 56.0, "batch_reward": 0.11453395502269267, "critic_loss": 0.3070056430697441, "actor_loss": -14.013418153762817, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.970030546188354, "step": 56000}
{"episode_reward": 39.35997628418207, "episode": 57.0, "batch_reward": 0.11442567512392998, "critic_loss": 0.2799056769087911, "actor_loss": -13.52678078842163, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.37312889099121, "step": 57000}
{"episode_reward": 253.33179752658495, "episode": 58.0, "batch_reward": 0.11591931515932083, "critic_loss": 0.2930230281427503, "actor_loss": -14.057307580947876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.03090190887451, "step": 58000}
{"episode_reward": 97.66010518089696, "episode": 59.0, "batch_reward": 0.11727282257378101, "critic_loss": 0.28888842937350273, "actor_loss": -13.994676597595214, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.953128337860107, "step": 59000}
{"episode_reward": 388.58911054935214, "episode": 60.0, "batch_reward": 0.12206164159625768, "critic_loss": 0.29400918012857435, "actor_loss": -14.826268022537231, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.45538878440857, "step": 60000}
{"episode_reward": 386.36459087117606, "episode": 61.0, "batch_reward": 0.1259090438261628, "critic_loss": 0.29522354385256766, "actor_loss": -15.36357061958313, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.23314166069031, "step": 61000}
{"episode_reward": 371.2843361661547, "episode": 62.0, "batch_reward": 0.13125083953887223, "critic_loss": 0.305884305678308, "actor_loss": -15.96138252067566, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.450790405273438, "step": 62000}
{"episode_reward": 420.7795490044414, "episode": 63.0, "batch_reward": 0.13460019385814667, "critic_loss": 0.32160693682730196, "actor_loss": -16.18350162124634, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.19850254058838, "step": 63000}
{"episode_reward": 364.0919894120403, "episode": 64.0, "batch_reward": 0.13898169292509555, "critic_loss": 0.33653806827962396, "actor_loss": -16.970203632354735, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.389837980270386, "step": 64000}
{"episode_reward": 380.1389440822682, "episode": 65.0, "batch_reward": 0.1438988478332758, "critic_loss": 0.36205760753154753, "actor_loss": -17.697444009780884, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.588220834732056, "step": 65000}
{"episode_reward": 445.1422149286363, "episode": 66.0, "batch_reward": 0.1472907340824604, "critic_loss": 0.34453934101760386, "actor_loss": -18.217063566207887, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.1281955242157, "step": 66000}
{"episode_reward": 421.8587618573645, "episode": 67.0, "batch_reward": 0.15153465446829795, "critic_loss": 0.33325455389916897, "actor_loss": -19.142178520202638, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.285467386245728, "step": 67000}
{"episode_reward": 446.9438461853115, "episode": 68.0, "batch_reward": 0.15623434983193873, "critic_loss": 0.3162639879137278, "actor_loss": -19.60041481781006, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.295353174209595, "step": 68000}
{"episode_reward": 404.58240042425405, "episode": 69.0, "batch_reward": 0.1605894336476922, "critic_loss": 0.3018124242573976, "actor_loss": -20.11988636779785, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.224218130111694, "step": 69000}
{"episode_reward": 417.31250117637023, "episode": 70.0, "batch_reward": 0.1637472848445177, "critic_loss": 0.3223864752501249, "actor_loss": -20.297019832611085, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.475861310958862, "step": 70000}
{"episode_reward": 445.3731091481421, "episode": 71.0, "batch_reward": 0.16653168587386608, "critic_loss": 0.37315512196719647, "actor_loss": -21.532971813201904, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.51723837852478, "step": 71000}
{"episode_reward": 442.84291096790184, "episode": 72.0, "batch_reward": 0.17071017630398275, "critic_loss": 0.34475372135639193, "actor_loss": -21.695591957092287, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.27518391609192, "step": 72000}
{"episode_reward": 420.34648463865665, "episode": 73.0, "batch_reward": 0.17382261515408753, "critic_loss": 0.3031403672844172, "actor_loss": -22.19429327392578, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.312172174453735, "step": 73000}
{"episode_reward": 442.0134375145492, "episode": 74.0, "batch_reward": 0.17872556513547896, "critic_loss": 0.29792427995800974, "actor_loss": -23.077800594329833, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.99162745475769, "step": 74000}
{"episode_reward": 442.9179754865222, "episode": 75.0, "batch_reward": 0.18240861125290395, "critic_loss": 0.27909786761552097, "actor_loss": -23.481727138519286, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.87732434272766, "step": 75000}
{"episode_reward": 455.1318409690591, "episode": 76.0, "batch_reward": 0.1858846987336874, "critic_loss": 0.26593212251365184, "actor_loss": -23.85674736404419, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.338126182556152, "step": 76000}
{"episode_reward": 488.1806275547612, "episode": 77.0, "batch_reward": 0.18905090062320232, "critic_loss": 0.26230443649739027, "actor_loss": -24.069363986968995, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.97524380683899, "step": 77000}
{"episode_reward": 449.8754329282182, "episode": 78.0, "batch_reward": 0.19258830013871192, "critic_loss": 0.26852026012539865, "actor_loss": -24.53317568588257, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.10982370376587, "step": 78000}
{"episode_reward": 444.67958284938055, "episode": 79.0, "batch_reward": 0.19610369683802129, "critic_loss": 0.2617249885126948, "actor_loss": -24.77850690460205, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.16989493370056, "step": 79000}
{"episode_reward": 474.5036464886286, "episode": 80.0, "batch_reward": 0.19860888531804086, "critic_loss": 0.26116533609479664, "actor_loss": -25.1928454208374, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.66801381111145, "step": 80000}
{"episode_reward": 441.30136456539105, "episode": 81.0, "batch_reward": 0.20330149793624877, "critic_loss": 0.24241919732838868, "actor_loss": -25.423032917022706, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.159820795059204, "step": 81000}
{"episode_reward": 445.2598403590322, "episode": 82.0, "batch_reward": 0.20469466030597686, "critic_loss": 0.2678101808577776, "actor_loss": -25.720315769195558, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.23009967803955, "step": 82000}
{"episode_reward": 439.9317189058674, "episode": 83.0, "batch_reward": 0.20695978525280953, "critic_loss": 0.2661984932422638, "actor_loss": -26.054884574890135, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.923152208328247, "step": 83000}
{"episode_reward": 453.5304260301714, "episode": 84.0, "batch_reward": 0.2114606440514326, "critic_loss": 0.26419223595410585, "actor_loss": -26.25306800842285, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.273274183273315, "step": 84000}
{"episode_reward": 463.5902957035301, "episode": 85.0, "batch_reward": 0.21456769874691964, "critic_loss": 0.25696823734045027, "actor_loss": -26.891725574493407, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.400764226913452, "step": 85000}
{"episode_reward": 486.03144515374555, "episode": 86.0, "batch_reward": 0.21881579679250718, "critic_loss": 0.26139345498383043, "actor_loss": -27.23293908691406, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.905037879943848, "step": 86000}
{"episode_reward": 495.45034310514694, "episode": 87.0, "batch_reward": 0.22093210552632808, "critic_loss": 0.2439240365549922, "actor_loss": -27.531865928649903, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.2916157245636, "step": 87000}
{"episode_reward": 468.48157235113496, "episode": 88.0, "batch_reward": 0.22472417053580285, "critic_loss": 0.24689252251386642, "actor_loss": -27.886256927490233, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.284531831741333, "step": 88000}
{"episode_reward": 473.4091882393525, "episode": 89.0, "batch_reward": 0.2269646216183901, "critic_loss": 0.23939205433428287, "actor_loss": -28.220914196014405, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.97423005104065, "step": 89000}
{"episode_reward": 385.01194142617027, "episode": 90.0, "batch_reward": 0.2281228240430355, "critic_loss": 0.22692691423743963, "actor_loss": -28.2232707862854, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.588119506835938, "step": 90000}
{"episode_reward": 464.1026914978348, "episode": 91.0, "batch_reward": 0.23113577136397362, "critic_loss": 0.22465138451755046, "actor_loss": -28.60550658416748, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.17337656021118, "step": 91000}
{"episode_reward": 501.0501296457692, "episode": 92.0, "batch_reward": 0.2337263796776533, "critic_loss": 0.23055785616487265, "actor_loss": -28.834163585662843, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.50440549850464, "step": 92000}
{"episode_reward": 502.2775228833694, "episode": 93.0, "batch_reward": 0.23672307054698466, "critic_loss": 0.227999797783792, "actor_loss": -28.855489154815675, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.930933237075806, "step": 93000}
{"episode_reward": 476.5835641608941, "episode": 94.0, "batch_reward": 0.23933091519773006, "critic_loss": 0.23019254936277866, "actor_loss": -29.12581519317627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.28132200241089, "step": 94000}
{"episode_reward": 478.28662639960356, "episode": 95.0, "batch_reward": 0.24252523231506348, "critic_loss": 0.22067835453152657, "actor_loss": -29.334025512695312, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.7817702293396, "step": 95000}
{"episode_reward": 485.03011528213864, "episode": 96.0, "batch_reward": 0.2448275583833456, "critic_loss": 0.2589603898823261, "actor_loss": -29.625988788604737, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.130993127822876, "step": 96000}
{"episode_reward": 473.62727672628534, "episode": 97.0, "batch_reward": 0.24646374240517616, "critic_loss": 0.2912009915485978, "actor_loss": -30.14507371902466, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.22368288040161, "step": 97000}
{"episode_reward": 502.6237108777665, "episode": 98.0, "batch_reward": 0.24908047690987586, "critic_loss": 0.3217437847405672, "actor_loss": -30.44457745742798, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.42404341697693, "step": 98000}
{"episode_reward": 483.7632396752964, "episode": 99.0, "batch_reward": 0.25245696485042574, "critic_loss": 0.30228129819780586, "actor_loss": -30.988504470825195, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.163803577423096, "step": 99000}
{"episode_reward": 488.9398032162988, "episode": 100.0, "batch_reward": 0.2538537691831589, "critic_loss": 0.3029577058702707, "actor_loss": -31.26895238113403, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.695871829986572, "step": 100000}
{"episode_reward": 490.8714869325615, "episode": 101.0, "batch_reward": 0.2567598658204079, "critic_loss": 0.31957702143490313, "actor_loss": -31.980191272735595, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.514972448349, "step": 101000}
{"episode_reward": 491.7326759749873, "episode": 102.0, "batch_reward": 0.258714592307806, "critic_loss": 0.2868889112919569, "actor_loss": -32.3412978591919, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.445672035217285, "step": 102000}
{"episode_reward": 504.6685573229547, "episode": 103.0, "batch_reward": 0.2614795849174261, "critic_loss": 0.2800878797322512, "actor_loss": -33.08789608001709, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.973337650299072, "step": 103000}
{"episode_reward": 513.3286394495168, "episode": 104.0, "batch_reward": 0.2632601259946823, "critic_loss": 0.26216910319775344, "actor_loss": -33.642727096557614, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.312812328338623, "step": 104000}
{"episode_reward": 497.60037522819, "episode": 105.0, "batch_reward": 0.2665063354820013, "critic_loss": 0.2583823292776942, "actor_loss": -34.2588420715332, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.726200342178345, "step": 105000}
{"episode_reward": 503.33647843544077, "episode": 106.0, "batch_reward": 0.2672452935874462, "critic_loss": 0.27010631788522005, "actor_loss": -34.60445232391358, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.968679904937744, "step": 106000}
{"episode_reward": 486.5109882672986, "episode": 107.0, "batch_reward": 0.2696490667164326, "critic_loss": 0.255047152325511, "actor_loss": -34.83121615600586, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.71550416946411, "step": 107000}
{"episode_reward": 495.224134219461, "episode": 108.0, "batch_reward": 0.2714907645583153, "critic_loss": 0.27987240527570245, "actor_loss": -35.12588771820069, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.178097009658813, "step": 108000}
{"episode_reward": 484.0406143654504, "episode": 109.0, "batch_reward": 0.27428940489888193, "critic_loss": 0.2651147133782506, "actor_loss": -35.38818240356445, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.430362224578857, "step": 109000}
{"episode_reward": 504.4267923418287, "episode": 110.0, "batch_reward": 0.27658132080733777, "critic_loss": 0.2506174535006285, "actor_loss": -35.67999802398682, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.587175130844116, "step": 110000}
{"episode_reward": 483.35174280670094, "episode": 111.0, "batch_reward": 0.2778248010277748, "critic_loss": 0.25351483207941056, "actor_loss": -35.795046913146976, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.471606492996216, "step": 111000}
{"episode_reward": 484.003147917985, "episode": 112.0, "batch_reward": 0.28051297698915006, "critic_loss": 0.2596742012947798, "actor_loss": -36.0575326385498, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.652732133865356, "step": 112000}
{"episode_reward": 509.48142397389995, "episode": 113.0, "batch_reward": 0.28231218929588797, "critic_loss": 0.2623588445410132, "actor_loss": -36.42246918487549, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.269607305526733, "step": 113000}
{"episode_reward": 489.9233222331122, "episode": 114.0, "batch_reward": 0.28327862510085106, "critic_loss": 0.2747198453396559, "actor_loss": -36.52202564239502, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.56682801246643, "step": 114000}
{"episode_reward": 472.02436432550587, "episode": 115.0, "batch_reward": 0.28470971842110154, "critic_loss": 0.25172044295817614, "actor_loss": -36.735263542175296, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.388542413711548, "step": 115000}
{"episode_reward": 508.6089978222024, "episode": 116.0, "batch_reward": 0.28844677793979645, "critic_loss": 0.24094213254749774, "actor_loss": -37.1626706161499, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.34647560119629, "step": 116000}
{"episode_reward": 492.7527521369489, "episode": 117.0, "batch_reward": 0.2897612039744854, "critic_loss": 0.2565619049370289, "actor_loss": -37.60656219482422, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.826330423355103, "step": 117000}
{"episode_reward": 481.18703237585186, "episode": 118.0, "batch_reward": 0.2909767300635576, "critic_loss": 0.2563990395739675, "actor_loss": -38.396525772094726, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.258696794509888, "step": 118000}
{"episode_reward": 497.70879565471284, "episode": 119.0, "batch_reward": 0.2931514299660921, "critic_loss": 0.2340688801109791, "actor_loss": -39.04202365875244, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.224941730499268, "step": 119000}
{"episode_reward": 514.3620388448811, "episode": 120.0, "batch_reward": 0.2936379585415125, "critic_loss": 0.22378134907782077, "actor_loss": -39.329751342773434, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.507399082183838, "step": 120000}
{"episode_reward": 492.2993751572322, "episode": 121.0, "batch_reward": 0.29525707721710204, "critic_loss": 0.23060891854017973, "actor_loss": -39.61702258300781, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.64667344093323, "step": 121000}
{"episode_reward": 493.71398863925504, "episode": 122.0, "batch_reward": 0.2986645157337189, "critic_loss": 0.2455893283933401, "actor_loss": -39.962507369995116, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.50486660003662, "step": 122000}
{"episode_reward": 481.7546830087579, "episode": 123.0, "batch_reward": 0.2988069304674864, "critic_loss": 0.23590765944868325, "actor_loss": -40.49751265716553, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.288268327713013, "step": 123000}
{"episode_reward": 507.27898219525565, "episode": 124.0, "batch_reward": 0.30028821595013144, "critic_loss": 0.23122798792272806, "actor_loss": -40.72513999176025, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.802886962890625, "step": 124000}
{"episode_reward": 485.1663545039416, "episode": 125.0, "batch_reward": 0.30251769226789477, "critic_loss": 0.2298581249937415, "actor_loss": -40.767568099975584, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.749747276306152, "step": 125000}
{"episode_reward": 499.07093446882305, "episode": 126.0, "batch_reward": 0.3039694058150053, "critic_loss": 0.23174330636113882, "actor_loss": -40.82296009063721, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.492791414260864, "step": 126000}
{"episode_reward": 509.22345055388024, "episode": 127.0, "batch_reward": 0.3046656533628702, "critic_loss": 0.22379626903682948, "actor_loss": -40.7988740234375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.5808527469635, "step": 127000}
{"episode_reward": 489.183453002005, "episode": 128.0, "batch_reward": 0.30639293137192725, "critic_loss": 0.23173287038505078, "actor_loss": -40.782117111206055, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.872889518737793, "step": 128000}
{"episode_reward": 501.5620832026506, "episode": 129.0, "batch_reward": 0.3082217541784048, "critic_loss": 0.23453131053596735, "actor_loss": -40.864360946655275, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.12847137451172, "step": 129000}
{"episode_reward": 524.0258102636984, "episode": 130.0, "batch_reward": 0.31106989078223707, "critic_loss": 0.22965171056240796, "actor_loss": -40.93581002044678, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.023465633392334, "step": 130000}
{"episode_reward": 507.1297340825508, "episode": 131.0, "batch_reward": 0.3117893494069576, "critic_loss": 0.21965005745738744, "actor_loss": -40.80625341033936, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.64719796180725, "step": 131000}
{"episode_reward": 509.63962966795316, "episode": 132.0, "batch_reward": 0.31268390637636184, "critic_loss": 0.22223629819601773, "actor_loss": -40.80258123779297, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.19860053062439, "step": 132000}
{"episode_reward": 510.31383968324246, "episode": 133.0, "batch_reward": 0.31571077144145965, "critic_loss": 0.21527535915374757, "actor_loss": -40.76995722198486, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.022611379623413, "step": 133000}
{"episode_reward": 532.6600366121573, "episode": 134.0, "batch_reward": 0.3162344036102295, "critic_loss": 0.20820697181671857, "actor_loss": -40.61184327697754, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.454153060913086, "step": 134000}
{"episode_reward": 522.7377984807645, "episode": 135.0, "batch_reward": 0.3187304944694042, "critic_loss": 0.20951459174603224, "actor_loss": -40.54040544128418, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.223899126052856, "step": 135000}
{"episode_reward": 511.3242881048396, "episode": 136.0, "batch_reward": 0.3185365845263004, "critic_loss": 0.20921419448405504, "actor_loss": -40.43053876495361, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.99050235748291, "step": 136000}
{"episode_reward": 508.44892876240476, "episode": 137.0, "batch_reward": 0.3206845175027847, "critic_loss": 0.19141845010966063, "actor_loss": -40.34700315093994, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.456101655960083, "step": 137000}
{"episode_reward": 498.48155163785526, "episode": 138.0, "batch_reward": 0.3233050818145275, "critic_loss": 0.19466031968593597, "actor_loss": -40.29040998077392, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.36455488204956, "step": 138000}
{"episode_reward": 512.9051458445537, "episode": 139.0, "batch_reward": 0.3242165568768978, "critic_loss": 0.18075608511269092, "actor_loss": -40.136137168884275, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.254775285720825, "step": 139000}
{"episode_reward": 532.6842226852314, "episode": 140.0, "batch_reward": 0.3260085618197918, "critic_loss": 0.16657280030846597, "actor_loss": -40.0773163986206, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.479995489120483, "step": 140000}
{"episode_reward": 519.4322864948998, "episode": 141.0, "batch_reward": 0.32490311005711553, "critic_loss": 0.16827543070167303, "actor_loss": -39.76369789886475, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.62504863739014, "step": 141000}
{"episode_reward": 149.30377595401748, "episode": 142.0, "batch_reward": 0.32459520909190176, "critic_loss": 0.17338661918789147, "actor_loss": -39.608345581054685, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.886040925979614, "step": 142000}
{"episode_reward": 521.6994809652552, "episode": 143.0, "batch_reward": 0.3262011886239052, "critic_loss": 0.1615802334547043, "actor_loss": -39.53823444366455, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.722298860549927, "step": 143000}
{"episode_reward": 515.9715540048485, "episode": 144.0, "batch_reward": 0.3284665459394455, "critic_loss": 0.1680577561557293, "actor_loss": -39.374879440307616, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.619259119033813, "step": 144000}
{"episode_reward": 534.6051755866855, "episode": 145.0, "batch_reward": 0.3300729977786541, "critic_loss": 0.15980978026241063, "actor_loss": -39.29259135437012, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.867952585220337, "step": 145000}
{"episode_reward": 512.850214526514, "episode": 146.0, "batch_reward": 0.3299611917734146, "critic_loss": 0.16510536903887987, "actor_loss": -39.16032456970215, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.984585523605347, "step": 146000}
{"episode_reward": 517.6557467789839, "episode": 147.0, "batch_reward": 0.33132858875393867, "critic_loss": 0.172701690942049, "actor_loss": -39.13710790252686, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.092360973358154, "step": 147000}
{"episode_reward": 512.9850811801449, "episode": 148.0, "batch_reward": 0.333465466350317, "critic_loss": 0.16304155523329975, "actor_loss": -39.164347114562986, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.98084306716919, "step": 148000}
{"episode_reward": 541.0761699422237, "episode": 149.0, "batch_reward": 0.3339697775840759, "critic_loss": 0.18209330035746096, "actor_loss": -39.11513078308106, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.639480352401733, "step": 149000}
{"episode_reward": 541.6858829177673, "episode": 150.0, "batch_reward": 0.3358570048511028, "critic_loss": 0.18283036991208793, "actor_loss": -38.98054021453857, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
