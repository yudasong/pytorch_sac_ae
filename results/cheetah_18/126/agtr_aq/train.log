{"episode": 1.0, "duration": 16.469138860702515, "episode_reward": 4.231880753996205, "step": 1000}
{"episode": 2.0, "duration": 1.49397873878479, "episode_reward": 395.1450543749875, "step": 2000}
{"episode": 3.0, "batch_reward": 0.1975807288898234, "actor_loss": -41.024868788457766, "actor_target_entropy": -6.0, "alpha_value": 0.010699999250839183, "duration": 49.32039141654968, "episode_reward": 189.2983396871991, "step": 3000}
{"episode": 4.0, "batch_reward": 0.20965496945381165, "actor_loss": -40.97543144226074, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.76428985595703, "episode_reward": 285.43094038461976, "step": 4000}
{"episode": 5.0, "batch_reward": 0.22741516369581222, "actor_loss": -41.65005348968506, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.979646921157837, "episode_reward": 334.7831950348734, "step": 5000}
{"episode": 6.0, "batch_reward": 0.2426512734144926, "actor_loss": -42.42668006896972, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.567790269851685, "episode_reward": 280.82051580916726, "step": 6000}
{"episode": 7.0, "batch_reward": 0.2541048870533705, "actor_loss": -42.99011678314209, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.75105118751526, "episode_reward": 334.5623328919232, "step": 7000}
{"episode": 8.0, "batch_reward": 0.2655574029535055, "actor_loss": -43.57945760345459, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.762943744659424, "episode_reward": 320.6907261995087, "step": 8000}
{"episode": 9.0, "batch_reward": 0.27055222435295584, "actor_loss": -43.7494395904541, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.485888242721558, "episode_reward": 334.20057937326567, "step": 9000}
{"episode": 10.0, "batch_reward": 0.26901748786866664, "actor_loss": -38.80451739501953, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 3832.559599161148, "episode_reward": 160.77681656940723, "step": 10000}
{"episode": 11.0, "batch_reward": 0.2639401640444994, "actor_loss": -38.43824662017822, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 39.88526511192322, "episode_reward": 265.5531799132803, "step": 11000}
{"episode": 12.0, "batch_reward": 0.26335990710556506, "actor_loss": -35.40612483978271, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 444.24523162841797, "episode_reward": 249.24337501099347, "step": 12000}
{"episode": 13.0, "batch_reward": 0.2618151601701975, "actor_loss": -35.25502535247803, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.218865633010864, "episode_reward": 252.89107250189355, "step": 13000}
{"episode": 14.0, "batch_reward": 0.256595931276679, "actor_loss": -32.51089751434326, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 449.9460208415985, "episode_reward": 58.824581160185865, "step": 14000}
{"episode": 15.0, "batch_reward": 0.2472685162127018, "actor_loss": -31.53505872344971, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.107081651687622, "episode_reward": 251.16651009290666, "step": 15000}
{"episode": 16.0, "batch_reward": 0.24617783957719802, "actor_loss": -29.89027233505249, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 426.72294068336487, "episode_reward": 184.90658606629526, "step": 16000}
{"episode": 17.0, "batch_reward": 0.240076766833663, "actor_loss": -29.15942696380615, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.781843662261963, "episode_reward": 60.99487915247592, "step": 17000}
{"episode": 18.0, "batch_reward": 0.23066052843630314, "actor_loss": -26.74581489944458, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 408.02578926086426, "episode_reward": 76.37170238208994, "step": 18000}
{"episode": 19.0, "batch_reward": 0.2213775549083948, "actor_loss": -25.54763285446167, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.447173833847046, "episode_reward": 73.48088258969132, "step": 19000}
{"episode": 20.0, "batch_reward": 0.2157543171644211, "actor_loss": -24.122589641571047, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 409.2530243396759, "episode_reward": 179.67232263597893, "step": 20000}
{"episode": 21.0, "batch_reward": 0.21484195205569268, "actor_loss": -24.089819904327392, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 35.416245222091675, "episode_reward": 183.4911219663386, "step": 21000}
{"episode": 22.0, "batch_reward": 0.21414930030703544, "actor_loss": -23.099331199645995, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 410.58910870552063, "episode_reward": 241.20045692802603, "step": 22000}
{"episode": 23.0, "batch_reward": 0.21497825437784196, "actor_loss": -23.317244232177735, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 15.61421799659729, "episode_reward": 274.75876529717294, "step": 23000}
{"episode": 24.0, "batch_reward": 0.2184916027635336, "actor_loss": -22.986323017120363, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 408.20938444137573, "episode_reward": 297.116318653316, "step": 24000}
{"episode": 25.0, "batch_reward": 0.22129452307522296, "actor_loss": -23.374408149719237, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.603460788726807, "episode_reward": 274.44397963298724, "step": 25000}
{"episode": 26.0, "batch_reward": 0.22376515114307405, "actor_loss": -22.94196718978882, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 414.195921421051, "episode_reward": 275.58012764904896, "step": 26000}
{"episode": 27.0, "batch_reward": 0.22542448696494102, "actor_loss": -23.159126678466798, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 15.523146867752075, "episode_reward": 303.2535185668412, "step": 27000}
{"episode": 28.0, "batch_reward": 0.2285239948630333, "actor_loss": -22.83791583633423, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 437.662273645401, "episode_reward": 272.2282074521078, "step": 28000}
{"episode": 29.0, "batch_reward": 0.2279618656784296, "actor_loss": -22.845657653808594, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.152034997940063, "episode_reward": 98.21016730787476, "step": 29000}
{"episode": 30.0, "batch_reward": 0.22565165773034096, "actor_loss": -21.971504886627198, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 440.5338785648346, "episode_reward": 299.5915345667609, "step": 30000}
{"episode": 31.0, "batch_reward": 0.22843585474789144, "actor_loss": -22.350366680145264, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 35.4701189994812, "episode_reward": 274.63889798793366, "step": 31000}
{"episode": 32.0, "batch_reward": 0.22733310006558896, "actor_loss": -21.7703180809021, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 420.46832633018494, "episode_reward": 88.40257886543121, "step": 32000}
{"episode": 33.0, "batch_reward": 0.2240081425309181, "actor_loss": -21.03197055053711, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.22012424468994, "episode_reward": 253.53245868637742, "step": 33000}
{"episode": 34.0, "batch_reward": 0.2256714368313551, "actor_loss": -21.040422054290772, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 403.6628031730652, "episode_reward": 250.27487400376594, "step": 34000}
{"episode": 35.0, "batch_reward": 0.2262626755088568, "actor_loss": -21.28585414505005, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.943115711212158, "episode_reward": 168.6872354042262, "step": 35000}
{"episode": 36.0, "batch_reward": 0.22464587211608886, "actor_loss": -20.42663391113281, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 411.895925283432, "episode_reward": 285.21446014046734, "step": 36000}
{"episode": 37.0, "batch_reward": 0.2261508347094059, "actor_loss": -20.726941528320314, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 15.558077812194824, "episode_reward": 279.6289487447536, "step": 37000}
{"episode": 38.0, "batch_reward": 0.2273212507069111, "actor_loss": -21.197355346679686, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 413.64284443855286, "episode_reward": 234.08094479299814, "step": 38000}
{"episode": 39.0, "batch_reward": 0.22647044885158538, "actor_loss": -21.279799905776976, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.518993854522705, "episode_reward": 174.2917920294669, "step": 39000}
{"episode": 40.0, "batch_reward": 0.22666178861260414, "actor_loss": -21.100295917510987, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 416.21641063690186, "episode_reward": 260.39507188315326, "step": 40000}
{"episode": 41.0, "batch_reward": 0.2272104081660509, "actor_loss": -21.363139125823974, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 32.347039222717285, "episode_reward": 252.16843391368428, "step": 41000}
{"episode": 42.0, "batch_reward": 0.22837215675413608, "actor_loss": -21.874664531707765, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 412.2373843193054, "episode_reward": 295.7139987280638, "step": 42000}
{"episode": 43.0, "batch_reward": 0.2294975728094578, "actor_loss": -22.026856552124023, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.10540223121643, "episode_reward": 302.3444748075418, "step": 43000}
{"episode": 44.0, "batch_reward": 0.23168983566761017, "actor_loss": -22.474810043334962, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 405.4410719871521, "episode_reward": 250.92972697632928, "step": 44000}
{"episode": 45.0, "batch_reward": 0.23219379211962224, "actor_loss": -22.466998878479004, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.13665223121643, "episode_reward": 294.0216342093677, "step": 45000}
{"episode": 46.0, "batch_reward": 0.2337295109629631, "actor_loss": -23.37063318634033, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 419.94073247909546, "episode_reward": 283.15804746880417, "step": 46000}
{"episode": 47.0, "batch_reward": 0.23436995117366313, "actor_loss": -23.443378845214845, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.628990173339844, "episode_reward": 286.3617196266669, "step": 47000}
{"episode": 48.0, "batch_reward": 0.2356781292259693, "actor_loss": -23.493608158111574, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 406.9838705062866, "episode_reward": 296.0192302168029, "step": 48000}
{"episode": 49.0, "batch_reward": 0.23682094039022922, "actor_loss": -23.594247371673585, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.66890788078308, "episode_reward": 303.7655652297103, "step": 49000}
{"episode": 50.0, "batch_reward": 0.2383501894623041, "actor_loss": -24.22403358078003, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 439.6977334022522, "episode_reward": 300.33170039793805, "step": 50000}
{"episode": 51.0, "batch_reward": 0.23923340123891831, "actor_loss": -24.37745770263672, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 36.711719036102295, "episode_reward": 298.9329400756802, "step": 51000}
{"episode": 52.0, "batch_reward": 0.2408675829321146, "actor_loss": -24.772684116363525, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 443.32631063461304, "episode_reward": 325.2726543620603, "step": 52000}
{"episode": 53.0, "batch_reward": 0.24258068458735943, "actor_loss": -24.928218864440918, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.34779715538025, "episode_reward": 284.45483644204216, "step": 53000}
{"episode": 54.0, "batch_reward": 0.24316337698698043, "actor_loss": -25.51976732635498, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 436.97543954849243, "episode_reward": 293.571357592579, "step": 54000}
{"episode": 55.0, "batch_reward": 0.2435997595489025, "actor_loss": -25.57303443145752, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.228358030319214, "episode_reward": 316.45040934103696, "step": 55000}
{"episode": 56.0, "batch_reward": 0.24551881468296052, "actor_loss": -26.110724918365477, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 450.7870714664459, "episode_reward": 326.6625992405937, "step": 56000}
{"episode": 57.0, "batch_reward": 0.24715025655925274, "actor_loss": -26.165734119415283, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.197511911392212, "episode_reward": 334.3409494111298, "step": 57000}
{"episode": 58.0, "batch_reward": 0.24822163639962674, "actor_loss": -26.617462852478027, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 438.19574427604675, "episode_reward": 315.8053602090027, "step": 58000}
{"episode": 59.0, "batch_reward": 0.24948090685904026, "actor_loss": -26.798444442749023, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.782550573349, "episode_reward": 316.35437536808445, "step": 59000}
{"episode": 60.0, "batch_reward": 0.2502693740427494, "actor_loss": -26.977078105926513, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 444.94665122032166, "episode_reward": 333.67362368265435, "step": 60000}
{"episode": 61.0, "batch_reward": 0.2523619269579649, "actor_loss": -27.25198815917969, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 37.168614864349365, "episode_reward": 313.6867731698101, "step": 61000}
{"episode": 62.0, "batch_reward": 0.25296440909802914, "actor_loss": -27.14192939758301, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 447.33352279663086, "episode_reward": 337.21813204778107, "step": 62000}
{"episode": 63.0, "batch_reward": 0.2538881841897965, "actor_loss": -27.26998781967163, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.568363666534424, "episode_reward": 337.2391039639435, "step": 63000}
{"episode": 64.0, "batch_reward": 0.25597587575018405, "actor_loss": -27.120860485076904, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 444.8409125804901, "episode_reward": 332.9611779510351, "step": 64000}
{"episode": 65.0, "batch_reward": 0.2573283384591341, "actor_loss": -27.30126633453369, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.060827255249023, "episode_reward": 338.68316309158354, "step": 65000}
{"episode": 66.0, "batch_reward": 0.2585164106488228, "actor_loss": -27.817328037261962, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 441.8223943710327, "episode_reward": 327.3498001768372, "step": 66000}
{"episode": 67.0, "batch_reward": 0.2593112242817879, "actor_loss": -27.930234550476076, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.058470249176025, "episode_reward": 327.71719908296024, "step": 67000}
{"episode": 68.0, "batch_reward": 0.26011221526563166, "actor_loss": -27.756665950775147, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 447.8550190925598, "episode_reward": 242.50087054814637, "step": 68000}
{"episode": 69.0, "batch_reward": 0.2596850444227457, "actor_loss": -27.643000827789308, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.757684230804443, "episode_reward": 310.4952873525963, "step": 69000}
{"episode": 70.0, "batch_reward": 0.2608871958553791, "actor_loss": -27.842156257629394, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 447.27841806411743, "episode_reward": 346.66469641486594, "step": 70000}
{"episode": 71.0, "batch_reward": 0.2617616997361183, "actor_loss": -27.964231182098388, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 36.893786668777466, "episode_reward": 329.6201399683795, "step": 71000}
{"episode": 72.0, "batch_reward": 0.2628866376578808, "actor_loss": -28.344546760559084, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 442.4232256412506, "episode_reward": 350.45757647677254, "step": 72000}
{"episode": 73.0, "batch_reward": 0.2640238984823227, "actor_loss": -28.42988161087036, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.40237021446228, "episode_reward": 359.74031018549044, "step": 73000}
{"episode": 74.0, "batch_reward": 0.2655159312784672, "actor_loss": -29.009689819335936, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 450.0441002845764, "episode_reward": 339.8726651996073, "step": 74000}
{"episode": 75.0, "batch_reward": 0.26660895846784116, "actor_loss": -29.17770807647705, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.612502813339233, "episode_reward": 337.46424245743447, "step": 75000}
{"episode": 76.0, "batch_reward": 0.2670687864869833, "actor_loss": -28.848373424530028, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 444.32358837127686, "episode_reward": 349.7100676268755, "step": 76000}
{"episode": 77.0, "batch_reward": 0.26917683920264246, "actor_loss": -29.11485470199585, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.17424201965332, "episode_reward": 340.0258568499663, "step": 77000}
{"episode": 78.0, "batch_reward": 0.2698139848858118, "actor_loss": -29.21205721282959, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 447.40947675704956, "episode_reward": 325.51439563303325, "step": 78000}
{"episode": 79.0, "batch_reward": 0.2696959841698408, "actor_loss": -29.11341879272461, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.413819313049316, "episode_reward": 332.01506646868114, "step": 79000}
{"episode": 80.0, "batch_reward": 0.2712484628856182, "actor_loss": -29.499958236694336, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 442.88935375213623, "episode_reward": 348.1480750233319, "step": 80000}
{"episode": 81.0, "batch_reward": 0.2719952665865421, "actor_loss": -29.541517253875732, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 34.399518728256226, "episode_reward": 356.4749080650512, "step": 81000}
{"episode": 82.0, "batch_reward": 0.2722435168772936, "actor_loss": -29.181721523284914, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 445.68268060684204, "episode_reward": 353.1914862183913, "step": 82000}
{"episode": 83.0, "batch_reward": 0.2735126848071814, "actor_loss": -29.40145263671875, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.310017347335815, "episode_reward": 342.3895832677885, "step": 83000}
{"episode": 84.0, "batch_reward": 0.2748262750506401, "actor_loss": -29.63797426223755, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 442.8002276420593, "episode_reward": 343.6937913994576, "step": 84000}
{"episode": 85.0, "batch_reward": 0.2751598863899708, "actor_loss": -29.662494285583495, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.192728281021118, "episode_reward": 335.7715466699842, "step": 85000}
{"episode": 86.0, "batch_reward": 0.2763363115787506, "actor_loss": -30.12214485549927, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 449.86702609062195, "episode_reward": 330.9452266303727, "step": 86000}
{"episode": 87.0, "batch_reward": 0.2769798756688833, "actor_loss": -30.18273546218872, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.837461948394775, "episode_reward": 340.6251503930385, "step": 87000}
{"episode": 88.0, "batch_reward": 0.2777232434153557, "actor_loss": -30.115226886749266, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 418.34335947036743, "episode_reward": 319.6514625890106, "step": 88000}
{"episode": 89.0, "batch_reward": 0.27762550976872447, "actor_loss": -30.00197650527954, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.462974309921265, "episode_reward": 316.30091196543873, "step": 89000}
{"episode": 90.0, "batch_reward": 0.2783620655834675, "actor_loss": -30.222718479156494, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 424.4365425109863, "episode_reward": 356.14308954565536, "step": 90000}
{"episode": 91.0, "batch_reward": 0.2795002917051315, "actor_loss": -30.3278878326416, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 39.45208382606506, "episode_reward": 364.402475152036, "step": 91000}
{"episode": 92.0, "batch_reward": 0.27991124722361566, "actor_loss": -30.154648864746093, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 438.4231958389282, "episode_reward": 357.9854297534842, "step": 92000}
{"episode": 93.0, "batch_reward": 0.2812235015630722, "actor_loss": -30.34729067993164, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.52672505378723, "episode_reward": 334.9619837873798, "step": 93000}
{"episode": 94.0, "batch_reward": 0.2813430334925652, "actor_loss": -30.231527099609377, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 444.2274808883667, "episode_reward": 332.22401782127594, "step": 94000}
{"episode": 95.0, "batch_reward": 0.2822164697647095, "actor_loss": -30.263318054199217, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.098637104034424, "episode_reward": 336.73510419101746, "step": 95000}
{"episode": 96.0, "batch_reward": 0.2828399102985859, "actor_loss": -30.245346576690675, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 442.6350541114807, "episode_reward": 348.0130065574658, "step": 96000}
{"episode": 97.0, "batch_reward": 0.2836646882891655, "actor_loss": -30.353951679229738, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.17523717880249, "episode_reward": 362.4334918623443, "step": 97000}
{"episode": 98.0, "batch_reward": 0.28441937193274497, "actor_loss": -29.6577982673645, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 447.14804458618164, "episode_reward": 356.68806017899607, "step": 98000}
{"episode": 99.0, "batch_reward": 0.28507022601366044, "actor_loss": -29.840639492034914, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.70036554336548, "episode_reward": 345.00799977583233, "step": 99000}
{"episode": 100.0, "batch_reward": 0.2850055932700634, "actor_loss": -29.339553791046143, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 447.98405408859253, "episode_reward": 347.58527344113645, "step": 100000}
{"episode": 101.0, "batch_reward": 0.2863756625056267, "actor_loss": -29.538807819366454, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 32.71847987174988, "episode_reward": 345.98968211492695, "step": 101000}
{"episode": 102.0, "batch_reward": 0.2866628786921501, "actor_loss": -29.33690739440918, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 406.94196581840515, "episode_reward": 322.53531456016333, "step": 102000}
{"episode": 103.0, "batch_reward": 0.2866952792108059, "actor_loss": -29.35985701751709, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.57848310470581, "episode_reward": 337.0837624259686, "step": 103000}
{"episode": 104.0, "batch_reward": 0.28753229713439943, "actor_loss": -28.912636474609375, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 417.85604882240295, "episode_reward": 317.78793225010713, "step": 104000}
{"episode": 105.0, "batch_reward": 0.2878853493630886, "actor_loss": -28.96611716079712, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.414124011993408, "episode_reward": 303.0744259231525, "step": 105000}
{"episode": 106.0, "batch_reward": 0.2882680334150791, "actor_loss": -28.976055866241456, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 406.0829164981842, "episode_reward": 230.23614863768591, "step": 106000}
{"episode": 107.0, "batch_reward": 0.28801746186614036, "actor_loss": -28.870449085235595, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.50511121749878, "episode_reward": 348.716874192026, "step": 107000}
{"episode": 108.0, "batch_reward": 0.2886324755847454, "actor_loss": -28.83461170578003, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 411.07585406303406, "episode_reward": 341.87863552490694, "step": 108000}
{"episode": 109.0, "batch_reward": 0.288588604927063, "actor_loss": -28.842904293060304, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.38258171081543, "episode_reward": 327.3883282450235, "step": 109000}
{"episode": 110.0, "batch_reward": 0.28858083647489546, "actor_loss": -28.603526248931885, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 409.9188823699951, "episode_reward": 352.418692685698, "step": 110000}
{"episode": 111.0, "batch_reward": 0.2893209328651428, "actor_loss": -28.68502828979492, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 34.05919361114502, "episode_reward": 358.98086278899603, "step": 111000}
{"episode": 112.0, "batch_reward": 0.29005989161133766, "actor_loss": -28.846749530792238, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 413.8748712539673, "episode_reward": 346.89204128729585, "step": 112000}
{"episode": 113.0, "batch_reward": 0.2905044794082642, "actor_loss": -28.998530872344972, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.181689739227295, "episode_reward": 367.6457865062179, "step": 113000}
{"episode": 114.0, "batch_reward": 0.29137154334783555, "actor_loss": -29.19566147994995, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 408.91705322265625, "episode_reward": 350.1671755058675, "step": 114000}
{"episode": 115.0, "batch_reward": 0.2922373246252537, "actor_loss": -29.242322311401367, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.620861053466797, "episode_reward": 336.8799664387839, "step": 115000}
{"episode": 116.0, "batch_reward": 0.29234135138988493, "actor_loss": -29.465578742980956, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 424.46377062797546, "episode_reward": 346.95686963319133, "step": 116000}
{"episode": 117.0, "batch_reward": 0.29303700622916223, "actor_loss": -29.387210720062257, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.35939931869507, "episode_reward": 352.4939622912342, "step": 117000}
{"episode": 118.0, "batch_reward": 0.29358531391620635, "actor_loss": -29.440558601379394, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 406.31373834609985, "episode_reward": 338.6485004623677, "step": 118000}
{"episode": 119.0, "batch_reward": 0.29354899471998214, "actor_loss": -29.416990116119386, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.663431644439697, "episode_reward": 351.6203323171843, "step": 119000}
{"episode": 120.0, "batch_reward": 0.2940556401759386, "actor_loss": -30.030256282806395, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 408.25010681152344, "episode_reward": 332.6087012243471, "step": 120000}
{"episode": 121.0, "batch_reward": 0.2945318702161312, "actor_loss": -30.10141291427612, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 32.269654512405396, "episode_reward": 325.28956539748594, "step": 121000}
{"episode": 122.0, "batch_reward": 0.2946845987737179, "actor_loss": -29.973921600341797, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 408.4229063987732, "episode_reward": 370.45449686498574, "step": 122000}
{"episode": 123.0, "batch_reward": 0.29409882909059526, "actor_loss": -29.898263069152833, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.72532868385315, "episode_reward": 59.87067695330632, "step": 123000}
{"episode": 124.0, "batch_reward": 0.2929332999885082, "actor_loss": -29.852881950378418, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 408.2297101020813, "episode_reward": 352.1891898432687, "step": 124000}
{"episode": 125.0, "batch_reward": 0.29368584260344505, "actor_loss": -29.937348857879638, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 15.822901248931885, "episode_reward": 351.3226063959013, "step": 125000}
{"episode": 126.0, "batch_reward": 0.29489966946840285, "actor_loss": -30.257414825439454, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 404.8057985305786, "episode_reward": 354.77144683760156, "step": 126000}
{"episode": 127.0, "batch_reward": 0.2949171184003353, "actor_loss": -30.219895931243897, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.704939365386963, "episode_reward": 339.49065064346894, "step": 127000}
{"episode": 128.0, "batch_reward": 0.2954463400542736, "actor_loss": -30.434988430023193, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 410.3724217414856, "episode_reward": 354.3139496644299, "step": 128000}
{"episode": 129.0, "batch_reward": 0.2955070783495903, "actor_loss": -30.37290758514404, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 15.861751079559326, "episode_reward": 342.43182650742153, "step": 129000}
{"episode": 130.0, "batch_reward": 0.296261027097702, "actor_loss": -30.476053398132326, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 443.6178069114685, "episode_reward": 344.40507464851646, "step": 130000}
{"episode": 131.0, "batch_reward": 0.29637435007095336, "actor_loss": -30.42978519821167, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 36.56618905067444, "episode_reward": 341.4411454525172, "step": 131000}
{"episode": 132.0, "batch_reward": 0.2966567507088184, "actor_loss": -30.433402683258056, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 439.7386553287506, "episode_reward": 332.59500014227996, "step": 132000}
{"episode": 133.0, "batch_reward": 0.2970142853856087, "actor_loss": -30.523357860565184, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.079871892929077, "episode_reward": 310.7594880936448, "step": 133000}
{"episode": 134.0, "batch_reward": 0.29670578268170356, "actor_loss": -30.42010863494873, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 447.9411380290985, "episode_reward": 343.542342751977, "step": 134000}
{"episode": 135.0, "batch_reward": 0.2976506688594818, "actor_loss": -30.55078681564331, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.68001699447632, "episode_reward": 348.80411127245475, "step": 135000}
{"episode": 136.0, "batch_reward": 0.2981057151556015, "actor_loss": -30.796523319244386, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 451.12949109077454, "episode_reward": 348.09185783987556, "step": 136000}
{"episode": 137.0, "batch_reward": 0.2980180054605007, "actor_loss": -30.739209243774415, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.31596612930298, "episode_reward": 349.2856291598682, "step": 137000}
{"episode": 138.0, "batch_reward": 0.2988746213912964, "actor_loss": -30.70047857284546, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 446.20926308631897, "episode_reward": 357.60526833027944, "step": 138000}
{"episode": 139.0, "batch_reward": 0.29895369622111323, "actor_loss": -30.79900524520874, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.53886890411377, "episode_reward": 350.09596392483115, "step": 139000}
{"episode": 140.0, "batch_reward": 0.29934973961114886, "actor_loss": -31.049299789428712, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 448.73138523101807, "episode_reward": 351.06984994958384, "step": 140000}
{"episode": 141.0, "batch_reward": 0.29970092949271204, "actor_loss": -31.155846797943116, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 34.425363063812256, "episode_reward": 346.51063592926937, "step": 141000}
{"episode": 142.0, "batch_reward": 0.30020635488629344, "actor_loss": -31.03782357788086, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 447.2478358745575, "episode_reward": 331.42973672602807, "step": 142000}
{"episode": 143.0, "batch_reward": 0.3002955583631992, "actor_loss": -31.08611962890625, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.798590898513794, "episode_reward": 332.4842481083999, "step": 143000}
{"episode": 144.0, "batch_reward": 0.30053536999225616, "actor_loss": -31.077312419891356, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 442.435161113739, "episode_reward": 343.50121653667884, "step": 144000}
{"episode": 145.0, "batch_reward": 0.3009954261481762, "actor_loss": -31.051182140350342, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 19.133058309555054, "episode_reward": 330.1304372117323, "step": 145000}
{"episode": 146.0, "batch_reward": 0.3009750523865223, "actor_loss": -30.674371852874756, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 449.3737008571625, "episode_reward": 336.69332770103654, "step": 146000}
{"episode": 147.0, "batch_reward": 0.3012060789167881, "actor_loss": -30.752208442687987, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.745853662490845, "episode_reward": 351.9528417849911, "step": 147000}
{"episode": 148.0, "batch_reward": 0.3015705603957176, "actor_loss": -31.18470213317871, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 452.3959581851959, "episode_reward": 338.81405684889523, "step": 148000}
{"episode": 149.0, "batch_reward": 0.30183387362957, "actor_loss": -31.35812574005127, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.729654550552368, "episode_reward": 353.97151395044693, "step": 149000}
{"episode": 150.0, "batch_reward": 0.30178617003560065, "actor_loss": -30.757127002716064, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "step": 150000}
