{"episode_reward": 0.0, "episode": 1.0, "duration": 13.862995624542236, "step": 1000}
{"episode_reward": 4.231880753996205, "episode": 2.0, "duration": 1.2581543922424316, "step": 2000}
{"episode_reward": 395.1450543749875, "episode": 3.0, "batch_reward": 0.18907703134557652, "critic_loss": 0.050773455597716156, "actor_loss": -32.25830416057576, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 74.31887006759644, "step": 3000}
{"episode_reward": 20.40639614528827, "episode": 4.0, "batch_reward": 0.12238106076419354, "critic_loss": 0.026229110023006798, "actor_loss": -28.57676628303528, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.22294783592224, "step": 4000}
{"episode_reward": 7.858670953037585, "episode": 5.0, "batch_reward": 0.09770829483494163, "critic_loss": 0.022598272336646914, "actor_loss": -25.254423486709594, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.180075645446777, "step": 5000}
{"episode_reward": 11.27209816280049, "episode": 6.0, "batch_reward": 0.08578813641518354, "critic_loss": 0.02758540144003928, "actor_loss": -25.49711678504944, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.413978576660156, "step": 6000}
{"episode_reward": 35.52393199010761, "episode": 7.0, "batch_reward": 0.07531878380104899, "critic_loss": 0.019078534292057157, "actor_loss": -24.720132701396942, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.451791524887085, "step": 7000}
{"episode_reward": 15.89343978052294, "episode": 8.0, "batch_reward": 0.06678290128149092, "critic_loss": 0.020923538387753068, "actor_loss": -22.59976980829239, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.736253261566162, "step": 8000}
{"episode_reward": 10.551534212044308, "episode": 9.0, "batch_reward": 0.05938454543799162, "critic_loss": 0.027300924696959557, "actor_loss": -22.343759297370912, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.10780358314514, "step": 9000}
{"episode_reward": 8.846459093041897, "episode": 10.0, "batch_reward": 0.056440774828195574, "critic_loss": 0.0432404421325773, "actor_loss": -20.82151585960388, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.14240026473999, "step": 10000}
{"episode_reward": 44.06006967871134, "episode": 11.0, "batch_reward": 0.05432033082842827, "critic_loss": 0.055938240287825465, "actor_loss": -21.424767905235292, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.72865605354309, "step": 11000}
{"episode_reward": 24.863771962400662, "episode": 12.0, "batch_reward": 0.053320883942767974, "critic_loss": 0.06762593676522374, "actor_loss": -19.22252626180649, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.62898087501526, "step": 12000}
{"episode_reward": 33.8510204876123, "episode": 13.0, "batch_reward": 0.053576294537633656, "critic_loss": 0.06703152337670326, "actor_loss": -19.821100611686706, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.03636622428894, "step": 13000}
{"episode_reward": 62.83081185006985, "episode": 14.0, "batch_reward": 0.050672015385702256, "critic_loss": 0.06227770463563502, "actor_loss": -18.66303515434265, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.477188110351562, "step": 14000}
{"episode_reward": 20.15924366912639, "episode": 15.0, "batch_reward": 0.04970391827262938, "critic_loss": 0.06258321249857544, "actor_loss": -18.649238735675812, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.09261441230774, "step": 15000}
{"episode_reward": 27.2783940735468, "episode": 16.0, "batch_reward": 0.049914802119135855, "critic_loss": 0.08401940931379795, "actor_loss": -14.728586406707764, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.283058881759644, "step": 16000}
{"episode_reward": 68.04173574330743, "episode": 17.0, "batch_reward": 0.04891374975256622, "critic_loss": 0.07498194147646427, "actor_loss": -14.877354051738978, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.49786138534546, "step": 17000}
{"episode_reward": 24.340659376498063, "episode": 18.0, "batch_reward": 0.04790541077964008, "critic_loss": 0.06566953392513096, "actor_loss": -14.358345930367708, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.203125, "step": 18000}
{"episode_reward": 33.44446455147493, "episode": 19.0, "batch_reward": 0.047418815959244964, "critic_loss": 0.06566020458191633, "actor_loss": -13.845402837499977, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.950277090072632, "step": 19000}
{"episode_reward": 29.607181240838013, "episode": 20.0, "batch_reward": 0.05067156710848212, "critic_loss": 0.08597791050374508, "actor_loss": -14.691995401211082, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.326869249343872, "step": 20000}
{"episode_reward": 165.42412066718998, "episode": 21.0, "batch_reward": 0.05279096214100718, "critic_loss": 0.08924104707688094, "actor_loss": -13.88520489448309, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.066497802734375, "step": 21000}
{"episode_reward": 57.92542774229287, "episode": 22.0, "batch_reward": 0.057053645506501195, "critic_loss": 0.09846045712567866, "actor_loss": -14.59846499145031, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.375723600387573, "step": 22000}
{"episode_reward": 204.68386744840956, "episode": 23.0, "batch_reward": 0.05989265152066946, "critic_loss": 0.08955882430821657, "actor_loss": -13.97017947870493, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.447720527648926, "step": 23000}
{"episode_reward": 39.44601117576094, "episode": 24.0, "batch_reward": 0.058891251266002656, "critic_loss": 0.08711427472531795, "actor_loss": -13.719814837396145, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.165756702423096, "step": 24000}
{"episode_reward": 47.106773523948625, "episode": 25.0, "batch_reward": 0.058968864813447, "critic_loss": 0.08424195975251496, "actor_loss": -13.357333695098758, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.462841272354126, "step": 25000}
{"episode_reward": 57.55871801046196, "episode": 26.0, "batch_reward": 0.05862764640524983, "critic_loss": 0.09391444481350482, "actor_loss": -12.513090951442718, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.88583493232727, "step": 26000}
{"episode_reward": 44.34472310306393, "episode": 27.0, "batch_reward": 0.05898762877285481, "critic_loss": 0.12312714295461774, "actor_loss": -13.035393176317214, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.37682580947876, "step": 27000}
{"episode_reward": 65.81665275431472, "episode": 28.0, "batch_reward": 0.058161909356713296, "critic_loss": 0.12353545064106583, "actor_loss": -11.918960973620415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.890032291412354, "step": 28000}
{"episode_reward": 71.83728406452826, "episode": 29.0, "batch_reward": 0.05871426587551832, "critic_loss": 0.14038033942878247, "actor_loss": -12.638823362827301, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.128329277038574, "step": 29000}
{"episode_reward": 71.68765480451852, "episode": 30.0, "batch_reward": 0.059064900163561106, "critic_loss": 0.16005951995775103, "actor_loss": -12.24589251112938, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.234105348587036, "step": 30000}
{"episode_reward": 36.05819322745404, "episode": 31.0, "batch_reward": 0.05845178277045488, "critic_loss": 0.17970504799112677, "actor_loss": -11.607979922056199, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.800517320632935, "step": 31000}
{"episode_reward": 44.27674657050169, "episode": 32.0, "batch_reward": 0.05789954291284084, "critic_loss": 0.16634628143534064, "actor_loss": -11.44673000884056, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.689852476119995, "step": 32000}
{"episode_reward": 32.171276972064874, "episode": 33.0, "batch_reward": 0.06035310781002045, "critic_loss": 0.20338502409681677, "actor_loss": -12.008722848415374, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.58702325820923, "step": 33000}
{"episode_reward": 205.07251382214804, "episode": 34.0, "batch_reward": 0.06375903546437621, "critic_loss": 0.21896494195610286, "actor_loss": -11.492342057704926, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.944517612457275, "step": 34000}
{"episode_reward": 166.85222015427965, "episode": 35.0, "batch_reward": 0.06478733662888407, "critic_loss": 0.20690043654665352, "actor_loss": -11.916614883422852, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.49396538734436, "step": 35000}
{"episode_reward": 49.94812877517614, "episode": 36.0, "batch_reward": 0.06560042686015367, "critic_loss": 0.23326957729458808, "actor_loss": -11.074921527385712, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.71388053894043, "step": 36000}
{"episode_reward": 99.11715551938319, "episode": 37.0, "batch_reward": 0.06631181111559271, "critic_loss": 0.24502939423173667, "actor_loss": -11.366158727645875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.660293102264404, "step": 37000}
{"episode_reward": 114.12756128604367, "episode": 38.0, "batch_reward": 0.066291059859097, "critic_loss": 0.19896180922165513, "actor_loss": -12.155706440925599, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.49177598953247, "step": 38000}
{"episode_reward": 56.53940919288729, "episode": 39.0, "batch_reward": 0.06926770729199051, "critic_loss": 0.23316987865418196, "actor_loss": -11.432578187942505, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.88054895401001, "step": 39000}
{"episode_reward": 302.34987239288074, "episode": 40.0, "batch_reward": 0.07269028120487929, "critic_loss": 0.24950619318336248, "actor_loss": -11.707969217300414, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.820342779159546, "step": 40000}
{"episode_reward": 84.47783654639288, "episode": 41.0, "batch_reward": 0.07444596749171614, "critic_loss": 0.24043252477794885, "actor_loss": -11.358166051864623, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.27075815200806, "step": 41000}
{"episode_reward": 140.25496765403798, "episode": 42.0, "batch_reward": 0.07520959095656872, "critic_loss": 0.23161496412009, "actor_loss": -11.715516377449037, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.421163320541382, "step": 42000}
{"episode_reward": 107.82792276947724, "episode": 43.0, "batch_reward": 0.075905010137707, "critic_loss": 0.2287412192299962, "actor_loss": -11.281824416160584, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.47160530090332, "step": 43000}
{"episode_reward": 93.85100849722403, "episode": 44.0, "batch_reward": 0.07661683429777623, "critic_loss": 0.22523688115924598, "actor_loss": -11.173718620300294, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.530714750289917, "step": 44000}
{"episode_reward": 159.29007245987168, "episode": 45.0, "batch_reward": 0.07940124142542482, "critic_loss": 0.2245928057357669, "actor_loss": -11.557554982185364, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.70026421546936, "step": 45000}
{"episode_reward": 221.41320551986516, "episode": 46.0, "batch_reward": 0.08168126591667534, "critic_loss": 0.22400467249006034, "actor_loss": -11.60848133945465, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.08979606628418, "step": 46000}
{"episode_reward": 200.47629429510116, "episode": 47.0, "batch_reward": 0.08395834029838443, "critic_loss": 0.2569192247763276, "actor_loss": -11.628495589256287, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.546554565429688, "step": 47000}
{"episode_reward": 157.8383109600017, "episode": 48.0, "batch_reward": 0.08684414776414633, "critic_loss": 0.25040391720086336, "actor_loss": -11.98115154838562, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.14548897743225, "step": 48000}
{"episode_reward": 175.49612648355517, "episode": 49.0, "batch_reward": 0.08883148097246886, "critic_loss": 0.2494543538838625, "actor_loss": -11.96785013103485, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.653090953826904, "step": 49000}
{"episode_reward": 188.51465056571337, "episode": 50.0, "batch_reward": 0.09030735901743174, "critic_loss": 0.24192498963326214, "actor_loss": -12.46566259765625, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.389904975891113, "step": 50000}
{"episode_reward": 299.9846933897064, "episode": 51.0, "batch_reward": 0.093399373665452, "critic_loss": 0.23440877918154002, "actor_loss": -12.621869967460633, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.922539710998535, "step": 51000}
{"episode_reward": 62.209987668341185, "episode": 52.0, "batch_reward": 0.0950879001095891, "critic_loss": 0.27584018766134977, "actor_loss": -13.274670473098755, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.32140278816223, "step": 52000}
{"episode_reward": 323.2754102621362, "episode": 53.0, "batch_reward": 0.09654726723954081, "critic_loss": 0.24358075881749391, "actor_loss": -14.418888618469238, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.54444980621338, "step": 53000}
{"episode_reward": 57.96508136666049, "episode": 54.0, "batch_reward": 0.09788091319054365, "critic_loss": 0.20468654615432025, "actor_loss": -14.090378677368165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.699862718582153, "step": 54000}
{"episode_reward": 307.4170080263052, "episode": 55.0, "batch_reward": 0.10139978028088809, "critic_loss": 0.19923405484855175, "actor_loss": -14.767070043563843, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.579196453094482, "step": 55000}
{"episode_reward": 359.94929835194193, "episode": 56.0, "batch_reward": 0.10548824579268694, "critic_loss": 0.19396329686790706, "actor_loss": -15.571415157318116, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.722846269607544, "step": 56000}
{"episode_reward": 291.1173828687407, "episode": 57.0, "batch_reward": 0.11008398890495301, "critic_loss": 0.21522422727942467, "actor_loss": -15.594913772583007, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.039502382278442, "step": 57000}
{"episode_reward": 351.7190293678592, "episode": 58.0, "batch_reward": 0.11296418087929487, "critic_loss": 0.21980376175045968, "actor_loss": -16.434625663757323, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.12453818321228, "step": 58000}
{"episode_reward": 93.47309285153122, "episode": 59.0, "batch_reward": 0.1134875895678997, "critic_loss": 0.20463935887813567, "actor_loss": -16.60183506202698, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.987838983535767, "step": 59000}
{"episode_reward": 340.68467609722944, "episode": 60.0, "batch_reward": 0.11656686030328274, "critic_loss": 0.2062480740994215, "actor_loss": -16.881691690444946, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.466218948364258, "step": 60000}
{"episode_reward": 180.30501425118737, "episode": 61.0, "batch_reward": 0.11927912368625403, "critic_loss": 0.19771014065295459, "actor_loss": -16.913788080215454, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.912607192993164, "step": 61000}
{"episode_reward": 360.7260002748485, "episode": 62.0, "batch_reward": 0.1234725583344698, "critic_loss": 0.19558373209834098, "actor_loss": -17.739433170318602, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.98491072654724, "step": 62000}
{"episode_reward": 305.9781310339623, "episode": 63.0, "batch_reward": 0.12502219288051128, "critic_loss": 0.19581620740890504, "actor_loss": -17.864499586105346, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.490081071853638, "step": 63000}
{"episode_reward": 367.07584192468073, "episode": 64.0, "batch_reward": 0.12919829389452933, "critic_loss": 0.19461714757978915, "actor_loss": -18.20054668235779, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.297466039657593, "step": 64000}
{"episode_reward": 364.5932214232411, "episode": 65.0, "batch_reward": 0.1335656130760908, "critic_loss": 0.18595801717042923, "actor_loss": -18.58405793762207, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.509973764419556, "step": 65000}
{"episode_reward": 233.65473484976886, "episode": 66.0, "batch_reward": 0.13274116434901953, "critic_loss": 0.17551040200144052, "actor_loss": -18.443087324142457, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.810325860977173, "step": 66000}
{"episode_reward": 89.58793718812372, "episode": 67.0, "batch_reward": 0.13338212881237269, "critic_loss": 0.1689445133805275, "actor_loss": -18.44979479598999, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.63072657585144, "step": 67000}
{"episode_reward": 270.444466399068, "episode": 68.0, "batch_reward": 0.13705074983090162, "critic_loss": 0.16707588870823384, "actor_loss": -18.334399971008303, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.229886531829834, "step": 68000}
{"episode_reward": 353.4622434501577, "episode": 69.0, "batch_reward": 0.14058922345936298, "critic_loss": 0.17273642069101333, "actor_loss": -18.512860654830934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.458879709243774, "step": 69000}
{"episode_reward": 387.99745876841047, "episode": 70.0, "batch_reward": 0.14267080300301313, "critic_loss": 0.17786130186915397, "actor_loss": -18.744942974090577, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.093005418777466, "step": 70000}
{"episode_reward": 378.4297247258455, "episode": 71.0, "batch_reward": 0.1457261413410306, "critic_loss": 0.18687909612059594, "actor_loss": -19.41168808555603, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.6656174659729, "step": 71000}
{"episode_reward": 392.33085670117185, "episode": 72.0, "batch_reward": 0.14954167792201042, "critic_loss": 0.17065532367676498, "actor_loss": -19.29803681564331, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.95959234237671, "step": 72000}
{"episode_reward": 378.6698547482699, "episode": 73.0, "batch_reward": 0.15220130810141563, "critic_loss": 0.1760834394097328, "actor_loss": -19.636882581710815, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.110081672668457, "step": 73000}
{"episode_reward": 252.8713703655984, "episode": 74.0, "batch_reward": 0.1545454188808799, "critic_loss": 0.17884183117002247, "actor_loss": -19.91954618835449, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.844906330108643, "step": 74000}
{"episode_reward": 429.82308324864056, "episode": 75.0, "batch_reward": 0.15819050738960505, "critic_loss": 0.17111299165338278, "actor_loss": -19.968816339492797, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.96515202522278, "step": 75000}
{"episode_reward": 398.79926440245276, "episode": 76.0, "batch_reward": 0.16156768659502269, "critic_loss": 0.17555074118077754, "actor_loss": -20.322672136306764, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.913037061691284, "step": 76000}
{"episode_reward": 442.2660355112355, "episode": 77.0, "batch_reward": 0.1648196315690875, "critic_loss": 0.17193348405510187, "actor_loss": -20.633815589904785, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.767062664031982, "step": 77000}
{"episode_reward": 391.12230289993795, "episode": 78.0, "batch_reward": 0.16769978187978268, "critic_loss": 0.16883176933974028, "actor_loss": -20.962973920822144, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.718984842300415, "step": 78000}
{"episode_reward": 411.40543652732737, "episode": 79.0, "batch_reward": 0.17090294694155456, "critic_loss": 0.16927082050591707, "actor_loss": -20.83130619049072, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.73993968963623, "step": 79000}
{"episode_reward": 429.42584276187114, "episode": 80.0, "batch_reward": 0.17349374510347843, "critic_loss": 0.1759971093311906, "actor_loss": -21.052906829833983, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.758132934570312, "step": 80000}
{"episode_reward": 427.3951656751827, "episode": 81.0, "batch_reward": 0.1784389633089304, "critic_loss": 0.1789602615609765, "actor_loss": -21.41158842086792, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.823302268981934, "step": 81000}
{"episode_reward": 443.5204712679706, "episode": 82.0, "batch_reward": 0.17962548132240772, "critic_loss": 0.18055246206372977, "actor_loss": -21.47514345550537, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.132161140441895, "step": 82000}
{"episode_reward": 152.83189076319636, "episode": 83.0, "batch_reward": 0.1796905979514122, "critic_loss": 0.18951544449478389, "actor_loss": -21.42723544692993, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.482576847076416, "step": 83000}
{"episode_reward": 435.7831449987932, "episode": 84.0, "batch_reward": 0.18251627638936044, "critic_loss": 0.18600453670322895, "actor_loss": -21.250453857421874, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.513386011123657, "step": 84000}
{"episode_reward": 440.75806229809007, "episode": 85.0, "batch_reward": 0.18652774108946324, "critic_loss": 0.19124574874341488, "actor_loss": -22.089635581970214, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.021223545074463, "step": 85000}
{"episode_reward": 477.3221844751117, "episode": 86.0, "batch_reward": 0.18936140318214895, "critic_loss": 0.20998620565980672, "actor_loss": -22.145840015411377, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.870879888534546, "step": 86000}
{"episode_reward": 113.8826082412105, "episode": 87.0, "batch_reward": 0.18900595395267009, "critic_loss": 0.20003226996958257, "actor_loss": -22.33221869659424, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.732039213180542, "step": 87000}
{"episode_reward": 434.21014459304104, "episode": 88.0, "batch_reward": 0.19237600991129875, "critic_loss": 0.18997122524678708, "actor_loss": -22.733416370391847, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.03304386138916, "step": 88000}
{"episode_reward": 418.3476617120336, "episode": 89.0, "batch_reward": 0.19409981149435043, "critic_loss": 0.2057300887182355, "actor_loss": -23.242900566101074, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.519784450531006, "step": 89000}
{"episode_reward": 439.81352998757785, "episode": 90.0, "batch_reward": 0.1967851858139038, "critic_loss": 0.20238929533213376, "actor_loss": -23.494391952514647, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.756652355194092, "step": 90000}
{"episode_reward": 460.8114216528168, "episode": 91.0, "batch_reward": 0.20018576750159264, "critic_loss": 0.19733701564371586, "actor_loss": -23.788071739196777, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.750221490859985, "step": 91000}
{"episode_reward": 463.56205925340396, "episode": 92.0, "batch_reward": 0.20266686049103738, "critic_loss": 0.19216677918285133, "actor_loss": -23.95463098526001, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.538195848464966, "step": 92000}
{"episode_reward": 438.32973180605103, "episode": 93.0, "batch_reward": 0.20511616852879525, "critic_loss": 0.18617706645280122, "actor_loss": -23.819277687072756, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.87466788291931, "step": 93000}
{"episode_reward": 430.93472464888976, "episode": 94.0, "batch_reward": 0.2086666436046362, "critic_loss": 0.18770757445693015, "actor_loss": -24.139757663726808, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.734415292739868, "step": 94000}
{"episode_reward": 467.915082344995, "episode": 95.0, "batch_reward": 0.2104234869480133, "critic_loss": 0.18581152066588402, "actor_loss": -24.33989631652832, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.84363579750061, "step": 95000}
{"episode_reward": 441.8019044982274, "episode": 96.0, "batch_reward": 0.21301346252858638, "critic_loss": 0.19944541251659392, "actor_loss": -24.81343698120117, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.472156286239624, "step": 96000}
{"episode_reward": 417.4984540617319, "episode": 97.0, "batch_reward": 0.2154019902795553, "critic_loss": 0.21039891777187586, "actor_loss": -24.877702201843263, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.768107652664185, "step": 97000}
{"episode_reward": 471.25422004952424, "episode": 98.0, "batch_reward": 0.21804778704047204, "critic_loss": 0.19835207203775646, "actor_loss": -24.996304206848144, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.380515813827515, "step": 98000}
{"episode_reward": 433.1162795780829, "episode": 99.0, "batch_reward": 0.22054889778792858, "critic_loss": 0.19469443103298545, "actor_loss": -25.44509000778198, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.57600688934326, "step": 99000}
{"episode_reward": 437.1317890371333, "episode": 100.0, "batch_reward": 0.22120079164206982, "critic_loss": 0.19457395858317614, "actor_loss": -25.45589461135864, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.026982307434082, "step": 100000}
{"episode_reward": 419.8965291679737, "episode": 101.0, "batch_reward": 0.22443585053086282, "critic_loss": 0.18674550139904023, "actor_loss": -25.83179357147217, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.59332895278931, "step": 101000}
{"episode_reward": 459.44358994221784, "episode": 102.0, "batch_reward": 0.226304738342762, "critic_loss": 0.20229986190050842, "actor_loss": -25.885075214385985, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.84703803062439, "step": 102000}
{"episode_reward": 433.8639255622698, "episode": 103.0, "batch_reward": 0.228523829087615, "critic_loss": 0.20883678106218576, "actor_loss": -26.65378677749634, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.307560443878174, "step": 103000}
{"episode_reward": 467.50518544670877, "episode": 104.0, "batch_reward": 0.22995362074673176, "critic_loss": 0.20237343295663596, "actor_loss": -26.586281993865967, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.52972984313965, "step": 104000}
{"episode_reward": 431.47400613430494, "episode": 105.0, "batch_reward": 0.23357384207844734, "critic_loss": 0.21355363550782203, "actor_loss": -27.11578619003296, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.755329608917236, "step": 105000}
{"episode_reward": 453.59366564200207, "episode": 106.0, "batch_reward": 0.2342206199169159, "critic_loss": 0.22885477405041457, "actor_loss": -26.745367446899415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.65407156944275, "step": 106000}
{"episode_reward": 448.5529993088136, "episode": 107.0, "batch_reward": 0.23699469800293446, "critic_loss": 0.21274223030358552, "actor_loss": -26.97970104598999, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.819929838180542, "step": 107000}
{"episode_reward": 446.09658564036533, "episode": 108.0, "batch_reward": 0.23753202791512013, "critic_loss": 0.22197075241804123, "actor_loss": -27.467064517974855, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.86042308807373, "step": 108000}
{"episode_reward": 419.8547011626708, "episode": 109.0, "batch_reward": 0.24047572986781598, "critic_loss": 0.215465891122818, "actor_loss": -27.546552772521974, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.500093936920166, "step": 109000}
{"episode_reward": 468.51576895725447, "episode": 110.0, "batch_reward": 0.24328104062378406, "critic_loss": 0.20660475210100412, "actor_loss": -27.841495399475097, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.665541887283325, "step": 110000}
{"episode_reward": 458.3755770004751, "episode": 111.0, "batch_reward": 0.24351678040623664, "critic_loss": 0.2002723668515682, "actor_loss": -28.00444666671753, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.86719083786011, "step": 111000}
{"episode_reward": 407.63408910246375, "episode": 112.0, "batch_reward": 0.24640459294617176, "critic_loss": 0.21243920338898897, "actor_loss": -28.049274589538573, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.11253833770752, "step": 112000}
{"episode_reward": 454.68543569580754, "episode": 113.0, "batch_reward": 0.24743948014080525, "critic_loss": 0.21311269899457694, "actor_loss": -28.12801700592041, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.63616967201233, "step": 113000}
{"episode_reward": 173.39052535589119, "episode": 114.0, "batch_reward": 0.24675500094890596, "critic_loss": 0.19892190892994405, "actor_loss": -28.011538562774657, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.94708514213562, "step": 114000}
{"episode_reward": 425.56457185695257, "episode": 115.0, "batch_reward": 0.24787068699300288, "critic_loss": 0.20327714781463146, "actor_loss": -28.443192779541015, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.694387912750244, "step": 115000}
{"episode_reward": 428.24789979997405, "episode": 116.0, "batch_reward": 0.2510264259874821, "critic_loss": 0.20627702075242996, "actor_loss": -28.59966370010376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.638633728027344, "step": 116000}
{"episode_reward": 417.2127536305596, "episode": 117.0, "batch_reward": 0.25203027060627936, "critic_loss": 0.22033626472204923, "actor_loss": -29.110470100402832, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.971800327301025, "step": 117000}
{"episode_reward": 465.13621551172315, "episode": 118.0, "batch_reward": 0.2539883929640055, "critic_loss": 0.23382552512735127, "actor_loss": -29.161057708740234, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.182894706726074, "step": 118000}
{"episode_reward": 463.23494567794125, "episode": 119.0, "batch_reward": 0.254301475584507, "critic_loss": 0.23440671598166227, "actor_loss": -29.170112575531007, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.0856192111969, "step": 119000}
{"episode_reward": 106.79318808834404, "episode": 120.0, "batch_reward": 0.2531792284995317, "critic_loss": 0.2591924725398421, "actor_loss": -29.39182385635376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.70966339111328, "step": 120000}
{"episode_reward": 480.7404123885011, "episode": 121.0, "batch_reward": 0.2551310798078775, "critic_loss": 0.25833208534121516, "actor_loss": -29.80741748046875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.88199520111084, "step": 121000}
{"episode_reward": 455.8317249615884, "episode": 122.0, "batch_reward": 0.2577555815726519, "critic_loss": 0.2569783323481679, "actor_loss": -29.96213996887207, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.80391550064087, "step": 122000}
{"episode_reward": 446.1975699871639, "episode": 123.0, "batch_reward": 0.2595310500860214, "critic_loss": 0.2531682537123561, "actor_loss": -30.224050056457518, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.378189086914062, "step": 123000}
{"episode_reward": 424.5288608549645, "episode": 124.0, "batch_reward": 0.2600413411408663, "critic_loss": 0.23341680118441582, "actor_loss": -30.46639408493042, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.91797375679016, "step": 124000}
{"episode_reward": 479.61353129596444, "episode": 125.0, "batch_reward": 0.26229998902976515, "critic_loss": 0.24910044848173857, "actor_loss": -30.75252408218384, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.696210145950317, "step": 125000}
{"episode_reward": 458.9287584596089, "episode": 126.0, "batch_reward": 0.2639334615767002, "critic_loss": 0.2516229813620448, "actor_loss": -31.097175411224367, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.498148918151855, "step": 126000}
{"episode_reward": 475.81776777097184, "episode": 127.0, "batch_reward": 0.26481268756091597, "critic_loss": 0.24331325563043357, "actor_loss": -31.188191623687743, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.535593271255493, "step": 127000}
{"episode_reward": 468.5877140896197, "episode": 128.0, "batch_reward": 0.26637832932174205, "critic_loss": 0.23371042896062136, "actor_loss": -31.238343788146974, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.56116485595703, "step": 128000}
{"episode_reward": 488.5531241849559, "episode": 129.0, "batch_reward": 0.26887692941725255, "critic_loss": 0.2428457383289933, "actor_loss": -31.29007206726074, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.703189611434937, "step": 129000}
{"episode_reward": 496.552364879731, "episode": 130.0, "batch_reward": 0.2706840554773807, "critic_loss": 0.23416132646799087, "actor_loss": -31.578549320220947, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.620757579803467, "step": 130000}
{"episode_reward": 470.28660455018274, "episode": 131.0, "batch_reward": 0.2728002381026745, "critic_loss": 0.22809997864067555, "actor_loss": -31.45812770462036, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.602808475494385, "step": 131000}
{"episode_reward": 461.85602601019815, "episode": 132.0, "batch_reward": 0.2725528975725174, "critic_loss": 0.2183560611009598, "actor_loss": -31.25477451324463, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.665363311767578, "step": 132000}
{"episode_reward": 494.6321249777636, "episode": 133.0, "batch_reward": 0.27539889803528783, "critic_loss": 0.22991689478605987, "actor_loss": -31.64232361602783, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.779231071472168, "step": 133000}
{"episode_reward": 502.1699765993129, "episode": 134.0, "batch_reward": 0.2764759753793478, "critic_loss": 0.22394838462024927, "actor_loss": -31.838109806060793, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.164128065109253, "step": 134000}
{"episode_reward": 476.3834436490519, "episode": 135.0, "batch_reward": 0.27849732269346716, "critic_loss": 0.21724910466372968, "actor_loss": -32.11913806152344, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.72631311416626, "step": 135000}
{"episode_reward": 463.8630495846365, "episode": 136.0, "batch_reward": 0.27909930257499216, "critic_loss": 0.21613580981642008, "actor_loss": -32.287654300689695, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.684067964553833, "step": 136000}
{"episode_reward": 483.63994397961665, "episode": 137.0, "batch_reward": 0.2805551748126745, "critic_loss": 0.22021396627277137, "actor_loss": -32.064072010040285, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.52755331993103, "step": 137000}
{"episode_reward": 461.0735515443747, "episode": 138.0, "batch_reward": 0.2836543443351984, "critic_loss": 0.2204572627544403, "actor_loss": -32.27777467346191, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.486517429351807, "step": 138000}
{"episode_reward": 484.7053813403456, "episode": 139.0, "batch_reward": 0.2842518100589514, "critic_loss": 0.2220967798382044, "actor_loss": -32.47574231719971, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.93023991584778, "step": 139000}
{"episode_reward": 478.31766283903244, "episode": 140.0, "batch_reward": 0.2858453352749348, "critic_loss": 0.21208191525936126, "actor_loss": -32.48955881500244, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.58424162864685, "step": 140000}
{"episode_reward": 457.95004915931486, "episode": 141.0, "batch_reward": 0.28625273168087007, "critic_loss": 0.20307841446995736, "actor_loss": -32.38629623413086, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.00857400894165, "step": 141000}
{"episode_reward": 479.92633007290084, "episode": 142.0, "batch_reward": 0.28726465061306955, "critic_loss": 0.21853865107148887, "actor_loss": -32.969488273620605, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.543916702270508, "step": 142000}
{"episode_reward": 466.46323252106515, "episode": 143.0, "batch_reward": 0.2887065777629614, "critic_loss": 0.20817813492566348, "actor_loss": -32.91204323577881, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.54565715789795, "step": 143000}
{"episode_reward": 476.2938098627526, "episode": 144.0, "batch_reward": 0.29035293389856814, "critic_loss": 0.20315021312236786, "actor_loss": -32.75288846588135, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.701287746429443, "step": 144000}
{"episode_reward": 455.2260623311455, "episode": 145.0, "batch_reward": 0.2925031368136406, "critic_loss": 0.21170783314853905, "actor_loss": -32.71655892181396, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.502033948898315, "step": 145000}
{"episode_reward": 465.27559039674424, "episode": 146.0, "batch_reward": 0.29216193841397764, "critic_loss": 0.21550193079560995, "actor_loss": -32.86496143722534, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.612504243850708, "step": 146000}
{"episode_reward": 469.4380312425363, "episode": 147.0, "batch_reward": 0.2940007385611534, "critic_loss": 0.20496770294010638, "actor_loss": -33.17463777160645, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.43547296524048, "step": 147000}
{"episode_reward": 473.30947291304483, "episode": 148.0, "batch_reward": 0.29514379915595057, "critic_loss": 0.2166431568413973, "actor_loss": -33.04686590957642, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.4361572265625, "step": 148000}
{"episode_reward": 474.92692299732846, "episode": 149.0, "batch_reward": 0.2962360463440418, "critic_loss": 0.20476174245029688, "actor_loss": -33.38758006668091, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.775296449661255, "step": 149000}
{"episode_reward": 498.3307796506676, "episode": 150.0, "batch_reward": 0.29778213545680043, "critic_loss": 0.21970745431631802, "actor_loss": -33.18952864074707, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
