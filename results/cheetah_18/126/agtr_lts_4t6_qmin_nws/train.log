{"episode_reward": 0.0, "episode": 1.0, "duration": 14.002224445343018, "step": 1000}
{"episode_reward": 4.231880753996205, "episode": 2.0, "duration": 1.2062947750091553, "step": 2000}
{"episode_reward": 395.1450543749875, "episode": 3.0, "batch_reward": 0.1885431866624547, "critic_loss": 0.03301544963789308, "actor_loss": -24.62608599909941, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 71.51716017723083, "step": 3000}
{"episode_reward": 28.589759397704483, "episode": 4.0, "batch_reward": 0.13337132269889115, "critic_loss": 0.03235412345360965, "actor_loss": -21.5011287676692, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.28050446510315, "step": 4000}
{"episode_reward": 41.45617370668995, "episode": 5.0, "batch_reward": 0.11519572957605123, "critic_loss": 0.035200073493644596, "actor_loss": -18.593931323975326, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.169228315353394, "step": 5000}
{"episode_reward": 91.2754711226454, "episode": 6.0, "batch_reward": 0.10663431909680367, "critic_loss": 0.03067463276721537, "actor_loss": -18.855284875921907, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.68342638015747, "step": 6000}
{"episode_reward": 45.652405590022745, "episode": 7.0, "batch_reward": 0.09767811102047562, "critic_loss": 0.03190421549603343, "actor_loss": -18.263626105442643, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.91116976737976, "step": 7000}
{"episode_reward": 46.57444282615304, "episode": 8.0, "batch_reward": 0.09295076093450189, "critic_loss": 0.037073165982961655, "actor_loss": -17.696852164536715, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.764020442962646, "step": 8000}
{"episode_reward": 117.0644467859148, "episode": 9.0, "batch_reward": 0.09501836390420794, "critic_loss": 0.05206912764161825, "actor_loss": -17.044444307118653, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.819619178771973, "step": 9000}
{"episode_reward": 49.82143321486994, "episode": 10.0, "batch_reward": 0.09193831518664956, "critic_loss": 0.0520979774966836, "actor_loss": -15.886364949129522, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.968233346939087, "step": 10000}
{"episode_reward": 82.60310505532757, "episode": 11.0, "batch_reward": 0.08825652159005404, "critic_loss": 0.05378782151453197, "actor_loss": -16.74371772827208, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.22377586364746, "step": 11000}
{"episode_reward": 33.10280405803704, "episode": 12.0, "batch_reward": 0.08761566169932485, "critic_loss": 0.07384987400844693, "actor_loss": -14.99960117264092, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.21446919441223, "step": 12000}
{"episode_reward": 101.494262274417, "episode": 13.0, "batch_reward": 0.08592808336392045, "critic_loss": 0.0832948875837028, "actor_loss": -15.306208691492676, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.498417615890503, "step": 13000}
{"episode_reward": 37.96619383850842, "episode": 14.0, "batch_reward": 0.08222506972029806, "critic_loss": 0.08880221323668956, "actor_loss": -14.530978317290545, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.98165988922119, "step": 14000}
{"episode_reward": 54.40975389881918, "episode": 15.0, "batch_reward": 0.08042339830845595, "critic_loss": 0.09502853546664118, "actor_loss": -15.210606299221515, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.38035559654236, "step": 15000}
{"episode_reward": 46.59603229853325, "episode": 16.0, "batch_reward": 0.08399007447436452, "critic_loss": 0.11213019504025579, "actor_loss": -12.960872517317533, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.853866577148438, "step": 16000}
{"episode_reward": 236.16973469247483, "episode": 17.0, "batch_reward": 0.08996072029322386, "critic_loss": 0.12273159769177437, "actor_loss": -13.772296005010604, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.07647728919983, "step": 17000}
{"episode_reward": 91.60815183920741, "episode": 18.0, "batch_reward": 0.08931611468270421, "critic_loss": 0.13728102518990637, "actor_loss": -13.343177034378051, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.988186836242676, "step": 18000}
{"episode_reward": 84.61670658797888, "episode": 19.0, "batch_reward": 0.0872336467280984, "critic_loss": 0.13168391923233866, "actor_loss": -13.424636679410934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.751513481140137, "step": 19000}
{"episode_reward": 30.737494864751053, "episode": 20.0, "batch_reward": 0.08513947581499814, "critic_loss": 0.13001780219748615, "actor_loss": -14.052489885807038, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.462146043777466, "step": 20000}
{"episode_reward": 41.732746402237225, "episode": 21.0, "batch_reward": 0.08444577623531223, "critic_loss": 0.1442042829990387, "actor_loss": -13.201078740358353, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.95976495742798, "step": 21000}
{"episode_reward": 111.87905618026579, "episode": 22.0, "batch_reward": 0.08628510554507375, "critic_loss": 0.16082578220963478, "actor_loss": -13.687616465568542, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.829986572265625, "step": 22000}
{"episode_reward": 94.31956773309821, "episode": 23.0, "batch_reward": 0.08528896044939756, "critic_loss": 0.1549249383173883, "actor_loss": -13.634887037038803, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.78638482093811, "step": 23000}
{"episode_reward": 59.331601219788325, "episode": 24.0, "batch_reward": 0.0848151234202087, "critic_loss": 0.15494525004550816, "actor_loss": -13.438714636802674, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.199049711227417, "step": 24000}
{"episode_reward": 84.09725014445382, "episode": 25.0, "batch_reward": 0.08321751344949008, "critic_loss": 0.1259283599629998, "actor_loss": -13.286363754272461, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.871866941452026, "step": 25000}
{"episode_reward": 34.63922766856495, "episode": 26.0, "batch_reward": 0.08219705968722701, "critic_loss": 0.1535683763474226, "actor_loss": -12.579626376628875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.06547999382019, "step": 26000}
{"episode_reward": 52.947922798982354, "episode": 27.0, "batch_reward": 0.08330808874592185, "critic_loss": 0.15631251971051097, "actor_loss": -13.25718056154251, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.273827075958252, "step": 27000}
{"episode_reward": 148.38269955103718, "episode": 28.0, "batch_reward": 0.08666199247911573, "critic_loss": 0.16364374723285435, "actor_loss": -12.730682638168336, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.565526247024536, "step": 28000}
{"episode_reward": 276.6805481687, "episode": 29.0, "batch_reward": 0.0893737210854888, "critic_loss": 0.19707613689824938, "actor_loss": -13.749079249858855, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.139447927474976, "step": 29000}
{"episode_reward": 56.80203021690451, "episode": 30.0, "batch_reward": 0.09068174504861236, "critic_loss": 0.2197093379944563, "actor_loss": -13.477350713729859, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.688934803009033, "step": 30000}
{"episode_reward": 106.94367320577885, "episode": 31.0, "batch_reward": 0.09136543959379197, "critic_loss": 0.2012129569351673, "actor_loss": -13.125160960197448, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.44737482070923, "step": 31000}
{"episode_reward": 135.40838152987925, "episode": 32.0, "batch_reward": 0.09392690701037645, "critic_loss": 0.20364232099428772, "actor_loss": -13.28749547958374, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.93137288093567, "step": 32000}
{"episode_reward": 193.2510964016939, "episode": 33.0, "batch_reward": 0.09756762488186359, "critic_loss": 0.21335410965979099, "actor_loss": -14.511462107658387, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.91283869743347, "step": 33000}
{"episode_reward": 279.02780042295825, "episode": 34.0, "batch_reward": 0.10281335216760636, "critic_loss": 0.23150851746648551, "actor_loss": -14.16103999185562, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.83646059036255, "step": 34000}
{"episode_reward": 308.2699600834321, "episode": 35.0, "batch_reward": 0.105977539755404, "critic_loss": 0.19350774597749115, "actor_loss": -14.589964558601379, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.103313207626343, "step": 35000}
{"episode_reward": 73.52405020391195, "episode": 36.0, "batch_reward": 0.1070174126252532, "critic_loss": 0.1990137041732669, "actor_loss": -13.694410700798034, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.17274045944214, "step": 36000}
{"episode_reward": 131.17713448735807, "episode": 37.0, "batch_reward": 0.10548045100644231, "critic_loss": 0.2066478736102581, "actor_loss": -14.359430129051209, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.2114577293396, "step": 37000}
{"episode_reward": 81.73342124280705, "episode": 38.0, "batch_reward": 0.10697679553925991, "critic_loss": 0.216491669267416, "actor_loss": -15.09417137813568, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.86716341972351, "step": 38000}
{"episode_reward": 206.1821227594375, "episode": 39.0, "batch_reward": 0.11009780913591385, "critic_loss": 0.22528929467499256, "actor_loss": -14.711420251846313, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.735528230667114, "step": 39000}
{"episode_reward": 172.845039144715, "episode": 40.0, "batch_reward": 0.11114272182434798, "critic_loss": 0.24447332096844912, "actor_loss": -14.201393310546875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.30289340019226, "step": 40000}
{"episode_reward": 304.98077711551224, "episode": 41.0, "batch_reward": 0.11564372909814119, "critic_loss": 0.2587276322990656, "actor_loss": -14.47978933620453, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.87909913063049, "step": 41000}
{"episode_reward": 152.0472641926978, "episode": 42.0, "batch_reward": 0.11540321670472622, "critic_loss": 0.236758056409657, "actor_loss": -15.171594491004944, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.24423360824585, "step": 42000}
{"episode_reward": 58.72207225261309, "episode": 43.0, "batch_reward": 0.11399883379042149, "critic_loss": 0.2416538614630699, "actor_loss": -14.646603298187255, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.280473709106445, "step": 43000}
{"episode_reward": 66.02465953633744, "episode": 44.0, "batch_reward": 0.11208837981522084, "critic_loss": 0.2309417304545641, "actor_loss": -14.903640540122986, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.777536153793335, "step": 44000}
{"episode_reward": 70.66144553831707, "episode": 45.0, "batch_reward": 0.11337027902901173, "critic_loss": 0.2420181274190545, "actor_loss": -15.36913618850708, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.38972568511963, "step": 45000}
{"episode_reward": 295.2156441235049, "episode": 46.0, "batch_reward": 0.11854356430470943, "critic_loss": 0.27010754810273646, "actor_loss": -14.888530716896057, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.028639316558838, "step": 46000}
{"episode_reward": 342.76473997540046, "episode": 47.0, "batch_reward": 0.12256316374242306, "critic_loss": 0.3161345148086548, "actor_loss": -15.25825969028473, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.2647442817688, "step": 47000}
{"episode_reward": 336.5528468304412, "episode": 48.0, "batch_reward": 0.12780939806252717, "critic_loss": 0.30263243478536606, "actor_loss": -15.833109328269959, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.275181531906128, "step": 48000}
{"episode_reward": 327.56087787475565, "episode": 49.0, "batch_reward": 0.13215865960717202, "critic_loss": 0.3048134694695473, "actor_loss": -16.025377993583678, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.851516008377075, "step": 49000}
{"episode_reward": 363.21754877728563, "episode": 50.0, "batch_reward": 0.13515822310745715, "critic_loss": 0.29940490856021645, "actor_loss": -16.85463661766052, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.369763135910034, "step": 50000}
{"episode_reward": 141.43977141391798, "episode": 51.0, "batch_reward": 0.13761790589243172, "critic_loss": 0.29268637410551307, "actor_loss": -17.286412593841554, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.09630513191223, "step": 51000}
{"episode_reward": 344.1487915029209, "episode": 52.0, "batch_reward": 0.14105310068279506, "critic_loss": 0.3016139526590705, "actor_loss": -16.962568148612977, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.302380084991455, "step": 52000}
{"episode_reward": 326.1589554642337, "episode": 53.0, "batch_reward": 0.1434976107850671, "critic_loss": 0.35535445062071086, "actor_loss": -18.36044130897522, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.2666654586792, "step": 53000}
{"episode_reward": 162.2721298357716, "episode": 54.0, "batch_reward": 0.14258258175104857, "critic_loss": 0.3467321929037571, "actor_loss": -16.953155517578125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.030613660812378, "step": 54000}
{"episode_reward": 60.04331647357591, "episode": 55.0, "batch_reward": 0.1430274079144001, "critic_loss": 0.3162603726387024, "actor_loss": -17.44100616645813, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.655537128448486, "step": 55000}
{"episode_reward": 368.9117633960937, "episode": 56.0, "batch_reward": 0.1458533455207944, "critic_loss": 0.32196807150542733, "actor_loss": -18.364864271163942, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.43217444419861, "step": 56000}
{"episode_reward": 147.77104428184722, "episode": 57.0, "batch_reward": 0.1470228445455432, "critic_loss": 0.32191785337775947, "actor_loss": -18.01599806404114, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.44860339164734, "step": 57000}
{"episode_reward": 138.7290612993349, "episode": 58.0, "batch_reward": 0.14741914688795804, "critic_loss": 0.3225296385139227, "actor_loss": -18.038731573104858, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.474897384643555, "step": 58000}
{"episode_reward": 370.6569797671728, "episode": 59.0, "batch_reward": 0.1507561262771487, "critic_loss": 0.3217578309252858, "actor_loss": -18.390827688217165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.860048055648804, "step": 59000}
{"episode_reward": 374.26502953756426, "episode": 60.0, "batch_reward": 0.1523005742356181, "critic_loss": 0.2879061419814825, "actor_loss": -18.43538104057312, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.02958917617798, "step": 60000}
{"episode_reward": 85.23818567740732, "episode": 61.0, "batch_reward": 0.15271055851876736, "critic_loss": 0.2730477345138788, "actor_loss": -18.30513855934143, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.00966715812683, "step": 61000}
{"episode_reward": 188.60828254815576, "episode": 62.0, "batch_reward": 0.15409294678270816, "critic_loss": 0.27340098371356725, "actor_loss": -19.1092646484375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.48029351234436, "step": 62000}
{"episode_reward": 360.4663021189242, "episode": 63.0, "batch_reward": 0.15714135904610158, "critic_loss": 0.26500307776778936, "actor_loss": -19.457331632614135, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.47649312019348, "step": 63000}
{"episode_reward": 359.6700394689043, "episode": 64.0, "batch_reward": 0.1603460142761469, "critic_loss": 0.2854902148321271, "actor_loss": -19.446405658721925, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.792648792266846, "step": 64000}
{"episode_reward": 292.7564146653497, "episode": 65.0, "batch_reward": 0.1637716279923916, "critic_loss": 0.28217488468438384, "actor_loss": -20.048468906402586, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.61159372329712, "step": 65000}
{"episode_reward": 393.7737866244759, "episode": 66.0, "batch_reward": 0.16625540462881327, "critic_loss": 0.27728718692809345, "actor_loss": -19.96200351524353, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.04836893081665, "step": 66000}
{"episode_reward": 427.1214228037216, "episode": 67.0, "batch_reward": 0.16931068897247314, "critic_loss": 0.2620037212148309, "actor_loss": -20.49984764289856, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.520955801010132, "step": 67000}
{"episode_reward": 174.35946118640442, "episode": 68.0, "batch_reward": 0.1702506972551346, "critic_loss": 0.2855413877516985, "actor_loss": -20.07039063835144, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.35467004776001, "step": 68000}
{"episode_reward": 313.7021841043365, "episode": 69.0, "batch_reward": 0.1736449423134327, "critic_loss": 0.2819085876941681, "actor_loss": -20.481716556549074, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.22336721420288, "step": 69000}
{"episode_reward": 419.38068346156496, "episode": 70.0, "batch_reward": 0.1766183832734823, "critic_loss": 0.2927544742748141, "actor_loss": -20.133356712341307, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.41922950744629, "step": 70000}
{"episode_reward": 383.7773687257678, "episode": 71.0, "batch_reward": 0.1786200653910637, "critic_loss": 0.28103698045760395, "actor_loss": -21.45996096801758, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.44223237037659, "step": 71000}
{"episode_reward": 405.23710342812285, "episode": 72.0, "batch_reward": 0.1815559352785349, "critic_loss": 0.28360342885553835, "actor_loss": -21.041703409194945, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.362318992614746, "step": 72000}
{"episode_reward": 416.98686869683195, "episode": 73.0, "batch_reward": 0.18473532135784626, "critic_loss": 0.2581002171635628, "actor_loss": -21.528392278671266, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.77557349205017, "step": 73000}
{"episode_reward": 398.59263251545434, "episode": 74.0, "batch_reward": 0.18909721305966376, "critic_loss": 0.26586262696236374, "actor_loss": -21.873952434539795, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.399128675460815, "step": 74000}
{"episode_reward": 414.20283587386245, "episode": 75.0, "batch_reward": 0.19182079270482064, "critic_loss": 0.2505261028781533, "actor_loss": -22.14811873626709, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.91005301475525, "step": 75000}
{"episode_reward": 419.5946536891335, "episode": 76.0, "batch_reward": 0.19498267939686775, "critic_loss": 0.24737192343175413, "actor_loss": -22.280313745498656, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.086841344833374, "step": 76000}
{"episode_reward": 443.501756842831, "episode": 77.0, "batch_reward": 0.19703251193463803, "critic_loss": 0.2609838059693575, "actor_loss": -22.541795671463014, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.01601481437683, "step": 77000}
{"episode_reward": 392.45675537488916, "episode": 78.0, "batch_reward": 0.19987689988315105, "critic_loss": 0.23947184620797635, "actor_loss": -23.22334825897217, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.560362100601196, "step": 78000}
{"episode_reward": 414.3299310468653, "episode": 79.0, "batch_reward": 0.20210463954508304, "critic_loss": 0.231634912699461, "actor_loss": -23.26155449104309, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.96072006225586, "step": 79000}
{"episode_reward": 432.53263201725576, "episode": 80.0, "batch_reward": 0.2057828968167305, "critic_loss": 0.24228106056898832, "actor_loss": -23.564340873718262, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.144625425338745, "step": 80000}
{"episode_reward": 418.07326977713313, "episode": 81.0, "batch_reward": 0.20969915014505386, "critic_loss": 0.2265129097253084, "actor_loss": -24.195630613327026, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.83172583580017, "step": 81000}
{"episode_reward": 431.92921545945154, "episode": 82.0, "batch_reward": 0.2109672260582447, "critic_loss": 0.25143056841939687, "actor_loss": -24.225745405197145, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.30387830734253, "step": 82000}
{"episode_reward": 433.503130148752, "episode": 83.0, "batch_reward": 0.21330249154567718, "critic_loss": 0.22612441508471967, "actor_loss": -24.06315294265747, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.09770178794861, "step": 83000}
{"episode_reward": 440.3315392229557, "episode": 84.0, "batch_reward": 0.21675134183466435, "critic_loss": 0.2278651062399149, "actor_loss": -24.039766548156738, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.80311870574951, "step": 84000}
{"episode_reward": 455.34890817707145, "episode": 85.0, "batch_reward": 0.2195608253479004, "critic_loss": 0.23600861709564924, "actor_loss": -25.055495754241942, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.592797994613647, "step": 85000}
{"episode_reward": 430.03849449033135, "episode": 86.0, "batch_reward": 0.22215779285132886, "critic_loss": 0.2355240282714367, "actor_loss": -25.334697734832762, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.141319751739502, "step": 86000}
{"episode_reward": 420.89183247679097, "episode": 87.0, "batch_reward": 0.2241644137054682, "critic_loss": 0.21905773233622314, "actor_loss": -25.315390985488893, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.36216711997986, "step": 87000}
{"episode_reward": 449.3297990704936, "episode": 88.0, "batch_reward": 0.22787141312658787, "critic_loss": 0.24400572145730257, "actor_loss": -25.37862586402893, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.18816113471985, "step": 88000}
{"episode_reward": 440.50059487346505, "episode": 89.0, "batch_reward": 0.2292227195650339, "critic_loss": 0.22895036370307206, "actor_loss": -26.04757030105591, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.87800359725952, "step": 89000}
{"episode_reward": 459.3218135902466, "episode": 90.0, "batch_reward": 0.23143658988177776, "critic_loss": 0.23191230915486813, "actor_loss": -25.982360801696778, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.130323886871338, "step": 90000}
{"episode_reward": 450.5757033075784, "episode": 91.0, "batch_reward": 0.23378131164610386, "critic_loss": 0.22996265033632518, "actor_loss": -26.400973346710206, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.7992889881134, "step": 91000}
{"episode_reward": 432.5237862173732, "episode": 92.0, "batch_reward": 0.2360880787819624, "critic_loss": 0.24032681170850992, "actor_loss": -26.749465427398682, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.49486804008484, "step": 92000}
{"episode_reward": 433.1735443363034, "episode": 93.0, "batch_reward": 0.23885891804099083, "critic_loss": 0.24422048276662828, "actor_loss": -26.993386863708498, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.32213854789734, "step": 93000}
{"episode_reward": 442.5259542312876, "episode": 94.0, "batch_reward": 0.24090691503882408, "critic_loss": 0.23132555206120015, "actor_loss": -27.068423347473143, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.01954197883606, "step": 94000}
{"episode_reward": 420.26179849178567, "episode": 95.0, "batch_reward": 0.24206508238613605, "critic_loss": 0.235236115552485, "actor_loss": -27.07332402038574, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.819530487060547, "step": 95000}
{"episode_reward": 430.3288706557486, "episode": 96.0, "batch_reward": 0.24529889118671416, "critic_loss": 0.24113131968677043, "actor_loss": -27.592331386566162, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.410642623901367, "step": 96000}
{"episode_reward": 432.75095020864876, "episode": 97.0, "batch_reward": 0.24644531713426113, "critic_loss": 0.23785528723150492, "actor_loss": -27.47943854522705, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.90831732749939, "step": 97000}
{"episode_reward": 473.2995081890869, "episode": 98.0, "batch_reward": 0.24895011560618877, "critic_loss": 0.2500924628227949, "actor_loss": -28.1683102645874, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.407108545303345, "step": 98000}
{"episode_reward": 450.0754871541775, "episode": 99.0, "batch_reward": 0.25123762430250646, "critic_loss": 0.23220398268848658, "actor_loss": -28.121015857696534, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.19603157043457, "step": 99000}
{"episode_reward": 473.9362931144322, "episode": 100.0, "batch_reward": 0.2525169352889061, "critic_loss": 0.25294999354332687, "actor_loss": -28.414165481567384, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.16410779953003, "step": 100000}
{"episode_reward": 455.0395469681531, "episode": 101.0, "batch_reward": 0.2551164348721504, "critic_loss": 0.23855597425252198, "actor_loss": -28.318535709381102, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.8596076965332, "step": 101000}
{"episode_reward": 450.78677895504785, "episode": 102.0, "batch_reward": 0.25738911332190034, "critic_loss": 0.24428539218753575, "actor_loss": -28.62766342163086, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.501052618026733, "step": 102000}
{"episode_reward": 474.4058377541187, "episode": 103.0, "batch_reward": 0.25941129204630853, "critic_loss": 0.236147777043283, "actor_loss": -29.050228275299073, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.29539442062378, "step": 103000}
{"episode_reward": 465.61942512134004, "episode": 104.0, "batch_reward": 0.26082759781181813, "critic_loss": 0.2305430540367961, "actor_loss": -29.005839584350586, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.921807289123535, "step": 104000}
{"episode_reward": 449.02491701905325, "episode": 105.0, "batch_reward": 0.26326292648911476, "critic_loss": 0.24798912220448255, "actor_loss": -29.70649837112427, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.638006687164307, "step": 105000}
{"episode_reward": 447.9845989767891, "episode": 106.0, "batch_reward": 0.264115397259593, "critic_loss": 0.2308695444688201, "actor_loss": -29.40960153198242, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.89132571220398, "step": 106000}
{"episode_reward": 444.7939119251342, "episode": 107.0, "batch_reward": 0.2675405634045601, "critic_loss": 0.22571752467751502, "actor_loss": -30.005088150024413, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.30644726753235, "step": 107000}
{"episode_reward": 465.672427392047, "episode": 108.0, "batch_reward": 0.2673077842891216, "critic_loss": 0.24486123669147491, "actor_loss": -30.220206722259523, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.447000741958618, "step": 108000}
{"episode_reward": 434.67103083554036, "episode": 109.0, "batch_reward": 0.27009711804986, "critic_loss": 0.21721978644281625, "actor_loss": -29.95603801345825, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.338530778884888, "step": 109000}
{"episode_reward": 471.59719919101394, "episode": 110.0, "batch_reward": 0.2721713687181473, "critic_loss": 0.20795317659527063, "actor_loss": -30.082155494689943, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.3581645488739, "step": 110000}
{"episode_reward": 479.17055854445545, "episode": 111.0, "batch_reward": 0.2731833036988974, "critic_loss": 0.2217381441667676, "actor_loss": -30.83823134613037, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.97613859176636, "step": 111000}
{"episode_reward": 437.0461419448178, "episode": 112.0, "batch_reward": 0.2752275692820549, "critic_loss": 0.22075707668811081, "actor_loss": -30.28345503616333, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.24380922317505, "step": 112000}
{"episode_reward": 453.96771553436275, "episode": 113.0, "batch_reward": 0.27682495349645614, "critic_loss": 0.22693476559221745, "actor_loss": -30.851481674194336, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.149563789367676, "step": 113000}
{"episode_reward": 448.54011722380534, "episode": 114.0, "batch_reward": 0.2776829946041107, "critic_loss": 0.2324627808853984, "actor_loss": -30.584955394744874, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.91841983795166, "step": 114000}
{"episode_reward": 450.90039691548486, "episode": 115.0, "batch_reward": 0.279282948166132, "critic_loss": 0.22484191027283668, "actor_loss": -31.077763526916502, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.929818630218506, "step": 115000}
{"episode_reward": 466.99406070364086, "episode": 116.0, "batch_reward": 0.2822256959080696, "critic_loss": 0.21701628124713898, "actor_loss": -31.129272548675537, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.374293327331543, "step": 116000}
{"episode_reward": 436.57709673327366, "episode": 117.0, "batch_reward": 0.2834854684770107, "critic_loss": 0.21958997040241957, "actor_loss": -32.03729476928711, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.139413595199585, "step": 117000}
{"episode_reward": 470.04117816839863, "episode": 118.0, "batch_reward": 0.2843106270283461, "critic_loss": 0.2081983365640044, "actor_loss": -31.80005122375488, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.069814205169678, "step": 118000}
{"episode_reward": 464.81875114867734, "episode": 119.0, "batch_reward": 0.28595915174484254, "critic_loss": 0.22573320139199496, "actor_loss": -31.76117710494995, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.079429626464844, "step": 119000}
{"episode_reward": 475.10408999954774, "episode": 120.0, "batch_reward": 0.28680342514812945, "critic_loss": 0.22388463162630795, "actor_loss": -32.12717725372315, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.188361644744873, "step": 120000}
{"episode_reward": 452.128709276599, "episode": 121.0, "batch_reward": 0.2879371359795332, "critic_loss": 0.2108039331585169, "actor_loss": -32.34437556838989, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.43422508239746, "step": 121000}
{"episode_reward": 458.3524552951077, "episode": 122.0, "batch_reward": 0.2908670626729727, "critic_loss": 0.22919790117442607, "actor_loss": -32.47260107803345, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.316199779510498, "step": 122000}
{"episode_reward": 449.3257686003147, "episode": 123.0, "batch_reward": 0.2910133035480976, "critic_loss": 0.20964634938538074, "actor_loss": -31.996674949645996, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.480511903762817, "step": 123000}
{"episode_reward": 453.4737205213126, "episode": 124.0, "batch_reward": 0.29204528473317626, "critic_loss": 0.21922895188629626, "actor_loss": -32.460419094085694, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.255024194717407, "step": 124000}
{"episode_reward": 441.8836912157118, "episode": 125.0, "batch_reward": 0.2940950033813715, "critic_loss": 0.21659262716025113, "actor_loss": -32.64720727539063, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.734750509262085, "step": 125000}
{"episode_reward": 466.4402891328566, "episode": 126.0, "batch_reward": 0.29529988096654414, "critic_loss": 0.2217297624051571, "actor_loss": -33.10546966934204, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.258201837539673, "step": 126000}
{"episode_reward": 464.77284568279714, "episode": 127.0, "batch_reward": 0.29653470635414125, "critic_loss": 0.2145508830845356, "actor_loss": -32.93916268539429, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.547740936279297, "step": 127000}
{"episode_reward": 467.7495878326345, "episode": 128.0, "batch_reward": 0.2971735772639513, "critic_loss": 0.21755940147489308, "actor_loss": -33.06680307006836, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.42286229133606, "step": 128000}
{"episode_reward": 466.8737241803039, "episode": 129.0, "batch_reward": 0.2990305463522673, "critic_loss": 0.21548459789901972, "actor_loss": -33.525512439727784, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.166882514953613, "step": 129000}
{"episode_reward": 490.83154503899755, "episode": 130.0, "batch_reward": 0.3009769940376282, "critic_loss": 0.20847401251643896, "actor_loss": -33.730252208709715, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.361929893493652, "step": 130000}
{"episode_reward": 461.7385421669936, "episode": 131.0, "batch_reward": 0.301912759616971, "critic_loss": 0.21143280444294213, "actor_loss": -33.61558728027344, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.26409554481506, "step": 131000}
{"episode_reward": 475.5859690035433, "episode": 132.0, "batch_reward": 0.30215552762150766, "critic_loss": 0.21568851017951965, "actor_loss": -33.17786385726929, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.325541019439697, "step": 132000}
{"episode_reward": 448.69895183645633, "episode": 133.0, "batch_reward": 0.30550546042621135, "critic_loss": 0.21242392770946025, "actor_loss": -33.95816036605835, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.20352840423584, "step": 133000}
{"episode_reward": 487.0870412796356, "episode": 134.0, "batch_reward": 0.30581244206428526, "critic_loss": 0.20083780171722174, "actor_loss": -34.44673321914673, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.403446197509766, "step": 134000}
{"episode_reward": 468.72616907561104, "episode": 135.0, "batch_reward": 0.30721582016348836, "critic_loss": 0.2057272612005472, "actor_loss": -33.833065670013426, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.922590494155884, "step": 135000}
{"episode_reward": 463.6876954387144, "episode": 136.0, "batch_reward": 0.30800402468442917, "critic_loss": 0.20339635785669088, "actor_loss": -35.08202528762818, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.891337633132935, "step": 136000}
{"episode_reward": 434.112281354086, "episode": 137.0, "batch_reward": 0.30884673869609836, "critic_loss": 0.22477879332751036, "actor_loss": -34.301753047943116, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.87935161590576, "step": 137000}
{"episode_reward": 465.1882144021563, "episode": 138.0, "batch_reward": 0.31073578211665154, "critic_loss": 0.22343829102814197, "actor_loss": -34.44626164627075, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.048852920532227, "step": 138000}
{"episode_reward": 478.03488265144983, "episode": 139.0, "batch_reward": 0.3121081587076187, "critic_loss": 0.2205168385207653, "actor_loss": -34.70361005783081, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.64756679534912, "step": 139000}
{"episode_reward": 495.25653249611116, "episode": 140.0, "batch_reward": 0.3127131644785404, "critic_loss": 0.21120431193709374, "actor_loss": -34.621791603088376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.10212254524231, "step": 140000}
{"episode_reward": 432.50506480728416, "episode": 141.0, "batch_reward": 0.31313711050152776, "critic_loss": 0.21531513802707195, "actor_loss": -34.554384452819825, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.26710271835327, "step": 141000}
{"episode_reward": 449.5811436507519, "episode": 142.0, "batch_reward": 0.3136740013659, "critic_loss": 0.2147264254167676, "actor_loss": -35.27379736328125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.260107040405273, "step": 142000}
{"episode_reward": 471.8469140120442, "episode": 143.0, "batch_reward": 0.3156287743747234, "critic_loss": 0.20703497129678727, "actor_loss": -35.35869738006592, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.241445064544678, "step": 143000}
{"episode_reward": 475.603447815868, "episode": 144.0, "batch_reward": 0.31673512545228005, "critic_loss": 0.20814381447434424, "actor_loss": -34.9231879234314, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.33471155166626, "step": 144000}
{"episode_reward": 454.500086147994, "episode": 145.0, "batch_reward": 0.318621472299099, "critic_loss": 0.2020414622351527, "actor_loss": -35.00035564041138, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.885655641555786, "step": 145000}
{"episode_reward": 489.4220326290021, "episode": 146.0, "batch_reward": 0.31849706265330313, "critic_loss": 0.2021044308617711, "actor_loss": -34.966396919250485, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.803486824035645, "step": 146000}
{"episode_reward": 495.5367688976682, "episode": 147.0, "batch_reward": 0.3192872560918331, "critic_loss": 0.20336260459572078, "actor_loss": -35.22829139328003, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.52070116996765, "step": 147000}
{"episode_reward": 466.2945214870199, "episode": 148.0, "batch_reward": 0.32107054090499876, "critic_loss": 0.20053047880530359, "actor_loss": -35.46043459320068, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.099175214767456, "step": 148000}
{"episode_reward": 475.0166694333727, "episode": 149.0, "batch_reward": 0.3215817192494869, "critic_loss": 0.20129011158645152, "actor_loss": -35.56747185134888, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.065258502960205, "step": 149000}
{"episode_reward": 484.335719880536, "episode": 150.0, "batch_reward": 0.3234364213347435, "critic_loss": 0.20502700304985047, "actor_loss": -35.48047044372559, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
