{"episode": 1.0, "duration": 18.31633949279785, "episode_reward": 4.231880753996205, "step": 1000}
{"episode": 2.0, "duration": 1.6879901885986328, "episode_reward": 395.1450543749875, "step": 2000}
{"episode": 3.0, "batch_reward": 0.19421120572284922, "actor_loss": -40.81411489919454, "actor_target_entropy": -6.0, "alpha_value": 0.010699999250839183, "duration": 52.78259563446045, "episode_reward": 143.81231319785206, "step": 3000}
{"episode": 4.0, "batch_reward": 0.16503520372509956, "actor_loss": -35.988578556060794, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.484315872192383, "episode_reward": 36.98707803649464, "step": 4000}
{"episode": 5.0, "batch_reward": 0.1485263351276517, "actor_loss": -33.2258034362793, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.444718599319458, "episode_reward": 157.93822285384144, "step": 5000}
{"episode": 6.0, "batch_reward": 0.14167442408949138, "actor_loss": -31.930965312957763, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.462785482406616, "episode_reward": 44.094436920386876, "step": 6000}
{"episode": 7.0, "batch_reward": 0.13589390493184328, "actor_loss": -30.860109413146972, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.070178985595703, "episode_reward": 187.60712535406472, "step": 7000}
{"episode": 8.0, "batch_reward": 0.14028545248508453, "actor_loss": -31.37416817855835, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.191504955291748, "episode_reward": 179.92649647488014, "step": 8000}
{"episode": 9.0, "batch_reward": 0.14019655936956404, "actor_loss": -31.191954513549806, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.368921041488647, "episode_reward": 54.39379573426166, "step": 9000}
{"episode": 10.0, "batch_reward": 0.13366937794536352, "actor_loss": -27.136569538116454, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 3750.545382499695, "episode_reward": 157.05283471194485, "step": 10000}
{"episode": 11.0, "batch_reward": 0.1366506764739752, "actor_loss": -27.690070991516112, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 34.29559922218323, "episode_reward": 173.56479072828256, "step": 11000}
{"episode": 12.0, "batch_reward": 0.14219454533606768, "actor_loss": -25.834184005737306, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 416.07338666915894, "episode_reward": 225.4814304883323, "step": 12000}
{"episode": 13.0, "batch_reward": 0.14446323654055596, "actor_loss": -25.80758472442627, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.2912335395813, "episode_reward": 48.922600178241225, "step": 13000}
{"episode": 14.0, "batch_reward": 0.14078150913119317, "actor_loss": -23.56016019439697, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 412.0878357887268, "episode_reward": 224.59528264334116, "step": 14000}
{"episode": 15.0, "batch_reward": 0.1482665026411414, "actor_loss": -24.412761287689207, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.593509435653687, "episode_reward": 236.83400054578826, "step": 15000}
{"episode": 16.0, "batch_reward": 0.15547257547080517, "actor_loss": -23.87547159957886, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 414.5201299190521, "episode_reward": 278.7929087921268, "step": 16000}
{"episode": 17.0, "batch_reward": 0.16363122254610063, "actor_loss": -24.631476039886476, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.457489013671875, "episode_reward": 274.32359246230624, "step": 17000}
{"episode": 18.0, "batch_reward": 0.16950302465260028, "actor_loss": -24.190065803527833, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 406.3397014141083, "episode_reward": 269.4172488496161, "step": 18000}
{"episode": 19.0, "batch_reward": 0.17234047594666482, "actor_loss": -24.401025135040282, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 15.843473672866821, "episode_reward": 148.71943983506893, "step": 19000}
{"episode": 20.0, "batch_reward": 0.1716727030724287, "actor_loss": -22.99652248764038, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 419.13671922683716, "episode_reward": 174.93247497342054, "step": 20000}
{"episode": 21.0, "batch_reward": 0.17162034405767917, "actor_loss": -22.93979217529297, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 32.63138389587402, "episode_reward": 162.3906131758277, "step": 21000}
{"episode": 22.0, "batch_reward": 0.17356153143942357, "actor_loss": -22.581631439208984, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 405.5231475830078, "episode_reward": 289.7141049613716, "step": 22000}
{"episode": 23.0, "batch_reward": 0.1777819851189852, "actor_loss": -23.051495532989502, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.581488609313965, "episode_reward": 275.87021777853477, "step": 23000}
{"episode": 24.0, "batch_reward": 0.181912985637784, "actor_loss": -22.870768859863283, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 408.098997592926, "episode_reward": 253.5889795470449, "step": 24000}
{"episode": 25.0, "batch_reward": 0.18586431258916855, "actor_loss": -23.279825695037843, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.062527418136597, "episode_reward": 311.3396172480521, "step": 25000}
{"episode": 26.0, "batch_reward": 0.1867188045680523, "actor_loss": -22.451320388793945, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 404.48627829551697, "episode_reward": 59.90989644864468, "step": 26000}
{"episode": 27.0, "batch_reward": 0.1852687951028347, "actor_loss": -21.98443631362915, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.429808378219604, "episode_reward": 314.96857952880924, "step": 27000}
{"episode": 28.0, "batch_reward": 0.19057229641079904, "actor_loss": -21.48919470214844, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 410.50794672966003, "episode_reward": 285.9040461510633, "step": 28000}
{"episode": 29.0, "batch_reward": 0.19461795657873154, "actor_loss": -21.97628863143921, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.465793132781982, "episode_reward": 314.2696288766262, "step": 29000}
{"episode": 30.0, "batch_reward": 0.19826288503408432, "actor_loss": -21.835160720825197, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 404.5383257865906, "episode_reward": 329.9649471402916, "step": 30000}
{"episode": 31.0, "batch_reward": 0.20316460487246513, "actor_loss": -22.30221435546875, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 34.21415615081787, "episode_reward": 333.17679172312126, "step": 31000}
{"episode": 32.0, "batch_reward": 0.2063061597943306, "actor_loss": -21.996876750946043, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 412.1669270992279, "episode_reward": 331.4502353505648, "step": 32000}
{"episode": 33.0, "batch_reward": 0.20882534021139146, "actor_loss": -22.285218505859376, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.861875772476196, "episode_reward": 322.2089490191922, "step": 33000}
{"episode": 34.0, "batch_reward": 0.21049391414225102, "actor_loss": -21.590271236419678, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 410.78138875961304, "episode_reward": 57.1679986939738, "step": 34000}
{"episode": 35.0, "batch_reward": 0.2092080145776272, "actor_loss": -21.22819063949585, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.530323266983032, "episode_reward": 330.47963106711427, "step": 35000}
{"episode": 36.0, "batch_reward": 0.21202597123384476, "actor_loss": -20.5111610622406, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 416.2236638069153, "episode_reward": 338.1115127682679, "step": 36000}
{"episode": 37.0, "batch_reward": 0.21603368234634399, "actor_loss": -21.028821578979493, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.456241130828857, "episode_reward": 345.70310282606744, "step": 37000}
{"episode": 38.0, "batch_reward": 0.21967620642483235, "actor_loss": -20.53721103477478, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 408.39563632011414, "episode_reward": 355.91957924986986, "step": 38000}
{"episode": 39.0, "batch_reward": 0.22299963745474816, "actor_loss": -21.066773139953614, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.49345874786377, "episode_reward": 339.5928135840147, "step": 39000}
{"episode": 40.0, "batch_reward": 0.22698668971657754, "actor_loss": -20.71512265586853, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 414.3868179321289, "episode_reward": 370.24985452323665, "step": 40000}
{"episode": 41.0, "batch_reward": 0.23075297550857068, "actor_loss": -21.225947259902956, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 32.64011740684509, "episode_reward": 371.07919652526033, "step": 41000}
{"episode": 42.0, "batch_reward": 0.2338525121510029, "actor_loss": -21.119745655059816, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 396.78328680992126, "episode_reward": 298.0590539872313, "step": 42000}
{"episode": 43.0, "batch_reward": 0.23541859386861325, "actor_loss": -21.584511686325072, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.320953130722046, "episode_reward": 366.5489901740213, "step": 43000}
{"episode": 44.0, "batch_reward": 0.2379619816839695, "actor_loss": -21.613085849761962, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 409.9733455181122, "episode_reward": 377.81062110137105, "step": 44000}
{"episode": 45.0, "batch_reward": 0.2411548377275467, "actor_loss": -22.033321701049804, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.52934765815735, "episode_reward": 369.9623654510113, "step": 45000}
{"episode": 46.0, "batch_reward": 0.24380358715355396, "actor_loss": -21.954273832321167, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 410.8355972766876, "episode_reward": 329.41611497539355, "step": 46000}
{"episode": 47.0, "batch_reward": 0.24591499882936477, "actor_loss": -22.346908924102785, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.190596103668213, "episode_reward": 360.29830148710164, "step": 47000}
{"episode": 48.0, "batch_reward": 0.24825459164381028, "actor_loss": -22.506947677612306, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 410.6946346759796, "episode_reward": 370.8583022970991, "step": 48000}
{"episode": 49.0, "batch_reward": 0.25121819791197775, "actor_loss": -22.954005250930788, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.462889909744263, "episode_reward": 358.633550070228, "step": 49000}
{"episode": 50.0, "batch_reward": 0.25217032100260256, "actor_loss": -23.51979242324829, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 413.2282042503357, "episode_reward": 336.7004272255278, "step": 50000}
{"episode": 51.0, "batch_reward": 0.2538112323433161, "actor_loss": -23.789141986846925, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 34.80482506752014, "episode_reward": 344.3399308859138, "step": 51000}
{"episode": 52.0, "batch_reward": 0.2558277302235365, "actor_loss": -23.86360160827637, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 415.3463354110718, "episode_reward": 350.0650157164976, "step": 52000}
{"episode": 53.0, "batch_reward": 0.25820972153544425, "actor_loss": -23.919230655670166, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.5840585231781, "episode_reward": 352.27410060168046, "step": 53000}
{"episode": 54.0, "batch_reward": 0.2601239404529333, "actor_loss": -23.985745807647707, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 418.4225208759308, "episode_reward": 336.77703731839, "step": 54000}
{"episode": 55.0, "batch_reward": 0.2609600986242294, "actor_loss": -24.264090396881105, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.015928745269775, "episode_reward": 268.976444191265, "step": 55000}
{"episode": 56.0, "batch_reward": 0.26153672602772715, "actor_loss": -24.269363258361818, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 410.41609835624695, "episode_reward": 363.5055565495393, "step": 56000}
{"episode": 57.0, "batch_reward": 0.26353627452254297, "actor_loss": -24.624387313842774, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.531827211380005, "episode_reward": 369.243231128389, "step": 57000}
{"episode": 58.0, "batch_reward": 0.26444588498771193, "actor_loss": -24.377225757598875, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 410.7623858451843, "episode_reward": 328.28525893187503, "step": 58000}
{"episode": 59.0, "batch_reward": 0.2659353350698948, "actor_loss": -24.490330978393555, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.24371099472046, "episode_reward": 339.2403419982211, "step": 59000}
{"episode": 60.0, "batch_reward": 0.2670853054225445, "actor_loss": -24.643389492034913, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 406.4737021923065, "episode_reward": 328.4284309888097, "step": 60000}
{"episode": 61.0, "batch_reward": 0.26831776584684847, "actor_loss": -24.724249328613283, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 35.00925636291504, "episode_reward": 341.86715052708354, "step": 61000}
{"episode": 62.0, "batch_reward": 0.2690666644722223, "actor_loss": -24.638708377838135, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 407.3797845840454, "episode_reward": 349.29244027433737, "step": 62000}
{"episode": 63.0, "batch_reward": 0.27076033532619476, "actor_loss": -24.850661952972413, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.513038158416748, "episode_reward": 337.7952366979327, "step": 63000}
{"episode": 64.0, "batch_reward": 0.2719382034689188, "actor_loss": -24.20847229003906, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 404.83772587776184, "episode_reward": 340.80368141804615, "step": 64000}
{"episode": 65.0, "batch_reward": 0.2731609992533922, "actor_loss": -24.309018268585206, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.686567783355713, "episode_reward": 333.3639119257755, "step": 65000}
{"episode": 66.0, "batch_reward": 0.2739318934828043, "actor_loss": -24.23856046676636, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 410.61239194869995, "episode_reward": 365.27640654380394, "step": 66000}
{"episode": 67.0, "batch_reward": 0.27525624677538874, "actor_loss": -24.455804420471193, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.46609902381897, "episode_reward": 345.70354241930147, "step": 67000}
{"episode": 68.0, "batch_reward": 0.2761926146149635, "actor_loss": -24.496064575195312, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 409.66175079345703, "episode_reward": 348.54081150713836, "step": 68000}
{"episode": 69.0, "batch_reward": 0.2770040135681629, "actor_loss": -24.49421657562256, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.92523741722107, "episode_reward": 332.67128880590707, "step": 69000}
{"episode": 70.0, "batch_reward": 0.2774863038212061, "actor_loss": -24.24577407836914, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 409.1751539707184, "episode_reward": 352.99757752280175, "step": 70000}
{"episode": 71.0, "batch_reward": 0.27883667662739753, "actor_loss": -24.31806143951416, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 36.08602833747864, "episode_reward": 351.2769341417207, "step": 71000}
{"episode": 72.0, "batch_reward": 0.28019087022542954, "actor_loss": -24.56446487045288, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 412.8221309185028, "episode_reward": 348.6667981745772, "step": 72000}
{"episode": 73.0, "batch_reward": 0.2808061645776033, "actor_loss": -24.582763858795165, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.47358274459839, "episode_reward": 344.39546650408664, "step": 73000}
{"episode": 74.0, "batch_reward": 0.28195606857538225, "actor_loss": -24.269835891723634, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 420.75134086608887, "episode_reward": 331.3042239911071, "step": 74000}
{"episode": 75.0, "batch_reward": 0.2822598399221897, "actor_loss": -24.32441763687134, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.3591468334198, "episode_reward": 296.5985470810974, "step": 75000}
{"episode": 76.0, "batch_reward": 0.28238255487382413, "actor_loss": -24.548848442077638, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 414.5447280406952, "episode_reward": 345.3684245563497, "step": 76000}
{"episode": 77.0, "batch_reward": 0.2834664653837681, "actor_loss": -24.821604835510254, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.953006744384766, "episode_reward": 353.4475707245824, "step": 77000}
{"episode": 78.0, "batch_reward": 0.284871508538723, "actor_loss": -24.49828996658325, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 413.6874349117279, "episode_reward": 346.56084096313674, "step": 78000}
{"episode": 79.0, "batch_reward": 0.2842475117594004, "actor_loss": -24.523367153167726, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.6604745388031, "episode_reward": 138.9246766038064, "step": 79000}
{"episode": 80.0, "batch_reward": 0.28324593910574913, "actor_loss": -23.94494010925293, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 410.7754681110382, "episode_reward": 339.9073265060543, "step": 80000}
{"episode": 81.0, "batch_reward": 0.2842221647202969, "actor_loss": -23.999080699920654, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 32.67729926109314, "episode_reward": 326.3418451819458, "step": 81000}
{"episode": 82.0, "batch_reward": 0.2844516379833221, "actor_loss": -24.162264434814453, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 411.4357099533081, "episode_reward": 339.06911578092013, "step": 82000}
{"episode": 83.0, "batch_reward": 0.2855075487047434, "actor_loss": -24.23513688659668, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.351245641708374, "episode_reward": 337.7890791943094, "step": 83000}
{"episode": 84.0, "batch_reward": 0.28540538373589514, "actor_loss": -24.093800315856935, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 404.6686689853668, "episode_reward": 325.36352838890576, "step": 84000}
{"episode": 85.0, "batch_reward": 0.2864518916606903, "actor_loss": -24.37211458206177, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.44761061668396, "episode_reward": 287.07404029657084, "step": 85000}
{"episode": 86.0, "batch_reward": 0.2851128665804863, "actor_loss": -24.128898990631104, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 418.2455985546112, "episode_reward": 198.66393504388853, "step": 86000}
{"episode": 87.0, "batch_reward": 0.2854841439425945, "actor_loss": -23.973361011505126, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.15658926963806, "episode_reward": 357.7267646857958, "step": 87000}
{"episode": 88.0, "batch_reward": 0.28604003444314, "actor_loss": -23.990960971832276, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 415.28345370292664, "episode_reward": 290.5180455792895, "step": 88000}
{"episode": 89.0, "batch_reward": 0.2864687721729279, "actor_loss": -24.206450511932374, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.703261613845825, "episode_reward": 320.2289310825062, "step": 89000}
{"episode": 90.0, "batch_reward": 0.28655388033390045, "actor_loss": -23.90060238647461, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 422.77209734916687, "episode_reward": 371.63341295448856, "step": 90000}
{"episode": 91.0, "batch_reward": 0.2878131677210331, "actor_loss": -23.989766185760498, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 33.96406579017639, "episode_reward": 373.07197968703684, "step": 91000}
{"episode": 92.0, "batch_reward": 0.28868450540304186, "actor_loss": -24.206044647216796, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 407.64407563209534, "episode_reward": 372.2847421436157, "step": 92000}
{"episode": 93.0, "batch_reward": 0.2897801130712032, "actor_loss": -24.357069915771483, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.652180910110474, "episode_reward": 348.57414285070183, "step": 93000}
{"episode": 94.0, "batch_reward": 0.2903931039273739, "actor_loss": -24.84050503921509, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 417.5923705101013, "episode_reward": 380.85761987198396, "step": 94000}
{"episode": 95.0, "batch_reward": 0.29167021629214285, "actor_loss": -25.014729106903076, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.501056671142578, "episode_reward": 363.1532524078335, "step": 95000}
{"episode": 96.0, "batch_reward": 0.29087383887171747, "actor_loss": -24.102018131256102, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 411.51608085632324, "episode_reward": 296.3948376195918, "step": 96000}
{"episode": 97.0, "batch_reward": 0.2911889107525349, "actor_loss": -24.2426534576416, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.3560893535614, "episode_reward": 227.07766177513082, "step": 97000}
{"episode": 98.0, "batch_reward": 0.2904775939881802, "actor_loss": -24.02375489807129, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 408.1184072494507, "episode_reward": 273.7519906212651, "step": 98000}
{"episode": 99.0, "batch_reward": 0.29061512485146523, "actor_loss": -24.101609283447267, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.509208917617798, "episode_reward": 298.1473585024294, "step": 99000}
{"episode": 100.0, "batch_reward": 0.28976299011707307, "actor_loss": -24.356662593841552, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 407.5782108306885, "episode_reward": 153.9390703586629, "step": 100000}
{"episode": 101.0, "batch_reward": 0.2893771615922451, "actor_loss": -24.180189838409422, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 32.739250898361206, "episode_reward": 298.8016148892119, "step": 101000}
{"episode": 102.0, "batch_reward": 0.28862605279684067, "actor_loss": -24.46235391616821, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 416.4851655960083, "episode_reward": 138.57246687447287, "step": 102000}
{"episode": 103.0, "batch_reward": 0.28663509371876716, "actor_loss": -24.519910541534422, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.781497716903687, "episode_reward": 84.86266695274938, "step": 103000}
{"episode": 104.0, "batch_reward": 0.2856924133002758, "actor_loss": -24.40076132965088, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 407.44188046455383, "episode_reward": 292.98602321898863, "step": 104000}
{"episode": 105.0, "batch_reward": 0.2862461023628712, "actor_loss": -24.480734287261964, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.37592911720276, "episode_reward": 179.7199825685682, "step": 105000}
{"episode": 106.0, "batch_reward": 0.2849676520675421, "actor_loss": -24.38944940185547, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 408.6973946094513, "episode_reward": 242.84919682601893, "step": 106000}
{"episode": 107.0, "batch_reward": 0.2849537599980831, "actor_loss": -24.52984135055542, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.466175317764282, "episode_reward": 264.93870614871906, "step": 107000}
{"episode": 108.0, "batch_reward": 0.28495050758123397, "actor_loss": -25.18330793762207, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 405.23093366622925, "episode_reward": 321.61501882325865, "step": 108000}
{"episode": 109.0, "batch_reward": 0.28455581641197203, "actor_loss": -25.08612271118164, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.450820446014404, "episode_reward": 295.0325323051211, "step": 109000}
{"episode": 110.0, "batch_reward": 0.28433732292056085, "actor_loss": -24.936142803192137, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 417.20353150367737, "episode_reward": 171.96061153216527, "step": 110000}
{"episode": 111.0, "batch_reward": 0.2835198976546526, "actor_loss": -24.95484796524048, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 36.02045035362244, "episode_reward": 292.42485973520445, "step": 111000}
{"episode": 112.0, "batch_reward": 0.2838853568732739, "actor_loss": -25.58907096481323, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 412.1818630695343, "episode_reward": 306.08512320395255, "step": 112000}
{"episode": 113.0, "batch_reward": 0.2840057387948036, "actor_loss": -25.662700969696044, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.517261266708374, "episode_reward": 284.628143568378, "step": 113000}
{"episode": 114.0, "batch_reward": 0.2836518893241882, "actor_loss": -26.35062903213501, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 420.18588042259216, "episode_reward": 285.0359548565924, "step": 114000}
{"episode": 115.0, "batch_reward": 0.2836829213649035, "actor_loss": -26.299797924041748, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.646745681762695, "episode_reward": 221.84915005432413, "step": 115000}
{"episode": 116.0, "batch_reward": 0.2841633933186531, "actor_loss": -27.171367561340332, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 413.81231570243835, "episode_reward": 318.82112559928464, "step": 116000}
{"episode": 117.0, "batch_reward": 0.2832621396780014, "actor_loss": -27.14484938812256, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.59457492828369, "episode_reward": 370.78840472740796, "step": 117000}
{"episode": 118.0, "batch_reward": 0.285208724796772, "actor_loss": -27.38556774520874, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 420.85652470588684, "episode_reward": 335.3133314336489, "step": 118000}
{"episode": 119.0, "batch_reward": 0.2853508777618408, "actor_loss": -27.45598720550537, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.61833620071411, "episode_reward": 359.1576479342447, "step": 119000}
{"episode": 120.0, "batch_reward": 0.2861297157406807, "actor_loss": -27.785935913085936, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 416.13254165649414, "episode_reward": 340.79825874431646, "step": 120000}
{"episode": 121.0, "batch_reward": 0.2862934909313917, "actor_loss": -27.741952625274656, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 32.805964946746826, "episode_reward": 331.59872646770924, "step": 121000}
{"episode": 122.0, "batch_reward": 0.2865060655772686, "actor_loss": -28.160054302215578, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 411.07499074935913, "episode_reward": 192.65482138932293, "step": 122000}
{"episode": 123.0, "batch_reward": 0.2857518821954727, "actor_loss": -28.121813499450685, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.611950635910034, "episode_reward": 323.86180739536024, "step": 123000}
{"episode": 124.0, "batch_reward": 0.28586362017691136, "actor_loss": -28.86114485549927, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 405.4869747161865, "episode_reward": 272.3151969364687, "step": 124000}
{"episode": 125.0, "batch_reward": 0.2855056759864092, "actor_loss": -28.968947120666503, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.85145926475525, "episode_reward": 47.53567786601658, "step": 125000}
{"episode": 126.0, "batch_reward": 0.2839287231117487, "actor_loss": -28.098445713043212, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 408.7630031108856, "episode_reward": 208.62586161456557, "step": 126000}
{"episode": 127.0, "batch_reward": 0.28336053374409675, "actor_loss": -27.99149127960205, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 15.920861959457397, "episode_reward": 191.15985034015472, "step": 127000}
{"episode": 128.0, "batch_reward": 0.2836019379198551, "actor_loss": -28.40018183898926, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 411.5895507335663, "episode_reward": 304.97392176254505, "step": 128000}
{"episode": 129.0, "batch_reward": 0.28285687959194183, "actor_loss": -28.370906826019286, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.5108642578125, "episode_reward": 317.73213480967036, "step": 129000}
{"episode": 130.0, "batch_reward": 0.28296719160676004, "actor_loss": -28.29184596633911, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 409.32405614852905, "episode_reward": 314.77380167394256, "step": 130000}
{"episode": 131.0, "batch_reward": 0.2830222234725952, "actor_loss": -28.254678787231445, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 31.089593172073364, "episode_reward": 300.5982872738445, "step": 131000}
{"episode": 132.0, "batch_reward": 0.2836740429699421, "actor_loss": -28.087323501586916, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 412.1698684692383, "episode_reward": 308.50531469179504, "step": 132000}
{"episode": 133.0, "batch_reward": 0.284159371137619, "actor_loss": -28.21638073348999, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.040210962295532, "episode_reward": 308.0393053443262, "step": 133000}
{"episode": 134.0, "batch_reward": 0.28344088104367254, "actor_loss": -28.11071256637573, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 405.91122126579285, "episode_reward": 263.80663013813034, "step": 134000}
{"episode": 135.0, "batch_reward": 0.2838961328417063, "actor_loss": -28.105654315948485, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.739460468292236, "episode_reward": 261.9792138062535, "step": 135000}
{"episode": 136.0, "batch_reward": 0.28370912416279315, "actor_loss": -28.25946812057495, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 410.5294919013977, "episode_reward": 281.2657431436796, "step": 136000}
{"episode": 137.0, "batch_reward": 0.2833423816859722, "actor_loss": -28.10420791244507, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.73204231262207, "episode_reward": 301.42319085543517, "step": 137000}
{"episode": 138.0, "batch_reward": 0.2839827204197645, "actor_loss": -27.91133846282959, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 410.3630621433258, "episode_reward": 298.83621343116044, "step": 138000}
{"episode": 139.0, "batch_reward": 0.28363068360090254, "actor_loss": -27.891661994934083, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.80952000617981, "episode_reward": 274.1375186406127, "step": 139000}
{"episode": 140.0, "batch_reward": 0.2833790217936039, "actor_loss": -27.567944843292235, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 408.2282838821411, "episode_reward": 343.7849537689279, "step": 140000}
{"episode": 141.0, "batch_reward": 0.28437070646882057, "actor_loss": -27.675983203887938, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 36.259949922561646, "episode_reward": 340.53175528138013, "step": 141000}
{"episode": 142.0, "batch_reward": 0.2850761496126652, "actor_loss": -27.599500228881837, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 413.47526454925537, "episode_reward": 350.43688233205813, "step": 142000}
{"episode": 143.0, "batch_reward": 0.28496896907687186, "actor_loss": -27.692489334106444, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 15.476854801177979, "episode_reward": 342.97760152303937, "step": 143000}
{"episode": 144.0, "batch_reward": 0.2852829361408949, "actor_loss": -27.541522647857665, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 416.65316367149353, "episode_reward": 332.98103438057245, "step": 144000}
{"episode": 145.0, "batch_reward": 0.28645415443181993, "actor_loss": -27.43892275238037, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.85952591896057, "episode_reward": 327.6858080004892, "step": 145000}
{"episode": 146.0, "batch_reward": 0.28595031237602236, "actor_loss": -27.54982136154175, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 415.75594782829285, "episode_reward": 344.5944883493596, "step": 146000}
{"episode": 147.0, "batch_reward": 0.2872403476089239, "actor_loss": -27.55718669128418, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.142748594284058, "episode_reward": 359.6466650576457, "step": 147000}
{"episode": 148.0, "batch_reward": 0.28743433773517607, "actor_loss": -27.622069831848144, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 419.9693968296051, "episode_reward": 369.8954003426702, "step": 148000}
{"episode": 149.0, "batch_reward": 0.2881895402669907, "actor_loss": -27.714471961975097, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.23315930366516, "episode_reward": 381.40450867918634, "step": 149000}
{"episode": 150.0, "batch_reward": 0.28759895732998847, "actor_loss": -27.72195404815674, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "step": 150000}
