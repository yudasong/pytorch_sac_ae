{"episode": 1.0, "duration": 17.551931381225586, "episode_reward": 4.231880753996205, "step": 1000}
{"episode": 2.0, "duration": 1.6443679332733154, "episode_reward": 395.1450543749875, "step": 2000}
{"episode": 3.0, "batch_reward": 0.1883486751671949, "actor_loss": -41.207686337340874, "actor_target_entropy": -6.0, "alpha_value": 0.010699999250839183, "duration": 48.90293025970459, "episode_reward": 20.93084149664024, "step": 3000}
{"episode": 4.0, "batch_reward": 0.12519909945875407, "actor_loss": -34.03130587005615, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 15.611305475234985, "episode_reward": 30.468752798744923, "step": 4000}
{"episode": 5.0, "batch_reward": 0.10707162891328335, "actor_loss": -33.444294761657716, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.106932163238525, "episode_reward": 55.69337577130395, "step": 5000}
{"episode": 6.0, "batch_reward": 0.09677145567908883, "actor_loss": -33.02355170822143, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.94797110557556, "episode_reward": 44.793738442836236, "step": 6000}
{"episode": 7.0, "batch_reward": 0.09038883526995778, "actor_loss": -32.73955949020386, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.84138298034668, "episode_reward": 64.02088059624042, "step": 7000}
{"episode": 8.0, "batch_reward": 0.08699005256220699, "actor_loss": -32.560452445983884, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.367320775985718, "episode_reward": 83.11903191468636, "step": 8000}
{"episode": 9.0, "batch_reward": 0.08890496891364455, "actor_loss": -32.40740613937378, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.652100801467896, "episode_reward": 96.15118713287949, "step": 9000}
{"episode": 10.0, "batch_reward": 0.09134589982032776, "actor_loss": -28.651906494140626, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 3820.56378531456, "episode_reward": 158.41295830906694, "step": 10000}
{"episode": 11.0, "batch_reward": 0.0970375521928072, "actor_loss": -28.75602334213257, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 36.61803722381592, "episode_reward": 105.47348582907951, "step": 11000}
{"episode": 12.0, "batch_reward": 0.09494394988566637, "actor_loss": -25.755139888763427, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 417.55366706848145, "episode_reward": 43.92398571815716, "step": 12000}
{"episode": 13.0, "batch_reward": 0.09424758721515536, "actor_loss": -25.12176692199707, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 15.701649904251099, "episode_reward": 115.10462194365844, "step": 13000}
{"episode": 14.0, "batch_reward": 0.096568895727396, "actor_loss": -23.275790439605714, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 421.1893413066864, "episode_reward": 181.9489870452387, "step": 14000}
{"episode": 15.0, "batch_reward": 0.10223566058278084, "actor_loss": -23.57813564682007, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.59801936149597, "episode_reward": 104.0613982809213, "step": 15000}
{"episode": 16.0, "batch_reward": 0.10269441587477922, "actor_loss": -21.7483596496582, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 416.66818475723267, "episode_reward": 216.71338951590897, "step": 16000}
{"episode": 17.0, "batch_reward": 0.1064805806055665, "actor_loss": -21.68053416824341, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 15.69582462310791, "episode_reward": 45.93574823263784, "step": 17000}
{"episode": 18.0, "batch_reward": 0.10612120970338583, "actor_loss": -19.7500931224823, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 422.6207447052002, "episode_reward": 194.08177469838566, "step": 18000}
{"episode": 19.0, "batch_reward": 0.11165850361436605, "actor_loss": -20.454831016540528, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.835402011871338, "episode_reward": 203.0205730396494, "step": 19000}
{"episode": 20.0, "batch_reward": 0.11634660000354051, "actor_loss": -19.42469326400757, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 415.58192443847656, "episode_reward": 157.9197519281274, "step": 20000}
{"episode": 21.0, "batch_reward": 0.11914301726222039, "actor_loss": -19.46814539527893, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 33.06482291221619, "episode_reward": 252.74201219842288, "step": 21000}
{"episode": 22.0, "batch_reward": 0.12543124652653934, "actor_loss": -19.203073184967042, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 417.85862135887146, "episode_reward": 223.12413568422292, "step": 22000}
{"episode": 23.0, "batch_reward": 0.12775351569801568, "actor_loss": -19.590722312927245, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.336525917053223, "episode_reward": 179.28631992876, "step": 23000}
{"episode": 24.0, "batch_reward": 0.1309026658460498, "actor_loss": -19.164104431152342, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 412.32280349731445, "episode_reward": 215.21682617746563, "step": 24000}
{"episode": 25.0, "batch_reward": 0.13552016208320855, "actor_loss": -19.76133871269226, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.970155715942383, "episode_reward": 245.1997140165413, "step": 25000}
{"episode": 26.0, "batch_reward": 0.13912329260259867, "actor_loss": -19.583609930038453, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 422.0545313358307, "episode_reward": 197.9247937063092, "step": 26000}
{"episode": 27.0, "batch_reward": 0.14109032115340234, "actor_loss": -19.87201396560669, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.320053339004517, "episode_reward": 239.60296628584808, "step": 27000}
{"episode": 28.0, "batch_reward": 0.14416720108687878, "actor_loss": -19.490862325668335, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 413.17947030067444, "episode_reward": 195.74713852582002, "step": 28000}
{"episode": 29.0, "batch_reward": 0.1467027945816517, "actor_loss": -19.9459607963562, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.785754919052124, "episode_reward": 197.97790861222379, "step": 29000}
{"episode": 30.0, "batch_reward": 0.14762239854037762, "actor_loss": -19.398082929611206, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 418.277708530426, "episode_reward": 163.80525583213628, "step": 30000}
{"episode": 31.0, "batch_reward": 0.14871843165159226, "actor_loss": -19.53905488204956, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 34.89789843559265, "episode_reward": 211.35317075278675, "step": 31000}
{"episode": 32.0, "batch_reward": 0.15020771697163582, "actor_loss": -19.359799392700197, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 417.16697883605957, "episode_reward": 178.14071675567118, "step": 32000}
{"episode": 33.0, "batch_reward": 0.15105997915565966, "actor_loss": -19.506741012573244, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.72127389907837, "episode_reward": 207.28725005531197, "step": 33000}
{"episode": 34.0, "batch_reward": 0.1535228979885578, "actor_loss": -19.57885013961792, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 418.5677390098572, "episode_reward": 241.68441583172537, "step": 34000}
{"episode": 35.0, "batch_reward": 0.1567508380487561, "actor_loss": -19.96045536994934, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 15.718644857406616, "episode_reward": 261.04768166539503, "step": 35000}
{"episode": 36.0, "batch_reward": 0.15860520462691785, "actor_loss": -19.949949314117433, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 415.4837667942047, "episode_reward": 248.75377456901302, "step": 36000}
{"episode": 37.0, "batch_reward": 0.1613551330268383, "actor_loss": -20.27251910018921, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.92596745491028, "episode_reward": 255.65767831006718, "step": 37000}
{"episode": 38.0, "batch_reward": 0.16331699602305888, "actor_loss": -20.42712704849243, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 419.0452609062195, "episode_reward": 188.13611609517787, "step": 38000}
{"episode": 39.0, "batch_reward": 0.16415471033751963, "actor_loss": -20.77078776931763, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 15.733542919158936, "episode_reward": 196.98318258393058, "step": 39000}
{"episode": 40.0, "batch_reward": 0.1652081084251404, "actor_loss": -20.730684448242187, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 422.3762972354889, "episode_reward": 209.00093332281517, "step": 40000}
{"episode": 41.0, "batch_reward": 0.1663890722543001, "actor_loss": -20.87302545928955, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 34.404974699020386, "episode_reward": 196.03095630951864, "step": 41000}
{"episode": 42.0, "batch_reward": 0.16688520747423172, "actor_loss": -20.924165870666503, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 410.5624234676361, "episode_reward": 231.24714116099497, "step": 42000}
{"episode": 43.0, "batch_reward": 0.1688888290077448, "actor_loss": -21.17479898071289, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.799233436584473, "episode_reward": 238.46135321451837, "step": 43000}
{"episode": 44.0, "batch_reward": 0.17038324315845965, "actor_loss": -21.083094680786132, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 420.2563211917877, "episode_reward": 240.43958129529437, "step": 44000}
{"episode": 45.0, "batch_reward": 0.17155673603713512, "actor_loss": -21.200445812225343, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.902342319488525, "episode_reward": 212.54464786455483, "step": 45000}
{"episode": 46.0, "batch_reward": 0.17269264155626296, "actor_loss": -21.111028324127197, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 416.6820766925812, "episode_reward": 251.64836240479073, "step": 46000}
{"episode": 47.0, "batch_reward": 0.1743236267119646, "actor_loss": -21.29027700805664, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.15085792541504, "episode_reward": 192.93804735980305, "step": 47000}
{"episode": 48.0, "batch_reward": 0.1750590480864048, "actor_loss": -21.13964122390747, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 420.31732273101807, "episode_reward": 241.3632024702645, "step": 48000}
{"episode": 49.0, "batch_reward": 0.17681089328229427, "actor_loss": -21.3073578414917, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.93851923942566, "episode_reward": 250.6205387270581, "step": 49000}
{"episode": 50.0, "batch_reward": 0.17740661504864694, "actor_loss": -21.36504665374756, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 414.087117433548, "episode_reward": 199.39484226608835, "step": 50000}
{"episode": 51.0, "batch_reward": 0.1779681466370821, "actor_loss": -21.47142587661743, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 34.12149667739868, "episode_reward": 197.39691500183557, "step": 51000}
{"episode": 52.0, "batch_reward": 0.17848882007598876, "actor_loss": -20.64531953430176, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 422.18571186065674, "episode_reward": 222.09087891288456, "step": 52000}
{"episode": 53.0, "batch_reward": 0.17929439416527748, "actor_loss": -20.665241764068604, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.42907476425171, "episode_reward": 215.27214789465586, "step": 53000}
{"episode": 54.0, "batch_reward": 0.18032590298354625, "actor_loss": -20.877647747039795, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 416.7236318588257, "episode_reward": 198.02210019098962, "step": 54000}
{"episode": 55.0, "batch_reward": 0.1801304352283478, "actor_loss": -21.028176532745363, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.83072543144226, "episode_reward": 182.6966190255753, "step": 55000}
{"episode": 56.0, "batch_reward": 0.17966037771105767, "actor_loss": -21.67988375091553, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 419.9704885482788, "episode_reward": 176.02668200419916, "step": 56000}
{"episode": 57.0, "batch_reward": 0.18008805254101753, "actor_loss": -21.785011993408204, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.87554097175598, "episode_reward": 194.9409378234162, "step": 57000}
{"episode": 58.0, "batch_reward": 0.18081843170523643, "actor_loss": -21.61441902923584, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 416.8342385292053, "episode_reward": 222.92404439310565, "step": 58000}
{"episode": 59.0, "batch_reward": 0.18126026864349842, "actor_loss": -21.684127250671388, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.00721549987793, "episode_reward": 205.10857062426743, "step": 59000}
{"episode": 60.0, "batch_reward": 0.1818280089199543, "actor_loss": -21.34753077316284, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 420.34070014953613, "episode_reward": 234.3515596299721, "step": 60000}
{"episode": 61.0, "batch_reward": 0.18269310227036475, "actor_loss": -21.460233100891113, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 32.99374175071716, "episode_reward": 229.10311681024262, "step": 61000}
{"episode": 62.0, "batch_reward": 0.1831991235613823, "actor_loss": -21.234980476379395, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 413.9977433681488, "episode_reward": 239.18927130340393, "step": 62000}
{"episode": 63.0, "batch_reward": 0.18437908302247524, "actor_loss": -21.418571765899657, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.460326194763184, "episode_reward": 207.30991009466356, "step": 63000}
{"episode": 64.0, "batch_reward": 0.18501726001501084, "actor_loss": -21.595705783843993, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 419.30023288726807, "episode_reward": 245.5416878029067, "step": 64000}
{"episode": 65.0, "batch_reward": 0.18566437688469886, "actor_loss": -21.678666561126708, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 15.793558835983276, "episode_reward": 241.94365103811597, "step": 65000}
{"episode": 66.0, "batch_reward": 0.1866666543930769, "actor_loss": -21.608227340698242, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 416.49005126953125, "episode_reward": 267.7089563303658, "step": 66000}
{"episode": 67.0, "batch_reward": 0.18781285151839255, "actor_loss": -21.73027262878418, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.199285745620728, "episode_reward": 241.37865787687258, "step": 67000}
{"episode": 68.0, "batch_reward": 0.18812126621603967, "actor_loss": -21.72496231842041, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 418.92356634140015, "episode_reward": 225.1654448559257, "step": 68000}
{"episode": 69.0, "batch_reward": 0.18965054647624494, "actor_loss": -21.787693424224855, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 15.966055393218994, "episode_reward": 273.9587189127507, "step": 69000}
{"episode": 70.0, "batch_reward": 0.1905550476759672, "actor_loss": -21.558181316375734, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 419.8339846134186, "episode_reward": 281.57526175972185, "step": 70000}
{"episode": 71.0, "batch_reward": 0.19168125092983246, "actor_loss": -21.59735871887207, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 36.80501413345337, "episode_reward": 286.8848961290162, "step": 71000}
{"episode": 72.0, "batch_reward": 0.19325832760334014, "actor_loss": -21.710997184753417, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 414.4406991004944, "episode_reward": 308.729073883711, "step": 72000}
{"episode": 73.0, "batch_reward": 0.19432923144102096, "actor_loss": -21.75865124130249, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.732900857925415, "episode_reward": 289.85282167614434, "step": 73000}
{"episode": 74.0, "batch_reward": 0.19612707389891149, "actor_loss": -21.661778129577637, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 420.5697145462036, "episode_reward": 318.9338040456479, "step": 74000}
{"episode": 75.0, "batch_reward": 0.19809794133901595, "actor_loss": -21.864541389465334, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.811923265457153, "episode_reward": 323.52092035685587, "step": 75000}
{"episode": 76.0, "batch_reward": 0.1996920148730278, "actor_loss": -22.230192489624024, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 413.59264850616455, "episode_reward": 284.0050648342968, "step": 76000}
{"episode": 77.0, "batch_reward": 0.20039893981814386, "actor_loss": -22.34889836883545, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.289512157440186, "episode_reward": 285.4735029761005, "step": 77000}
{"episode": 78.0, "batch_reward": 0.20190116938948632, "actor_loss": -22.250463344573976, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 421.15061211586, "episode_reward": 283.40870086336224, "step": 78000}
{"episode": 79.0, "batch_reward": 0.20299926257133483, "actor_loss": -22.3449454536438, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.24290180206299, "episode_reward": 283.1301732721052, "step": 79000}
{"episode": 80.0, "batch_reward": 0.2040028485059738, "actor_loss": -22.574327209472656, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 416.0228044986725, "episode_reward": 294.5658812197195, "step": 80000}
{"episode": 81.0, "batch_reward": 0.20499714083969592, "actor_loss": -22.623577709198, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 33.184571981430054, "episode_reward": 270.6074682586083, "step": 81000}
{"episode": 82.0, "batch_reward": 0.20580430638790131, "actor_loss": -22.921238361358643, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 418.9236238002777, "episode_reward": 239.66979167341285, "step": 82000}
{"episode": 83.0, "batch_reward": 0.20561440159380437, "actor_loss": -22.88500521850586, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.38249373435974, "episode_reward": 222.98698747593613, "step": 83000}
{"episode": 84.0, "batch_reward": 0.2063027820289135, "actor_loss": -23.279463108062743, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 412.77921175956726, "episode_reward": 338.3464859411766, "step": 84000}
{"episode": 85.0, "batch_reward": 0.20821405562758447, "actor_loss": -23.44357469177246, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.94353675842285, "episode_reward": 331.66095721955026, "step": 85000}
{"episode": 86.0, "batch_reward": 0.20888317066431045, "actor_loss": -23.33130972290039, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 419.4918625354767, "episode_reward": 289.312149714189, "step": 86000}
{"episode": 87.0, "batch_reward": 0.21048694282770156, "actor_loss": -23.56055694580078, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.23084855079651, "episode_reward": 335.68044735698254, "step": 87000}
{"episode": 88.0, "batch_reward": 0.2122451658397913, "actor_loss": -23.413008708953857, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 411.37068581581116, "episode_reward": 273.33725572551066, "step": 88000}
{"episode": 89.0, "batch_reward": 0.21256906686723231, "actor_loss": -23.517472332000732, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.73291325569153, "episode_reward": 288.6101726170715, "step": 89000}
{"episode": 90.0, "batch_reward": 0.21322318695485593, "actor_loss": -23.50709702682495, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 420.8397340774536, "episode_reward": 307.34178888070227, "step": 90000}
{"episode": 91.0, "batch_reward": 0.214248920917511, "actor_loss": -23.53092512893677, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 32.77731966972351, "episode_reward": 294.75947151376835, "step": 91000}
{"episode": 92.0, "batch_reward": 0.2150743753761053, "actor_loss": -23.607843643188478, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 405.89968085289, "episode_reward": 289.63402752100757, "step": 92000}
{"episode": 93.0, "batch_reward": 0.21549333807826043, "actor_loss": -23.686993106842042, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.733577013015747, "episode_reward": 273.61849792974846, "step": 93000}
{"episode": 94.0, "batch_reward": 0.2161957479417324, "actor_loss": -23.70907410430908, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 422.04792952537537, "episode_reward": 255.1483688111205, "step": 94000}
{"episode": 95.0, "batch_reward": 0.21702919681370259, "actor_loss": -23.747423748016356, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.88672685623169, "episode_reward": 313.6754656757901, "step": 95000}
{"episode": 96.0, "batch_reward": 0.21793587489426136, "actor_loss": -23.593181144714354, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 420.23091197013855, "episode_reward": 259.4410481307453, "step": 96000}
{"episode": 97.0, "batch_reward": 0.21837787199020386, "actor_loss": -23.735439952850342, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.25983738899231, "episode_reward": 229.36384289519268, "step": 97000}
{"episode": 98.0, "batch_reward": 0.21851775877177715, "actor_loss": -23.656611766815185, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 420.16380190849304, "episode_reward": 266.23014371762974, "step": 98000}
{"episode": 99.0, "batch_reward": 0.21890910230576993, "actor_loss": -23.717215770721435, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.515809297561646, "episode_reward": 272.23442963097455, "step": 99000}
{"episode": 100.0, "batch_reward": 0.2183330092281103, "actor_loss": -23.707570907592775, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 417.73415327072144, "episode_reward": 225.19074580669516, "step": 100000}
{"episode": 101.0, "batch_reward": 0.21958071430027484, "actor_loss": -23.769886009216307, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 33.45846438407898, "episode_reward": 303.5013914576488, "step": 101000}
{"episode": 102.0, "batch_reward": 0.21951271161437036, "actor_loss": -23.79434044265747, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 422.2515048980713, "episode_reward": 203.1855002777273, "step": 102000}
{"episode": 103.0, "batch_reward": 0.2197227766364813, "actor_loss": -23.8521869430542, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.0761981010437, "episode_reward": 231.67028083994222, "step": 103000}
{"episode": 104.0, "batch_reward": 0.2201059062629938, "actor_loss": -24.270518993377685, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 418.52553844451904, "episode_reward": 267.6218489058899, "step": 104000}
{"episode": 105.0, "batch_reward": 0.22057402962446213, "actor_loss": -24.37815146636963, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.7885262966156, "episode_reward": 236.15892248116438, "step": 105000}
{"episode": 106.0, "batch_reward": 0.22089355827867985, "actor_loss": -24.68945160293579, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 423.2694387435913, "episode_reward": 234.41243353830004, "step": 106000}
{"episode": 107.0, "batch_reward": 0.22065423762798309, "actor_loss": -24.51374967956543, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.709553241729736, "episode_reward": 48.01700828264807, "step": 107000}
{"episode": 108.0, "batch_reward": 0.21937216272950172, "actor_loss": -24.465963680267333, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 411.536447763443, "episode_reward": 288.02988745577505, "step": 108000}
{"episode": 109.0, "batch_reward": 0.2198291517049074, "actor_loss": -24.474667495727537, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.202721118927002, "episode_reward": 281.41952396546185, "step": 109000}
{"episode": 110.0, "batch_reward": 0.2199451823681593, "actor_loss": -24.692784732818602, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 418.432009935379, "episode_reward": 237.2330446219884, "step": 110000}
{"episode": 111.0, "batch_reward": 0.2201678414195776, "actor_loss": -24.64106304550171, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 33.80673384666443, "episode_reward": 99.45064765511965, "step": 111000}
{"episode": 112.0, "batch_reward": 0.2197804956883192, "actor_loss": -24.837012397766113, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 417.19557189941406, "episode_reward": 287.3416869725809, "step": 112000}
{"episode": 113.0, "batch_reward": 0.22004838129878043, "actor_loss": -24.89260506439209, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.727166891098022, "episode_reward": 279.4106094898226, "step": 113000}
{"episode": 114.0, "batch_reward": 0.22031397224962712, "actor_loss": -25.210431785583495, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 422.5681781768799, "episode_reward": 264.8090424499139, "step": 114000}
{"episode": 115.0, "batch_reward": 0.22079792046546937, "actor_loss": -25.170687236785888, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.134573936462402, "episode_reward": 241.1387108606526, "step": 115000}
{"episode": 116.0, "batch_reward": 0.22134501527249814, "actor_loss": -25.653048259735108, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 419.5918822288513, "episode_reward": 248.14101368327607, "step": 116000}
{"episode": 117.0, "batch_reward": 0.22167780475318433, "actor_loss": -25.70261725997925, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.014923095703125, "episode_reward": 266.60411403529474, "step": 117000}
{"episode": 118.0, "batch_reward": 0.22219561105966568, "actor_loss": -26.189786933898926, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 418.86767411231995, "episode_reward": 261.45412317746843, "step": 118000}
{"episode": 119.0, "batch_reward": 0.2220251434445381, "actor_loss": -26.21883280944824, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.104146480560303, "episode_reward": 271.97895895151765, "step": 119000}
{"episode": 120.0, "batch_reward": 0.22238810347020627, "actor_loss": -27.005237991333008, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 414.96691155433655, "episode_reward": 275.41333782309425, "step": 120000}
{"episode": 121.0, "batch_reward": 0.2231504652053118, "actor_loss": -27.108106525421142, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 33.823686838150024, "episode_reward": 277.40426926527607, "step": 121000}
{"episode": 122.0, "batch_reward": 0.2236496006399393, "actor_loss": -27.568447731018065, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 419.5446789264679, "episode_reward": 319.2954453186339, "step": 122000}
{"episode": 123.0, "batch_reward": 0.224196253195405, "actor_loss": -27.716740367889404, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.77942728996277, "episode_reward": 326.1809783753159, "step": 123000}
{"episode": 124.0, "batch_reward": 0.22525218173861503, "actor_loss": -28.29600413131714, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 421.4018623828888, "episode_reward": 320.9849209063823, "step": 124000}
{"episode": 125.0, "batch_reward": 0.2257644582092762, "actor_loss": -28.369344184875487, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.68523073196411, "episode_reward": 309.5884974872647, "step": 125000}
{"episode": 126.0, "batch_reward": 0.2264497152417898, "actor_loss": -28.481097248077393, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 414.19221925735474, "episode_reward": 265.3114221662073, "step": 126000}
{"episode": 127.0, "batch_reward": 0.22672888791561127, "actor_loss": -28.5596665725708, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.801005601882935, "episode_reward": 232.6979637456314, "step": 127000}
{"episode": 128.0, "batch_reward": 0.22707680836319924, "actor_loss": -28.566827617645263, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 420.24174070358276, "episode_reward": 287.4988037354878, "step": 128000}
{"episode": 129.0, "batch_reward": 0.22736795382201672, "actor_loss": -28.60422850418091, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.353609800338745, "episode_reward": 287.2615083762756, "step": 129000}
{"episode": 130.0, "batch_reward": 0.22820418833196163, "actor_loss": -28.79678812789917, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 416.8643419742584, "episode_reward": 308.9945501545553, "step": 130000}
{"episode": 131.0, "batch_reward": 0.2284416877180338, "actor_loss": -28.895593841552735, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 36.026113986968994, "episode_reward": 274.611441477929, "step": 131000}
{"episode": 132.0, "batch_reward": 0.2287787661254406, "actor_loss": -28.67664839172363, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 421.9328854084015, "episode_reward": 206.56948845307207, "step": 132000}
{"episode": 133.0, "batch_reward": 0.22845718502998352, "actor_loss": -28.71051917266846, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.280118465423584, "episode_reward": 227.50367059593168, "step": 133000}
{"episode": 134.0, "batch_reward": 0.22819479727745057, "actor_loss": -28.643959255218505, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 420.3568594455719, "episode_reward": 208.98438276546798, "step": 134000}
{"episode": 135.0, "batch_reward": 0.22879120244085788, "actor_loss": -28.721523708343504, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.706797122955322, "episode_reward": 245.04239216459334, "step": 135000}
{"episode": 136.0, "batch_reward": 0.2278550940454006, "actor_loss": -28.260487297058106, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 418.67177867889404, "episode_reward": 234.07849650457962, "step": 136000}
{"episode": 137.0, "batch_reward": 0.22896829438209534, "actor_loss": -28.400429050445556, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.46692132949829, "episode_reward": 267.99270147260836, "step": 137000}
{"episode": 138.0, "batch_reward": 0.2284908621609211, "actor_loss": -28.34088123703003, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 417.5295603275299, "episode_reward": 174.10183369980913, "step": 138000}
{"episode": 139.0, "batch_reward": 0.2279823905080557, "actor_loss": -28.362160400390625, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.82202458381653, "episode_reward": 151.48499248597423, "step": 139000}
{"episode": 140.0, "batch_reward": 0.22743776841461658, "actor_loss": -28.43707078933716, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 417.8640282154083, "episode_reward": 208.55284015601444, "step": 140000}
{"episode": 141.0, "batch_reward": 0.22721566535532475, "actor_loss": -28.35283144378662, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 32.83225989341736, "episode_reward": 201.00510092225167, "step": 141000}
{"episode": 142.0, "batch_reward": 0.2276024154573679, "actor_loss": -28.550978515625, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 409.3832428455353, "episode_reward": 230.16885707046512, "step": 142000}
{"episode": 143.0, "batch_reward": 0.2276650874465704, "actor_loss": -28.542997062683106, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.713106155395508, "episode_reward": 251.59761066083354, "step": 143000}
{"episode": 144.0, "batch_reward": 0.22730738180875779, "actor_loss": -28.541542572021484, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 412.57124400138855, "episode_reward": 189.12746956416711, "step": 144000}
{"episode": 145.0, "batch_reward": 0.22762407280504704, "actor_loss": -28.631264923095703, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 16.854188919067383, "episode_reward": 188.9007461105, "step": 145000}
{"episode": 146.0, "batch_reward": 0.22747537729144096, "actor_loss": -28.22281833267212, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 420.24037504196167, "episode_reward": 213.07900351710114, "step": 146000}
{"episode": 147.0, "batch_reward": 0.22724991519749166, "actor_loss": -28.139413589477538, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 17.31931781768799, "episode_reward": 209.77247215077327, "step": 147000}
{"episode": 148.0, "batch_reward": 0.22684859852492809, "actor_loss": -28.43347151184082, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 409.0347237586975, "episode_reward": 178.48107138914506, "step": 148000}
{"episode": 149.0, "batch_reward": 0.22622240893542767, "actor_loss": -28.41595714187622, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "duration": 18.35229754447937, "episode_reward": 212.6048759350345, "step": 149000}
{"episode": 150.0, "batch_reward": 0.2259875080883503, "actor_loss": -28.0795782661438, "actor_target_entropy": -6.0, "alpha_value": 0.01069999925083912, "step": 150000}
