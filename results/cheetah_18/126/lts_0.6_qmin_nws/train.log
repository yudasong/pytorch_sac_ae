{"episode_reward": 0.0, "episode": 1.0, "duration": 19.771498918533325, "step": 1000}
{"episode_reward": 4.231880753996205, "episode": 2.0, "duration": 1.6886587142944336, "step": 2000}
{"episode_reward": 395.1450543749875, "episode": 3.0, "batch_reward": 0.18762085346052274, "critic_loss": 0.037406921676922465, "actor_loss": -24.9569887028975, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 65.97810387611389, "step": 3000}
{"episode_reward": 8.622809988095, "episode": 4.0, "batch_reward": 0.12153450984507799, "critic_loss": 0.029753617564216257, "actor_loss": -20.697325192928314, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.18899440765381, "step": 4000}
{"episode_reward": 21.532820225765704, "episode": 5.0, "batch_reward": 0.10490096794441342, "critic_loss": 0.04188036606181413, "actor_loss": -19.89708811467886, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.11774516105652, "step": 5000}
{"episode_reward": 61.303909728360544, "episode": 6.0, "batch_reward": 0.09147384703159332, "critic_loss": 0.03006891542766243, "actor_loss": -17.029731722593308, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.3551983833313, "step": 6000}
{"episode_reward": 17.490772376356276, "episode": 7.0, "batch_reward": 0.08076016476377845, "critic_loss": 0.021988262189552188, "actor_loss": -16.96599906206131, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.73911142349243, "step": 7000}
{"episode_reward": 17.98516545598013, "episode": 8.0, "batch_reward": 0.0727706349119544, "critic_loss": 0.028286340162158013, "actor_loss": -18.619206684291363, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.33805227279663, "step": 8000}
{"episode_reward": 52.48257629495448, "episode": 9.0, "batch_reward": 0.07398111847043037, "critic_loss": 0.03607507732603699, "actor_loss": -17.76355856129527, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.056192636489868, "step": 9000}
{"episode_reward": 105.79224369881005, "episode": 10.0, "batch_reward": 0.07552710459008813, "critic_loss": 0.04089100442640484, "actor_loss": -18.464947775661944, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.089476108551025, "step": 10000}
{"episode_reward": 37.297323638550615, "episode": 11.0, "batch_reward": 0.07289826311543583, "critic_loss": 0.04409006339684129, "actor_loss": -17.605681994736194, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.62501358985901, "step": 11000}
{"episode_reward": 56.26146752922702, "episode": 12.0, "batch_reward": 0.07368522571772337, "critic_loss": 0.057398451503366234, "actor_loss": -18.230429418839513, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.218225479125977, "step": 12000}
{"episode_reward": 151.56249009580543, "episode": 13.0, "batch_reward": 0.07737075763940811, "critic_loss": 0.06880437407642603, "actor_loss": -17.576857060723007, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.14237332344055, "step": 13000}
{"episode_reward": 47.567351649268595, "episode": 14.0, "batch_reward": 0.07412960352748632, "critic_loss": 0.07539213725179433, "actor_loss": -17.478211621403695, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.14526867866516, "step": 14000}
{"episode_reward": 35.62741575135402, "episode": 15.0, "batch_reward": 0.07563027223572134, "critic_loss": 0.09916144143790007, "actor_loss": -15.978927958905697, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.320923805236816, "step": 15000}
{"episode_reward": 156.49444542402534, "episode": 16.0, "batch_reward": 0.07726912354677916, "critic_loss": 0.11648208336532116, "actor_loss": -18.226953914940356, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.476102352142334, "step": 16000}
{"episode_reward": 41.421749248910494, "episode": 17.0, "batch_reward": 0.07452184771373868, "critic_loss": 0.11116342705860734, "actor_loss": -17.357186545014383, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.795653581619263, "step": 17000}
{"episode_reward": 28.146454973747783, "episode": 18.0, "batch_reward": 0.07284311060979963, "critic_loss": 0.12596624252200125, "actor_loss": -17.274428464770317, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.740598917007446, "step": 18000}
{"episode_reward": 52.731827258451936, "episode": 19.0, "batch_reward": 0.07396121974289417, "critic_loss": 0.13919897435232997, "actor_loss": -17.73082261288166, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.659299612045288, "step": 19000}
{"episode_reward": 93.87863349616849, "episode": 20.0, "batch_reward": 0.07792845868691801, "critic_loss": 0.15379186814650894, "actor_loss": -16.118384963750838, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.66448163986206, "step": 20000}
{"episode_reward": 239.92156656567795, "episode": 21.0, "batch_reward": 0.08559177046269179, "critic_loss": 0.18560477596521377, "actor_loss": -18.124103155612946, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.60071301460266, "step": 21000}
{"episode_reward": 259.38500611905033, "episode": 22.0, "batch_reward": 0.09315284436196089, "critic_loss": 0.19841118504852057, "actor_loss": -17.955548870563508, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.069716691970825, "step": 22000}
{"episode_reward": 205.26790476047083, "episode": 23.0, "batch_reward": 0.09723042066022754, "critic_loss": 0.19994954007864, "actor_loss": -18.726158623218538, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.984732627868652, "step": 23000}
{"episode_reward": 118.14785273134397, "episode": 24.0, "batch_reward": 0.09725863424688577, "critic_loss": 0.19453300391882658, "actor_loss": -18.661538283348083, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.511003971099854, "step": 24000}
{"episode_reward": 90.1915776299315, "episode": 25.0, "batch_reward": 0.09776727461069823, "critic_loss": 0.1802889251559973, "actor_loss": -18.606163255691527, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.409395217895508, "step": 25000}
{"episode_reward": 115.41272769541646, "episode": 26.0, "batch_reward": 0.10002501504868269, "critic_loss": 0.19222230929136278, "actor_loss": -19.249773454666137, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.76235604286194, "step": 26000}
{"episode_reward": 261.62240275029075, "episode": 27.0, "batch_reward": 0.1071991744786501, "critic_loss": 0.20481587632000448, "actor_loss": -19.122548645973204, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.63507056236267, "step": 27000}
{"episode_reward": 239.02609818056757, "episode": 28.0, "batch_reward": 0.11105096912384033, "critic_loss": 0.19050846253335477, "actor_loss": -19.727398896217345, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.2759268283844, "step": 28000}
{"episode_reward": 299.6651519888693, "episode": 29.0, "batch_reward": 0.11822485276311635, "critic_loss": 0.2055148780196905, "actor_loss": -19.817122106552123, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.730931043624878, "step": 29000}
{"episode_reward": 300.10117668526306, "episode": 30.0, "batch_reward": 0.12412512598186731, "critic_loss": 0.2185032758116722, "actor_loss": -20.113647086143494, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.574816942214966, "step": 30000}
{"episode_reward": 307.94037866356103, "episode": 31.0, "batch_reward": 0.12946736935526132, "critic_loss": 0.2457848530858755, "actor_loss": -21.216336562156677, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.94469428062439, "step": 31000}
{"episode_reward": 272.8400383676642, "episode": 32.0, "batch_reward": 0.13412566496431827, "critic_loss": 0.24531054572016, "actor_loss": -21.573501934051514, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.503713846206665, "step": 32000}
{"episode_reward": 168.45526950817407, "episode": 33.0, "batch_reward": 0.13576908255368472, "critic_loss": 0.24531314834207296, "actor_loss": -21.472990421295165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.485357761383057, "step": 33000}
{"episode_reward": 259.91016359718145, "episode": 34.0, "batch_reward": 0.13665297165513038, "critic_loss": 0.251805520452559, "actor_loss": -22.082317028999327, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.726376056671143, "step": 34000}
{"episode_reward": 53.99492148833225, "episode": 35.0, "batch_reward": 0.1369129069224, "critic_loss": 0.2483261769786477, "actor_loss": -21.643058124542236, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.980448007583618, "step": 35000}
{"episode_reward": 211.21720254128059, "episode": 36.0, "batch_reward": 0.13628952342271805, "critic_loss": 0.25564025253802536, "actor_loss": -22.494913776397706, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.028488636016846, "step": 36000}
{"episode_reward": 73.03812793186776, "episode": 37.0, "batch_reward": 0.13738135335594415, "critic_loss": 0.28855194805562495, "actor_loss": -21.84649610900879, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.916788339614868, "step": 37000}
{"episode_reward": 324.9716467518077, "episode": 38.0, "batch_reward": 0.1424334488660097, "critic_loss": 0.3093239889740944, "actor_loss": -21.467529556274414, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.361992120742798, "step": 38000}
{"episode_reward": 188.62281709861261, "episode": 39.0, "batch_reward": 0.14449126374721527, "critic_loss": 0.29378829757124186, "actor_loss": -22.562714317321777, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.99571394920349, "step": 39000}
{"episode_reward": 378.85026155515015, "episode": 40.0, "batch_reward": 0.14860406024754047, "critic_loss": 0.3072694284319878, "actor_loss": -23.39657802581787, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.55594825744629, "step": 40000}
{"episode_reward": 370.9488040402159, "episode": 41.0, "batch_reward": 0.15564502281695605, "critic_loss": 0.3170742771178484, "actor_loss": -24.04898997116089, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.02934718132019, "step": 41000}
{"episode_reward": 302.5669523007536, "episode": 42.0, "batch_reward": 0.1592261193394661, "critic_loss": 0.34877450589090586, "actor_loss": -23.53371294212341, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.51332139968872, "step": 42000}
{"episode_reward": 314.6959969624838, "episode": 43.0, "batch_reward": 0.15986336617171765, "critic_loss": 0.34867575143277646, "actor_loss": -24.309468866348265, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.662086963653564, "step": 43000}
{"episode_reward": 53.074709787674166, "episode": 44.0, "batch_reward": 0.15772406097501515, "critic_loss": 0.366453571178019, "actor_loss": -23.158774305343627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.691967964172363, "step": 44000}
{"episode_reward": 78.67051781360139, "episode": 45.0, "batch_reward": 0.1553286334052682, "critic_loss": 0.3531771478503942, "actor_loss": -22.599789459228514, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.929347038269043, "step": 45000}
{"episode_reward": 50.11854034880111, "episode": 46.0, "batch_reward": 0.15623199012130498, "critic_loss": 0.3288993083685636, "actor_loss": -23.680405576705933, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.085740566253662, "step": 46000}
{"episode_reward": 340.94135373629587, "episode": 47.0, "batch_reward": 0.15957190157473086, "critic_loss": 0.3227082723379135, "actor_loss": -23.948771564483643, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.68002939224243, "step": 47000}
{"episode_reward": 241.91134872770243, "episode": 48.0, "batch_reward": 0.1611759996265173, "critic_loss": 0.3193032300174236, "actor_loss": -24.25050135421753, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.192853689193726, "step": 48000}
{"episode_reward": 255.16075287556527, "episode": 49.0, "batch_reward": 0.16363118819892405, "critic_loss": 0.34178620828688144, "actor_loss": -24.471935134887694, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.179699182510376, "step": 49000}
{"episode_reward": 350.3752870326843, "episode": 50.0, "batch_reward": 0.16710708626359702, "critic_loss": 0.33923204109072685, "actor_loss": -24.37647184562683, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.941457509994507, "step": 50000}
{"episode_reward": 380.4077219766626, "episode": 51.0, "batch_reward": 0.17176312358677387, "critic_loss": 0.325662132576108, "actor_loss": -24.520381032943725, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.32376551628113, "step": 51000}
{"episode_reward": 400.7391494675499, "episode": 52.0, "batch_reward": 0.17651485179364682, "critic_loss": 0.3401023496091366, "actor_loss": -25.66196742248535, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.007766723632812, "step": 52000}
{"episode_reward": 387.58047078644427, "episode": 53.0, "batch_reward": 0.18076901422441005, "critic_loss": 0.33104850897192956, "actor_loss": -24.75786539077759, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.24529504776001, "step": 53000}
{"episode_reward": 394.25515613292754, "episode": 54.0, "batch_reward": 0.18444758586585522, "critic_loss": 0.3200917523577809, "actor_loss": -26.551461236953735, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.058768272399902, "step": 54000}
{"episode_reward": 354.92957800732677, "episode": 55.0, "batch_reward": 0.18708361116051675, "critic_loss": 0.3424993007928133, "actor_loss": -26.5596798248291, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.079089403152466, "step": 55000}
{"episode_reward": 371.91247859099644, "episode": 56.0, "batch_reward": 0.19019937565922737, "critic_loss": 0.32767516289651394, "actor_loss": -26.100050462722777, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.224578857421875, "step": 56000}
{"episode_reward": 406.01617102910865, "episode": 57.0, "batch_reward": 0.19496163493394852, "critic_loss": 0.30760360161215067, "actor_loss": -26.908288288116456, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.238840579986572, "step": 57000}
{"episode_reward": 378.12666625059666, "episode": 58.0, "batch_reward": 0.19737921226024627, "critic_loss": 0.30792324121296405, "actor_loss": -27.33471640586853, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.74671983718872, "step": 58000}
{"episode_reward": 395.9761987502691, "episode": 59.0, "batch_reward": 0.20108331394195555, "critic_loss": 0.3044278540611267, "actor_loss": -27.65092733192444, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.450850248336792, "step": 59000}
{"episode_reward": 342.80393773793014, "episode": 60.0, "batch_reward": 0.20365313939750196, "critic_loss": 0.30089326232671737, "actor_loss": -27.9927190322876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.179611921310425, "step": 60000}
{"episode_reward": 361.62316867458304, "episode": 61.0, "batch_reward": 0.20610611276328564, "critic_loss": 0.31013426796346905, "actor_loss": -28.45249942779541, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.3169047832489, "step": 61000}
{"episode_reward": 271.4429428372119, "episode": 62.0, "batch_reward": 0.2071113887578249, "critic_loss": 0.2977483097165823, "actor_loss": -27.707785606384277, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.029985189437866, "step": 62000}
{"episode_reward": 383.6496547577476, "episode": 63.0, "batch_reward": 0.20873240648210048, "critic_loss": 0.2774850245118141, "actor_loss": -27.79820481491089, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.171283721923828, "step": 63000}
{"episode_reward": 388.67864504059344, "episode": 64.0, "batch_reward": 0.21270891551673413, "critic_loss": 0.27513471819460394, "actor_loss": -28.64392066192627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.255735158920288, "step": 64000}
{"episode_reward": 363.9078772906495, "episode": 65.0, "batch_reward": 0.2160773600488901, "critic_loss": 0.2670946377068758, "actor_loss": -28.557510639190674, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.724579334259033, "step": 65000}
{"episode_reward": 401.34645595908364, "episode": 66.0, "batch_reward": 0.2180808798968792, "critic_loss": 0.2683537248447537, "actor_loss": -29.17339970397949, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.3065767288208, "step": 66000}
{"episode_reward": 381.62415712869307, "episode": 67.0, "batch_reward": 0.22115882834792136, "critic_loss": 0.26841390173137186, "actor_loss": -29.073150398254395, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.979264497756958, "step": 67000}
{"episode_reward": 419.44863130014807, "episode": 68.0, "batch_reward": 0.22424829460680484, "critic_loss": 0.26267713063955306, "actor_loss": -29.9166930770874, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.72121000289917, "step": 68000}
{"episode_reward": 418.522230976056, "episode": 69.0, "batch_reward": 0.22660350109636784, "critic_loss": 0.2477064561918378, "actor_loss": -29.96181742477417, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.999617338180542, "step": 69000}
{"episode_reward": 398.1927303714807, "episode": 70.0, "batch_reward": 0.22883309905231, "critic_loss": 0.23067019797861577, "actor_loss": -30.756389739990233, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.58443522453308, "step": 70000}
{"episode_reward": 410.01631268484886, "episode": 71.0, "batch_reward": 0.2309751339405775, "critic_loss": 0.25675621096044776, "actor_loss": -30.023874420166017, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.29733633995056, "step": 71000}
{"episode_reward": 404.0891657444405, "episode": 72.0, "batch_reward": 0.23392413859069347, "critic_loss": 0.2420572308972478, "actor_loss": -30.86267839050293, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.699636936187744, "step": 72000}
{"episode_reward": 401.44197427206655, "episode": 73.0, "batch_reward": 0.23546576619148255, "critic_loss": 0.24933447299152614, "actor_loss": -30.83049980545044, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.876193046569824, "step": 73000}
{"episode_reward": 394.1930021902069, "episode": 74.0, "batch_reward": 0.2388875494748354, "critic_loss": 0.24212234302610158, "actor_loss": -31.160278827667238, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.45992636680603, "step": 74000}
{"episode_reward": 387.02090993606015, "episode": 75.0, "batch_reward": 0.24035729031264783, "critic_loss": 0.24450884173810483, "actor_loss": -31.372859630584717, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.093859910964966, "step": 75000}
{"episode_reward": 388.44238952467623, "episode": 76.0, "batch_reward": 0.24239037217199802, "critic_loss": 0.2478856603577733, "actor_loss": -31.78829222488403, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.602099180221558, "step": 76000}
{"episode_reward": 425.0864539012589, "episode": 77.0, "batch_reward": 0.24493602491915226, "critic_loss": 0.2538657958135009, "actor_loss": -31.945891510009766, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.27695655822754, "step": 77000}
{"episode_reward": 389.49902159036435, "episode": 78.0, "batch_reward": 0.2464240763038397, "critic_loss": 0.23490833226591348, "actor_loss": -31.801723987579347, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.94766068458557, "step": 78000}
{"episode_reward": 416.7001251471094, "episode": 79.0, "batch_reward": 0.24706574684381485, "critic_loss": 0.23608810960501433, "actor_loss": -31.951712245941163, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.131475687026978, "step": 79000}
{"episode_reward": 124.54120283831844, "episode": 80.0, "batch_reward": 0.2471156862527132, "critic_loss": 0.23966041987389325, "actor_loss": -32.0518747253418, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.137972354888916, "step": 80000}
{"episode_reward": 428.2838063749398, "episode": 81.0, "batch_reward": 0.250285962626338, "critic_loss": 0.2318014723137021, "actor_loss": -32.120237644195555, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.68574833869934, "step": 81000}
{"episode_reward": 431.91106396332754, "episode": 82.0, "batch_reward": 0.2507750048935413, "critic_loss": 0.2420209022089839, "actor_loss": -32.30646330261231, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.838854551315308, "step": 82000}
{"episode_reward": 427.2166639609607, "episode": 83.0, "batch_reward": 0.25330370756983756, "critic_loss": 0.22242198987305165, "actor_loss": -32.977326820373534, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.128926277160645, "step": 83000}
{"episode_reward": 409.58527007648144, "episode": 84.0, "batch_reward": 0.2556977128982544, "critic_loss": 0.24976406323909758, "actor_loss": -33.46049178314209, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.631526947021484, "step": 84000}
{"episode_reward": 416.4605945054739, "episode": 85.0, "batch_reward": 0.25780181954801085, "critic_loss": 0.26073514886945487, "actor_loss": -32.87204005432129, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.496469259262085, "step": 85000}
{"episode_reward": 414.2498917880175, "episode": 86.0, "batch_reward": 0.2592544801831245, "critic_loss": 0.2575390444025397, "actor_loss": -33.05713426208496, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.322540998458862, "step": 86000}
{"episode_reward": 410.63846301658464, "episode": 87.0, "batch_reward": 0.260684304907918, "critic_loss": 0.2783075725361705, "actor_loss": -33.395050888061526, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.850422382354736, "step": 87000}
{"episode_reward": 430.7616877481097, "episode": 88.0, "batch_reward": 0.2635739000290632, "critic_loss": 0.2789611160680652, "actor_loss": -33.93378803253174, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.827242612838745, "step": 88000}
{"episode_reward": 401.3117055287476, "episode": 89.0, "batch_reward": 0.2650558232963085, "critic_loss": 0.26136079398542644, "actor_loss": -33.58022420120239, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.985841512680054, "step": 89000}
{"episode_reward": 415.3080544312602, "episode": 90.0, "batch_reward": 0.26618957993388176, "critic_loss": 0.26884588481485844, "actor_loss": -34.029127292633056, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.09527826309204, "step": 90000}
{"episode_reward": 436.9603709520811, "episode": 91.0, "batch_reward": 0.26698023653030395, "critic_loss": 0.2572657949253917, "actor_loss": -33.764493419647216, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.10461664199829, "step": 91000}
{"episode_reward": 61.0371120863986, "episode": 92.0, "batch_reward": 0.2657808333188295, "critic_loss": 0.2842774521112442, "actor_loss": -33.4518277130127, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.59952974319458, "step": 92000}
{"episode_reward": 438.22046637435005, "episode": 93.0, "batch_reward": 0.267853417545557, "critic_loss": 0.2816959055662155, "actor_loss": -33.66125399780273, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.663008213043213, "step": 93000}
{"episode_reward": 414.7294303210989, "episode": 94.0, "batch_reward": 0.26944323989748953, "critic_loss": 0.28297168148308993, "actor_loss": -34.18915057754516, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.82662558555603, "step": 94000}
{"episode_reward": 412.10344311488103, "episode": 95.0, "batch_reward": 0.2704885693192482, "critic_loss": 0.2995316039919853, "actor_loss": -34.33523592376709, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.261240005493164, "step": 95000}
{"episode_reward": 416.57918884872737, "episode": 96.0, "batch_reward": 0.27246847684681413, "critic_loss": 0.27407422445714474, "actor_loss": -34.40862580108642, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.348642587661743, "step": 96000}
{"episode_reward": 423.1196001256679, "episode": 97.0, "batch_reward": 0.2738117265701294, "critic_loss": 0.25895521631091833, "actor_loss": -34.57265858459473, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.79927921295166, "step": 97000}
{"episode_reward": 449.17151140962903, "episode": 98.0, "batch_reward": 0.27595716615021226, "critic_loss": 0.2618662938848138, "actor_loss": -34.386383464813235, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.069342136383057, "step": 98000}
{"episode_reward": 438.9658911454074, "episode": 99.0, "batch_reward": 0.2776399954408407, "critic_loss": 0.2672463482543826, "actor_loss": -34.985038249969485, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.16691303253174, "step": 99000}
{"episode_reward": 403.0485582301976, "episode": 100.0, "batch_reward": 0.2774179586619139, "critic_loss": 0.2665343002602458, "actor_loss": -34.70993357467651, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.2723171710968, "step": 100000}
{"episode_reward": 435.4571604805488, "episode": 101.0, "batch_reward": 0.28085614371299744, "critic_loss": 0.2578333694934845, "actor_loss": -35.36249771499634, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.55959105491638, "step": 101000}
{"episode_reward": 433.70661219701344, "episode": 102.0, "batch_reward": 0.28203478692471984, "critic_loss": 0.25582371626794337, "actor_loss": -35.40994555282593, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.587636947631836, "step": 102000}
{"episode_reward": 413.8335834952428, "episode": 103.0, "batch_reward": 0.2830807880014181, "critic_loss": 0.23179288888722657, "actor_loss": -35.16763036727905, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.798468589782715, "step": 103000}
{"episode_reward": 424.93211535097356, "episode": 104.0, "batch_reward": 0.2834541151970625, "critic_loss": 0.21704543105512858, "actor_loss": -35.57913650894165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.97619605064392, "step": 104000}
{"episode_reward": 424.0488949205607, "episode": 105.0, "batch_reward": 0.28633634029328825, "critic_loss": 0.23260847898572684, "actor_loss": -35.40770099639892, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.120535850524902, "step": 105000}
{"episode_reward": 443.2130870589268, "episode": 106.0, "batch_reward": 0.28689439146220685, "critic_loss": 0.2322814539819956, "actor_loss": -35.909003646850586, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.273662328720093, "step": 106000}
{"episode_reward": 430.2147219658671, "episode": 107.0, "batch_reward": 0.2888941295742989, "critic_loss": 0.23440435370057822, "actor_loss": -35.816570049285886, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.685542345046997, "step": 107000}
{"episode_reward": 424.6151189036198, "episode": 108.0, "batch_reward": 0.28886489994823933, "critic_loss": 0.23767694457620384, "actor_loss": -35.40638004684448, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.59301209449768, "step": 108000}
{"episode_reward": 444.17208298893166, "episode": 109.0, "batch_reward": 0.2910670015215874, "critic_loss": 0.2294441125690937, "actor_loss": -36.381519481658934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.97400999069214, "step": 109000}
{"episode_reward": 402.25744066377666, "episode": 110.0, "batch_reward": 0.29248960031569005, "critic_loss": 0.20896001924574376, "actor_loss": -36.50491482543946, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.284173727035522, "step": 110000}
{"episode_reward": 412.92614088053716, "episode": 111.0, "batch_reward": 0.29331616036593916, "critic_loss": 0.23455211658775807, "actor_loss": -35.696760238647464, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.454782009124756, "step": 111000}
{"episode_reward": 443.46991337356656, "episode": 112.0, "batch_reward": 0.29413024759292605, "critic_loss": 0.23665386414527892, "actor_loss": -36.68217087173462, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.241330862045288, "step": 112000}
{"episode_reward": 415.18057012659625, "episode": 113.0, "batch_reward": 0.29559652517735957, "critic_loss": 0.22171088760346175, "actor_loss": -36.34102233886719, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.61654019355774, "step": 113000}
{"episode_reward": 414.78312081519834, "episode": 114.0, "batch_reward": 0.29592129838466646, "critic_loss": 0.2863059635087848, "actor_loss": -36.79422285842895, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.96767807006836, "step": 114000}
{"episode_reward": 148.78774875158345, "episode": 115.0, "batch_reward": 0.2946574597358704, "critic_loss": 0.2384320630952716, "actor_loss": -36.29735482406616, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.910473585128784, "step": 115000}
{"episode_reward": 420.27134225399277, "episode": 116.0, "batch_reward": 0.29790155808627605, "critic_loss": 0.25080192589759825, "actor_loss": -36.80274772644043, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.79180121421814, "step": 116000}
{"episode_reward": 408.1526897432276, "episode": 117.0, "batch_reward": 0.2972539059966803, "critic_loss": 0.2810428099706769, "actor_loss": -36.02850786972046, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.219581604003906, "step": 117000}
{"episode_reward": 428.2425260869341, "episode": 118.0, "batch_reward": 0.29902521473169325, "critic_loss": 0.24180897690355777, "actor_loss": -36.6484536857605, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.1267192363739, "step": 118000}
{"episode_reward": 430.032821589919, "episode": 119.0, "batch_reward": 0.3004512302875519, "critic_loss": 0.2508961737677455, "actor_loss": -36.80921125411987, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.29319930076599, "step": 119000}
{"episode_reward": 398.61063522439963, "episode": 120.0, "batch_reward": 0.30124223175644876, "critic_loss": 0.24025605712085962, "actor_loss": -36.613510013580324, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.62138032913208, "step": 120000}
{"episode_reward": 442.4455021976773, "episode": 121.0, "batch_reward": 0.300896518304944, "critic_loss": 0.2447363716363907, "actor_loss": -36.601404010772704, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.9159791469574, "step": 121000}
{"episode_reward": 405.4477160541511, "episode": 122.0, "batch_reward": 0.3037009265720844, "critic_loss": 0.21026190064102412, "actor_loss": -36.66340908813476, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.946748971939087, "step": 122000}
{"episode_reward": 441.31395906535266, "episode": 123.0, "batch_reward": 0.3041922232210636, "critic_loss": 0.2728779492303729, "actor_loss": -37.45069863128662, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.879311084747314, "step": 123000}
{"episode_reward": 436.27910507774806, "episode": 124.0, "batch_reward": 0.30458496902883053, "critic_loss": 0.22734173445403577, "actor_loss": -37.00787102127075, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.70733618736267, "step": 124000}
{"episode_reward": 428.7863963760682, "episode": 125.0, "batch_reward": 0.30545248654484747, "critic_loss": 0.24220676605403424, "actor_loss": -37.2209121131897, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.06317400932312, "step": 125000}
{"episode_reward": 426.634289835741, "episode": 126.0, "batch_reward": 0.3068244328200817, "critic_loss": 0.23921571942418815, "actor_loss": -36.91514284515381, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.651590585708618, "step": 126000}
{"episode_reward": 451.43890001376724, "episode": 127.0, "batch_reward": 0.3073406361043453, "critic_loss": 0.2342943413183093, "actor_loss": -37.301770641326904, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.319190979003906, "step": 127000}
{"episode_reward": 419.72741273516004, "episode": 128.0, "batch_reward": 0.30861185774207117, "critic_loss": 0.22508026406168938, "actor_loss": -37.385950504302976, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.097638368606567, "step": 128000}
{"episode_reward": 437.43229130132744, "episode": 129.0, "batch_reward": 0.3102418442666531, "critic_loss": 0.22759591134637594, "actor_loss": -37.10623118591309, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.116674184799194, "step": 129000}
{"episode_reward": 454.175554567712, "episode": 130.0, "batch_reward": 0.3112894594669342, "critic_loss": 0.22524488377571106, "actor_loss": -37.42446252059936, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.166513681411743, "step": 130000}
{"episode_reward": 429.0611554002682, "episode": 131.0, "batch_reward": 0.31182508486509325, "critic_loss": 0.22799356514215469, "actor_loss": -37.60580737304687, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.85572338104248, "step": 131000}
{"episode_reward": 421.4242445260364, "episode": 132.0, "batch_reward": 0.3121269563138485, "critic_loss": 0.2167668286934495, "actor_loss": -38.15206046295166, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.997729778289795, "step": 132000}
{"episode_reward": 410.494789202363, "episode": 133.0, "batch_reward": 0.3139118505716324, "critic_loss": 0.20648533074557782, "actor_loss": -37.75096659851074, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.558501720428467, "step": 133000}
{"episode_reward": 439.92254451118276, "episode": 134.0, "batch_reward": 0.3142745227217674, "critic_loss": 0.21527956078946592, "actor_loss": -37.27620421600342, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.2990779876709, "step": 134000}
{"episode_reward": 460.1583689709728, "episode": 135.0, "batch_reward": 0.31567252618074415, "critic_loss": 0.21828086417913437, "actor_loss": -38.247447063446046, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.728288173675537, "step": 135000}
{"episode_reward": 445.3024923971183, "episode": 136.0, "batch_reward": 0.31675138339400294, "critic_loss": 0.20750912650674583, "actor_loss": -36.97190140151977, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.494940042495728, "step": 136000}
{"episode_reward": 460.88924783340525, "episode": 137.0, "batch_reward": 0.3166152890920639, "critic_loss": 0.20974285234510898, "actor_loss": -38.066387336730955, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.887634754180908, "step": 137000}
{"episode_reward": 425.4974583034547, "episode": 138.0, "batch_reward": 0.31880245730280876, "critic_loss": 0.20480048459768296, "actor_loss": -38.02815871810913, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.851932287216187, "step": 138000}
{"episode_reward": 447.1941735700433, "episode": 139.0, "batch_reward": 0.3200874323546886, "critic_loss": 0.21589339180290698, "actor_loss": -38.23149536514282, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.27531909942627, "step": 139000}
{"episode_reward": 440.1815114539739, "episode": 140.0, "batch_reward": 0.3211332881450653, "critic_loss": 0.20524378146976233, "actor_loss": -38.23413625717163, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.840622663497925, "step": 140000}
{"episode_reward": 436.19502907509974, "episode": 141.0, "batch_reward": 0.320265017747879, "critic_loss": 0.20715820945054292, "actor_loss": -38.357149154663084, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.81776142120361, "step": 141000}
{"episode_reward": 451.9311206114242, "episode": 142.0, "batch_reward": 0.32174842661619185, "critic_loss": 0.20468731781095267, "actor_loss": -37.9429298248291, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.57679796218872, "step": 142000}
{"episode_reward": 454.39005976198064, "episode": 143.0, "batch_reward": 0.32254349052906034, "critic_loss": 0.19399950935691596, "actor_loss": -38.047489147186276, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.521816968917847, "step": 143000}
{"episode_reward": 444.3191953015662, "episode": 144.0, "batch_reward": 0.32431438148021696, "critic_loss": 0.1938133371323347, "actor_loss": -38.6933105430603, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.68086814880371, "step": 144000}
{"episode_reward": 445.0672315356048, "episode": 145.0, "batch_reward": 0.3255517382323742, "critic_loss": 0.20381575128436089, "actor_loss": -38.842934009552, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.58389687538147, "step": 145000}
{"episode_reward": 438.8448695256955, "episode": 146.0, "batch_reward": 0.3252091426849365, "critic_loss": 0.19677934903651476, "actor_loss": -38.97277578353882, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.153844118118286, "step": 146000}
{"episode_reward": 430.6239555251956, "episode": 147.0, "batch_reward": 0.32528014743328093, "critic_loss": 0.20072426032274962, "actor_loss": -38.73363891983032, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.63218593597412, "step": 147000}
{"episode_reward": 420.69088796846523, "episode": 148.0, "batch_reward": 0.3266454871594906, "critic_loss": 0.19694130378961563, "actor_loss": -38.94629692459107, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.226261377334595, "step": 148000}
{"episode_reward": 438.4627464124331, "episode": 149.0, "batch_reward": 0.3271885035932064, "critic_loss": 0.18690459971129894, "actor_loss": -38.730575916290285, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.9335036277771, "step": 149000}
{"episode_reward": 454.04569840565017, "episode": 150.0, "batch_reward": 0.32834336113929746, "critic_loss": 0.1900766629576683, "actor_loss": -39.14793278503418, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
