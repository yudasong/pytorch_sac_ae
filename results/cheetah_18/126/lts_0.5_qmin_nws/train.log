{"episode_reward": 0.0, "episode": 1.0, "duration": 18.6219699382782, "step": 1000}
{"episode_reward": 4.231880753996205, "episode": 2.0, "duration": 1.8437612056732178, "step": 2000}
{"episode_reward": 395.1450543749875, "episode": 3.0, "batch_reward": 0.18964694478375468, "critic_loss": 0.0246560331196445, "actor_loss": -20.898346019021066, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 66.23063921928406, "step": 3000}
{"episode_reward": 33.405021173430356, "episode": 4.0, "batch_reward": 0.12777972279489042, "critic_loss": 0.02018392816837877, "actor_loss": -16.919462472483517, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.306727170944214, "step": 4000}
{"episode_reward": 17.594718473153613, "episode": 5.0, "batch_reward": 0.10325380190834403, "critic_loss": 0.024280947849154473, "actor_loss": -17.686190753784032, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.63997793197632, "step": 5000}
{"episode_reward": 16.778492976715643, "episode": 6.0, "batch_reward": 0.08769699832797051, "critic_loss": 0.025135753797367214, "actor_loss": -15.823359163772315, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.88150691986084, "step": 6000}
{"episode_reward": 25.551450914678195, "episode": 7.0, "batch_reward": 0.08471161967143416, "critic_loss": 0.037776117329485714, "actor_loss": -16.184969188839197, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.61562490463257, "step": 7000}
{"episode_reward": 93.68875575177185, "episode": 8.0, "batch_reward": 0.08240935611352325, "critic_loss": 0.0491066604424268, "actor_loss": -16.817573299571873, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.859007120132446, "step": 8000}
{"episode_reward": 34.9193725469432, "episode": 9.0, "batch_reward": 0.07940131033957004, "critic_loss": 0.058701154567301274, "actor_loss": -15.671567280545831, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.638454914093018, "step": 9000}
{"episode_reward": 82.51545095681496, "episode": 10.0, "batch_reward": 0.08039411569014192, "critic_loss": 0.06865130775235594, "actor_loss": -15.905667528294027, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.308889627456665, "step": 10000}
{"episode_reward": 131.07415331593495, "episode": 11.0, "batch_reward": 0.08492520060390234, "critic_loss": 0.08430090434476734, "actor_loss": -14.871327931076289, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.538461685180664, "step": 11000}
{"episode_reward": 67.20740437688926, "episode": 12.0, "batch_reward": 0.0812230764515698, "critic_loss": 0.08497707253694534, "actor_loss": -15.200537132158875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.232218265533447, "step": 12000}
{"episode_reward": 33.643042912102516, "episode": 13.0, "batch_reward": 0.07793304712325334, "critic_loss": 0.0938829119578004, "actor_loss": -13.728005747139454, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.48607063293457, "step": 13000}
{"episode_reward": 39.14145756542894, "episode": 14.0, "batch_reward": 0.0751896946504712, "critic_loss": 0.10137967067956924, "actor_loss": -14.041988372385502, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.261847496032715, "step": 14000}
{"episode_reward": 57.80755682562565, "episode": 15.0, "batch_reward": 0.07284077132120728, "critic_loss": 0.12411460257321597, "actor_loss": -12.478818962693214, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.16655397415161, "step": 15000}
{"episode_reward": 24.851783240054043, "episode": 16.0, "batch_reward": 0.07114158146828413, "critic_loss": 0.14010455611720682, "actor_loss": -14.443917236685753, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.8852117061615, "step": 16000}
{"episode_reward": 45.54656662369286, "episode": 17.0, "batch_reward": 0.07166523065045476, "critic_loss": 0.17565065570548177, "actor_loss": -13.839564129829407, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.35155487060547, "step": 17000}
{"episode_reward": 112.83191784340421, "episode": 18.0, "batch_reward": 0.07231897974386811, "critic_loss": 0.1745407132394612, "actor_loss": -14.45200713968277, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.164865255355835, "step": 18000}
{"episode_reward": 68.58858520196932, "episode": 19.0, "batch_reward": 0.07570479720830918, "critic_loss": 0.18529841025546193, "actor_loss": -14.464800046443939, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.926840782165527, "step": 19000}
{"episode_reward": 240.29814167273489, "episode": 20.0, "batch_reward": 0.08201594164967536, "critic_loss": 0.18063726185262202, "actor_loss": -13.667400952339172, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.429989337921143, "step": 20000}
{"episode_reward": 89.17611288299867, "episode": 21.0, "batch_reward": 0.0822127984277904, "critic_loss": 0.17098283582180737, "actor_loss": -14.672688337802887, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.8187575340271, "step": 21000}
{"episode_reward": 130.91622539275536, "episode": 22.0, "batch_reward": 0.08636046972125769, "critic_loss": 0.18164880627766253, "actor_loss": -14.70084092092514, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.62553334236145, "step": 22000}
{"episode_reward": 201.25363451340576, "episode": 23.0, "batch_reward": 0.08974485692381859, "critic_loss": 0.20028215788304807, "actor_loss": -14.845862452507019, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.2353413105011, "step": 23000}
{"episode_reward": 105.20086588657763, "episode": 24.0, "batch_reward": 0.0911383731290698, "critic_loss": 0.20596395267918705, "actor_loss": -14.986097490787506, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.240804433822632, "step": 24000}
{"episode_reward": 125.47412288497954, "episode": 25.0, "batch_reward": 0.09157985167577863, "critic_loss": 0.21504634269326925, "actor_loss": -14.96704444217682, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.53727889060974, "step": 25000}
{"episode_reward": 84.02467954735852, "episode": 26.0, "batch_reward": 0.09305090291798115, "critic_loss": 0.2348399078771472, "actor_loss": -15.602982202529907, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.952961921691895, "step": 26000}
{"episode_reward": 138.7322881481008, "episode": 27.0, "batch_reward": 0.09318894463777543, "critic_loss": 0.23770854596048593, "actor_loss": -14.826053385734559, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.254722833633423, "step": 27000}
{"episode_reward": 60.90909203061139, "episode": 28.0, "batch_reward": 0.09079079439491033, "critic_loss": 0.23323270632326604, "actor_loss": -15.629949553489684, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.155555486679077, "step": 28000}
{"episode_reward": 56.721788331586474, "episode": 29.0, "batch_reward": 0.08920248375833034, "critic_loss": 0.25297540667653085, "actor_loss": -14.451670363426208, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.57528805732727, "step": 29000}
{"episode_reward": 33.455202540235106, "episode": 30.0, "batch_reward": 0.08988543815538287, "critic_loss": 0.2764126818776131, "actor_loss": -14.764172229766846, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.92148518562317, "step": 30000}
{"episode_reward": 120.21478569965164, "episode": 31.0, "batch_reward": 0.08848617587983608, "critic_loss": 0.2700795283392072, "actor_loss": -15.339387683868408, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.04723763465881, "step": 31000}
{"episode_reward": 38.98317346092333, "episode": 32.0, "batch_reward": 0.09115032623708248, "critic_loss": 0.32625562496483324, "actor_loss": -15.646866494178772, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.627193212509155, "step": 32000}
{"episode_reward": 289.04839378807753, "episode": 33.0, "batch_reward": 0.09468074690550565, "critic_loss": 0.31250296596437693, "actor_loss": -15.166515587806702, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.437453269958496, "step": 33000}
{"episode_reward": 77.78324562508355, "episode": 34.0, "batch_reward": 0.09240407430380583, "critic_loss": 0.29780304326862095, "actor_loss": -15.569119903564452, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.935869932174683, "step": 34000}
{"episode_reward": 33.56766754272791, "episode": 35.0, "batch_reward": 0.09170400248095394, "critic_loss": 0.28859105037897825, "actor_loss": -15.778841654777526, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.67908477783203, "step": 35000}
{"episode_reward": 51.95754094569086, "episode": 36.0, "batch_reward": 0.0933041432313621, "critic_loss": 0.32216853120923045, "actor_loss": -16.16204267501831, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.795507192611694, "step": 36000}
{"episode_reward": 197.77691320652096, "episode": 37.0, "batch_reward": 0.09380005388706923, "critic_loss": 0.34396809981763365, "actor_loss": -15.876207689285279, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.091309070587158, "step": 37000}
{"episode_reward": 69.16418703482813, "episode": 38.0, "batch_reward": 0.0939779966250062, "critic_loss": 0.3383574615120888, "actor_loss": -15.206882655143739, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.626853942871094, "step": 38000}
{"episode_reward": 111.9243037758511, "episode": 39.0, "batch_reward": 0.0949072997123003, "critic_loss": 0.37336510366946457, "actor_loss": -15.74279319858551, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.0607271194458, "step": 39000}
{"episode_reward": 115.31326107927144, "episode": 40.0, "batch_reward": 0.09569650388509035, "critic_loss": 0.38053593969345095, "actor_loss": -16.255779183387755, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.33869481086731, "step": 40000}
{"episode_reward": 287.7462060122148, "episode": 41.0, "batch_reward": 0.09921913182735444, "critic_loss": 0.34673140861094, "actor_loss": -16.845171506881712, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.16476368904114, "step": 41000}
{"episode_reward": 65.51747850811378, "episode": 42.0, "batch_reward": 0.09985931648313999, "critic_loss": 0.32103972662240265, "actor_loss": -16.16030372238159, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.170005321502686, "step": 42000}
{"episode_reward": 296.5475332178611, "episode": 43.0, "batch_reward": 0.10466772851347923, "critic_loss": 0.3592024264484644, "actor_loss": -16.883650937080382, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.82897639274597, "step": 43000}
{"episode_reward": 264.9960317517891, "episode": 44.0, "batch_reward": 0.10768006493896246, "critic_loss": 0.37312769356369974, "actor_loss": -16.833800352096556, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.682912588119507, "step": 44000}
{"episode_reward": 290.9824171710907, "episode": 45.0, "batch_reward": 0.10983421962708234, "critic_loss": 0.3394726116061211, "actor_loss": -16.62581307506561, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.50640368461609, "step": 45000}
{"episode_reward": 64.25227754522123, "episode": 46.0, "batch_reward": 0.10915031138807535, "critic_loss": 0.3288619956672192, "actor_loss": -17.20993024158478, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.900639295578003, "step": 46000}
{"episode_reward": 72.16211165112234, "episode": 47.0, "batch_reward": 0.10988613206148147, "critic_loss": 0.35570190493762494, "actor_loss": -17.57469517612457, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.545867919921875, "step": 47000}
{"episode_reward": 276.53115465841285, "episode": 48.0, "batch_reward": 0.11237752157449722, "critic_loss": 0.3470551774203777, "actor_loss": -17.1858437871933, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.963138818740845, "step": 48000}
{"episode_reward": 70.58813157370378, "episode": 49.0, "batch_reward": 0.11334551670402289, "critic_loss": 0.3465457835942507, "actor_loss": -17.48864632320404, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.616856575012207, "step": 49000}
{"episode_reward": 227.03439252280637, "episode": 50.0, "batch_reward": 0.11435907199978829, "critic_loss": 0.31667852023243903, "actor_loss": -17.149830671310426, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.370877742767334, "step": 50000}
{"episode_reward": 120.49466375551566, "episode": 51.0, "batch_reward": 0.11577083256840706, "critic_loss": 0.2733498913273215, "actor_loss": -16.56441547012329, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.40124726295471, "step": 51000}
{"episode_reward": 285.6407028323024, "episode": 52.0, "batch_reward": 0.11984679997712373, "critic_loss": 0.31035590256750584, "actor_loss": -18.18809783554077, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.06917405128479, "step": 52000}
{"episode_reward": 314.3522312486014, "episode": 53.0, "batch_reward": 0.12256303664296865, "critic_loss": 0.292705259680748, "actor_loss": -17.125006313323976, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.56853723526001, "step": 53000}
{"episode_reward": 298.0469551693541, "episode": 54.0, "batch_reward": 0.12607235871255398, "critic_loss": 0.2903558575809002, "actor_loss": -18.812852964401245, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.52248215675354, "step": 54000}
{"episode_reward": 178.06335500882858, "episode": 55.0, "batch_reward": 0.12679403785616158, "critic_loss": 0.2995265987738967, "actor_loss": -18.518230260849, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.16173768043518, "step": 55000}
{"episode_reward": 298.0167162009657, "episode": 56.0, "batch_reward": 0.13030169772356748, "critic_loss": 0.3125386401861906, "actor_loss": -18.10839045524597, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.901314973831177, "step": 56000}
{"episode_reward": 384.8453126040603, "episode": 57.0, "batch_reward": 0.1332010964900255, "critic_loss": 0.2941603624969721, "actor_loss": -18.49473278236389, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.629534244537354, "step": 57000}
{"episode_reward": 66.50140716216367, "episode": 58.0, "batch_reward": 0.13330159869790076, "critic_loss": 0.30633604563772676, "actor_loss": -18.18095084762573, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.388391733169556, "step": 58000}
{"episode_reward": 367.5916440745353, "episode": 59.0, "batch_reward": 0.13608738078922034, "critic_loss": 0.3040313723683357, "actor_loss": -18.93950746536255, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.34085178375244, "step": 59000}
{"episode_reward": 136.23756645387428, "episode": 60.0, "batch_reward": 0.13767073141783476, "critic_loss": 0.2984245978295803, "actor_loss": -19.48153911972046, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.322071075439453, "step": 60000}
{"episode_reward": 370.6655792885565, "episode": 61.0, "batch_reward": 0.14135778127610685, "critic_loss": 0.29068456395715475, "actor_loss": -19.517342922210695, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.35046744346619, "step": 61000}
{"episode_reward": 362.666884261724, "episode": 62.0, "batch_reward": 0.1451365438774228, "critic_loss": 0.27126276214420797, "actor_loss": -19.050069772720338, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.739100694656372, "step": 62000}
{"episode_reward": 226.87209105822507, "episode": 63.0, "batch_reward": 0.1441490520760417, "critic_loss": 0.2836410942152143, "actor_loss": -18.931438947677613, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.123746871948242, "step": 63000}
{"episode_reward": 60.21024824408087, "episode": 64.0, "batch_reward": 0.14280485343188049, "critic_loss": 0.28229982843250034, "actor_loss": -19.167622919082643, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.00361657142639, "step": 64000}
{"episode_reward": 46.39724766997223, "episode": 65.0, "batch_reward": 0.14451145078241825, "critic_loss": 0.2998919215723872, "actor_loss": -19.091459272384643, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.803129196166992, "step": 65000}
{"episode_reward": 386.9157594659828, "episode": 66.0, "batch_reward": 0.14724487421661617, "critic_loss": 0.2746475786045194, "actor_loss": -19.544785190582274, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.683031797409058, "step": 66000}
{"episode_reward": 307.371510019346, "episode": 67.0, "batch_reward": 0.14896646070480346, "critic_loss": 0.2627638530880213, "actor_loss": -19.213854642868043, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.919986724853516, "step": 67000}
{"episode_reward": 395.10723640677566, "episode": 68.0, "batch_reward": 0.15327054408192634, "critic_loss": 0.28423942998051643, "actor_loss": -20.1387788066864, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.53112816810608, "step": 68000}
{"episode_reward": 218.81694616122357, "episode": 69.0, "batch_reward": 0.15448880556225777, "critic_loss": 0.3122490651756525, "actor_loss": -20.185309476852417, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.51951503753662, "step": 69000}
{"episode_reward": 393.4806408199755, "episode": 70.0, "batch_reward": 0.1577996107712388, "critic_loss": 0.2906329747512937, "actor_loss": -20.760711820602417, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.214372634887695, "step": 70000}
{"episode_reward": 367.7987776035883, "episode": 71.0, "batch_reward": 0.1606917170956731, "critic_loss": 0.3028098411113024, "actor_loss": -21.037231267929076, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.02206468582153, "step": 71000}
{"episode_reward": 424.2322677242646, "episode": 72.0, "batch_reward": 0.16480014744400978, "critic_loss": 0.27547184632718563, "actor_loss": -21.133927967071532, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.094582080841064, "step": 72000}
{"episode_reward": 405.90743432256374, "episode": 73.0, "batch_reward": 0.16790634548664093, "critic_loss": 0.2763992207571864, "actor_loss": -21.353912578582765, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.16376805305481, "step": 73000}
{"episode_reward": 396.531433390626, "episode": 74.0, "batch_reward": 0.1714364194869995, "critic_loss": 0.28503299828618767, "actor_loss": -21.831140516281128, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.421181678771973, "step": 74000}
{"episode_reward": 360.8418770249629, "episode": 75.0, "batch_reward": 0.1731929642856121, "critic_loss": 0.2813590713366866, "actor_loss": -22.098637331008913, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.424270153045654, "step": 75000}
{"episode_reward": 395.34508121915127, "episode": 76.0, "batch_reward": 0.17702057211101055, "critic_loss": 0.27403937389701605, "actor_loss": -22.621167907714845, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.20600438117981, "step": 76000}
{"episode_reward": 413.5165513788323, "episode": 77.0, "batch_reward": 0.17945122663676738, "critic_loss": 0.2765677989423275, "actor_loss": -22.524336795806885, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.89844250679016, "step": 77000}
{"episode_reward": 403.6263329038135, "episode": 78.0, "batch_reward": 0.18228182201087476, "critic_loss": 0.2559842681884766, "actor_loss": -22.76624674606323, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.811577796936035, "step": 78000}
{"episode_reward": 399.22510998596545, "episode": 79.0, "batch_reward": 0.1849808899462223, "critic_loss": 0.2691304619982839, "actor_loss": -22.888919765472412, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.14278221130371, "step": 79000}
{"episode_reward": 435.7413095766617, "episode": 80.0, "batch_reward": 0.18768579684197903, "critic_loss": 0.26022461653500795, "actor_loss": -23.309753248214722, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.138393878936768, "step": 80000}
{"episode_reward": 394.9864199297742, "episode": 81.0, "batch_reward": 0.19101158393919468, "critic_loss": 0.27622693014889954, "actor_loss": -23.454654483795167, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.96072816848755, "step": 81000}
{"episode_reward": 425.4117729097001, "episode": 82.0, "batch_reward": 0.19345414566993713, "critic_loss": 0.27216734615713356, "actor_loss": -23.526734245300293, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.617023944854736, "step": 82000}
{"episode_reward": 415.126602410223, "episode": 83.0, "batch_reward": 0.1954038434177637, "critic_loss": 0.25197826823592184, "actor_loss": -24.323267471313475, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.77583956718445, "step": 83000}
{"episode_reward": 398.7449629354417, "episode": 84.0, "batch_reward": 0.19934722831845283, "critic_loss": 0.24836908977478742, "actor_loss": -24.765504436492918, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.948007822036743, "step": 84000}
{"episode_reward": 425.77428755909943, "episode": 85.0, "batch_reward": 0.2026733731031418, "critic_loss": 0.24535796877741814, "actor_loss": -24.310024709701537, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.330317974090576, "step": 85000}
{"episode_reward": 448.1069852530657, "episode": 86.0, "batch_reward": 0.20510048261284827, "critic_loss": 0.24794153948873282, "actor_loss": -24.854413608551024, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.239553928375244, "step": 86000}
{"episode_reward": 404.1676943302946, "episode": 87.0, "batch_reward": 0.20720294578373433, "critic_loss": 0.26795954003185035, "actor_loss": -25.508551931381227, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.374361991882324, "step": 87000}
{"episode_reward": 436.03554126395386, "episode": 88.0, "batch_reward": 0.2100816052556038, "critic_loss": 0.25233533404022457, "actor_loss": -25.872896215438843, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.786405563354492, "step": 88000}
{"episode_reward": 400.61329763123433, "episode": 89.0, "batch_reward": 0.21179769368469714, "critic_loss": 0.24821278693526982, "actor_loss": -25.327230260849, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.314841985702515, "step": 89000}
{"episode_reward": 389.1285397882736, "episode": 90.0, "batch_reward": 0.2134887310117483, "critic_loss": 0.24639491042494774, "actor_loss": -25.689491260528566, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.864970445632935, "step": 90000}
{"episode_reward": 398.387812095049, "episode": 91.0, "batch_reward": 0.21589669214189053, "critic_loss": 0.2498820710927248, "actor_loss": -25.653080068588256, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.057398080825806, "step": 91000}
{"episode_reward": 445.88697872585885, "episode": 92.0, "batch_reward": 0.21757488322257995, "critic_loss": 0.2154253422021866, "actor_loss": -25.946813707351684, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.398160934448242, "step": 92000}
{"episode_reward": 407.55406684578736, "episode": 93.0, "batch_reward": 0.22035023653507232, "critic_loss": 0.24998263937979937, "actor_loss": -26.255083200454713, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.142764806747437, "step": 93000}
{"episode_reward": 397.40033900776916, "episode": 94.0, "batch_reward": 0.22241142286360263, "critic_loss": 0.24180049550533295, "actor_loss": -26.473284002304077, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.714680194854736, "step": 94000}
{"episode_reward": 421.3687262268085, "episode": 95.0, "batch_reward": 0.2245871958732605, "critic_loss": 0.2392819094955921, "actor_loss": -26.886682826995848, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.345574855804443, "step": 95000}
{"episode_reward": 446.5314061768971, "episode": 96.0, "batch_reward": 0.22697114641964436, "critic_loss": 0.23563560707867146, "actor_loss": -27.13905209541321, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.348012447357178, "step": 96000}
{"episode_reward": 415.0717868668739, "episode": 97.0, "batch_reward": 0.2287029378414154, "critic_loss": 0.23322414465993643, "actor_loss": -27.106655452728273, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.708585023880005, "step": 97000}
{"episode_reward": 439.11664560348925, "episode": 98.0, "batch_reward": 0.23080431768298149, "critic_loss": 0.23435388717055322, "actor_loss": -26.960588470458983, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.73379397392273, "step": 98000}
{"episode_reward": 432.0314066808464, "episode": 99.0, "batch_reward": 0.2332071778923273, "critic_loss": 0.243785693064332, "actor_loss": -27.90465340805054, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.4458270072937, "step": 99000}
{"episode_reward": 441.67644542895374, "episode": 100.0, "batch_reward": 0.23419933691620826, "critic_loss": 0.23510058349370958, "actor_loss": -27.83145245361328, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.789095163345337, "step": 100000}
{"episode_reward": 425.66687542665, "episode": 101.0, "batch_reward": 0.2377697005867958, "critic_loss": 0.25178186435997485, "actor_loss": -28.06802431869507, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.92574739456177, "step": 101000}
{"episode_reward": 456.14135265951415, "episode": 102.0, "batch_reward": 0.23933939035236834, "critic_loss": 0.2514532187506556, "actor_loss": -28.212240283966064, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.756136655807495, "step": 102000}
{"episode_reward": 458.59260081805365, "episode": 103.0, "batch_reward": 0.24169782930612563, "critic_loss": 0.24375902991741896, "actor_loss": -28.311371433258056, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.51952600479126, "step": 103000}
{"episode_reward": 431.15160080949397, "episode": 104.0, "batch_reward": 0.24275215864181518, "critic_loss": 0.2454800103753805, "actor_loss": -28.908230041503906, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.98972773551941, "step": 104000}
{"episode_reward": 440.00203416630995, "episode": 105.0, "batch_reward": 0.2449882548749447, "critic_loss": 0.23506258786469697, "actor_loss": -28.61616286087036, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.373894214630127, "step": 105000}
{"episode_reward": 422.14732508273966, "episode": 106.0, "batch_reward": 0.24589034795761108, "critic_loss": 0.24690060181170703, "actor_loss": -29.105264835357666, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.174222946166992, "step": 106000}
{"episode_reward": 432.40817498274504, "episode": 107.0, "batch_reward": 0.2484465834349394, "critic_loss": 0.2397838746458292, "actor_loss": -29.171018611907957, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.579172611236572, "step": 107000}
{"episode_reward": 433.4904404821207, "episode": 108.0, "batch_reward": 0.2493203033655882, "critic_loss": 0.24387257892638445, "actor_loss": -28.51874606323242, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.11094355583191, "step": 108000}
{"episode_reward": 458.00516368759304, "episode": 109.0, "batch_reward": 0.25161373035609724, "critic_loss": 0.24532497239112855, "actor_loss": -29.951269065856934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.06691026687622, "step": 109000}
{"episode_reward": 404.60560751390676, "episode": 110.0, "batch_reward": 0.2537503226697445, "critic_loss": 0.23638392155617474, "actor_loss": -30.113270893096924, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.72953748703003, "step": 110000}
{"episode_reward": 417.126009121315, "episode": 111.0, "batch_reward": 0.25455908608436584, "critic_loss": 0.23602649618685245, "actor_loss": -29.09479723739624, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.33054542541504, "step": 111000}
{"episode_reward": 451.2858649546015, "episode": 112.0, "batch_reward": 0.25630474780499934, "critic_loss": 0.2576307682171464, "actor_loss": -30.466444202423094, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.30143642425537, "step": 112000}
{"episode_reward": 444.91258886443364, "episode": 113.0, "batch_reward": 0.2577643267512321, "critic_loss": 0.24924401631206275, "actor_loss": -29.91227713394165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.78470468521118, "step": 113000}
{"episode_reward": 421.88200138249266, "episode": 114.0, "batch_reward": 0.25919537983834745, "critic_loss": 0.2442893347144127, "actor_loss": -30.253353092193603, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.54200005531311, "step": 114000}
{"episode_reward": 450.89068514885565, "episode": 115.0, "batch_reward": 0.26054745095968246, "critic_loss": 0.2465270959287882, "actor_loss": -30.28156887817383, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.669921398162842, "step": 115000}
{"episode_reward": 412.8808179698948, "episode": 116.0, "batch_reward": 0.2634281174391508, "critic_loss": 0.2562001695036888, "actor_loss": -30.71687184524536, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.05178737640381, "step": 116000}
{"episode_reward": 428.77754068494346, "episode": 117.0, "batch_reward": 0.2646188102513552, "critic_loss": 0.2516451677083969, "actor_loss": -29.768272132873534, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.494765520095825, "step": 117000}
{"episode_reward": 452.52856044508377, "episode": 118.0, "batch_reward": 0.26589808106422425, "critic_loss": 0.2682621725946665, "actor_loss": -30.61969061279297, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.916029691696167, "step": 118000}
{"episode_reward": 451.439489983427, "episode": 119.0, "batch_reward": 0.2679169049859047, "critic_loss": 0.25337688796967267, "actor_loss": -30.95918103790283, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.085932970046997, "step": 119000}
{"episode_reward": 456.20906840091493, "episode": 120.0, "batch_reward": 0.2677539320588112, "critic_loss": 0.24427579279989003, "actor_loss": -30.49852328491211, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.471452713012695, "step": 120000}
{"episode_reward": 415.16827712982854, "episode": 121.0, "batch_reward": 0.26927788990736007, "critic_loss": 0.24394908040761948, "actor_loss": -30.745559642791747, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.45641875267029, "step": 121000}
{"episode_reward": 438.61515855539625, "episode": 122.0, "batch_reward": 0.2724800684005022, "critic_loss": 0.24102528333663942, "actor_loss": -31.113117515563964, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.161879777908325, "step": 122000}
{"episode_reward": 432.8074517675341, "episode": 123.0, "batch_reward": 0.2729616598933935, "critic_loss": 0.24484720668196677, "actor_loss": -31.572702514648437, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.392382860183716, "step": 123000}
{"episode_reward": 463.5119084036706, "episode": 124.0, "batch_reward": 0.2740900662094355, "critic_loss": 0.24405734822899103, "actor_loss": -31.60670325088501, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.370343685150146, "step": 124000}
{"episode_reward": 388.010999172287, "episode": 125.0, "batch_reward": 0.2762058578878641, "critic_loss": 0.24849438523501158, "actor_loss": -31.82053678894043, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.483959436416626, "step": 125000}
{"episode_reward": 446.9817647576412, "episode": 126.0, "batch_reward": 0.27704305347800257, "critic_loss": 0.25104082965105773, "actor_loss": -31.554499839782714, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.373518466949463, "step": 126000}
{"episode_reward": 447.39049446594134, "episode": 127.0, "batch_reward": 0.27748574906587603, "critic_loss": 0.24580677182227373, "actor_loss": -32.27537117004395, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.90760612487793, "step": 127000}
{"episode_reward": 432.763864081136, "episode": 128.0, "batch_reward": 0.27917506037652495, "critic_loss": 0.24051488745212554, "actor_loss": -32.090898719787596, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.729746341705322, "step": 128000}
{"episode_reward": 448.9957051134808, "episode": 129.0, "batch_reward": 0.2803206971883774, "critic_loss": 0.24362558459490538, "actor_loss": -31.936847381591797, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.900415658950806, "step": 129000}
{"episode_reward": 442.97563431909316, "episode": 130.0, "batch_reward": 0.2815276843905449, "critic_loss": 0.23946780378371477, "actor_loss": -32.059492519378665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.36321258544922, "step": 130000}
{"episode_reward": 432.0477713612902, "episode": 131.0, "batch_reward": 0.28306590841710566, "critic_loss": 0.23947780770808458, "actor_loss": -32.55753800201416, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.243375301361084, "step": 131000}
{"episode_reward": 449.3266193064129, "episode": 132.0, "batch_reward": 0.28325362817943095, "critic_loss": 0.23874107978492976, "actor_loss": -32.81237392044067, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.522094011306763, "step": 132000}
{"episode_reward": 455.5658006675395, "episode": 133.0, "batch_reward": 0.28652890406548975, "critic_loss": 0.2304564223587513, "actor_loss": -32.43636516189575, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.69120478630066, "step": 133000}
{"episode_reward": 467.519634117994, "episode": 134.0, "batch_reward": 0.2872275879830122, "critic_loss": 0.24618126267939805, "actor_loss": -32.27470676803589, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.275366067886353, "step": 134000}
{"episode_reward": 457.493863676519, "episode": 135.0, "batch_reward": 0.2881684308797121, "critic_loss": 0.24239121256768703, "actor_loss": -33.441185180664064, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.936135053634644, "step": 135000}
{"episode_reward": 423.56347931636935, "episode": 136.0, "batch_reward": 0.2887683174908161, "critic_loss": 0.24109880976378917, "actor_loss": -31.97156357574463, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.473647594451904, "step": 136000}
{"episode_reward": 382.28327409844496, "episode": 137.0, "batch_reward": 0.2896199421882629, "critic_loss": 0.23587231414020063, "actor_loss": -33.21902896881104, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.585047483444214, "step": 137000}
{"episode_reward": 440.52044412350574, "episode": 138.0, "batch_reward": 0.2922748440802097, "critic_loss": 0.2517834760323167, "actor_loss": -33.29401932907105, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.17535924911499, "step": 138000}
{"episode_reward": 478.9037942939054, "episode": 139.0, "batch_reward": 0.2929367892891169, "critic_loss": 0.2534021459743381, "actor_loss": -33.38381985092163, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.979134798049927, "step": 139000}
{"episode_reward": 454.75739585707345, "episode": 140.0, "batch_reward": 0.29398522625863555, "critic_loss": 0.26111241603642704, "actor_loss": -33.576356819152835, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.61949133872986, "step": 140000}
{"episode_reward": 444.5336201133141, "episode": 141.0, "batch_reward": 0.2941311337053776, "critic_loss": 0.2517539793923497, "actor_loss": -33.74376969909668, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.71330165863037, "step": 141000}
{"episode_reward": 428.5358719213898, "episode": 142.0, "batch_reward": 0.2947250582873821, "critic_loss": 0.25828405979275704, "actor_loss": -33.13267104721069, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.91999125480652, "step": 142000}
{"episode_reward": 468.35533762758905, "episode": 143.0, "batch_reward": 0.2963500301241875, "critic_loss": 0.2457573350816965, "actor_loss": -33.1249655380249, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.503527402877808, "step": 143000}
{"episode_reward": 454.8292872398907, "episode": 144.0, "batch_reward": 0.2980011408030987, "critic_loss": 0.2477050438672304, "actor_loss": -34.15091222763061, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.13408899307251, "step": 144000}
{"episode_reward": 462.5321538224169, "episode": 145.0, "batch_reward": 0.29907424442470076, "critic_loss": 0.2516894978955388, "actor_loss": -34.12283150100708, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.35373878479004, "step": 145000}
{"episode_reward": 470.6526044581695, "episode": 146.0, "batch_reward": 0.30019247061014176, "critic_loss": 0.2624371102899313, "actor_loss": -34.328685131073, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.058785915374756, "step": 146000}
{"episode_reward": 432.95286332526695, "episode": 147.0, "batch_reward": 0.3001624913364649, "critic_loss": 0.23978746382147073, "actor_loss": -34.36674686050415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.673836946487427, "step": 147000}
{"episode_reward": 445.2299952830156, "episode": 148.0, "batch_reward": 0.3029067777842283, "critic_loss": 0.24671419718861579, "actor_loss": -34.48447688293457, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.744860649108887, "step": 148000}
{"episode_reward": 468.03088610267014, "episode": 149.0, "batch_reward": 0.3027937357276678, "critic_loss": 0.24845601338148118, "actor_loss": -34.40865326309204, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.29385781288147, "step": 149000}
{"episode_reward": 425.3806400810469, "episode": 150.0, "batch_reward": 0.3039107097387314, "critic_loss": 0.24174355197697878, "actor_loss": -34.6709567604065, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
