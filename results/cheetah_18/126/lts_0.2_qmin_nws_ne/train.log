{"episode_reward": 0.0, "episode": 1.0, "duration": 20.05704116821289, "step": 1000}
{"episode_reward": 4.231880753996205, "episode": 2.0, "duration": 1.554663896560669, "step": 2000}
{"episode_reward": 395.1450543749875, "episode": 3.0, "batch_reward": 0.18721398578043102, "critic_loss": 0.019035698909488877, "actor_loss": -10.863075511417494, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 69.57978940010071, "step": 3000}
{"episode_reward": 2.2733962331823814, "episode": 4.0, "batch_reward": 0.11639363951236009, "critic_loss": 0.01020908967545256, "actor_loss": -10.632681712150573, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.206716060638428, "step": 4000}
{"episode_reward": 2.4156261338198712, "episode": 5.0, "batch_reward": 0.09112498234584927, "critic_loss": 0.011718952110270037, "actor_loss": -10.527599696159363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.186306476593018, "step": 5000}
{"episode_reward": 3.4994726674957, "episode": 6.0, "batch_reward": 0.07496359596773983, "critic_loss": 0.009992578029399738, "actor_loss": -9.118860373973847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.745392322540283, "step": 6000}
{"episode_reward": 3.1099234492816334, "episode": 7.0, "batch_reward": 0.06408843474648893, "critic_loss": 0.009388013123068958, "actor_loss": -7.904285488128662, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.038817644119263, "step": 7000}
{"episode_reward": 2.8323786259866415, "episode": 8.0, "batch_reward": 0.055702974344603716, "critic_loss": 0.009739329981151968, "actor_loss": -9.848111379146577, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.916831970214844, "step": 8000}
{"episode_reward": 2.9210524291517626, "episode": 9.0, "batch_reward": 0.048910900061950084, "critic_loss": 0.007432176898582839, "actor_loss": -9.125712213993072, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.216323614120483, "step": 9000}
{"episode_reward": 3.036487451855191, "episode": 10.0, "batch_reward": 0.04471489548683166, "critic_loss": 0.009457130250404589, "actor_loss": -8.89121884918213, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.899177074432373, "step": 10000}
{"episode_reward": 2.5720249438738323, "episode": 11.0, "batch_reward": 0.040216899873688816, "critic_loss": 0.006832058534026146, "actor_loss": -7.629841547489166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.30829310417175, "step": 11000}
{"episode_reward": 2.2817005958346286, "episode": 12.0, "batch_reward": 0.03737870344333351, "critic_loss": 0.008750658261182253, "actor_loss": -9.138743572235107, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.656925439834595, "step": 12000}
{"episode_reward": 2.4546329955785557, "episode": 13.0, "batch_reward": 0.03466901989746839, "critic_loss": 0.008543520520266612, "actor_loss": -7.957604672908783, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.945870399475098, "step": 13000}
{"episode_reward": 3.027380581698016, "episode": 14.0, "batch_reward": 0.03156922744074837, "critic_loss": 0.007656384415808134, "actor_loss": -7.4217610495090485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.20639204978943, "step": 14000}
{"episode_reward": 1.8933584298831319, "episode": 15.0, "batch_reward": 0.029910021838266403, "critic_loss": 0.006653688865655568, "actor_loss": -6.442555038928986, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.25602698326111, "step": 15000}
{"episode_reward": 1.9550350340899727, "episode": 16.0, "batch_reward": 0.02771786790480837, "critic_loss": 0.006753307636827231, "actor_loss": -8.241769807100296, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.14693522453308, "step": 16000}
{"episode_reward": 3.011192669171708, "episode": 17.0, "batch_reward": 0.026386129717808217, "critic_loss": 0.005669933659519301, "actor_loss": -8.955615516901016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.548601150512695, "step": 17000}
{"episode_reward": 2.8245360795475394, "episode": 18.0, "batch_reward": 0.024890347633510827, "critic_loss": 0.005735259468987351, "actor_loss": -7.927703101396561, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.588709354400635, "step": 18000}
{"episode_reward": 2.33914694712068, "episode": 19.0, "batch_reward": 0.024378521881764755, "critic_loss": 0.005932771007035626, "actor_loss": -8.03794895863533, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.567169666290283, "step": 19000}
{"episode_reward": 3.723025308100697, "episode": 20.0, "batch_reward": 0.02320226860092953, "critic_loss": 0.00524634900498495, "actor_loss": -7.391858572483063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.41175389289856, "step": 20000}
{"episode_reward": 2.5822296696263134, "episode": 21.0, "batch_reward": 0.021479208660311996, "critic_loss": 0.004806192667572759, "actor_loss": -8.318715760231019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.903353452682495, "step": 21000}
{"episode_reward": 2.4250078279941567, "episode": 22.0, "batch_reward": 0.02075227999407798, "critic_loss": 0.0055909765283577145, "actor_loss": -7.104487746953964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.214317798614502, "step": 22000}
{"episode_reward": 2.6360939420020983, "episode": 23.0, "batch_reward": 0.020167329150252045, "critic_loss": 0.004165459335796186, "actor_loss": -7.025426872014999, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.229596853256226, "step": 23000}
{"episode_reward": 2.009502847004504, "episode": 24.0, "batch_reward": 0.019520735576748847, "critic_loss": 0.004323677530243003, "actor_loss": -6.9132271027565, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.013556480407715, "step": 24000}
{"episode_reward": 2.0403689412193913, "episode": 25.0, "batch_reward": 0.01867022935813293, "critic_loss": 0.0033529484848404535, "actor_loss": -6.761604075431824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.99968910217285, "step": 25000}
{"episode_reward": 2.5290894170437914, "episode": 26.0, "batch_reward": 0.018435830160044134, "critic_loss": 0.003514100835309364, "actor_loss": -7.043842846870422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.40354871749878, "step": 26000}
{"episode_reward": 3.1325946005562018, "episode": 27.0, "batch_reward": 0.017780686147743835, "critic_loss": 0.003904757182346657, "actor_loss": -6.032108583807945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.059624433517456, "step": 27000}
{"episode_reward": 2.3912595005626134, "episode": 28.0, "batch_reward": 0.016497275338042527, "critic_loss": 0.003487710763627547, "actor_loss": -7.244718983411789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.037840127944946, "step": 28000}
{"episode_reward": 2.1159376523057976, "episode": 29.0, "batch_reward": 0.01606250494462438, "critic_loss": 0.0035942335323343286, "actor_loss": -5.810756209492683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.622782468795776, "step": 29000}
{"episode_reward": 2.3159956188285236, "episode": 30.0, "batch_reward": 0.016250958764576353, "critic_loss": 0.0041366541371389755, "actor_loss": -6.566384352207184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.92643904685974, "step": 30000}
{"episode_reward": 1.9810007750914262, "episode": 31.0, "batch_reward": 0.015471713350270875, "critic_loss": 0.002679931844875682, "actor_loss": -6.966295061230659, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.69482421875, "step": 31000}
{"episode_reward": 2.7415880634392176, "episode": 32.0, "batch_reward": 0.015032125098980031, "critic_loss": 0.004368846836783632, "actor_loss": -6.312321053385735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.354703426361084, "step": 32000}
{"episode_reward": 1.9879061075500892, "episode": 33.0, "batch_reward": 0.015064758370164782, "critic_loss": 0.0028466214067157125, "actor_loss": -6.576158360362053, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.027942895889282, "step": 33000}
{"episode_reward": 2.980466839797492, "episode": 34.0, "batch_reward": 0.014179975892184303, "critic_loss": 0.0026440684578010404, "actor_loss": -6.731388771295547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.885866403579712, "step": 34000}
{"episode_reward": 2.7167162004125043, "episode": 35.0, "batch_reward": 0.013967789460206404, "critic_loss": 0.002471960129729268, "actor_loss": -6.5385796813964845, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.14973020553589, "step": 35000}
{"episode_reward": 2.3332280442162734, "episode": 36.0, "batch_reward": 0.013687721174908803, "critic_loss": 0.0026759637154100346, "actor_loss": -6.908628050804138, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.56896710395813, "step": 36000}
{"episode_reward": 3.069263414431961, "episode": 37.0, "batch_reward": 0.013348545584827662, "critic_loss": 0.0022685802927189798, "actor_loss": -7.392414832353592, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.209579467773438, "step": 37000}
{"episode_reward": 2.089085199579736, "episode": 38.0, "batch_reward": 0.013139136398443952, "critic_loss": 0.0028731422226774155, "actor_loss": -5.817932168662548, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.502249479293823, "step": 38000}
{"episode_reward": 2.8691116835124104, "episode": 39.0, "batch_reward": 0.013056418674299493, "critic_loss": 0.002696017535545252, "actor_loss": -6.582017838001251, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.18535351753235, "step": 39000}
{"episode_reward": 1.7551030922628066, "episode": 40.0, "batch_reward": 0.012371326717548072, "critic_loss": 0.002528901231220516, "actor_loss": -6.679537140727043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.22496724128723, "step": 40000}
{"episode_reward": 1.8730266629135752, "episode": 41.0, "batch_reward": 0.012341506247408688, "critic_loss": 0.0019226417540558031, "actor_loss": -7.1313124563694, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.45006704330444, "step": 41000}
{"episode_reward": 2.828701704408658, "episode": 42.0, "batch_reward": 0.012003892433014699, "critic_loss": 0.002442482240661775, "actor_loss": -7.092988346219062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.441655158996582, "step": 42000}
{"episode_reward": 2.2116786543804285, "episode": 43.0, "batch_reward": 0.011722094615804963, "critic_loss": 0.002665725718630711, "actor_loss": -6.2721161034107205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.63207173347473, "step": 43000}
{"episode_reward": 2.5740358587375627, "episode": 44.0, "batch_reward": 0.011401865866151639, "critic_loss": 0.0022319669113421694, "actor_loss": -6.820607177972794, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.002657651901245, "step": 44000}
{"episode_reward": 2.5711310299858017, "episode": 45.0, "batch_reward": 0.01131461014074739, "critic_loss": 0.0023072727698890956, "actor_loss": -6.179312816441059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.790755033493042, "step": 45000}
{"episode_reward": 2.782622051417974, "episode": 46.0, "batch_reward": 0.011293638812378048, "critic_loss": 0.002177764892945561, "actor_loss": -6.9106338975429535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.903578281402588, "step": 46000}
{"episode_reward": 3.126149056203073, "episode": 47.0, "batch_reward": 0.011042411271482706, "critic_loss": 0.002513374324371398, "actor_loss": -7.304611481130123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.552300691604614, "step": 47000}
{"episode_reward": 2.36006247086926, "episode": 48.0, "batch_reward": 0.010807403266313485, "critic_loss": 0.002594336241141718, "actor_loss": -5.683969254732132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.508451223373413, "step": 48000}
{"episode_reward": 2.6746474389085466, "episode": 49.0, "batch_reward": 0.010990708880708553, "critic_loss": 0.0024849470242079407, "actor_loss": -5.910072909116745, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.705819129943848, "step": 49000}
{"episode_reward": 2.7933267736865544, "episode": 50.0, "batch_reward": 0.010672232856275514, "critic_loss": 0.0020363073130429256, "actor_loss": -6.517618059933185, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.96982192993164, "step": 50000}
{"episode_reward": 3.5139239345896414, "episode": 51.0, "batch_reward": 0.010399807861307635, "critic_loss": 0.0020012195646377223, "actor_loss": -5.519816090345382, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.58485221862793, "step": 51000}
{"episode_reward": 3.108558565155713, "episode": 52.0, "batch_reward": 0.010399514541495592, "critic_loss": 0.002048198510758084, "actor_loss": -6.264840658426285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.712332010269165, "step": 52000}
{"episode_reward": 2.059643150695908, "episode": 53.0, "batch_reward": 0.010226522995042614, "critic_loss": 0.0021253439688989602, "actor_loss": -5.4462317615747455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.133111238479614, "step": 53000}
{"episode_reward": 2.902212753091402, "episode": 54.0, "batch_reward": 0.010263370156404562, "critic_loss": 0.002834918823606131, "actor_loss": -5.99955389598012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.234517812728882, "step": 54000}
{"episode_reward": 2.4632684948455865, "episode": 55.0, "batch_reward": 0.009772585156140849, "critic_loss": 0.002043389166443376, "actor_loss": -6.266307374209165, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.52495002746582, "step": 55000}
{"episode_reward": 3.1630169047321983, "episode": 56.0, "batch_reward": 0.009563626877730711, "critic_loss": 0.0019243065501013917, "actor_loss": -5.270923505872488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.083094120025635, "step": 56000}
{"episode_reward": 2.171228702176631, "episode": 57.0, "batch_reward": 0.009691770831006578, "critic_loss": 0.001882379043986475, "actor_loss": -5.775351099252701, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.163312673568726, "step": 57000}
{"episode_reward": 2.241191398926657, "episode": 58.0, "batch_reward": 0.009479552852222696, "critic_loss": 0.002352049198525492, "actor_loss": -5.132879610896111, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20229482650757, "step": 58000}
{"episode_reward": 2.7827965009444666, "episode": 59.0, "batch_reward": 0.009202972408616915, "critic_loss": 0.0016899961313865787, "actor_loss": -5.630983357399702, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.12174963951111, "step": 59000}
{"episode_reward": 3.690142691052043, "episode": 60.0, "batch_reward": 0.009257180968765169, "critic_loss": 0.0017521168444582145, "actor_loss": -5.8496549281477925, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.536290645599365, "step": 60000}
{"episode_reward": 3.1682733279886035, "episode": 61.0, "batch_reward": 0.00902753860328812, "critic_loss": 0.001460831931573921, "actor_loss": -5.7269806923568245, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.33610534667969, "step": 61000}
{"episode_reward": 3.061056008789957, "episode": 62.0, "batch_reward": 0.00874191606999375, "critic_loss": 0.001953341109247049, "actor_loss": -5.249811574786902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.482816457748413, "step": 62000}
{"episode_reward": 2.5768129763053707, "episode": 63.0, "batch_reward": 0.00886108073987998, "critic_loss": 0.0015386311101283354, "actor_loss": -5.53070287206769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.613604307174683, "step": 63000}
{"episode_reward": 3.190561891123756, "episode": 64.0, "batch_reward": 0.008716249720891937, "critic_loss": 0.0016387085838123312, "actor_loss": -6.0462929494380955, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.585525274276733, "step": 64000}
{"episode_reward": 3.3301734034928994, "episode": 65.0, "batch_reward": 0.008833736078464426, "critic_loss": 0.0019237293954156485, "actor_loss": -5.238299791932106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.937943935394287, "step": 65000}
{"episode_reward": 2.497651677977446, "episode": 66.0, "batch_reward": 0.008484883653814904, "critic_loss": 0.002247520579569027, "actor_loss": -6.14564680558443, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.020909309387207, "step": 66000}
{"episode_reward": 2.7288908977308215, "episode": 67.0, "batch_reward": 0.008427960765780881, "critic_loss": 0.002047122694382779, "actor_loss": -5.73109719632566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.235265970230103, "step": 67000}
{"episode_reward": 2.4847767709731934, "episode": 68.0, "batch_reward": 0.008558478354127146, "critic_loss": 0.00234519245928459, "actor_loss": -5.793332558825612, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.389153480529785, "step": 68000}
{"episode_reward": 2.021973825303625, "episode": 69.0, "batch_reward": 0.008529980709892698, "critic_loss": 0.0014204287091906735, "actor_loss": -6.070203340277076, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.713349103927612, "step": 69000}
{"episode_reward": 3.448847064684717, "episode": 70.0, "batch_reward": 0.008267968674656003, "critic_loss": 0.001385433817620651, "actor_loss": -5.541324004173279, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.373918771743774, "step": 70000}
{"episode_reward": 2.117254323252734, "episode": 71.0, "batch_reward": 0.008225271347677336, "critic_loss": 0.0020391941332036367, "actor_loss": -5.596694768935442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.833824634552, "step": 71000}
{"episode_reward": 2.224325343422689, "episode": 72.0, "batch_reward": 0.008101085065165535, "critic_loss": 0.001506756838183719, "actor_loss": -5.648705470025539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.362871408462524, "step": 72000}
{"episode_reward": 2.6760370587627076, "episode": 73.0, "batch_reward": 0.008119814387639052, "critic_loss": 0.0016487279949815275, "actor_loss": -6.157292472183705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.977975606918335, "step": 73000}
{"episode_reward": 2.986094641041872, "episode": 74.0, "batch_reward": 0.007939484727336094, "critic_loss": 0.0016552240709024773, "actor_loss": -5.573676332548261, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.97152853012085, "step": 74000}
{"episode_reward": 2.871248224392117, "episode": 75.0, "batch_reward": 0.008152442565304226, "critic_loss": 0.0018373076044936169, "actor_loss": -5.923915934696794, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.391177892684937, "step": 75000}
{"episode_reward": 2.822295608966114, "episode": 76.0, "batch_reward": 0.0077455523553071545, "critic_loss": 0.001606722676911886, "actor_loss": -6.421041577830911, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9395170211792, "step": 76000}
{"episode_reward": 1.8050981975380596, "episode": 77.0, "batch_reward": 0.007608557794126682, "critic_loss": 0.0015521842556245247, "actor_loss": -5.8384790132939814, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.57588768005371, "step": 77000}
{"episode_reward": 2.2257544153639994, "episode": 78.0, "batch_reward": 0.007817943652509712, "critic_loss": 0.0018982784682011697, "actor_loss": -4.928232784926891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.12430429458618, "step": 78000}
{"episode_reward": 2.362369115837126, "episode": 79.0, "batch_reward": 0.007534197280416265, "critic_loss": 0.0017763587885383457, "actor_loss": -5.0809099516049026, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.500372409820557, "step": 79000}
{"episode_reward": 1.9573442813270074, "episode": 80.0, "batch_reward": 0.007567063295515254, "critic_loss": 0.002322983050989933, "actor_loss": -6.121563004396855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.259010076522827, "step": 80000}
{"episode_reward": 2.2675015730290875, "episode": 81.0, "batch_reward": 0.00761643149331212, "critic_loss": 0.00156452211814576, "actor_loss": -5.838317643456161, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.74449276924133, "step": 81000}
{"episode_reward": 2.1822416128560853, "episode": 82.0, "batch_reward": 0.007320560061372817, "critic_loss": 0.0021300234836216987, "actor_loss": -5.596236496731639, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.387971878051758, "step": 82000}
{"episode_reward": 3.1365406004513137, "episode": 83.0, "batch_reward": 0.007290174389723688, "critic_loss": 0.0017432027060367546, "actor_loss": -6.728832269117236, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.853493213653564, "step": 83000}
{"episode_reward": 1.797776957277495, "episode": 84.0, "batch_reward": 0.007072354896226898, "critic_loss": 0.0012713713503271719, "actor_loss": -6.03337845248729, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.568066120147705, "step": 84000}
{"episode_reward": 2.4441051838393686, "episode": 85.0, "batch_reward": 0.0074565173430601135, "critic_loss": 0.0012582838663875008, "actor_loss": -5.8685943968445065, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.107197761535645, "step": 85000}
{"episode_reward": 2.42358871920921, "episode": 86.0, "batch_reward": 0.007238290440756827, "critic_loss": 0.0019523156774976086, "actor_loss": -6.7818303798064585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.86123824119568, "step": 86000}
{"episode_reward": 2.5799914260396193, "episode": 87.0, "batch_reward": 0.007425263725337573, "critic_loss": 0.0010937083274793623, "actor_loss": -6.031991019509733, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.36045551300049, "step": 87000}
{"episode_reward": 2.844172915522674, "episode": 88.0, "batch_reward": 0.007269826311036013, "critic_loss": 0.001816932372545125, "actor_loss": -6.605613162927329, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.264187335968018, "step": 88000}
{"episode_reward": 2.4422336494118637, "episode": 89.0, "batch_reward": 0.007098070454783737, "critic_loss": 0.0014450987318696206, "actor_loss": -5.503799636386335, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.002669095993042, "step": 89000}
{"episode_reward": 2.654164512735669, "episode": 90.0, "batch_reward": 0.006897901551565155, "critic_loss": 0.0012480160997611165, "actor_loss": -4.745390542067588, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.731430530548096, "step": 90000}
{"episode_reward": 2.425625062938005, "episode": 91.0, "batch_reward": 0.006969064585515298, "critic_loss": 0.0016158874571956404, "actor_loss": -5.780814631670713, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.4657347202301, "step": 91000}
{"episode_reward": 2.5981738576913767, "episode": 92.0, "batch_reward": 0.006889045952702872, "critic_loss": 0.0009164093410108762, "actor_loss": -6.065228564284742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.990895986557007, "step": 92000}
{"episode_reward": 3.0677478395080713, "episode": 93.0, "batch_reward": 0.006899768554372713, "critic_loss": 0.000803468651582989, "actor_loss": -5.5960785528160635, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.701934099197388, "step": 93000}
{"episode_reward": 2.3959271769579944, "episode": 94.0, "batch_reward": 0.006712171233608387, "critic_loss": 0.001591976557898306, "actor_loss": -6.005029026307166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.050230026245117, "step": 94000}
{"episode_reward": 2.1152027419256623, "episode": 95.0, "batch_reward": 0.006722236478002742, "critic_loss": 0.00141408122933899, "actor_loss": -4.912256945542991, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.445285081863403, "step": 95000}
{"episode_reward": 2.9645920660790672, "episode": 96.0, "batch_reward": 0.006712125861551612, "critic_loss": 0.001749129616382561, "actor_loss": -7.268966576263309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.296854734420776, "step": 96000}
{"episode_reward": 2.474365410232089, "episode": 97.0, "batch_reward": 0.006606865574140102, "critic_loss": 0.0015270619134171283, "actor_loss": -6.345455010939389, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.132436275482178, "step": 97000}
{"episode_reward": 1.4185833752992818, "episode": 98.0, "batch_reward": 0.006587404005229473, "critic_loss": 0.0013216351330811449, "actor_loss": -5.022091011207551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.506129026412964, "step": 98000}
{"episode_reward": 2.016842445564644, "episode": 99.0, "batch_reward": 0.0066782007494475696, "critic_loss": 0.001567801646566295, "actor_loss": -7.087608303815126, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.938724517822266, "step": 99000}
{"episode_reward": 2.6878088087297383, "episode": 100.0, "batch_reward": 0.00641821747762151, "critic_loss": 0.0016405782314486714, "actor_loss": -6.453221643347293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.16158890724182, "step": 100000}
{"episode_reward": 2.323888214949344, "episode": 101.0, "batch_reward": 0.0064122304469347, "critic_loss": 0.001290864403422347, "actor_loss": -7.5391901919040825, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.62513065338135, "step": 101000}
{"episode_reward": 1.700132634711815, "episode": 102.0, "batch_reward": 0.006311718260170892, "critic_loss": 0.001915295757640706, "actor_loss": -6.209853177340701, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.016717195510864, "step": 102000}
{"episode_reward": 1.6001436821937036, "episode": 103.0, "batch_reward": 0.006501751190749928, "critic_loss": 0.0019454289319437521, "actor_loss": -5.467813245251775, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.485891103744507, "step": 103000}
{"episode_reward": 1.6914289837156393, "episode": 104.0, "batch_reward": 0.006567417031154037, "critic_loss": 0.0013013620622405143, "actor_loss": -6.275469620505348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.29495882987976, "step": 104000}
{"episode_reward": 2.239334512696328, "episode": 105.0, "batch_reward": 0.006265788140241057, "critic_loss": 0.0015437633079673106, "actor_loss": -6.430875557732769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.582098245620728, "step": 105000}
{"episode_reward": 2.3758739754257157, "episode": 106.0, "batch_reward": 0.0063940393516095356, "critic_loss": 0.0010832060316006392, "actor_loss": -6.547982718294486, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.79544687271118, "step": 106000}
{"episode_reward": 2.989069980987457, "episode": 107.0, "batch_reward": 0.006261902131373062, "critic_loss": 0.0008343762575259462, "actor_loss": -6.4715145439356565, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.294445514678955, "step": 107000}
{"episode_reward": 2.864378908222313, "episode": 108.0, "batch_reward": 0.006032996463240124, "critic_loss": 0.0010948520423144147, "actor_loss": -5.203186572568491, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.86503505706787, "step": 108000}
{"episode_reward": 2.647090273146156, "episode": 109.0, "batch_reward": 0.006195732731954195, "critic_loss": 0.0009824307159697128, "actor_loss": -5.559590439405293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.945855379104614, "step": 109000}
{"episode_reward": 2.022732631585435, "episode": 110.0, "batch_reward": 0.0060689743460388855, "critic_loss": 0.0010416237449217079, "actor_loss": -5.899747462252155, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.269798040390015, "step": 110000}
{"episode_reward": 2.5610070633795177, "episode": 111.0, "batch_reward": 0.006131149322725833, "critic_loss": 0.001199622389716751, "actor_loss": -4.989606806992786, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.75757956504822, "step": 111000}
{"episode_reward": 2.7203460346006323, "episode": 112.0, "batch_reward": 0.006145573973539285, "critic_loss": 0.0009730741244839009, "actor_loss": -6.771709125793539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.555150985717773, "step": 112000}
{"episode_reward": 2.2334666183073066, "episode": 113.0, "batch_reward": 0.006129909462179057, "critic_loss": 0.000996301205315831, "actor_loss": -5.909198544249637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.47041082382202, "step": 113000}
{"episode_reward": 2.7417750399171954, "episode": 114.0, "batch_reward": 0.006080844965879805, "critic_loss": 0.0011361621365313112, "actor_loss": -6.47550115749042, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.963685750961304, "step": 114000}
{"episode_reward": 2.6042077239392523, "episode": 115.0, "batch_reward": 0.005865942201111466, "critic_loss": 0.0010932008183926882, "actor_loss": -6.300375965575804, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.630755186080933, "step": 115000}
{"episode_reward": 3.1171306785935773, "episode": 116.0, "batch_reward": 0.0058815709768095985, "critic_loss": 0.001105128709701603, "actor_loss": -5.950682691413618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.563395500183105, "step": 116000}
{"episode_reward": 3.472686576239319, "episode": 117.0, "batch_reward": 0.006265446003410034, "critic_loss": 0.001256965603079152, "actor_loss": -5.620130677510984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.59430193901062, "step": 117000}
{"episode_reward": 2.390233349259836, "episode": 118.0, "batch_reward": 0.005838784361607395, "critic_loss": 0.0009748676809267636, "actor_loss": -6.061362948118243, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.023723363876343, "step": 118000}
{"episode_reward": 2.058455189368442, "episode": 119.0, "batch_reward": 0.0058101423335028815, "critic_loss": 0.0009955393038198963, "actor_loss": -5.716246663523838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.15477752685547, "step": 119000}
{"episode_reward": 2.793843510976657, "episode": 120.0, "batch_reward": 0.005838425458641723, "critic_loss": 0.0010381198768927788, "actor_loss": -5.137862642290594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.195910453796387, "step": 120000}
{"episode_reward": 3.1281082231997037, "episode": 121.0, "batch_reward": 0.005835608150577173, "critic_loss": 0.0006806875354604927, "actor_loss": -6.010172869126778, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.365888357162476, "step": 121000}
{"episode_reward": 2.2277524032570915, "episode": 122.0, "batch_reward": 0.005833311396301724, "critic_loss": 0.0008750097890088, "actor_loss": -5.485842098938417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.228474617004395, "step": 122000}
{"episode_reward": 2.8274797636159654, "episode": 123.0, "batch_reward": 0.005598389870021492, "critic_loss": 0.0008953641592343047, "actor_loss": -5.884797774766979, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00019335746765, "step": 123000}
{"episode_reward": 3.269496166340966, "episode": 124.0, "batch_reward": 0.0058005240610800686, "critic_loss": 0.0008170608926657224, "actor_loss": -6.631591841421818, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.954190015792847, "step": 124000}
{"episode_reward": 3.2405079197827176, "episode": 125.0, "batch_reward": 0.005792389753391035, "critic_loss": 0.0007404666459951841, "actor_loss": -6.351618896590197, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.861365795135498, "step": 125000}
{"episode_reward": 2.716818126025781, "episode": 126.0, "batch_reward": 0.005850353865534999, "critic_loss": 0.0010143332932821068, "actor_loss": -5.37591124085593, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.132070064544678, "step": 126000}
{"episode_reward": 2.438463342561178, "episode": 127.0, "batch_reward": 0.005742509527830407, "critic_loss": 0.0010806087695573296, "actor_loss": -6.576953188968241, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.82327175140381, "step": 127000}
{"episode_reward": 2.377861932891343, "episode": 128.0, "batch_reward": 0.0053762825781013815, "critic_loss": 0.0008110630106075405, "actor_loss": -6.23147808718204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.95086669921875, "step": 128000}
{"episode_reward": 3.1488419341774776, "episode": 129.0, "batch_reward": 0.0057645144810667265, "critic_loss": 0.0010902595485222264, "actor_loss": -5.601639564746408, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.149672746658325, "step": 129000}
{"episode_reward": 2.3521677744970018, "episode": 130.0, "batch_reward": 0.005483791162609122, "critic_loss": 0.0009293354151559469, "actor_loss": -5.597163164850266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.399159908294678, "step": 130000}
{"episode_reward": 2.484337776807303, "episode": 131.0, "batch_reward": 0.005592635430395603, "critic_loss": 0.0010968393859839124, "actor_loss": -5.84916720416618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.225147008895874, "step": 131000}
{"episode_reward": 3.0659664332172554, "episode": 132.0, "batch_reward": 0.005502041181665846, "critic_loss": 0.0010264564978724592, "actor_loss": -5.65936645973986, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.002949714660645, "step": 132000}
{"episode_reward": 2.35763238745111, "episode": 133.0, "batch_reward": 0.005403836466488428, "critic_loss": 0.0010387623176638953, "actor_loss": -4.906121234159509, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.56772470474243, "step": 133000}
{"episode_reward": 2.164471012531129, "episode": 134.0, "batch_reward": 0.0056544403503648935, "critic_loss": 0.001190085993910543, "actor_loss": -5.497572110249894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.44140362739563, "step": 134000}
{"episode_reward": 2.9947394630610056, "episode": 135.0, "batch_reward": 0.005515055221156217, "critic_loss": 0.0009137906745863802, "actor_loss": -6.405553331284958, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.47009015083313, "step": 135000}
{"episode_reward": 2.704772823635544, "episode": 136.0, "batch_reward": 0.00540952516568359, "critic_loss": 0.0013327786662366635, "actor_loss": -5.080268107682467, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.587411403656006, "step": 136000}
{"episode_reward": 2.6558568972938064, "episode": 137.0, "batch_reward": 0.0054090692194877195, "critic_loss": 0.0006946384228895113, "actor_loss": -5.8880421632281505, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.115392684936523, "step": 137000}
{"episode_reward": 2.3622728230736465, "episode": 138.0, "batch_reward": 0.005441632404108531, "critic_loss": 0.001226715291990331, "actor_loss": -6.517816329837893, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.082225561141968, "step": 138000}
{"episode_reward": 2.4428302910355764, "episode": 139.0, "batch_reward": 0.005381658012629487, "critic_loss": 0.001034971341304299, "actor_loss": -4.501455229041225, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.698490858078003, "step": 139000}
{"episode_reward": 2.1309064461395453, "episode": 140.0, "batch_reward": 0.005342924428288825, "critic_loss": 0.0007900516922391034, "actor_loss": -5.94505385033213, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.23296308517456, "step": 140000}
{"episode_reward": 3.547788235343901, "episode": 141.0, "batch_reward": 0.005514757395372726, "critic_loss": 0.0012358256030875054, "actor_loss": -6.6330045311486465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.69177865982056, "step": 141000}
{"episode_reward": 2.531790281068182, "episode": 142.0, "batch_reward": 0.005384349048370495, "critic_loss": 0.0011779478031276084, "actor_loss": -5.256370892153587, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.49266266822815, "step": 142000}
{"episode_reward": 2.7180324141039645, "episode": 143.0, "batch_reward": 0.005465167660382577, "critic_loss": 0.0009356637006221717, "actor_loss": -5.1408644441801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.978100061416626, "step": 143000}
{"episode_reward": 3.181473735867095, "episode": 144.0, "batch_reward": 0.005184221758041531, "critic_loss": 0.0010816325769737887, "actor_loss": -5.480976046887284, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.467187643051147, "step": 144000}
{"episode_reward": 3.276249655357719, "episode": 145.0, "batch_reward": 0.005243908167351037, "critic_loss": 0.0008205722169423097, "actor_loss": -6.220867672831984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.81926989555359, "step": 145000}
{"episode_reward": 3.119435523294389, "episode": 146.0, "batch_reward": 0.005350828743888997, "critic_loss": 0.0008203323222714971, "actor_loss": -6.516353913377272, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06427550315857, "step": 146000}
{"episode_reward": 3.0755363101312287, "episode": 147.0, "batch_reward": 0.005234063004842028, "critic_loss": 0.0006598312346759485, "actor_loss": -5.876366851679806, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.393635749816895, "step": 147000}
{"episode_reward": 2.240240966750567, "episode": 148.0, "batch_reward": 0.0052745406057219954, "critic_loss": 0.0009790710868146561, "actor_loss": -5.878147304771584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.844908475875854, "step": 148000}
{"episode_reward": 2.9111433075892528, "episode": 149.0, "batch_reward": 0.005263639515731484, "critic_loss": 0.0010395491728168054, "actor_loss": -5.649129059979808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.025099754333496, "step": 149000}
{"episode_reward": 2.1985344625682837, "episode": 150.0, "batch_reward": 0.0055188965757843106, "critic_loss": 0.0010299177046526893, "actor_loss": -6.343266048169811, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
