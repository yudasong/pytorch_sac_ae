{"episode_reward": 0.0, "episode": 1.0, "duration": 18.60111117362976, "step": 1000}
{"episode_reward": 4.231880753996205, "episode": 2.0, "duration": 1.5552244186401367, "step": 2000}
{"episode_reward": 395.1450543749875, "episode": 3.0, "batch_reward": 0.1876796269717913, "critic_loss": 0.019990655284582395, "actor_loss": -9.125682672297414, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 68.59471130371094, "step": 3000}
{"episode_reward": 10.848577701623801, "episode": 4.0, "batch_reward": 0.12860937330871822, "critic_loss": 0.021060817356221378, "actor_loss": -8.983308448791504, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.388089656829834, "step": 4000}
{"episode_reward": 44.641162993170525, "episode": 5.0, "batch_reward": 0.10634133443236352, "critic_loss": 0.02273138048686087, "actor_loss": -9.38433590888977, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.383869647979736, "step": 5000}
{"episode_reward": 26.470304539384284, "episode": 6.0, "batch_reward": 0.09888087271526456, "critic_loss": 0.03101262426469475, "actor_loss": -8.632620968341827, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.61623740196228, "step": 6000}
{"episode_reward": 87.40039148663863, "episode": 7.0, "batch_reward": 0.10152437118068337, "critic_loss": 0.042232086673378945, "actor_loss": -8.358175664424897, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.432433128356934, "step": 7000}
{"episode_reward": 142.3205626863501, "episode": 8.0, "batch_reward": 0.09789488543570042, "critic_loss": 0.042801471358165144, "actor_loss": -10.47017322731018, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.687845945358276, "step": 8000}
{"episode_reward": 30.895689245747533, "episode": 9.0, "batch_reward": 0.09058559476211667, "critic_loss": 0.04753333025239408, "actor_loss": -9.736308836936951, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.186773538589478, "step": 9000}
{"episode_reward": 37.556681752039154, "episode": 10.0, "batch_reward": 0.0850365392230451, "critic_loss": 0.06540982971712947, "actor_loss": -9.715654537677764, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.997887134552002, "step": 10000}
{"episode_reward": 26.837041520567734, "episode": 11.0, "batch_reward": 0.08333737074583769, "critic_loss": 0.08324443257972598, "actor_loss": -9.400610068321228, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.525219440460205, "step": 11000}
{"episode_reward": 87.31682446200432, "episode": 12.0, "batch_reward": 0.08263219684362412, "critic_loss": 0.09448798340559006, "actor_loss": -10.912168696403503, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.224858045578003, "step": 12000}
{"episode_reward": 63.23264437347173, "episode": 13.0, "batch_reward": 0.08006490617617965, "critic_loss": 0.10276448759064079, "actor_loss": -10.490540238380433, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.47225332260132, "step": 13000}
{"episode_reward": 42.27884955368111, "episode": 14.0, "batch_reward": 0.07533715120330453, "critic_loss": 0.12431671285256743, "actor_loss": -10.381965893745422, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.476892232894897, "step": 14000}
{"episode_reward": 29.351089466769686, "episode": 15.0, "batch_reward": 0.0747202188409865, "critic_loss": 0.13716648565605283, "actor_loss": -10.414869095802308, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.205049991607666, "step": 15000}
{"episode_reward": 131.79007066232418, "episode": 16.0, "batch_reward": 0.07955163610726596, "critic_loss": 0.1600236562602222, "actor_loss": -11.867509157180786, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.354982376098633, "step": 16000}
{"episode_reward": 107.51579881236623, "episode": 17.0, "batch_reward": 0.07691916721314192, "critic_loss": 0.1381406573690474, "actor_loss": -12.518980445861816, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.76799249649048, "step": 17000}
{"episode_reward": 5.414214678007643, "episode": 18.0, "batch_reward": 0.07309576169401408, "critic_loss": 0.14982091874629258, "actor_loss": -12.909288457870483, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.89160466194153, "step": 18000}
{"episode_reward": 10.1888688528094, "episode": 19.0, "batch_reward": 0.07017212092131377, "critic_loss": 0.1621820697709918, "actor_loss": -14.133693529129028, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.767614603042603, "step": 19000}
{"episode_reward": 35.27458010486526, "episode": 20.0, "batch_reward": 0.0719191533997655, "critic_loss": 0.17721698065847158, "actor_loss": -14.724234100341796, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.150856256484985, "step": 20000}
{"episode_reward": 115.06386113784355, "episode": 21.0, "batch_reward": 0.07212943394854665, "critic_loss": 0.18283304073661566, "actor_loss": -15.717243104934692, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.92760968208313, "step": 21000}
{"episode_reward": 63.18861034094044, "episode": 22.0, "batch_reward": 0.07083532183617354, "critic_loss": 0.16418157459795474, "actor_loss": -15.885539438247681, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.827584266662598, "step": 22000}
{"episode_reward": 47.150295952837745, "episode": 23.0, "batch_reward": 0.07421143676713109, "critic_loss": 0.20154794076085092, "actor_loss": -16.570841522216796, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.02475333213806, "step": 23000}
{"episode_reward": 227.98743347553707, "episode": 24.0, "batch_reward": 0.08198614559695125, "critic_loss": 0.22895389677584171, "actor_loss": -17.266093185424804, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.5556423664093, "step": 24000}
{"episode_reward": 305.4048410194819, "episode": 25.0, "batch_reward": 0.08742851430922746, "critic_loss": 0.2570305598974228, "actor_loss": -17.963486837387084, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.88257384300232, "step": 25000}
{"episode_reward": 92.81294008829461, "episode": 26.0, "batch_reward": 0.09015792961791158, "critic_loss": 0.24389130448549987, "actor_loss": -18.443233070373534, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.762991905212402, "step": 26000}
{"episode_reward": 173.4775245438793, "episode": 27.0, "batch_reward": 0.09269881163537502, "critic_loss": 0.23651055876165628, "actor_loss": -18.798025049209595, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.40718412399292, "step": 27000}
{"episode_reward": 146.9340156435736, "episode": 28.0, "batch_reward": 0.09234751158952713, "critic_loss": 0.25119048400223254, "actor_loss": -19.30314203643799, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.232640981674194, "step": 28000}
{"episode_reward": 85.44367341883517, "episode": 29.0, "batch_reward": 0.09453254931420088, "critic_loss": 0.23565800244361162, "actor_loss": -19.11281157684326, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.70736598968506, "step": 29000}
{"episode_reward": 178.4448546434278, "episode": 30.0, "batch_reward": 0.09651533412560821, "critic_loss": 0.2401622589826584, "actor_loss": -19.284606838226317, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.04689621925354, "step": 30000}
{"episode_reward": 120.85439724062635, "episode": 31.0, "batch_reward": 0.0969484022334218, "critic_loss": 0.2292076970115304, "actor_loss": -19.291830513000487, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.06045937538147, "step": 31000}
{"episode_reward": 92.59931929329962, "episode": 32.0, "batch_reward": 0.09910989334434271, "critic_loss": 0.26011562485992906, "actor_loss": -19.17989747238159, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.51954174041748, "step": 32000}
{"episode_reward": 220.6606261830068, "episode": 33.0, "batch_reward": 0.10141036573797464, "critic_loss": 0.25200561367720364, "actor_loss": -19.443463697433472, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.3228280544281, "step": 33000}
{"episode_reward": 124.1002581580517, "episode": 34.0, "batch_reward": 0.10288490887731314, "critic_loss": 0.24293371195346117, "actor_loss": -19.443818418502808, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.610870838165283, "step": 34000}
{"episode_reward": 241.09079414674017, "episode": 35.0, "batch_reward": 0.10646569732576609, "critic_loss": 0.2764027581810951, "actor_loss": -19.585117179870604, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.24162459373474, "step": 35000}
{"episode_reward": 165.59578401569465, "episode": 36.0, "batch_reward": 0.10950448478013278, "critic_loss": 0.26378591629117726, "actor_loss": -19.65805797958374, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.668919563293457, "step": 36000}
{"episode_reward": 312.4623232938048, "episode": 37.0, "batch_reward": 0.11137395077943801, "critic_loss": 0.2631789925396442, "actor_loss": -19.772632011413574, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.494856595993042, "step": 37000}
{"episode_reward": 38.16547820017041, "episode": 38.0, "batch_reward": 0.11045558797568082, "critic_loss": 0.26643554035574196, "actor_loss": -19.09791052055359, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.90029525756836, "step": 38000}
{"episode_reward": 94.31845970993012, "episode": 39.0, "batch_reward": 0.10979924813657999, "critic_loss": 0.2613420513868332, "actor_loss": -19.134668600082396, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.26025080680847, "step": 39000}
{"episode_reward": 48.084937885825276, "episode": 40.0, "batch_reward": 0.1080218690559268, "critic_loss": 0.2700586274638772, "actor_loss": -18.979209091186522, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.91415524482727, "step": 40000}
{"episode_reward": 95.30726477145494, "episode": 41.0, "batch_reward": 0.11047903744876385, "critic_loss": 0.25728705335408447, "actor_loss": -19.17959356880188, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.0432710647583, "step": 41000}
{"episode_reward": 335.9060426531048, "episode": 42.0, "batch_reward": 0.11474571318179369, "critic_loss": 0.29468284187465904, "actor_loss": -19.410316680908203, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.013404369354248, "step": 42000}
{"episode_reward": 229.97079772980328, "episode": 43.0, "batch_reward": 0.1173408090993762, "critic_loss": 0.3320168428197503, "actor_loss": -19.393205709457398, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.02600073814392, "step": 43000}
{"episode_reward": 276.6075198342601, "episode": 44.0, "batch_reward": 0.12178255119174719, "critic_loss": 0.3204984635934234, "actor_loss": -19.822028038024904, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.30925440788269, "step": 44000}
{"episode_reward": 198.07591093936455, "episode": 45.0, "batch_reward": 0.12374683781713247, "critic_loss": 0.28983459442853926, "actor_loss": -19.741188255310057, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.103039741516113, "step": 45000}
{"episode_reward": 371.45294110359714, "episode": 46.0, "batch_reward": 0.12816541983932256, "critic_loss": 0.2801035921946168, "actor_loss": -20.065377128601074, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.510409832000732, "step": 46000}
{"episode_reward": 182.70883873059535, "episode": 47.0, "batch_reward": 0.13050045217573641, "critic_loss": 0.28670058024674655, "actor_loss": -20.315561420440673, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.504618167877197, "step": 47000}
{"episode_reward": 371.4544281790704, "episode": 48.0, "batch_reward": 0.13481970931589604, "critic_loss": 0.2830833011344075, "actor_loss": -20.101380977630615, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.998844623565674, "step": 48000}
{"episode_reward": 109.70389659723907, "episode": 49.0, "batch_reward": 0.13584061028808356, "critic_loss": 0.2720188744813204, "actor_loss": -20.143838535308838, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.692675590515137, "step": 49000}
{"episode_reward": 306.871848088235, "episode": 50.0, "batch_reward": 0.1379103023186326, "critic_loss": 0.28642991446703675, "actor_loss": -20.460909496307373, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.115660905838013, "step": 50000}
{"episode_reward": 191.51439460169544, "episode": 51.0, "batch_reward": 0.1404096730053425, "critic_loss": 0.2815949423238635, "actor_loss": -20.352705558776854, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.09444880485535, "step": 51000}
{"episode_reward": 277.6379017144302, "episode": 52.0, "batch_reward": 0.1404921472594142, "critic_loss": 0.28225677163898943, "actor_loss": -20.503553703308107, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.475650310516357, "step": 52000}
{"episode_reward": 92.98726278933961, "episode": 53.0, "batch_reward": 0.14096295213699342, "critic_loss": 0.28161162562668324, "actor_loss": -20.2834893989563, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.40694832801819, "step": 53000}
{"episode_reward": 246.882420812441, "episode": 54.0, "batch_reward": 0.14422739666700363, "critic_loss": 0.2732129492610693, "actor_loss": -20.639877059936524, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.6730637550354, "step": 54000}
{"episode_reward": 369.28905192242615, "episode": 55.0, "batch_reward": 0.14739369370788336, "critic_loss": 0.2625791487172246, "actor_loss": -20.86679107284546, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.197765350341797, "step": 55000}
{"episode_reward": 211.9684234964021, "episode": 56.0, "batch_reward": 0.14687671038508415, "critic_loss": 0.24542115946859122, "actor_loss": -20.522604831695556, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.31039810180664, "step": 56000}
{"episode_reward": 72.24419966326485, "episode": 57.0, "batch_reward": 0.14620668751746416, "critic_loss": 0.25428392638266084, "actor_loss": -20.39104920196533, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.42969560623169, "step": 57000}
{"episode_reward": 112.23275688922375, "episode": 58.0, "batch_reward": 0.14669777831435205, "critic_loss": 0.27679813399910924, "actor_loss": -20.228804378509523, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.484272956848145, "step": 58000}
{"episode_reward": 368.2117745157876, "episode": 59.0, "batch_reward": 0.14965569701045753, "critic_loss": 0.26431219548732043, "actor_loss": -20.533027114868165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.867659330368042, "step": 59000}
{"episode_reward": 295.2476491950459, "episode": 60.0, "batch_reward": 0.1526422747671604, "critic_loss": 0.26682330324500797, "actor_loss": -20.919690368652343, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.423624277114868, "step": 60000}
{"episode_reward": 356.61253380764316, "episode": 61.0, "batch_reward": 0.15548338971287012, "critic_loss": 0.27342802884429696, "actor_loss": -21.050275840759276, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.61332035064697, "step": 61000}
{"episode_reward": 368.2639080480972, "episode": 62.0, "batch_reward": 0.15989539769291877, "critic_loss": 0.25861796759068967, "actor_loss": -21.271941318511963, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.9965980052948, "step": 62000}
{"episode_reward": 399.9543864384516, "episode": 63.0, "batch_reward": 0.16325305919349192, "critic_loss": 0.24381192073225974, "actor_loss": -21.553120441436768, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.981297254562378, "step": 63000}
{"episode_reward": 368.47906908394987, "episode": 64.0, "batch_reward": 0.1678076581209898, "critic_loss": 0.23419534199684858, "actor_loss": -22.03811024475098, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.858686685562134, "step": 64000}
{"episode_reward": 405.2281194449224, "episode": 65.0, "batch_reward": 0.17105373034626245, "critic_loss": 0.23309720338135959, "actor_loss": -21.94835666656494, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.93346333503723, "step": 65000}
{"episode_reward": 393.122830931391, "episode": 66.0, "batch_reward": 0.1739918237924576, "critic_loss": 0.2272386501058936, "actor_loss": -22.48888648223877, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.154750108718872, "step": 66000}
{"episode_reward": 387.6885008678171, "episode": 67.0, "batch_reward": 0.17735561417043208, "critic_loss": 0.24952726259082555, "actor_loss": -22.57774197769165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.897865056991577, "step": 67000}
{"episode_reward": 414.4758668864496, "episode": 68.0, "batch_reward": 0.1820043608546257, "critic_loss": 0.22951103403419257, "actor_loss": -22.892050651550292, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.791727304458618, "step": 68000}
{"episode_reward": 382.2392481712565, "episode": 69.0, "batch_reward": 0.18519464436173438, "critic_loss": 0.2544128988087177, "actor_loss": -23.13843991088867, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.707472324371338, "step": 69000}
{"episode_reward": 384.99908901414295, "episode": 70.0, "batch_reward": 0.1873194140791893, "critic_loss": 0.24679291896522046, "actor_loss": -23.18204837036133, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.179721355438232, "step": 70000}
{"episode_reward": 381.1563121815323, "episode": 71.0, "batch_reward": 0.18815287232398986, "critic_loss": 0.235203691765666, "actor_loss": -23.246606426239012, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.768070459365845, "step": 71000}
{"episode_reward": 401.3208247773782, "episode": 72.0, "batch_reward": 0.1923734444230795, "critic_loss": 0.2445928819924593, "actor_loss": -23.52777843475342, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.599172592163086, "step": 72000}
{"episode_reward": 413.96314141068336, "episode": 73.0, "batch_reward": 0.19470532135665417, "critic_loss": 0.24588567093014718, "actor_loss": -23.882232807159422, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.026036500930786, "step": 73000}
{"episode_reward": 431.07882440247164, "episode": 74.0, "batch_reward": 0.19914411808550359, "critic_loss": 0.2500236345976591, "actor_loss": -23.96913967514038, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.218258380889893, "step": 74000}
{"episode_reward": 426.3590654127187, "episode": 75.0, "batch_reward": 0.2018581853955984, "critic_loss": 0.24880349481850864, "actor_loss": -24.33207260131836, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.39707326889038, "step": 75000}
{"episode_reward": 278.3396309368597, "episode": 76.0, "batch_reward": 0.2034250567406416, "critic_loss": 0.27512611546367405, "actor_loss": -24.575614223480226, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.932936191558838, "step": 76000}
{"episode_reward": 438.0916613793901, "episode": 77.0, "batch_reward": 0.20594453771412372, "critic_loss": 0.26114056465774776, "actor_loss": -24.64576659011841, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.699913263320923, "step": 77000}
{"episode_reward": 293.957246153988, "episode": 78.0, "batch_reward": 0.20672763787209988, "critic_loss": 0.26507733834534886, "actor_loss": -24.493182720184326, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.759540796279907, "step": 78000}
{"episode_reward": 439.6507649438212, "episode": 79.0, "batch_reward": 0.2098601192831993, "critic_loss": 0.24987605986744166, "actor_loss": -24.82509930419922, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.871396780014038, "step": 79000}
{"episode_reward": 400.44529260450406, "episode": 80.0, "batch_reward": 0.21227083979547023, "critic_loss": 0.25613484816253185, "actor_loss": -25.24047729873657, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.38520336151123, "step": 80000}
{"episode_reward": 439.0552048661374, "episode": 81.0, "batch_reward": 0.21647767630219458, "critic_loss": 0.2664223395213485, "actor_loss": -25.504702194213866, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.75075697898865, "step": 81000}
{"episode_reward": 459.9051830186976, "episode": 82.0, "batch_reward": 0.21857435770332814, "critic_loss": 0.2527370260283351, "actor_loss": -25.68536328125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.716725826263428, "step": 82000}
{"episode_reward": 463.63260295295186, "episode": 83.0, "batch_reward": 0.2210979134440422, "critic_loss": 0.2633917599469423, "actor_loss": -26.20450192260742, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.876505613327026, "step": 83000}
{"episode_reward": 442.95316539103095, "episode": 84.0, "batch_reward": 0.22456996390223502, "critic_loss": 0.2986799112632871, "actor_loss": -26.241551216125487, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.807751655578613, "step": 84000}
{"episode_reward": 448.3950733582781, "episode": 85.0, "batch_reward": 0.22639921069145202, "critic_loss": 0.26926451697945597, "actor_loss": -26.479934993743896, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.71106743812561, "step": 85000}
{"episode_reward": 422.50672152781414, "episode": 86.0, "batch_reward": 0.23068387810885907, "critic_loss": 0.2733672658652067, "actor_loss": -27.099493293762208, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.903400659561157, "step": 86000}
{"episode_reward": 448.5357580181767, "episode": 87.0, "batch_reward": 0.2322875536829233, "critic_loss": 0.2645050356984138, "actor_loss": -26.991104179382326, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.209465503692627, "step": 87000}
{"episode_reward": 445.54881623482174, "episode": 88.0, "batch_reward": 0.23463246412575245, "critic_loss": 0.25306063117086885, "actor_loss": -27.47887454223633, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.716304063796997, "step": 88000}
{"episode_reward": 444.8465614075793, "episode": 89.0, "batch_reward": 0.236392967030406, "critic_loss": 0.28151605793088674, "actor_loss": -27.14404331588745, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.26787781715393, "step": 89000}
{"episode_reward": 480.66731346691427, "episode": 90.0, "batch_reward": 0.2389773487150669, "critic_loss": 0.24827874123305083, "actor_loss": -27.19619136428833, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.050006866455078, "step": 90000}
{"episode_reward": 463.3003533667325, "episode": 91.0, "batch_reward": 0.24234140345454216, "critic_loss": 0.25668115175515416, "actor_loss": -27.734205043792723, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.50809335708618, "step": 91000}
{"episode_reward": 469.2490372019453, "episode": 92.0, "batch_reward": 0.24440761935710906, "critic_loss": 0.2624462125226855, "actor_loss": -28.076437297821045, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.121062755584717, "step": 92000}
{"episode_reward": 500.90074821897235, "episode": 93.0, "batch_reward": 0.2462105814963579, "critic_loss": 0.2553765490651131, "actor_loss": -28.077053562164306, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.05732798576355, "step": 93000}
{"episode_reward": 421.59324956359285, "episode": 94.0, "batch_reward": 0.2493961965739727, "critic_loss": 0.2534674270749092, "actor_loss": -28.56356851196289, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.193344116210938, "step": 94000}
{"episode_reward": 461.8424314505013, "episode": 95.0, "batch_reward": 0.2519247754365206, "critic_loss": 0.24983571884036065, "actor_loss": -28.388874572753906, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.686291456222534, "step": 95000}
{"episode_reward": 450.99998129244756, "episode": 96.0, "batch_reward": 0.25448649092018605, "critic_loss": 0.23885935697704552, "actor_loss": -29.298625923156738, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.734862089157104, "step": 96000}
{"episode_reward": 494.2294302364095, "episode": 97.0, "batch_reward": 0.2554545673727989, "critic_loss": 0.2614814374893904, "actor_loss": -29.126407039642334, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.832603931427002, "step": 97000}
{"episode_reward": 449.89783048755305, "episode": 98.0, "batch_reward": 0.2576923952996731, "critic_loss": 0.23448045494407416, "actor_loss": -28.930281162261963, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.763744831085205, "step": 98000}
{"episode_reward": 494.95551880400257, "episode": 99.0, "batch_reward": 0.26041272160410883, "critic_loss": 0.23147572780400513, "actor_loss": -29.841594944000246, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.827717781066895, "step": 99000}
{"episode_reward": 473.2464225381142, "episode": 100.0, "batch_reward": 0.2613461070805788, "critic_loss": 0.24958627048134804, "actor_loss": -29.775088684082032, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.30972671508789, "step": 100000}
{"episode_reward": 461.47502415433735, "episode": 101.0, "batch_reward": 0.26445010001957414, "critic_loss": 0.2613421143963933, "actor_loss": -30.295349323272706, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.33902025222778, "step": 101000}
{"episode_reward": 485.4832630316441, "episode": 102.0, "batch_reward": 0.2662172293961048, "critic_loss": 0.2579866278916597, "actor_loss": -30.010136070251466, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.014450788497925, "step": 102000}
{"episode_reward": 496.6633880083017, "episode": 103.0, "batch_reward": 0.2689706806093454, "critic_loss": 0.24227429397404193, "actor_loss": -30.094616619110106, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.27223014831543, "step": 103000}
{"episode_reward": 481.71330998652934, "episode": 104.0, "batch_reward": 0.2698826378583908, "critic_loss": 0.24458193120360375, "actor_loss": -30.49643885421753, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.840580940246582, "step": 104000}
{"episode_reward": 493.75670263715443, "episode": 105.0, "batch_reward": 0.273252422824502, "critic_loss": 0.24423583322763442, "actor_loss": -30.810466598510743, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.32633924484253, "step": 105000}
{"episode_reward": 469.21148740675056, "episode": 106.0, "batch_reward": 0.27405214913189413, "critic_loss": 0.25527988699823617, "actor_loss": -31.022210273742676, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.900105714797974, "step": 106000}
{"episode_reward": 492.0639435291365, "episode": 107.0, "batch_reward": 0.2766562117934227, "critic_loss": 0.24392238003760577, "actor_loss": -31.150873607635496, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.579551458358765, "step": 107000}
{"episode_reward": 384.1222686329709, "episode": 108.0, "batch_reward": 0.27676980568468573, "critic_loss": 0.2598398316949606, "actor_loss": -30.91315926361084, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.584794282913208, "step": 108000}
{"episode_reward": 482.5256045424046, "episode": 109.0, "batch_reward": 0.2795563898533583, "critic_loss": 0.26714362840354444, "actor_loss": -31.210584255218507, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.132063627243042, "step": 109000}
{"episode_reward": 456.2183726401803, "episode": 110.0, "batch_reward": 0.281146796643734, "critic_loss": 0.2589336510077119, "actor_loss": -31.541547954559327, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.93928074836731, "step": 110000}
{"episode_reward": 439.33382191772324, "episode": 111.0, "batch_reward": 0.28261302918195724, "critic_loss": 0.256084917627275, "actor_loss": -31.34591868209839, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.996384382247925, "step": 111000}
{"episode_reward": 483.43940416750274, "episode": 112.0, "batch_reward": 0.28479275314509866, "critic_loss": 0.2681391289383173, "actor_loss": -32.12256606292725, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.119378566741943, "step": 112000}
{"episode_reward": 495.2333853559666, "episode": 113.0, "batch_reward": 0.28630178517103194, "critic_loss": 0.2574262748360634, "actor_loss": -32.041912956237795, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.951274871826172, "step": 113000}
{"episode_reward": 486.2918037039847, "episode": 114.0, "batch_reward": 0.2882008502334356, "critic_loss": 0.27502131410688163, "actor_loss": -32.37050113677979, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.11828637123108, "step": 114000}
{"episode_reward": 501.96579064480636, "episode": 115.0, "batch_reward": 0.28909350122511385, "critic_loss": 0.2570586854740977, "actor_loss": -32.37529501724243, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.146767377853394, "step": 115000}
{"episode_reward": 493.53270239180716, "episode": 116.0, "batch_reward": 0.2923936587572098, "critic_loss": 0.26184200279414654, "actor_loss": -32.61595352935791, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.101909399032593, "step": 116000}
{"episode_reward": 479.6116618806993, "episode": 117.0, "batch_reward": 0.2934487461894751, "critic_loss": 0.24993972098082304, "actor_loss": -32.64181233596802, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.500961780548096, "step": 117000}
{"episode_reward": 501.4984125093484, "episode": 118.0, "batch_reward": 0.2955083187222481, "critic_loss": 0.24540336108207703, "actor_loss": -33.14336725997925, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.306356191635132, "step": 118000}
{"episode_reward": 519.2521046944237, "episode": 119.0, "batch_reward": 0.2966355376839638, "critic_loss": 0.24260137694329023, "actor_loss": -32.99427484512329, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.80255627632141, "step": 119000}
{"episode_reward": 150.34677354750676, "episode": 120.0, "batch_reward": 0.2949562273174524, "critic_loss": 0.2640725995674729, "actor_loss": -32.8053099899292, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.15902876853943, "step": 120000}
{"episode_reward": 484.19224301985435, "episode": 121.0, "batch_reward": 0.29570518955588343, "critic_loss": 0.27154473700374365, "actor_loss": -33.11541343688965, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.853142976760864, "step": 121000}
{"episode_reward": 148.67315730024671, "episode": 122.0, "batch_reward": 0.29756666070222854, "critic_loss": 0.3018349278792739, "actor_loss": -33.04986321258545, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.351852655410767, "step": 122000}
{"episode_reward": 482.34839342230714, "episode": 123.0, "batch_reward": 0.29736225126683713, "critic_loss": 0.2982016896083951, "actor_loss": -33.28321943664551, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.084008932113647, "step": 123000}
{"episode_reward": 296.5546876349018, "episode": 124.0, "batch_reward": 0.297159380659461, "critic_loss": 0.30706940744817257, "actor_loss": -33.43383583068848, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.23761558532715, "step": 124000}
{"episode_reward": 487.06410858865524, "episode": 125.0, "batch_reward": 0.29938233105838297, "critic_loss": 0.28958913274109366, "actor_loss": -33.64918074798584, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.128973484039307, "step": 125000}
{"episode_reward": 511.9832240270515, "episode": 126.0, "batch_reward": 0.30102203983068465, "critic_loss": 0.2939440416768193, "actor_loss": -33.46144052886963, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.134397506713867, "step": 126000}
{"episode_reward": 512.9506611752039, "episode": 127.0, "batch_reward": 0.30173505446314813, "critic_loss": 0.28315124758332966, "actor_loss": -33.985887313842774, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.821276664733887, "step": 127000}
{"episode_reward": 461.3945558855394, "episode": 128.0, "batch_reward": 0.30307562740147115, "critic_loss": 0.2776816325038671, "actor_loss": -34.07197219467163, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.87869644165039, "step": 128000}
{"episode_reward": 517.9150306659047, "episode": 129.0, "batch_reward": 0.30423234175145625, "critic_loss": 0.27680106946080923, "actor_loss": -34.0632008934021, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.34824013710022, "step": 129000}
{"episode_reward": 211.3055932558998, "episode": 130.0, "batch_reward": 0.30532663968205453, "critic_loss": 0.2890649882555008, "actor_loss": -34.248049949645996, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.725365161895752, "step": 130000}
{"episode_reward": 510.36954563321484, "episode": 131.0, "batch_reward": 0.3061439260840416, "critic_loss": 0.28443017148971556, "actor_loss": -34.387664897918704, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.12294125556946, "step": 131000}
{"episode_reward": 521.0879665527295, "episode": 132.0, "batch_reward": 0.30702948912978173, "critic_loss": 0.2999789485707879, "actor_loss": -34.457175731658936, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.902236938476562, "step": 132000}
{"episode_reward": 398.21170721837984, "episode": 133.0, "batch_reward": 0.3096753860414028, "critic_loss": 0.2813892442807555, "actor_loss": -34.45174019622803, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.90616250038147, "step": 133000}
{"episode_reward": 521.4804994389982, "episode": 134.0, "batch_reward": 0.3102639386355877, "critic_loss": 0.27369772086292504, "actor_loss": -34.662583675384525, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.48754048347473, "step": 134000}
{"episode_reward": 516.8943776155429, "episode": 135.0, "batch_reward": 0.31198474431037904, "critic_loss": 0.2833517169505358, "actor_loss": -35.226778507232666, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.243412971496582, "step": 135000}
{"episode_reward": 515.3857945545734, "episode": 136.0, "batch_reward": 0.31261252707242965, "critic_loss": 0.31940399154275656, "actor_loss": -34.80860010528564, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.050880193710327, "step": 136000}
{"episode_reward": 528.5876821375455, "episode": 137.0, "batch_reward": 0.3141669454872608, "critic_loss": 0.28436171245574954, "actor_loss": -35.212445022583005, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.839492321014404, "step": 137000}
{"episode_reward": 514.3279587461498, "episode": 138.0, "batch_reward": 0.31760920894145966, "critic_loss": 0.28552532333880665, "actor_loss": -35.62501382446289, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.58307409286499, "step": 138000}
{"episode_reward": 527.7836963023001, "episode": 139.0, "batch_reward": 0.31859863263368604, "critic_loss": 0.2634170169606805, "actor_loss": -35.19467730331421, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.51694679260254, "step": 139000}
{"episode_reward": 526.460739767362, "episode": 140.0, "batch_reward": 0.3201070298552513, "critic_loss": 0.2735057357698679, "actor_loss": -35.71328928375244, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.85746955871582, "step": 140000}
{"episode_reward": 519.2296857385905, "episode": 141.0, "batch_reward": 0.3204269427061081, "critic_loss": 0.2914906338229775, "actor_loss": -35.903748462677, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.938114643096924, "step": 141000}
{"episode_reward": 511.85423857119576, "episode": 142.0, "batch_reward": 0.3209301796257496, "critic_loss": 0.2762860825881362, "actor_loss": -35.67195860290527, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.67552351951599, "step": 142000}
{"episode_reward": 498.48288685732035, "episode": 143.0, "batch_reward": 0.32310855585336684, "critic_loss": 0.29436076249927284, "actor_loss": -35.81894232559204, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.082226276397705, "step": 143000}
{"episode_reward": 516.6526899982149, "episode": 144.0, "batch_reward": 0.32522652205824853, "critic_loss": 0.2901498988121748, "actor_loss": -36.02489199829102, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.906484365463257, "step": 144000}
{"episode_reward": 473.46279658635103, "episode": 145.0, "batch_reward": 0.32562276962399483, "critic_loss": 0.28978393656760454, "actor_loss": -36.26866062545776, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.2766535282135, "step": 145000}
{"episode_reward": 465.63595804160906, "episode": 146.0, "batch_reward": 0.3261152298748493, "critic_loss": 0.28124528561532497, "actor_loss": -36.38596348953247, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.18926453590393, "step": 146000}
{"episode_reward": 527.9156902522993, "episode": 147.0, "batch_reward": 0.3279356977939606, "critic_loss": 0.28637232427299025, "actor_loss": -36.48927095413208, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.245353937149048, "step": 147000}
{"episode_reward": 527.5893829017539, "episode": 148.0, "batch_reward": 0.3304986192882061, "critic_loss": 0.2793636448830366, "actor_loss": -36.701320987701415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.536126375198364, "step": 148000}
{"episode_reward": 538.0108455013882, "episode": 149.0, "batch_reward": 0.3306755835711956, "critic_loss": 0.30360301131755113, "actor_loss": -36.598786655426025, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.650432109832764, "step": 149000}
{"episode_reward": 508.75735217388257, "episode": 150.0, "batch_reward": 0.33245311671495437, "critic_loss": 0.27687402798980476, "actor_loss": -36.926635177612305, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
