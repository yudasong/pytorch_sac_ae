{"episode_reward": 0.0, "episode": 1.0, "duration": 19.585747718811035, "step": 1000}
{"episode_reward": 4.231880753996205, "episode": 2.0, "duration": 1.5663719177246094, "step": 2000}
{"episode_reward": 395.1450543749875, "episode": 3.0, "batch_reward": 0.18884612697885608, "critic_loss": 0.05047051076631013, "actor_loss": -32.98761620429479, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 66.69754600524902, "step": 3000}
{"episode_reward": 30.574488582528005, "episode": 4.0, "batch_reward": 0.1309342644661665, "critic_loss": 0.04427140211500227, "actor_loss": -28.252163406848908, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.81218457221985, "step": 4000}
{"episode_reward": 53.07780788977069, "episode": 5.0, "batch_reward": 0.11310531707853079, "critic_loss": 0.061717214541509746, "actor_loss": -25.505971730709074, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.85752558708191, "step": 5000}
{"episode_reward": 27.93897039189772, "episode": 6.0, "batch_reward": 0.09582217372208833, "critic_loss": 0.042536630475893615, "actor_loss": -23.230964275836946, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.777709245681763, "step": 6000}
{"episode_reward": 17.26282956215509, "episode": 7.0, "batch_reward": 0.08627016650512814, "critic_loss": 0.04207664468884468, "actor_loss": -23.262853999614716, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.789830446243286, "step": 7000}
{"episode_reward": 53.95617634211761, "episode": 8.0, "batch_reward": 0.08063822635263204, "critic_loss": 0.03734337582625449, "actor_loss": -22.570043713569643, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.911341905593872, "step": 8000}
{"episode_reward": 25.826318389914267, "episode": 9.0, "batch_reward": 0.07534513824805618, "critic_loss": 0.05039592007920146, "actor_loss": -20.784628618717193, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.771360397338867, "step": 9000}
{"episode_reward": 61.43685031120215, "episode": 10.0, "batch_reward": 0.07622210638597608, "critic_loss": 0.056703469544649124, "actor_loss": -20.761449849128724, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.493451833724976, "step": 10000}
{"episode_reward": 73.14291810602506, "episode": 11.0, "batch_reward": 0.0744903207756579, "critic_loss": 0.05886495139636099, "actor_loss": -20.406318469047548, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.94771146774292, "step": 11000}
{"episode_reward": 76.67229920352041, "episode": 12.0, "batch_reward": 0.07479573391377926, "critic_loss": 0.07218298294767737, "actor_loss": -21.019869087696076, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.105215311050415, "step": 12000}
{"episode_reward": 90.6527252982109, "episode": 13.0, "batch_reward": 0.07705849205330015, "critic_loss": 0.0820532107912004, "actor_loss": -21.409921503067018, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.462143182754517, "step": 13000}
{"episode_reward": 97.68737811091937, "episode": 14.0, "batch_reward": 0.07934802633523941, "critic_loss": 0.0937908654510975, "actor_loss": -22.032502937793733, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.001271724700928, "step": 14000}
{"episode_reward": 141.54204820746457, "episode": 15.0, "batch_reward": 0.08307103834673762, "critic_loss": 0.10060948266088962, "actor_loss": -20.463991630077363, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.905674695968628, "step": 15000}
{"episode_reward": 68.01336045098628, "episode": 16.0, "batch_reward": 0.08384997196123004, "critic_loss": 0.11053524207696319, "actor_loss": -22.071685553073884, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.96583843231201, "step": 16000}
{"episode_reward": 165.09601575206514, "episode": 17.0, "batch_reward": 0.08722315664961934, "critic_loss": 0.12743491676449775, "actor_loss": -21.875894312381746, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.452765941619873, "step": 17000}
{"episode_reward": 117.83078102884232, "episode": 18.0, "batch_reward": 0.09059754022210836, "critic_loss": 0.13939704510569573, "actor_loss": -22.607439130306243, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.14901089668274, "step": 18000}
{"episode_reward": 152.32347709171754, "episode": 19.0, "batch_reward": 0.09614764793217181, "critic_loss": 0.1745779983922839, "actor_loss": -23.432517202973365, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.38442325592041, "step": 19000}
{"episode_reward": 201.22800542533983, "episode": 20.0, "batch_reward": 0.10008061372488737, "critic_loss": 0.19650804526358842, "actor_loss": -22.132345614537595, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.414969205856323, "step": 20000}
{"episode_reward": 124.17225087027585, "episode": 21.0, "batch_reward": 0.10029221457242966, "critic_loss": 0.2371886399537325, "actor_loss": -22.158861078172922, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.80553340911865, "step": 21000}
{"episode_reward": 133.40814935080678, "episode": 22.0, "batch_reward": 0.10312831231951713, "critic_loss": 0.2765382101237774, "actor_loss": -21.96615617544949, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.81240487098694, "step": 22000}
{"episode_reward": 151.208025376879, "episode": 23.0, "batch_reward": 0.10234959309548139, "critic_loss": 0.29271887622773646, "actor_loss": -22.16477925248444, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.499740600585938, "step": 23000}
{"episode_reward": 53.478936891079925, "episode": 24.0, "batch_reward": 0.10165142653137446, "critic_loss": 0.2806165226697922, "actor_loss": -21.69664198859036, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.612247943878174, "step": 24000}
{"episode_reward": 88.275981131848, "episode": 25.0, "batch_reward": 0.1012523390725255, "critic_loss": 0.28139522793889044, "actor_loss": -22.512466564416886, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.32175636291504, "step": 25000}
{"episode_reward": 97.79725483972868, "episode": 26.0, "batch_reward": 0.10065428753942252, "critic_loss": 0.2652369031533599, "actor_loss": -21.462990068912507, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.7531259059906, "step": 26000}
{"episode_reward": 73.24389349305748, "episode": 27.0, "batch_reward": 0.100393824711442, "critic_loss": 0.2556622530892491, "actor_loss": -21.3033114413023, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.960906744003296, "step": 27000}
{"episode_reward": 96.70007071398553, "episode": 28.0, "batch_reward": 0.09874343128502369, "critic_loss": 0.21820383301377297, "actor_loss": -21.463350771188736, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.982327938079834, "step": 28000}
{"episode_reward": 88.66672434369318, "episode": 29.0, "batch_reward": 0.09954040601849556, "critic_loss": 0.22842274268716573, "actor_loss": -20.47456478023529, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.706135988235474, "step": 29000}
{"episode_reward": 127.30494804201422, "episode": 30.0, "batch_reward": 0.10032541545853019, "critic_loss": 0.23239838382601738, "actor_loss": -20.291880071163177, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.696062564849854, "step": 30000}
{"episode_reward": 71.70246758556797, "episode": 31.0, "batch_reward": 0.10117346856743098, "critic_loss": 0.20182645678520203, "actor_loss": -21.43030135253072, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.998361110687256, "step": 31000}
{"episode_reward": 278.58303432178815, "episode": 32.0, "batch_reward": 0.10684875271469355, "critic_loss": 0.20905733256042003, "actor_loss": -21.52873500418663, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.022182941436768, "step": 32000}
{"episode_reward": 247.00222821006835, "episode": 33.0, "batch_reward": 0.11151930895447731, "critic_loss": 0.17828917606920003, "actor_loss": -22.033012166500093, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.738512754440308, "step": 33000}
{"episode_reward": 265.5303976514498, "episode": 34.0, "batch_reward": 0.11506337750703097, "critic_loss": 0.19550980177521707, "actor_loss": -22.43861511731148, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.03097105026245, "step": 34000}
{"episode_reward": 247.86716163075369, "episode": 35.0, "batch_reward": 0.12043926306068897, "critic_loss": 0.18407106840610504, "actor_loss": -22.44452429676056, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.89901375770569, "step": 35000}
{"episode_reward": 280.8975204436451, "episode": 36.0, "batch_reward": 0.12462192770093679, "critic_loss": 0.17700631143152715, "actor_loss": -24.173492458343507, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.677561044692993, "step": 36000}
{"episode_reward": 279.72253714824006, "episode": 37.0, "batch_reward": 0.12940741515159607, "critic_loss": 0.16924915248155595, "actor_loss": -23.924459637165068, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.943358421325684, "step": 37000}
{"episode_reward": 309.31151403730973, "episode": 38.0, "batch_reward": 0.13340679425746202, "critic_loss": 0.17054389356821775, "actor_loss": -23.55432649421692, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.593270540237427, "step": 38000}
{"episode_reward": 279.2457260711674, "episode": 39.0, "batch_reward": 0.13627430305629967, "critic_loss": 0.1723572988063097, "actor_loss": -24.830147090435027, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.096927404403687, "step": 39000}
{"episode_reward": 123.05804827372503, "episode": 40.0, "batch_reward": 0.1369615390598774, "critic_loss": 0.19399866396933793, "actor_loss": -24.737759625911714, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.223001718521118, "step": 40000}
{"episode_reward": 242.2454250688118, "episode": 41.0, "batch_reward": 0.13850229197740554, "critic_loss": 0.19080656216293573, "actor_loss": -25.38576187181473, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.04118251800537, "step": 41000}
{"episode_reward": 150.92701202972472, "episode": 42.0, "batch_reward": 0.14044650632143021, "critic_loss": 0.1827209397405386, "actor_loss": -24.022510995864867, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.034752368927002, "step": 42000}
{"episode_reward": 310.2569125656561, "episode": 43.0, "batch_reward": 0.14474163311719895, "critic_loss": 0.20536049050092697, "actor_loss": -25.26693805217743, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.80779194831848, "step": 43000}
{"episode_reward": 317.3921615465164, "episode": 44.0, "batch_reward": 0.14773920548707248, "critic_loss": 0.2251760376393795, "actor_loss": -25.473752833366394, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.494630575180054, "step": 44000}
{"episode_reward": 274.4034990314479, "episode": 45.0, "batch_reward": 0.1485604906976223, "critic_loss": 0.209476465664804, "actor_loss": -25.302142218589783, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.24980926513672, "step": 45000}
{"episode_reward": 89.7637543365813, "episode": 46.0, "batch_reward": 0.14892315973341466, "critic_loss": 0.22563183883577584, "actor_loss": -25.067878182411192, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.468475341796875, "step": 46000}
{"episode_reward": 285.50624530876723, "episode": 47.0, "batch_reward": 0.15201819279789924, "critic_loss": 0.22930148270726203, "actor_loss": -26.004420449256898, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.918742418289185, "step": 47000}
{"episode_reward": 203.4745189345886, "episode": 48.0, "batch_reward": 0.15324522015452385, "critic_loss": 0.2549696050956845, "actor_loss": -25.901479253768922, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.481836318969727, "step": 48000}
{"episode_reward": 188.22710746618057, "episode": 49.0, "batch_reward": 0.15343199387937784, "critic_loss": 0.2659667626991868, "actor_loss": -26.013262141227724, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.601442575454712, "step": 49000}
{"episode_reward": 121.85154530807903, "episode": 50.0, "batch_reward": 0.15237563037872315, "critic_loss": 0.2738578953593969, "actor_loss": -25.200100038528443, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.334734439849854, "step": 50000}
{"episode_reward": 110.23061009236639, "episode": 51.0, "batch_reward": 0.1534851192831993, "critic_loss": 0.26358730988949536, "actor_loss": -25.259373287200926, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.74210715293884, "step": 51000}
{"episode_reward": 333.8036803878089, "episode": 52.0, "batch_reward": 0.15605824982374908, "critic_loss": 0.28338790534436703, "actor_loss": -26.172440907478332, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.843884468078613, "step": 52000}
{"episode_reward": 262.977975769519, "episode": 53.0, "batch_reward": 0.15648060240596534, "critic_loss": 0.2506131597235799, "actor_loss": -24.959825083732603, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.488712072372437, "step": 53000}
{"episode_reward": 82.60188825269013, "episode": 54.0, "batch_reward": 0.15774921884387733, "critic_loss": 0.24424484560638665, "actor_loss": -26.436858772277834, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.441746473312378, "step": 54000}
{"episode_reward": 335.32321736888383, "episode": 55.0, "batch_reward": 0.15959554517269134, "critic_loss": 0.24318108156323434, "actor_loss": -26.22600710296631, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.103092432022095, "step": 55000}
{"episode_reward": 331.92951433962145, "episode": 56.0, "batch_reward": 0.16258822935074568, "critic_loss": 0.2361092608049512, "actor_loss": -25.573464632987974, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.05898427963257, "step": 56000}
{"episode_reward": 200.4495031796523, "episode": 57.0, "batch_reward": 0.1648232810497284, "critic_loss": 0.23668073882907628, "actor_loss": -26.703360204696654, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.640167713165283, "step": 57000}
{"episode_reward": 356.9689847975152, "episode": 58.0, "batch_reward": 0.16711657628417015, "critic_loss": 0.23110100766271352, "actor_loss": -26.44179619503021, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.546643495559692, "step": 58000}
{"episode_reward": 331.11800108818977, "episode": 59.0, "batch_reward": 0.17038090842962264, "critic_loss": 0.2264759366363287, "actor_loss": -26.773428134918213, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.38141393661499, "step": 59000}
{"episode_reward": 329.2349008903062, "episode": 60.0, "batch_reward": 0.17287304419279098, "critic_loss": 0.2308945710286498, "actor_loss": -27.0562837266922, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.36739206314087, "step": 60000}
{"episode_reward": 275.2357369698981, "episode": 61.0, "batch_reward": 0.17501696567237376, "critic_loss": 0.24793290705233811, "actor_loss": -27.717681836128236, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.356900453567505, "step": 61000}
{"episode_reward": 336.65167633407685, "episode": 62.0, "batch_reward": 0.17771476638317107, "critic_loss": 0.24786496698856353, "actor_loss": -27.238447326660157, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.10300374031067, "step": 62000}
{"episode_reward": 350.4221264622871, "episode": 63.0, "batch_reward": 0.17903628860414028, "critic_loss": 0.24081254605948926, "actor_loss": -27.541208402633668, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.800151586532593, "step": 63000}
{"episode_reward": 335.9148093657843, "episode": 64.0, "batch_reward": 0.1821747868359089, "critic_loss": 0.24757256738096475, "actor_loss": -27.941447149276733, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.064711809158325, "step": 64000}
{"episode_reward": 340.878471871508, "episode": 65.0, "batch_reward": 0.18559902791678906, "critic_loss": 0.22401019902527333, "actor_loss": -28.041229013442994, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.08656930923462, "step": 65000}
{"episode_reward": 341.0077389912888, "episode": 66.0, "batch_reward": 0.18728486643731593, "critic_loss": 0.23761687387526034, "actor_loss": -28.276339721679687, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.024173498153687, "step": 66000}
{"episode_reward": 303.36302799340797, "episode": 67.0, "batch_reward": 0.18866091561317444, "critic_loss": 0.26784959364682437, "actor_loss": -28.008670669555663, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.837456226348877, "step": 67000}
{"episode_reward": 338.63708145590795, "episode": 68.0, "batch_reward": 0.19158705794811248, "critic_loss": 0.29099815436452625, "actor_loss": -29.04689002609253, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.987281322479248, "step": 68000}
{"episode_reward": 341.99933177566425, "episode": 69.0, "batch_reward": 0.19429163160920143, "critic_loss": 0.259779340878129, "actor_loss": -29.178165313720704, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.38843321800232, "step": 69000}
{"episode_reward": 337.48024351856304, "episode": 70.0, "batch_reward": 0.19638337601721287, "critic_loss": 0.2685558832213283, "actor_loss": -29.4498665599823, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.907318830490112, "step": 70000}
{"episode_reward": 375.052778215396, "episode": 71.0, "batch_reward": 0.1978548360466957, "critic_loss": 0.2550723225697875, "actor_loss": -29.0086213054657, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.27872633934021, "step": 71000}
{"episode_reward": 365.23522746792537, "episode": 72.0, "batch_reward": 0.20071124719083308, "critic_loss": 0.23352315252274275, "actor_loss": -30.140902017593383, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.31898784637451, "step": 72000}
{"episode_reward": 364.3940965867173, "episode": 73.0, "batch_reward": 0.20228102377057075, "critic_loss": 0.25396650825440886, "actor_loss": -30.11484697723389, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.093410968780518, "step": 73000}
{"episode_reward": 366.0283749666748, "episode": 74.0, "batch_reward": 0.20496702332794667, "critic_loss": 0.227278946749866, "actor_loss": -29.91271951675415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.90919303894043, "step": 74000}
{"episode_reward": 336.7162140889736, "episode": 75.0, "batch_reward": 0.20689139018952846, "critic_loss": 0.24861471128463744, "actor_loss": -30.624950527191164, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.41484832763672, "step": 75000}
{"episode_reward": 167.56375204351252, "episode": 76.0, "batch_reward": 0.20597127267718315, "critic_loss": 0.24509514196962118, "actor_loss": -30.162123888015746, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.49251699447632, "step": 76000}
{"episode_reward": 354.3255988086694, "episode": 77.0, "batch_reward": 0.20803646443784238, "critic_loss": 0.30003300558775664, "actor_loss": -30.23640040588379, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.753313779830933, "step": 77000}
{"episode_reward": 329.805772314199, "episode": 78.0, "batch_reward": 0.20905137950181962, "critic_loss": 0.25795939772576093, "actor_loss": -30.088834939956666, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.11500906944275, "step": 78000}
{"episode_reward": 351.4738577168338, "episode": 79.0, "batch_reward": 0.21147116708755492, "critic_loss": 0.24771683348715307, "actor_loss": -30.71420139503479, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.58208990097046, "step": 79000}
{"episode_reward": 377.6115397731122, "episode": 80.0, "batch_reward": 0.21402870245277883, "critic_loss": 0.27106605064868927, "actor_loss": -30.965484512329102, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.61504817008972, "step": 80000}
{"episode_reward": 366.1054517277783, "episode": 81.0, "batch_reward": 0.21631524689495563, "critic_loss": 0.2539249842166901, "actor_loss": -31.26805697631836, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.30803871154785, "step": 81000}
{"episode_reward": 360.4437083754485, "episode": 82.0, "batch_reward": 0.2172444406747818, "critic_loss": 0.25756893019378185, "actor_loss": -31.22078463745117, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.441162586212158, "step": 82000}
{"episode_reward": 389.03291685502677, "episode": 83.0, "batch_reward": 0.21870762805640698, "critic_loss": 0.2737782724574208, "actor_loss": -31.39745170021057, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.43292474746704, "step": 83000}
{"episode_reward": 379.59869620819927, "episode": 84.0, "batch_reward": 0.22076588082313536, "critic_loss": 0.24539126998186112, "actor_loss": -32.10856715965271, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.195071935653687, "step": 84000}
{"episode_reward": 364.8456937745488, "episode": 85.0, "batch_reward": 0.22295914016664029, "critic_loss": 0.24587532804906367, "actor_loss": -31.920058975219728, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.20595097541809, "step": 85000}
{"episode_reward": 385.9396255452024, "episode": 86.0, "batch_reward": 0.22546081140637397, "critic_loss": 0.25450740249454973, "actor_loss": -32.36648777198791, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.76732110977173, "step": 86000}
{"episode_reward": 385.8495022838108, "episode": 87.0, "batch_reward": 0.22526413410902024, "critic_loss": 0.23879622153937816, "actor_loss": -32.269226577758786, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.634443759918213, "step": 87000}
{"episode_reward": 48.82060589225736, "episode": 88.0, "batch_reward": 0.22426967035233975, "critic_loss": 0.27752589701116087, "actor_loss": -32.336366359710695, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.676073789596558, "step": 88000}
{"episode_reward": 124.45144169723402, "episode": 89.0, "batch_reward": 0.22401267200708389, "critic_loss": 0.3204477310925722, "actor_loss": -31.71076509284973, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.782387256622314, "step": 89000}
{"episode_reward": 365.1017542629851, "episode": 90.0, "batch_reward": 0.2252134806215763, "critic_loss": 0.24654791214317084, "actor_loss": -31.98011988258362, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.344178438186646, "step": 90000}
{"episode_reward": 388.64578990057953, "episode": 91.0, "batch_reward": 0.2270875745564699, "critic_loss": 0.27211882373690605, "actor_loss": -31.75896515274048, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.81684136390686, "step": 91000}
{"episode_reward": 382.0538256986439, "episode": 92.0, "batch_reward": 0.22842880357801915, "critic_loss": 0.2355220262631774, "actor_loss": -32.11255359840393, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.408189296722412, "step": 92000}
{"episode_reward": 360.1328501276532, "episode": 93.0, "batch_reward": 0.23007725928723813, "critic_loss": 0.2707954590469599, "actor_loss": -32.80028298950195, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.449607610702515, "step": 93000}
{"episode_reward": 388.2673026570377, "episode": 94.0, "batch_reward": 0.23236273622512818, "critic_loss": 0.2617500389367342, "actor_loss": -33.01548247718811, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.24623966217041, "step": 94000}
{"episode_reward": 225.4044888654097, "episode": 95.0, "batch_reward": 0.2320812603980303, "critic_loss": 0.3216545412838459, "actor_loss": -32.87944850540161, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.21650218963623, "step": 95000}
{"episode_reward": 370.89982318191784, "episode": 96.0, "batch_reward": 0.23373441357910632, "critic_loss": 0.28406665533035996, "actor_loss": -32.7507448387146, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.079291343688965, "step": 96000}
{"episode_reward": 370.5874603509289, "episode": 97.0, "batch_reward": 0.2349574357420206, "critic_loss": 0.23746849987655877, "actor_loss": -33.11651073646546, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.534533500671387, "step": 97000}
{"episode_reward": 391.50504368643976, "episode": 98.0, "batch_reward": 0.23629588985443115, "critic_loss": 0.2783186922520399, "actor_loss": -33.335837265014646, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.699288845062256, "step": 98000}
{"episode_reward": 373.80413961374865, "episode": 99.0, "batch_reward": 0.2380282907038927, "critic_loss": 0.272538070037961, "actor_loss": -33.21565505981445, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.062456369400024, "step": 99000}
{"episode_reward": 374.93121476189464, "episode": 100.0, "batch_reward": 0.23869229678809642, "critic_loss": 0.24336385609209538, "actor_loss": -33.82426492500305, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.599085092544556, "step": 100000}
{"episode_reward": 376.03147211450954, "episode": 101.0, "batch_reward": 0.24092929628491402, "critic_loss": 0.2575848505496979, "actor_loss": -33.78970101928711, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.63518667221069, "step": 101000}
{"episode_reward": 369.7117123717421, "episode": 102.0, "batch_reward": 0.24140034706890584, "critic_loss": 0.2294080272614956, "actor_loss": -34.2048833026886, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.278943300247192, "step": 102000}
{"episode_reward": 377.3445786680485, "episode": 103.0, "batch_reward": 0.24309563845396043, "critic_loss": 0.2556647458821535, "actor_loss": -33.266591411590575, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.716045141220093, "step": 103000}
{"episode_reward": 403.5602014641952, "episode": 104.0, "batch_reward": 0.24406829488277434, "critic_loss": 0.2509846024513245, "actor_loss": -34.00669298934937, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.702520608901978, "step": 104000}
{"episode_reward": 393.5273793223448, "episode": 105.0, "batch_reward": 0.24675262889266014, "critic_loss": 0.28149934256821874, "actor_loss": -33.89081831741333, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.14427614212036, "step": 105000}
{"episode_reward": 355.10044600463704, "episode": 106.0, "batch_reward": 0.24712932857871056, "critic_loss": 0.24421115135401486, "actor_loss": -34.82556593513489, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.802456617355347, "step": 106000}
{"episode_reward": 383.40499118791075, "episode": 107.0, "batch_reward": 0.24865571635961534, "critic_loss": 0.24171314961463214, "actor_loss": -34.7972279663086, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.22752594947815, "step": 107000}
{"episode_reward": 401.8638607476539, "episode": 108.0, "batch_reward": 0.24934184703230858, "critic_loss": 0.2620006079226732, "actor_loss": -34.11848034286499, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.156174421310425, "step": 108000}
{"episode_reward": 383.3885943880209, "episode": 109.0, "batch_reward": 0.25109539943933484, "critic_loss": 0.24976091980189086, "actor_loss": -34.8360689125061, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.82519221305847, "step": 109000}
{"episode_reward": 384.7787028200396, "episode": 110.0, "batch_reward": 0.25236364065110684, "critic_loss": 0.25993995540589093, "actor_loss": -34.77257702255249, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.36335563659668, "step": 110000}
{"episode_reward": 218.10951269842573, "episode": 111.0, "batch_reward": 0.2510175075829029, "critic_loss": 0.2584569223672152, "actor_loss": -34.306338665008546, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.99261808395386, "step": 111000}
{"episode_reward": 358.3435709644576, "episode": 112.0, "batch_reward": 0.2525140315443277, "critic_loss": 0.28850608395040034, "actor_loss": -34.823592796325684, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.627542734146118, "step": 112000}
{"episode_reward": 396.15455967112376, "episode": 113.0, "batch_reward": 0.2541119635850191, "critic_loss": 0.26881751118600367, "actor_loss": -35.1641142578125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.141533851623535, "step": 113000}
{"episode_reward": 372.6896282032283, "episode": 114.0, "batch_reward": 0.2551301032751799, "critic_loss": 0.2906801196038723, "actor_loss": -35.4422958946228, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.530492544174194, "step": 114000}
{"episode_reward": 395.57438936647407, "episode": 115.0, "batch_reward": 0.2557894067466259, "critic_loss": 0.2928829766064882, "actor_loss": -34.77297552490234, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.94135046005249, "step": 115000}
{"episode_reward": 375.02640155107713, "episode": 116.0, "batch_reward": 0.258213660761714, "critic_loss": 0.30566419334709644, "actor_loss": -35.263095539093015, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.964882612228394, "step": 116000}
{"episode_reward": 397.23874154447356, "episode": 117.0, "batch_reward": 0.2584206660836935, "critic_loss": 0.2897903650328517, "actor_loss": -34.54470379257202, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.06867790222168, "step": 117000}
{"episode_reward": 393.52653379286187, "episode": 118.0, "batch_reward": 0.25986953237652777, "critic_loss": 0.2830035569742322, "actor_loss": -35.156365047454834, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.43736171722412, "step": 118000}
{"episode_reward": 395.23954226452776, "episode": 119.0, "batch_reward": 0.2617405733317137, "critic_loss": 0.3063114106506109, "actor_loss": -35.24941622543335, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.495782375335693, "step": 119000}
{"episode_reward": 382.03008930078016, "episode": 120.0, "batch_reward": 0.2617101624161005, "critic_loss": 0.3437424111664295, "actor_loss": -35.28614223480225, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.45189666748047, "step": 120000}
{"episode_reward": 382.27845694701875, "episode": 121.0, "batch_reward": 0.2624765267372131, "critic_loss": 0.3179496766626835, "actor_loss": -35.325402843475345, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.6204719543457, "step": 121000}
{"episode_reward": 415.59504003466424, "episode": 122.0, "batch_reward": 0.26467722781002523, "critic_loss": 0.3053962983042002, "actor_loss": -35.95772008514404, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.558395624160767, "step": 122000}
{"episode_reward": 397.40991023012924, "episode": 123.0, "batch_reward": 0.2654477218091488, "critic_loss": 0.2874934301301837, "actor_loss": -36.29505073547363, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.726216554641724, "step": 123000}
{"episode_reward": 389.21589103175234, "episode": 124.0, "batch_reward": 0.26553765407204627, "critic_loss": 0.290191178701818, "actor_loss": -36.20990422821045, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.586832284927368, "step": 124000}
{"episode_reward": 365.4166770956713, "episode": 125.0, "batch_reward": 0.26738109101355073, "critic_loss": 0.2889907880797982, "actor_loss": -36.31866923522949, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.30541706085205, "step": 125000}
{"episode_reward": 385.0896138124853, "episode": 126.0, "batch_reward": 0.2687513509094715, "critic_loss": 0.31775288974493743, "actor_loss": -35.91585168838501, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.71323275566101, "step": 126000}
{"episode_reward": 396.4016296425919, "episode": 127.0, "batch_reward": 0.26837180435657504, "critic_loss": 0.2736515341326594, "actor_loss": -35.74572407913208, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.963009357452393, "step": 127000}
{"episode_reward": 411.1113709793256, "episode": 128.0, "batch_reward": 0.27050631275773046, "critic_loss": 0.2830745643377304, "actor_loss": -36.10171926879883, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.148771047592163, "step": 128000}
{"episode_reward": 401.6512121363298, "episode": 129.0, "batch_reward": 0.2715229720324278, "critic_loss": 0.2820782600492239, "actor_loss": -36.39715859222412, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.033114671707153, "step": 129000}
{"episode_reward": 414.5577268089502, "episode": 130.0, "batch_reward": 0.27277216927707193, "critic_loss": 0.26733893820643423, "actor_loss": -36.277457515716556, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.82075047492981, "step": 130000}
{"episode_reward": 398.912106303077, "episode": 131.0, "batch_reward": 0.27328025276958945, "critic_loss": 0.27002744264155626, "actor_loss": -36.870975986480715, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.70888161659241, "step": 131000}
{"episode_reward": 375.6590796059704, "episode": 132.0, "batch_reward": 0.27375900867581365, "critic_loss": 0.2802958103194833, "actor_loss": -37.059335067749025, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.92404317855835, "step": 132000}
{"episode_reward": 373.8391843970191, "episode": 133.0, "batch_reward": 0.2752412684261799, "critic_loss": 0.27504741559922696, "actor_loss": -36.93416860198975, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.652989387512207, "step": 133000}
{"episode_reward": 414.2478489992898, "episode": 134.0, "batch_reward": 0.2759184219539165, "critic_loss": 0.2635413658842444, "actor_loss": -36.68462024688721, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.990900993347168, "step": 134000}
{"episode_reward": 404.6485841634705, "episode": 135.0, "batch_reward": 0.2774624227583408, "critic_loss": 0.28598578640818595, "actor_loss": -36.68833299255371, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.780434370040894, "step": 135000}
{"episode_reward": 363.22434349451527, "episode": 136.0, "batch_reward": 0.2768424800187349, "critic_loss": 0.26269580821692945, "actor_loss": -36.28615914916992, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.258630990982056, "step": 136000}
{"episode_reward": 400.8461754766478, "episode": 137.0, "batch_reward": 0.27840332420170305, "critic_loss": 0.2638973387479782, "actor_loss": -37.49357806777954, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.821298360824585, "step": 137000}
{"episode_reward": 404.58814309825596, "episode": 138.0, "batch_reward": 0.2799810983985662, "critic_loss": 0.30089296838641166, "actor_loss": -37.23002609634399, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.443928003311157, "step": 138000}
{"episode_reward": 401.0773808875029, "episode": 139.0, "batch_reward": 0.2805002981871367, "critic_loss": 0.29300878358632326, "actor_loss": -37.13836672210693, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.96324324607849, "step": 139000}
{"episode_reward": 402.15001682492283, "episode": 140.0, "batch_reward": 0.2816128565967083, "critic_loss": 0.30370920364558696, "actor_loss": -37.16429893112183, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.87706446647644, "step": 140000}
{"episode_reward": 407.14356777846683, "episode": 141.0, "batch_reward": 0.2817063173800707, "critic_loss": 0.29396277482807637, "actor_loss": -37.623465591430666, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.829124212265015, "step": 141000}
{"episode_reward": 402.1555537303734, "episode": 142.0, "batch_reward": 0.2821416461467743, "critic_loss": 0.26120859360694887, "actor_loss": -36.52443429946899, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.707728385925293, "step": 142000}
{"episode_reward": 387.737676954744, "episode": 143.0, "batch_reward": 0.28311933122575283, "critic_loss": 0.2753320817947388, "actor_loss": -36.85372193527222, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.77512240409851, "step": 143000}
{"episode_reward": 403.63863110215533, "episode": 144.0, "batch_reward": 0.28478923693299296, "critic_loss": 0.27637762448191644, "actor_loss": -37.530497035980225, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.486092805862427, "step": 144000}
{"episode_reward": 410.8584141706497, "episode": 145.0, "batch_reward": 0.28560236608982087, "critic_loss": 0.2610028748288751, "actor_loss": -38.09347161483765, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.319170236587524, "step": 145000}
{"episode_reward": 386.92003824450404, "episode": 146.0, "batch_reward": 0.28565785424411294, "critic_loss": 0.28095277172327043, "actor_loss": -37.949439014434816, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.463618278503418, "step": 146000}
{"episode_reward": 390.9298074824805, "episode": 147.0, "batch_reward": 0.2864375802278519, "critic_loss": 0.27695680149644614, "actor_loss": -37.56211052703858, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.465139865875244, "step": 147000}
{"episode_reward": 377.0842966859964, "episode": 148.0, "batch_reward": 0.2876066938191652, "critic_loss": 0.25628922737389803, "actor_loss": -38.334185962677005, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.008018255233765, "step": 148000}
{"episode_reward": 400.6277849636962, "episode": 149.0, "batch_reward": 0.28747989049553874, "critic_loss": 0.2685508941411972, "actor_loss": -37.51649576187134, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.70860981941223, "step": 149000}
{"episode_reward": 415.36260539266453, "episode": 150.0, "batch_reward": 0.28878369157016276, "critic_loss": 0.24810698985308408, "actor_loss": -38.29492238998413, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
