{"episode_reward": 0.0, "episode": 1.0, "duration": 19.5473415851593, "step": 1000}
{"episode_reward": 4.231880753996205, "episode": 2.0, "duration": 1.594331979751587, "step": 2000}
{"episode_reward": 395.1450543749875, "episode": 3.0, "batch_reward": 0.18721398608849105, "critic_loss": 0.018883906272151477, "actor_loss": -25.959761080747636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 68.10365176200867, "step": 3000}
{"episode_reward": 2.273398624595633, "episode": 4.0, "batch_reward": 0.11639364022761584, "critic_loss": 0.010966924770036713, "actor_loss": -22.432834020614624, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.16284441947937, "step": 4000}
{"episode_reward": 2.415626252786721, "episode": 5.0, "batch_reward": 0.09112498282268644, "critic_loss": 0.014704429382923991, "actor_loss": -21.8373512134552, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.37077307701111, "step": 5000}
{"episode_reward": 3.4994727305601456, "episode": 6.0, "batch_reward": 0.07496359716728329, "critic_loss": 0.008918448270764202, "actor_loss": -19.972702541828156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.515611171722412, "step": 6000}
{"episode_reward": 3.109925725519539, "episode": 7.0, "batch_reward": 0.06408844174444675, "critic_loss": 0.00970583302504383, "actor_loss": -19.549780942916872, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.861960887908936, "step": 7000}
{"episode_reward": 2.832419999522987, "episode": 8.0, "batch_reward": 0.05577563052345067, "critic_loss": 0.01701316407090053, "actor_loss": -20.539725877761843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.275941133499146, "step": 8000}
{"episode_reward": 3.3694153731585006, "episode": 9.0, "batch_reward": 0.04904465621337294, "critic_loss": 0.016287892339983956, "actor_loss": -19.482345386981965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.02187991142273, "step": 9000}
{"episode_reward": 4.730582178370143, "episode": 10.0, "batch_reward": 0.0450681751742959, "critic_loss": 0.01709933700086549, "actor_loss": -19.978305693149565, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.84876537322998, "step": 10000}
{"episode_reward": 5.406129033304301, "episode": 11.0, "batch_reward": 0.04084408564865589, "critic_loss": 0.013633720926009119, "actor_loss": -19.250213670253753, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.10011911392212, "step": 11000}
{"episode_reward": 5.606847374373978, "episode": 12.0, "batch_reward": 0.03815345659758896, "critic_loss": 0.01712831881258171, "actor_loss": -19.441762791633607, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.110360622406006, "step": 12000}
{"episode_reward": 4.430227463141778, "episode": 13.0, "batch_reward": 0.035541203183121976, "critic_loss": 0.01303971070505213, "actor_loss": -18.619792663097382, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.368624925613403, "step": 13000}
{"episode_reward": 3.449410453342426, "episode": 14.0, "batch_reward": 0.032367268171161416, "critic_loss": 0.011392887630383484, "actor_loss": -18.986540133476257, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.286670684814453, "step": 14000}
{"episode_reward": 2.0963086236846475, "episode": 15.0, "batch_reward": 0.03068807389587164, "critic_loss": 0.009089864281704649, "actor_loss": -17.428354413032533, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.583529710769653, "step": 15000}
{"episode_reward": 2.1991309334103284, "episode": 16.0, "batch_reward": 0.028447939294390382, "critic_loss": 0.010348969356215093, "actor_loss": -19.408863056182863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.91172456741333, "step": 16000}
{"episode_reward": 2.0173536726889028, "episode": 17.0, "batch_reward": 0.02701136014657095, "critic_loss": 0.008155479223234579, "actor_loss": -18.874625275850295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.37267565727234, "step": 17000}
{"episode_reward": 2.3409698127882237, "episode": 18.0, "batch_reward": 0.025464201535563915, "critic_loss": 0.007993218326300849, "actor_loss": -18.90067429471016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.717689514160156, "step": 18000}
{"episode_reward": 2.3293324106929663, "episode": 19.0, "batch_reward": 0.02487240984663367, "critic_loss": 0.008676284939516336, "actor_loss": -19.28530122947693, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.13843297958374, "step": 19000}
{"episode_reward": 2.1804086201378303, "episode": 20.0, "batch_reward": 0.02362419300619513, "critic_loss": 0.00789970165170962, "actor_loss": -17.10489391374588, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.958367347717285, "step": 20000}
{"episode_reward": 3.4139789800757816, "episode": 21.0, "batch_reward": 0.02191862410446629, "critic_loss": 0.007656499838922173, "actor_loss": -18.353810920715333, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.72226643562317, "step": 21000}
{"episode_reward": 2.3407723637670905, "episode": 22.0, "batch_reward": 0.021191601247061043, "critic_loss": 0.011520279442018364, "actor_loss": -17.494865627527236, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.801657676696777, "step": 22000}
{"episode_reward": 3.610744715475542, "episode": 23.0, "batch_reward": 0.020734346662415193, "critic_loss": 0.014054307363927364, "actor_loss": -18.089392137050627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.343250513076782, "step": 23000}
{"episode_reward": 6.728216783396503, "episode": 24.0, "batch_reward": 0.020308234800584614, "critic_loss": 0.013677344332681968, "actor_loss": -18.370692446231843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.233957290649414, "step": 24000}
{"episode_reward": 6.570542983986407, "episode": 25.0, "batch_reward": 0.01998303863196634, "critic_loss": 0.015047578434925527, "actor_loss": -18.640740325927734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.030592918395996, "step": 25000}
{"episode_reward": 28.821969603581582, "episode": 26.0, "batch_reward": 0.020683609165251256, "critic_loss": 0.012327711764024571, "actor_loss": -19.36923555135727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.75308084487915, "step": 26000}
{"episode_reward": 27.429941892847594, "episode": 27.0, "batch_reward": 0.020997492645401506, "critic_loss": 0.007484555365983397, "actor_loss": -18.760975178718567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.536471843719482, "step": 27000}
{"episode_reward": 29.19507705279563, "episode": 28.0, "batch_reward": 0.020503060003044082, "critic_loss": 0.008973897075047716, "actor_loss": -19.127933068275453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.473055362701416, "step": 28000}
{"episode_reward": 28.414566253751243, "episode": 29.0, "batch_reward": 0.02089155426900834, "critic_loss": 0.008227877258090302, "actor_loss": -18.221611842632292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.010757207870483, "step": 29000}
{"episode_reward": 25.421447601318928, "episode": 30.0, "batch_reward": 0.021484223717357965, "critic_loss": 0.007959620020585135, "actor_loss": -17.492153064250946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.76252245903015, "step": 30000}
{"episode_reward": 24.624059161324528, "episode": 31.0, "batch_reward": 0.021349469581153243, "critic_loss": 0.0061243803610559555, "actor_loss": -17.925777631759644, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.17412042617798, "step": 31000}
{"episode_reward": 22.213970647762935, "episode": 32.0, "batch_reward": 0.02131536748772487, "critic_loss": 0.0056103802749421445, "actor_loss": -17.642452427387237, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.340282678604126, "step": 32000}
{"episode_reward": 12.761282180143827, "episode": 33.0, "batch_reward": 0.021437192889396103, "critic_loss": 0.00463738203945104, "actor_loss": -17.23667546081543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.864251852035522, "step": 33000}
{"episode_reward": 21.04830440555114, "episode": 34.0, "batch_reward": 0.02091525516565889, "critic_loss": 0.004916532988892868, "actor_loss": -17.88835797572136, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.5234854221344, "step": 34000}
{"episode_reward": 19.940786380150996, "episode": 35.0, "batch_reward": 0.02099252299638465, "critic_loss": 0.004076329115894623, "actor_loss": -17.194250210523606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.332454442977905, "step": 35000}
{"episode_reward": 19.581003924527018, "episode": 36.0, "batch_reward": 0.021052728141192346, "critic_loss": 0.003885669033508748, "actor_loss": -18.65405582642555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.16674304008484, "step": 36000}
{"episode_reward": 23.53766195382402, "episode": 37.0, "batch_reward": 0.021012448069173843, "critic_loss": 0.003747623555304017, "actor_loss": -17.704355478286743, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.993552446365356, "step": 37000}
{"episode_reward": 20.75965025042979, "episode": 38.0, "batch_reward": 0.021181142806541174, "critic_loss": 0.004843332116259262, "actor_loss": -16.652763659000396, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.046406984329224, "step": 38000}
{"episode_reward": 17.723283058411322, "episode": 39.0, "batch_reward": 0.021230113262310623, "critic_loss": 0.00547466113534756, "actor_loss": -17.709192675113677, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.536765813827515, "step": 39000}
{"episode_reward": 12.58972001449412, "episode": 40.0, "batch_reward": 0.020545383838936688, "critic_loss": 0.00451149186771363, "actor_loss": -18.12437719988823, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95318913459778, "step": 40000}
{"episode_reward": 11.88566476691406, "episode": 41.0, "batch_reward": 0.020426829610485583, "critic_loss": 0.003292008251068182, "actor_loss": -18.245776170015336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.36792993545532, "step": 41000}
{"episode_reward": 10.731642186749394, "episode": 42.0, "batch_reward": 0.020234788018278778, "critic_loss": 0.003616496810456738, "actor_loss": -17.06139529848099, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.70765209197998, "step": 42000}
{"episode_reward": 15.767215488440065, "episode": 43.0, "batch_reward": 0.02013584514381364, "critic_loss": 0.004549284597043879, "actor_loss": -18.001996079444886, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.806944847106934, "step": 43000}
{"episode_reward": 24.022591733422484, "episode": 44.0, "batch_reward": 0.020192058349959553, "critic_loss": 0.0036422217405634003, "actor_loss": -16.720205350399016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.547211408615112, "step": 44000}
{"episode_reward": 12.326523450199094, "episode": 45.0, "batch_reward": 0.01996142912656069, "critic_loss": 0.003921616096864454, "actor_loss": -16.24024373984337, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.51671028137207, "step": 45000}
{"episode_reward": 13.449248303804971, "episode": 46.0, "batch_reward": 0.019954128916375338, "critic_loss": 0.003635925682145171, "actor_loss": -17.42169616818428, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.836979150772095, "step": 46000}
{"episode_reward": 8.842011938382472, "episode": 47.0, "batch_reward": 0.01975692491605878, "critic_loss": 0.003972331228433177, "actor_loss": -17.48576205134392, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.61532974243164, "step": 47000}
{"episode_reward": 13.762152614583465, "episode": 48.0, "batch_reward": 0.01941193211078644, "critic_loss": 0.003966048727044836, "actor_loss": -17.493531286478042, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.10297441482544, "step": 48000}
{"episode_reward": 7.519618337076188, "episode": 49.0, "batch_reward": 0.01955521289166063, "critic_loss": 0.0036734729377785698, "actor_loss": -17.37963031578064, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.355207681655884, "step": 49000}
{"episode_reward": 12.921742664819083, "episode": 50.0, "batch_reward": 0.01938837685994804, "critic_loss": 0.003797014466836117, "actor_loss": -16.63190593457222, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.955373764038086, "step": 50000}
{"episode_reward": 24.50001476458455, "episode": 51.0, "batch_reward": 0.01928236204572022, "critic_loss": 0.003943923393031582, "actor_loss": -16.137987786769866, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.467464447021484, "step": 51000}
{"episode_reward": 20.41205626479539, "episode": 52.0, "batch_reward": 0.01947530712839216, "critic_loss": 0.004088925319665577, "actor_loss": -17.217778344631196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.10720682144165, "step": 52000}
{"episode_reward": 14.400106771843314, "episode": 53.0, "batch_reward": 0.019339109314605595, "critic_loss": 0.004015359930112027, "actor_loss": -15.098103461503982, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.134265899658203, "step": 53000}
{"episode_reward": 12.956717594761148, "episode": 54.0, "batch_reward": 0.019429989106953142, "critic_loss": 0.003978601472801529, "actor_loss": -17.345110054731368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.242433786392212, "step": 54000}
{"episode_reward": 11.018236484709286, "episode": 55.0, "batch_reward": 0.018809865606017412, "critic_loss": 0.004441447615507059, "actor_loss": -16.74349016904831, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.354300022125244, "step": 55000}
{"episode_reward": 13.831584129457022, "episode": 56.0, "batch_reward": 0.018664579792879523, "critic_loss": 0.005895935594802722, "actor_loss": -15.511912006378173, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.54873538017273, "step": 56000}
{"episode_reward": 15.956587278314121, "episode": 57.0, "batch_reward": 0.01895089410059154, "critic_loss": 0.006808100440423005, "actor_loss": -16.022095846772196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.42572832107544, "step": 57000}
{"episode_reward": 12.238128045606416, "episode": 58.0, "batch_reward": 0.01876539873704314, "critic_loss": 0.004934704844374209, "actor_loss": -16.21416619384289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.72411584854126, "step": 58000}
{"episode_reward": 14.386869845317493, "episode": 59.0, "batch_reward": 0.018485428874380885, "critic_loss": 0.004637316243024543, "actor_loss": -16.031358226537705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.518276691436768, "step": 59000}
{"episode_reward": 16.680226848809717, "episode": 60.0, "batch_reward": 0.018590033600106835, "critic_loss": 0.0037605097896885125, "actor_loss": -16.25151015305519, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.693552017211914, "step": 60000}
{"episode_reward": 13.307257568682836, "episode": 61.0, "batch_reward": 0.01839718893682584, "critic_loss": 0.004652429988491349, "actor_loss": -16.594850895881653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.01742458343506, "step": 61000}
{"episode_reward": 10.049793040530423, "episode": 62.0, "batch_reward": 0.018269037147983908, "critic_loss": 0.006527572454651818, "actor_loss": -15.085239902496339, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.229771614074707, "step": 62000}
{"episode_reward": 23.69903255374492, "episode": 63.0, "batch_reward": 0.01846265136823058, "critic_loss": 0.006492730789701454, "actor_loss": -14.886592439889908, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.44566035270691, "step": 63000}
{"episode_reward": 26.938994761185455, "episode": 64.0, "batch_reward": 0.018494956756010653, "critic_loss": 0.013919071439886466, "actor_loss": -15.60037456357479, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.841703414916992, "step": 64000}
{"episode_reward": 11.672537113232265, "episode": 65.0, "batch_reward": 0.018591637372970583, "critic_loss": 0.008202312502544374, "actor_loss": -14.958967260360717, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.9927077293396, "step": 65000}
{"episode_reward": 13.920589564632003, "episode": 66.0, "batch_reward": 0.01816594675835222, "critic_loss": 0.0057813866240903735, "actor_loss": -15.43056953382492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.617366790771484, "step": 66000}
{"episode_reward": 12.112498391722372, "episode": 67.0, "batch_reward": 0.018300796379800886, "critic_loss": 0.005489421616890468, "actor_loss": -14.840508921861648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.913592100143433, "step": 67000}
{"episode_reward": 18.025001343400014, "episode": 68.0, "batch_reward": 0.01846204231120646, "critic_loss": 0.00543331165437121, "actor_loss": -15.715678183674813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.823343515396118, "step": 68000}
{"episode_reward": 14.626343082733847, "episode": 69.0, "batch_reward": 0.018460946298204363, "critic_loss": 0.005031733682262712, "actor_loss": -15.556560981631279, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.39352321624756, "step": 69000}
{"episode_reward": 28.250271752921424, "episode": 70.0, "batch_reward": 0.018448191066272556, "critic_loss": 0.0062533870721235875, "actor_loss": -16.485404359817505, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.549869537353516, "step": 70000}
{"episode_reward": 24.028141934504117, "episode": 71.0, "batch_reward": 0.01854818390123546, "critic_loss": 0.00635302128479816, "actor_loss": -14.83668542611599, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.68980693817139, "step": 71000}
{"episode_reward": 27.031056438778524, "episode": 72.0, "batch_reward": 0.018562887324020266, "critic_loss": 0.00489690485491883, "actor_loss": -15.945724917054177, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.855552196502686, "step": 72000}
{"episode_reward": 26.985129680257405, "episode": 73.0, "batch_reward": 0.01890228336304426, "critic_loss": 0.004614631003467366, "actor_loss": -15.607280097961425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.787814140319824, "step": 73000}
{"episode_reward": 27.316784443470937, "episode": 74.0, "batch_reward": 0.018821710025891662, "critic_loss": 0.003916421485715546, "actor_loss": -15.653792753219605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.665501356124878, "step": 74000}
{"episode_reward": 23.69152102764464, "episode": 75.0, "batch_reward": 0.019081348154693843, "critic_loss": 0.004378485031076707, "actor_loss": -15.898115939378739, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.227120399475098, "step": 75000}
{"episode_reward": 24.388795799716615, "episode": 76.0, "batch_reward": 0.018907117213122545, "critic_loss": 0.004295863892068155, "actor_loss": -16.111447222948076, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.527347087860107, "step": 76000}
{"episode_reward": 9.11566060129482, "episode": 77.0, "batch_reward": 0.018700455959886314, "critic_loss": 0.007078432524809614, "actor_loss": -15.922876322031021, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.750911712646484, "step": 77000}
{"episode_reward": 19.63199454281875, "episode": 78.0, "batch_reward": 0.018891880994662644, "critic_loss": 0.005846446134033613, "actor_loss": -15.375336931228638, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.324365854263306, "step": 78000}
{"episode_reward": 18.155308808941083, "episode": 79.0, "batch_reward": 0.018845339192077516, "critic_loss": 0.005819892951636575, "actor_loss": -15.638107039809228, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.18421769142151, "step": 79000}
{"episode_reward": 25.906936384038477, "episode": 80.0, "batch_reward": 0.018992922626435756, "critic_loss": 0.007466216614935547, "actor_loss": -15.672762482523918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.070916414260864, "step": 80000}
{"episode_reward": 22.41989365051939, "episode": 81.0, "batch_reward": 0.019131899883039295, "critic_loss": 0.00793900273181498, "actor_loss": -15.36468367421627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.831403493881226, "step": 81000}
{"episode_reward": 27.423335132735705, "episode": 82.0, "batch_reward": 0.019010313984937965, "critic_loss": 0.006299200925510376, "actor_loss": -15.50172358083725, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.500253438949585, "step": 82000}
{"episode_reward": 28.60430484720519, "episode": 83.0, "batch_reward": 0.019115827589295805, "critic_loss": 0.00583062927168794, "actor_loss": -16.475792979478836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.674396514892578, "step": 83000}
{"episode_reward": 24.112937107175647, "episode": 84.0, "batch_reward": 0.019109649956226347, "critic_loss": 0.00561836612119805, "actor_loss": -17.022261294841766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.742910861968994, "step": 84000}
{"episode_reward": 23.999408695075548, "episode": 85.0, "batch_reward": 0.019557144535705447, "critic_loss": 0.005818391856155358, "actor_loss": -15.783024172067643, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.776478052139282, "step": 85000}
{"episode_reward": 24.95662039656896, "episode": 86.0, "batch_reward": 0.019452215661294757, "critic_loss": 0.00621411742863711, "actor_loss": -15.65007780969143, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.33968234062195, "step": 86000}
{"episode_reward": 25.887776110664678, "episode": 87.0, "batch_reward": 0.019774755492806436, "critic_loss": 0.005728459978476166, "actor_loss": -16.09265302360058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.52752923965454, "step": 87000}
{"episode_reward": 24.83124026113746, "episode": 88.0, "batch_reward": 0.01970030800346285, "critic_loss": 0.005246141487848945, "actor_loss": -16.677267481088638, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.05893564224243, "step": 88000}
{"episode_reward": 26.751503434335095, "episode": 89.0, "batch_reward": 0.019717763928696515, "critic_loss": 0.0039779830409679565, "actor_loss": -15.629933584690095, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.107139587402344, "step": 89000}
{"episode_reward": 24.008792481010722, "episode": 90.0, "batch_reward": 0.019497593219392, "critic_loss": 0.004224332065554335, "actor_loss": -16.343078670501708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.35968518257141, "step": 90000}
{"episode_reward": 27.06354766344128, "episode": 91.0, "batch_reward": 0.019834812797605992, "critic_loss": 0.004258423630497418, "actor_loss": -16.037585389375685, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.67617607116699, "step": 91000}
{"episode_reward": 26.281532747552728, "episode": 92.0, "batch_reward": 0.019744478459469975, "critic_loss": 0.0043460982252145185, "actor_loss": -15.703747603416442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.747801542282104, "step": 92000}
{"episode_reward": 26.226017642238233, "episode": 93.0, "batch_reward": 0.019957208630628883, "critic_loss": 0.003624992153607309, "actor_loss": -15.758456568479538, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.330122470855713, "step": 93000}
{"episode_reward": 29.65569348617449, "episode": 94.0, "batch_reward": 0.019934995756484566, "critic_loss": 0.003707319761510007, "actor_loss": -16.272927500009537, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.76180934906006, "step": 94000}
{"episode_reward": 26.0811247621341, "episode": 95.0, "batch_reward": 0.020027066421695053, "critic_loss": 0.003917990671936423, "actor_loss": -16.498471158027648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.3430495262146, "step": 95000}
{"episode_reward": 29.13978531658108, "episode": 96.0, "batch_reward": 0.020406709148548544, "critic_loss": 0.004665990856825374, "actor_loss": -16.22167220377922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.71581244468689, "step": 96000}
{"episode_reward": 28.711815673995186, "episode": 97.0, "batch_reward": 0.020183757211081683, "critic_loss": 0.004182899515959434, "actor_loss": -16.551794966697692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.352123737335205, "step": 97000}
{"episode_reward": 26.326247058793115, "episode": 98.0, "batch_reward": 0.0203261535493657, "critic_loss": 0.003970524684409611, "actor_loss": -15.776766777038574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.66312265396118, "step": 98000}
{"episode_reward": 27.287332239572, "episode": 99.0, "batch_reward": 0.0205775259481743, "critic_loss": 0.0035174742718227206, "actor_loss": -16.530073961496353, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.984062671661377, "step": 99000}
{"episode_reward": 29.39459401586077, "episode": 100.0, "batch_reward": 0.020305658298544586, "critic_loss": 0.0038127589817158877, "actor_loss": -16.228053745746614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.644059658050537, "step": 100000}
{"episode_reward": 20.527394363852384, "episode": 101.0, "batch_reward": 0.02038171017821878, "critic_loss": 0.0038465673924656585, "actor_loss": -16.73381421661377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.68585753440857, "step": 101000}
{"episode_reward": 28.95448121824545, "episode": 102.0, "batch_reward": 0.020426099790260197, "critic_loss": 0.0041462620253441855, "actor_loss": -16.652431092739103, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.823116540908813, "step": 102000}
{"episode_reward": 26.814276637490064, "episode": 103.0, "batch_reward": 0.020785887227393687, "critic_loss": 0.004624281399417668, "actor_loss": -16.154201133966446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.45424509048462, "step": 103000}
{"episode_reward": 22.989001961573305, "episode": 104.0, "batch_reward": 0.02085855490155518, "critic_loss": 0.004004309360869229, "actor_loss": -16.80428141951561, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.638223886489868, "step": 104000}
{"episode_reward": 23.450441038176603, "episode": 105.0, "batch_reward": 0.020725724529474975, "critic_loss": 0.003675997677841224, "actor_loss": -16.049514981031418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.075941562652588, "step": 105000}
{"episode_reward": 28.887642293075544, "episode": 106.0, "batch_reward": 0.020960891790688038, "critic_loss": 0.003532084071659483, "actor_loss": -16.820186937093734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.585699796676636, "step": 106000}
{"episode_reward": 30.043401436644626, "episode": 107.0, "batch_reward": 0.020890540478751062, "critic_loss": 0.0034015138896647842, "actor_loss": -16.387550581932068, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.55315375328064, "step": 107000}
{"episode_reward": 32.5772186460476, "episode": 108.0, "batch_reward": 0.02078799798153341, "critic_loss": 0.003222196447663009, "actor_loss": -15.643915911912918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.265751838684082, "step": 108000}
{"episode_reward": 13.655992593665712, "episode": 109.0, "batch_reward": 0.020996979277580978, "critic_loss": 0.003265615499112755, "actor_loss": -16.858460705280304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.44430112838745, "step": 109000}
{"episode_reward": 12.40449183091894, "episode": 110.0, "batch_reward": 0.020794070321135224, "critic_loss": 0.003552505816332996, "actor_loss": -16.96892829489708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.78228998184204, "step": 110000}
{"episode_reward": 14.899201741000107, "episode": 111.0, "batch_reward": 0.02070506197679788, "critic_loss": 0.004081435552914627, "actor_loss": -15.491994110584258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.868348598480225, "step": 111000}
{"episode_reward": 14.002598533504004, "episode": 112.0, "batch_reward": 0.020803600267507136, "critic_loss": 0.002968146483064629, "actor_loss": -16.968120762825013, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.985527992248535, "step": 112000}
{"episode_reward": 28.122077187980757, "episode": 113.0, "batch_reward": 0.020808434819802643, "critic_loss": 0.003115050891996361, "actor_loss": -16.22679860496521, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.715544939041138, "step": 113000}
{"episode_reward": 28.488368275152396, "episode": 114.0, "batch_reward": 0.02095392499305308, "critic_loss": 0.003518509850371629, "actor_loss": -16.906589767217636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.8976309299469, "step": 114000}
{"episode_reward": 28.935370190406946, "episode": 115.0, "batch_reward": 0.020847346170805393, "critic_loss": 0.006148981128353626, "actor_loss": -16.356414338827133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.060420989990234, "step": 115000}
{"episode_reward": 29.77494784355881, "episode": 116.0, "batch_reward": 0.021117786061018707, "critic_loss": 0.007852473284117877, "actor_loss": -16.737199361801146, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.944833517074585, "step": 116000}
{"episode_reward": 30.05222480206275, "episode": 117.0, "batch_reward": 0.021283828115090726, "critic_loss": 0.009694327158038505, "actor_loss": -15.573722893714905, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.877108812332153, "step": 117000}
{"episode_reward": 29.177550610108746, "episode": 118.0, "batch_reward": 0.0209857055908069, "critic_loss": 0.009632727398187853, "actor_loss": -16.21699719119072, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.59161376953125, "step": 118000}
{"episode_reward": 29.227577842577507, "episode": 119.0, "batch_reward": 0.02107617574092001, "critic_loss": 0.00795331367070321, "actor_loss": -16.418691957950593, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.439165353775024, "step": 119000}
{"episode_reward": 18.669888133812844, "episode": 120.0, "batch_reward": 0.021066057100892068, "critic_loss": 0.011986305253696627, "actor_loss": -15.80768471646309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.75899314880371, "step": 120000}
{"episode_reward": 11.70136986147586, "episode": 121.0, "batch_reward": 0.020991560181602836, "critic_loss": 0.006161241163383238, "actor_loss": -15.637153237581254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.55948042869568, "step": 121000}
{"episode_reward": 13.562081946892643, "episode": 122.0, "batch_reward": 0.021162362021394075, "critic_loss": 0.004919233672088012, "actor_loss": -15.540103346586227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99446392059326, "step": 122000}
{"episode_reward": 13.57288664382978, "episode": 123.0, "batch_reward": 0.020950377496890722, "critic_loss": 0.005070861719083041, "actor_loss": -16.771664832830428, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.484797716140747, "step": 123000}
{"episode_reward": 28.78509700839451, "episode": 124.0, "batch_reward": 0.02098975677974522, "critic_loss": 0.006164950750535354, "actor_loss": -15.96326123905182, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.12872624397278, "step": 124000}
{"episode_reward": 29.625393684429696, "episode": 125.0, "batch_reward": 0.021239562078379095, "critic_loss": 0.009771990249864757, "actor_loss": -16.186410670995713, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.164493799209595, "step": 125000}
{"episode_reward": 25.77404722572905, "episode": 126.0, "batch_reward": 0.021229363163933156, "critic_loss": 0.007460617587901652, "actor_loss": -15.41039900445938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.204803228378296, "step": 126000}
{"episode_reward": 29.016067315392018, "episode": 127.0, "batch_reward": 0.021090214971452952, "critic_loss": 0.005935613699490205, "actor_loss": -16.057293689727782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.912372589111328, "step": 127000}
{"episode_reward": 14.441068732453996, "episode": 128.0, "batch_reward": 0.02089204096235335, "critic_loss": 0.007018349656136707, "actor_loss": -16.002507491350173, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.582103490829468, "step": 128000}
{"episode_reward": 26.78206226649646, "episode": 129.0, "batch_reward": 0.021442430885508658, "critic_loss": 0.011262413488584571, "actor_loss": -15.347927118301392, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.498992204666138, "step": 129000}
{"episode_reward": 23.319227159887674, "episode": 130.0, "batch_reward": 0.021042944494634865, "critic_loss": 0.0063843316857237365, "actor_loss": -15.440100635409355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.43233299255371, "step": 130000}
{"episode_reward": 22.023181651836243, "episode": 131.0, "batch_reward": 0.021251818230375648, "critic_loss": 0.005324150713859126, "actor_loss": -15.832821164488793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.04559540748596, "step": 131000}
{"episode_reward": 26.11638778513302, "episode": 132.0, "batch_reward": 0.021319365059956907, "critic_loss": 0.006894611970055848, "actor_loss": -16.826820319890977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.956258058547974, "step": 132000}
{"episode_reward": 24.361339340792497, "episode": 133.0, "batch_reward": 0.020996633740141987, "critic_loss": 0.006781308389268816, "actor_loss": -15.760926613211632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.794143438339233, "step": 133000}
{"episode_reward": 22.363886284963577, "episode": 134.0, "batch_reward": 0.0213586104279384, "critic_loss": 0.006799777520354837, "actor_loss": -14.870707548499107, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.288816213607788, "step": 134000}
{"episode_reward": 24.608323628195873, "episode": 135.0, "batch_reward": 0.021277935137040915, "critic_loss": 0.005389819120406173, "actor_loss": -16.560187628269194, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.19855785369873, "step": 135000}
{"episode_reward": 24.836612700755325, "episode": 136.0, "batch_reward": 0.02123480861261487, "critic_loss": 0.004866989235975779, "actor_loss": -13.920858645319939, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.58109140396118, "step": 136000}
{"episode_reward": 27.366168118558914, "episode": 137.0, "batch_reward": 0.02137875750660896, "critic_loss": 0.004702053864020854, "actor_loss": -15.831291016578675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.8725004196167, "step": 137000}
{"episode_reward": 16.888353889839067, "episode": 138.0, "batch_reward": 0.02135291418712586, "critic_loss": 0.004512504332582466, "actor_loss": -15.673382087945939, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.24740767478943, "step": 138000}
{"episode_reward": 27.572342958324953, "episode": 139.0, "batch_reward": 0.021392717407085003, "critic_loss": 0.004443157216068357, "actor_loss": -15.68835676074028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.031559228897095, "step": 139000}
{"episode_reward": 27.836059904810707, "episode": 140.0, "batch_reward": 0.021393217004835607, "critic_loss": 0.004117296351236291, "actor_loss": -15.71586645746231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.42250394821167, "step": 140000}
{"episode_reward": 30.817464614849353, "episode": 141.0, "batch_reward": 0.021768841789104043, "critic_loss": 0.0041042716153897344, "actor_loss": -16.10981457400322, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.57911825180054, "step": 141000}
{"episode_reward": 13.569401915304613, "episode": 142.0, "batch_reward": 0.021471640785224736, "critic_loss": 0.004108054751995951, "actor_loss": -14.889553973197938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.138710975646973, "step": 142000}
{"episode_reward": 10.412635584918377, "episode": 143.0, "batch_reward": 0.02158217927720398, "critic_loss": 0.00417170858324971, "actor_loss": -14.926863817691803, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.84577775001526, "step": 143000}
{"episode_reward": 18.456507998010448, "episode": 144.0, "batch_reward": 0.021303284971043467, "critic_loss": 0.004181133726960979, "actor_loss": -15.864119875669479, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.645244598388672, "step": 144000}
{"episode_reward": 27.619440016637025, "episode": 145.0, "batch_reward": 0.021261361985467374, "critic_loss": 0.004103713303455152, "actor_loss": -16.033919903993606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.392406225204468, "step": 145000}
{"episode_reward": 28.187208826092874, "episode": 146.0, "batch_reward": 0.021545485217124224, "critic_loss": 0.004212296604178846, "actor_loss": -16.2901962556839, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.630332231521606, "step": 146000}
{"episode_reward": 26.085636133421787, "episode": 147.0, "batch_reward": 0.02130076802149415, "critic_loss": 0.00578459639439825, "actor_loss": -15.850126969814301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.5730721950531, "step": 147000}
{"episode_reward": 25.235034596566397, "episode": 148.0, "batch_reward": 0.02148972601722926, "critic_loss": 0.00822487693093717, "actor_loss": -15.911331944704056, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.460495948791504, "step": 148000}
{"episode_reward": 21.406504984962623, "episode": 149.0, "batch_reward": 0.021531964543275536, "critic_loss": 0.006222335377708077, "actor_loss": -15.57775728559494, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.219404697418213, "step": 149000}
{"episode_reward": 25.93514519139184, "episode": 150.0, "batch_reward": 0.021917292713187635, "critic_loss": 0.005466516485437751, "actor_loss": -16.24600731372833, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
