{"episode_reward": 0.0, "episode": 1.0, "duration": 17.73859739303589, "step": 1000}
{"episode_reward": 4.231880753996205, "episode": 2.0, "duration": 1.5322308540344238, "step": 2000}
{"episode_reward": 395.1450543749875, "episode": 3.0, "batch_reward": 0.18721398614314685, "critic_loss": 0.019693188552417685, "actor_loss": -14.468217940682791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 70.57248544692993, "step": 3000}
{"episode_reward": 2.2733982655680327, "episode": 4.0, "batch_reward": 0.11639364006370306, "critic_loss": 0.01017880134214647, "actor_loss": -13.353717288970948, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.385045289993286, "step": 4000}
{"episode_reward": 2.415625908771457, "episode": 5.0, "batch_reward": 0.09112498275190592, "critic_loss": 0.013207620740868151, "actor_loss": -13.683662486076354, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.44242262840271, "step": 5000}
{"episode_reward": 3.4994728560970145, "episode": 6.0, "batch_reward": 0.07496359678357839, "critic_loss": 0.011405601396691055, "actor_loss": -11.857127272605895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.652961492538452, "step": 6000}
{"episode_reward": 3.1099256745186983, "episode": 7.0, "batch_reward": 0.06408844060637056, "critic_loss": 0.011556344617391006, "actor_loss": -11.397896787166596, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.77699065208435, "step": 7000}
{"episode_reward": 2.832411850957753, "episode": 8.0, "batch_reward": 0.05601180165074766, "critic_loss": 0.018116619937121867, "actor_loss": -12.186674447059632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.442792177200317, "step": 8000}
{"episode_reward": 7.289818313654402, "episode": 9.0, "batch_reward": 0.04951128077879548, "critic_loss": 0.016100691128289327, "actor_loss": -11.945686388969422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.297873497009277, "step": 9000}
{"episode_reward": 4.831094404067021, "episode": 10.0, "batch_reward": 0.045456432504579425, "critic_loss": 0.017161268750671296, "actor_loss": -12.243706961631775, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.375847339630127, "step": 10000}
{"episode_reward": 4.134653767996874, "episode": 11.0, "batch_reward": 0.041092104451730845, "critic_loss": 0.015413431289372965, "actor_loss": -10.758711613655091, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.32729148864746, "step": 11000}
{"episode_reward": 4.520795998018375, "episode": 12.0, "batch_reward": 0.03834950886014849, "critic_loss": 0.020065551165258513, "actor_loss": -11.789825791835785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.04804491996765, "step": 12000}
{"episode_reward": 4.400110086686338, "episode": 13.0, "batch_reward": 0.035694996518082917, "critic_loss": 0.014948716248152777, "actor_loss": -10.161958144664764, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.17191171646118, "step": 13000}
{"episode_reward": 4.64047649456317, "episode": 14.0, "batch_reward": 0.03262612296734005, "critic_loss": 0.01321986925881356, "actor_loss": -10.155890068531036, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.00581121444702, "step": 14000}
{"episode_reward": 3.8232801380630086, "episode": 15.0, "batch_reward": 0.031077734113670884, "critic_loss": 0.010418656681780703, "actor_loss": -8.479580464839936, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.063687801361084, "step": 15000}
{"episode_reward": 4.772623865214232, "episode": 16.0, "batch_reward": 0.029037032739259304, "critic_loss": 0.011078540512127802, "actor_loss": -11.29936620926857, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.7447988986969, "step": 16000}
{"episode_reward": 5.743361628156864, "episode": 17.0, "batch_reward": 0.027714161123149096, "critic_loss": 0.009078301503555848, "actor_loss": -11.287413024663925, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.97893238067627, "step": 17000}
{"episode_reward": 4.5709119360171915, "episode": 18.0, "batch_reward": 0.026255003791302443, "critic_loss": 0.009878588557126932, "actor_loss": -10.564244646787644, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.54756760597229, "step": 18000}
{"episode_reward": 3.9096736521633892, "episode": 19.0, "batch_reward": 0.02570045098895207, "critic_loss": 0.00902944447263144, "actor_loss": -10.603661548614502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.417245864868164, "step": 19000}
{"episode_reward": 3.782535250819288, "episode": 20.0, "batch_reward": 0.024529651421122255, "critic_loss": 0.008862578260013833, "actor_loss": -9.369441041946411, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.29324960708618, "step": 20000}
{"episode_reward": 4.08835389280446, "episode": 21.0, "batch_reward": 0.02280179736902937, "critic_loss": 0.00685802700970089, "actor_loss": -9.947460897922516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.36764168739319, "step": 21000}
{"episode_reward": 4.909884151092771, "episode": 22.0, "batch_reward": 0.022150788847822695, "critic_loss": 0.008729713836160955, "actor_loss": -8.815483753442765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.047839641571045, "step": 22000}
{"episode_reward": 4.4223473205664385, "episode": 23.0, "batch_reward": 0.02156161495205015, "critic_loss": 0.006033613848267123, "actor_loss": -9.403839533090592, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.871891021728516, "step": 23000}
{"episode_reward": 3.8052672387423154, "episode": 24.0, "batch_reward": 0.020974900133907796, "critic_loss": 0.007093315471604001, "actor_loss": -8.719364961862563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.88790535926819, "step": 24000}
{"episode_reward": 4.977158909499923, "episode": 25.0, "batch_reward": 0.020154090099502354, "critic_loss": 0.005123421310767299, "actor_loss": -9.062616834402084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.937776803970337, "step": 25000}
{"episode_reward": 4.873816258890923, "episode": 26.0, "batch_reward": 0.019928153870627283, "critic_loss": 0.005080150617257459, "actor_loss": -9.078330757141114, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.44735598564148, "step": 26000}
{"episode_reward": 4.321652859175804, "episode": 27.0, "batch_reward": 0.019309407221153378, "critic_loss": 0.0047681866638595236, "actor_loss": -8.711710292577743, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.969792127609253, "step": 27000}
{"episode_reward": 4.773260747913891, "episode": 28.0, "batch_reward": 0.01806680816807784, "critic_loss": 0.005566396810143487, "actor_loss": -9.099259366750717, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.6718533039093, "step": 28000}
{"episode_reward": 4.6606379283070485, "episode": 29.0, "batch_reward": 0.017668539963662626, "critic_loss": 0.0038641714889963625, "actor_loss": -7.586598305821418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.121338367462158, "step": 29000}
{"episode_reward": 4.228595186768957, "episode": 30.0, "batch_reward": 0.017846992372302337, "critic_loss": 0.006352880116988672, "actor_loss": -9.128279376506805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.364063501358032, "step": 30000}
{"episode_reward": 5.4893808724420134, "episode": 31.0, "batch_reward": 0.017050332118058578, "critic_loss": 0.004558438934996957, "actor_loss": -9.324674586057663, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.50122356414795, "step": 31000}
{"episode_reward": 4.6641987549734045, "episode": 32.0, "batch_reward": 0.016717768422560765, "critic_loss": 0.005451086279615993, "actor_loss": -8.65888298881054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.442423582077026, "step": 32000}
{"episode_reward": 3.637836571799106, "episode": 33.0, "batch_reward": 0.01670092728943564, "critic_loss": 0.004764562728523742, "actor_loss": -8.078467083096504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.533478498458862, "step": 33000}
{"episode_reward": 4.3165621819541204, "episode": 34.0, "batch_reward": 0.01586092346534133, "critic_loss": 0.0031517063956125638, "actor_loss": -9.219527822256088, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.6029155254364, "step": 34000}
{"episode_reward": 4.764609647044237, "episode": 35.0, "batch_reward": 0.015608524854527786, "critic_loss": 0.0029927472310955637, "actor_loss": -8.274740886569024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.57246470451355, "step": 35000}
{"episode_reward": 4.296141568254454, "episode": 36.0, "batch_reward": 0.015331625571707263, "critic_loss": 0.0037225232927303297, "actor_loss": -8.748436863422393, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.380278825759888, "step": 36000}
{"episode_reward": 5.215747202804245, "episode": 37.0, "batch_reward": 0.015040758069837465, "critic_loss": 0.0024518932907376437, "actor_loss": -8.969773576617241, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.83393359184265, "step": 37000}
{"episode_reward": 4.008250470124999, "episode": 38.0, "batch_reward": 0.014815321011003107, "critic_loss": 0.00351623145796475, "actor_loss": -7.655566371560097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.30626392364502, "step": 38000}
{"episode_reward": 4.257432434179255, "episode": 39.0, "batch_reward": 0.014719012379413471, "critic_loss": 0.003768227830325486, "actor_loss": -8.282719180703163, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.592174530029297, "step": 39000}
{"episode_reward": 3.7855097251501393, "episode": 40.0, "batch_reward": 0.014058338048867882, "critic_loss": 0.00428846272607916, "actor_loss": -8.764097854495049, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.039254426956177, "step": 40000}
{"episode_reward": 3.358615671251119, "episode": 41.0, "batch_reward": 0.014028939261101186, "critic_loss": 0.0027433523331128525, "actor_loss": -9.10882002556324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.34368109703064, "step": 41000}
{"episode_reward": 5.665038121501667, "episode": 42.0, "batch_reward": 0.013710451593389735, "critic_loss": 0.0036423036431660876, "actor_loss": -8.643654518842697, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.112281799316406, "step": 42000}
{"episode_reward": 3.885176604672477, "episode": 43.0, "batch_reward": 0.013372645600233227, "critic_loss": 0.003388108586703311, "actor_loss": -8.82624238216877, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.508927822113037, "step": 43000}
{"episode_reward": 3.4530511447787866, "episode": 44.0, "batch_reward": 0.013073265412589534, "critic_loss": 0.0024141313447180435, "actor_loss": -8.624411336779595, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.480682373046875, "step": 44000}
{"episode_reward": 4.396727066240988, "episode": 45.0, "batch_reward": 0.01304967919830233, "critic_loss": 0.0030981222082918976, "actor_loss": -7.941800431966781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.327874660491943, "step": 45000}
{"episode_reward": 4.646445080135698, "episode": 46.0, "batch_reward": 0.012962534843944013, "critic_loss": 0.0029517746780475134, "actor_loss": -8.433213774085045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.345556020736694, "step": 46000}
{"episode_reward": 4.384624077814405, "episode": 47.0, "batch_reward": 0.012737093164818362, "critic_loss": 0.002991261915609357, "actor_loss": -9.203263081848622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.052223205566406, "step": 47000}
{"episode_reward": 4.155303611625572, "episode": 48.0, "batch_reward": 0.012476416158024221, "critic_loss": 0.0026952731135388604, "actor_loss": -7.626318562209606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.39466643333435, "step": 48000}
{"episode_reward": 4.049917442776224, "episode": 49.0, "batch_reward": 0.012685612785164268, "critic_loss": 0.00344340546336025, "actor_loss": -8.08258306491375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.682711124420166, "step": 49000}
{"episode_reward": 4.885574119667428, "episode": 50.0, "batch_reward": 0.012340591105632483, "critic_loss": 0.0031709907955955715, "actor_loss": -8.509817069649696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.043805599212646, "step": 50000}
{"episode_reward": 4.970710303917491, "episode": 51.0, "batch_reward": 0.01210900707426481, "critic_loss": 0.0022561999669851503, "actor_loss": -6.8979331603646274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.48060441017151, "step": 51000}
{"episode_reward": 4.5578117027248854, "episode": 52.0, "batch_reward": 0.012073743690969422, "critic_loss": 0.0021044203294732144, "actor_loss": -8.530393193483352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.805938720703125, "step": 52000}
{"episode_reward": 4.895404890843018, "episode": 53.0, "batch_reward": 0.01192233310593292, "critic_loss": 0.002662710981850978, "actor_loss": -7.131592144846916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.87118625640869, "step": 53000}
{"episode_reward": 4.148798849099568, "episode": 54.0, "batch_reward": 0.011975096648326144, "critic_loss": 0.0021312482576031472, "actor_loss": -8.187553078114986, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.633450031280518, "step": 54000}
{"episode_reward": 4.807626745623708, "episode": 55.0, "batch_reward": 0.011449823327129707, "critic_loss": 0.0021734811828209785, "actor_loss": -8.356982889950276, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.95886731147766, "step": 55000}
{"episode_reward": 4.7857173118658185, "episode": 56.0, "batch_reward": 0.011291399246547372, "critic_loss": 0.0024524833143514117, "actor_loss": -7.578692330479622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.719117403030396, "step": 56000}
{"episode_reward": 4.228853153373737, "episode": 57.0, "batch_reward": 0.01137835401087068, "critic_loss": 0.0022347289992758305, "actor_loss": -8.031582526683808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.867791652679443, "step": 57000}
{"episode_reward": 3.6227340311591254, "episode": 58.0, "batch_reward": 0.011191146834054961, "critic_loss": 0.0028125864031462696, "actor_loss": -7.254630669355392, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.52456307411194, "step": 58000}
{"episode_reward": 4.85948841852442, "episode": 59.0, "batch_reward": 0.010892494327155873, "critic_loss": 0.0020315587134537056, "actor_loss": -7.753752801299095, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.390257120132446, "step": 59000}
{"episode_reward": 4.997529102188104, "episode": 60.0, "batch_reward": 0.011005159324733541, "critic_loss": 0.0018446095062536188, "actor_loss": -8.420400416374207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.622188091278076, "step": 60000}
{"episode_reward": 4.418648449563399, "episode": 61.0, "batch_reward": 0.010714652331545949, "critic_loss": 0.001858240379820927, "actor_loss": -8.03307361060381, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.04603099822998, "step": 61000}
{"episode_reward": 4.979578544346495, "episode": 62.0, "batch_reward": 0.010447903900407255, "critic_loss": 0.0018623711934196764, "actor_loss": -6.982511344790459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.85151958465576, "step": 62000}
{"episode_reward": 4.423228237918383, "episode": 63.0, "batch_reward": 0.010543535049073398, "critic_loss": 0.0020990211678727066, "actor_loss": -6.820835404157639, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.714454650878906, "step": 63000}
{"episode_reward": 4.628241855615735, "episode": 64.0, "batch_reward": 0.010405635579489172, "critic_loss": 0.0018045933238900033, "actor_loss": -7.887084092974662, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.39829659461975, "step": 64000}
{"episode_reward": 5.170319901408445, "episode": 65.0, "batch_reward": 0.010557069008238613, "critic_loss": 0.0017874153222001042, "actor_loss": -7.527020486354828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.33499765396118, "step": 65000}
{"episode_reward": 4.9696278277171375, "episode": 66.0, "batch_reward": 0.010193422675598413, "critic_loss": 0.002366497272858396, "actor_loss": -7.870603528290987, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.280129432678223, "step": 66000}
{"episode_reward": 3.683951245465771, "episode": 67.0, "batch_reward": 0.010167818595422432, "critic_loss": 0.0018354490456185886, "actor_loss": -7.392862544417381, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.704447746276855, "step": 67000}
{"episode_reward": 4.161537278540899, "episode": 68.0, "batch_reward": 0.010291812875075267, "critic_loss": 0.0023862886876595438, "actor_loss": -7.806152331680059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.031821727752686, "step": 68000}
{"episode_reward": 3.525237310256129, "episode": 69.0, "batch_reward": 0.01023703259555623, "critic_loss": 0.0016786606652458432, "actor_loss": -7.487227235913276, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.624034643173218, "step": 69000}
{"episode_reward": 4.670350796483153, "episode": 70.0, "batch_reward": 0.00993584079039283, "critic_loss": 0.0016209626308191219, "actor_loss": -8.408283057957888, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.650108814239502, "step": 70000}
{"episode_reward": 4.500874963136312, "episode": 71.0, "batch_reward": 0.009949841844383626, "critic_loss": 0.002479649531058385, "actor_loss": -7.378847148507833, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.950860023498535, "step": 71000}
{"episode_reward": 4.4976846013518585, "episode": 72.0, "batch_reward": 0.009785581616451964, "critic_loss": 0.0017446329037629766, "actor_loss": -7.8303033967018125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.025388956069946, "step": 72000}
{"episode_reward": 3.9946909583738144, "episode": 73.0, "batch_reward": 0.009850584113737569, "critic_loss": 0.0020511279850179563, "actor_loss": -7.870087615370751, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.565860986709595, "step": 73000}
{"episode_reward": 4.838495312394427, "episode": 74.0, "batch_reward": 0.009667986014159396, "critic_loss": 0.001773306492701522, "actor_loss": -8.37245552149415, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.876545667648315, "step": 74000}
{"episode_reward": 4.247882392119268, "episode": 75.0, "batch_reward": 0.009836460610153154, "critic_loss": 0.0019403340509015835, "actor_loss": -8.166951165944338, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.428765773773193, "step": 75000}
{"episode_reward": 3.4883446048416245, "episode": 76.0, "batch_reward": 0.009430482525611296, "critic_loss": 0.001307531342295988, "actor_loss": -8.554954612761735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.121681928634644, "step": 76000}
{"episode_reward": 3.713392347420446, "episode": 77.0, "batch_reward": 0.009302403021138161, "critic_loss": 0.0015480041641276329, "actor_loss": -7.151568300038576, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.977917671203613, "step": 77000}
{"episode_reward": 5.479836583065036, "episode": 78.0, "batch_reward": 0.009527257502544672, "critic_loss": 0.0017479863876724267, "actor_loss": -7.277057997614145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.782548666000366, "step": 78000}
{"episode_reward": 4.756256012170224, "episode": 79.0, "batch_reward": 0.009266500764293596, "critic_loss": 0.001568979723364464, "actor_loss": -7.147894217193127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.040354251861572, "step": 79000}
{"episode_reward": 3.714558184701108, "episode": 80.0, "batch_reward": 0.00928082605660893, "critic_loss": 0.0021247306791556185, "actor_loss": -8.119434066832065, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.064283847808838, "step": 80000}
{"episode_reward": 4.682661163985689, "episode": 81.0, "batch_reward": 0.009346369545906782, "critic_loss": 0.0015517334307660348, "actor_loss": -7.522823741137981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.57276797294617, "step": 81000}
{"episode_reward": 5.303963965733854, "episode": 82.0, "batch_reward": 0.00903993099136278, "critic_loss": 0.0015344057188995065, "actor_loss": -7.665130838572979, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.906151056289673, "step": 82000}
{"episode_reward": 4.624952131694436, "episode": 83.0, "batch_reward": 0.009037011843873188, "critic_loss": 0.0018460638598626247, "actor_loss": -8.159161708682776, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.794513940811157, "step": 83000}
{"episode_reward": 3.65457303905195, "episode": 84.0, "batch_reward": 0.008811397293582558, "critic_loss": 0.0016836422971537104, "actor_loss": -8.153639713197947, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.133561611175537, "step": 84000}
{"episode_reward": 4.073488088736481, "episode": 85.0, "batch_reward": 0.009245007905643433, "critic_loss": 0.0020711230469387374, "actor_loss": -7.084515750616789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.554863691329956, "step": 85000}
{"episode_reward": 4.243368878087128, "episode": 86.0, "batch_reward": 0.009019060384947807, "critic_loss": 0.002515094323862286, "actor_loss": -8.360968306347727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.81030535697937, "step": 86000}
{"episode_reward": 5.4363525820236065, "episode": 87.0, "batch_reward": 0.00918887650128454, "critic_loss": 0.0014429995081591187, "actor_loss": -8.036009315341712, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.56779980659485, "step": 87000}
{"episode_reward": 4.368290241230555, "episode": 88.0, "batch_reward": 0.009060927910031751, "critic_loss": 0.001716374276787974, "actor_loss": -8.053498637408017, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.09173583984375, "step": 88000}
{"episode_reward": 4.703168980280797, "episode": 89.0, "batch_reward": 0.008876074841246008, "critic_loss": 0.001812216195387009, "actor_loss": -7.73463524377346, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.109000205993652, "step": 89000}
{"episode_reward": 4.80263245975621, "episode": 90.0, "batch_reward": 0.008662939542206004, "critic_loss": 0.0019477716205801698, "actor_loss": -7.214894734814763, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.99138045310974, "step": 90000}
{"episode_reward": 4.268033361292713, "episode": 91.0, "batch_reward": 0.008735326438210905, "critic_loss": 0.0025301818931257004, "actor_loss": -7.263280832394957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.827292919158936, "step": 91000}
{"episode_reward": 3.844892962962813, "episode": 92.0, "batch_reward": 0.008623326611705125, "critic_loss": 0.0013260665909692762, "actor_loss": -7.867607105821371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.433929681777954, "step": 92000}
{"episode_reward": 4.071620530794886, "episode": 93.0, "batch_reward": 0.008661384950391949, "critic_loss": 0.001193313685209432, "actor_loss": -7.750633937552571, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.959586143493652, "step": 93000}
{"episode_reward": 4.505086559583248, "episode": 94.0, "batch_reward": 0.008435638387687504, "critic_loss": 0.002301906000531744, "actor_loss": -7.854455883800983, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.96604299545288, "step": 94000}
{"episode_reward": 4.19763829240998, "episode": 95.0, "batch_reward": 0.00850392469484359, "critic_loss": 0.0012061489094412536, "actor_loss": -6.481602719128132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.386802911758423, "step": 95000}
{"episode_reward": 5.644069916190122, "episode": 96.0, "batch_reward": 0.00850936842779629, "critic_loss": 0.002102435217348102, "actor_loss": -9.016772498458623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.070825815200806, "step": 96000}
{"episode_reward": 5.477282658296862, "episode": 97.0, "batch_reward": 0.008369869692251087, "critic_loss": 0.0018302475182281341, "actor_loss": -8.095921680048107, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.945051193237305, "step": 97000}
{"episode_reward": 3.897005040798887, "episode": 98.0, "batch_reward": 0.008353170918067917, "critic_loss": 0.0015585510048476863, "actor_loss": -6.922110762208701, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.91948628425598, "step": 98000}
{"episode_reward": 4.896731147255296, "episode": 99.0, "batch_reward": 0.008503451109863818, "critic_loss": 0.0018262847064033849, "actor_loss": -8.950686950281263, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.04924726486206, "step": 99000}
{"episode_reward": 3.935141906125698, "episode": 100.0, "batch_reward": 0.008219802866922692, "critic_loss": 0.0016790726479157456, "actor_loss": -8.188809208005667, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.387503385543823, "step": 100000}
{"episode_reward": 4.201141774590166, "episode": 101.0, "batch_reward": 0.008204719997476786, "critic_loss": 0.0013935600809636525, "actor_loss": -8.686300013586878, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.24652862548828, "step": 101000}
{"episode_reward": 3.9828694113177363, "episode": 102.0, "batch_reward": 0.0081182398237288, "critic_loss": 0.0016604034014089848, "actor_loss": -8.124685827165843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.22265100479126, "step": 102000}
{"episode_reward": 3.8893316467380763, "episode": 103.0, "batch_reward": 0.00833975699590519, "critic_loss": 0.0013940870494552654, "actor_loss": -7.922814318820834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.03614854812622, "step": 103000}
{"episode_reward": 3.5574548940733766, "episode": 104.0, "batch_reward": 0.008410467852372676, "critic_loss": 0.0012765207895135972, "actor_loss": -8.22439146323502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.354186296463013, "step": 104000}
{"episode_reward": 3.887113238684938, "episode": 105.0, "batch_reward": 0.008067265685647727, "critic_loss": 0.0017649466016082442, "actor_loss": -8.20805088353157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.41082000732422, "step": 105000}
{"episode_reward": 3.6473644158925924, "episode": 106.0, "batch_reward": 0.008210920309647918, "critic_loss": 0.0014439685579636717, "actor_loss": -8.820036234110594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.546393394470215, "step": 106000}
{"episode_reward": 5.289892757719342, "episode": 107.0, "batch_reward": 0.008036419722484424, "critic_loss": 0.0013130225665227045, "actor_loss": -8.70604452048242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.95068335533142, "step": 107000}
{"episode_reward": 5.260704880165863, "episode": 108.0, "batch_reward": 0.007825180245563388, "critic_loss": 0.0014485674178795307, "actor_loss": -7.279050763040781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.01487922668457, "step": 108000}
{"episode_reward": 4.655924475277735, "episode": 109.0, "batch_reward": 0.008011744990712031, "critic_loss": 0.0014548157630924834, "actor_loss": -8.257067282304167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.925297498703003, "step": 109000}
{"episode_reward": 3.9197327487131615, "episode": 110.0, "batch_reward": 0.007841636922908946, "critic_loss": 0.0013262124016364396, "actor_loss": -8.496893502146005, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.059741020202637, "step": 110000}
{"episode_reward": 5.074613659145324, "episode": 111.0, "batch_reward": 0.007946597025264054, "critic_loss": 0.001159276141486771, "actor_loss": -7.033420919135213, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.462446212768555, "step": 111000}
{"episode_reward": 5.261766729519938, "episode": 112.0, "batch_reward": 0.007984012603526935, "critic_loss": 0.0017075699513516157, "actor_loss": -8.910532920494676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.527642488479614, "step": 112000}
{"episode_reward": 3.879492116155549, "episode": 113.0, "batch_reward": 0.007946049438323825, "critic_loss": 0.0017111620129362565, "actor_loss": -8.14606178741157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.111692667007446, "step": 113000}
{"episode_reward": 4.6596161537568275, "episode": 114.0, "batch_reward": 0.007915917176753282, "critic_loss": 0.0014637609687779332, "actor_loss": -8.297087954506278, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.374806880950928, "step": 114000}
{"episode_reward": 4.675433405038777, "episode": 115.0, "batch_reward": 0.007698187495348975, "critic_loss": 0.0017598277511497145, "actor_loss": -7.888411786511541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.613168716430664, "step": 115000}
{"episode_reward": 5.054479097138075, "episode": 116.0, "batch_reward": 0.007755338822724298, "critic_loss": 0.0013565397704223868, "actor_loss": -7.511851211696863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.08959436416626, "step": 116000}
{"episode_reward": 5.47836727998652, "episode": 117.0, "batch_reward": 0.008070300969062373, "critic_loss": 0.0018612818930487266, "actor_loss": -6.776386439427734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.33445167541504, "step": 117000}
{"episode_reward": 5.164542026713802, "episode": 118.0, "batch_reward": 0.007677806264953688, "critic_loss": 0.001420786596951075, "actor_loss": -7.366411138772964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.17776584625244, "step": 118000}
{"episode_reward": 4.233145921312438, "episode": 119.0, "batch_reward": 0.0076437458151485775, "critic_loss": 0.0013453511895349947, "actor_loss": -7.5675876275897025, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.758965730667114, "step": 119000}
{"episode_reward": 4.61405505462251, "episode": 120.0, "batch_reward": 0.007632992403814569, "critic_loss": 0.0016402735054216464, "actor_loss": -6.752490204840899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.956108570098877, "step": 120000}
{"episode_reward": 4.403956696718225, "episode": 121.0, "batch_reward": 0.007668489496223629, "critic_loss": 0.0010903035473602358, "actor_loss": -7.988815759330988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.85793972015381, "step": 121000}
{"episode_reward": 3.977958653158053, "episode": 122.0, "batch_reward": 0.007665698345983401, "critic_loss": 0.0017090536589821567, "actor_loss": -7.672148722082376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.76409602165222, "step": 122000}
{"episode_reward": 5.329257795207205, "episode": 123.0, "batch_reward": 0.007451232612365857, "critic_loss": 0.001287256050229189, "actor_loss": -7.969206700012088, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.923650979995728, "step": 123000}
{"episode_reward": 4.7365067612722, "episode": 124.0, "batch_reward": 0.00760035043885, "critic_loss": 0.0012147983574832325, "actor_loss": -8.263246296733618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.12296199798584, "step": 124000}
{"episode_reward": 5.055730484743039, "episode": 125.0, "batch_reward": 0.007626904132543131, "critic_loss": 0.0012338392896563163, "actor_loss": -7.823621702834964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.346697092056274, "step": 125000}
{"episode_reward": 4.6877688962769195, "episode": 126.0, "batch_reward": 0.007691345351515338, "critic_loss": 0.0015473542199470102, "actor_loss": -7.2113984383940695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.949472188949585, "step": 126000}
{"episode_reward": 4.464118569002554, "episode": 127.0, "batch_reward": 0.0075457992686424405, "critic_loss": 0.0013000624688211245, "actor_loss": -8.419979102388025, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.8211567401886, "step": 127000}
{"episode_reward": 4.533395998342019, "episode": 128.0, "batch_reward": 0.0072159099455457185, "critic_loss": 0.0014571870478903293, "actor_loss": -8.46806501737237, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.40201473236084, "step": 128000}
{"episode_reward": 4.324474475971396, "episode": 129.0, "batch_reward": 0.007605974070262164, "critic_loss": 0.001874600780713081, "actor_loss": -7.7688092299103735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.461841821670532, "step": 129000}
{"episode_reward": 3.922599195232124, "episode": 130.0, "batch_reward": 0.007325576102128252, "critic_loss": 0.001163329071154294, "actor_loss": -7.749041396826506, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.708261251449585, "step": 130000}
{"episode_reward": 4.102103762485432, "episode": 131.0, "batch_reward": 0.007430129695683718, "critic_loss": 0.0013103955770566245, "actor_loss": -7.420668325453996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.18605017662048, "step": 131000}
{"episode_reward": 4.814849750561348, "episode": 132.0, "batch_reward": 0.0073516705515794456, "critic_loss": 0.0014631532529674586, "actor_loss": -7.858365487858653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.998798370361328, "step": 132000}
{"episode_reward": 3.613565487027829, "episode": 133.0, "batch_reward": 0.007220397364115343, "critic_loss": 0.001456279453021125, "actor_loss": -6.739258702382445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.032435655593872, "step": 133000}
{"episode_reward": 3.812778397577727, "episode": 134.0, "batch_reward": 0.007450138716492802, "critic_loss": 0.001721398832531122, "actor_loss": -7.11142706464231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.49979519844055, "step": 134000}
{"episode_reward": 4.629067550689803, "episode": 135.0, "batch_reward": 0.007260163209401071, "critic_loss": 0.0012026597260846757, "actor_loss": -8.209463170766831, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.647624015808105, "step": 135000}
{"episode_reward": 3.846942323038567, "episode": 136.0, "batch_reward": 0.007175444825552404, "critic_loss": 0.0014228285126519041, "actor_loss": -6.531073203220964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.351174116134644, "step": 136000}
{"episode_reward": 4.181724662911637, "episode": 137.0, "batch_reward": 0.00721730036335066, "critic_loss": 0.0010016653242710164, "actor_loss": -7.8989285348057745, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.667500495910645, "step": 137000}
{"episode_reward": 3.71017817564482, "episode": 138.0, "batch_reward": 0.007282450716942549, "critic_loss": 0.0014037534849194345, "actor_loss": -8.347806375816464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.935190200805664, "step": 138000}
{"episode_reward": 4.227135428703222, "episode": 139.0, "batch_reward": 0.007177665667608381, "critic_loss": 0.0013076139652112033, "actor_loss": -7.236909422673285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.691969633102417, "step": 139000}
{"episode_reward": 3.766206397888679, "episode": 140.0, "batch_reward": 0.007088875687215477, "critic_loss": 0.0011026098299480509, "actor_loss": -7.790740266323089, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.728471040725708, "step": 140000}
{"episode_reward": 4.706575169500073, "episode": 141.0, "batch_reward": 0.007321535601979122, "critic_loss": 0.0015409996943490114, "actor_loss": -8.207743837043642, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.51050615310669, "step": 141000}
{"episode_reward": 5.197859702078044, "episode": 142.0, "batch_reward": 0.007167445690138266, "critic_loss": 0.0012066449490812374, "actor_loss": -7.194261528357863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.494606018066406, "step": 142000}
{"episode_reward": 3.7719521845581787, "episode": 143.0, "batch_reward": 0.007257384696276859, "critic_loss": 0.0013105205633546575, "actor_loss": -6.934461822465062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.740455389022827, "step": 143000}
{"episode_reward": 4.962202480170564, "episode": 144.0, "batch_reward": 0.006982725455192849, "critic_loss": 0.0012709041246489505, "actor_loss": -7.692127873376012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.9607937335968, "step": 144000}
{"episode_reward": 4.670256019989664, "episode": 145.0, "batch_reward": 0.007049529794603587, "critic_loss": 0.0011360864756425144, "actor_loss": -8.036611381798982, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.846286296844482, "step": 145000}
{"episode_reward": 4.903295354349064, "episode": 146.0, "batch_reward": 0.007135724841151387, "critic_loss": 0.001061936752317706, "actor_loss": -8.460621173888445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.8686785697937, "step": 146000}
{"episode_reward": 4.151994453898119, "episode": 147.0, "batch_reward": 0.007015648873057216, "critic_loss": 0.0009056301360651559, "actor_loss": -7.636673253104091, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.05791735649109, "step": 147000}
{"episode_reward": 4.4571172815760365, "episode": 148.0, "batch_reward": 0.00712059476855211, "critic_loss": 0.0012289064622018487, "actor_loss": -7.787946760401129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.349409103393555, "step": 148000}
{"episode_reward": 5.248416562976256, "episode": 149.0, "batch_reward": 0.007035505482461304, "critic_loss": 0.0014719345695557422, "actor_loss": -7.582536660403013, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.18131113052368, "step": 149000}
{"episode_reward": 3.5202737482961686, "episode": 150.0, "batch_reward": 0.007333489775424823, "critic_loss": 0.0012206518448365387, "actor_loss": -7.639529305860401, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
