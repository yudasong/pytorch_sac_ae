{"episode_reward": 0.0, "episode": 1.0, "duration": 19.51089906692505, "step": 1000}
{"episode_reward": 4.231880753996205, "episode": 2.0, "duration": 1.6768269538879395, "step": 2000}
{"episode_reward": 395.1450543749875, "episode": 3.0, "batch_reward": 0.18774400824117596, "critic_loss": 0.02226410207977421, "actor_loss": -16.65946247353151, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 67.42906451225281, "step": 3000}
{"episode_reward": 9.59422352938068, "episode": 4.0, "batch_reward": 0.11983251298964023, "critic_loss": 0.01720781080191955, "actor_loss": -13.726593694791198, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.39695119857788, "step": 4000}
{"episode_reward": 8.594969819332992, "episode": 5.0, "batch_reward": 0.0947463194206357, "critic_loss": 0.016878511817194523, "actor_loss": -13.967432616338133, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.690454959869385, "step": 5000}
{"episode_reward": 7.02253187572508, "episode": 6.0, "batch_reward": 0.08438501056656242, "critic_loss": 0.03116823806334287, "actor_loss": -12.612341905042529, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.79301404953003, "step": 6000}
{"episode_reward": 46.14748398219448, "episode": 7.0, "batch_reward": 0.08922295636683703, "critic_loss": 0.039424000487662855, "actor_loss": -12.545447369106114, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.789945125579834, "step": 7000}
{"episode_reward": 143.453454555766, "episode": 8.0, "batch_reward": 0.08615116688236595, "critic_loss": 0.04699402173794806, "actor_loss": -12.795542992651463, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.030889987945557, "step": 8000}
{"episode_reward": 63.736404894776875, "episode": 9.0, "batch_reward": 0.08115999917685986, "critic_loss": 0.05343979288078844, "actor_loss": -13.075940880060196, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.70143437385559, "step": 9000}
{"episode_reward": 22.712544891455774, "episode": 10.0, "batch_reward": 0.07616533932834864, "critic_loss": 0.056106839634478094, "actor_loss": -12.636578288793563, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.899489641189575, "step": 10000}
{"episode_reward": 23.403654371635643, "episode": 11.0, "batch_reward": 0.07219170599803329, "critic_loss": 0.052268952583894135, "actor_loss": -11.129416966438294, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.754769802093506, "step": 11000}
{"episode_reward": 41.391172693656635, "episode": 12.0, "batch_reward": 0.069026902012527, "critic_loss": 0.05753747400455177, "actor_loss": -11.826121449947356, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.356585264205933, "step": 12000}
{"episode_reward": 32.41696056126132, "episode": 13.0, "batch_reward": 0.06778764627873897, "critic_loss": 0.06998664171993732, "actor_loss": -10.747623327732086, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.231696605682373, "step": 13000}
{"episode_reward": 53.41203683207943, "episode": 14.0, "batch_reward": 0.06617725387215614, "critic_loss": 0.0880413210093975, "actor_loss": -10.962067799806595, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.566030025482178, "step": 14000}
{"episode_reward": 65.68171252989335, "episode": 15.0, "batch_reward": 0.06520436511933804, "critic_loss": 0.09159872085601091, "actor_loss": -9.701422027111054, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.8576397895813, "step": 15000}
{"episode_reward": 35.30242250159827, "episode": 16.0, "batch_reward": 0.06303958561643958, "critic_loss": 0.0967997102625668, "actor_loss": -11.844926116943359, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.24230146408081, "step": 16000}
{"episode_reward": 40.154637719192664, "episode": 17.0, "batch_reward": 0.06290531624481081, "critic_loss": 0.11546618631109595, "actor_loss": -11.640795236587524, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.5265896320343, "step": 17000}
{"episode_reward": 67.02857677000891, "episode": 18.0, "batch_reward": 0.06456355160474778, "critic_loss": 0.1342192471921444, "actor_loss": -11.913264267921448, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.174347639083862, "step": 18000}
{"episode_reward": 117.08961277029627, "episode": 19.0, "batch_reward": 0.06849998282641172, "critic_loss": 0.1430497063063085, "actor_loss": -12.403727665424347, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.103951692581177, "step": 19000}
{"episode_reward": 135.40262349051898, "episode": 20.0, "batch_reward": 0.06952381844818592, "critic_loss": 0.13652902145683765, "actor_loss": -11.70077793264389, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.367873907089233, "step": 20000}
{"episode_reward": 48.43839885191878, "episode": 21.0, "batch_reward": 0.06843057074397803, "critic_loss": 0.1485198381729424, "actor_loss": -12.212054936408997, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.29942226409912, "step": 21000}
{"episode_reward": 59.28124035677622, "episode": 22.0, "batch_reward": 0.06747879333049059, "critic_loss": 0.16057495462149382, "actor_loss": -11.1084817070961, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.990930318832397, "step": 22000}
{"episode_reward": 51.26907165317175, "episode": 23.0, "batch_reward": 0.06644210368022323, "critic_loss": 0.1735349260829389, "actor_loss": -11.73033695602417, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.317611694335938, "step": 23000}
{"episode_reward": 34.983594596172736, "episode": 24.0, "batch_reward": 0.06759623085707427, "critic_loss": 0.17531254420429468, "actor_loss": -11.537097204208374, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.089215993881226, "step": 24000}
{"episode_reward": 99.06090347380501, "episode": 25.0, "batch_reward": 0.06709938417002559, "critic_loss": 0.16379708951339125, "actor_loss": -11.838747071743011, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.90079379081726, "step": 25000}
{"episode_reward": 52.277082276914335, "episode": 26.0, "batch_reward": 0.06753200415894389, "critic_loss": 0.19688502088934184, "actor_loss": -12.212046183586121, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.853303909301758, "step": 26000}
{"episode_reward": 97.07767369844997, "episode": 27.0, "batch_reward": 0.07088891473785043, "critic_loss": 0.2385388096347451, "actor_loss": -11.824418135643006, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.994926929473877, "step": 27000}
{"episode_reward": 204.3114919143177, "episode": 28.0, "batch_reward": 0.07377491531148553, "critic_loss": 0.2706703105196357, "actor_loss": -13.10229430770874, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.344342708587646, "step": 28000}
{"episode_reward": 128.40694823495383, "episode": 29.0, "batch_reward": 0.0767663886025548, "critic_loss": 0.26681238182634115, "actor_loss": -12.693483222961426, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.550072193145752, "step": 29000}
{"episode_reward": 149.12775392596575, "episode": 30.0, "batch_reward": 0.08159956621006131, "critic_loss": 0.27016669519245623, "actor_loss": -13.41487929058075, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.008825063705444, "step": 30000}
{"episode_reward": 309.72225256747805, "episode": 31.0, "batch_reward": 0.08663502205908298, "critic_loss": 0.3086920531615615, "actor_loss": -14.567171329498292, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.492475509643555, "step": 31000}
{"episode_reward": 103.25996892063371, "episode": 32.0, "batch_reward": 0.08539589821174741, "critic_loss": 0.2984170041978359, "actor_loss": -14.029282725334168, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.542332649230957, "step": 32000}
{"episode_reward": 42.38259041768041, "episode": 33.0, "batch_reward": 0.08629413578659297, "critic_loss": 0.2628231420814991, "actor_loss": -13.637784587860107, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.808813333511353, "step": 33000}
{"episode_reward": 133.6615067582554, "episode": 34.0, "batch_reward": 0.08575179467350244, "critic_loss": 0.27305741292238234, "actor_loss": -14.308037323951721, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.794294595718384, "step": 34000}
{"episode_reward": 72.90798496686855, "episode": 35.0, "batch_reward": 0.08562818874418736, "critic_loss": 0.268001300573349, "actor_loss": -14.352588624954224, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.561025857925415, "step": 35000}
{"episode_reward": 59.47676144249937, "episode": 36.0, "batch_reward": 0.08742391804233193, "critic_loss": 0.2847150776013732, "actor_loss": -14.425067648887634, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.705399990081787, "step": 36000}
{"episode_reward": 321.29060377607726, "episode": 37.0, "batch_reward": 0.0920348501354456, "critic_loss": 0.31121438390761613, "actor_loss": -14.888572239875794, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.32425856590271, "step": 37000}
{"episode_reward": 111.16530321635113, "episode": 38.0, "batch_reward": 0.09180532589182258, "critic_loss": 0.29930132933706044, "actor_loss": -14.33849462223053, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.867239236831665, "step": 38000}
{"episode_reward": 63.81686663386187, "episode": 39.0, "batch_reward": 0.09459344882145523, "critic_loss": 0.29763309203088284, "actor_loss": -14.796520480155944, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.152603149414062, "step": 39000}
{"episode_reward": 341.7237701300298, "episode": 40.0, "batch_reward": 0.09893196227401495, "critic_loss": 0.3312948389798403, "actor_loss": -15.571046431541443, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.422696828842163, "step": 40000}
{"episode_reward": 195.76469727713604, "episode": 41.0, "batch_reward": 0.1025639366209507, "critic_loss": 0.3058112840652466, "actor_loss": -16.224864727020265, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.475961208343506, "step": 41000}
{"episode_reward": 350.82080164280546, "episode": 42.0, "batch_reward": 0.10905935245007277, "critic_loss": 0.3373692915961146, "actor_loss": -16.386463956832884, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.513680696487427, "step": 42000}
{"episode_reward": 352.9794853621427, "episode": 43.0, "batch_reward": 0.1148936178162694, "critic_loss": 0.28924478083103894, "actor_loss": -16.984230268478395, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.229676246643066, "step": 43000}
{"episode_reward": 355.76811353535453, "episode": 44.0, "batch_reward": 0.11791584932804108, "critic_loss": 0.3296201642230153, "actor_loss": -17.03537141609192, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.541261911392212, "step": 44000}
{"episode_reward": 116.78771697859271, "episode": 45.0, "batch_reward": 0.11977120387554169, "critic_loss": 0.34964803414046763, "actor_loss": -16.882014717102052, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.812822341918945, "step": 45000}
{"episode_reward": 365.3966793210703, "episode": 46.0, "batch_reward": 0.12476391671597957, "critic_loss": 0.3256443821489811, "actor_loss": -17.644613092422485, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.300711393356323, "step": 46000}
{"episode_reward": 327.5764040329532, "episode": 47.0, "batch_reward": 0.12714985295385123, "critic_loss": 0.3573268845975399, "actor_loss": -18.2448183555603, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.379823923110962, "step": 47000}
{"episode_reward": 78.68220371744214, "episode": 48.0, "batch_reward": 0.12793958269804717, "critic_loss": 0.37126107938587666, "actor_loss": -17.66838593864441, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.04365611076355, "step": 48000}
{"episode_reward": 150.8717622813774, "episode": 49.0, "batch_reward": 0.12708608612418174, "critic_loss": 0.3303606267943978, "actor_loss": -17.51800242805481, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.092087030410767, "step": 49000}
{"episode_reward": 45.04027843132164, "episode": 50.0, "batch_reward": 0.12709071877598763, "critic_loss": 0.3936228400170803, "actor_loss": -17.865318281173707, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.80478072166443, "step": 50000}
{"episode_reward": 369.2712916261193, "episode": 51.0, "batch_reward": 0.1316597807481885, "critic_loss": 0.39702512918412686, "actor_loss": -17.319769804000856, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.23962712287903, "step": 51000}
{"episode_reward": 158.3290054553089, "episode": 52.0, "batch_reward": 0.13355010195076467, "critic_loss": 0.37927439396083357, "actor_loss": -18.670932359695435, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.585363626480103, "step": 52000}
{"episode_reward": 370.65846843435065, "episode": 53.0, "batch_reward": 0.13687736155092717, "critic_loss": 0.3954207234829664, "actor_loss": -17.985444757461547, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.79769778251648, "step": 53000}
{"episode_reward": 219.9471356599054, "episode": 54.0, "batch_reward": 0.13912000945955516, "critic_loss": 0.37591356866806747, "actor_loss": -18.973725872039793, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.356863260269165, "step": 54000}
{"episode_reward": 383.171889942927, "episode": 55.0, "batch_reward": 0.1428946005180478, "critic_loss": 0.3538758977800608, "actor_loss": -19.110469421386718, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.174365997314453, "step": 55000}
{"episode_reward": 383.8188221939491, "episode": 56.0, "batch_reward": 0.1473210529386997, "critic_loss": 0.3402364960536361, "actor_loss": -19.01255073928833, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.636679887771606, "step": 56000}
{"episode_reward": 399.72788104912587, "episode": 57.0, "batch_reward": 0.15162586013227702, "critic_loss": 0.357322331443429, "actor_loss": -19.494119152069093, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.24251389503479, "step": 57000}
{"episode_reward": 180.1650766480773, "episode": 58.0, "batch_reward": 0.1528024610131979, "critic_loss": 0.3122446779534221, "actor_loss": -19.421130794525148, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.213342666625977, "step": 58000}
{"episode_reward": 398.1560904304672, "episode": 59.0, "batch_reward": 0.15632478638738395, "critic_loss": 0.33090367962419986, "actor_loss": -20.3412999420166, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.479315757751465, "step": 59000}
{"episode_reward": 385.89873082813216, "episode": 60.0, "batch_reward": 0.1608604313582182, "critic_loss": 0.3548369623795152, "actor_loss": -20.960095722198485, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.410224676132202, "step": 60000}
{"episode_reward": 384.2041692251566, "episode": 61.0, "batch_reward": 0.16467951016128063, "critic_loss": 0.330854773670435, "actor_loss": -20.89098560523987, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.769692182540894, "step": 61000}
{"episode_reward": 378.0666187746444, "episode": 62.0, "batch_reward": 0.16831728404015303, "critic_loss": 0.3524481091797352, "actor_loss": -20.689760496139527, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.11718726158142, "step": 62000}
{"episode_reward": 407.07057233144843, "episode": 63.0, "batch_reward": 0.17101672338694335, "critic_loss": 0.337223700940609, "actor_loss": -20.89519945716858, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.493849754333496, "step": 63000}
{"episode_reward": 399.9612888803127, "episode": 64.0, "batch_reward": 0.17561158818006514, "critic_loss": 0.3392093653678894, "actor_loss": -21.92364732551575, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.324991703033447, "step": 64000}
{"episode_reward": 397.47631726883594, "episode": 65.0, "batch_reward": 0.17893848057091236, "critic_loss": 0.3635769294351339, "actor_loss": -22.179133417129517, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.014170169830322, "step": 65000}
{"episode_reward": 315.7661135965274, "episode": 66.0, "batch_reward": 0.1808719245940447, "critic_loss": 0.3471300224140286, "actor_loss": -22.170319789886474, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.962578773498535, "step": 66000}
{"episode_reward": 387.563583466665, "episode": 67.0, "batch_reward": 0.18440853455662728, "critic_loss": 0.37366324439644816, "actor_loss": -22.55557745552063, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.587891817092896, "step": 67000}
{"episode_reward": 425.31434376487636, "episode": 68.0, "batch_reward": 0.18799003487825394, "critic_loss": 0.3626422055512667, "actor_loss": -23.370304809570314, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.319886684417725, "step": 68000}
{"episode_reward": 416.1954621737256, "episode": 69.0, "batch_reward": 0.1926439411342144, "critic_loss": 0.3478256067633629, "actor_loss": -23.573368824005126, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.824207305908203, "step": 69000}
{"episode_reward": 401.6641690793286, "episode": 70.0, "batch_reward": 0.19210169427096843, "critic_loss": 0.36713731214404105, "actor_loss": -23.981282875061034, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.73751950263977, "step": 70000}
{"episode_reward": 56.47445164183754, "episode": 71.0, "batch_reward": 0.1916479891985655, "critic_loss": 0.3622316153943539, "actor_loss": -24.09699010848999, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.91765642166138, "step": 71000}
{"episode_reward": 432.99143960869156, "episode": 72.0, "batch_reward": 0.1958487073034048, "critic_loss": 0.364086315125227, "actor_loss": -24.426111686706545, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.21791934967041, "step": 72000}
{"episode_reward": 431.9022536368074, "episode": 73.0, "batch_reward": 0.19873719783127308, "critic_loss": 0.3481081824451685, "actor_loss": -24.74988325881958, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.29426383972168, "step": 73000}
{"episode_reward": 430.6037772484847, "episode": 74.0, "batch_reward": 0.2019388947635889, "critic_loss": 0.36304966312646864, "actor_loss": -25.518901859283446, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.052687883377075, "step": 74000}
{"episode_reward": 417.33437681321095, "episode": 75.0, "batch_reward": 0.20537064135074615, "critic_loss": 0.3769806036502123, "actor_loss": -25.75001549911499, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.59699821472168, "step": 75000}
{"episode_reward": 451.41222081873894, "episode": 76.0, "batch_reward": 0.2086389594823122, "critic_loss": 0.36399743776023386, "actor_loss": -26.30059345626831, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.998903036117554, "step": 76000}
{"episode_reward": 350.6086801494671, "episode": 77.0, "batch_reward": 0.20981868097186088, "critic_loss": 0.35825286220759156, "actor_loss": -25.856033855438234, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.502538442611694, "step": 77000}
{"episode_reward": 424.5473030322187, "episode": 78.0, "batch_reward": 0.21268937343358993, "critic_loss": 0.35549421501904727, "actor_loss": -26.179453174591064, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.828400135040283, "step": 78000}
{"episode_reward": 435.4522831169538, "episode": 79.0, "batch_reward": 0.21562500590085984, "critic_loss": 0.3684870153218508, "actor_loss": -26.364472229003905, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.953304529190063, "step": 79000}
{"episode_reward": 475.8240841652635, "episode": 80.0, "batch_reward": 0.21881540164351462, "critic_loss": 0.3420448063313961, "actor_loss": -26.945060104370118, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.36885714530945, "step": 80000}
{"episode_reward": 416.2840355565153, "episode": 81.0, "batch_reward": 0.222578492552042, "critic_loss": 0.32758931316435336, "actor_loss": -27.001786521911622, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.17020511627197, "step": 81000}
{"episode_reward": 445.30833727934487, "episode": 82.0, "batch_reward": 0.22401882281899452, "critic_loss": 0.3145292347073555, "actor_loss": -27.12673391723633, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.822355031967163, "step": 82000}
{"episode_reward": 447.1378394428208, "episode": 83.0, "batch_reward": 0.2263851273357868, "critic_loss": 0.3167049334645271, "actor_loss": -27.637848094940185, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.334242343902588, "step": 83000}
{"episode_reward": 436.70165362416327, "episode": 84.0, "batch_reward": 0.2292705879509449, "critic_loss": 0.3134480941593647, "actor_loss": -27.90757828140259, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.23795509338379, "step": 84000}
{"episode_reward": 445.00306573419505, "episode": 85.0, "batch_reward": 0.232646780192852, "critic_loss": 0.3096316053122282, "actor_loss": -27.659918155670166, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.761693239212036, "step": 85000}
{"episode_reward": 450.084603775528, "episode": 86.0, "batch_reward": 0.23509568172693251, "critic_loss": 0.3015220932140946, "actor_loss": -28.160726329803467, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.16752338409424, "step": 86000}
{"episode_reward": 434.66534656815145, "episode": 87.0, "batch_reward": 0.2366295222789049, "critic_loss": 0.3143694815188646, "actor_loss": -28.269326095581054, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.220571994781494, "step": 87000}
{"episode_reward": 445.4123868953724, "episode": 88.0, "batch_reward": 0.2399453998953104, "critic_loss": 0.32161364845186474, "actor_loss": -28.726598274230955, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.60611844062805, "step": 88000}
{"episode_reward": 436.35203636225384, "episode": 89.0, "batch_reward": 0.24160285159945488, "critic_loss": 0.31241589120030405, "actor_loss": -28.542549991607665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.42994999885559, "step": 89000}
{"episode_reward": 438.68311357580825, "episode": 90.0, "batch_reward": 0.24324891000986099, "critic_loss": 0.31994137704372405, "actor_loss": -28.787771575927735, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.593217849731445, "step": 90000}
{"episode_reward": 450.3462071898973, "episode": 91.0, "batch_reward": 0.24600803902745247, "critic_loss": 0.295010972186923, "actor_loss": -28.989772270202636, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.68506217002869, "step": 91000}
{"episode_reward": 446.59815994317285, "episode": 92.0, "batch_reward": 0.24797941705584525, "critic_loss": 0.28731269147992133, "actor_loss": -29.21349299621582, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.653376817703247, "step": 92000}
{"episode_reward": 438.0263157587715, "episode": 93.0, "batch_reward": 0.25045183998346326, "critic_loss": 0.27122707840055227, "actor_loss": -29.35901328277588, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.15734624862671, "step": 93000}
{"episode_reward": 417.237990193422, "episode": 94.0, "batch_reward": 0.2524278857707977, "critic_loss": 0.2811884589567781, "actor_loss": -29.82901371002197, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.3818199634552, "step": 94000}
{"episode_reward": 451.4459767311569, "episode": 95.0, "batch_reward": 0.25387476164102557, "critic_loss": 0.2645034032687545, "actor_loss": -29.676717250823973, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.503461837768555, "step": 95000}
{"episode_reward": 440.997213187387, "episode": 96.0, "batch_reward": 0.2564323388636112, "critic_loss": 0.278175790078938, "actor_loss": -30.38007544708252, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.17239737510681, "step": 96000}
{"episode_reward": 464.62816511289367, "episode": 97.0, "batch_reward": 0.2581302393078804, "critic_loss": 0.27290242157876493, "actor_loss": -30.13314828491211, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.874569416046143, "step": 97000}
{"episode_reward": 481.1846172623916, "episode": 98.0, "batch_reward": 0.26078458555042744, "critic_loss": 0.26920164868980645, "actor_loss": -30.20145482635498, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.499324798583984, "step": 98000}
{"episode_reward": 453.5408204204941, "episode": 99.0, "batch_reward": 0.263602441072464, "critic_loss": 0.2629981719627976, "actor_loss": -31.036193088531494, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.15447473526001, "step": 99000}
{"episode_reward": 436.0715658354014, "episode": 100.0, "batch_reward": 0.26335297819972037, "critic_loss": 0.26852235292643306, "actor_loss": -30.66827006149292, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.104899406433105, "step": 100000}
{"episode_reward": 450.39689937495183, "episode": 101.0, "batch_reward": 0.2667083883583546, "critic_loss": 0.2600305706113577, "actor_loss": -31.173352615356446, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.41410160064697, "step": 101000}
{"episode_reward": 460.63423017310635, "episode": 102.0, "batch_reward": 0.26801438242197034, "critic_loss": 0.26398652063310146, "actor_loss": -31.015023746490478, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.146480560302734, "step": 102000}
{"episode_reward": 478.79675570034146, "episode": 103.0, "batch_reward": 0.2706749252080917, "critic_loss": 0.26631046361476185, "actor_loss": -31.190107814788817, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.20966410636902, "step": 103000}
{"episode_reward": 474.8906014185305, "episode": 104.0, "batch_reward": 0.2714924564063549, "critic_loss": 0.250748618863523, "actor_loss": -31.639608242034914, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.47657799720764, "step": 104000}
{"episode_reward": 453.79624033272853, "episode": 105.0, "batch_reward": 0.2745014206320047, "critic_loss": 0.255476156167686, "actor_loss": -31.884400913238526, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.81967568397522, "step": 105000}
{"episode_reward": 454.00588825466895, "episode": 106.0, "batch_reward": 0.2744325808286667, "critic_loss": 0.26655617415905, "actor_loss": -31.937772113800047, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.8939425945282, "step": 106000}
{"episode_reward": 439.763152048129, "episode": 107.0, "batch_reward": 0.2768574412614107, "critic_loss": 0.2646763325929642, "actor_loss": -32.11220002365112, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.994280576705933, "step": 107000}
{"episode_reward": 426.81020073364414, "episode": 108.0, "batch_reward": 0.2774788666218519, "critic_loss": 0.2529085195064545, "actor_loss": -31.662134098052977, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.043337106704712, "step": 108000}
{"episode_reward": 443.33665766025814, "episode": 109.0, "batch_reward": 0.28030928248167036, "critic_loss": 0.25210066376626494, "actor_loss": -32.58220425796509, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.128455877304077, "step": 109000}
{"episode_reward": 455.5192402236683, "episode": 110.0, "batch_reward": 0.28177332878112793, "critic_loss": 0.25945145639032124, "actor_loss": -32.66773720550537, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.095731258392334, "step": 110000}
{"episode_reward": 437.36018625005073, "episode": 111.0, "batch_reward": 0.282576746866107, "critic_loss": 0.2574932872503996, "actor_loss": -31.979666347503663, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.517796993255615, "step": 111000}
{"episode_reward": 450.5566900854869, "episode": 112.0, "batch_reward": 0.28412854665517806, "critic_loss": 0.24314602816849948, "actor_loss": -33.09205978012085, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.699095964431763, "step": 112000}
{"episode_reward": 427.2243408489671, "episode": 113.0, "batch_reward": 0.2855392049998045, "critic_loss": 0.25283433278650047, "actor_loss": -32.642351791381834, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.631893634796143, "step": 113000}
{"episode_reward": 470.16727330078254, "episode": 114.0, "batch_reward": 0.2868593980669975, "critic_loss": 0.2458155898526311, "actor_loss": -32.86940849685669, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.1356258392334, "step": 114000}
{"episode_reward": 471.5415164145555, "episode": 115.0, "batch_reward": 0.2883065352588892, "critic_loss": 0.2429395435154438, "actor_loss": -32.842329601287844, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.778738260269165, "step": 115000}
{"episode_reward": 452.20423390952146, "episode": 116.0, "batch_reward": 0.29123491859436035, "critic_loss": 0.2502088592723012, "actor_loss": -32.97579411315918, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.188416242599487, "step": 116000}
{"episode_reward": 445.12832075162635, "episode": 117.0, "batch_reward": 0.29081064718961713, "critic_loss": 0.23114217882603408, "actor_loss": -32.483161342620846, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.98318099975586, "step": 117000}
{"episode_reward": 481.3799252874072, "episode": 118.0, "batch_reward": 0.29333567287027834, "critic_loss": 0.23861702033132315, "actor_loss": -33.099699325561524, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.89015007019043, "step": 118000}
{"episode_reward": 473.38536786358196, "episode": 119.0, "batch_reward": 0.2946504228562117, "critic_loss": 0.22002363266795874, "actor_loss": -33.09003145599365, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.05606460571289, "step": 119000}
{"episode_reward": 481.13290601768017, "episode": 120.0, "batch_reward": 0.2957148507237434, "critic_loss": 0.22747692085802554, "actor_loss": -32.867318656921384, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.320448637008667, "step": 120000}
{"episode_reward": 455.125106954692, "episode": 121.0, "batch_reward": 0.2966095489859581, "critic_loss": 0.22413018869608642, "actor_loss": -33.33353809738159, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.30092263221741, "step": 121000}
{"episode_reward": 455.0674589320127, "episode": 122.0, "batch_reward": 0.29997701951861383, "critic_loss": 0.2201192940697074, "actor_loss": -33.52128021621704, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.415206909179688, "step": 122000}
{"episode_reward": 472.81512444710154, "episode": 123.0, "batch_reward": 0.30049983321130275, "critic_loss": 0.2255715756267309, "actor_loss": -33.85229379653931, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.643569946289062, "step": 123000}
{"episode_reward": 451.0643157968884, "episode": 124.0, "batch_reward": 0.3016622226387262, "critic_loss": 0.21208895944058895, "actor_loss": -33.96056624984741, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.87553644180298, "step": 124000}
{"episode_reward": 443.5338066850392, "episode": 125.0, "batch_reward": 0.3034945281744003, "critic_loss": 0.21421619876474143, "actor_loss": -34.012933292388915, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.833519220352173, "step": 125000}
{"episode_reward": 463.9736779089114, "episode": 126.0, "batch_reward": 0.304172197163105, "critic_loss": 0.21796426051855086, "actor_loss": -33.754210941314696, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.76927947998047, "step": 126000}
{"episode_reward": 454.6782771953085, "episode": 127.0, "batch_reward": 0.30448398953676226, "critic_loss": 0.2078111148774624, "actor_loss": -34.46288842010498, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.092116117477417, "step": 127000}
{"episode_reward": 435.9744160577816, "episode": 128.0, "batch_reward": 0.30588563656806944, "critic_loss": 0.20270838221162557, "actor_loss": -34.15052939605713, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.53770613670349, "step": 128000}
{"episode_reward": 470.7152343629989, "episode": 129.0, "batch_reward": 0.3074401834756136, "critic_loss": 0.20483925722539426, "actor_loss": -33.975168411254884, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.46903705596924, "step": 129000}
{"episode_reward": 486.965374957118, "episode": 130.0, "batch_reward": 0.31018011677265167, "critic_loss": 0.1993285401687026, "actor_loss": -34.370440994262694, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.558343410491943, "step": 130000}
{"episode_reward": 472.68162781796536, "episode": 131.0, "batch_reward": 0.31044806429743765, "critic_loss": 0.1932019532173872, "actor_loss": -34.61476776885986, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.43763542175293, "step": 131000}
{"episode_reward": 430.97946368318594, "episode": 132.0, "batch_reward": 0.3104362169802189, "critic_loss": 0.19694022307544948, "actor_loss": -34.73843183898926, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.612637519836426, "step": 132000}
{"episode_reward": 463.73758859788535, "episode": 133.0, "batch_reward": 0.3134069872498512, "critic_loss": 0.20454486440122127, "actor_loss": -34.50865939712524, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.346798419952393, "step": 133000}
{"episode_reward": 491.64307916964657, "episode": 134.0, "batch_reward": 0.31377425211668014, "critic_loss": 0.19205494885891675, "actor_loss": -34.3244277305603, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.181476831436157, "step": 134000}
{"episode_reward": 466.48792358538407, "episode": 135.0, "batch_reward": 0.3154964529871941, "critic_loss": 0.21328910291194916, "actor_loss": -35.23483293914795, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.59913444519043, "step": 135000}
{"episode_reward": 462.4133633905475, "episode": 136.0, "batch_reward": 0.3154643568694592, "critic_loss": 0.19740589798241853, "actor_loss": -34.23598882675171, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.359756231307983, "step": 136000}
{"episode_reward": 470.5727399743115, "episode": 137.0, "batch_reward": 0.3165931564569473, "critic_loss": 0.19986941237747669, "actor_loss": -35.163739990234376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.611000776290894, "step": 137000}
{"episode_reward": 447.02566402810066, "episode": 138.0, "batch_reward": 0.3189609204232693, "critic_loss": 0.2035511801466346, "actor_loss": -35.22956358337402, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.07642126083374, "step": 138000}
{"episode_reward": 458.03676581905097, "episode": 139.0, "batch_reward": 0.3194963936507702, "critic_loss": 0.20740802117437124, "actor_loss": -35.09113053131104, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.908613681793213, "step": 139000}
{"episode_reward": 473.3472043939851, "episode": 140.0, "batch_reward": 0.3210889569222927, "critic_loss": 0.21205080581456423, "actor_loss": -35.49577233505249, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.028911352157593, "step": 140000}
{"episode_reward": 445.06494603299535, "episode": 141.0, "batch_reward": 0.320786360681057, "critic_loss": 0.211478554174304, "actor_loss": -35.59537034606934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.08330035209656, "step": 141000}
{"episode_reward": 447.75494496602505, "episode": 142.0, "batch_reward": 0.3213649280667305, "critic_loss": 0.2135091138035059, "actor_loss": -35.30090364837646, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.627084970474243, "step": 142000}
{"episode_reward": 489.21391842140883, "episode": 143.0, "batch_reward": 0.3220640810728073, "critic_loss": 0.20504227813333273, "actor_loss": -35.22929373550415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.273592948913574, "step": 143000}
{"episode_reward": 471.15927442102964, "episode": 144.0, "batch_reward": 0.3248039484322071, "critic_loss": 0.20231599824875593, "actor_loss": -35.70758501434326, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.307491302490234, "step": 144000}
{"episode_reward": 451.4582069379782, "episode": 145.0, "batch_reward": 0.3253388051688671, "critic_loss": 0.19754737710952758, "actor_loss": -35.88907502746582, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.509880781173706, "step": 145000}
{"episode_reward": 421.6213029004801, "episode": 146.0, "batch_reward": 0.32481833720207215, "critic_loss": 0.21377405382692813, "actor_loss": -35.89468957901001, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.635529041290283, "step": 146000}
{"episode_reward": 452.9314109989462, "episode": 147.0, "batch_reward": 0.3266275059878826, "critic_loss": 0.21885170865803957, "actor_loss": -35.81935536193848, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.985825061798096, "step": 147000}
{"episode_reward": 449.55499614337583, "episode": 148.0, "batch_reward": 0.32808136495947837, "critic_loss": 0.2110097089856863, "actor_loss": -36.10597842407226, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.558449745178223, "step": 148000}
{"episode_reward": 478.20076434061156, "episode": 149.0, "batch_reward": 0.3285218033492565, "critic_loss": 0.2141144388243556, "actor_loss": -36.11661988067627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.12595224380493, "step": 149000}
{"episode_reward": 473.75525318347826, "episode": 150.0, "batch_reward": 0.32984330552816393, "critic_loss": 0.2025620432123542, "actor_loss": -36.384049980163574, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
