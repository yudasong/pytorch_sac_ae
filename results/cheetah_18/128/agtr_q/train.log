{"episode": 1.0, "duration": 17.481529474258423, "episode_reward": 4.20996189079657, "step": 1000}
{"episode": 2.0, "duration": 1.5534582138061523, "episode_reward": 252.2457487418515, "step": 2000}
{"episode": 3.0, "batch_reward": 0.12286972395253404, "actor_loss": -35.72206324699069, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254236, "duration": 50.83293843269348, "episode_reward": 38.050768073870735, "step": 3000}
{"episode": 4.0, "batch_reward": 0.09046319162845612, "actor_loss": -32.712591510772704, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.50868248939514, "episode_reward": 30.46355669963464, "step": 4000}
{"episode": 5.0, "batch_reward": 0.07955511812120676, "actor_loss": -29.946003856658937, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.002323627471924, "episode_reward": 95.74208507919764, "step": 5000}
{"episode": 6.0, "batch_reward": 0.08539795481413603, "actor_loss": -30.710777069091797, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.24497127532959, "episode_reward": 106.73011550650371, "step": 6000}
{"episode": 7.0, "batch_reward": 0.09134657923877239, "actor_loss": -30.735652950286866, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.34638476371765, "episode_reward": 93.71186310869373, "step": 7000}
{"episode": 8.0, "batch_reward": 0.09352783168107272, "actor_loss": -30.02861011123657, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 15.917280197143555, "episode_reward": 177.34717469807086, "step": 8000}
{"episode": 9.0, "batch_reward": 0.11007989606261254, "actor_loss": -31.188657485961915, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 15.550710916519165, "episode_reward": 259.6867311046038, "step": 9000}
{"episode": 10.0, "batch_reward": 0.11573276778310537, "actor_loss": -27.881570026397704, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 3778.4176297187805, "episode_reward": 63.08686554133729, "step": 10000}
{"episode": 11.0, "batch_reward": 0.11292687187343836, "actor_loss": -27.22867624282837, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 34.950968980789185, "episode_reward": 156.2120365032065, "step": 11000}
{"episode": 12.0, "batch_reward": 0.11595518484711648, "actor_loss": -24.841262397766112, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 412.84315490722656, "episode_reward": 71.57846554102287, "step": 12000}
{"episode": 13.0, "batch_reward": 0.11839228009432554, "actor_loss": -24.572404972076416, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.380818605422974, "episode_reward": 173.02124350399254, "step": 13000}
{"episode": 14.0, "batch_reward": 0.11871201563626528, "actor_loss": -22.408151737213135, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 413.5508370399475, "episode_reward": 113.41328628334395, "step": 14000}
{"episode": 15.0, "batch_reward": 0.12329614197462797, "actor_loss": -22.447323791503905, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.818098306655884, "episode_reward": 328.8482766741608, "step": 15000}
{"episode": 16.0, "batch_reward": 0.13139680943638085, "actor_loss": -21.874815269470215, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 415.2470304965973, "episode_reward": 109.8383777307016, "step": 16000}
{"episode": 17.0, "batch_reward": 0.13414270497113467, "actor_loss": -22.015622554779053, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.648155450820923, "episode_reward": 284.5361068280608, "step": 17000}
{"episode": 18.0, "batch_reward": 0.14015790289640426, "actor_loss": -21.376104438781738, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 412.5024263858795, "episode_reward": 142.0119836517659, "step": 18000}
{"episode": 19.0, "batch_reward": 0.14126730329543352, "actor_loss": -21.413875396728514, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.794642210006714, "episode_reward": 232.45010662552764, "step": 19000}
{"episode": 20.0, "batch_reward": 0.14722467742115258, "actor_loss": -20.84762281036377, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 407.54343271255493, "episode_reward": 297.5267021274084, "step": 20000}
{"episode": 21.0, "batch_reward": 0.1528593746200204, "actor_loss": -21.301142158508302, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 32.712342977523804, "episode_reward": 191.1368762078551, "step": 21000}
{"episode": 22.0, "batch_reward": 0.15617517992854119, "actor_loss": -20.121571090698243, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 415.1550168991089, "episode_reward": 287.25230592044977, "step": 22000}
{"episode": 23.0, "batch_reward": 0.16502571991086007, "actor_loss": -20.897269453048708, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.16057848930359, "episode_reward": 398.8056901077889, "step": 23000}
{"episode": 24.0, "batch_reward": 0.16984833949804307, "actor_loss": -19.25618888092041, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 403.73224353790283, "episode_reward": 116.69650975182081, "step": 24000}
{"episode": 25.0, "batch_reward": 0.1731381002739072, "actor_loss": -19.49538042640686, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.02329158782959, "episode_reward": 424.0434594209419, "step": 25000}
{"episode": 26.0, "batch_reward": 0.18085618993639946, "actor_loss": -19.37749648475647, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 410.8738691806793, "episode_reward": 338.3955014407437, "step": 26000}
{"episode": 27.0, "batch_reward": 0.18264332777261735, "actor_loss": -19.328340463638305, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.541029453277588, "episode_reward": 46.78670247035948, "step": 27000}
{"episode": 28.0, "batch_reward": 0.17940781408548356, "actor_loss": -18.408050914764406, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 411.6639714241028, "episode_reward": 145.36447190135092, "step": 28000}
{"episode": 29.0, "batch_reward": 0.18189658223092556, "actor_loss": -18.61413718223572, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.063202381134033, "episode_reward": 334.80862200682816, "step": 29000}
{"episode": 30.0, "batch_reward": 0.18145090301334857, "actor_loss": -17.98281103515625, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 419.5052556991577, "episode_reward": 38.19105561792356, "step": 30000}
{"episode": 31.0, "batch_reward": 0.1814046292155981, "actor_loss": -18.02334537887573, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 32.89060831069946, "episode_reward": 379.34077788732804, "step": 31000}
{"episode": 32.0, "batch_reward": 0.1867467951774597, "actor_loss": -18.438967418670654, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 412.88078713417053, "episode_reward": 325.58356136094835, "step": 32000}
{"episode": 33.0, "batch_reward": 0.19221656082570554, "actor_loss": -19.117134984970093, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.500814199447632, "episode_reward": 392.6473742484678, "step": 33000}
{"episode": 34.0, "batch_reward": 0.19972855985164642, "actor_loss": -20.14573093223572, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 414.176393032074, "episode_reward": 429.29736688890847, "step": 34000}
{"episode": 35.0, "batch_reward": 0.20548419527709483, "actor_loss": -20.673758598327638, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.407083749771118, "episode_reward": 391.54209384593685, "step": 35000}
{"episode": 36.0, "batch_reward": 0.20821236325800418, "actor_loss": -20.598581884384156, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 410.235068321228, "episode_reward": 118.18729166237915, "step": 36000}
{"episode": 37.0, "batch_reward": 0.20701568399369716, "actor_loss": -20.60694331550598, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.390653610229492, "episode_reward": 386.58657668323855, "step": 37000}
{"episode": 38.0, "batch_reward": 0.2120813081264496, "actor_loss": -21.142159420013428, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 414.9345455169678, "episode_reward": 346.50691035292425, "step": 38000}
{"episode": 39.0, "batch_reward": 0.21450419369339943, "actor_loss": -21.533831111907958, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.749736309051514, "episode_reward": 357.4735546101047, "step": 39000}
{"episode": 40.0, "batch_reward": 0.21677253672480584, "actor_loss": -21.894256580352785, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 407.23579573631287, "episode_reward": 77.01609298847121, "step": 40000}
{"episode": 41.0, "batch_reward": 0.21587368984520436, "actor_loss": -21.79362804031372, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 33.450276613235474, "episode_reward": 374.7555220273381, "step": 41000}
{"episode": 42.0, "batch_reward": 0.21864968656003475, "actor_loss": -21.740762828826906, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 404.43830728530884, "episode_reward": 363.74748147187086, "step": 42000}
{"episode": 43.0, "batch_reward": 0.22332614570856094, "actor_loss": -22.181535762786865, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.587673664093018, "episode_reward": 375.28885809995757, "step": 43000}
{"episode": 44.0, "batch_reward": 0.22661131769418716, "actor_loss": -22.294180042266845, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 415.7280147075653, "episode_reward": 242.62686431652344, "step": 44000}
{"episode": 45.0, "batch_reward": 0.22604063349962233, "actor_loss": -22.1744807510376, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 15.768694639205933, "episode_reward": 323.26954283309203, "step": 45000}
{"episode": 46.0, "batch_reward": 0.2272080209851265, "actor_loss": -22.410970027923582, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 414.68827533721924, "episode_reward": 358.2565280271381, "step": 46000}
{"episode": 47.0, "batch_reward": 0.23229972709715366, "actor_loss": -22.89178275680542, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.95683741569519, "episode_reward": 348.906227661029, "step": 47000}
{"episode": 48.0, "batch_reward": 0.23374505849182606, "actor_loss": -22.27484670639038, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 417.20926117897034, "episode_reward": 381.63970352673726, "step": 48000}
{"episode": 49.0, "batch_reward": 0.23734870207309722, "actor_loss": -22.656881244659424, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.015867948532104, "episode_reward": 346.68758718612094, "step": 49000}
{"episode": 50.0, "batch_reward": 0.23920799569785595, "actor_loss": -22.58888056564331, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 420.00918555259705, "episode_reward": 343.2122783300139, "step": 50000}
{"episode": 51.0, "batch_reward": 0.24103712917864323, "actor_loss": -22.63187343597412, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 35.454333782196045, "episode_reward": 349.22764978280685, "step": 51000}
{"episode": 52.0, "batch_reward": 0.24521527591347694, "actor_loss": -22.735818019866944, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 414.3220856189728, "episode_reward": 394.205796085336, "step": 52000}
{"episode": 53.0, "batch_reward": 0.24630196346342564, "actor_loss": -22.996979343414306, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 15.495875597000122, "episode_reward": 382.61677895417137, "step": 53000}
{"episode": 54.0, "batch_reward": 0.2496632400751114, "actor_loss": -23.02359790420532, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 413.53169322013855, "episode_reward": 429.63222178304443, "step": 54000}
{"episode": 55.0, "batch_reward": 0.2535124191790819, "actor_loss": -23.216750171661378, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.669100284576416, "episode_reward": 417.19137160710756, "step": 55000}
{"episode": 56.0, "batch_reward": 0.25540776407718657, "actor_loss": -23.380434265136717, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 413.8859157562256, "episode_reward": 412.6390936483945, "step": 56000}
{"episode": 57.0, "batch_reward": 0.25879764133691785, "actor_loss": -23.69435046005249, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.338961839675903, "episode_reward": 397.36065241343823, "step": 57000}
{"episode": 58.0, "batch_reward": 0.2609893210232258, "actor_loss": -23.270708038330078, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 407.3744099140167, "episode_reward": 394.75946556844383, "step": 58000}
{"episode": 59.0, "batch_reward": 0.26351453994214535, "actor_loss": -23.56540850067139, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.56517791748047, "episode_reward": 422.13821156842823, "step": 59000}
{"episode": 60.0, "batch_reward": 0.2661203652769327, "actor_loss": -23.672236320495607, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 412.8681025505066, "episode_reward": 413.2910213893313, "step": 60000}
{"episode": 61.0, "batch_reward": 0.26775111325085166, "actor_loss": -23.869209384918214, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 32.558881998062134, "episode_reward": 416.2131002371137, "step": 61000}
{"episode": 62.0, "batch_reward": 0.27061751136183737, "actor_loss": -23.512770332336427, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 408.61695313453674, "episode_reward": 415.5466618662089, "step": 62000}
{"episode": 63.0, "batch_reward": 0.27284356428682804, "actor_loss": -23.747197715759278, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.621530771255493, "episode_reward": 441.0582876038544, "step": 63000}
{"episode": 64.0, "batch_reward": 0.2757557619512081, "actor_loss": -24.174687282562257, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 416.76279950141907, "episode_reward": 391.0130662934701, "step": 64000}
{"episode": 65.0, "batch_reward": 0.27725573965907097, "actor_loss": -24.292171314239503, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.54006862640381, "episode_reward": 379.4955134166592, "step": 65000}
{"episode": 66.0, "batch_reward": 0.27868202252686025, "actor_loss": -24.225556041717528, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 410.45409750938416, "episode_reward": 419.2149891906378, "step": 66000}
{"episode": 67.0, "batch_reward": 0.28126056052744386, "actor_loss": -24.338075916290283, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.3992919921875, "episode_reward": 402.3561550288012, "step": 67000}
{"episode": 68.0, "batch_reward": 0.282698366060853, "actor_loss": -24.644391429901123, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 417.71776819229126, "episode_reward": 381.1224827260847, "step": 68000}
{"episode": 69.0, "batch_reward": 0.28249157628417015, "actor_loss": -24.470708278656005, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.82693576812744, "episode_reward": 118.74156057980247, "step": 69000}
{"episode": 70.0, "batch_reward": 0.28079538336396215, "actor_loss": -24.117833686828615, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 417.6084988117218, "episode_reward": 407.75941577951727, "step": 70000}
{"episode": 71.0, "batch_reward": 0.28408553268015385, "actor_loss": -24.406455810546873, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 34.458301305770874, "episode_reward": 420.1169054463485, "step": 71000}
{"episode": 72.0, "batch_reward": 0.2851347569227219, "actor_loss": -24.250131217956543, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 421.2423017024994, "episode_reward": 404.56342359147203, "step": 72000}
{"episode": 73.0, "batch_reward": 0.2871655254364014, "actor_loss": -24.3732123336792, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 15.781156063079834, "episode_reward": 411.58576001294693, "step": 73000}
{"episode": 74.0, "batch_reward": 0.2888792851418257, "actor_loss": -24.601790687561035, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 419.7616832256317, "episode_reward": 389.93563878988795, "step": 74000}
{"episode": 75.0, "batch_reward": 0.28986100149154664, "actor_loss": -24.62202529144287, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.262767791748047, "episode_reward": 410.77326134978546, "step": 75000}
{"episode": 76.0, "batch_reward": 0.2920088481456041, "actor_loss": -25.168800495147703, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 412.29384303092957, "episode_reward": 394.9494888349172, "step": 76000}
{"episode": 77.0, "batch_reward": 0.29340034613013266, "actor_loss": -25.261432342529297, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.38983941078186, "episode_reward": 373.9743091823232, "step": 77000}
{"episode": 78.0, "batch_reward": 0.29455007195472716, "actor_loss": -25.183350105285644, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 408.79147362709045, "episode_reward": 399.6285647547155, "step": 78000}
{"episode": 79.0, "batch_reward": 0.29518862935900686, "actor_loss": -25.15357221221924, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.589885473251343, "episode_reward": 265.5340024719493, "step": 79000}
{"episode": 80.0, "batch_reward": 0.2950965160578489, "actor_loss": -25.355343444824218, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 415.08652663230896, "episode_reward": 352.24919260434774, "step": 80000}
{"episode": 81.0, "batch_reward": 0.29439245477318765, "actor_loss": -25.297431072235106, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 32.04508876800537, "episode_reward": 367.3434917203487, "step": 81000}
{"episode": 82.0, "batch_reward": 0.29662097746133803, "actor_loss": -25.425672412872313, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 416.47520184516907, "episode_reward": 398.21717457197565, "step": 82000}
{"episode": 83.0, "batch_reward": 0.2978912511467934, "actor_loss": -25.466941478729247, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.45711922645569, "episode_reward": 426.65401641087914, "step": 83000}
{"episode": 84.0, "batch_reward": 0.29931949073076247, "actor_loss": -25.720134899139403, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 421.2953383922577, "episode_reward": 416.0024545980252, "step": 84000}
{"episode": 85.0, "batch_reward": 0.30083712422847747, "actor_loss": -25.78804546356201, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.396737575531006, "episode_reward": 416.0300545639518, "step": 85000}
{"episode": 86.0, "batch_reward": 0.30213894340395925, "actor_loss": -25.765674808502197, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 418.50446796417236, "episode_reward": 202.90025705313545, "step": 86000}
{"episode": 87.0, "batch_reward": 0.30024767887592313, "actor_loss": -25.630324462890623, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.61445903778076, "episode_reward": 406.7125909662409, "step": 87000}
{"episode": 88.0, "batch_reward": 0.30382808700203895, "actor_loss": -25.804094299316407, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 416.78608655929565, "episode_reward": 420.1820285932326, "step": 88000}
{"episode": 89.0, "batch_reward": 0.30327262768149377, "actor_loss": -25.740619899749756, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.349737405776978, "episode_reward": 391.0045929678227, "step": 89000}
{"episode": 90.0, "batch_reward": 0.30450779432058334, "actor_loss": -25.84896943283081, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 421.98965525627136, "episode_reward": 406.518897829494, "step": 90000}
{"episode": 91.0, "batch_reward": 0.30565174934267997, "actor_loss": -25.941803718566895, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 34.075340270996094, "episode_reward": 423.42311332553686, "step": 91000}
{"episode": 92.0, "batch_reward": 0.3071567425429821, "actor_loss": -25.88002416229248, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 409.12219285964966, "episode_reward": 421.3612433740497, "step": 92000}
{"episode": 93.0, "batch_reward": 0.3084952705800533, "actor_loss": -25.93141004180908, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 15.532393217086792, "episode_reward": 401.10231446338395, "step": 93000}
{"episode": 94.0, "batch_reward": 0.3094425437748432, "actor_loss": -26.242132976531984, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 412.6611535549164, "episode_reward": 429.77593345442386, "step": 94000}
{"episode": 95.0, "batch_reward": 0.30958292803168297, "actor_loss": -26.371458763122558, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.460914850234985, "episode_reward": 443.2220620680673, "step": 95000}
{"episode": 96.0, "batch_reward": 0.3116709599494934, "actor_loss": -26.562970432281496, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 410.66311287879944, "episode_reward": 106.72169704398628, "step": 96000}
{"episode": 97.0, "batch_reward": 0.30980682629346845, "actor_loss": -26.133829654693603, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.53349256515503, "episode_reward": 262.73647005391047, "step": 97000}
{"episode": 98.0, "batch_reward": 0.30942852634191514, "actor_loss": -26.660545722961427, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 413.2383985519409, "episode_reward": 439.2482824627573, "step": 98000}
{"episode": 99.0, "batch_reward": 0.3109013846516609, "actor_loss": -26.817982543945313, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.589876651763916, "episode_reward": 426.96120845708657, "step": 99000}
{"episode": 100.0, "batch_reward": 0.312034419208765, "actor_loss": -27.089755569458006, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 415.1655304431915, "episode_reward": 418.93203824642023, "step": 100000}
{"episode": 101.0, "batch_reward": 0.31252136871218683, "actor_loss": -27.183269054412843, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 31.309747219085693, "episode_reward": 393.53103122204556, "step": 101000}
{"episode": 102.0, "batch_reward": 0.31373287335038186, "actor_loss": -27.43867169570923, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 414.4492926597595, "episode_reward": 336.673827117398, "step": 102000}
{"episode": 103.0, "batch_reward": 0.3140045012831688, "actor_loss": -27.535154903411865, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.793274641036987, "episode_reward": 409.6649059958976, "step": 103000}
{"episode": 104.0, "batch_reward": 0.31515834125876424, "actor_loss": -27.357673004150392, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 406.7938265800476, "episode_reward": 447.85957332055875, "step": 104000}
{"episode": 105.0, "batch_reward": 0.316247947961092, "actor_loss": -27.507148166656496, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.98499894142151, "episode_reward": 422.79837439318015, "step": 105000}
{"episode": 106.0, "batch_reward": 0.3167079372406006, "actor_loss": -27.742769344329833, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 415.6144061088562, "episode_reward": 423.06720701505446, "step": 106000}
{"episode": 107.0, "batch_reward": 0.3176686231791973, "actor_loss": -27.837267345428465, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.272358894348145, "episode_reward": 401.1877789088469, "step": 107000}
{"episode": 108.0, "batch_reward": 0.318591323018074, "actor_loss": -28.027077075958253, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 420.1705105304718, "episode_reward": 402.07667483401457, "step": 108000}
{"episode": 109.0, "batch_reward": 0.32008045983314515, "actor_loss": -28.173907958984376, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.214995622634888, "episode_reward": 436.33549473441013, "step": 109000}
{"episode": 110.0, "batch_reward": 0.3213122509419918, "actor_loss": -28.163275619506837, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 424.0256452560425, "episode_reward": 449.5032853649008, "step": 110000}
{"episode": 111.0, "batch_reward": 0.3214488772451878, "actor_loss": -28.14829133605957, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 33.51377272605896, "episode_reward": 435.53139859144454, "step": 111000}
{"episode": 112.0, "batch_reward": 0.3226396120488644, "actor_loss": -28.38229000091553, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 417.12019300460815, "episode_reward": 419.9924488718824, "step": 112000}
{"episode": 113.0, "batch_reward": 0.3230945700705051, "actor_loss": -28.462216846466063, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.937151670455933, "episode_reward": 410.37714434896594, "step": 113000}
{"episode": 114.0, "batch_reward": 0.32462259221076967, "actor_loss": -28.722545028686522, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 422.71473693847656, "episode_reward": 404.08536064855014, "step": 114000}
{"episode": 115.0, "batch_reward": 0.3258683800697327, "actor_loss": -28.860286437988282, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.34866714477539, "episode_reward": 413.78392804685143, "step": 115000}
{"episode": 116.0, "batch_reward": 0.3259118736684322, "actor_loss": -28.9044462890625, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 417.03790736198425, "episode_reward": 453.22407957741416, "step": 116000}
{"episode": 117.0, "batch_reward": 0.32820201620459555, "actor_loss": -29.210998756408692, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.524221658706665, "episode_reward": 447.4168188408982, "step": 117000}
{"episode": 118.0, "batch_reward": 0.3280460914969444, "actor_loss": -29.351673389434815, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 413.87283086776733, "episode_reward": 414.48977543989776, "step": 118000}
{"episode": 119.0, "batch_reward": 0.3287481484413147, "actor_loss": -29.46070584869385, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.351229906082153, "episode_reward": 423.83735211252855, "step": 119000}
{"episode": 120.0, "batch_reward": 0.32966598027944566, "actor_loss": -29.650988819122315, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 408.53790068626404, "episode_reward": 418.4401155370978, "step": 120000}
{"episode": 121.0, "batch_reward": 0.3300446729362011, "actor_loss": -29.565938854217528, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 32.90152311325073, "episode_reward": 402.86053831266435, "step": 121000}
{"episode": 122.0, "batch_reward": 0.33047504812479017, "actor_loss": -29.517688629150392, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 410.6876411437988, "episode_reward": 363.55124605234647, "step": 122000}
{"episode": 123.0, "batch_reward": 0.3313142572045326, "actor_loss": -29.542297035217285, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.222437620162964, "episode_reward": 406.92135884033473, "step": 123000}
{"episode": 124.0, "batch_reward": 0.3311226429641247, "actor_loss": -29.470817752838133, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 413.38954401016235, "episode_reward": 438.8574027339055, "step": 124000}
{"episode": 125.0, "batch_reward": 0.33269852757453916, "actor_loss": -29.693521156311036, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.5779128074646, "episode_reward": 413.01338033844803, "step": 125000}
{"episode": 126.0, "batch_reward": 0.3336155175864696, "actor_loss": -29.683746891021727, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 411.71911811828613, "episode_reward": 418.6053348686124, "step": 126000}
{"episode": 127.0, "batch_reward": 0.333420264005661, "actor_loss": -29.759565101623537, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.407145023345947, "episode_reward": 406.78846045312093, "step": 127000}
{"episode": 128.0, "batch_reward": 0.3340174975991249, "actor_loss": -30.09078162765503, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 408.80953884124756, "episode_reward": 430.6000658520083, "step": 128000}
{"episode": 129.0, "batch_reward": 0.33570402884483336, "actor_loss": -30.25819903564453, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.61214780807495, "episode_reward": 436.65712837841295, "step": 129000}
{"episode": 130.0, "batch_reward": 0.3369450815618038, "actor_loss": -30.696361282348633, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 410.6506791114807, "episode_reward": 450.2520388220195, "step": 130000}
{"episode": 131.0, "batch_reward": 0.3366385813355446, "actor_loss": -30.705724395751954, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 32.51743721961975, "episode_reward": 434.59953502363845, "step": 131000}
{"episode": 132.0, "batch_reward": 0.3379542438685894, "actor_loss": -30.854582069396972, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 412.9544770717621, "episode_reward": 379.9813590585714, "step": 132000}
{"episode": 133.0, "batch_reward": 0.33880575957894327, "actor_loss": -30.855270221710207, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.834177494049072, "episode_reward": 445.9293106744334, "step": 133000}
{"episode": 134.0, "batch_reward": 0.33929070916771886, "actor_loss": -30.721350578308105, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 412.67409086227417, "episode_reward": 445.2250058112397, "step": 134000}
{"episode": 135.0, "batch_reward": 0.33967460510134695, "actor_loss": -30.766807933807375, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.86805033683777, "episode_reward": 456.2223297352401, "step": 135000}
{"episode": 136.0, "batch_reward": 0.3408666609823704, "actor_loss": -30.970761611938478, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 410.531991481781, "episode_reward": 446.461540457933, "step": 136000}
{"episode": 137.0, "batch_reward": 0.34080041539669037, "actor_loss": -30.984464630126954, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.79848837852478, "episode_reward": 451.98171296920225, "step": 137000}
{"episode": 138.0, "batch_reward": 0.34229994502663613, "actor_loss": -31.184080718994142, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 426.4330735206604, "episode_reward": 446.7958256633975, "step": 138000}
{"episode": 139.0, "batch_reward": 0.3426325342357159, "actor_loss": -31.364389797210695, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 15.534611463546753, "episode_reward": 447.15307969312215, "step": 139000}
{"episode": 140.0, "batch_reward": 0.3435149230659008, "actor_loss": -31.255821502685546, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 418.8478481769562, "episode_reward": 468.1708301648175, "step": 140000}
{"episode": 141.0, "batch_reward": 0.34533857583999633, "actor_loss": -31.360319591522217, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 36.58863139152527, "episode_reward": 460.24559105513913, "step": 141000}
{"episode": 142.0, "batch_reward": 0.3454309573173523, "actor_loss": -31.501859130859376, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 409.4500708580017, "episode_reward": 454.74803514896854, "step": 142000}
{"episode": 143.0, "batch_reward": 0.3465200973153114, "actor_loss": -31.643377868652344, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.33758306503296, "episode_reward": 451.4942396393979, "step": 143000}
{"episode": 144.0, "batch_reward": 0.3465464061200619, "actor_loss": -31.64150379943848, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 421.1058895587921, "episode_reward": 456.58396589439604, "step": 144000}
{"episode": 145.0, "batch_reward": 0.3475252386331558, "actor_loss": -31.680794960021974, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.687340021133423, "episode_reward": 456.05135940217116, "step": 145000}
{"episode": 146.0, "batch_reward": 0.3485043178200722, "actor_loss": -31.37556988143921, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 423.08317494392395, "episode_reward": 436.23910231041384, "step": 146000}
{"episode": 147.0, "batch_reward": 0.3486075410246849, "actor_loss": -31.49894842529297, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.328543663024902, "episode_reward": 447.7589800862304, "step": 147000}
{"episode": 148.0, "batch_reward": 0.3486907896101475, "actor_loss": -31.592035472869874, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 422.1647653579712, "episode_reward": 382.75371951471675, "step": 148000}
{"episode": 149.0, "batch_reward": 0.34985678720474245, "actor_loss": -31.681141788482666, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.621765613555908, "episode_reward": 432.13249499137714, "step": 149000}
{"episode": 150.0, "batch_reward": 0.3510708089470863, "actor_loss": -31.58520413208008, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "step": 150000}
