{"episode_reward": 0.0, "episode": 1.0, "duration": 17.645225763320923, "step": 1000}
{"episode_reward": 4.20996189079657, "episode": 2.0, "duration": 1.5867059230804443, "step": 2000}
{"episode_reward": 252.2457487418515, "episode": 3.0, "batch_reward": 0.12213570541736682, "critic_loss": 0.022102021846222147, "actor_loss": -7.429921871473437, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 63.99255180358887, "step": 3000}
{"episode_reward": 27.954357242837954, "episode": 4.0, "batch_reward": 0.09276354685798287, "critic_loss": 0.03424459481611848, "actor_loss": -8.594723930835723, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.54127836227417, "step": 4000}
{"episode_reward": 83.09825644191734, "episode": 5.0, "batch_reward": 0.09066342928260565, "critic_loss": 0.05082577426545322, "actor_loss": -8.388275849580765, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.125802755355835, "step": 5000}
{"episode_reward": 51.0169889546251, "episode": 6.0, "batch_reward": 0.08056215282529593, "critic_loss": 0.04956360029615462, "actor_loss": -7.23386021733284, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.85202717781067, "step": 6000}
{"episode_reward": 27.80776492692438, "episode": 7.0, "batch_reward": 0.0757494978196919, "critic_loss": 0.0633113679997623, "actor_loss": -6.1193503329753876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.50827980041504, "step": 7000}
{"episode_reward": 58.633488494427375, "episode": 8.0, "batch_reward": 0.07581139818951488, "critic_loss": 0.08992348357848823, "actor_loss": -7.261489997386932, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.133434057235718, "step": 8000}
{"episode_reward": 77.7300904470594, "episode": 9.0, "batch_reward": 0.0712377574145794, "critic_loss": 0.09966153241693973, "actor_loss": -6.5286811633110045, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.23123860359192, "step": 9000}
{"episode_reward": 29.923968856371516, "episode": 10.0, "batch_reward": 0.06838967845588922, "critic_loss": 0.11550442837551236, "actor_loss": -7.360262090206146, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.782169580459595, "step": 10000}
{"episode_reward": 58.404275527934956, "episode": 11.0, "batch_reward": 0.06578107519075274, "critic_loss": 0.0998660228997469, "actor_loss": -7.33617534160614, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.46389031410217, "step": 11000}
{"episode_reward": 33.68022144567756, "episode": 12.0, "batch_reward": 0.06326948725804686, "critic_loss": 0.11615640154108405, "actor_loss": -7.717564124107361, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.54235339164734, "step": 12000}
{"episode_reward": 27.156563414809803, "episode": 13.0, "batch_reward": 0.06276702576130629, "critic_loss": 0.1381599719580263, "actor_loss": -8.302259802818298, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.766945123672485, "step": 13000}
{"episode_reward": 73.55002060397352, "episode": 14.0, "batch_reward": 0.06446652084961534, "critic_loss": 0.1907186443321407, "actor_loss": -9.126017795562744, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.451642751693726, "step": 14000}
{"episode_reward": 139.8292769359926, "episode": 15.0, "batch_reward": 0.06856391469761729, "critic_loss": 0.22535579594969748, "actor_loss": -9.544068880081177, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.415184259414673, "step": 15000}
{"episode_reward": 67.12384431378646, "episode": 16.0, "batch_reward": 0.07141346178576351, "critic_loss": 0.2364885413274169, "actor_loss": -9.844147283554078, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.170862436294556, "step": 16000}
{"episode_reward": 123.30781272409989, "episode": 17.0, "batch_reward": 0.07188559431955219, "critic_loss": 0.2201381083726883, "actor_loss": -9.855352155685425, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.520775318145752, "step": 17000}
{"episode_reward": 61.665758348755894, "episode": 18.0, "batch_reward": 0.071044658690691, "critic_loss": 0.23815893375128508, "actor_loss": -10.148980735778808, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.527648210525513, "step": 18000}
{"episode_reward": 55.994178962037, "episode": 19.0, "batch_reward": 0.07351311361417175, "critic_loss": 0.2987946933954954, "actor_loss": -10.876242367744446, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.847254276275635, "step": 19000}
{"episode_reward": 176.17759866987996, "episode": 20.0, "batch_reward": 0.07670711098611355, "critic_loss": 0.32928643029928206, "actor_loss": -11.395509345054627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.735854387283325, "step": 20000}
{"episode_reward": 75.42270145663103, "episode": 21.0, "batch_reward": 0.07398342676460742, "critic_loss": 0.3132431446313858, "actor_loss": -11.417496793746949, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.08513331413269, "step": 21000}
{"episode_reward": 30.258354571704515, "episode": 22.0, "batch_reward": 0.07297120798379182, "critic_loss": 0.2897147220224142, "actor_loss": -11.825653280258178, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.068090677261353, "step": 22000}
{"episode_reward": 56.542076066843244, "episode": 23.0, "batch_reward": 0.07361464769765734, "critic_loss": 0.27356110244244336, "actor_loss": -11.692664770126342, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.21690011024475, "step": 23000}
{"episode_reward": 73.40807275476384, "episode": 24.0, "batch_reward": 0.07488149093464017, "critic_loss": 0.28756694634258745, "actor_loss": -12.338351593017578, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.491073608398438, "step": 24000}
{"episode_reward": 227.68108144171848, "episode": 25.0, "batch_reward": 0.08132579539716243, "critic_loss": 0.3366331297159195, "actor_loss": -12.960894407272338, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.209625482559204, "step": 25000}
{"episode_reward": 156.03254956588827, "episode": 26.0, "batch_reward": 0.08270820718631149, "critic_loss": 0.3448954241722822, "actor_loss": -13.102655879974366, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.105947971343994, "step": 26000}
{"episode_reward": 60.50809033459926, "episode": 27.0, "batch_reward": 0.0817220005132258, "critic_loss": 0.31523391157388686, "actor_loss": -13.107363389968873, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.52519679069519, "step": 27000}
{"episode_reward": 74.21734767500001, "episode": 28.0, "batch_reward": 0.08146247512102127, "critic_loss": 0.3142658312022686, "actor_loss": -13.182356874465942, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.506116151809692, "step": 28000}
{"episode_reward": 52.579034942363876, "episode": 29.0, "batch_reward": 0.07997149757295847, "critic_loss": 0.3532588888853788, "actor_loss": -13.113919233322143, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.777161121368408, "step": 29000}
{"episode_reward": 48.95721756308429, "episode": 30.0, "batch_reward": 0.08018460255861283, "critic_loss": 0.36474713349342347, "actor_loss": -13.297908052444457, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.690648794174194, "step": 30000}
{"episode_reward": 88.60747753762298, "episode": 31.0, "batch_reward": 0.07914468639343977, "critic_loss": 0.33481504794210193, "actor_loss": -13.423606216430665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.14061117172241, "step": 31000}
{"episode_reward": 43.784069834184166, "episode": 32.0, "batch_reward": 0.08031116172298788, "critic_loss": 0.4008308474943042, "actor_loss": -13.490679065704345, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.922927379608154, "step": 32000}
{"episode_reward": 251.13491832123879, "episode": 33.0, "batch_reward": 0.08534869400411844, "critic_loss": 0.3961543352752924, "actor_loss": -14.312968557357788, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.305525541305542, "step": 33000}
{"episode_reward": 283.4537816022592, "episode": 34.0, "batch_reward": 0.0926346168294549, "critic_loss": 0.4177907320410013, "actor_loss": -15.160688726425171, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.47989296913147, "step": 34000}
{"episode_reward": 279.1012753947492, "episode": 35.0, "batch_reward": 0.09828238438069821, "critic_loss": 0.46277290016412737, "actor_loss": -15.661635276794433, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.4929780960083, "step": 35000}
{"episode_reward": 245.33430496979756, "episode": 36.0, "batch_reward": 0.09914388007670641, "critic_loss": 0.4936306849718094, "actor_loss": -15.910082691192628, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.992667198181152, "step": 36000}
{"episode_reward": 57.156270749204346, "episode": 37.0, "batch_reward": 0.10203498598188161, "critic_loss": 0.4673378635197878, "actor_loss": -16.167826681137086, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.34691286087036, "step": 37000}
{"episode_reward": 386.47411439633566, "episode": 38.0, "batch_reward": 0.1091331540569663, "critic_loss": 0.4824059394299984, "actor_loss": -16.893555265426635, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.45319962501526, "step": 38000}
{"episode_reward": 317.55348226787254, "episode": 39.0, "batch_reward": 0.11432578272372484, "critic_loss": 0.4843393044173718, "actor_loss": -17.458715747833253, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.643853902816772, "step": 39000}
{"episode_reward": 332.58705190416794, "episode": 40.0, "batch_reward": 0.12120062459260225, "critic_loss": 0.4366858012676239, "actor_loss": -18.210688583374022, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.52234721183777, "step": 40000}
{"episode_reward": 339.9768822107425, "episode": 41.0, "batch_reward": 0.125928964599967, "critic_loss": 0.4320692551583052, "actor_loss": -18.49335268211365, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.87792682647705, "step": 41000}
{"episode_reward": 391.34037020029353, "episode": 42.0, "batch_reward": 0.13233695816993712, "critic_loss": 0.43406850718706846, "actor_loss": -19.176977899551392, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.531172513961792, "step": 42000}
{"episode_reward": 346.8300630920856, "episode": 43.0, "batch_reward": 0.13709942432492972, "critic_loss": 0.4561797146052122, "actor_loss": -19.766264867782592, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.85535979270935, "step": 43000}
{"episode_reward": 461.80818427129003, "episode": 44.0, "batch_reward": 0.1457832789644599, "critic_loss": 0.439152568846941, "actor_loss": -20.574580432891846, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.577996969223022, "step": 44000}
{"episode_reward": 322.32745871304894, "episode": 45.0, "batch_reward": 0.1498853275924921, "critic_loss": 0.4289086534827948, "actor_loss": -20.859829002380373, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.01197099685669, "step": 45000}
{"episode_reward": 449.2209349164291, "episode": 46.0, "batch_reward": 0.1558894164338708, "critic_loss": 0.4229287756085396, "actor_loss": -21.484508144378662, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.501808881759644, "step": 46000}
{"episode_reward": 434.1048655689843, "episode": 47.0, "batch_reward": 0.16087341310083866, "critic_loss": 0.4214074036031961, "actor_loss": -22.086303470611572, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.967011213302612, "step": 47000}
{"episode_reward": 214.59054384646242, "episode": 48.0, "batch_reward": 0.16262374909222127, "critic_loss": 0.43183838593959806, "actor_loss": -22.167589378356933, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.573922872543335, "step": 48000}
{"episode_reward": 448.040503679292, "episode": 49.0, "batch_reward": 0.16867935801297426, "critic_loss": 0.43951417329907416, "actor_loss": -22.86291899108887, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.03940510749817, "step": 49000}
{"episode_reward": 399.67538861292616, "episode": 50.0, "batch_reward": 0.1738465238660574, "critic_loss": 0.45488443537056444, "actor_loss": -23.412780796051024, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.470182418823242, "step": 50000}
{"episode_reward": 468.4852722818516, "episode": 51.0, "batch_reward": 0.1762823970243335, "critic_loss": 0.4058995351344347, "actor_loss": -23.505145957946777, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.344154357910156, "step": 51000}
{"episode_reward": 210.809222259198, "episode": 52.0, "batch_reward": 0.17933296266943216, "critic_loss": 0.3885891482979059, "actor_loss": -23.810981533050537, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.079301834106445, "step": 52000}
{"episode_reward": 215.8754506539568, "episode": 53.0, "batch_reward": 0.18124570474028587, "critic_loss": 0.4119971214532852, "actor_loss": -23.97192551422119, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.500335216522217, "step": 53000}
{"episode_reward": 504.774497139769, "episode": 54.0, "batch_reward": 0.18751654548943042, "critic_loss": 0.38558821511268615, "actor_loss": -24.427474308013917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.9597487449646, "step": 54000}
{"episode_reward": 427.4363374662624, "episode": 55.0, "batch_reward": 0.1903865781724453, "critic_loss": 0.4366569072008133, "actor_loss": -24.627990745544434, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.521631717681885, "step": 55000}
{"episode_reward": 295.8784556985687, "episode": 56.0, "batch_reward": 0.19364246690273285, "critic_loss": 0.4425924748629332, "actor_loss": -24.78948790359497, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.850666522979736, "step": 56000}
{"episode_reward": 465.72927184200176, "episode": 57.0, "batch_reward": 0.19862562884390353, "critic_loss": 0.4522713954746723, "actor_loss": -25.11906373977661, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.49872374534607, "step": 57000}
{"episode_reward": 546.2246961255117, "episode": 58.0, "batch_reward": 0.20482397757470608, "critic_loss": 0.4240598511099815, "actor_loss": -25.861563949584962, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.477335214614868, "step": 58000}
{"episode_reward": 527.7410946324169, "episode": 59.0, "batch_reward": 0.207351875603199, "critic_loss": 0.442577344968915, "actor_loss": -25.776925926208495, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.256327152252197, "step": 59000}
{"episode_reward": 103.74020212967515, "episode": 60.0, "batch_reward": 0.20784784510731696, "critic_loss": 0.4174706765562296, "actor_loss": -25.87213041305542, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.5738422870636, "step": 60000}
{"episode_reward": 484.51407147880764, "episode": 61.0, "batch_reward": 0.21116221141815186, "critic_loss": 0.4519773746430874, "actor_loss": -26.29531209564209, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.91769552230835, "step": 61000}
{"episode_reward": 485.6545234040504, "episode": 62.0, "batch_reward": 0.21690503162145613, "critic_loss": 0.41032108168303966, "actor_loss": -26.688245277404786, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.0146586894989, "step": 62000}
{"episode_reward": 543.8557317884827, "episode": 63.0, "batch_reward": 0.22268194314837456, "critic_loss": 0.39528549887239933, "actor_loss": -27.220399448394776, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.519327878952026, "step": 63000}
{"episode_reward": 520.7217918115286, "episode": 64.0, "batch_reward": 0.22734307798743247, "critic_loss": 0.424640267431736, "actor_loss": -27.639700141906737, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.530200242996216, "step": 64000}
{"episode_reward": 534.4757745661086, "episode": 65.0, "batch_reward": 0.2314412162154913, "critic_loss": 0.3942140520066023, "actor_loss": -27.905741539001465, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.19811248779297, "step": 65000}
{"episode_reward": 336.1099201649861, "episode": 66.0, "batch_reward": 0.23316075557470323, "critic_loss": 0.4170297600030899, "actor_loss": -28.006066204071043, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.410127878189087, "step": 66000}
{"episode_reward": 529.6608262077341, "episode": 67.0, "batch_reward": 0.2373600343465805, "critic_loss": 0.3838413385897875, "actor_loss": -28.320861400604247, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.51204800605774, "step": 67000}
{"episode_reward": 515.3855687503163, "episode": 68.0, "batch_reward": 0.24258921447396278, "critic_loss": 0.41410967990756037, "actor_loss": -28.952512981414795, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.497410535812378, "step": 68000}
{"episode_reward": 495.6073474330874, "episode": 69.0, "batch_reward": 0.24535049659013747, "critic_loss": 0.40072274252772333, "actor_loss": -28.98597024154663, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.533758878707886, "step": 69000}
{"episode_reward": 489.7066208090594, "episode": 70.0, "batch_reward": 0.24893176706135273, "critic_loss": 0.4099494966864586, "actor_loss": -29.30203197479248, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.53290104866028, "step": 70000}
{"episode_reward": 506.4692009274809, "episode": 71.0, "batch_reward": 0.2541326122581959, "critic_loss": 0.3955422143936157, "actor_loss": -29.85625413131714, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.11237168312073, "step": 71000}
{"episode_reward": 536.8635025899874, "episode": 72.0, "batch_reward": 0.25622254660725596, "critic_loss": 0.3941715797483921, "actor_loss": -29.89292570114136, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.56551241874695, "step": 72000}
{"episode_reward": 473.9853094489039, "episode": 73.0, "batch_reward": 0.2597737725526094, "critic_loss": 0.4156652532666922, "actor_loss": -30.49432342529297, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.121281623840332, "step": 73000}
{"episode_reward": 528.6189550977523, "episode": 74.0, "batch_reward": 0.2627289117872715, "critic_loss": 0.3536485203206539, "actor_loss": -30.633543071746825, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.441811084747314, "step": 74000}
{"episode_reward": 509.9476758932621, "episode": 75.0, "batch_reward": 0.2676872941851616, "critic_loss": 0.42969337160885335, "actor_loss": -30.98609027862549, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.739243745803833, "step": 75000}
{"episode_reward": 532.3877246169568, "episode": 76.0, "batch_reward": 0.2706145002990961, "critic_loss": 0.3824772651642561, "actor_loss": -31.29989638519287, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.60292148590088, "step": 76000}
{"episode_reward": 534.761336665431, "episode": 77.0, "batch_reward": 0.27227881728112696, "critic_loss": 0.3774215422421694, "actor_loss": -31.47939637374878, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.762391805648804, "step": 77000}
{"episode_reward": 197.09408590793444, "episode": 78.0, "batch_reward": 0.2728814930319786, "critic_loss": 0.3872463516145945, "actor_loss": -31.27055184173584, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.51026725769043, "step": 78000}
{"episode_reward": 388.0325084407882, "episode": 79.0, "batch_reward": 0.275148596405983, "critic_loss": 0.4068680286258459, "actor_loss": -31.54185066986084, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.197535514831543, "step": 79000}
{"episode_reward": 495.2542553777959, "episode": 80.0, "batch_reward": 0.276361698448658, "critic_loss": 0.372868583932519, "actor_loss": -31.730036346435547, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.205766677856445, "step": 80000}
{"episode_reward": 574.2734056308797, "episode": 81.0, "batch_reward": 0.28101624466478825, "critic_loss": 0.40012905818223954, "actor_loss": -32.179693145751955, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.43992877006531, "step": 81000}
{"episode_reward": 541.7735091697455, "episode": 82.0, "batch_reward": 0.28422479186952115, "critic_loss": 0.3795072927027941, "actor_loss": -32.44741803741455, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.783642292022705, "step": 82000}
{"episode_reward": 570.7412199467075, "episode": 83.0, "batch_reward": 0.2886894701421261, "critic_loss": 0.3838982244580984, "actor_loss": -32.60290856933594, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.52543020248413, "step": 83000}
{"episode_reward": 546.529041721058, "episode": 84.0, "batch_reward": 0.28997688464820387, "critic_loss": 0.41559001134335993, "actor_loss": -32.94359664916992, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.003982305526733, "step": 84000}
{"episode_reward": 526.8697203338053, "episode": 85.0, "batch_reward": 0.29077061031758783, "critic_loss": 0.4051835824251175, "actor_loss": -32.861979446411134, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.617056608200073, "step": 85000}
{"episode_reward": 128.41570238866282, "episode": 86.0, "batch_reward": 0.2912324704527855, "critic_loss": 0.43851156836748123, "actor_loss": -33.15352658462525, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.058776140213013, "step": 86000}
{"episode_reward": 384.3280824763937, "episode": 87.0, "batch_reward": 0.29236860252916813, "critic_loss": 0.42274537704885007, "actor_loss": -33.10538858795166, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.57685112953186, "step": 87000}
{"episode_reward": 562.0115734469009, "episode": 88.0, "batch_reward": 0.29561689776182176, "critic_loss": 0.42291486233472825, "actor_loss": -33.38538750076294, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.605717658996582, "step": 88000}
{"episode_reward": 534.8791044722548, "episode": 89.0, "batch_reward": 0.2970675482302904, "critic_loss": 0.5266547238379717, "actor_loss": -33.66057596969605, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.45490336418152, "step": 89000}
{"episode_reward": 191.43319154819955, "episode": 90.0, "batch_reward": 0.29711355502903464, "critic_loss": 0.49589383175969126, "actor_loss": -34.03112599182129, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.69648027420044, "step": 90000}
{"episode_reward": 578.5657625586455, "episode": 91.0, "batch_reward": 0.30063469360768796, "critic_loss": 0.4625614157170057, "actor_loss": -34.25975466156006, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.45076084136963, "step": 91000}
{"episode_reward": 577.2328919459703, "episode": 92.0, "batch_reward": 0.30289196079969405, "critic_loss": 0.44183266326785087, "actor_loss": -34.311755084991454, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.5930073261261, "step": 92000}
{"episode_reward": 563.8586173295741, "episode": 93.0, "batch_reward": 0.30549123914539816, "critic_loss": 0.493250682130456, "actor_loss": -34.48885639190674, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.741814613342285, "step": 93000}
{"episode_reward": 370.5918555426826, "episode": 94.0, "batch_reward": 0.30757424323260785, "critic_loss": 0.43939508152008055, "actor_loss": -34.76324612426758, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.21755075454712, "step": 94000}
{"episode_reward": 547.6176604563734, "episode": 95.0, "batch_reward": 0.30745940054953097, "critic_loss": 0.42825906647741796, "actor_loss": -35.01825189971924, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.480462789535522, "step": 95000}
{"episode_reward": 391.7459545092441, "episode": 96.0, "batch_reward": 0.3103322565257549, "critic_loss": 0.44199392093718054, "actor_loss": -34.87875155639649, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.559396982192993, "step": 96000}
{"episode_reward": 550.3555435446019, "episode": 97.0, "batch_reward": 0.3127433790266514, "critic_loss": 0.4409018384814262, "actor_loss": -35.21865906906128, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.272583484649658, "step": 97000}
{"episode_reward": 559.4641188828144, "episode": 98.0, "batch_reward": 0.3164959592372179, "critic_loss": 0.48046310599148273, "actor_loss": -35.78588910293579, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.262141704559326, "step": 98000}
{"episode_reward": 579.9009261391064, "episode": 99.0, "batch_reward": 0.3169292561411858, "critic_loss": 0.4521547136455774, "actor_loss": -35.72363840484619, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.57634949684143, "step": 99000}
{"episode_reward": 569.398375995827, "episode": 100.0, "batch_reward": 0.3212001769542694, "critic_loss": 0.47157621824741364, "actor_loss": -35.92638399124146, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.793941020965576, "step": 100000}
{"episode_reward": 583.641982221336, "episode": 101.0, "batch_reward": 0.3233843464255333, "critic_loss": 0.49333254489302636, "actor_loss": -36.05518898010254, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.11280632019043, "step": 101000}
{"episode_reward": 544.6404671700352, "episode": 102.0, "batch_reward": 0.32499380433559416, "critic_loss": 0.4743315941244364, "actor_loss": -36.19161627960205, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.540496587753296, "step": 102000}
{"episode_reward": 316.9183359905957, "episode": 103.0, "batch_reward": 0.3245105831325054, "critic_loss": 0.4766200618296862, "actor_loss": -36.0549528541565, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.459821939468384, "step": 103000}
{"episode_reward": 559.8280414083091, "episode": 104.0, "batch_reward": 0.3285575961768627, "critic_loss": 0.477885410875082, "actor_loss": -36.4017834854126, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.495610237121582, "step": 104000}
{"episode_reward": 584.6342687588533, "episode": 105.0, "batch_reward": 0.3294458477497101, "critic_loss": 0.5211999071240425, "actor_loss": -36.58056910324097, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.71304416656494, "step": 105000}
{"episode_reward": 595.1611853736205, "episode": 106.0, "batch_reward": 0.33074764722585676, "critic_loss": 0.542289924621582, "actor_loss": -36.69672808456421, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.506051540374756, "step": 106000}
{"episode_reward": 162.82726886052313, "episode": 107.0, "batch_reward": 0.33066908237338066, "critic_loss": 0.5703142026364804, "actor_loss": -36.76819295501709, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.406240701675415, "step": 107000}
{"episode_reward": 572.8045941303509, "episode": 108.0, "batch_reward": 0.3323545716404915, "critic_loss": 0.5199627531021833, "actor_loss": -36.86229347229004, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.059890031814575, "step": 108000}
{"episode_reward": 590.3914293790052, "episode": 109.0, "batch_reward": 0.3363726701140404, "critic_loss": 0.5272894610017538, "actor_loss": -37.43137646102905, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.054844856262207, "step": 109000}
{"episode_reward": 503.0439858268065, "episode": 110.0, "batch_reward": 0.3338830341696739, "critic_loss": 0.5164223628640174, "actor_loss": -37.38686476516724, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.027931213378906, "step": 110000}
{"episode_reward": 11.061636506867591, "episode": 111.0, "batch_reward": 0.3307251992225647, "critic_loss": 0.5505408588349819, "actor_loss": -37.419284729003905, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.53173089027405, "step": 111000}
{"episode_reward": 12.822073307077243, "episode": 112.0, "batch_reward": 0.328990301579237, "critic_loss": 0.5215233048200607, "actor_loss": -37.48469356536865, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.083479404449463, "step": 112000}
{"episode_reward": 8.05535036151141, "episode": 113.0, "batch_reward": 0.3273263007700443, "critic_loss": 0.5334270137101412, "actor_loss": -37.51619044494629, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.104629516601562, "step": 113000}
{"episode_reward": 9.573582086208832, "episode": 114.0, "batch_reward": 0.323622056633234, "critic_loss": 0.4899795241653919, "actor_loss": -37.755944816589356, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04084587097168, "step": 114000}
{"episode_reward": 7.622492070460885, "episode": 115.0, "batch_reward": 0.32012661826610567, "critic_loss": 0.49276949401199815, "actor_loss": -37.586634532928464, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.07897186279297, "step": 115000}
{"episode_reward": 9.59743843228848, "episode": 116.0, "batch_reward": 0.3169567532390356, "critic_loss": 0.47007375507056715, "actor_loss": -37.684119873046875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05231761932373, "step": 116000}
{"episode_reward": 13.42784963403126, "episode": 117.0, "batch_reward": 0.31702973271906376, "critic_loss": 0.49931579549610616, "actor_loss": -37.93786524963379, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04841446876526, "step": 117000}
{"episode_reward": 179.04957621033518, "episode": 118.0, "batch_reward": 0.31462659227848055, "critic_loss": 0.4764078816175461, "actor_loss": -37.541737316131595, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05962085723877, "step": 118000}
{"episode_reward": 23.362643456533917, "episode": 119.0, "batch_reward": 0.31341134540736676, "critic_loss": 0.432320894703269, "actor_loss": -37.43022737121582, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.028564453125, "step": 119000}
{"episode_reward": 558.3300849513286, "episode": 120.0, "batch_reward": 0.3156996268779039, "critic_loss": 0.4122803982794285, "actor_loss": -37.60089966583252, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.994937419891357, "step": 120000}
{"episode_reward": 596.6611454781494, "episode": 121.0, "batch_reward": 0.3186191509962082, "critic_loss": 0.40097058603167535, "actor_loss": -37.666505912780764, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.55702805519104, "step": 121000}
{"episode_reward": 582.1935255592132, "episode": 122.0, "batch_reward": 0.321651132106781, "critic_loss": 0.39131406232714655, "actor_loss": -37.806131519317624, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.075926542282104, "step": 122000}
{"episode_reward": 617.8688317393128, "episode": 123.0, "batch_reward": 0.32222248850762847, "critic_loss": 0.4586494193524122, "actor_loss": -38.04482847595215, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.090261459350586, "step": 123000}
{"episode_reward": 528.9988509118107, "episode": 124.0, "batch_reward": 0.3242185101658106, "critic_loss": 0.4452766680717468, "actor_loss": -38.18874521636963, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.09546947479248, "step": 124000}
{"episode_reward": 569.2665362740352, "episode": 125.0, "batch_reward": 0.3269411751627922, "critic_loss": 0.47779162785410884, "actor_loss": -38.313999641418455, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.109989881515503, "step": 125000}
{"episode_reward": 594.8750042716447, "episode": 126.0, "batch_reward": 0.3275583176314831, "critic_loss": 0.48133922481536867, "actor_loss": -38.49521266174317, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.111898183822632, "step": 126000}
{"episode_reward": 606.9375795898178, "episode": 127.0, "batch_reward": 0.3316598523557186, "critic_loss": 0.4421534213721752, "actor_loss": -38.73994578552246, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.072004318237305, "step": 127000}
{"episode_reward": 593.8343481014676, "episode": 128.0, "batch_reward": 0.33308396822214126, "critic_loss": 0.4425466893315315, "actor_loss": -38.74493054199219, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0953209400177, "step": 128000}
{"episode_reward": 601.6372459008375, "episode": 129.0, "batch_reward": 0.3337953081727028, "critic_loss": 0.4663335004597902, "actor_loss": -38.79614541625977, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.074530601501465, "step": 129000}
{"episode_reward": 565.3473821389895, "episode": 130.0, "batch_reward": 0.33592706006765366, "critic_loss": 0.4584907025396824, "actor_loss": -39.211457534790036, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.082514762878418, "step": 130000}
{"episode_reward": 232.98172747045126, "episode": 131.0, "batch_reward": 0.3359182816743851, "critic_loss": 0.4398326755166054, "actor_loss": -39.003357292175295, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.75626349449158, "step": 131000}
{"episode_reward": 560.4616853083869, "episode": 132.0, "batch_reward": 0.3360877071917057, "critic_loss": 0.42052074860036376, "actor_loss": -39.20018260192871, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.067123889923096, "step": 132000}
{"episode_reward": 585.7452126599729, "episode": 133.0, "batch_reward": 0.3382475669980049, "critic_loss": 0.4458797899931669, "actor_loss": -39.308721923828124, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.089400053024292, "step": 133000}
{"episode_reward": 563.5867184914151, "episode": 134.0, "batch_reward": 0.34129485303163526, "critic_loss": 0.42784566900134086, "actor_loss": -39.480309104919435, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.046363830566406, "step": 134000}
{"episode_reward": 576.4124922591509, "episode": 135.0, "batch_reward": 0.3428759343624115, "critic_loss": 0.4198518228828907, "actor_loss": -39.58674780273437, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.015785694122314, "step": 135000}
{"episode_reward": 607.118882611039, "episode": 136.0, "batch_reward": 0.3445294498503208, "critic_loss": 0.4035221644937992, "actor_loss": -39.61085444641113, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.046184539794922, "step": 136000}
{"episode_reward": 592.2673418122358, "episode": 137.0, "batch_reward": 0.347188324958086, "critic_loss": 0.42299451753497125, "actor_loss": -39.932147018432616, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.036673545837402, "step": 137000}
{"episode_reward": 596.0821197545343, "episode": 138.0, "batch_reward": 0.34907822823524476, "critic_loss": 0.434721573472023, "actor_loss": -39.879956184387204, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.006754398345947, "step": 138000}
{"episode_reward": 627.0012995924235, "episode": 139.0, "batch_reward": 0.35082527059316637, "critic_loss": 0.39323021242022516, "actor_loss": -40.012772300720215, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.032267332077026, "step": 139000}
{"episode_reward": 602.2024682720885, "episode": 140.0, "batch_reward": 0.3529782619476318, "critic_loss": 0.41814055360853675, "actor_loss": -40.14412900543213, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.033398866653442, "step": 140000}
{"episode_reward": 578.3358586439291, "episode": 141.0, "batch_reward": 0.3535820022523403, "critic_loss": 0.4285104650557041, "actor_loss": -40.172806747436525, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.403663873672485, "step": 141000}
{"episode_reward": 588.1100832439975, "episode": 142.0, "batch_reward": 0.3553382721543312, "critic_loss": 0.38850591661036016, "actor_loss": -40.31145738220215, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01591420173645, "step": 142000}
{"episode_reward": 612.4616824683872, "episode": 143.0, "batch_reward": 0.3571765500307083, "critic_loss": 0.38935687047243117, "actor_loss": -40.539055000305176, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.024702787399292, "step": 143000}
{"episode_reward": 610.8207842103253, "episode": 144.0, "batch_reward": 0.35932022765278815, "critic_loss": 0.4068891762346029, "actor_loss": -40.57010608673096, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.055100440979004, "step": 144000}
{"episode_reward": 606.7393172141101, "episode": 145.0, "batch_reward": 0.36091371935606004, "critic_loss": 0.41972135800123217, "actor_loss": -40.69691809082031, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04148578643799, "step": 145000}
{"episode_reward": 608.6381702502265, "episode": 146.0, "batch_reward": 0.36259716567397116, "critic_loss": 0.42409869138896467, "actor_loss": -40.74260866546631, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.057867288589478, "step": 146000}
{"episode_reward": 614.283552637395, "episode": 147.0, "batch_reward": 0.3639143878519535, "critic_loss": 0.3964046767205, "actor_loss": -40.7692748260498, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.026386737823486, "step": 147000}
{"episode_reward": 602.2592887644829, "episode": 148.0, "batch_reward": 0.3659465951025486, "critic_loss": 0.4033041188418865, "actor_loss": -40.97997343444824, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.034528017044067, "step": 148000}
{"episode_reward": 636.3254782710258, "episode": 149.0, "batch_reward": 0.3661424016952515, "critic_loss": 0.3987636299133301, "actor_loss": -41.05273254394531, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.050262689590454, "step": 149000}
{"episode_reward": 193.4281193306748, "episode": 150.0, "batch_reward": 0.3665436625778675, "critic_loss": 0.4061310719549656, "actor_loss": -40.90893649291992, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
