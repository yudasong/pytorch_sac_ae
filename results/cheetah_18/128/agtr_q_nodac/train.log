{"episode": 1.0, "duration": 20.591428756713867, "episode_reward": 4.20996189079657, "step": 1000}
{"episode": 2.0, "duration": 1.8471384048461914, "episode_reward": 252.2457487418515, "step": 2000}
{"episode": 3.0, "batch_reward": 0.12281155384761487, "actor_loss": -35.712469575690385, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254236, "duration": 64.2047770023346, "episode_reward": 46.01521010511295, "step": 3000}
{"episode": 4.0, "batch_reward": 0.09947298597544432, "actor_loss": -34.00039120101929, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.280744075775146, "episode_reward": 71.67993765688965, "step": 4000}
{"episode": 5.0, "batch_reward": 0.09263664764910937, "actor_loss": -31.982549995422364, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.806215286254883, "episode_reward": 91.92615983649067, "step": 5000}
{"episode": 6.0, "batch_reward": 0.0943377128392458, "actor_loss": -31.97670560836792, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.87144112586975, "episode_reward": 103.15752955294825, "step": 6000}
{"episode": 7.0, "batch_reward": 0.09573035840690136, "actor_loss": -32.28070552444458, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.59179925918579, "episode_reward": 94.9917133394393, "step": 7000}
{"episode": 8.0, "batch_reward": 0.09631036406010389, "actor_loss": -32.38531297302246, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.149662494659424, "episode_reward": 86.8922550111963, "step": 8000}
{"episode": 9.0, "batch_reward": 0.09384054695069789, "actor_loss": -30.935002365112304, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.75674271583557, "episode_reward": 63.19545783666174, "step": 9000}
{"episode": 10.0, "batch_reward": 0.09122546067088842, "actor_loss": -29.826403038024903, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.94771671295166, "episode_reward": 82.93077533363675, "step": 10000}
{"episode": 11.0, "batch_reward": 0.08920431733503938, "actor_loss": -28.89476923751831, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 41.71300148963928, "episode_reward": 66.95983418380752, "step": 11000}
{"episode": 12.0, "batch_reward": 0.08930147443711757, "actor_loss": -28.403984558105467, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.896976232528687, "episode_reward": 132.50859371993727, "step": 12000}
{"episode": 13.0, "batch_reward": 0.0939564172513783, "actor_loss": -29.07938231277466, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.332618474960327, "episode_reward": 146.17915549077478, "step": 13000}
{"episode": 14.0, "batch_reward": 0.0952707387432456, "actor_loss": -29.10272982788086, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.35376763343811, "episode_reward": 62.79911380674963, "step": 14000}
{"episode": 15.0, "batch_reward": 0.09582951041311026, "actor_loss": -28.72429981613159, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.090046882629395, "episode_reward": 138.74220447831698, "step": 15000}
{"episode": 16.0, "batch_reward": 0.09778487347066403, "actor_loss": -28.761797103881836, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.92333221435547, "episode_reward": 134.999486656051, "step": 16000}
{"episode": 17.0, "batch_reward": 0.09995474995672703, "actor_loss": -29.097496856689453, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.652615308761597, "episode_reward": 97.77618678293256, "step": 17000}
{"episode": 18.0, "batch_reward": 0.09974433279782534, "actor_loss": -28.516165363311767, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.12293243408203, "episode_reward": 90.27356629530246, "step": 18000}
{"episode": 19.0, "batch_reward": 0.09971821883320808, "actor_loss": -28.18302404022217, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.053948163986206, "episode_reward": 116.08169110410623, "step": 19000}
{"episode": 20.0, "batch_reward": 0.10082667122036218, "actor_loss": -28.051628997802734, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.68696427345276, "episode_reward": 177.1889895307859, "step": 20000}
{"episode": 21.0, "batch_reward": 0.1041897466853261, "actor_loss": -28.03854988861084, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 42.018470287323, "episode_reward": 125.33121080970096, "step": 21000}
{"episode": 22.0, "batch_reward": 0.10665950082242488, "actor_loss": -28.095656169891356, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.287321090698242, "episode_reward": 211.73783013509188, "step": 22000}
{"episode": 23.0, "batch_reward": 0.11007244428992272, "actor_loss": -28.26978423690796, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.38040852546692, "episode_reward": 198.95124498324859, "step": 23000}
{"episode": 24.0, "batch_reward": 0.11526393190026284, "actor_loss": -28.794130470275878, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.780174255371094, "episode_reward": 213.02867245519326, "step": 24000}
{"episode": 25.0, "batch_reward": 0.1189015953540802, "actor_loss": -28.93026064682007, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.480828762054443, "episode_reward": 166.44551623778403, "step": 25000}
{"episode": 26.0, "batch_reward": 0.11842779807001352, "actor_loss": -28.578406852722168, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.65438222885132, "episode_reward": 57.674132738087124, "step": 26000}
{"episode": 27.0, "batch_reward": 0.12064625915139914, "actor_loss": -28.558832984924315, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.800334453582764, "episode_reward": 286.86482419393093, "step": 27000}
{"episode": 28.0, "batch_reward": 0.12340089914947748, "actor_loss": -28.613301498413087, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.916049242019653, "episode_reward": 106.27002495561764, "step": 28000}
{"episode": 29.0, "batch_reward": 0.12241379918903113, "actor_loss": -28.14034812927246, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.46428418159485, "episode_reward": 79.4683607771352, "step": 29000}
{"episode": 30.0, "batch_reward": 0.12077548864483834, "actor_loss": -27.81632658004761, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.360138654708862, "episode_reward": 93.3905954771984, "step": 30000}
{"episode": 31.0, "batch_reward": 0.12335753600299358, "actor_loss": -27.860874557495116, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 41.219316720962524, "episode_reward": 321.8207174084738, "step": 31000}
{"episode": 32.0, "batch_reward": 0.1258531136661768, "actor_loss": -27.949257446289064, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.485195875167847, "episode_reward": 59.96792559026021, "step": 32000}
{"episode": 33.0, "batch_reward": 0.12490156814455985, "actor_loss": -27.628726432800292, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.768624544143677, "episode_reward": 208.50703937366075, "step": 33000}
{"episode": 34.0, "batch_reward": 0.12702582869678736, "actor_loss": -27.699004013061522, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.55521011352539, "episode_reward": 111.96992851438563, "step": 34000}
{"episode": 35.0, "batch_reward": 0.1275230502486229, "actor_loss": -27.638377223968504, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.772387504577637, "episode_reward": 121.61817067989926, "step": 35000}
{"episode": 36.0, "batch_reward": 0.1265800821557641, "actor_loss": -27.477382930755617, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.898051738739014, "episode_reward": 99.53781993174448, "step": 36000}
{"episode": 37.0, "batch_reward": 0.12722766494750976, "actor_loss": -27.33363508224487, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.923089265823364, "episode_reward": 141.0479491045331, "step": 37000}
{"episode": 38.0, "batch_reward": 0.12892051831632853, "actor_loss": -27.474915142059327, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.143721342086792, "episode_reward": 327.88121660615815, "step": 38000}
{"episode": 39.0, "batch_reward": 0.13117582573741673, "actor_loss": -27.592835395812987, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.00722646713257, "episode_reward": 89.49749608441566, "step": 39000}
{"episode": 40.0, "batch_reward": 0.1301112446412444, "actor_loss": -27.23618405151367, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.275861978530884, "episode_reward": 76.58047299750572, "step": 40000}
{"episode": 41.0, "batch_reward": 0.128126544252038, "actor_loss": -26.83592207336426, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 39.79858756065369, "episode_reward": 53.18421389732967, "step": 41000}
{"episode": 42.0, "batch_reward": 0.12756013522297144, "actor_loss": -26.783261672973634, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.383368968963623, "episode_reward": 108.35697498738966, "step": 42000}
{"episode": 43.0, "batch_reward": 0.12763524589687586, "actor_loss": -26.651823944091795, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.51473379135132, "episode_reward": 181.4744855683775, "step": 43000}
{"episode": 44.0, "batch_reward": 0.12783968281000851, "actor_loss": -26.581969951629638, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.834202527999878, "episode_reward": 56.79365830597485, "step": 44000}
{"episode": 45.0, "batch_reward": 0.1280143543332815, "actor_loss": -26.48708008956909, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 25.819763660430908, "episode_reward": 265.45112363582916, "step": 45000}
{"episode": 46.0, "batch_reward": 0.12939563446491956, "actor_loss": -26.511466915130615, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.68175983428955, "episode_reward": 72.14264640833227, "step": 46000}
{"episode": 47.0, "batch_reward": 0.1303202931508422, "actor_loss": -26.606786422729492, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.526869773864746, "episode_reward": 317.14489099159056, "step": 47000}
{"episode": 48.0, "batch_reward": 0.13098647612333297, "actor_loss": -26.660114685058595, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.22937297821045, "episode_reward": 51.620398667900325, "step": 48000}
{"episode": 49.0, "batch_reward": 0.1302634988874197, "actor_loss": -26.493464168548584, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.177898406982422, "episode_reward": 68.60769023635085, "step": 49000}
{"episode": 50.0, "batch_reward": 0.12903333715349435, "actor_loss": -26.10014847564697, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.94470500946045, "episode_reward": 44.70959311323418, "step": 50000}
{"episode": 51.0, "batch_reward": 0.12809160397201777, "actor_loss": -26.001780361175538, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 39.265042781829834, "episode_reward": 184.399217694955, "step": 51000}
{"episode": 52.0, "batch_reward": 0.12783350796997547, "actor_loss": -25.921935512542724, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.188291311264038, "episode_reward": 52.00284687646186, "step": 52000}
{"episode": 53.0, "batch_reward": 0.12827556709200144, "actor_loss": -25.802058574676515, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.895648956298828, "episode_reward": 144.45973726609577, "step": 53000}
{"episode": 54.0, "batch_reward": 0.12771651484817267, "actor_loss": -25.66282753753662, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.880641222000122, "episode_reward": 137.3689574684929, "step": 54000}
{"episode": 55.0, "batch_reward": 0.1285363399684429, "actor_loss": -25.760744556427003, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.95809769630432, "episode_reward": 91.45036148714695, "step": 55000}
{"episode": 56.0, "batch_reward": 0.12773764707893134, "actor_loss": -25.521302017211916, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.50302505493164, "episode_reward": 133.17530815684057, "step": 56000}
{"episode": 57.0, "batch_reward": 0.12759425132721663, "actor_loss": -25.421964363098144, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.534573078155518, "episode_reward": 93.9504714668728, "step": 57000}
{"episode": 58.0, "batch_reward": 0.1270969659909606, "actor_loss": -25.245675731658935, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.316708087921143, "episode_reward": 98.05141147136293, "step": 58000}
{"episode": 59.0, "batch_reward": 0.12601036187261344, "actor_loss": -25.095980869293214, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.7273850440979, "episode_reward": 126.73268091794596, "step": 59000}
{"episode": 60.0, "batch_reward": 0.12837283159792423, "actor_loss": -25.298728733062745, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.850894689559937, "episode_reward": 305.3660586513248, "step": 60000}
{"episode": 61.0, "batch_reward": 0.13007341112196447, "actor_loss": -25.40307930755615, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 38.22690153121948, "episode_reward": 126.31527508552314, "step": 61000}
{"episode": 62.0, "batch_reward": 0.12895935474336148, "actor_loss": -25.17971374130249, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.098230361938477, "episode_reward": 66.49662278411954, "step": 62000}
{"episode": 63.0, "batch_reward": 0.12805501279979944, "actor_loss": -24.96032801055908, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.998366594314575, "episode_reward": 74.35605938549908, "step": 63000}
{"episode": 64.0, "batch_reward": 0.12682131495326757, "actor_loss": -24.89765128326416, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.911750316619873, "episode_reward": 107.65325594071118, "step": 64000}
{"episode": 65.0, "batch_reward": 0.12678432243317367, "actor_loss": -24.615994983673097, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.986143827438354, "episode_reward": 100.77069398717413, "step": 65000}
{"episode": 66.0, "batch_reward": 0.12755063459277152, "actor_loss": -24.634974643707274, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.81954550743103, "episode_reward": 156.9291928272076, "step": 66000}
{"episode": 67.0, "batch_reward": 0.12652443385869264, "actor_loss": -24.485532962799073, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.637656927108765, "episode_reward": 66.82009742155152, "step": 67000}
{"episode": 68.0, "batch_reward": 0.12667533314973117, "actor_loss": -24.486419551849366, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.679811000823975, "episode_reward": 278.9762588429531, "step": 68000}
{"episode": 69.0, "batch_reward": 0.12880215153843164, "actor_loss": -24.698409580230713, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.289973497390747, "episode_reward": 105.29322135060981, "step": 69000}
{"episode": 70.0, "batch_reward": 0.12815284430980683, "actor_loss": -24.60039543914795, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.34002423286438, "episode_reward": 140.03704434283603, "step": 70000}
{"episode": 71.0, "batch_reward": 0.1279574663117528, "actor_loss": -24.525477031707762, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 38.71275186538696, "episode_reward": 94.52622795906156, "step": 71000}
{"episode": 72.0, "batch_reward": 0.12771588687598706, "actor_loss": -24.467685596466065, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.365496397018433, "episode_reward": 64.29511310260591, "step": 72000}
{"episode": 73.0, "batch_reward": 0.12654423028975725, "actor_loss": -24.212812633514403, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.875413417816162, "episode_reward": 42.88977805547829, "step": 73000}
{"episode": 74.0, "batch_reward": 0.1257365878969431, "actor_loss": -24.089843978881834, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.971198081970215, "episode_reward": 73.53860059333671, "step": 74000}
{"episode": 75.0, "batch_reward": 0.12419902784377336, "actor_loss": -23.837039569854735, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.71079921722412, "episode_reward": 42.65583679143532, "step": 75000}
{"episode": 76.0, "batch_reward": 0.12397483842074872, "actor_loss": -23.72195774078369, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.041022777557373, "episode_reward": 46.78162825820412, "step": 76000}
{"episode": 77.0, "batch_reward": 0.12285742647945881, "actor_loss": -23.55891877746582, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.701152086257935, "episode_reward": 72.08139412793716, "step": 77000}
{"episode": 78.0, "batch_reward": 0.12149216532707215, "actor_loss": -23.368413372039797, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.564907550811768, "episode_reward": 76.93302298546223, "step": 78000}
{"episode": 79.0, "batch_reward": 0.12156122609972954, "actor_loss": -23.348221843719482, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.1642963886261, "episode_reward": 97.56075798146836, "step": 79000}
{"episode": 80.0, "batch_reward": 0.12262746276706457, "actor_loss": -23.443283168792725, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.00952434539795, "episode_reward": 271.7116766288663, "step": 80000}
{"episode": 81.0, "batch_reward": 0.12377051385492087, "actor_loss": -23.5095344581604, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 38.48268127441406, "episode_reward": 164.35087631239227, "step": 81000}
{"episode": 82.0, "batch_reward": 0.12448791353404522, "actor_loss": -23.50969926071167, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.361687898635864, "episode_reward": 154.05195747289886, "step": 82000}
{"episode": 83.0, "batch_reward": 0.1239023765400052, "actor_loss": -23.501544765472413, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.19808602333069, "episode_reward": 89.93905188065891, "step": 83000}
{"episode": 84.0, "batch_reward": 0.12308885234594345, "actor_loss": -23.40823783493042, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.853251934051514, "episode_reward": 49.194452127659154, "step": 84000}
{"episode": 85.0, "batch_reward": 0.12382623460888863, "actor_loss": -23.387043979644776, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.5886127948761, "episode_reward": 293.4352542732428, "step": 85000}
{"episode": 86.0, "batch_reward": 0.12574361604452133, "actor_loss": -23.606002838134767, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.662039041519165, "episode_reward": 322.04207038158796, "step": 86000}
{"episode": 87.0, "batch_reward": 0.12784828720241784, "actor_loss": -23.696940578460694, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.883766412734985, "episode_reward": 118.78811290743124, "step": 87000}
{"episode": 88.0, "batch_reward": 0.12726457356661558, "actor_loss": -23.66357607269287, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.545418739318848, "episode_reward": 170.70215549623003, "step": 88000}
{"episode": 89.0, "batch_reward": 0.12872680379450321, "actor_loss": -23.770538333892823, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.790745496749878, "episode_reward": 313.41511417790576, "step": 89000}
{"episode": 90.0, "batch_reward": 0.1308478020131588, "actor_loss": -23.94354162979126, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.092285633087158, "episode_reward": 362.6571476213287, "step": 90000}
{"episode": 91.0, "batch_reward": 0.1318487643674016, "actor_loss": -24.08893843841553, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 38.28616714477539, "episode_reward": 172.89982789749854, "step": 91000}
{"episode": 92.0, "batch_reward": 0.13257665952295064, "actor_loss": -24.152179431915282, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.586259603500366, "episode_reward": 70.45665939337144, "step": 92000}
{"episode": 93.0, "batch_reward": 0.13146521601080893, "actor_loss": -23.936252128601073, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.291999101638794, "episode_reward": 41.858950353414755, "step": 93000}
{"episode": 94.0, "batch_reward": 0.13144086968898774, "actor_loss": -23.831457843780516, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.92261791229248, "episode_reward": 158.8926257928139, "step": 94000}
{"episode": 95.0, "batch_reward": 0.13068850187957287, "actor_loss": -23.714431167602537, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.681047677993774, "episode_reward": 59.54295742986459, "step": 95000}
{"episode": 96.0, "batch_reward": 0.1304975913465023, "actor_loss": -23.712081745147707, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.821889877319336, "episode_reward": 37.162267882674456, "step": 96000}
{"episode": 97.0, "batch_reward": 0.1301979882195592, "actor_loss": -23.712853870391847, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.58621311187744, "episode_reward": 156.25105655421453, "step": 97000}
{"episode": 98.0, "batch_reward": 0.13049991948902606, "actor_loss": -23.587524921417238, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.818032026290894, "episode_reward": 166.28552165802378, "step": 98000}
{"episode": 99.0, "batch_reward": 0.1297604859471321, "actor_loss": -23.403636478424072, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.620726585388184, "episode_reward": 136.61888794517316, "step": 99000}
{"episode": 100.0, "batch_reward": 0.12944103810191154, "actor_loss": -23.4898511428833, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.16604447364807, "episode_reward": 68.75377328871991, "step": 100000}
{"episode": 101.0, "batch_reward": 0.13104637628793717, "actor_loss": -23.620266914367676, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 38.41548156738281, "episode_reward": 376.2191821939593, "step": 101000}
{"episode": 102.0, "batch_reward": 0.13246237115561962, "actor_loss": -23.75132033920288, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.96566128730774, "episode_reward": 151.28935857988273, "step": 102000}
{"episode": 103.0, "batch_reward": 0.13328533862531186, "actor_loss": -23.736309772491456, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.967838764190674, "episode_reward": 146.4993131531348, "step": 103000}
{"episode": 104.0, "batch_reward": 0.13362365406751633, "actor_loss": -23.738301975250245, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.676977157592773, "episode_reward": 352.1163271453197, "step": 104000}
{"episode": 105.0, "batch_reward": 0.1356529671475291, "actor_loss": -23.992568019866944, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.19296884536743, "episode_reward": 299.46883495573707, "step": 105000}
{"episode": 106.0, "batch_reward": 0.13639850121736527, "actor_loss": -24.092565063476563, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.77362608909607, "episode_reward": 332.58582807536106, "step": 106000}
{"episode": 107.0, "batch_reward": 0.1382095025256276, "actor_loss": -24.278726207733154, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.998461723327637, "episode_reward": 189.1125623519533, "step": 107000}
{"episode": 108.0, "batch_reward": 0.13809854675084351, "actor_loss": -24.106867454528807, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.890658617019653, "episode_reward": 158.37687380290214, "step": 108000}
{"episode": 109.0, "batch_reward": 0.13952006847411394, "actor_loss": -24.27133498764038, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.963645458221436, "episode_reward": 311.44371400068746, "step": 109000}
{"episode": 110.0, "batch_reward": 0.1412458406686783, "actor_loss": -24.373850685119628, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.09110403060913, "episode_reward": 408.0760208041096, "step": 110000}
{"episode": 111.0, "batch_reward": 0.1438521540015936, "actor_loss": -24.634824729919433, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 38.34796118736267, "episode_reward": 402.4550235716348, "step": 111000}
{"episode": 112.0, "batch_reward": 0.14578348124027252, "actor_loss": -24.83468846130371, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.35716199874878, "episode_reward": 326.5944061981716, "step": 112000}
{"episode": 113.0, "batch_reward": 0.1470625227242708, "actor_loss": -25.06755221557617, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.122400522232056, "episode_reward": 389.5390253186217, "step": 113000}
{"episode": 114.0, "batch_reward": 0.1481640431061387, "actor_loss": -25.142694702148436, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.855361700057983, "episode_reward": 77.25692662809554, "step": 114000}
{"episode": 115.0, "batch_reward": 0.14891375969350337, "actor_loss": -25.252762775421143, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.968193292617798, "episode_reward": 383.5064860525423, "step": 115000}
{"episode": 116.0, "batch_reward": 0.15111388846486806, "actor_loss": -25.343276020050048, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.168797969818115, "episode_reward": 405.4795451391637, "step": 116000}
{"episode": 117.0, "batch_reward": 0.15254351299256086, "actor_loss": -25.45271639251709, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.75153350830078, "episode_reward": 393.5844243631331, "step": 117000}
{"episode": 118.0, "batch_reward": 0.15610953518003226, "actor_loss": -25.873232124328613, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.72729253768921, "episode_reward": 294.3139631835635, "step": 118000}
{"episode": 119.0, "batch_reward": 0.155861374899745, "actor_loss": -25.84214538192749, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.471829414367676, "episode_reward": 89.15966711629635, "step": 119000}
{"episode": 120.0, "batch_reward": 0.15436292678117752, "actor_loss": -25.634897926330567, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.03552508354187, "episode_reward": 109.63012183011841, "step": 120000}
{"episode": 121.0, "batch_reward": 0.15479842069745064, "actor_loss": -25.54596616744995, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 38.690476179122925, "episode_reward": 118.89480790598545, "step": 121000}
{"episode": 122.0, "batch_reward": 0.1543005282357335, "actor_loss": -25.494723514556885, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.02614426612854, "episode_reward": 66.8383910173714, "step": 122000}
{"episode": 123.0, "batch_reward": 0.1538645223006606, "actor_loss": -25.41254493331909, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.14407205581665, "episode_reward": 145.93372697031634, "step": 123000}
{"episode": 124.0, "batch_reward": 0.15525803361833096, "actor_loss": -25.614182464599608, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.790679454803467, "episode_reward": 362.04462366165205, "step": 124000}
{"episode": 125.0, "batch_reward": 0.15494336964935065, "actor_loss": -25.572461811065672, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.85483455657959, "episode_reward": 122.03542820128074, "step": 125000}
{"episode": 126.0, "batch_reward": 0.15489147429913283, "actor_loss": -25.43899426651001, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.68363308906555, "episode_reward": 79.32401952565529, "step": 126000}
{"episode": 127.0, "batch_reward": 0.1553931273072958, "actor_loss": -25.613852661132814, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.66320037841797, "episode_reward": 307.57203081283643, "step": 127000}
{"episode": 128.0, "batch_reward": 0.15593892697989942, "actor_loss": -25.57165480041504, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.858859062194824, "episode_reward": 50.67186350306229, "step": 128000}
{"episode": 129.0, "batch_reward": 0.1546105035468936, "actor_loss": -25.385924098968506, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.69201421737671, "episode_reward": 42.111230134655806, "step": 129000}
{"episode": 130.0, "batch_reward": 0.15423806377500296, "actor_loss": -25.414426162719728, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.888195514678955, "episode_reward": 306.0435459989378, "step": 130000}
{"episode": 131.0, "batch_reward": 0.15541594856232405, "actor_loss": -25.501323883056642, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 39.9736602306366, "episode_reward": 152.5015240582681, "step": 131000}
{"episode": 132.0, "batch_reward": 0.15479100485891104, "actor_loss": -25.477427940368653, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.479334354400635, "episode_reward": 68.30823702711972, "step": 132000}
{"episode": 133.0, "batch_reward": 0.1544044340699911, "actor_loss": -25.343360752105713, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.20818543434143, "episode_reward": 82.01256672642599, "step": 133000}
{"episode": 134.0, "batch_reward": 0.15505461513996124, "actor_loss": -25.431491138458252, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.137070417404175, "episode_reward": 140.44689774869605, "step": 134000}
{"episode": 135.0, "batch_reward": 0.15462635624408722, "actor_loss": -25.407748096466065, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.495338439941406, "episode_reward": 336.87400941652345, "step": 135000}
{"episode": 136.0, "batch_reward": 0.15546716806292535, "actor_loss": -25.37377222061157, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.934070587158203, "episode_reward": 200.9175518738823, "step": 136000}
{"episode": 137.0, "batch_reward": 0.15560654001682997, "actor_loss": -25.550592498779295, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.930479049682617, "episode_reward": 88.56580527608357, "step": 137000}
{"episode": 138.0, "batch_reward": 0.15525415965169667, "actor_loss": -25.345937370300295, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.66539454460144, "episode_reward": 78.35559270181315, "step": 138000}
{"episode": 139.0, "batch_reward": 0.15556025045365096, "actor_loss": -25.330562782287597, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.878807544708252, "episode_reward": 206.07522429292493, "step": 139000}
{"episode": 140.0, "batch_reward": 0.15451657081395387, "actor_loss": -25.135674255371093, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.68337893486023, "episode_reward": 199.0178434609819, "step": 140000}
{"episode": 141.0, "batch_reward": 0.15490570334345102, "actor_loss": -25.222679912567138, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 40.99903631210327, "episode_reward": 123.84683073337534, "step": 141000}
{"episode": 142.0, "batch_reward": 0.1553302547261119, "actor_loss": -25.37131481552124, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.335013389587402, "episode_reward": 311.8656561266804, "step": 142000}
{"episode": 143.0, "batch_reward": 0.15624796488881112, "actor_loss": -25.41815867614746, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.996013402938843, "episode_reward": 181.53634845687682, "step": 143000}
{"episode": 144.0, "batch_reward": 0.15587764672189952, "actor_loss": -25.42671176147461, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.50571370124817, "episode_reward": 122.77745883802432, "step": 144000}
{"episode": 145.0, "batch_reward": 0.1571677847057581, "actor_loss": -25.573067138671874, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.04345679283142, "episode_reward": 301.35648084670044, "step": 145000}
{"episode": 146.0, "batch_reward": 0.15729594587534665, "actor_loss": -25.49492007446289, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.902441263198853, "episode_reward": 120.94394014069611, "step": 146000}
{"episode": 147.0, "batch_reward": 0.155113806553185, "actor_loss": -25.291783267974854, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.849876880645752, "episode_reward": 49.25419560409664, "step": 147000}
{"episode": 148.0, "batch_reward": 0.15611317602545022, "actor_loss": -25.265710651397704, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.070815801620483, "episode_reward": 309.6723347045663, "step": 148000}
{"episode": 149.0, "batch_reward": 0.1583750713542104, "actor_loss": -25.60632223510742, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.989525079727173, "episode_reward": 319.1844855768727, "step": 149000}
{"episode": 150.0, "batch_reward": 0.1580502379834652, "actor_loss": -25.61721017074585, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "step": 150000}
