{"episode_reward": 0.0, "episode": 1.0, "duration": 17.486490488052368, "step": 1000}
{"episode_reward": 4.20996189079657, "episode": 2.0, "duration": 1.5250754356384277, "step": 2000}
{"episode_reward": 252.2457487418515, "episode": 3.0, "batch_reward": 0.1217253621929723, "critic_loss": 0.028448074743357865, "actor_loss": -14.169564534606291, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 60.82749342918396, "step": 3000}
{"episode_reward": 18.363118750274918, "episode": 4.0, "batch_reward": 0.08350878260284662, "critic_loss": 0.024775262135080994, "actor_loss": -13.015870154082775, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.082387447357178, "step": 4000}
{"episode_reward": 33.35645718269619, "episode": 5.0, "batch_reward": 0.07266715886443853, "critic_loss": 0.040960763070732355, "actor_loss": -12.277324936136603, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06695556640625, "step": 5000}
{"episode_reward": 40.56780666403395, "episode": 6.0, "batch_reward": 0.0707081767320633, "critic_loss": 0.056234602695330975, "actor_loss": -12.802977533474564, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.07447576522827, "step": 6000}
{"episode_reward": 77.15476727625705, "episode": 7.0, "batch_reward": 0.07438885955139994, "critic_loss": 0.0686792323552072, "actor_loss": -12.237016545962542, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.07650637626648, "step": 7000}
{"episode_reward": 85.05472147499542, "episode": 8.0, "batch_reward": 0.07688173675164581, "critic_loss": 0.08938510924577713, "actor_loss": -13.1639925416708, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.064907550811768, "step": 8000}
{"episode_reward": 83.337160870177, "episode": 9.0, "batch_reward": 0.07292161801084876, "critic_loss": 0.10408626169338822, "actor_loss": -11.84875114017725, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.073997020721436, "step": 9000}
{"episode_reward": 27.725623633332066, "episode": 10.0, "batch_reward": 0.07083578003197909, "critic_loss": 0.15761338705196976, "actor_loss": -11.960471063613891, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.076695442199707, "step": 10000}
{"episode_reward": 58.80049249268986, "episode": 11.0, "batch_reward": 0.06579507372155785, "critic_loss": 0.12247096231952309, "actor_loss": -11.171100534915924, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.53167939186096, "step": 11000}
{"episode_reward": 23.197656563484443, "episode": 12.0, "batch_reward": 0.06406341204419733, "critic_loss": 0.11895708069577814, "actor_loss": -11.502637848854064, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.050070762634277, "step": 12000}
{"episode_reward": 36.884048761965005, "episode": 13.0, "batch_reward": 0.062486835107207296, "critic_loss": 0.12971045001223683, "actor_loss": -11.247775335788727, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.10391402244568, "step": 13000}
{"episode_reward": 52.63182132107616, "episode": 14.0, "batch_reward": 0.06160370485857129, "critic_loss": 0.11838578101247549, "actor_loss": -11.808867556095123, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06574010848999, "step": 14000}
{"episode_reward": 48.22014985040709, "episode": 15.0, "batch_reward": 0.06302727314084769, "critic_loss": 0.14365966096147895, "actor_loss": -11.661529770851136, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.083964109420776, "step": 15000}
{"episode_reward": 153.6634284508019, "episode": 16.0, "batch_reward": 0.06832666911929845, "critic_loss": 0.19279907650500536, "actor_loss": -12.46423695755005, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.084376573562622, "step": 16000}
{"episode_reward": 91.56122843090041, "episode": 17.0, "batch_reward": 0.06751844619214535, "critic_loss": 0.17233978427946567, "actor_loss": -13.109084606170654, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.043270111083984, "step": 17000}
{"episode_reward": 60.79105950569363, "episode": 18.0, "batch_reward": 0.07225386698171496, "critic_loss": 0.20995886500924826, "actor_loss": -14.231707689285278, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.075262784957886, "step": 18000}
{"episode_reward": 160.05777695219456, "episode": 19.0, "batch_reward": 0.07346375019103289, "critic_loss": 0.19416307632625102, "actor_loss": -14.215120474815368, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06903910636902, "step": 19000}
{"episode_reward": 75.52552894596091, "episode": 20.0, "batch_reward": 0.07553682247549295, "critic_loss": 0.21815212389826774, "actor_loss": -14.60416821861267, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.056509971618652, "step": 20000}
{"episode_reward": 112.88082669946151, "episode": 21.0, "batch_reward": 0.07434429616481066, "critic_loss": 0.18096893223375082, "actor_loss": -14.413652160644531, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.602105140686035, "step": 21000}
{"episode_reward": 31.340592242859003, "episode": 22.0, "batch_reward": 0.07627062890306115, "critic_loss": 0.19082802400738, "actor_loss": -14.793276388168335, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.07951021194458, "step": 22000}
{"episode_reward": 240.42624481527756, "episode": 23.0, "batch_reward": 0.0845244700461626, "critic_loss": 0.1936659548729658, "actor_loss": -15.475430837631226, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.086949110031128, "step": 23000}
{"episode_reward": 277.28008952797313, "episode": 24.0, "batch_reward": 0.09047239004075527, "critic_loss": 0.20732469890266658, "actor_loss": -15.798154933929442, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.53688955307007, "step": 24000}
{"episode_reward": 128.53301739926601, "episode": 25.0, "batch_reward": 0.0924410297833383, "critic_loss": 0.24103444217890502, "actor_loss": -16.500636657714843, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04660415649414, "step": 25000}
{"episode_reward": 195.04589811433905, "episode": 26.0, "batch_reward": 0.0985610341578722, "critic_loss": 0.25797659868746997, "actor_loss": -16.704372997283937, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.056209087371826, "step": 26000}
{"episode_reward": 265.7192356570612, "episode": 27.0, "batch_reward": 0.10559228166937829, "critic_loss": 0.2844211868047714, "actor_loss": -17.252752977371216, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.07408046722412, "step": 27000}
{"episode_reward": 277.6412104150587, "episode": 28.0, "batch_reward": 0.11248083160817623, "critic_loss": 0.2882582717984915, "actor_loss": -18.162476139068602, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.078524351119995, "step": 28000}
{"episode_reward": 283.8881151073356, "episode": 29.0, "batch_reward": 0.11552217401564122, "critic_loss": 0.27582421292364595, "actor_loss": -18.0841547164917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0763521194458, "step": 29000}
{"episode_reward": 130.34622139369918, "episode": 30.0, "batch_reward": 0.1190759873315692, "critic_loss": 0.3221396539136767, "actor_loss": -18.274783039093016, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.075501918792725, "step": 30000}
{"episode_reward": 353.3797372362044, "episode": 31.0, "batch_reward": 0.12187733712792397, "critic_loss": 0.29401097328960896, "actor_loss": -19.088883893966674, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.54771113395691, "step": 31000}
{"episode_reward": 42.45558706951593, "episode": 32.0, "batch_reward": 0.12135747662931681, "critic_loss": 0.3020388529449701, "actor_loss": -18.457811822891234, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05733561515808, "step": 32000}
{"episode_reward": 116.61084743525234, "episode": 33.0, "batch_reward": 0.1250499918460846, "critic_loss": 0.31796821404993536, "actor_loss": -18.82173302078247, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.09244441986084, "step": 33000}
{"episode_reward": 441.1625852471346, "episode": 34.0, "batch_reward": 0.13200995133817195, "critic_loss": 0.32433658657968045, "actor_loss": -19.56475822067261, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.095918655395508, "step": 34000}
{"episode_reward": 202.19901817477322, "episode": 35.0, "batch_reward": 0.13568671964854, "critic_loss": 0.3173935272991657, "actor_loss": -19.6777886428833, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06763243675232, "step": 35000}
{"episode_reward": 407.57471820982335, "episode": 36.0, "batch_reward": 0.1400525032132864, "critic_loss": 0.3131831906288862, "actor_loss": -20.245218524932863, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04925012588501, "step": 36000}
{"episode_reward": 121.52905897607597, "episode": 37.0, "batch_reward": 0.1439835291802883, "critic_loss": 0.3025849884748459, "actor_loss": -20.24103382873535, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.086626052856445, "step": 37000}
{"episode_reward": 387.32509290571716, "episode": 38.0, "batch_reward": 0.14633684670180083, "critic_loss": 0.24749763636291028, "actor_loss": -20.4411397895813, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.071552991867065, "step": 38000}
{"episode_reward": 171.58552562396721, "episode": 39.0, "batch_reward": 0.14939798187464476, "critic_loss": 0.25544383088499306, "actor_loss": -20.82312668991089, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.07782244682312, "step": 39000}
{"episode_reward": 415.09788667641095, "episode": 40.0, "batch_reward": 0.15677586144953967, "critic_loss": 0.25140637151151896, "actor_loss": -21.644168741226196, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.054235696792603, "step": 40000}
{"episode_reward": 415.01167404007623, "episode": 41.0, "batch_reward": 0.1638336231559515, "critic_loss": 0.28961014647781846, "actor_loss": -21.839883909225463, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.56052875518799, "step": 41000}
{"episode_reward": 488.16646653525555, "episode": 42.0, "batch_reward": 0.171472195237875, "critic_loss": 0.29631880031526087, "actor_loss": -22.5488545627594, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.07865309715271, "step": 42000}
{"episode_reward": 403.30779891651304, "episode": 43.0, "batch_reward": 0.17695942306518556, "critic_loss": 0.2949441588222981, "actor_loss": -22.96268000411987, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06508493423462, "step": 43000}
{"episode_reward": 467.71850617079184, "episode": 44.0, "batch_reward": 0.1844172061532736, "critic_loss": 0.33456896401941777, "actor_loss": -23.422269542694092, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.067557096481323, "step": 44000}
{"episode_reward": 498.839603052913, "episode": 45.0, "batch_reward": 0.19064821307361127, "critic_loss": 0.3091255436465144, "actor_loss": -23.435760925292968, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.08801293373108, "step": 45000}
{"episode_reward": 376.8363499734978, "episode": 46.0, "batch_reward": 0.1946876808255911, "critic_loss": 0.35663732182979585, "actor_loss": -23.771917469024658, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.061164379119873, "step": 46000}
{"episode_reward": 452.16530552861235, "episode": 47.0, "batch_reward": 0.20014969293773174, "critic_loss": 0.3627245010957122, "actor_loss": -24.73690263748169, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06427526473999, "step": 47000}
{"episode_reward": 457.91072474109427, "episode": 48.0, "batch_reward": 0.20509811814129353, "critic_loss": 0.3486336617022753, "actor_loss": -24.90505394744873, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.08445119857788, "step": 48000}
{"episode_reward": 443.8775207446471, "episode": 49.0, "batch_reward": 0.20969435307383538, "critic_loss": 0.34590529060363767, "actor_loss": -25.539400066375734, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.19587469100952, "step": 49000}
{"episode_reward": 440.8584250682519, "episode": 50.0, "batch_reward": 0.21569056916236878, "critic_loss": 0.374265554279089, "actor_loss": -25.908674503326417, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.32946801185608, "step": 50000}
{"episode_reward": 499.57232183985093, "episode": 51.0, "batch_reward": 0.21965203577280046, "critic_loss": 0.4321654729694128, "actor_loss": -26.372982803344726, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.50727701187134, "step": 51000}
{"episode_reward": 444.3473861249005, "episode": 52.0, "batch_reward": 0.2244182580858469, "critic_loss": 0.43124339421093466, "actor_loss": -26.66648139190674, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05107069015503, "step": 52000}
{"episode_reward": 303.63576643741766, "episode": 53.0, "batch_reward": 0.22641294822096825, "critic_loss": 0.4067185672521591, "actor_loss": -27.234376384735107, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.048210620880127, "step": 53000}
{"episode_reward": 497.7810071549666, "episode": 54.0, "batch_reward": 0.23273685504496097, "critic_loss": 0.4102437183111906, "actor_loss": -27.662487770080567, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.071136713027954, "step": 54000}
{"episode_reward": 499.2076638308818, "episode": 55.0, "batch_reward": 0.2364394801557064, "critic_loss": 0.40892341972887514, "actor_loss": -27.928475059509278, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.065441608428955, "step": 55000}
{"episode_reward": 522.8589081982464, "episode": 56.0, "batch_reward": 0.24097954595088958, "critic_loss": 0.3877256440222263, "actor_loss": -28.527458675384523, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05096197128296, "step": 56000}
{"episode_reward": 480.64132639636335, "episode": 57.0, "batch_reward": 0.24563297440111637, "critic_loss": 0.3868325998336077, "actor_loss": -28.78772534942627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.101580381393433, "step": 57000}
{"episode_reward": 472.49909520238793, "episode": 58.0, "batch_reward": 0.2497187788337469, "critic_loss": 0.35144577381014824, "actor_loss": -29.437577228546143, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.083268642425537, "step": 58000}
{"episode_reward": 470.27253798612014, "episode": 59.0, "batch_reward": 0.2541884317696094, "critic_loss": 0.3485358028262854, "actor_loss": -29.725221870422363, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.029155254364014, "step": 59000}
{"episode_reward": 507.70547893127, "episode": 60.0, "batch_reward": 0.25834733380377295, "critic_loss": 0.3436205082088709, "actor_loss": -29.82610721206665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06975293159485, "step": 60000}
{"episode_reward": 532.9884147399509, "episode": 61.0, "batch_reward": 0.26107194386422633, "critic_loss": 0.33457889331877233, "actor_loss": -30.265899688720705, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.59835171699524, "step": 61000}
{"episode_reward": 508.38466239953596, "episode": 62.0, "batch_reward": 0.26691266532242297, "critic_loss": 0.3436014071702957, "actor_loss": -30.40145804977417, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.11471176147461, "step": 62000}
{"episode_reward": 510.16857902942075, "episode": 63.0, "batch_reward": 0.2725334337800741, "critic_loss": 0.3309529582038522, "actor_loss": -31.127362007141112, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.114836931228638, "step": 63000}
{"episode_reward": 555.4967501326065, "episode": 64.0, "batch_reward": 0.2756661715656519, "critic_loss": 0.3286283292323351, "actor_loss": -31.825938755035402, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06488299369812, "step": 64000}
{"episode_reward": 523.3490388452651, "episode": 65.0, "batch_reward": 0.2800801144838333, "critic_loss": 0.35224241569638254, "actor_loss": -31.79980859375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.14839196205139, "step": 65000}
{"episode_reward": 568.3074497903718, "episode": 66.0, "batch_reward": 0.2843174397498369, "critic_loss": 0.32599730050563813, "actor_loss": -32.36807719039917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.143311500549316, "step": 66000}
{"episode_reward": 543.7431636151837, "episode": 67.0, "batch_reward": 0.28742493818700315, "critic_loss": 0.32164747853577136, "actor_loss": -32.606267276763916, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.110143423080444, "step": 67000}
{"episode_reward": 447.81346046354724, "episode": 68.0, "batch_reward": 0.2906531794220209, "critic_loss": 0.32887422235310076, "actor_loss": -33.371672576904295, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.1204252243042, "step": 68000}
{"episode_reward": 513.0737748600552, "episode": 69.0, "batch_reward": 0.2939712459743023, "critic_loss": 0.31915950305759905, "actor_loss": -33.15798342132568, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.140180349349976, "step": 69000}
{"episode_reward": 524.5619440543683, "episode": 70.0, "batch_reward": 0.29306947594881055, "critic_loss": 0.3286100980192423, "actor_loss": -33.07531092834473, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.101731061935425, "step": 70000}
{"episode_reward": 44.97582808267362, "episode": 71.0, "batch_reward": 0.29371221174299716, "critic_loss": 0.32446874848008156, "actor_loss": -33.04148483657837, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.58697319030762, "step": 71000}
{"episode_reward": 542.2791901832766, "episode": 72.0, "batch_reward": 0.2959975334405899, "critic_loss": 0.34908152823150157, "actor_loss": -33.45762748718262, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.055199146270752, "step": 72000}
{"episode_reward": 389.16416944006573, "episode": 73.0, "batch_reward": 0.2982802421450615, "critic_loss": 0.3748771512955427, "actor_loss": -33.835786743164064, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05958914756775, "step": 73000}
{"episode_reward": 513.8228720859347, "episode": 74.0, "batch_reward": 0.3005817319750786, "critic_loss": 0.35547757224738596, "actor_loss": -34.01308828353882, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.073549509048462, "step": 74000}
{"episode_reward": 555.8095982452372, "episode": 75.0, "batch_reward": 0.3046583675444126, "critic_loss": 0.3817541502118111, "actor_loss": -34.58549258422852, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.076125860214233, "step": 75000}
{"episode_reward": 514.3232111111914, "episode": 76.0, "batch_reward": 0.30724892440438273, "critic_loss": 0.3644105861485004, "actor_loss": -34.93125635147095, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.241312980651855, "step": 76000}
{"episode_reward": 546.8293536904627, "episode": 77.0, "batch_reward": 0.3099215219765902, "critic_loss": 0.4219433842152357, "actor_loss": -35.163069412231444, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.31306791305542, "step": 77000}
{"episode_reward": 284.9534250332298, "episode": 78.0, "batch_reward": 0.30969259767234325, "critic_loss": 0.4613751097470522, "actor_loss": -35.05186014938354, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.050410747528076, "step": 78000}
{"episode_reward": 528.8980658463817, "episode": 79.0, "batch_reward": 0.3121248367130756, "critic_loss": 0.45839055731892586, "actor_loss": -35.44228624725342, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.034261226654053, "step": 79000}
{"episode_reward": 383.324474230735, "episode": 80.0, "batch_reward": 0.3133807302415371, "critic_loss": 0.42194107146561144, "actor_loss": -35.81278145217895, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.040505170822144, "step": 80000}
{"episode_reward": 600.4643569885127, "episode": 81.0, "batch_reward": 0.3171873410642147, "critic_loss": 0.43252772696316244, "actor_loss": -36.31639199829102, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.572794675827026, "step": 81000}
{"episode_reward": 464.78893314622627, "episode": 82.0, "batch_reward": 0.317970779389143, "critic_loss": 0.4323516040593386, "actor_loss": -36.69574715423584, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02372097969055, "step": 82000}
{"episode_reward": 208.3099570830626, "episode": 83.0, "batch_reward": 0.3185308449566364, "critic_loss": 0.4065199213176966, "actor_loss": -36.20826630783081, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04459571838379, "step": 83000}
{"episode_reward": 534.5527196750835, "episode": 84.0, "batch_reward": 0.3190247665941715, "critic_loss": 0.3985993383973837, "actor_loss": -36.66628050231934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.087291955947876, "step": 84000}
{"episode_reward": 497.0358890955219, "episode": 85.0, "batch_reward": 0.3219629405885935, "critic_loss": 0.4205800990611315, "actor_loss": -36.8987331199646, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05703330039978, "step": 85000}
{"episode_reward": 559.0720497295806, "episode": 86.0, "batch_reward": 0.3245066321492195, "critic_loss": 0.4224010499417782, "actor_loss": -37.18127563095093, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.090862274169922, "step": 86000}
{"episode_reward": 550.1019046134522, "episode": 87.0, "batch_reward": 0.3264784370362759, "critic_loss": 0.40821890205144884, "actor_loss": -37.48687771987915, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.084517240524292, "step": 87000}
{"episode_reward": 489.07120948997454, "episode": 88.0, "batch_reward": 0.33017213600873946, "critic_loss": 0.44839974699914453, "actor_loss": -37.67066440963745, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.059504747390747, "step": 88000}
{"episode_reward": 600.6916479376216, "episode": 89.0, "batch_reward": 0.3328737302720547, "critic_loss": 0.4294626873880625, "actor_loss": -37.983313018798825, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.077898025512695, "step": 89000}
{"episode_reward": 580.906366844331, "episode": 90.0, "batch_reward": 0.3353334151208401, "critic_loss": 0.4805504799485207, "actor_loss": -38.23645150756836, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0737566947937, "step": 90000}
{"episode_reward": 547.7691300155308, "episode": 91.0, "batch_reward": 0.3376658929586411, "critic_loss": 0.4528636178672314, "actor_loss": -38.4185955619812, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.53446555137634, "step": 91000}
{"episode_reward": 566.3412097905862, "episode": 92.0, "batch_reward": 0.3393798600137234, "critic_loss": 0.42759181044995787, "actor_loss": -38.15719825744629, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.057796001434326, "step": 92000}
{"episode_reward": 573.9104663869479, "episode": 93.0, "batch_reward": 0.3433891436755657, "critic_loss": 0.4125095441639423, "actor_loss": -38.80236292266846, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.03056836128235, "step": 93000}
{"episode_reward": 578.8046290371584, "episode": 94.0, "batch_reward": 0.3458896704018116, "critic_loss": 0.41140324507653714, "actor_loss": -38.80530869293213, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05135726928711, "step": 94000}
{"episode_reward": 568.8373856004407, "episode": 95.0, "batch_reward": 0.344757559210062, "critic_loss": 0.43295948520302774, "actor_loss": -39.21225700378418, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.060344219207764, "step": 95000}
{"episode_reward": 160.97262852794017, "episode": 96.0, "batch_reward": 0.34562664991617204, "critic_loss": 0.41343114668130876, "actor_loss": -38.8624008102417, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.08628535270691, "step": 96000}
{"episode_reward": 492.12034386144427, "episode": 97.0, "batch_reward": 0.3468597458899021, "critic_loss": 0.424699006319046, "actor_loss": -39.23061880493164, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.062204122543335, "step": 97000}
{"episode_reward": 524.4506447220818, "episode": 98.0, "batch_reward": 0.35017614844441414, "critic_loss": 0.45902316381037234, "actor_loss": -39.66660813903808, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.043524265289307, "step": 98000}
{"episode_reward": 567.812615375938, "episode": 99.0, "batch_reward": 0.3500734425187111, "critic_loss": 0.41910294848680496, "actor_loss": -39.44414075469971, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04658341407776, "step": 99000}
{"episode_reward": 596.2536232367628, "episode": 100.0, "batch_reward": 0.3542925390601158, "critic_loss": 0.4273631014078855, "actor_loss": -39.757776321411136, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.074399709701538, "step": 100000}
{"episode_reward": 576.1410666464121, "episode": 101.0, "batch_reward": 0.3562046482861042, "critic_loss": 0.43907606169581415, "actor_loss": -40.01661896514893, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.53157353401184, "step": 101000}
{"episode_reward": 538.0513992477548, "episode": 102.0, "batch_reward": 0.35832540822029113, "critic_loss": 0.43189387556910513, "actor_loss": -40.20589331054688, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.053399324417114, "step": 102000}
{"episode_reward": 489.96891764048286, "episode": 103.0, "batch_reward": 0.35918393382430075, "critic_loss": 0.4161328388005495, "actor_loss": -40.214098457336426, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.064026355743408, "step": 103000}
{"episode_reward": 593.1814524525096, "episode": 104.0, "batch_reward": 0.36231288400292394, "critic_loss": 0.4669184961616993, "actor_loss": -40.568173950195316, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.073340892791748, "step": 104000}
{"episode_reward": 394.3721085824651, "episode": 105.0, "batch_reward": 0.3592603885531426, "critic_loss": 0.4472825786173344, "actor_loss": -40.173289764404295, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.063469409942627, "step": 105000}
{"episode_reward": 65.99580539098834, "episode": 106.0, "batch_reward": 0.3594511698186398, "critic_loss": 0.46215376041829587, "actor_loss": -40.17343830871582, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05427885055542, "step": 106000}
{"episode_reward": 541.973019521078, "episode": 107.0, "batch_reward": 0.3595244317948818, "critic_loss": 0.505915653526783, "actor_loss": -40.38360387420654, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.094057321548462, "step": 107000}
{"episode_reward": 559.4004931793881, "episode": 108.0, "batch_reward": 0.36214444825053216, "critic_loss": 0.4497686424702406, "actor_loss": -40.411219871521, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.07200002670288, "step": 108000}
{"episode_reward": 589.670674621535, "episode": 109.0, "batch_reward": 0.36478433960676193, "critic_loss": 0.41772275710105894, "actor_loss": -40.9144736404419, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.043368339538574, "step": 109000}
{"episode_reward": 576.0290399793291, "episode": 110.0, "batch_reward": 0.3649681922495365, "critic_loss": 0.4592723604440689, "actor_loss": -40.789804641723634, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.029075145721436, "step": 110000}
{"episode_reward": 279.13135487425956, "episode": 111.0, "batch_reward": 0.36581961810588837, "critic_loss": 0.4526510657966137, "actor_loss": -40.5953299407959, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.54531240463257, "step": 111000}
{"episode_reward": 558.4069351864681, "episode": 112.0, "batch_reward": 0.3668253858089447, "critic_loss": 0.47088498903810977, "actor_loss": -40.73152718353271, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.069934844970703, "step": 112000}
{"episode_reward": 586.9379499171966, "episode": 113.0, "batch_reward": 0.3708197914659977, "critic_loss": 0.43964975482225416, "actor_loss": -40.88478967285156, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.131986618041992, "step": 113000}
{"episode_reward": 603.7488143797308, "episode": 114.0, "batch_reward": 0.37043480587005617, "critic_loss": 0.43881765511631965, "actor_loss": -41.26822585296631, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.065303087234497, "step": 114000}
{"episode_reward": 383.8065624847666, "episode": 115.0, "batch_reward": 0.37202414593100547, "critic_loss": 0.47588395841419695, "actor_loss": -41.48942658233643, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.091766834259033, "step": 115000}
{"episode_reward": 541.0702431263101, "episode": 116.0, "batch_reward": 0.37257942709326747, "critic_loss": 0.4723036126792431, "actor_loss": -41.35935599517822, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.120316743850708, "step": 116000}
{"episode_reward": 565.6961888342199, "episode": 117.0, "batch_reward": 0.375246806114912, "critic_loss": 0.5080969699472189, "actor_loss": -41.54586377716065, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.106304168701172, "step": 117000}
{"episode_reward": 560.5957020914641, "episode": 118.0, "batch_reward": 0.376529132604599, "critic_loss": 0.5137608035802841, "actor_loss": -41.53679588317871, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.117198705673218, "step": 118000}
{"episode_reward": 540.4467552422751, "episode": 119.0, "batch_reward": 0.3758586681783199, "critic_loss": 0.5328211099356412, "actor_loss": -41.411970344543455, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.116472244262695, "step": 119000}
{"episode_reward": 171.5777180664991, "episode": 120.0, "batch_reward": 0.37534931749105455, "critic_loss": 0.49998367463052273, "actor_loss": -41.636467292785646, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.084802627563477, "step": 120000}
{"episode_reward": 547.4541913319911, "episode": 121.0, "batch_reward": 0.3783025375902653, "critic_loss": 0.5090549229681491, "actor_loss": -41.78797265625, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.84539604187012, "step": 121000}
{"episode_reward": 563.9678127076396, "episode": 122.0, "batch_reward": 0.381106438100338, "critic_loss": 0.4503406248688698, "actor_loss": -42.179047477722165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.121097564697266, "step": 122000}
{"episode_reward": 587.6351610888083, "episode": 123.0, "batch_reward": 0.38068588921427726, "critic_loss": 0.4677197532206774, "actor_loss": -42.32643893432617, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.10011124610901, "step": 123000}
{"episode_reward": 573.6727189957453, "episode": 124.0, "batch_reward": 0.3816845098733902, "critic_loss": 0.5170812894850969, "actor_loss": -42.20393357849121, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.112661361694336, "step": 124000}
{"episode_reward": 608.5914686373734, "episode": 125.0, "batch_reward": 0.38415824139118193, "critic_loss": 0.49571597364544867, "actor_loss": -42.24148554992676, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.126850366592407, "step": 125000}
{"episode_reward": 561.6143433385363, "episode": 126.0, "batch_reward": 0.38454114997386935, "critic_loss": 0.45205011902749537, "actor_loss": -42.30582013702393, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.111259698867798, "step": 126000}
{"episode_reward": 603.5125745897883, "episode": 127.0, "batch_reward": 0.38652643430233, "critic_loss": 0.46074940633773803, "actor_loss": -42.48825830841064, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06197190284729, "step": 127000}
{"episode_reward": 567.0434975892599, "episode": 128.0, "batch_reward": 0.38808433669805525, "critic_loss": 0.45379395803809164, "actor_loss": -42.47878276062012, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.114825010299683, "step": 128000}
{"episode_reward": 585.8420582598155, "episode": 129.0, "batch_reward": 0.39007703801989557, "critic_loss": 0.4777080600857735, "actor_loss": -42.64402169036865, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.1045823097229, "step": 129000}
{"episode_reward": 582.7089020409987, "episode": 130.0, "batch_reward": 0.39120523887872694, "critic_loss": 0.4428099667429924, "actor_loss": -43.029689781188964, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.07837224006653, "step": 130000}
{"episode_reward": 391.2009366688358, "episode": 131.0, "batch_reward": 0.3912475073635578, "critic_loss": 0.4854610719829798, "actor_loss": -42.61091844177246, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.926902294158936, "step": 131000}
{"episode_reward": 573.9465478614362, "episode": 132.0, "batch_reward": 0.39129468938708306, "critic_loss": 0.5078985383808613, "actor_loss": -42.761823669433596, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.103873014450073, "step": 132000}
{"episode_reward": 587.7675814403783, "episode": 133.0, "batch_reward": 0.39317128393054007, "critic_loss": 0.47563059739768504, "actor_loss": -43.15545660400391, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.119206190109253, "step": 133000}
{"episode_reward": 549.5203087921273, "episode": 134.0, "batch_reward": 0.3952275228202343, "critic_loss": 0.43558608096838, "actor_loss": -43.27792799377441, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.081079721450806, "step": 134000}
{"episode_reward": 590.6174105078339, "episode": 135.0, "batch_reward": 0.3958044002056122, "critic_loss": 0.42551654337346556, "actor_loss": -43.321749771118164, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0361270904541, "step": 135000}
{"episode_reward": 565.6050148468004, "episode": 136.0, "batch_reward": 0.39829537430405615, "critic_loss": 0.4657511757463217, "actor_loss": -43.43992552185058, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.051544904708862, "step": 136000}
{"episode_reward": 576.5002558379016, "episode": 137.0, "batch_reward": 0.400178618222475, "critic_loss": 0.43339449863135815, "actor_loss": -43.73198720550537, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.096714973449707, "step": 137000}
{"episode_reward": 562.3601072869453, "episode": 138.0, "batch_reward": 0.4012247525453568, "critic_loss": 0.4772866054773331, "actor_loss": -43.53892333221435, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.045659065246582, "step": 138000}
{"episode_reward": 617.3678189231524, "episode": 139.0, "batch_reward": 0.4025470285117626, "critic_loss": 0.47938546365499496, "actor_loss": -43.6237453918457, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.028493881225586, "step": 139000}
{"episode_reward": 552.9093462699233, "episode": 140.0, "batch_reward": 0.4022356626689434, "critic_loss": 0.440887444883585, "actor_loss": -43.54618569183349, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04671859741211, "step": 140000}
{"episode_reward": 597.4426022113028, "episode": 141.0, "batch_reward": 0.40442444205284117, "critic_loss": 0.4628004714101553, "actor_loss": -43.99535710144043, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.49377751350403, "step": 141000}
{"episode_reward": 582.299131814539, "episode": 142.0, "batch_reward": 0.4056115479171276, "critic_loss": 0.5014844496846199, "actor_loss": -44.12448532104492, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.080111742019653, "step": 142000}
{"episode_reward": 581.817213149427, "episode": 143.0, "batch_reward": 0.4078376184999943, "critic_loss": 0.4491846548169851, "actor_loss": -44.43088304901123, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.056509256362915, "step": 143000}
{"episode_reward": 554.0296753878752, "episode": 144.0, "batch_reward": 0.40884877553582194, "critic_loss": 0.49891602230072024, "actor_loss": -44.2974541015625, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.034431219100952, "step": 144000}
{"episode_reward": 599.1824206888436, "episode": 145.0, "batch_reward": 0.41014410454034805, "critic_loss": 0.5239542971551419, "actor_loss": -44.573094146728515, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.008981227874756, "step": 145000}
{"episode_reward": 556.3969277913692, "episode": 146.0, "batch_reward": 0.4101187071800232, "critic_loss": 0.42092620155215266, "actor_loss": -44.30207545471191, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.08358907699585, "step": 146000}
{"episode_reward": 578.2310484628666, "episode": 147.0, "batch_reward": 0.41203225222229956, "critic_loss": 0.4443851011544466, "actor_loss": -44.5284377746582, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.075324296951294, "step": 147000}
{"episode_reward": 593.6028523186695, "episode": 148.0, "batch_reward": 0.4130434509217739, "critic_loss": 0.44222336733341217, "actor_loss": -44.58726779174805, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.072317361831665, "step": 148000}
{"episode_reward": 603.2521289637268, "episode": 149.0, "batch_reward": 0.4139120972454548, "critic_loss": 0.47780300100147727, "actor_loss": -44.63807440185547, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.099780797958374, "step": 149000}
{"episode_reward": 582.2648078522307, "episode": 150.0, "batch_reward": 0.41531928196549417, "critic_loss": 0.44344645689427853, "actor_loss": -44.731227142333985, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
