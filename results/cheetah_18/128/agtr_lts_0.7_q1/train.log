{"episode_reward": 0.0, "episode": 1.0, "duration": 19.058825492858887, "step": 1000}
{"episode_reward": 4.20996189079657, "episode": 2.0, "duration": 1.6676719188690186, "step": 2000}
{"episode_reward": 252.2457487418515, "episode": 3.0, "batch_reward": 0.1383740548597212, "critic_loss": 0.41098593240998194, "actor_loss": -36.64653589096771, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 67.66651940345764, "step": 3000}
{"episode_reward": 324.14542121523766, "episode": 4.0, "batch_reward": 0.18155635879188775, "critic_loss": 0.6052117198109627, "actor_loss": -36.67455672836304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.16149115562439, "step": 4000}
{"episode_reward": 61.40731464421513, "episode": 5.0, "batch_reward": 0.1558634824231267, "critic_loss": 0.6762719626426696, "actor_loss": -31.4863278465271, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.75192379951477, "step": 5000}
{"episode_reward": 70.9563551753054, "episode": 6.0, "batch_reward": 0.1389650834798813, "critic_loss": 0.8468579785823822, "actor_loss": -28.555555488586425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.608144760131836, "step": 6000}
{"episode_reward": 58.840932579174165, "episode": 7.0, "batch_reward": 0.12876474662125112, "critic_loss": 0.9014345962405205, "actor_loss": -26.69570763015747, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.52143144607544, "step": 7000}
{"episode_reward": 67.24278416039958, "episode": 8.0, "batch_reward": 0.1287479250356555, "critic_loss": 1.2148992616832257, "actor_loss": -26.43098942565918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.929975509643555, "step": 8000}
{"episode_reward": 262.37294512575716, "episode": 9.0, "batch_reward": 0.14923304232209922, "critic_loss": 1.4344242334961892, "actor_loss": -28.276848609924315, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.641809463500977, "step": 9000}
{"episode_reward": 242.56974368694654, "episode": 10.0, "batch_reward": 0.15047850024700166, "critic_loss": 1.823975202858448, "actor_loss": -28.404460361480712, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.648199558258057, "step": 10000}
{"episode_reward": 161.63425662507376, "episode": 11.0, "batch_reward": 0.15975930973142385, "critic_loss": 2.057285274982452, "actor_loss": -30.54878126144409, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.57234263420105, "step": 11000}
{"episode_reward": 344.8822118486027, "episode": 12.0, "batch_reward": 0.17490666139125824, "critic_loss": 2.0085728430747984, "actor_loss": -33.785717071533206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.351781845092773, "step": 12000}
{"episode_reward": 320.3945746957657, "episode": 13.0, "batch_reward": 0.1911653928309679, "critic_loss": 2.1747625895738603, "actor_loss": -35.843835418701175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.70600390434265, "step": 13000}
{"episode_reward": 373.4914687848836, "episode": 14.0, "batch_reward": 0.20476983511447908, "critic_loss": 1.981466884791851, "actor_loss": -36.465564826965334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.14727783203125, "step": 14000}
{"episode_reward": 468.2484955021835, "episode": 15.0, "batch_reward": 0.21562227222323418, "critic_loss": 1.8783764083385468, "actor_loss": -36.75066114044189, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.161396741867065, "step": 15000}
{"episode_reward": 142.43660152656184, "episode": 16.0, "batch_reward": 0.217517112955451, "critic_loss": 1.6746603432893754, "actor_loss": -37.26131301498413, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.68087100982666, "step": 16000}
{"episode_reward": 504.00939711003906, "episode": 17.0, "batch_reward": 0.23693137633800507, "critic_loss": 1.1951534516215325, "actor_loss": -38.10902586364746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.985949993133545, "step": 17000}
{"episode_reward": 496.5942387598646, "episode": 18.0, "batch_reward": 0.2516161290258169, "critic_loss": 0.9897880410850048, "actor_loss": -38.93870961380005, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.938647270202637, "step": 18000}
{"episode_reward": 520.8899680257798, "episode": 19.0, "batch_reward": 0.26566017550230026, "critic_loss": 0.8816228983402252, "actor_loss": -39.44641552734375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.113955974578857, "step": 19000}
{"episode_reward": 507.2539761785015, "episode": 20.0, "batch_reward": 0.2749458779245615, "critic_loss": 0.9353727533519268, "actor_loss": -39.87372415161133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.770929098129272, "step": 20000}
{"episode_reward": 437.09851763768194, "episode": 21.0, "batch_reward": 0.28616121111810205, "critic_loss": 0.8914131664335728, "actor_loss": -40.60784474182129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.532620906829834, "step": 21000}
{"episode_reward": 438.73131234908885, "episode": 22.0, "batch_reward": 0.29372597536444667, "critic_loss": 0.858509890884161, "actor_loss": -40.54026103210449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.172942638397217, "step": 22000}
{"episode_reward": 526.5728339846405, "episode": 23.0, "batch_reward": 0.3030788545459509, "critic_loss": 0.8018694307804107, "actor_loss": -41.02193630218506, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.932616233825684, "step": 23000}
{"episode_reward": 495.36032603553514, "episode": 24.0, "batch_reward": 0.3116376024782658, "critic_loss": 0.7939303861558438, "actor_loss": -41.34592440795898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.01926279067993, "step": 24000}
{"episode_reward": 523.7619201050356, "episode": 25.0, "batch_reward": 0.3202059383392334, "critic_loss": 0.7592523899674416, "actor_loss": -41.78719955444336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.168367862701416, "step": 25000}
{"episode_reward": 540.9797525849701, "episode": 26.0, "batch_reward": 0.3289367735683918, "critic_loss": 0.7422334682047367, "actor_loss": -42.253338653564455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.172791957855225, "step": 26000}
{"episode_reward": 524.9655914761614, "episode": 27.0, "batch_reward": 0.3365132286250591, "critic_loss": 0.7288251452744007, "actor_loss": -42.56919634246826, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.906865119934082, "step": 27000}
{"episode_reward": 517.5712697789753, "episode": 28.0, "batch_reward": 0.3370520806014538, "critic_loss": 0.7754665566384792, "actor_loss": -42.47169610595703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.279128313064575, "step": 28000}
{"episode_reward": 93.92409068948514, "episode": 29.0, "batch_reward": 0.32899326261878015, "critic_loss": 0.7646517543792725, "actor_loss": -41.94696726989746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.791404247283936, "step": 29000}
{"episode_reward": 151.9722626481852, "episode": 30.0, "batch_reward": 0.3274442617893219, "critic_loss": 0.7248892775177955, "actor_loss": -41.6256506729126, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.10780167579651, "step": 30000}
{"episode_reward": 495.1285645224626, "episode": 31.0, "batch_reward": 0.33408842262625693, "critic_loss": 0.6876162815988064, "actor_loss": -42.06536766815186, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.41908288002014, "step": 31000}
{"episode_reward": 508.57894750946406, "episode": 32.0, "batch_reward": 0.3387710268497467, "critic_loss": 0.6900192814767361, "actor_loss": -42.21360099792481, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.376511573791504, "step": 32000}
{"episode_reward": 368.7391635063971, "episode": 33.0, "batch_reward": 0.33783445662260053, "critic_loss": 0.7008153658211231, "actor_loss": -42.14235418701172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.62887740135193, "step": 33000}
{"episode_reward": 229.4364685757813, "episode": 34.0, "batch_reward": 0.33477671030163764, "critic_loss": 0.7182765557467937, "actor_loss": -41.76168993377686, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.823906898498535, "step": 34000}
{"episode_reward": 269.82514817780327, "episode": 35.0, "batch_reward": 0.33013829931616784, "critic_loss": 0.7038584744930267, "actor_loss": -41.1530676574707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.36174488067627, "step": 35000}
{"episode_reward": 108.24715395537758, "episode": 36.0, "batch_reward": 0.32935778418183326, "critic_loss": 0.6967583298981189, "actor_loss": -40.8950475692749, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.128965854644775, "step": 36000}
{"episode_reward": 526.936067228553, "episode": 37.0, "batch_reward": 0.3347541220188141, "critic_loss": 0.7050037672519683, "actor_loss": -41.184776138305665, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.025511503219604, "step": 37000}
{"episode_reward": 542.6873012550061, "episode": 38.0, "batch_reward": 0.33495622664690017, "critic_loss": 0.7002957921028137, "actor_loss": -41.0833226852417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.232935190200806, "step": 38000}
{"episode_reward": 98.56206170993595, "episode": 39.0, "batch_reward": 0.3308020403087139, "critic_loss": 0.6834410983026028, "actor_loss": -40.694503852844235, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.74574613571167, "step": 39000}
{"episode_reward": 267.083472277649, "episode": 40.0, "batch_reward": 0.32875765094161036, "critic_loss": 0.7118078130185604, "actor_loss": -40.569875701904294, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.250554084777832, "step": 40000}
{"episode_reward": 217.71221576282556, "episode": 41.0, "batch_reward": 0.3294695855081081, "critic_loss": 0.6832011654675006, "actor_loss": -40.392121002197264, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.121598958969116, "step": 41000}
{"episode_reward": 545.0122649579747, "episode": 42.0, "batch_reward": 0.33058985316753386, "critic_loss": 0.6908937879800796, "actor_loss": -40.36094932556152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.425840139389038, "step": 42000}
{"episode_reward": 106.02344870405469, "episode": 43.0, "batch_reward": 0.32657832077145577, "critic_loss": 0.7044274384379386, "actor_loss": -39.84932554626465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.14866614341736, "step": 43000}
{"episode_reward": 190.32517120690184, "episode": 44.0, "batch_reward": 0.3262960107028484, "critic_loss": 0.7197580616474152, "actor_loss": -39.61451287841797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.79000425338745, "step": 44000}
{"episode_reward": 546.0028133886657, "episode": 45.0, "batch_reward": 0.33033068710565566, "critic_loss": 0.7592540802061558, "actor_loss": -39.600552993774414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.638786792755127, "step": 45000}
{"episode_reward": 525.3044807943085, "episode": 46.0, "batch_reward": 0.3353268938660622, "critic_loss": 0.7124898699223995, "actor_loss": -39.868617156982424, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.402606964111328, "step": 46000}
{"episode_reward": 536.0251659827007, "episode": 47.0, "batch_reward": 0.33836049363017084, "critic_loss": 0.7205290509462356, "actor_loss": -40.0702289428711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.01279616355896, "step": 47000}
{"episode_reward": 515.9709963420632, "episode": 48.0, "batch_reward": 0.34246236163377763, "critic_loss": 0.7304067363739014, "actor_loss": -40.19571438598633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.550882816314697, "step": 48000}
{"episode_reward": 570.6013411293691, "episode": 49.0, "batch_reward": 0.34835635212063787, "critic_loss": 0.711216539978981, "actor_loss": -40.75870143127442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.009352445602417, "step": 49000}
{"episode_reward": 560.3766564965741, "episode": 50.0, "batch_reward": 0.35244679844379423, "critic_loss": 0.7387324411571026, "actor_loss": -40.825934059143066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.668007135391235, "step": 50000}
{"episode_reward": 545.502993986125, "episode": 51.0, "batch_reward": 0.3549329848587513, "critic_loss": 0.7748830314576626, "actor_loss": -41.30367487335205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.90130543708801, "step": 51000}
{"episode_reward": 567.2321211784869, "episode": 52.0, "batch_reward": 0.36036396208405497, "critic_loss": 0.7775735319256782, "actor_loss": -41.24869305419922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.457184076309204, "step": 52000}
{"episode_reward": 581.6939217271723, "episode": 53.0, "batch_reward": 0.3597323195040226, "critic_loss": 0.8094226075708866, "actor_loss": -41.185276641845704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.314531326293945, "step": 53000}
{"episode_reward": 74.36661282701574, "episode": 54.0, "batch_reward": 0.35956552809476855, "critic_loss": 0.7831973055005074, "actor_loss": -41.29535025787354, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.099318265914917, "step": 54000}
{"episode_reward": 507.69579849707503, "episode": 55.0, "batch_reward": 0.36181059896945955, "critic_loss": 0.8132280824780465, "actor_loss": -41.10290617370605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.41517162322998, "step": 55000}
{"episode_reward": 564.7997900838888, "episode": 56.0, "batch_reward": 0.365347374856472, "critic_loss": 0.7948381795883178, "actor_loss": -41.54126240539551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.777459859848022, "step": 56000}
{"episode_reward": 556.6466058031227, "episode": 57.0, "batch_reward": 0.3680936845541, "critic_loss": 0.8371564636230469, "actor_loss": -41.62393813323975, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88924217224121, "step": 57000}
{"episode_reward": 556.9221931941563, "episode": 58.0, "batch_reward": 0.37191629177331925, "critic_loss": 0.8544742313623428, "actor_loss": -41.93757243347168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.997690439224243, "step": 58000}
{"episode_reward": 556.8048396549199, "episode": 59.0, "batch_reward": 0.3750287902653217, "critic_loss": 0.8998510808944702, "actor_loss": -42.49733307647705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.15946936607361, "step": 59000}
{"episode_reward": 500.3473829437436, "episode": 60.0, "batch_reward": 0.37684810400009155, "critic_loss": 0.8725954258739949, "actor_loss": -42.32653285980225, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35682201385498, "step": 60000}
{"episode_reward": 510.3878194297005, "episode": 61.0, "batch_reward": 0.3796029650270939, "critic_loss": 0.8000930343866348, "actor_loss": -42.32007064056396, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.75011324882507, "step": 61000}
{"episode_reward": 571.0676678385828, "episode": 62.0, "batch_reward": 0.38182680794596674, "critic_loss": 0.7696799780428409, "actor_loss": -42.61517897796631, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.75538468360901, "step": 62000}
{"episode_reward": 559.0930685259741, "episode": 63.0, "batch_reward": 0.38548807001113894, "critic_loss": 0.7943978251814843, "actor_loss": -42.89081583404541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.805795192718506, "step": 63000}
{"episode_reward": 550.37119646893, "episode": 64.0, "batch_reward": 0.3881308705210686, "critic_loss": 0.8198880012333393, "actor_loss": -43.4071838760376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.88543939590454, "step": 64000}
{"episode_reward": 565.7851953997076, "episode": 65.0, "batch_reward": 0.39005282989144324, "critic_loss": 0.7754968015253544, "actor_loss": -43.41213675689697, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.899883270263672, "step": 65000}
{"episode_reward": 556.6667166262577, "episode": 66.0, "batch_reward": 0.3933831248581409, "critic_loss": 0.8149301050007344, "actor_loss": -43.71632285308838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.73754644393921, "step": 66000}
{"episode_reward": 570.1830771082637, "episode": 67.0, "batch_reward": 0.39776985824108124, "critic_loss": 0.7636177091002464, "actor_loss": -44.0280513381958, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.60436177253723, "step": 67000}
{"episode_reward": 526.0309692967023, "episode": 68.0, "batch_reward": 0.39813563776016236, "critic_loss": 0.7741718240976334, "actor_loss": -44.25915776824951, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.130687475204468, "step": 68000}
{"episode_reward": 555.363438112853, "episode": 69.0, "batch_reward": 0.4002517278790474, "critic_loss": 0.7060968549251556, "actor_loss": -44.178814651489255, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.54825758934021, "step": 69000}
{"episode_reward": 562.1986293288293, "episode": 70.0, "batch_reward": 0.4026176948547363, "critic_loss": 0.698842583835125, "actor_loss": -44.799310760498045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.535016298294067, "step": 70000}
{"episode_reward": 557.6451296809189, "episode": 71.0, "batch_reward": 0.40463133904337883, "critic_loss": 0.6648601588159799, "actor_loss": -44.74404621887207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.58787679672241, "step": 71000}
{"episode_reward": 566.0098662143431, "episode": 72.0, "batch_reward": 0.407059571146965, "critic_loss": 0.7250094181597233, "actor_loss": -44.8493574142456, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.890538930892944, "step": 72000}
{"episode_reward": 559.4624762189209, "episode": 73.0, "batch_reward": 0.409173044025898, "critic_loss": 0.7027003392428159, "actor_loss": -45.2168939666748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.03058648109436, "step": 73000}
{"episode_reward": 555.9386091474121, "episode": 74.0, "batch_reward": 0.410329150557518, "critic_loss": 0.6723224361240864, "actor_loss": -44.99581749725342, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.95225477218628, "step": 74000}
{"episode_reward": 540.0795294353157, "episode": 75.0, "batch_reward": 0.41181091395020486, "critic_loss": 0.7290676273554564, "actor_loss": -45.841143020629886, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.514103889465332, "step": 75000}
{"episode_reward": 432.817344783309, "episode": 76.0, "batch_reward": 0.4125262233018875, "critic_loss": 0.7381049610674382, "actor_loss": -45.69862746429443, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.815430641174316, "step": 76000}
{"episode_reward": 535.0704940578806, "episode": 77.0, "batch_reward": 0.4146551236510277, "critic_loss": 0.7177243132293224, "actor_loss": -45.75676106262207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.748347520828247, "step": 77000}
{"episode_reward": 581.5722733144602, "episode": 78.0, "batch_reward": 0.41743310004472733, "critic_loss": 0.7078582108616829, "actor_loss": -45.942898239135744, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9143488407135, "step": 78000}
{"episode_reward": 554.6230324741405, "episode": 79.0, "batch_reward": 0.4198381399810314, "critic_loss": 0.779463737398386, "actor_loss": -46.362344833374024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.750135898590088, "step": 79000}
{"episode_reward": 542.7544130083442, "episode": 80.0, "batch_reward": 0.42052001813054085, "critic_loss": 0.7952600699365139, "actor_loss": -46.48896092224121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.885706901550293, "step": 80000}
{"episode_reward": 563.5935296549587, "episode": 81.0, "batch_reward": 0.42125332161784174, "critic_loss": 0.8232034019827843, "actor_loss": -46.31587203216553, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.21229434013367, "step": 81000}
{"episode_reward": 564.4809881628258, "episode": 82.0, "batch_reward": 0.42325802248716354, "critic_loss": 0.7813261303901672, "actor_loss": -46.53405626678467, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.70102858543396, "step": 82000}
{"episode_reward": 593.6959940386021, "episode": 83.0, "batch_reward": 0.42532207688689233, "critic_loss": 0.7877229040563106, "actor_loss": -46.81990648651123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.238430738449097, "step": 83000}
{"episode_reward": 522.7420844821936, "episode": 84.0, "batch_reward": 0.4260085286796093, "critic_loss": 0.7127038023471832, "actor_loss": -46.865098777770996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.88245439529419, "step": 84000}
{"episode_reward": 550.1701311802739, "episode": 85.0, "batch_reward": 0.42847349375486377, "critic_loss": 0.7444211673140526, "actor_loss": -47.22932006835938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.92439579963684, "step": 85000}
{"episode_reward": 528.1098219614676, "episode": 86.0, "batch_reward": 0.4287002314031124, "critic_loss": 0.8486309566497803, "actor_loss": -47.09684479522705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.719109535217285, "step": 86000}
{"episode_reward": 548.9495011559702, "episode": 87.0, "batch_reward": 0.4301873455643654, "critic_loss": 0.8051648114621639, "actor_loss": -47.03174103546142, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.828160524368286, "step": 87000}
{"episode_reward": 584.9678582005614, "episode": 88.0, "batch_reward": 0.4328675118684769, "critic_loss": 0.7985196764171123, "actor_loss": -47.262466567993165, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.371192455291748, "step": 88000}
{"episode_reward": 597.5342131076048, "episode": 89.0, "batch_reward": 0.4350334924161434, "critic_loss": 0.7791155008375644, "actor_loss": -47.65331942749023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.224706172943115, "step": 89000}
{"episode_reward": 567.9142359273337, "episode": 90.0, "batch_reward": 0.43597623723745343, "critic_loss": 0.8006069055795669, "actor_loss": -47.569794586181644, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.66243886947632, "step": 90000}
{"episode_reward": 601.9194388224714, "episode": 91.0, "batch_reward": 0.4376405513882637, "critic_loss": 0.8111024073958397, "actor_loss": -48.165013153076174, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.390100717544556, "step": 91000}
{"episode_reward": 590.8645746641572, "episode": 92.0, "batch_reward": 0.4396295645236969, "critic_loss": 0.772889483332634, "actor_loss": -47.938477973937985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.536033868789673, "step": 92000}
{"episode_reward": 597.8695084042798, "episode": 93.0, "batch_reward": 0.44064880910515786, "critic_loss": 0.7776899074912071, "actor_loss": -48.14455227661133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.08877968788147, "step": 93000}
{"episode_reward": 530.920001359668, "episode": 94.0, "batch_reward": 0.44263620758056643, "critic_loss": 0.7600987354815006, "actor_loss": -48.21976325988769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.877678871154785, "step": 94000}
{"episode_reward": 576.2478164526822, "episode": 95.0, "batch_reward": 0.44313203620910646, "critic_loss": 0.794672080129385, "actor_loss": -48.62605998229981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.418067693710327, "step": 95000}
{"episode_reward": 562.8191243380668, "episode": 96.0, "batch_reward": 0.44584095698595044, "critic_loss": 0.7902852366119624, "actor_loss": -48.77269863891602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.630781650543213, "step": 96000}
{"episode_reward": 583.6322280542861, "episode": 97.0, "batch_reward": 0.44668515449762347, "critic_loss": 0.7690089033544063, "actor_loss": -48.86159265136719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.32857370376587, "step": 97000}
{"episode_reward": 596.7441573884364, "episode": 98.0, "batch_reward": 0.4484131927490234, "critic_loss": 0.7931627600193024, "actor_loss": -49.04856851959229, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20435857772827, "step": 98000}
{"episode_reward": 588.953292373186, "episode": 99.0, "batch_reward": 0.44929055124521255, "critic_loss": 0.776334293961525, "actor_loss": -49.127682884216306, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.982341527938843, "step": 99000}
{"episode_reward": 590.1768205462466, "episode": 100.0, "batch_reward": 0.4504828858077526, "critic_loss": 0.7292109386920929, "actor_loss": -49.35426993560791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.13598608970642, "step": 100000}
{"episode_reward": 584.4944643247695, "episode": 101.0, "batch_reward": 0.4528358123898506, "critic_loss": 0.7638229453861713, "actor_loss": -49.377906326293946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.65951895713806, "step": 101000}
{"episode_reward": 569.0498816974982, "episode": 102.0, "batch_reward": 0.4528488138318062, "critic_loss": 0.764323148816824, "actor_loss": -49.67942603302002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.158851623535156, "step": 102000}
{"episode_reward": 549.9940476987838, "episode": 103.0, "batch_reward": 0.4540806553661823, "critic_loss": 0.7504179666638374, "actor_loss": -49.5908422164917, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.864859580993652, "step": 103000}
{"episode_reward": 554.1355462103012, "episode": 104.0, "batch_reward": 0.4556052549779415, "critic_loss": 0.7549461360275745, "actor_loss": -49.89359568786621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.842104196548462, "step": 104000}
{"episode_reward": 570.1223474915994, "episode": 105.0, "batch_reward": 0.45598030522465705, "critic_loss": 0.7928191075623036, "actor_loss": -49.618738632202145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.14423656463623, "step": 105000}
{"episode_reward": 568.7729469906286, "episode": 106.0, "batch_reward": 0.45682853227853776, "critic_loss": 0.7983645624220371, "actor_loss": -50.04720188140869, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.015809059143066, "step": 106000}
{"episode_reward": 550.3955711784162, "episode": 107.0, "batch_reward": 0.4561994468271732, "critic_loss": 0.8085376113355159, "actor_loss": -49.933935325622556, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.346319675445557, "step": 107000}
{"episode_reward": 224.73884394737672, "episode": 108.0, "batch_reward": 0.4555467779636383, "critic_loss": 0.8441097078025341, "actor_loss": -49.85322523498535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.683069705963135, "step": 108000}
{"episode_reward": 505.10856927845987, "episode": 109.0, "batch_reward": 0.4565256062746048, "critic_loss": 0.900565544784069, "actor_loss": -49.816848602294925, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.81865382194519, "step": 109000}
{"episode_reward": 526.9308738251805, "episode": 110.0, "batch_reward": 0.45803671357035636, "critic_loss": 0.913092602789402, "actor_loss": -49.83153704833985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.238581895828247, "step": 110000}
{"episode_reward": 564.2193378508049, "episode": 111.0, "batch_reward": 0.4580354367494583, "critic_loss": 0.9165581864118576, "actor_loss": -49.767926055908205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.4084689617157, "step": 111000}
{"episode_reward": 585.0166538508851, "episode": 112.0, "batch_reward": 0.45864701986312867, "critic_loss": 0.848529266089201, "actor_loss": -50.110158920288086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.978328466415405, "step": 112000}
{"episode_reward": 564.9451912413273, "episode": 113.0, "batch_reward": 0.4615054606795311, "critic_loss": 0.8879286807775497, "actor_loss": -49.88533674621582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.86036252975464, "step": 113000}
{"episode_reward": 564.8261146036323, "episode": 114.0, "batch_reward": 0.4601723442673683, "critic_loss": 0.8452291351258755, "actor_loss": -50.15571110534668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.87943983078003, "step": 114000}
{"episode_reward": 210.28813839364523, "episode": 115.0, "batch_reward": 0.45787754982709883, "critic_loss": 0.839342934936285, "actor_loss": -50.06270252990723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.752995252609253, "step": 115000}
{"episode_reward": 535.6149633203133, "episode": 116.0, "batch_reward": 0.4595717302560806, "critic_loss": 0.8148775334656239, "actor_loss": -50.12222648620605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.342756748199463, "step": 116000}
{"episode_reward": 563.0811498551402, "episode": 117.0, "batch_reward": 0.4606603507995605, "critic_loss": 0.8144291292726994, "actor_loss": -50.189189804077145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.23331117630005, "step": 117000}
{"episode_reward": 585.9720579616962, "episode": 118.0, "batch_reward": 0.4608901238143444, "critic_loss": 0.8396465875804424, "actor_loss": -50.16531972503662, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.742980003356934, "step": 118000}
{"episode_reward": 569.6954572029057, "episode": 119.0, "batch_reward": 0.4621942211985588, "critic_loss": 0.7639817225039005, "actor_loss": -50.34496203613281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.779625177383423, "step": 119000}
{"episode_reward": 528.1001023730853, "episode": 120.0, "batch_reward": 0.46305641514062884, "critic_loss": 0.7405215983688831, "actor_loss": -50.60546278381348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.937857151031494, "step": 120000}
{"episode_reward": 576.8766221907603, "episode": 121.0, "batch_reward": 0.4635764430463314, "critic_loss": 0.7327760249823332, "actor_loss": -50.53610048675537, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.09439826011658, "step": 121000}
{"episode_reward": 589.6254986549717, "episode": 122.0, "batch_reward": 0.4656365180015564, "critic_loss": 0.7300691170990468, "actor_loss": -50.80685870361328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.933770179748535, "step": 122000}
{"episode_reward": 643.3299365633582, "episode": 123.0, "batch_reward": 0.4662072967886925, "critic_loss": 0.7369264672547579, "actor_loss": -51.02649171447754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.715530157089233, "step": 123000}
{"episode_reward": 538.9183130174936, "episode": 124.0, "batch_reward": 0.4664784134328365, "critic_loss": 0.7407711679637432, "actor_loss": -50.963741302490234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.69227910041809, "step": 124000}
{"episode_reward": 572.6004831705653, "episode": 125.0, "batch_reward": 0.4682807574570179, "critic_loss": 0.7226781204938889, "actor_loss": -51.22309405517578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.81545901298523, "step": 125000}
{"episode_reward": 535.4519328095826, "episode": 126.0, "batch_reward": 0.46768984308838846, "critic_loss": 0.7352796330153942, "actor_loss": -51.238749053955075, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.552353143692017, "step": 126000}
{"episode_reward": 573.5082995017244, "episode": 127.0, "batch_reward": 0.4686680217087269, "critic_loss": 0.6985149478912354, "actor_loss": -51.00057189941406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.79179835319519, "step": 127000}
{"episode_reward": 550.5411084804072, "episode": 128.0, "batch_reward": 0.4703468724489212, "critic_loss": 0.71373471057415, "actor_loss": -51.266839233398436, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.493154287338257, "step": 128000}
{"episode_reward": 610.6638821745202, "episode": 129.0, "batch_reward": 0.4710920599102974, "critic_loss": 0.6615228083729744, "actor_loss": -51.39772984313965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.383486032485962, "step": 129000}
{"episode_reward": 550.4542526494224, "episode": 130.0, "batch_reward": 0.4719642189443111, "critic_loss": 0.6815813939273357, "actor_loss": -51.449913269042966, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.21105694770813, "step": 130000}
{"episode_reward": 568.5818325639333, "episode": 131.0, "batch_reward": 0.4718105757236481, "critic_loss": 0.6571386733353138, "actor_loss": -51.19045318603516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.42821002006531, "step": 131000}
{"episode_reward": 600.0071951853724, "episode": 132.0, "batch_reward": 0.47266839787364007, "critic_loss": 0.6817226682603359, "actor_loss": -51.424824714660645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.025389194488525, "step": 132000}
{"episode_reward": 599.6223949449638, "episode": 133.0, "batch_reward": 0.4732490371763706, "critic_loss": 0.7261934370696544, "actor_loss": -51.70819725036621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.39011836051941, "step": 133000}
{"episode_reward": 566.0057693650473, "episode": 134.0, "batch_reward": 0.47500736692547796, "critic_loss": 0.7292383984029293, "actor_loss": -51.89788385009766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.560086727142334, "step": 134000}
{"episode_reward": 557.2996877549706, "episode": 135.0, "batch_reward": 0.47472314968705176, "critic_loss": 0.7304920366108417, "actor_loss": -51.88086124420166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.223658800125122, "step": 135000}
{"episode_reward": 560.2712542205221, "episode": 136.0, "batch_reward": 0.47535889452695845, "critic_loss": 0.7769584690034389, "actor_loss": -51.89534482574463, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.928848028182983, "step": 136000}
{"episode_reward": 547.930115698142, "episode": 137.0, "batch_reward": 0.4767053065598011, "critic_loss": 0.8020781572312117, "actor_loss": -51.98304399108887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.43529200553894, "step": 137000}
{"episode_reward": 555.5504383880785, "episode": 138.0, "batch_reward": 0.4769337496161461, "critic_loss": 0.7693561045825481, "actor_loss": -51.78593242645264, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.501612186431885, "step": 138000}
{"episode_reward": 605.4773931112063, "episode": 139.0, "batch_reward": 0.4786527189314365, "critic_loss": 0.7270978986620903, "actor_loss": -51.89209869384766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.6653470993042, "step": 139000}
{"episode_reward": 569.073522632434, "episode": 140.0, "batch_reward": 0.4773578294813633, "critic_loss": 0.7478860603272914, "actor_loss": -51.83812664794922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.054887533187866, "step": 140000}
{"episode_reward": 577.5230268550769, "episode": 141.0, "batch_reward": 0.4788666990697384, "critic_loss": 0.718542713329196, "actor_loss": -52.18814183807373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.84123516082764, "step": 141000}
{"episode_reward": 560.101578941247, "episode": 142.0, "batch_reward": 0.47994356709718705, "critic_loss": 0.7493170465826988, "actor_loss": -52.235085891723635, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.076521396636963, "step": 142000}
{"episode_reward": 575.0175839105924, "episode": 143.0, "batch_reward": 0.4800031513571739, "critic_loss": 0.6812656774818897, "actor_loss": -52.35537614440918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.31554865837097, "step": 143000}
{"episode_reward": 321.21096279924325, "episode": 144.0, "batch_reward": 0.48044973465800284, "critic_loss": 0.7281619638800622, "actor_loss": -52.36238637542725, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.30759859085083, "step": 144000}
{"episode_reward": 574.479168976033, "episode": 145.0, "batch_reward": 0.48025599816441533, "critic_loss": 0.7532152093499899, "actor_loss": -52.54993147277832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98990488052368, "step": 145000}
{"episode_reward": 532.7780834522238, "episode": 146.0, "batch_reward": 0.48014772871136663, "critic_loss": 0.7101882373988628, "actor_loss": -52.08393383026123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.5412859916687, "step": 146000}
{"episode_reward": 595.2638694971686, "episode": 147.0, "batch_reward": 0.481607976436615, "critic_loss": 0.7142906457781791, "actor_loss": -52.344336395263674, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.516852378845215, "step": 147000}
{"episode_reward": 575.4212469211869, "episode": 148.0, "batch_reward": 0.48275334906578066, "critic_loss": 0.768771316409111, "actor_loss": -52.41474254608154, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.898791313171387, "step": 148000}
{"episode_reward": 607.0707700095779, "episode": 149.0, "batch_reward": 0.48210312700271607, "critic_loss": 0.7871468608081341, "actor_loss": -52.57408711242676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.43399477005005, "step": 149000}
