{"episode_reward": 0.0, "episode": 1.0, "duration": 14.14158320426941, "step": 1000}
{"episode_reward": 4.20996189079657, "episode": 2.0, "duration": 1.2304017543792725, "step": 2000}
{"episode_reward": 252.2457487418515, "episode": 3.0, "batch_reward": 0.12971632621335205, "critic_loss": 0.04425694621980151, "actor_loss": -25.561309338592384, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254236, "duration": 68.06146883964539, "step": 3000}
{"episode_reward": 151.5693941956046, "episode": 4.0, "batch_reward": 0.1262723938599229, "critic_loss": 0.06529442803934217, "actor_loss": -22.01885128450394, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.27526593208313, "step": 4000}
{"episode_reward": 40.222773505654395, "episode": 5.0, "batch_reward": 0.10369546303525567, "critic_loss": 0.05613239700905979, "actor_loss": -18.172913309574128, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.816737413406372, "step": 5000}
{"episode_reward": 23.934225874870904, "episode": 6.0, "batch_reward": 0.08982347514852881, "critic_loss": 0.06095209855400026, "actor_loss": -15.780726903438568, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.048399448394775, "step": 6000}
{"episode_reward": 26.56817836003452, "episode": 7.0, "batch_reward": 0.07956685689464212, "critic_loss": 0.0733615929223597, "actor_loss": -15.552003754377365, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.582284927368164, "step": 7000}
{"episode_reward": 18.637924508835063, "episode": 8.0, "batch_reward": 0.07374183506891131, "critic_loss": 0.11595185398310423, "actor_loss": -15.132725401729346, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.913700103759766, "step": 8000}
{"episode_reward": 63.323923508274866, "episode": 9.0, "batch_reward": 0.07641181506961583, "critic_loss": 0.11520059382170439, "actor_loss": -15.032308536916972, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.933309316635132, "step": 9000}
{"episode_reward": 125.11343768499188, "episode": 10.0, "batch_reward": 0.07818819066509604, "critic_loss": 0.09119406230375171, "actor_loss": -14.555699807323515, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.012305974960327, "step": 10000}
{"episode_reward": 42.54958363279438, "episode": 11.0, "batch_reward": 0.0787482003942132, "critic_loss": 0.07417731233686209, "actor_loss": -15.492056268453599, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 35.536365270614624, "step": 11000}
{"episode_reward": 197.70163215058835, "episode": 12.0, "batch_reward": 0.09181600115448237, "critic_loss": 0.08291866251453757, "actor_loss": -15.679826824903488, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.27332305908203, "step": 12000}
{"episode_reward": 170.4106364144359, "episode": 13.0, "batch_reward": 0.09272909292206168, "critic_loss": 0.08891172711551189, "actor_loss": -15.675028094768525, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.859199285507202, "step": 13000}
{"episode_reward": 51.77936576487946, "episode": 14.0, "batch_reward": 0.0920090425312519, "critic_loss": 0.09965502521768212, "actor_loss": -14.705970956802368, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.922332048416138, "step": 14000}
{"episode_reward": 92.63983138329377, "episode": 15.0, "batch_reward": 0.08944214016199112, "critic_loss": 0.1138651082329452, "actor_loss": -14.878529283523559, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.80886673927307, "step": 15000}
{"episode_reward": 42.584169637325544, "episode": 16.0, "batch_reward": 0.08525421809777617, "critic_loss": 0.10276718612760305, "actor_loss": -14.157508865356446, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.879979372024536, "step": 16000}
{"episode_reward": 33.60088315821291, "episode": 17.0, "batch_reward": 0.08516186964884401, "critic_loss": 0.10857356144487858, "actor_loss": -14.076104599952698, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.327340602874756, "step": 17000}
{"episode_reward": 73.93371627012297, "episode": 18.0, "batch_reward": 0.08211738983914256, "critic_loss": 0.11383389658853411, "actor_loss": -12.82354957962036, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.53493618965149, "step": 18000}
{"episode_reward": 37.26640562708905, "episode": 19.0, "batch_reward": 0.08120621788501739, "critic_loss": 0.12669137679040432, "actor_loss": -13.304327025413514, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.108500719070435, "step": 19000}
{"episode_reward": 66.48861518887158, "episode": 20.0, "batch_reward": 0.08002989897876978, "critic_loss": 0.13903841893747448, "actor_loss": -12.82456415462494, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.267784357070923, "step": 20000}
{"episode_reward": 53.69972642149884, "episode": 21.0, "batch_reward": 0.0775201521962881, "critic_loss": 0.16451491020992398, "actor_loss": -12.757915440559387, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 35.354981422424316, "step": 21000}
{"episode_reward": 44.467046152860846, "episode": 22.0, "batch_reward": 0.07835041343420744, "critic_loss": 0.18456723847240208, "actor_loss": -12.301168867111206, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.237001419067383, "step": 22000}
{"episode_reward": 89.69537688356402, "episode": 23.0, "batch_reward": 0.08108729735016823, "critic_loss": 0.2010428288578987, "actor_loss": -13.093136691093445, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.09342312812805, "step": 23000}
{"episode_reward": 174.16448634197275, "episode": 24.0, "batch_reward": 0.08228039214015007, "critic_loss": 0.20568575762212277, "actor_loss": -13.525628111839294, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.359352588653564, "step": 24000}
{"episode_reward": 98.75319565895656, "episode": 25.0, "batch_reward": 0.08393969797343016, "critic_loss": 0.19028089989721775, "actor_loss": -12.67401438999176, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.38439130783081, "step": 25000}
{"episode_reward": 120.44217791652794, "episode": 26.0, "batch_reward": 0.08954152663052083, "critic_loss": 0.21143508636206387, "actor_loss": -13.673017887115478, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.609377145767212, "step": 26000}
{"episode_reward": 310.16237565517986, "episode": 27.0, "batch_reward": 0.09601759808138013, "critic_loss": 0.2424538997039199, "actor_loss": -13.91945265674591, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.913974046707153, "step": 27000}
{"episode_reward": 257.1875554974346, "episode": 28.0, "batch_reward": 0.0992303596995771, "critic_loss": 0.2675064690336585, "actor_loss": -13.99637226009369, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.86892342567444, "step": 28000}
{"episode_reward": 81.83740661193703, "episode": 29.0, "batch_reward": 0.0974820130765438, "critic_loss": 0.2909044880494475, "actor_loss": -13.896375032424928, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.66827082633972, "step": 29000}
{"episode_reward": 41.0129035646715, "episode": 30.0, "batch_reward": 0.09721920735388995, "critic_loss": 0.2906265948116779, "actor_loss": -14.162067341804505, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.893017292022705, "step": 30000}
{"episode_reward": 97.2713368377392, "episode": 31.0, "batch_reward": 0.09795515791326762, "critic_loss": 0.3183070082217455, "actor_loss": -13.627967370986939, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 34.80871868133545, "step": 31000}
{"episode_reward": 105.78366110521361, "episode": 32.0, "batch_reward": 0.09682731745392084, "critic_loss": 0.3175531482771039, "actor_loss": -13.773120867729187, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.247405529022217, "step": 32000}
{"episode_reward": 59.080504796384325, "episode": 33.0, "batch_reward": 0.09643031053245067, "critic_loss": 0.3347911190614104, "actor_loss": -13.664542521476745, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.811370372772217, "step": 33000}
{"episode_reward": 114.9115251218081, "episode": 34.0, "batch_reward": 0.0950663234218955, "critic_loss": 0.3281501409262419, "actor_loss": -13.534947842597962, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.909390211105347, "step": 34000}
{"episode_reward": 48.13985396927981, "episode": 35.0, "batch_reward": 0.09488856891170144, "critic_loss": 0.32624223993718626, "actor_loss": -14.251284078598022, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.241955518722534, "step": 35000}
{"episode_reward": 53.014394546807274, "episode": 36.0, "batch_reward": 0.09331722787395119, "critic_loss": 0.30758940418064595, "actor_loss": -13.657555290222168, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.94514560699463, "step": 36000}
{"episode_reward": 58.49906647768323, "episode": 37.0, "batch_reward": 0.09373299066349863, "critic_loss": 0.3361025732085109, "actor_loss": -14.121981401443481, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.115898370742798, "step": 37000}
{"episode_reward": 109.20915047525706, "episode": 38.0, "batch_reward": 0.09443904137611389, "critic_loss": 0.33049997428804634, "actor_loss": -14.39183125114441, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.373619079589844, "step": 38000}
{"episode_reward": 89.51595734099169, "episode": 39.0, "batch_reward": 0.09632936856523157, "critic_loss": 0.3787428796067834, "actor_loss": -14.227230457305907, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.718783617019653, "step": 39000}
{"episode_reward": 394.11659743539036, "episode": 40.0, "batch_reward": 0.10126776953414082, "critic_loss": 0.31967283368855715, "actor_loss": -14.463742763519287, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.880428791046143, "step": 40000}
{"episode_reward": 123.71678552653296, "episode": 41.0, "batch_reward": 0.10502094645425677, "critic_loss": 0.3126210363730788, "actor_loss": -14.968073253631593, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 35.36916661262512, "step": 41000}
{"episode_reward": 385.0645814620859, "episode": 42.0, "batch_reward": 0.10916869174689055, "critic_loss": 0.33250436310470105, "actor_loss": -15.370019533157349, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.69111657142639, "step": 42000}
{"episode_reward": 98.42241083991985, "episode": 43.0, "batch_reward": 0.10939792705327273, "critic_loss": 0.31859825300425293, "actor_loss": -15.189514841079712, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.474696397781372, "step": 43000}
{"episode_reward": 135.22362952151238, "episode": 44.0, "batch_reward": 0.11311841240525246, "critic_loss": 0.31673189386725425, "actor_loss": -15.973366397857665, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.00174880027771, "step": 44000}
{"episode_reward": 455.06574621769374, "episode": 45.0, "batch_reward": 0.11870010227710008, "critic_loss": 0.3294750851616263, "actor_loss": -16.42376273918152, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.780903577804565, "step": 45000}
{"episode_reward": 384.5279383711886, "episode": 46.0, "batch_reward": 0.12579155793040991, "critic_loss": 0.4131429047435522, "actor_loss": -16.853623460769654, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.256991863250732, "step": 46000}
{"episode_reward": 346.5167291639543, "episode": 47.0, "batch_reward": 0.12966278332471848, "critic_loss": 0.44129106277227403, "actor_loss": -17.252165422439575, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.94404172897339, "step": 47000}
{"episode_reward": 366.06174204438764, "episode": 48.0, "batch_reward": 0.13436880976706744, "critic_loss": 0.4948764739632607, "actor_loss": -17.794030092239378, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.91691303253174, "step": 48000}
{"episode_reward": 404.6101172040687, "episode": 49.0, "batch_reward": 0.14048717039823533, "critic_loss": 0.563376209244132, "actor_loss": -18.149708990097047, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.15269923210144, "step": 49000}
{"episode_reward": 317.56241711991936, "episode": 50.0, "batch_reward": 0.14245972277224064, "critic_loss": 0.6735762265324593, "actor_loss": -18.741362115859985, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.45944595336914, "step": 50000}
{"episode_reward": 332.850148854646, "episode": 51.0, "batch_reward": 0.14341086307168008, "critic_loss": 0.7594554313719273, "actor_loss": -19.680076831817626, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 35.661067485809326, "step": 51000}
{"episode_reward": 27.455520996975324, "episode": 52.0, "batch_reward": 0.14205382088571786, "critic_loss": 0.7696174891293048, "actor_loss": -21.654515815734865, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.939094066619873, "step": 52000}
{"episode_reward": 3.723538763348939, "episode": 53.0, "batch_reward": 0.13957564760744573, "critic_loss": 0.6801135055720806, "actor_loss": -22.73146814727783, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.028298377990723, "step": 53000}
{"episode_reward": 6.534520348474827, "episode": 54.0, "batch_reward": 0.13720583073794843, "critic_loss": 0.6673243648409843, "actor_loss": -23.434103645324708, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.422342777252197, "step": 54000}
{"episode_reward": 11.42239101560909, "episode": 55.0, "batch_reward": 0.13420278488099574, "critic_loss": 0.7114416950345039, "actor_loss": -24.132211254119873, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.291982173919678, "step": 55000}
{"episode_reward": 12.405649813669827, "episode": 56.0, "batch_reward": 0.13232270123809575, "critic_loss": 0.6919248152077198, "actor_loss": -25.00375337219238, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.30515694618225, "step": 56000}
{"episode_reward": 14.091513428771785, "episode": 57.0, "batch_reward": 0.13010721135139466, "critic_loss": 0.6647086889743805, "actor_loss": -25.61107787322998, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.958189010620117, "step": 57000}
{"episode_reward": 9.79136207742908, "episode": 58.0, "batch_reward": 0.1276325891762972, "critic_loss": 0.6252325418442488, "actor_loss": -26.17840421295166, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.325966835021973, "step": 58000}
{"episode_reward": 16.02987162885604, "episode": 59.0, "batch_reward": 0.12630677496641873, "critic_loss": 0.5524288787543774, "actor_loss": -26.68687082672119, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.405808210372925, "step": 59000}
{"episode_reward": 24.038856193323703, "episode": 60.0, "batch_reward": 0.12482166943699122, "critic_loss": 0.5670444469004869, "actor_loss": -26.90242041015625, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.5364670753479, "step": 60000}
{"episode_reward": 14.12305181332603, "episode": 61.0, "batch_reward": 0.12202761715650559, "critic_loss": 0.5125237733870744, "actor_loss": -27.227443283081055, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 35.535902976989746, "step": 61000}
{"episode_reward": 4.117614021877014, "episode": 62.0, "batch_reward": 0.12086320163309575, "critic_loss": 0.5617525045126677, "actor_loss": -28.051567264556883, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.158008575439453, "step": 62000}
{"episode_reward": 14.094629417009314, "episode": 63.0, "batch_reward": 0.11930302270501852, "critic_loss": 0.5301044402122498, "actor_loss": -28.574515018463135, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.460234880447388, "step": 63000}
{"episode_reward": 15.741964526165578, "episode": 64.0, "batch_reward": 0.116812987819314, "critic_loss": 0.5001172591745854, "actor_loss": -29.09448711395264, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.69407367706299, "step": 64000}
{"episode_reward": 10.11033603143805, "episode": 65.0, "batch_reward": 0.11526652778685093, "critic_loss": 0.45362862245738506, "actor_loss": -29.46095463180542, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.080366373062134, "step": 65000}
{"episode_reward": 25.66173885072719, "episode": 66.0, "batch_reward": 0.11504811207205057, "critic_loss": 0.35752104096114634, "actor_loss": -30.00435717010498, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.993826389312744, "step": 66000}
{"episode_reward": 26.47697109635628, "episode": 67.0, "batch_reward": 0.11354567697644234, "critic_loss": 0.3166081509888172, "actor_loss": -29.904018394470214, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.8584406375885, "step": 67000}
{"episode_reward": 59.53768119288877, "episode": 68.0, "batch_reward": 0.11389140705764293, "critic_loss": 0.27703800836205483, "actor_loss": -30.15295389175415, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.92513155937195, "step": 68000}
{"episode_reward": 240.02555563337907, "episode": 69.0, "batch_reward": 0.11608488919585944, "critic_loss": 0.2294183581545949, "actor_loss": -29.728191219329833, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.207437992095947, "step": 69000}
{"episode_reward": 367.0463875061905, "episode": 70.0, "batch_reward": 0.12026781139522791, "critic_loss": 0.22186416833102704, "actor_loss": -29.72592430114746, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.80132293701172, "step": 70000}
{"episode_reward": 364.2593270761491, "episode": 71.0, "batch_reward": 0.1215697476118803, "critic_loss": 0.23432713843882083, "actor_loss": -29.232414905548097, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 35.2039589881897, "step": 71000}
{"episode_reward": 111.13712827612362, "episode": 72.0, "batch_reward": 0.12479507536441088, "critic_loss": 0.2547617614790797, "actor_loss": -28.891507343292236, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.792642831802368, "step": 72000}
{"episode_reward": 474.37331539553276, "episode": 73.0, "batch_reward": 0.12926403385400773, "critic_loss": 0.2706474827006459, "actor_loss": -28.803557064056395, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.509693384170532, "step": 73000}
{"episode_reward": 440.1941750548978, "episode": 74.0, "batch_reward": 0.1321701645255089, "critic_loss": 0.2984456024542451, "actor_loss": -28.439677642822264, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.75238347053528, "step": 74000}
{"episode_reward": 306.52757828365736, "episode": 75.0, "batch_reward": 0.13532839182019235, "critic_loss": 0.35471606063842775, "actor_loss": -28.527446109771727, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.853399991989136, "step": 75000}
{"episode_reward": 488.8100003027399, "episode": 76.0, "batch_reward": 0.14085344932228328, "critic_loss": 0.3498512005358934, "actor_loss": -28.47402031326294, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.321592330932617, "step": 76000}
{"episode_reward": 547.4871738399837, "episode": 77.0, "batch_reward": 0.14599641083925963, "critic_loss": 0.37095488706976176, "actor_loss": -28.50546183013916, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.424455642700195, "step": 77000}
{"episode_reward": 551.6990026064611, "episode": 78.0, "batch_reward": 0.1517877674624324, "critic_loss": 0.39338841220736503, "actor_loss": -28.78015687942505, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.062340021133423, "step": 78000}
{"episode_reward": 488.3660710489609, "episode": 79.0, "batch_reward": 0.1551735637485981, "critic_loss": 0.3980932292640209, "actor_loss": -28.743848804473878, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.830220460891724, "step": 79000}
{"episode_reward": 556.2032990918811, "episode": 80.0, "batch_reward": 0.16041688573360444, "critic_loss": 0.35471937280893323, "actor_loss": -28.904336055755614, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.45370602607727, "step": 80000}
{"episode_reward": 541.216640329437, "episode": 81.0, "batch_reward": 0.1658744284287095, "critic_loss": 0.37724701361358165, "actor_loss": -29.07206943511963, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 35.688154458999634, "step": 81000}
{"episode_reward": 579.4753104287006, "episode": 82.0, "batch_reward": 0.16746734044700862, "critic_loss": 0.37418038864433767, "actor_loss": -29.061710578918458, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.660773277282715, "step": 82000}
{"episode_reward": 79.88892548221871, "episode": 83.0, "batch_reward": 0.16833744260668754, "critic_loss": 0.36579299650341274, "actor_loss": -29.03126469039917, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.164968967437744, "step": 83000}
{"episode_reward": 559.7672721103178, "episode": 84.0, "batch_reward": 0.17320974074304105, "critic_loss": 0.3488040487766266, "actor_loss": -29.166190826416017, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.624091148376465, "step": 84000}
{"episode_reward": 554.9695706515249, "episode": 85.0, "batch_reward": 0.17931720834225418, "critic_loss": 0.3980156458467245, "actor_loss": -29.379694622039796, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.29343342781067, "step": 85000}
{"episode_reward": 585.0892324337945, "episode": 86.0, "batch_reward": 0.18170427991449833, "critic_loss": 0.34612762576341627, "actor_loss": -29.573110427856445, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.048397302627563, "step": 86000}
{"episode_reward": 581.379428705335, "episode": 87.0, "batch_reward": 0.18766941209882498, "critic_loss": 0.3543570580780506, "actor_loss": -29.815471641540526, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.840720415115356, "step": 87000}
{"episode_reward": 563.8954459727789, "episode": 88.0, "batch_reward": 0.19307928907871247, "critic_loss": 0.3609223707690835, "actor_loss": -30.18801835632324, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.894309997558594, "step": 88000}
{"episode_reward": 558.3778502888043, "episode": 89.0, "batch_reward": 0.19596473528444766, "critic_loss": 0.3685885468870401, "actor_loss": -30.249484619140624, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.91275119781494, "step": 89000}
{"episode_reward": 527.3186966756216, "episode": 90.0, "batch_reward": 0.20068560874462127, "critic_loss": 0.3572011959180236, "actor_loss": -30.503497760772706, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.51906156539917, "step": 90000}
{"episode_reward": 552.8604617085069, "episode": 91.0, "batch_reward": 0.20363519270718097, "critic_loss": 0.36489707277715205, "actor_loss": -30.558150276184083, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 35.990238904953, "step": 91000}
{"episode_reward": 547.8636150738448, "episode": 92.0, "batch_reward": 0.2068307232260704, "critic_loss": 0.34517549867928027, "actor_loss": -30.741683475494384, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.888009071350098, "step": 92000}
{"episode_reward": 533.6169719677592, "episode": 93.0, "batch_reward": 0.2121766785532236, "critic_loss": 0.3581972282230854, "actor_loss": -31.113187351226806, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.007689476013184, "step": 93000}
{"episode_reward": 591.000135894314, "episode": 94.0, "batch_reward": 0.2162116800248623, "critic_loss": 0.36983920955657956, "actor_loss": -31.411000007629394, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.556639909744263, "step": 94000}
{"episode_reward": 554.7162509397068, "episode": 95.0, "batch_reward": 0.21817808581888676, "critic_loss": 0.34355083292722705, "actor_loss": -31.39291677093506, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.08810257911682, "step": 95000}
{"episode_reward": 523.5286464089667, "episode": 96.0, "batch_reward": 0.2222093907892704, "critic_loss": 0.3277596295699477, "actor_loss": -31.647007564544676, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.169828414916992, "step": 96000}
{"episode_reward": 559.0765808294118, "episode": 97.0, "batch_reward": 0.22533897353708743, "critic_loss": 0.3333583039417863, "actor_loss": -31.71057846069336, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.039812326431274, "step": 97000}
{"episode_reward": 578.2815449032315, "episode": 98.0, "batch_reward": 0.22910588155686856, "critic_loss": 0.36207655603438615, "actor_loss": -32.012832019805906, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.290955305099487, "step": 98000}
{"episode_reward": 566.0576232670834, "episode": 99.0, "batch_reward": 0.23167502096295356, "critic_loss": 0.33466734404861925, "actor_loss": -32.12172944641113, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.942272186279297, "step": 99000}
{"episode_reward": 584.4483339784141, "episode": 100.0, "batch_reward": 0.23473259638249874, "critic_loss": 0.3651083285138011, "actor_loss": -32.197944858551026, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.910534143447876, "step": 100000}
{"episode_reward": 594.3253716930361, "episode": 101.0, "batch_reward": 0.2404653960466385, "critic_loss": 0.3390064207017422, "actor_loss": -32.75487007904053, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 35.49280786514282, "step": 101000}
{"episode_reward": 580.6003023141184, "episode": 102.0, "batch_reward": 0.24310993286967278, "critic_loss": 0.3541490549147129, "actor_loss": -32.51411633300781, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.59870743751526, "step": 102000}
{"episode_reward": 582.380870489586, "episode": 103.0, "batch_reward": 0.24607672436535358, "critic_loss": 0.3337850478887558, "actor_loss": -32.987242362976076, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.726815462112427, "step": 103000}
{"episode_reward": 615.1249915467313, "episode": 104.0, "batch_reward": 0.2495984160900116, "critic_loss": 0.3465752461850643, "actor_loss": -32.94519055938721, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.93427348136902, "step": 104000}
{"episode_reward": 462.5648432225724, "episode": 105.0, "batch_reward": 0.25165261003375056, "critic_loss": 0.3372689489275217, "actor_loss": -33.44227208328247, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.003864288330078, "step": 105000}
{"episode_reward": 554.2135794502565, "episode": 106.0, "batch_reward": 0.2553663637191057, "critic_loss": 0.3548656786009669, "actor_loss": -33.57124449920654, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.59447979927063, "step": 106000}
{"episode_reward": 584.2638831896941, "episode": 107.0, "batch_reward": 0.25760803060233595, "critic_loss": 0.34716026759147645, "actor_loss": -33.578217292785645, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.534202337265015, "step": 107000}
{"episode_reward": 596.9191452262108, "episode": 108.0, "batch_reward": 0.2615356071293354, "critic_loss": 0.35072683019936085, "actor_loss": -33.76465960311889, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.044485092163086, "step": 108000}
{"episode_reward": 586.2708483220632, "episode": 109.0, "batch_reward": 0.26461509783566, "critic_loss": 0.3809828250706196, "actor_loss": -34.112873825073244, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.202308416366577, "step": 109000}
{"episode_reward": 562.8316598994724, "episode": 110.0, "batch_reward": 0.2672351895719767, "critic_loss": 0.3473750514239073, "actor_loss": -34.093664478302, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.02966833114624, "step": 110000}
{"episode_reward": 574.9288895447747, "episode": 111.0, "batch_reward": 0.2707993950098753, "critic_loss": 0.3685798536092043, "actor_loss": -34.546799125671384, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 35.24065542221069, "step": 111000}
{"episode_reward": 595.5797944340165, "episode": 112.0, "batch_reward": 0.2717061935067177, "critic_loss": 0.36780659201741217, "actor_loss": -34.472559535980224, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.206342220306396, "step": 112000}
{"episode_reward": 495.26008616309963, "episode": 113.0, "batch_reward": 0.27573448610305784, "critic_loss": 0.3596343637704849, "actor_loss": -34.84042445755005, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.861106395721436, "step": 113000}
{"episode_reward": 577.0095539469769, "episode": 114.0, "batch_reward": 0.2776260722577572, "critic_loss": 0.3515411339104176, "actor_loss": -34.98446680450439, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.822258949279785, "step": 114000}
{"episode_reward": 590.7899031740843, "episode": 115.0, "batch_reward": 0.28005037988722326, "critic_loss": 0.37032916803658006, "actor_loss": -34.95357927322388, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.093406677246094, "step": 115000}
{"episode_reward": 560.7068396558144, "episode": 116.0, "batch_reward": 0.2815091634094715, "critic_loss": 0.3865612908452749, "actor_loss": -35.12001607894897, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.15009570121765, "step": 116000}
{"episode_reward": 610.5888965669996, "episode": 117.0, "batch_reward": 0.2861287373006344, "critic_loss": 0.3765195742696524, "actor_loss": -35.565049194335934, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.100409984588623, "step": 117000}
{"episode_reward": 576.4516451788669, "episode": 118.0, "batch_reward": 0.2883551731556654, "critic_loss": 0.40205340811610224, "actor_loss": -35.63507043075562, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.803040027618408, "step": 118000}
{"episode_reward": 576.0074096046769, "episode": 119.0, "batch_reward": 0.2899192852079868, "critic_loss": 0.40902073691785334, "actor_loss": -35.66190605163574, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.36042046546936, "step": 119000}
{"episode_reward": 572.4469458567419, "episode": 120.0, "batch_reward": 0.2928865236192942, "critic_loss": 0.375960392460227, "actor_loss": -35.97061460494995, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.934473037719727, "step": 120000}
{"episode_reward": 576.6402597027934, "episode": 121.0, "batch_reward": 0.2954322231560946, "critic_loss": 0.4059014428406954, "actor_loss": -36.244625190734865, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 35.55549454689026, "step": 121000}
{"episode_reward": 570.761890922259, "episode": 122.0, "batch_reward": 0.29800748072564603, "critic_loss": 0.40382654865086076, "actor_loss": -36.161742973327634, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.813596487045288, "step": 122000}
{"episode_reward": 618.7233131930916, "episode": 123.0, "batch_reward": 0.29936359578371047, "critic_loss": 0.4107429266124964, "actor_loss": -36.407095489501955, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.040755033493042, "step": 123000}
{"episode_reward": 617.0081253222069, "episode": 124.0, "batch_reward": 0.30236347725987434, "critic_loss": 0.403915832914412, "actor_loss": -36.764372974395755, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.53060555458069, "step": 124000}
{"episode_reward": 610.7847828802609, "episode": 125.0, "batch_reward": 0.30548468816280366, "critic_loss": 0.39150713697075845, "actor_loss": -36.97862874221802, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.818166255950928, "step": 125000}
{"episode_reward": 604.0168502461187, "episode": 126.0, "batch_reward": 0.30636176410317423, "critic_loss": 0.4004737312793732, "actor_loss": -36.937339366912845, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.050679445266724, "step": 126000}
{"episode_reward": 630.630445802319, "episode": 127.0, "batch_reward": 0.3095110252648592, "critic_loss": 0.39749773928523063, "actor_loss": -37.259420963287354, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.58973526954651, "step": 127000}
{"episode_reward": 626.3363389167364, "episode": 128.0, "batch_reward": 0.3121194370388985, "critic_loss": 0.3896482881307602, "actor_loss": -37.47486814880371, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.172194242477417, "step": 128000}
{"episode_reward": 641.89846050089, "episode": 129.0, "batch_reward": 0.31464513097703456, "critic_loss": 0.40800953133404255, "actor_loss": -37.67545867919922, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.393675565719604, "step": 129000}
{"episode_reward": 601.1742332272827, "episode": 130.0, "batch_reward": 0.3171044325232506, "critic_loss": 0.35490402394533155, "actor_loss": -37.96891703796387, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.154570817947388, "step": 130000}
{"episode_reward": 624.0139145629398, "episode": 131.0, "batch_reward": 0.31920714600384237, "critic_loss": 0.38799464266002176, "actor_loss": -38.23298984527588, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 35.4283709526062, "step": 131000}
{"episode_reward": 541.4990270988607, "episode": 132.0, "batch_reward": 0.32114062237739566, "critic_loss": 0.3873928221166134, "actor_loss": -38.2338323097229, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.251973152160645, "step": 132000}
{"episode_reward": 605.650233211647, "episode": 133.0, "batch_reward": 0.32168682903051377, "critic_loss": 0.37950804050266745, "actor_loss": -38.31264233779907, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.899489402770996, "step": 133000}
{"episode_reward": 582.6932966042742, "episode": 134.0, "batch_reward": 0.32582468205690385, "critic_loss": 0.37526951295137406, "actor_loss": -38.50769080352783, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.726605653762817, "step": 134000}
{"episode_reward": 598.3810674021836, "episode": 135.0, "batch_reward": 0.3271327873468399, "critic_loss": 0.36156953470408915, "actor_loss": -38.5758872756958, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.307415008544922, "step": 135000}
{"episode_reward": 639.1512682376832, "episode": 136.0, "batch_reward": 0.32791679468750956, "critic_loss": 0.36245927396416666, "actor_loss": -38.595659355163576, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.73563861846924, "step": 136000}
{"episode_reward": 623.6075272524702, "episode": 137.0, "batch_reward": 0.33202812230587003, "critic_loss": 0.3556998063325882, "actor_loss": -39.019499847412106, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.43233847618103, "step": 137000}
{"episode_reward": 593.1023648693118, "episode": 138.0, "batch_reward": 0.33361372727155686, "critic_loss": 0.3690222962647676, "actor_loss": -39.20961811065674, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.858874797821045, "step": 138000}
{"episode_reward": 627.2182755667463, "episode": 139.0, "batch_reward": 0.3342535877674818, "critic_loss": 0.34371566140651705, "actor_loss": -39.436096466064456, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.479669332504272, "step": 139000}
{"episode_reward": 238.37162721995583, "episode": 140.0, "batch_reward": 0.3338871778547764, "critic_loss": 0.3839118076339364, "actor_loss": -39.345891609191895, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.95587992668152, "step": 140000}
{"episode_reward": 593.0426176897112, "episode": 141.0, "batch_reward": 0.3360455830097199, "critic_loss": 0.3760019820481539, "actor_loss": -39.28749965667725, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 34.83946108818054, "step": 141000}
{"episode_reward": 628.5060604435268, "episode": 142.0, "batch_reward": 0.33828589633107187, "critic_loss": 0.37674888731539247, "actor_loss": -39.58831974792481, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.585976362228394, "step": 142000}
{"episode_reward": 628.2815648801702, "episode": 143.0, "batch_reward": 0.34113990700244906, "critic_loss": 0.3812621278986335, "actor_loss": -39.5269895324707, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.169405221939087, "step": 143000}
{"episode_reward": 623.6399812975977, "episode": 144.0, "batch_reward": 0.34433924189209936, "critic_loss": 0.3852606362178922, "actor_loss": -40.00131269836426, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 20.931642532348633, "step": 144000}
{"episode_reward": 397.04091388681377, "episode": 145.0, "batch_reward": 0.3436298606544733, "critic_loss": 0.36574751859903337, "actor_loss": -39.666918815612796, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.223380088806152, "step": 145000}
{"episode_reward": 611.7680741203283, "episode": 146.0, "batch_reward": 0.34402128466963766, "critic_loss": 0.40914647410809996, "actor_loss": -40.11292906951904, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.52275538444519, "step": 146000}
{"episode_reward": 571.7864710949149, "episode": 147.0, "batch_reward": 0.34751637491583826, "critic_loss": 0.4029533976763487, "actor_loss": -40.283383979797364, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.490753173828125, "step": 147000}
{"episode_reward": 560.7660320591515, "episode": 148.0, "batch_reward": 0.34786213651299475, "critic_loss": 0.3948455942869186, "actor_loss": -40.278515396118166, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 22.068800687789917, "step": 148000}
{"episode_reward": 598.3353150025367, "episode": 149.0, "batch_reward": 0.34840628078579905, "critic_loss": 0.40769559134542943, "actor_loss": -40.433083862304684, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 21.951020002365112, "step": 149000}
{"episode_reward": 584.808564397074, "episode": 150.0, "batch_reward": 0.3514023281335831, "critic_loss": 0.3934272692799568, "actor_loss": -40.51060207366943, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "step": 150000}
