{"episode_reward": 0.0, "episode": 1.0, "duration": 17.53450584411621, "step": 1000}
{"episode_reward": 4.20996189079657, "episode": 2.0, "duration": 1.5206332206726074, "step": 2000}
{"episode_reward": 252.2457487418515, "episode": 3.0, "batch_reward": 0.12117903195656948, "critic_loss": 0.00994819440674279, "actor_loss": -15.380351497099644, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.11845803260803, "step": 3000}
{"episode_reward": 7.599380923988762, "episode": 4.0, "batch_reward": 0.07689578083902597, "critic_loss": 0.00422668047004845, "actor_loss": -13.649371606588364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.47708797454834, "step": 4000}
{"episode_reward": 4.254953318418285, "episode": 5.0, "batch_reward": 0.06058615553565323, "critic_loss": 0.007629540822817944, "actor_loss": -12.994833230733871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.498308897018433, "step": 5000}
{"episode_reward": 6.33061535777115, "episode": 6.0, "batch_reward": 0.05248468995280564, "critic_loss": 0.014053561196895317, "actor_loss": -14.167694229602814, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.504733324050903, "step": 6000}
{"episode_reward": 35.39551982756776, "episode": 7.0, "batch_reward": 0.05136831409856677, "critic_loss": 0.01586313745379448, "actor_loss": -13.315757275104522, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.486281871795654, "step": 7000}
{"episode_reward": 39.86454319808947, "episode": 8.0, "batch_reward": 0.04814994538202882, "critic_loss": 0.021630574548617006, "actor_loss": -14.320961948394775, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.48961091041565, "step": 8000}
{"episode_reward": 13.478464581146781, "episode": 9.0, "batch_reward": 0.04306499345973134, "critic_loss": 0.024623274898622184, "actor_loss": -13.389771879196166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.498568058013916, "step": 9000}
{"episode_reward": 4.409953796450715, "episode": 10.0, "batch_reward": 0.03872407888993621, "critic_loss": 0.02505124755715951, "actor_loss": -13.650632511138916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.464890718460083, "step": 10000}
{"episode_reward": 3.472283442604208, "episode": 11.0, "batch_reward": 0.034891293640248476, "critic_loss": 0.02160545692127198, "actor_loss": -12.898865564346313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.079731464385986, "step": 11000}
{"episode_reward": 5.030217318395643, "episode": 12.0, "batch_reward": 0.03315764591190964, "critic_loss": 0.017568660455057398, "actor_loss": -13.461993993759155, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.506038665771484, "step": 12000}
{"episode_reward": 5.368041514184722, "episode": 13.0, "batch_reward": 0.030708255666308106, "critic_loss": 0.01840544488443993, "actor_loss": -13.063452687501908, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.466870069503784, "step": 13000}
{"episode_reward": 5.833692733476317, "episode": 14.0, "batch_reward": 0.02896285863034427, "critic_loss": 0.013709746423643083, "actor_loss": -13.947304579019546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.46520709991455, "step": 14000}
{"episode_reward": 7.87371678955305, "episode": 15.0, "batch_reward": 0.02772328397259116, "critic_loss": 0.014505419920664281, "actor_loss": -12.938984424829483, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.48842763900757, "step": 15000}
{"episode_reward": 5.267181797468539, "episode": 16.0, "batch_reward": 0.026385294505394997, "critic_loss": 0.01769837185693905, "actor_loss": -12.763172388553619, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.500138759613037, "step": 16000}
{"episode_reward": 7.87771773837706, "episode": 17.0, "batch_reward": 0.025187497501261532, "critic_loss": 0.011362718933844008, "actor_loss": -13.049043337345124, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.50964117050171, "step": 17000}
{"episode_reward": 4.763261787814022, "episode": 18.0, "batch_reward": 0.024001499115489423, "critic_loss": 0.012217011531000025, "actor_loss": -13.591704105377197, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.504497289657593, "step": 18000}
{"episode_reward": 5.781853758145508, "episode": 19.0, "batch_reward": 0.02265695628663525, "critic_loss": 0.010014487725915388, "actor_loss": -12.606077319860459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.48730492591858, "step": 19000}
{"episode_reward": 7.183532050224226, "episode": 20.0, "batch_reward": 0.022062640922144057, "critic_loss": 0.009347929006326012, "actor_loss": -12.887839913368225, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.50521683692932, "step": 20000}
{"episode_reward": 5.072669265106797, "episode": 21.0, "batch_reward": 0.02079428831860423, "critic_loss": 0.00899070856301114, "actor_loss": -12.62800620651245, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.07491183280945, "step": 21000}
{"episode_reward": 6.157011940709125, "episode": 22.0, "batch_reward": 0.020174365370068698, "critic_loss": 0.010030724435346201, "actor_loss": -12.757256381273269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.478156328201294, "step": 22000}
{"episode_reward": 6.5380547587046225, "episode": 23.0, "batch_reward": 0.019900898919906467, "critic_loss": 0.008014163588290104, "actor_loss": -12.140823310256005, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.46471881866455, "step": 23000}
{"episode_reward": 4.061474291372712, "episode": 24.0, "batch_reward": 0.01887866629473865, "critic_loss": 0.008730649816803633, "actor_loss": -11.404394539356232, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.503393411636353, "step": 24000}
{"episode_reward": 3.4095268325707, "episode": 25.0, "batch_reward": 0.01799493878427893, "critic_loss": 0.006813245625933632, "actor_loss": -12.692030479073525, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.49656844139099, "step": 25000}
{"episode_reward": 5.524223158726062, "episode": 26.0, "batch_reward": 0.01806319754989818, "critic_loss": 0.005824615837831516, "actor_loss": -11.833629776835442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.603740692138672, "step": 26000}
{"episode_reward": 4.065803190614717, "episode": 27.0, "batch_reward": 0.017312669730279593, "critic_loss": 0.007152407468762249, "actor_loss": -11.505497144222259, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.717941761016846, "step": 27000}
{"episode_reward": 4.949249613749863, "episode": 28.0, "batch_reward": 0.017282215139362962, "critic_loss": 0.005731885386630893, "actor_loss": -12.432356348991394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.46525502204895, "step": 28000}
{"episode_reward": 4.115304229304145, "episode": 29.0, "batch_reward": 0.0165203802222386, "critic_loss": 0.006719657814828679, "actor_loss": -11.751672348499298, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.443326950073242, "step": 29000}
{"episode_reward": 4.080098129428517, "episode": 30.0, "batch_reward": 0.016137093691388146, "critic_loss": 0.005268591345695313, "actor_loss": -11.686651520729065, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.494975566864014, "step": 30000}
{"episode_reward": 5.016443932626189, "episode": 31.0, "batch_reward": 0.01603637752495706, "critic_loss": 0.005536823235452175, "actor_loss": -13.13404103732109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.06814646720886, "step": 31000}
{"episode_reward": 7.7987283587967315, "episode": 32.0, "batch_reward": 0.01575156132923439, "critic_loss": 0.006003468153765425, "actor_loss": -11.922249585986137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.461612701416016, "step": 32000}
{"episode_reward": 7.26669973498873, "episode": 33.0, "batch_reward": 0.015146561698522418, "critic_loss": 0.00497776368225459, "actor_loss": -11.997971847772599, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.470680952072144, "step": 33000}
{"episode_reward": 7.6017146243898095, "episode": 34.0, "batch_reward": 0.014939385945443064, "critic_loss": 0.006928285844507627, "actor_loss": -12.525049273610115, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.4804630279541, "step": 34000}
{"episode_reward": 7.897667767968503, "episode": 35.0, "batch_reward": 0.014917087045498193, "critic_loss": 0.006925782289239578, "actor_loss": -11.846340027809143, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.513582944869995, "step": 35000}
{"episode_reward": 5.317073855453696, "episode": 36.0, "batch_reward": 0.014849713185802102, "critic_loss": 0.007758149422705174, "actor_loss": -12.451039150238037, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.492539405822754, "step": 36000}
{"episode_reward": 36.94412647027509, "episode": 37.0, "batch_reward": 0.01565507123898715, "critic_loss": 0.012323849471984432, "actor_loss": -13.27697415614128, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.476621866226196, "step": 37000}
{"episode_reward": 24.1462018983451, "episode": 38.0, "batch_reward": 0.016060968396719544, "critic_loss": 0.006457305334857665, "actor_loss": -13.772748672008515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.46947741508484, "step": 38000}
{"episode_reward": 18.14584222211844, "episode": 39.0, "batch_reward": 0.015576557297026738, "critic_loss": 0.005608519032830372, "actor_loss": -13.623452536582947, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.496361255645752, "step": 39000}
{"episode_reward": 15.973570976382316, "episode": 40.0, "batch_reward": 0.015809901085682213, "critic_loss": 0.00471538135339506, "actor_loss": -13.999133150577546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.4641375541687, "step": 40000}
{"episode_reward": 13.79396865159054, "episode": 41.0, "batch_reward": 0.01579957862896845, "critic_loss": 0.004514119200059213, "actor_loss": -13.336172104358672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.057979345321655, "step": 41000}
{"episode_reward": 16.42765586175424, "episode": 42.0, "batch_reward": 0.015534367696847767, "critic_loss": 0.005448784413165413, "actor_loss": -13.512667824268341, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.43429470062256, "step": 42000}
{"episode_reward": 5.215249500984923, "episode": 43.0, "batch_reward": 0.015430605202447623, "critic_loss": 0.005544421718455851, "actor_loss": -13.691977588653565, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.449786901474, "step": 43000}
{"episode_reward": 3.9614270626279735, "episode": 44.0, "batch_reward": 0.014968082542531192, "critic_loss": 0.0070726807131431995, "actor_loss": -13.0425679063797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.488703727722168, "step": 44000}
{"episode_reward": 7.4653954206112045, "episode": 45.0, "batch_reward": 0.015024878011550754, "critic_loss": 0.006025609848322347, "actor_loss": -12.033979487419128, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.480204582214355, "step": 45000}
{"episode_reward": 31.843476234209533, "episode": 46.0, "batch_reward": 0.016451982385478913, "critic_loss": 0.008225799243198708, "actor_loss": -11.707972597122192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.51914143562317, "step": 46000}
{"episode_reward": 110.07249488054431, "episode": 47.0, "batch_reward": 0.01783264917647466, "critic_loss": 0.011399654511595145, "actor_loss": -13.30872487783432, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.453340530395508, "step": 47000}
{"episode_reward": 45.62141775111213, "episode": 48.0, "batch_reward": 0.01800310149649158, "critic_loss": 0.012579220002982765, "actor_loss": -13.03409318304062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.456943035125732, "step": 48000}
{"episode_reward": 44.80744599979288, "episode": 49.0, "batch_reward": 0.019666931960731746, "critic_loss": 0.01473205118952319, "actor_loss": -13.506231350421906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.471473693847656, "step": 49000}
{"episode_reward": 126.51151959261134, "episode": 50.0, "batch_reward": 0.021640637351199983, "critic_loss": 0.01708314744569361, "actor_loss": -13.297306739807128, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.47916603088379, "step": 50000}
{"episode_reward": 117.24496772788736, "episode": 51.0, "batch_reward": 0.022863598068244756, "critic_loss": 0.019060399441514164, "actor_loss": -13.603942142486572, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.016908407211304, "step": 51000}
{"episode_reward": 52.01654451377089, "episode": 52.0, "batch_reward": 0.023225621474906803, "critic_loss": 0.02021371329203248, "actor_loss": -13.61517679977417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.51192331314087, "step": 52000}
{"episode_reward": 33.07195303094774, "episode": 53.0, "batch_reward": 0.024149499244987965, "critic_loss": 0.024485556964762508, "actor_loss": -14.900733820915223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.452444553375244, "step": 53000}
{"episode_reward": 68.27369984269768, "episode": 54.0, "batch_reward": 0.024243280986323952, "critic_loss": 0.027915847985073926, "actor_loss": -14.55173433303833, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.464189767837524, "step": 54000}
{"episode_reward": 66.67734648511302, "episode": 55.0, "batch_reward": 0.025949439607560635, "critic_loss": 0.03587803831230849, "actor_loss": -14.343668676376343, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.468993186950684, "step": 55000}
{"episode_reward": 133.46452949040082, "episode": 56.0, "batch_reward": 0.028516213740222156, "critic_loss": 0.039339104693382976, "actor_loss": -14.491071570396423, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.46074652671814, "step": 56000}
{"episode_reward": 186.25442585260797, "episode": 57.0, "batch_reward": 0.02994193757791072, "critic_loss": 0.04555318053625524, "actor_loss": -14.549667895317077, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.471287488937378, "step": 57000}
{"episode_reward": 45.751846141446784, "episode": 58.0, "batch_reward": 0.029889947209507228, "critic_loss": 0.05752203450724482, "actor_loss": -15.317195889472961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.472761869430542, "step": 58000}
{"episode_reward": 13.709049853978492, "episode": 59.0, "batch_reward": 0.03076851886510849, "critic_loss": 0.06315163315273821, "actor_loss": -15.442906032562256, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.445627450942993, "step": 59000}
{"episode_reward": 157.74092808583703, "episode": 60.0, "batch_reward": 0.03273328268714249, "critic_loss": 0.07677069859020412, "actor_loss": -14.697850347518921, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.454368114471436, "step": 60000}
{"episode_reward": 95.45955006433734, "episode": 61.0, "batch_reward": 0.03307270512357354, "critic_loss": 0.08731162502616643, "actor_loss": -14.813794966697692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.037193059921265, "step": 61000}
{"episode_reward": 126.7916531822576, "episode": 62.0, "batch_reward": 0.034843101857230066, "critic_loss": 0.08931264090538026, "actor_loss": -13.880109818458557, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.48263454437256, "step": 62000}
{"episode_reward": 65.91999065115373, "episode": 63.0, "batch_reward": 0.03560872021317482, "critic_loss": 0.08975869475118815, "actor_loss": -14.33243893623352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.508874654769897, "step": 63000}
{"episode_reward": 64.38892595186766, "episode": 64.0, "batch_reward": 0.03597119360603392, "critic_loss": 0.09617479993216693, "actor_loss": -15.045283261299133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.46218466758728, "step": 64000}
{"episode_reward": 43.35010018635699, "episode": 65.0, "batch_reward": 0.036201529692858454, "critic_loss": 0.09099345204606653, "actor_loss": -13.976504112243653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.493374586105347, "step": 65000}
{"episode_reward": 91.79840988216235, "episode": 66.0, "batch_reward": 0.03627740748599172, "critic_loss": 0.10130963854119182, "actor_loss": -14.404924184799194, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.492573261260986, "step": 66000}
{"episode_reward": 24.56278979499752, "episode": 67.0, "batch_reward": 0.03684865959919989, "critic_loss": 0.10972111079841852, "actor_loss": -14.194575964927674, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.487032175064087, "step": 67000}
{"episode_reward": 79.03263910661805, "episode": 68.0, "batch_reward": 0.03797853635437787, "critic_loss": 0.142969694044441, "actor_loss": -14.85264382839203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.465271949768066, "step": 68000}
{"episode_reward": 152.29573483479982, "episode": 69.0, "batch_reward": 0.03911100746691227, "critic_loss": 0.1368322298116982, "actor_loss": -14.11365362071991, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.471231937408447, "step": 69000}
{"episode_reward": 99.13315610242313, "episode": 70.0, "batch_reward": 0.03989914973080158, "critic_loss": 0.14766341229528188, "actor_loss": -14.148659809112548, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.4787118434906, "step": 70000}
{"episode_reward": 75.39733407690632, "episode": 71.0, "batch_reward": 0.040594087483361366, "critic_loss": 0.1393340771496296, "actor_loss": -14.111707760810852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.03384470939636, "step": 71000}
{"episode_reward": 93.88767523587273, "episode": 72.0, "batch_reward": 0.041382793590426445, "critic_loss": 0.14302600810304283, "actor_loss": -14.101861740112305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.497968912124634, "step": 72000}
{"episode_reward": 120.16300234733316, "episode": 73.0, "batch_reward": 0.04208866282738745, "critic_loss": 0.1514317783638835, "actor_loss": -14.22429277229309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.51196002960205, "step": 73000}
{"episode_reward": 74.72903626422816, "episode": 74.0, "batch_reward": 0.042538078697398306, "critic_loss": 0.1472555278353393, "actor_loss": -14.02562131690979, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.49176526069641, "step": 74000}
{"episode_reward": 79.04340032536706, "episode": 75.0, "batch_reward": 0.04311918776668608, "critic_loss": 0.15231105495616792, "actor_loss": -14.341864818572999, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.466556787490845, "step": 75000}
{"episode_reward": 79.07230705734858, "episode": 76.0, "batch_reward": 0.043720693293958904, "critic_loss": 0.17484963097795844, "actor_loss": -14.614437886238099, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.459765911102295, "step": 76000}
{"episode_reward": 55.30282094171792, "episode": 77.0, "batch_reward": 0.04449289909936488, "critic_loss": 0.1923689605295658, "actor_loss": -14.380549726486207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.453274726867676, "step": 77000}
{"episode_reward": 197.37391251712467, "episode": 78.0, "batch_reward": 0.047044625606387856, "critic_loss": 0.22549089736491443, "actor_loss": -14.768518342018128, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.460693836212158, "step": 78000}
{"episode_reward": 214.6402077687235, "episode": 79.0, "batch_reward": 0.048521520486101505, "critic_loss": 0.19838146276772023, "actor_loss": -15.344434418678283, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.455398321151733, "step": 79000}
{"episode_reward": 221.00729617448442, "episode": 80.0, "batch_reward": 0.0507956794667989, "critic_loss": 0.19406984930112958, "actor_loss": -15.63756590270996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.50458526611328, "step": 80000}
{"episode_reward": 166.45213394316465, "episode": 81.0, "batch_reward": 0.05174456574767828, "critic_loss": 0.16448752592504023, "actor_loss": -15.928487845420838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.094319581985474, "step": 81000}
{"episode_reward": 27.318384739491034, "episode": 82.0, "batch_reward": 0.05221087601780892, "critic_loss": 0.21133820384740828, "actor_loss": -16.183246616363526, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.4544095993042, "step": 82000}
{"episode_reward": 153.09863714485553, "episode": 83.0, "batch_reward": 0.0532786580324173, "critic_loss": 0.1936593971028924, "actor_loss": -14.992890637397766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.48430871963501, "step": 83000}
{"episode_reward": 235.2806240398295, "episode": 84.0, "batch_reward": 0.05568256542086601, "critic_loss": 0.19559017779678106, "actor_loss": -15.67346312046051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.457709550857544, "step": 84000}
{"episode_reward": 238.54444817818117, "episode": 85.0, "batch_reward": 0.057227100413292646, "critic_loss": 0.16150022503361106, "actor_loss": -15.96066190624237, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.46179461479187, "step": 85000}
{"episode_reward": 168.88738991263529, "episode": 86.0, "batch_reward": 0.05784355169907212, "critic_loss": 0.1924320774562657, "actor_loss": -15.901094330787659, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.53515887260437, "step": 86000}
{"episode_reward": 54.38808840593504, "episode": 87.0, "batch_reward": 0.05836034880205989, "critic_loss": 0.1922224226370454, "actor_loss": -16.00532295036316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.456227779388428, "step": 87000}
{"episode_reward": 98.62350522127802, "episode": 88.0, "batch_reward": 0.05974892967939377, "critic_loss": 0.19628426843881608, "actor_loss": -16.028051431655882, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.457146644592285, "step": 88000}
{"episode_reward": 250.68052186676206, "episode": 89.0, "batch_reward": 0.0610792358443141, "critic_loss": 0.20116553954780103, "actor_loss": -16.488052320480346, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.46320414543152, "step": 89000}
{"episode_reward": 109.00731022282342, "episode": 90.0, "batch_reward": 0.06220632332935929, "critic_loss": 0.1961386142447591, "actor_loss": -16.71176450252533, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.438496351242065, "step": 90000}
{"episode_reward": 208.59728871185067, "episode": 91.0, "batch_reward": 0.0628692099750042, "critic_loss": 0.2008629581183195, "actor_loss": -16.532052282333375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.083120584487915, "step": 91000}
{"episode_reward": 42.417854709018314, "episode": 92.0, "batch_reward": 0.06283356127142906, "critic_loss": 0.18822130089253186, "actor_loss": -15.682334080696107, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.492545127868652, "step": 92000}
{"episode_reward": 119.607974236151, "episode": 93.0, "batch_reward": 0.06412131086736918, "critic_loss": 0.19626666598021983, "actor_loss": -16.311204778671264, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.419081926345825, "step": 93000}
{"episode_reward": 242.0816162308909, "episode": 94.0, "batch_reward": 0.06598867497220635, "critic_loss": 0.21022602631151677, "actor_loss": -15.832212745666505, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.488689184188843, "step": 94000}
{"episode_reward": 203.53978122170844, "episode": 95.0, "batch_reward": 0.06692555982246995, "critic_loss": 0.2274786901399493, "actor_loss": -17.053278661727905, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.48743486404419, "step": 95000}
{"episode_reward": 208.84176244898882, "episode": 96.0, "batch_reward": 0.06920341490581632, "critic_loss": 0.23843035276979208, "actor_loss": -16.364422931671143, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.486663818359375, "step": 96000}
{"episode_reward": 235.78808099565504, "episode": 97.0, "batch_reward": 0.07101193477585911, "critic_loss": 0.22489195206761362, "actor_loss": -17.59981113243103, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.507288932800293, "step": 97000}
{"episode_reward": 245.70896656200534, "episode": 98.0, "batch_reward": 0.07295445421338081, "critic_loss": 0.22576649969816207, "actor_loss": -18.11493898010254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.466475009918213, "step": 98000}
{"episode_reward": 254.69231751529057, "episode": 99.0, "batch_reward": 0.0733868222720921, "critic_loss": 0.2564345953091979, "actor_loss": -17.418526527404786, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.490309238433838, "step": 99000}
{"episode_reward": 33.612932370746876, "episode": 100.0, "batch_reward": 0.07381883566826582, "critic_loss": 0.25077962440997364, "actor_loss": -17.139122938156127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.66078472137451, "step": 100000}
{"episode_reward": 238.75077860319337, "episode": 101.0, "batch_reward": 0.07569492027908564, "critic_loss": 0.2559282502681017, "actor_loss": -17.057235944747926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.017271280288696, "step": 101000}
{"episode_reward": 190.99814726867044, "episode": 102.0, "batch_reward": 0.07693185582756996, "critic_loss": 0.26011251292377713, "actor_loss": -17.712616539001466, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.483673095703125, "step": 102000}
{"episode_reward": 247.46080187901876, "episode": 103.0, "batch_reward": 0.07727844020724296, "critic_loss": 0.2761257743537426, "actor_loss": -17.186677898406984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.487926721572876, "step": 103000}
{"episode_reward": 24.326636134552235, "episode": 104.0, "batch_reward": 0.07776304316520691, "critic_loss": 0.28231150629371404, "actor_loss": -17.9289686794281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.4733304977417, "step": 104000}
{"episode_reward": 221.61080551251735, "episode": 105.0, "batch_reward": 0.07885678130760788, "critic_loss": 0.3090346852168441, "actor_loss": -17.23811994934082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.52053475379944, "step": 105000}
{"episode_reward": 200.04536788612134, "episode": 106.0, "batch_reward": 0.07976613239943982, "critic_loss": 0.28788234100490806, "actor_loss": -17.459246578216554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.493195295333862, "step": 106000}
{"episode_reward": 207.82252604595638, "episode": 107.0, "batch_reward": 0.081270035892725, "critic_loss": 0.29604881228506563, "actor_loss": -17.91389987564087, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.4798800945282, "step": 107000}
{"episode_reward": 232.24403557950964, "episode": 108.0, "batch_reward": 0.0826194976232946, "critic_loss": 0.3052451657727361, "actor_loss": -17.999261304855345, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.506311655044556, "step": 108000}
{"episode_reward": 147.99529823306588, "episode": 109.0, "batch_reward": 0.08294999537989498, "critic_loss": 0.3292587624564767, "actor_loss": -18.4694321975708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.49203109741211, "step": 109000}
{"episode_reward": 25.969090911258697, "episode": 110.0, "batch_reward": 0.08240429648384452, "critic_loss": 0.2951616472452879, "actor_loss": -18.240637958526612, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.49949860572815, "step": 110000}
{"episode_reward": 64.22425665738574, "episode": 111.0, "batch_reward": 0.08220865839347244, "critic_loss": 0.32946718944609166, "actor_loss": -17.386882722854615, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.03232288360596, "step": 111000}
{"episode_reward": 57.34738650414938, "episode": 112.0, "batch_reward": 0.08235715499520302, "critic_loss": 0.36205103937536476, "actor_loss": -17.475721433639528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.47125482559204, "step": 112000}
{"episode_reward": 77.25285751990916, "episode": 113.0, "batch_reward": 0.08192314107716084, "critic_loss": 0.38300284844636917, "actor_loss": -17.077129779815674, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.508650541305542, "step": 113000}
{"episode_reward": 43.84819214280844, "episode": 114.0, "batch_reward": 0.08223947348073125, "critic_loss": 0.30814145585894587, "actor_loss": -17.83408759880066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.484965801239014, "step": 114000}
{"episode_reward": 198.42630028801452, "episode": 115.0, "batch_reward": 0.08294053906202316, "critic_loss": 0.3336235384643078, "actor_loss": -18.768676265716554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.450692415237427, "step": 115000}
{"episode_reward": 163.34333134264136, "episode": 116.0, "batch_reward": 0.08370607089623809, "critic_loss": 0.37966122845560313, "actor_loss": -18.364245115280152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.51206374168396, "step": 116000}
{"episode_reward": 167.14816949158643, "episode": 117.0, "batch_reward": 0.08409679815545679, "critic_loss": 0.29260647711902854, "actor_loss": -17.99775982284546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.50193214416504, "step": 117000}
{"episode_reward": 85.4887077385095, "episode": 118.0, "batch_reward": 0.08436398897692561, "critic_loss": 0.30420634618401526, "actor_loss": -17.66519660949707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.49108862876892, "step": 118000}
{"episode_reward": 134.7658633324832, "episode": 119.0, "batch_reward": 0.08455473322048783, "critic_loss": 0.3160016764700413, "actor_loss": -17.657012422561646, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.481664657592773, "step": 119000}
{"episode_reward": 106.38427685176259, "episode": 120.0, "batch_reward": 0.08562279767170548, "critic_loss": 0.3323964040502906, "actor_loss": -18.184354459762574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.479279279708862, "step": 120000}
{"episode_reward": 267.43635211744726, "episode": 121.0, "batch_reward": 0.08766667822375894, "critic_loss": 0.3428367331847548, "actor_loss": -17.747353635787963, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.99685025215149, "step": 121000}
{"episode_reward": 263.19430418643805, "episode": 122.0, "batch_reward": 0.08846866000071169, "critic_loss": 0.3542785730659962, "actor_loss": -18.65774510383606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.47973132133484, "step": 122000}
{"episode_reward": 257.0063026075303, "episode": 123.0, "batch_reward": 0.08969087959453463, "critic_loss": 0.35170372527092697, "actor_loss": -19.011799097061157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.473522186279297, "step": 123000}
{"episode_reward": 228.2474136473238, "episode": 124.0, "batch_reward": 0.08998747098073363, "critic_loss": 0.36918634600937367, "actor_loss": -18.427710435867308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.52126455307007, "step": 124000}
{"episode_reward": 36.82861411690426, "episode": 125.0, "batch_reward": 0.09008942166715861, "critic_loss": 0.40338376054167746, "actor_loss": -18.226643287658693, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.490206718444824, "step": 125000}
{"episode_reward": 109.64702138771743, "episode": 126.0, "batch_reward": 0.09042089855670929, "critic_loss": 0.4150203746408224, "actor_loss": -18.262466419219972, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.415871381759644, "step": 126000}
{"episode_reward": 276.6145774029261, "episode": 127.0, "batch_reward": 0.09206136018037796, "critic_loss": 0.3801165120899677, "actor_loss": -18.7226881275177, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.857903003692627, "step": 127000}
{"episode_reward": 258.71105524203966, "episode": 128.0, "batch_reward": 0.09265638212487101, "critic_loss": 0.4211056205034256, "actor_loss": -18.10964670944214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.503758907318115, "step": 128000}
{"episode_reward": 70.09789900533247, "episode": 129.0, "batch_reward": 0.09278160807490349, "critic_loss": 0.3683686262667179, "actor_loss": -18.077327255249024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.460715532302856, "step": 129000}
{"episode_reward": 280.9389610331156, "episode": 130.0, "batch_reward": 0.09481957989931107, "critic_loss": 0.38065802603960036, "actor_loss": -18.509751899719237, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.44696021080017, "step": 130000}
{"episode_reward": 283.17361538938053, "episode": 131.0, "batch_reward": 0.09529463080316782, "critic_loss": 0.37239356149733066, "actor_loss": -17.37549604034424, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.99912214279175, "step": 131000}
{"episode_reward": 81.50873414197814, "episode": 132.0, "batch_reward": 0.09527145563811064, "critic_loss": 0.43100701458007096, "actor_loss": -17.79952073287964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.490985870361328, "step": 132000}
{"episode_reward": 41.199492840316644, "episode": 133.0, "batch_reward": 0.09442069952189923, "critic_loss": 0.4668177174255252, "actor_loss": -17.949817348480224, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.51392936706543, "step": 133000}
{"episode_reward": 27.62266411035042, "episode": 134.0, "batch_reward": 0.09428727430105209, "critic_loss": 0.4577179627716541, "actor_loss": -17.993864448547363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.473586797714233, "step": 134000}
{"episode_reward": 69.94103282975111, "episode": 135.0, "batch_reward": 0.09359451287984848, "critic_loss": 0.42455093272030353, "actor_loss": -18.198938097000124, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.496524333953857, "step": 135000}
{"episode_reward": 29.225113107225443, "episode": 136.0, "batch_reward": 0.09327875401079655, "critic_loss": 0.4143734418079257, "actor_loss": -18.1829616355896, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.50774049758911, "step": 136000}
{"episode_reward": 30.680455947376405, "episode": 137.0, "batch_reward": 0.09416870388388633, "critic_loss": 0.39411235389858484, "actor_loss": -18.0043281288147, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.46845531463623, "step": 137000}
{"episode_reward": 175.73326710985006, "episode": 138.0, "batch_reward": 0.09433203689381481, "critic_loss": 0.39648763136565685, "actor_loss": -17.39373485946655, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.49075698852539, "step": 138000}
{"episode_reward": 167.84185298231614, "episode": 139.0, "batch_reward": 0.09414085142314434, "critic_loss": 0.4068830409348011, "actor_loss": -17.21410549736023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.486159563064575, "step": 139000}
{"episode_reward": 26.86278215521136, "episode": 140.0, "batch_reward": 0.09418675201386213, "critic_loss": 0.48449717220664024, "actor_loss": -16.898485046386718, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.498518705368042, "step": 140000}
{"episode_reward": 186.35220382177275, "episode": 141.0, "batch_reward": 0.09476939729973674, "critic_loss": 0.5225460998862982, "actor_loss": -17.719412014007567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.04465413093567, "step": 141000}
{"episode_reward": 104.54650074957543, "episode": 142.0, "batch_reward": 0.09410835122317075, "critic_loss": 0.4889720373004675, "actor_loss": -17.545310665130614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.465771436691284, "step": 142000}
{"episode_reward": 28.993895388589706, "episode": 143.0, "batch_reward": 0.09467396677285433, "critic_loss": 0.45095425128936767, "actor_loss": -18.01176980018616, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.471215963363647, "step": 143000}
{"episode_reward": 147.29463208721504, "episode": 144.0, "batch_reward": 0.09566753228008747, "critic_loss": 0.4375451596081257, "actor_loss": -17.435010597229002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.500319242477417, "step": 144000}
{"episode_reward": 142.8043724117834, "episode": 145.0, "batch_reward": 0.09454631929844617, "critic_loss": 0.415869506277144, "actor_loss": -18.03161413383484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.468075037002563, "step": 145000}
{"episode_reward": 23.71960873443342, "episode": 146.0, "batch_reward": 0.09353142544254661, "critic_loss": 0.4104493317827582, "actor_loss": -16.803823572158812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.51889181137085, "step": 146000}
{"episode_reward": 33.58639301689982, "episode": 147.0, "batch_reward": 0.09401402729004621, "critic_loss": 0.42048566275089977, "actor_loss": -16.935945531845093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.502951860427856, "step": 147000}
{"episode_reward": 69.14044257593845, "episode": 148.0, "batch_reward": 0.0934473349750042, "critic_loss": 0.48210354731976984, "actor_loss": -16.372206562042237, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.466480016708374, "step": 148000}
{"episode_reward": 22.71239998460485, "episode": 149.0, "batch_reward": 0.09352712704241276, "critic_loss": 0.44127332151681187, "actor_loss": -15.981127094268798, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.489328145980835, "step": 149000}
{"episode_reward": 205.57729199063775, "episode": 150.0, "batch_reward": 0.09474804631620645, "critic_loss": 0.41917103312909604, "actor_loss": -16.256000144958495, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
