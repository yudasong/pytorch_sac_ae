{"episode_reward": 0.0, "episode": 1.0, "duration": 17.236822605133057, "step": 1000}
{"episode_reward": 4.20996189079657, "episode": 2.0, "duration": 1.4792084693908691, "step": 2000}
{"episode_reward": 252.2457487418515, "episode": 3.0, "batch_reward": 0.13351335604813305, "critic_loss": 0.2655897227629259, "actor_loss": -36.71958820301802, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 59.957531452178955, "step": 3000}
{"episode_reward": 154.19996030993968, "episode": 4.0, "batch_reward": 0.17030610404908658, "critic_loss": 0.44551389902830124, "actor_loss": -36.23238129043579, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.799432039260864, "step": 4000}
{"episode_reward": 357.1315443045291, "episode": 5.0, "batch_reward": 0.18734409657865764, "critic_loss": 0.4671341778486967, "actor_loss": -35.12817473983765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.787910223007202, "step": 5000}
{"episode_reward": 81.94113058235257, "episode": 6.0, "batch_reward": 0.19628483924269677, "critic_loss": 0.5916685852855444, "actor_loss": -34.626988025665284, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.81057620048523, "step": 6000}
{"episode_reward": 452.94553598482673, "episode": 7.0, "batch_reward": 0.23072457276284694, "critic_loss": 0.7371364490389823, "actor_loss": -37.159571250915526, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.801427602767944, "step": 7000}
{"episode_reward": 357.88496353746916, "episode": 8.0, "batch_reward": 0.2403604920953512, "critic_loss": 0.8688018654882907, "actor_loss": -37.436721961975095, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.77789068222046, "step": 8000}
{"episode_reward": 176.46334799547907, "episode": 9.0, "batch_reward": 0.23472721649706363, "critic_loss": 0.9594599081873894, "actor_loss": -36.54040982055664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.84584641456604, "step": 9000}
{"episode_reward": 219.87393923702126, "episode": 10.0, "batch_reward": 0.24479317472875117, "critic_loss": 0.9587630632519722, "actor_loss": -36.87888352203369, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.83634114265442, "step": 10000}
{"episode_reward": 538.5657400494075, "episode": 11.0, "batch_reward": 0.2666153431981802, "critic_loss": 0.9832078732252121, "actor_loss": -38.68881378555298, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.123215436935425, "step": 11000}
{"episode_reward": 348.24194971576827, "episode": 12.0, "batch_reward": 0.27156523898243906, "critic_loss": 0.937673188328743, "actor_loss": -38.544211948394775, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.82801842689514, "step": 12000}
{"episode_reward": 409.89300395545166, "episode": 13.0, "batch_reward": 0.2811881588846445, "critic_loss": 1.011135534465313, "actor_loss": -39.02915557098389, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.784411668777466, "step": 13000}
{"episode_reward": 306.1521049592461, "episode": 14.0, "batch_reward": 0.28895984384417533, "critic_loss": 1.0380167221426964, "actor_loss": -39.57507006072998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.790355682373047, "step": 14000}
{"episode_reward": 516.3440668929851, "episode": 15.0, "batch_reward": 0.30249384181201455, "critic_loss": 1.2264380100369454, "actor_loss": -40.654084877014164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.85294532775879, "step": 15000}
{"episode_reward": 314.7522854198959, "episode": 16.0, "batch_reward": 0.2994134239703417, "critic_loss": 1.6404183753728867, "actor_loss": -40.18360782623291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.857458114624023, "step": 16000}
{"episode_reward": 429.1723490262443, "episode": 17.0, "batch_reward": 0.3054661352187395, "critic_loss": 1.9543051501512527, "actor_loss": -40.485501663208005, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.82248091697693, "step": 17000}
{"episode_reward": 154.34303503263027, "episode": 18.0, "batch_reward": 0.29772350552678106, "critic_loss": 3.151871419906616, "actor_loss": -40.36138409423828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.80569076538086, "step": 18000}
{"episode_reward": 171.46820489145685, "episode": 19.0, "batch_reward": 0.2861455154120922, "critic_loss": 5.659549277544022, "actor_loss": -39.6189260635376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.80238437652588, "step": 19000}
{"episode_reward": 59.583602655586304, "episode": 20.0, "batch_reward": 0.27260269002616405, "critic_loss": 7.883501363754273, "actor_loss": -38.91645425033569, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.806323528289795, "step": 20000}
{"episode_reward": 39.389136807505714, "episode": 21.0, "batch_reward": 0.26141492269933225, "critic_loss": 7.588289977788925, "actor_loss": -39.05899448394776, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.08722686767578, "step": 21000}
{"episode_reward": 26.349317061633165, "episode": 22.0, "batch_reward": 0.2518791225105524, "critic_loss": 6.321702009916305, "actor_loss": -38.71301390457153, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.843559980392456, "step": 22000}
{"episode_reward": 85.84109268453543, "episode": 23.0, "batch_reward": 0.24315617187321187, "critic_loss": 5.204778687238694, "actor_loss": -39.05216087341309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.82407259941101, "step": 23000}
{"episode_reward": 23.503124427107604, "episode": 24.0, "batch_reward": 0.23530805407464503, "critic_loss": 4.457887037754059, "actor_loss": -39.55962320709229, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.841838598251343, "step": 24000}
{"episode_reward": 140.41905020629125, "episode": 25.0, "batch_reward": 0.2335497517734766, "critic_loss": 4.379918604373932, "actor_loss": -39.16179471588135, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.804705381393433, "step": 25000}
{"episode_reward": 175.48471385302688, "episode": 26.0, "batch_reward": 0.23011200211942195, "critic_loss": 4.655974252700806, "actor_loss": -39.21807932662964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.803411722183228, "step": 26000}
{"episode_reward": 94.11528012893609, "episode": 27.0, "batch_reward": 0.22649910444021226, "critic_loss": 4.82206307387352, "actor_loss": -38.52923021697998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.101672649383545, "step": 27000}
{"episode_reward": 217.60614403151362, "episode": 28.0, "batch_reward": 0.22743412850797176, "critic_loss": 4.60951593708992, "actor_loss": -38.50517837524414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.81246066093445, "step": 28000}
{"episode_reward": 228.7262334946993, "episode": 29.0, "batch_reward": 0.23123575846850872, "critic_loss": 3.8095711698532106, "actor_loss": -38.973592502593995, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.809294939041138, "step": 29000}
{"episode_reward": 480.63320014840303, "episode": 30.0, "batch_reward": 0.24001098205149174, "critic_loss": 2.9436525341272355, "actor_loss": -40.23643291091919, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.808297157287598, "step": 30000}
{"episode_reward": 551.0868980075917, "episode": 31.0, "batch_reward": 0.24840314926207066, "critic_loss": 2.2519105817079543, "actor_loss": -40.263509719848635, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.02000617980957, "step": 31000}
{"episode_reward": 468.4675489750354, "episode": 32.0, "batch_reward": 0.2560058641880751, "critic_loss": 2.036924584209919, "actor_loss": -40.86882774734497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.807570457458496, "step": 32000}
{"episode_reward": 395.4749015579941, "episode": 33.0, "batch_reward": 0.2610860110074282, "critic_loss": 2.131498428940773, "actor_loss": -40.86377173614502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.809354543685913, "step": 33000}
{"episode_reward": 549.2686906315809, "episode": 34.0, "batch_reward": 0.2678835068196058, "critic_loss": 2.0863800750970842, "actor_loss": -41.27311371231079, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.76831030845642, "step": 34000}
{"episode_reward": 409.7220309486312, "episode": 35.0, "batch_reward": 0.2734857069849968, "critic_loss": 1.7620032063126565, "actor_loss": -42.37266497421265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.79592204093933, "step": 35000}
{"episode_reward": 540.8767904656693, "episode": 36.0, "batch_reward": 0.28081214427948, "critic_loss": 1.5982501084804535, "actor_loss": -41.78854287338257, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.787672996520996, "step": 36000}
{"episode_reward": 502.1240762716649, "episode": 37.0, "batch_reward": 0.28802220183610916, "critic_loss": 1.3830587747097016, "actor_loss": -42.57317423248291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.808556079864502, "step": 37000}
{"episode_reward": 514.9045101347441, "episode": 38.0, "batch_reward": 0.29365720497071746, "critic_loss": 1.282852388381958, "actor_loss": -42.95882328414917, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.78477168083191, "step": 38000}
{"episode_reward": 588.2398048841945, "episode": 39.0, "batch_reward": 0.30068947955965997, "critic_loss": 1.2705028386116028, "actor_loss": -42.49704172515869, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.77826738357544, "step": 39000}
{"episode_reward": 569.4854071766547, "episode": 40.0, "batch_reward": 0.30897640374302865, "critic_loss": 1.2011338136792182, "actor_loss": -42.626327270507815, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.777865171432495, "step": 40000}
{"episode_reward": 556.2556295524655, "episode": 41.0, "batch_reward": 0.3139172021597624, "critic_loss": 1.1275603311657905, "actor_loss": -43.04551128387451, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.0622079372406, "step": 41000}
{"episode_reward": 563.1121518809475, "episode": 42.0, "batch_reward": 0.3213427305817604, "critic_loss": 1.0756165774166584, "actor_loss": -43.14542133331299, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.763143301010132, "step": 42000}
{"episode_reward": 592.8307747891619, "episode": 43.0, "batch_reward": 0.32545652747154236, "critic_loss": 0.9840363602936267, "actor_loss": -43.18631811523438, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.77913761138916, "step": 43000}
{"episode_reward": 528.9483419968363, "episode": 44.0, "batch_reward": 0.3316276393830776, "critic_loss": 0.9365627149939537, "actor_loss": -43.83222324371338, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.80555295944214, "step": 44000}
{"episode_reward": 589.0919273591742, "episode": 45.0, "batch_reward": 0.3384534193277359, "critic_loss": 0.9377809959948062, "actor_loss": -44.01245499420166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.783089637756348, "step": 45000}
{"episode_reward": 585.1212907032061, "episode": 46.0, "batch_reward": 0.3417844969034195, "critic_loss": 0.9006542602777481, "actor_loss": -43.931798561096194, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.79381036758423, "step": 46000}
{"episode_reward": 567.4885292744901, "episode": 47.0, "batch_reward": 0.34774088743329046, "critic_loss": 0.8436034571230412, "actor_loss": -44.21171022033691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.819278240203857, "step": 47000}
{"episode_reward": 581.3591911842062, "episode": 48.0, "batch_reward": 0.353070283561945, "critic_loss": 0.8603617064058781, "actor_loss": -44.48089119720459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.84002947807312, "step": 48000}
{"episode_reward": 565.5240418834621, "episode": 49.0, "batch_reward": 0.35769707822799685, "critic_loss": 0.8161670203804969, "actor_loss": -44.57425713348389, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.830450773239136, "step": 49000}
{"episode_reward": 577.1454126244653, "episode": 50.0, "batch_reward": 0.360908282071352, "critic_loss": 0.7727167243659496, "actor_loss": -44.61634973144531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.824131727218628, "step": 50000}
{"episode_reward": 592.2364088144046, "episode": 51.0, "batch_reward": 0.36452701458334924, "critic_loss": 0.7199228431582451, "actor_loss": -44.599982078552245, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.09638953208923, "step": 51000}
{"episode_reward": 562.2603723739535, "episode": 52.0, "batch_reward": 0.3695654271245003, "critic_loss": 0.7633617148697376, "actor_loss": -45.000983070373536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.793660402297974, "step": 52000}
{"episode_reward": 574.4250263739302, "episode": 53.0, "batch_reward": 0.3733094053566456, "critic_loss": 0.7229902534782886, "actor_loss": -45.112279518127444, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.85886001586914, "step": 53000}
{"episode_reward": 572.8372782474942, "episode": 54.0, "batch_reward": 0.3772835386693478, "critic_loss": 0.7084646872580052, "actor_loss": -45.05054676055908, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.780794858932495, "step": 54000}
{"episode_reward": 601.5993141473131, "episode": 55.0, "batch_reward": 0.3810615075826645, "critic_loss": 0.6962955094575882, "actor_loss": -45.515230430603026, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.77750253677368, "step": 55000}
{"episode_reward": 603.4510191150478, "episode": 56.0, "batch_reward": 0.38456443560123443, "critic_loss": 0.717195737928152, "actor_loss": -45.55974432373047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.770566701889038, "step": 56000}
{"episode_reward": 577.7745155369349, "episode": 57.0, "batch_reward": 0.3886303684413433, "critic_loss": 0.7242314822673798, "actor_loss": -45.73317704772949, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.818530797958374, "step": 57000}
{"episode_reward": 568.4846804265954, "episode": 58.0, "batch_reward": 0.39189423167705534, "critic_loss": 0.7552408190667629, "actor_loss": -46.01177223205566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.782440900802612, "step": 58000}
{"episode_reward": 571.6730480072425, "episode": 59.0, "batch_reward": 0.3955000925064087, "critic_loss": 0.7926701102852821, "actor_loss": -46.07275847625733, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.79199242591858, "step": 59000}
{"episode_reward": 574.9075124956182, "episode": 60.0, "batch_reward": 0.3984619830846787, "critic_loss": 0.7944456741809846, "actor_loss": -46.239111541748045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.78005886077881, "step": 60000}
{"episode_reward": 562.5192272347107, "episode": 61.0, "batch_reward": 0.40004824474453926, "critic_loss": 0.8397008323073387, "actor_loss": -46.33326116943359, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.092907190322876, "step": 61000}
{"episode_reward": 607.9468807748809, "episode": 62.0, "batch_reward": 0.4036267180144787, "critic_loss": 0.8559238957762718, "actor_loss": -46.486455390930175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.82376503944397, "step": 62000}
{"episode_reward": 604.9545898256921, "episode": 63.0, "batch_reward": 0.40770862126350405, "critic_loss": 0.878846750497818, "actor_loss": -46.89517359161377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.822479009628296, "step": 63000}
{"episode_reward": 600.9052143365893, "episode": 64.0, "batch_reward": 0.410170398414135, "critic_loss": 0.8701752063333988, "actor_loss": -46.967207160949705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.81494951248169, "step": 64000}
{"episode_reward": 653.01509266, "episode": 65.0, "batch_reward": 0.41444668599963186, "critic_loss": 0.8603220841884613, "actor_loss": -47.20101531982422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.809632301330566, "step": 65000}
{"episode_reward": 634.9303667402295, "episode": 66.0, "batch_reward": 0.4181150386035442, "critic_loss": 0.837274374216795, "actor_loss": -47.53667258453369, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.76726198196411, "step": 66000}
{"episode_reward": 586.0742420165402, "episode": 67.0, "batch_reward": 0.42043918213248255, "critic_loss": 0.7960573434233665, "actor_loss": -47.49469053649902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.82740092277527, "step": 67000}
{"episode_reward": 616.6948019299983, "episode": 68.0, "batch_reward": 0.422761189609766, "critic_loss": 0.7761972462236881, "actor_loss": -47.73898976898193, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.813063383102417, "step": 68000}
{"episode_reward": 536.6108035209895, "episode": 69.0, "batch_reward": 0.42592976000905036, "critic_loss": 0.7830185713469983, "actor_loss": -47.81988375091553, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.822147369384766, "step": 69000}
{"episode_reward": 600.9683949664087, "episode": 70.0, "batch_reward": 0.4265640566945076, "critic_loss": 0.7514323961138726, "actor_loss": -47.762778388977054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.768080234527588, "step": 70000}
{"episode_reward": 554.2097722256532, "episode": 71.0, "batch_reward": 0.4296649019420147, "critic_loss": 0.7236159798800945, "actor_loss": -48.045616249084475, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.07620286941528, "step": 71000}
{"episode_reward": 631.1574808550595, "episode": 72.0, "batch_reward": 0.4312683049738407, "critic_loss": 0.6999855321347713, "actor_loss": -48.06145494842529, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.8017840385437, "step": 72000}
{"episode_reward": 565.2141883750342, "episode": 73.0, "batch_reward": 0.4338603344857693, "critic_loss": 0.6971990052759648, "actor_loss": -48.39793842315674, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.781270027160645, "step": 73000}
{"episode_reward": 608.1139352162951, "episode": 74.0, "batch_reward": 0.4361390646994114, "critic_loss": 0.6570788138210774, "actor_loss": -48.51150016784668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.825289726257324, "step": 74000}
{"episode_reward": 578.7993210288712, "episode": 75.0, "batch_reward": 0.43894423708319663, "critic_loss": 0.6554138028025627, "actor_loss": -48.848716979980466, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.813805103302002, "step": 75000}
{"episode_reward": 586.9998021678864, "episode": 76.0, "batch_reward": 0.4410917336046696, "critic_loss": 0.6900761177539826, "actor_loss": -48.92067052459717, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.83434009552002, "step": 76000}
{"episode_reward": 573.8715298149145, "episode": 77.0, "batch_reward": 0.44249924293160436, "critic_loss": 0.6961177031695843, "actor_loss": -49.13043813323974, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.8527410030365, "step": 77000}
{"episode_reward": 613.2478132738394, "episode": 78.0, "batch_reward": 0.4452465589046478, "critic_loss": 0.6743352538347245, "actor_loss": -49.29604558563232, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.820821523666382, "step": 78000}
{"episode_reward": 587.651555232876, "episode": 79.0, "batch_reward": 0.44658878195285795, "critic_loss": 0.6705330083966256, "actor_loss": -49.330423957824706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.79379439353943, "step": 79000}
{"episode_reward": 611.1501894658827, "episode": 80.0, "batch_reward": 0.4463454240262508, "critic_loss": 0.653532655864954, "actor_loss": -49.41333576202393, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.811527013778687, "step": 80000}
{"episode_reward": 616.0745159267758, "episode": 81.0, "batch_reward": 0.4501569536328316, "critic_loss": 0.6795365509986877, "actor_loss": -49.692650619506836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.09618377685547, "step": 81000}
{"episode_reward": 569.6711873476995, "episode": 82.0, "batch_reward": 0.452488862991333, "critic_loss": 0.7319937651753425, "actor_loss": -49.9269545211792, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.81338882446289, "step": 82000}
{"episode_reward": 601.9899896578986, "episode": 83.0, "batch_reward": 0.4538000328540802, "critic_loss": 0.8010389214456082, "actor_loss": -49.96291660308838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.812421083450317, "step": 83000}
{"episode_reward": 604.6502758337672, "episode": 84.0, "batch_reward": 0.4545076836049557, "critic_loss": 0.8842458717525006, "actor_loss": -50.159099609375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.819488048553467, "step": 84000}
{"episode_reward": 593.9528736032573, "episode": 85.0, "batch_reward": 0.4572874920070171, "critic_loss": 0.9152842681705952, "actor_loss": -50.5631021194458, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.828572511672974, "step": 85000}
{"episode_reward": 612.6269587047218, "episode": 86.0, "batch_reward": 0.4576176066994667, "critic_loss": 0.8962895728945732, "actor_loss": -50.546304901123044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.827489376068115, "step": 86000}
{"episode_reward": 638.1562132166101, "episode": 87.0, "batch_reward": 0.46043419405817987, "critic_loss": 0.916433463037014, "actor_loss": -50.761971504211424, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.82074475288391, "step": 87000}
{"episode_reward": 585.3954693263804, "episode": 88.0, "batch_reward": 0.4621989817023277, "critic_loss": 0.9385586639046669, "actor_loss": -51.0086894607544, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.822793006896973, "step": 88000}
{"episode_reward": 612.1932840202913, "episode": 89.0, "batch_reward": 0.4641604578197002, "critic_loss": 0.9708497568070888, "actor_loss": -51.22786136627197, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.83833599090576, "step": 89000}
{"episode_reward": 602.6684412728769, "episode": 90.0, "batch_reward": 0.4656934731900692, "critic_loss": 0.9061584825217723, "actor_loss": -51.36017701721192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.807470560073853, "step": 90000}
{"episode_reward": 605.719701721893, "episode": 91.0, "batch_reward": 0.46604247024655343, "critic_loss": 0.8853322559893131, "actor_loss": -51.355122421264646, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.135459423065186, "step": 91000}
{"episode_reward": 607.6127500796421, "episode": 92.0, "batch_reward": 0.46889176592230797, "critic_loss": 0.9018217504620553, "actor_loss": -51.51093872833252, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.869059801101685, "step": 92000}
{"episode_reward": 638.7277011981624, "episode": 93.0, "batch_reward": 0.4704976677596569, "critic_loss": 0.9092786321640015, "actor_loss": -51.651481925964355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.837355852127075, "step": 93000}
{"episode_reward": 596.3753924241803, "episode": 94.0, "batch_reward": 0.47327933299541475, "critic_loss": 0.9112880120575428, "actor_loss": -51.90438562011719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.831320762634277, "step": 94000}
{"episode_reward": 612.0028533731341, "episode": 95.0, "batch_reward": 0.47182499000430106, "critic_loss": 0.9516169980168343, "actor_loss": -51.99511159515381, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.846058130264282, "step": 95000}
{"episode_reward": 609.7541448795608, "episode": 96.0, "batch_reward": 0.4742874477803707, "critic_loss": 0.9179030419588089, "actor_loss": -52.053384399414064, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.859097719192505, "step": 96000}
{"episode_reward": 603.0109336010137, "episode": 97.0, "batch_reward": 0.47545829179883004, "critic_loss": 0.9465662500858307, "actor_loss": -52.283138130187986, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.848281383514404, "step": 97000}
{"episode_reward": 627.26308504193, "episode": 98.0, "batch_reward": 0.47830233547091483, "critic_loss": 0.9472973598539829, "actor_loss": -52.692915168762205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.835151433944702, "step": 98000}
{"episode_reward": 579.7142086084727, "episode": 99.0, "batch_reward": 0.47789440521597865, "critic_loss": 0.9890635815858841, "actor_loss": -52.47632181549072, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.835238695144653, "step": 99000}
{"episode_reward": 627.0621571798494, "episode": 100.0, "batch_reward": 0.4802470394074917, "critic_loss": 0.9699810788929463, "actor_loss": -52.830561378479004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.818230867385864, "step": 100000}
{"episode_reward": 624.8636423455403, "episode": 101.0, "batch_reward": 0.4816577507257462, "critic_loss": 0.9557000311017037, "actor_loss": -52.85645458984375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.17084288597107, "step": 101000}
{"episode_reward": 580.6805715456088, "episode": 102.0, "batch_reward": 0.4829292271733284, "critic_loss": 0.9655383877456188, "actor_loss": -52.97465627288818, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.840590953826904, "step": 102000}
{"episode_reward": 623.7386536100468, "episode": 103.0, "batch_reward": 0.4836550731956959, "critic_loss": 1.0233594793379306, "actor_loss": -53.07133822631836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.870543718338013, "step": 103000}
{"episode_reward": 595.0022868096034, "episode": 104.0, "batch_reward": 0.4858630268871784, "critic_loss": 1.024704274147749, "actor_loss": -53.274667594909666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.838213205337524, "step": 104000}
{"episode_reward": 606.4355859591633, "episode": 105.0, "batch_reward": 0.4855169579386711, "critic_loss": 0.9884090647697449, "actor_loss": -53.184184997558596, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.859113931655884, "step": 105000}
{"episode_reward": 623.3437385031159, "episode": 106.0, "batch_reward": 0.48760318651795387, "critic_loss": 1.0030932369828225, "actor_loss": -53.38665637969971, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.842029809951782, "step": 106000}
{"episode_reward": 617.6626145472288, "episode": 107.0, "batch_reward": 0.4890846581459045, "critic_loss": 1.040423027575016, "actor_loss": -53.50808148956299, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.852981328964233, "step": 107000}
{"episode_reward": 626.4111691369791, "episode": 108.0, "batch_reward": 0.489151416182518, "critic_loss": 1.073239297270775, "actor_loss": -53.60872356414795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.84441304206848, "step": 108000}
{"episode_reward": 653.3531256347484, "episode": 109.0, "batch_reward": 0.49138964238762856, "critic_loss": 1.0611068530678749, "actor_loss": -53.77181204986572, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.820667028427124, "step": 109000}
{"episode_reward": 589.0711274984486, "episode": 110.0, "batch_reward": 0.49102748796343804, "critic_loss": 1.1059145765006542, "actor_loss": -53.80359872436524, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.81755256652832, "step": 110000}
{"episode_reward": 527.7155532233579, "episode": 111.0, "batch_reward": 0.4922916673719883, "critic_loss": 1.0676564939618112, "actor_loss": -53.684558288574216, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.08240008354187, "step": 111000}
{"episode_reward": 648.8455548855495, "episode": 112.0, "batch_reward": 0.49351781180500987, "critic_loss": 1.1535600765645504, "actor_loss": -54.054907722473146, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.81958031654358, "step": 112000}
{"episode_reward": 603.1041052078183, "episode": 113.0, "batch_reward": 0.49563673374056816, "critic_loss": 1.2162575098872184, "actor_loss": -54.07251058959961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.84096121788025, "step": 113000}
{"episode_reward": 593.4472660463492, "episode": 114.0, "batch_reward": 0.4951367535591126, "critic_loss": 1.2465752225220204, "actor_loss": -54.16314260864258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.867201805114746, "step": 114000}
{"episode_reward": 615.9513721035283, "episode": 115.0, "batch_reward": 0.4962600479424, "critic_loss": 1.2798028352260589, "actor_loss": -54.28236796569824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15560030937195, "step": 115000}
{"episode_reward": 583.0964836527191, "episode": 116.0, "batch_reward": 0.4980830983221531, "critic_loss": 1.2974056722521783, "actor_loss": -54.34511083984375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.12627410888672, "step": 116000}
{"episode_reward": 621.0881070977019, "episode": 117.0, "batch_reward": 0.49864038756489754, "critic_loss": 1.2928913609087467, "actor_loss": -54.552134979248045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.81020712852478, "step": 117000}
{"episode_reward": 605.918876179245, "episode": 118.0, "batch_reward": 0.498996762663126, "critic_loss": 1.2493151313960553, "actor_loss": -54.37793930053711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.77159833908081, "step": 118000}
{"episode_reward": 501.2562532792941, "episode": 119.0, "batch_reward": 0.4986334582269192, "critic_loss": 1.1972190634012223, "actor_loss": -54.33543254089356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.77141261100769, "step": 119000}
{"episode_reward": 565.139414280438, "episode": 120.0, "batch_reward": 0.49947259160876273, "critic_loss": 1.2831816642582416, "actor_loss": -54.435938499450685, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.83223843574524, "step": 120000}
{"episode_reward": 536.9378374881123, "episode": 121.0, "batch_reward": 0.5010956282317638, "critic_loss": 1.0413901542425155, "actor_loss": -54.581527816772464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.14115262031555, "step": 121000}
{"episode_reward": 588.2450140121762, "episode": 122.0, "batch_reward": 0.5027427401244641, "critic_loss": 1.04266714656353, "actor_loss": -54.59200816345215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.798238039016724, "step": 122000}
{"episode_reward": 622.4707389901697, "episode": 123.0, "batch_reward": 0.5023964877128602, "critic_loss": 0.9905378012359143, "actor_loss": -54.6742301864624, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.797616958618164, "step": 123000}
{"episode_reward": 571.7794718405127, "episode": 124.0, "batch_reward": 0.5025666092038155, "critic_loss": 0.978642844736576, "actor_loss": -54.51324810028076, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.83060121536255, "step": 124000}
{"episode_reward": 631.3600851474453, "episode": 125.0, "batch_reward": 0.5038686650693417, "critic_loss": 0.8927603152394294, "actor_loss": -54.703679077148436, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.840067863464355, "step": 125000}
{"episode_reward": 555.8043121667798, "episode": 126.0, "batch_reward": 0.5048542195558547, "critic_loss": 0.8936180137693882, "actor_loss": -54.79463613128662, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.833963632583618, "step": 126000}
{"episode_reward": 614.3935000791539, "episode": 127.0, "batch_reward": 0.5053169651329518, "critic_loss": 0.885693516433239, "actor_loss": -54.67220455169678, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.853095054626465, "step": 127000}
{"episode_reward": 631.8553044078678, "episode": 128.0, "batch_reward": 0.5058546077013015, "critic_loss": 0.8956837016046048, "actor_loss": -54.68070027160645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.854439973831177, "step": 128000}
{"episode_reward": 627.1958479394206, "episode": 129.0, "batch_reward": 0.5069913811385631, "critic_loss": 0.8800783530175685, "actor_loss": -54.80472553253174, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.812435150146484, "step": 129000}
{"episode_reward": 598.100576293344, "episode": 130.0, "batch_reward": 0.5073346512317658, "critic_loss": 0.8702452790737152, "actor_loss": -54.79659115600586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.77065110206604, "step": 130000}
{"episode_reward": 613.7647208229367, "episode": 131.0, "batch_reward": 0.5080671597719193, "critic_loss": 0.8732853606939316, "actor_loss": -54.718927154541014, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.15355682373047, "step": 131000}
{"episode_reward": 604.1540930767896, "episode": 132.0, "batch_reward": 0.5089401021301746, "critic_loss": 0.8129363591074944, "actor_loss": -54.91510031890869, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.827069759368896, "step": 132000}
{"episode_reward": 636.6772660447685, "episode": 133.0, "batch_reward": 0.5090796553492546, "critic_loss": 0.7889248126149178, "actor_loss": -55.04886391448974, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.816121101379395, "step": 133000}
{"episode_reward": 596.1258219144471, "episode": 134.0, "batch_reward": 0.5099858084321022, "critic_loss": 0.7591670415997506, "actor_loss": -55.15250996398926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.854121685028076, "step": 134000}
{"episode_reward": 618.1910643328619, "episode": 135.0, "batch_reward": 0.5106571716368198, "critic_loss": 0.7653779558539391, "actor_loss": -55.10464793395996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.839624643325806, "step": 135000}
{"episode_reward": 592.3162056656645, "episode": 136.0, "batch_reward": 0.5119004331231117, "critic_loss": 0.766980468839407, "actor_loss": -55.23805360412597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.822412729263306, "step": 136000}
{"episode_reward": 597.8411261041404, "episode": 137.0, "batch_reward": 0.5126283639967442, "critic_loss": 0.6923847922384739, "actor_loss": -55.29797170257569, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.82175064086914, "step": 137000}
{"episode_reward": 578.3463948154107, "episode": 138.0, "batch_reward": 0.5141354775428773, "critic_loss": 0.7142447910010815, "actor_loss": -55.213039756774904, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.846683263778687, "step": 138000}
{"episode_reward": 586.9867121609068, "episode": 139.0, "batch_reward": 0.513775269895792, "critic_loss": 0.6979066714942456, "actor_loss": -55.255867179870606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.84922480583191, "step": 139000}
{"episode_reward": 630.88851888458, "episode": 140.0, "batch_reward": 0.5146182879805565, "critic_loss": 0.7041154936254025, "actor_loss": -55.28488385009766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.833476066589355, "step": 140000}
{"episode_reward": 597.8126355867295, "episode": 141.0, "batch_reward": 0.5148991585373879, "critic_loss": 0.652656546741724, "actor_loss": -55.52929778289795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.0935423374176, "step": 141000}
{"episode_reward": 605.156430743137, "episode": 142.0, "batch_reward": 0.5141810904145241, "critic_loss": 0.6579446351230145, "actor_loss": -55.45213981628418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.819196462631226, "step": 142000}
{"episode_reward": 606.545998525201, "episode": 143.0, "batch_reward": 0.5163543114960194, "critic_loss": 0.6753627799749374, "actor_loss": -55.6833625869751, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.850132703781128, "step": 143000}
{"episode_reward": 600.2623013738104, "episode": 144.0, "batch_reward": 0.5171998061835766, "critic_loss": 0.6422986146509647, "actor_loss": -55.713908920288084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.84214186668396, "step": 144000}
{"episode_reward": 610.6455932368249, "episode": 145.0, "batch_reward": 0.5176728335022927, "critic_loss": 0.6597330860495567, "actor_loss": -55.868376083374024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.84171962738037, "step": 145000}
{"episode_reward": 574.429476178823, "episode": 146.0, "batch_reward": 0.5179516145288944, "critic_loss": 0.6705692492574453, "actor_loss": -55.66500038909912, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.859299898147583, "step": 146000}
{"episode_reward": 623.6973352753422, "episode": 147.0, "batch_reward": 0.5195428999960423, "critic_loss": 0.6353820899426937, "actor_loss": -55.864549659729, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.855945348739624, "step": 147000}
{"episode_reward": 618.9627346769911, "episode": 148.0, "batch_reward": 0.5205364214479923, "critic_loss": 0.6277740148305893, "actor_loss": -56.07110460662842, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.859910249710083, "step": 148000}
{"episode_reward": 618.3122419382867, "episode": 149.0, "batch_reward": 0.5193672838509082, "critic_loss": 0.6488482729792595, "actor_loss": -55.96013584136963, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.862436056137085, "step": 149000}
{"episode_reward": 613.1550935594947, "episode": 150.0, "batch_reward": 0.5217713171243668, "critic_loss": 0.6103663570582867, "actor_loss": -56.11427377319336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
