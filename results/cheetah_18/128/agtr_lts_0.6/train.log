{"episode_reward": 0.0, "episode": 1.0, "duration": 17.10582971572876, "step": 1000}
{"episode_reward": 4.20996189079657, "episode": 2.0, "duration": 1.4707646369934082, "step": 2000}
{"episode_reward": 252.2457487418515, "episode": 3.0, "batch_reward": 0.1471287983557549, "critic_loss": 0.25943645484628736, "actor_loss": -37.52810400893756, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.51749515533447, "step": 3000}
{"episode_reward": 429.3808225231501, "episode": 4.0, "batch_reward": 0.2564208182543516, "critic_loss": 0.4146773208230734, "actor_loss": -44.375725929260255, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.846245288848877, "step": 4000}
{"episode_reward": 352.58279947212895, "episode": 5.0, "batch_reward": 0.2788465036600828, "critic_loss": 0.5796374742686748, "actor_loss": -44.3162336730957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.846851587295532, "step": 5000}
{"episode_reward": 417.4844415963108, "episode": 6.0, "batch_reward": 0.30784164810180664, "critic_loss": 0.6490290729403496, "actor_loss": -46.01511776733398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.849015951156616, "step": 6000}
{"episode_reward": 485.9236082795731, "episode": 7.0, "batch_reward": 0.3369074150621891, "critic_loss": 0.7205892607569695, "actor_loss": -47.455775978088376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.849773406982422, "step": 7000}
{"episode_reward": 519.5064926164831, "episode": 8.0, "batch_reward": 0.3614760461449623, "critic_loss": 0.709628979742527, "actor_loss": -48.881098052978516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.84339475631714, "step": 8000}
{"episode_reward": 525.1084552293478, "episode": 9.0, "batch_reward": 0.3742974959015846, "critic_loss": 0.8744502430558204, "actor_loss": -49.77171203613281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.84430694580078, "step": 9000}
{"episode_reward": 465.9756663532409, "episode": 10.0, "batch_reward": 0.38048303800821304, "critic_loss": 1.2873212444782256, "actor_loss": -50.648989479064944, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.85335350036621, "step": 10000}
{"episode_reward": 440.67522011118433, "episode": 11.0, "batch_reward": 0.38657789608836174, "critic_loss": 1.2077022644281388, "actor_loss": -51.48003658294678, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.99287271499634, "step": 11000}
{"episode_reward": 359.6526291590107, "episode": 12.0, "batch_reward": 0.39059821373224257, "critic_loss": 1.0074584902524948, "actor_loss": -50.82837889099121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.834810972213745, "step": 12000}
{"episode_reward": 528.2454985396693, "episode": 13.0, "batch_reward": 0.4000565122961998, "critic_loss": 0.9522638352811337, "actor_loss": -51.11278103637695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.83804726600647, "step": 13000}
{"episode_reward": 435.2960951441202, "episode": 14.0, "batch_reward": 0.3871820303201675, "critic_loss": 0.9862397252321243, "actor_loss": -50.88418658447266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.852401971817017, "step": 14000}
{"episode_reward": 4.9947884782301974, "episode": 15.0, "batch_reward": 0.36039976423978803, "critic_loss": 0.8842597523629665, "actor_loss": -50.45881157684326, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.843305110931396, "step": 15000}
{"episode_reward": 2.0727710194555287, "episode": 16.0, "batch_reward": 0.33631328102946284, "critic_loss": 1.110677627801895, "actor_loss": -49.51294805908203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.839670419692993, "step": 16000}
{"episode_reward": 3.247057922812063, "episode": 17.0, "batch_reward": 0.32184959241747857, "critic_loss": 1.5276552211642265, "actor_loss": -48.84468862915039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.845970392227173, "step": 17000}
{"episode_reward": 177.83829561649168, "episode": 18.0, "batch_reward": 0.30926843494176864, "critic_loss": 1.787822325050831, "actor_loss": -48.27222625732422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.84655737876892, "step": 18000}
{"episode_reward": 5.098157730377995, "episode": 19.0, "batch_reward": 0.29330353617668153, "critic_loss": 2.913257780611515, "actor_loss": -47.754869735717776, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.843255281448364, "step": 19000}
{"episode_reward": 4.182950961053027, "episode": 20.0, "batch_reward": 0.2782717140316963, "critic_loss": 5.023926697969436, "actor_loss": -47.28887552642822, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.846319675445557, "step": 20000}
{"episode_reward": 6.299989015229881, "episode": 21.0, "batch_reward": 0.2634676611721516, "critic_loss": 6.675373955726624, "actor_loss": -47.95530629730224, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.07943868637085, "step": 21000}
{"episode_reward": 4.63122553143009, "episode": 22.0, "batch_reward": 0.25317157423496245, "critic_loss": 7.346912506341934, "actor_loss": -47.81510406494141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.85940957069397, "step": 22000}
{"episode_reward": 35.35139619988027, "episode": 23.0, "batch_reward": 0.24284332199394704, "critic_loss": 7.042334401607514, "actor_loss": -49.389155784606935, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.861377239227295, "step": 23000}
{"episode_reward": 16.73848848289215, "episode": 24.0, "batch_reward": 0.23412677998840808, "critic_loss": 5.530148939490318, "actor_loss": -51.86964304351807, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.86688232421875, "step": 24000}
{"episode_reward": 14.76414776752866, "episode": 25.0, "batch_reward": 0.22493181283771993, "critic_loss": 4.1736730008125305, "actor_loss": -51.4214893951416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.854847192764282, "step": 25000}
{"episode_reward": 44.76217734436362, "episode": 26.0, "batch_reward": 0.21723168087005615, "critic_loss": 3.3362066173553466, "actor_loss": -52.037823783874515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.843997478485107, "step": 26000}
{"episode_reward": 51.228041662372625, "episode": 27.0, "batch_reward": 0.21305655609071256, "critic_loss": 2.9135028420686724, "actor_loss": -51.997823417663575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.832502841949463, "step": 27000}
{"episode_reward": 109.25159267042993, "episode": 28.0, "batch_reward": 0.20980008988082408, "critic_loss": 3.177121654868126, "actor_loss": -51.42885679626465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.830094814300537, "step": 28000}
{"episode_reward": 89.07818129196914, "episode": 29.0, "batch_reward": 0.2053646061271429, "critic_loss": 3.357471027255058, "actor_loss": -51.31819319152832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.83855628967285, "step": 29000}
{"episode_reward": 39.28615517532045, "episode": 30.0, "batch_reward": 0.20000896272063257, "critic_loss": 3.6991078612804413, "actor_loss": -52.174181175231936, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.836722373962402, "step": 30000}
{"episode_reward": 117.82597540921626, "episode": 31.0, "batch_reward": 0.202734375, "critic_loss": 3.066163364291191, "actor_loss": -51.56582188415528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.957823514938354, "step": 31000}
{"episode_reward": 489.33202019965654, "episode": 32.0, "batch_reward": 0.21228626863658429, "critic_loss": 2.5046861362457276, "actor_loss": -53.147212524414066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.834354877471924, "step": 32000}
{"episode_reward": 465.09411695922137, "episode": 33.0, "batch_reward": 0.21859068393707276, "critic_loss": 2.3711841468811037, "actor_loss": -52.66446340942383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.836228132247925, "step": 33000}
{"episode_reward": 451.05622460197355, "episode": 34.0, "batch_reward": 0.22387370839715004, "critic_loss": 2.303838631272316, "actor_loss": -52.70828628540039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.844184398651123, "step": 34000}
{"episode_reward": 426.6566942219733, "episode": 35.0, "batch_reward": 0.23310072967410086, "critic_loss": 2.176182020008564, "actor_loss": -55.20557579040528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.84283447265625, "step": 35000}
{"episode_reward": 504.37457942493256, "episode": 36.0, "batch_reward": 0.24018762888014317, "critic_loss": 2.0559697147011757, "actor_loss": -52.452189239501955, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.848110675811768, "step": 36000}
{"episode_reward": 520.8670748989614, "episode": 37.0, "batch_reward": 0.24856167122721673, "critic_loss": 1.7318709765076636, "actor_loss": -53.58087422180176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.851655960083008, "step": 37000}
{"episode_reward": 562.6341051518048, "episode": 38.0, "batch_reward": 0.25592618449032306, "critic_loss": 1.3860792331695557, "actor_loss": -53.93304752349854, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.849252700805664, "step": 38000}
{"episode_reward": 500.2173470822537, "episode": 39.0, "batch_reward": 0.2620679814219475, "critic_loss": 1.2163234038949013, "actor_loss": -52.019315505981446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.834750175476074, "step": 39000}
{"episode_reward": 518.2341148025704, "episode": 40.0, "batch_reward": 0.2693949422091246, "critic_loss": 1.1899853042960167, "actor_loss": -50.98368318176269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.855877161026, "step": 40000}
{"episode_reward": 505.83215899363876, "episode": 41.0, "batch_reward": 0.27449288360774515, "critic_loss": 1.191773688197136, "actor_loss": -51.44181603240967, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.98755359649658, "step": 41000}
{"episode_reward": 514.1604792131699, "episode": 42.0, "batch_reward": 0.28103326362371445, "critic_loss": 1.1074922703504562, "actor_loss": -51.72749259185791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.841522216796875, "step": 42000}
{"episode_reward": 486.90884564131886, "episode": 43.0, "batch_reward": 0.28549084885418413, "critic_loss": 0.9975423702001571, "actor_loss": -51.200446067810056, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.832529067993164, "step": 43000}
{"episode_reward": 527.3529750014264, "episode": 44.0, "batch_reward": 0.2921654500961304, "critic_loss": 0.819362942904234, "actor_loss": -52.37498623657227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.841415405273438, "step": 44000}
{"episode_reward": 545.2872645764248, "episode": 45.0, "batch_reward": 0.29753003938496114, "critic_loss": 0.7628881039619446, "actor_loss": -52.37431439208984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.843859434127808, "step": 45000}
{"episode_reward": 533.6145323161621, "episode": 46.0, "batch_reward": 0.3012582624107599, "critic_loss": 0.7336256797909737, "actor_loss": -51.52712308502197, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.837219715118408, "step": 46000}
{"episode_reward": 273.4947840076227, "episode": 47.0, "batch_reward": 0.3023207101970911, "critic_loss": 0.7392704042494297, "actor_loss": -51.11583047485352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.836716175079346, "step": 47000}
{"episode_reward": 592.2372808993142, "episode": 48.0, "batch_reward": 0.3090056419670582, "critic_loss": 0.6873390038907528, "actor_loss": -51.21334084320068, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.837859869003296, "step": 48000}
{"episode_reward": 590.5706257902267, "episode": 49.0, "batch_reward": 0.3142059110701084, "critic_loss": 0.6182010968625545, "actor_loss": -50.962737297058105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.842309713363647, "step": 49000}
{"episode_reward": 566.7822812835324, "episode": 50.0, "batch_reward": 0.3161042425483465, "critic_loss": 0.5802114152610302, "actor_loss": -50.66684380340576, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.850215911865234, "step": 50000}
{"episode_reward": 266.05347089966995, "episode": 51.0, "batch_reward": 0.31714460608363154, "critic_loss": 0.5764836033582688, "actor_loss": -50.1942554397583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.99826097488403, "step": 51000}
{"episode_reward": 537.3819758756847, "episode": 52.0, "batch_reward": 0.3223828264027834, "critic_loss": 0.5649079267382622, "actor_loss": -50.49795104980469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.850882053375244, "step": 52000}
{"episode_reward": 574.6753178919369, "episode": 53.0, "batch_reward": 0.32733161401748656, "critic_loss": 0.5419253351092339, "actor_loss": -50.28366149902344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.838582277297974, "step": 53000}
{"episode_reward": 548.87539983351, "episode": 54.0, "batch_reward": 0.3309829680621624, "critic_loss": 0.5220239140093327, "actor_loss": -50.054778251647946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.857210874557495, "step": 54000}
{"episode_reward": 544.2276894002695, "episode": 55.0, "batch_reward": 0.3348634963780642, "critic_loss": 0.47973995715379714, "actor_loss": -49.97059862518311, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.868244647979736, "step": 55000}
{"episode_reward": 559.159972997333, "episode": 56.0, "batch_reward": 0.33777491623163225, "critic_loss": 0.44891576139628886, "actor_loss": -49.64994243621826, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.850382804870605, "step": 56000}
{"episode_reward": 544.5535336794405, "episode": 57.0, "batch_reward": 0.3433076367676258, "critic_loss": 0.4828469981998205, "actor_loss": -49.72669059753418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.854358911514282, "step": 57000}
{"episode_reward": 575.1517049691201, "episode": 58.0, "batch_reward": 0.3460722676217556, "critic_loss": 0.4629789230078459, "actor_loss": -49.67552647399902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.840076684951782, "step": 58000}
{"episode_reward": 546.9220630844175, "episode": 59.0, "batch_reward": 0.34966305750608445, "critic_loss": 0.46388342982530595, "actor_loss": -49.579546714782715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.83283305168152, "step": 59000}
{"episode_reward": 567.1180071465421, "episode": 60.0, "batch_reward": 0.3533124202787876, "critic_loss": 0.47879332354664805, "actor_loss": -49.741544715881346, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.839888095855713, "step": 60000}
{"episode_reward": 537.7110373104118, "episode": 61.0, "batch_reward": 0.3571102904677391, "critic_loss": 0.4673653053939342, "actor_loss": -50.00741804504395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.95348596572876, "step": 61000}
{"episode_reward": 572.288788927525, "episode": 62.0, "batch_reward": 0.360257466763258, "critic_loss": 0.48548879657685756, "actor_loss": -50.01273775482178, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.833455801010132, "step": 62000}
{"episode_reward": 538.872090318127, "episode": 63.0, "batch_reward": 0.36337185895442964, "critic_loss": 0.4637511319220066, "actor_loss": -49.89318904876709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.84275507926941, "step": 63000}
{"episode_reward": 584.3390728988971, "episode": 64.0, "batch_reward": 0.3655898172557354, "critic_loss": 0.47553102792799473, "actor_loss": -49.629840408325194, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.83841586112976, "step": 64000}
{"episode_reward": 527.0598338500166, "episode": 65.0, "batch_reward": 0.36931110724806787, "critic_loss": 0.4803777317404747, "actor_loss": -49.69432793426514, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.845187425613403, "step": 65000}
{"episode_reward": 589.0394798655865, "episode": 66.0, "batch_reward": 0.3727802120447159, "critic_loss": 0.48132355462014675, "actor_loss": -49.789633819580075, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.834931135177612, "step": 66000}
{"episode_reward": 564.9639326285151, "episode": 67.0, "batch_reward": 0.3751095423698425, "critic_loss": 0.4735506661236286, "actor_loss": -50.09140791320801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.840593338012695, "step": 67000}
{"episode_reward": 522.8504532357707, "episode": 68.0, "batch_reward": 0.3768115808367729, "critic_loss": 0.5021667662411928, "actor_loss": -49.794054023742675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.834088563919067, "step": 68000}
{"episode_reward": 497.8740529852363, "episode": 69.0, "batch_reward": 0.3802778688669205, "critic_loss": 0.4845334335267544, "actor_loss": -49.88574035644531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.828290224075317, "step": 69000}
{"episode_reward": 598.4250378679538, "episode": 70.0, "batch_reward": 0.3821322417855263, "critic_loss": 0.48907856018841267, "actor_loss": -49.898719337463376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.823850870132446, "step": 70000}
{"episode_reward": 542.9852588402014, "episode": 71.0, "batch_reward": 0.38553565499186515, "critic_loss": 0.49826309275627134, "actor_loss": -49.952275390625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.958396673202515, "step": 71000}
{"episode_reward": 602.0743855414979, "episode": 72.0, "batch_reward": 0.3874459576010704, "critic_loss": 0.5104736499190331, "actor_loss": -49.9318157043457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.8205623626709, "step": 72000}
{"episode_reward": 586.9038506883152, "episode": 73.0, "batch_reward": 0.3893935200273991, "critic_loss": 0.5065748302638531, "actor_loss": -49.91501473236084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.828974962234497, "step": 73000}
{"episode_reward": 186.57711165251007, "episode": 74.0, "batch_reward": 0.3876939681172371, "critic_loss": 0.5286843105256558, "actor_loss": -49.59924970245361, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.82781171798706, "step": 74000}
{"episode_reward": 556.8838181119754, "episode": 75.0, "batch_reward": 0.3908143129050732, "critic_loss": 0.5146662878990174, "actor_loss": -49.62204515838623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.844468593597412, "step": 75000}
{"episode_reward": 566.8027152190585, "episode": 76.0, "batch_reward": 0.39234280404448507, "critic_loss": 0.5210783356428146, "actor_loss": -49.76056031036377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.86032509803772, "step": 76000}
{"episode_reward": 576.4132887585482, "episode": 77.0, "batch_reward": 0.39523977929353715, "critic_loss": 0.5112118388861417, "actor_loss": -49.87642179107666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.853651523590088, "step": 77000}
{"episode_reward": 560.2309541247625, "episode": 78.0, "batch_reward": 0.3969403189718723, "critic_loss": 0.5031289384365082, "actor_loss": -49.916128982543945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.83366322517395, "step": 78000}
{"episode_reward": 518.4633810129326, "episode": 79.0, "batch_reward": 0.399462922513485, "critic_loss": 0.4808712433278561, "actor_loss": -49.93217770385742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.83073091506958, "step": 79000}
{"episode_reward": 595.0129467133497, "episode": 80.0, "batch_reward": 0.40035531651973727, "critic_loss": 0.4769129269272089, "actor_loss": -50.02585494232178, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.841980934143066, "step": 80000}
{"episode_reward": 561.2776942562971, "episode": 81.0, "batch_reward": 0.40355561310052873, "critic_loss": 0.49049392715096474, "actor_loss": -50.0154482421875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.9718382358551, "step": 81000}
{"episode_reward": 589.8198011501769, "episode": 82.0, "batch_reward": 0.4049597609043121, "critic_loss": 0.4620708555877209, "actor_loss": -49.97339922332764, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.83153486251831, "step": 82000}
{"episode_reward": 586.187205983363, "episode": 83.0, "batch_reward": 0.40893627816438677, "critic_loss": 0.45490732227265834, "actor_loss": -50.199706100463864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.82128095626831, "step": 83000}
{"episode_reward": 579.2356135507817, "episode": 84.0, "batch_reward": 0.4086223949790001, "critic_loss": 0.4434202298372984, "actor_loss": -50.12891426849365, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.835286378860474, "step": 84000}
{"episode_reward": 578.8893814808193, "episode": 85.0, "batch_reward": 0.4091045335531235, "critic_loss": 0.43917028661072255, "actor_loss": -50.02545930480957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.833205223083496, "step": 85000}
{"episode_reward": 104.37874097067996, "episode": 86.0, "batch_reward": 0.4072966333329678, "critic_loss": 0.42944585567712784, "actor_loss": -49.76312490844727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.843964099884033, "step": 86000}
{"episode_reward": 554.3171193783205, "episode": 87.0, "batch_reward": 0.4094075897634029, "critic_loss": 0.427558443531394, "actor_loss": -49.78657151031494, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.834004878997803, "step": 87000}
{"episode_reward": 599.0810361180297, "episode": 88.0, "batch_reward": 0.41188270422816275, "critic_loss": 0.3931783634573221, "actor_loss": -49.972430221557616, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.84044361114502, "step": 88000}
{"episode_reward": 583.2746224778289, "episode": 89.0, "batch_reward": 0.41503990489244463, "critic_loss": 0.4208738462626934, "actor_loss": -50.15819245147705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.842973232269287, "step": 89000}
{"episode_reward": 566.9575471744847, "episode": 90.0, "batch_reward": 0.4161255752444267, "critic_loss": 0.3917782349139452, "actor_loss": -50.26664780426025, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.849595308303833, "step": 90000}
{"episode_reward": 573.2311201262982, "episode": 91.0, "batch_reward": 0.4166343423724175, "critic_loss": 0.43096150834858415, "actor_loss": -50.251072929382325, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.0327935218811, "step": 91000}
{"episode_reward": 578.4166862861196, "episode": 92.0, "batch_reward": 0.4189501432478428, "critic_loss": 0.41604062262177466, "actor_loss": -50.22452484130859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.872989654541016, "step": 92000}
{"episode_reward": 567.4053375764347, "episode": 93.0, "batch_reward": 0.4211689412295818, "critic_loss": 0.4077519060969353, "actor_loss": -50.401464706420896, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.88004159927368, "step": 93000}
{"episode_reward": 551.9333467855663, "episode": 94.0, "batch_reward": 0.4219840205311775, "critic_loss": 0.42147823448479177, "actor_loss": -50.275378295898435, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.84479856491089, "step": 94000}
{"episode_reward": 168.46772817451821, "episode": 95.0, "batch_reward": 0.4190425483584404, "critic_loss": 0.3953414570838213, "actor_loss": -50.09325694274902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.85607123374939, "step": 95000}
{"episode_reward": 563.4189530538497, "episode": 96.0, "batch_reward": 0.42118344923853873, "critic_loss": 0.40770245155692103, "actor_loss": -50.119419639587406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.835529804229736, "step": 96000}
{"episode_reward": 569.9760777286141, "episode": 97.0, "batch_reward": 0.42293604379892347, "critic_loss": 0.407023138076067, "actor_loss": -50.20508679962158, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.83805751800537, "step": 97000}
{"episode_reward": 601.1409267114605, "episode": 98.0, "batch_reward": 0.4247066678404808, "critic_loss": 0.3892674466073513, "actor_loss": -50.409436073303226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.826997756958008, "step": 98000}
{"episode_reward": 556.2317958226545, "episode": 99.0, "batch_reward": 0.42556119057536124, "critic_loss": 0.41837089897692203, "actor_loss": -50.474383964538575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.83076000213623, "step": 99000}
{"episode_reward": 566.8786381816886, "episode": 100.0, "batch_reward": 0.42678911590576174, "critic_loss": 0.4079408459365368, "actor_loss": -50.51485256958008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.851013898849487, "step": 100000}
{"episode_reward": 578.0677921174948, "episode": 101.0, "batch_reward": 0.42821872934699057, "critic_loss": 0.42210499599575996, "actor_loss": -50.43554270172119, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.97475838661194, "step": 101000}
{"episode_reward": 548.4335377142781, "episode": 102.0, "batch_reward": 0.43002831378579137, "critic_loss": 0.4163632033765316, "actor_loss": -50.64767923736572, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.841646671295166, "step": 102000}
{"episode_reward": 587.2005203157322, "episode": 103.0, "batch_reward": 0.43116819033026693, "critic_loss": 0.42572662349045276, "actor_loss": -50.715378471374514, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.843767881393433, "step": 103000}
{"episode_reward": 523.9393082153082, "episode": 104.0, "batch_reward": 0.4328265519440174, "critic_loss": 0.4028425661325455, "actor_loss": -50.825281227111816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.837574005126953, "step": 104000}
{"episode_reward": 564.8698347944495, "episode": 105.0, "batch_reward": 0.4327227856218815, "critic_loss": 0.39709558805823325, "actor_loss": -50.786355628967286, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.836386919021606, "step": 105000}
{"episode_reward": 592.7029429342083, "episode": 106.0, "batch_reward": 0.4352071256935596, "critic_loss": 0.38803579403460026, "actor_loss": -50.913747581481935, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.850759983062744, "step": 106000}
{"episode_reward": 565.7283284092929, "episode": 107.0, "batch_reward": 0.43648703941702843, "critic_loss": 0.4143065178990364, "actor_loss": -50.95371711730957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.845550775527954, "step": 107000}
{"episode_reward": 599.9388103879224, "episode": 108.0, "batch_reward": 0.4367172912955284, "critic_loss": 0.3985877532362938, "actor_loss": -51.03035292816162, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.8480384349823, "step": 108000}
{"episode_reward": 576.906617146931, "episode": 109.0, "batch_reward": 0.4391060663461685, "critic_loss": 0.3783239946514368, "actor_loss": -51.10542493438721, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.834933519363403, "step": 109000}
{"episode_reward": 565.740677584623, "episode": 110.0, "batch_reward": 0.4398476357161999, "critic_loss": 0.3838414172679186, "actor_loss": -51.111026786804196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.839220762252808, "step": 110000}
{"episode_reward": 577.1234624155485, "episode": 111.0, "batch_reward": 0.44166560700535773, "critic_loss": 0.41260942827165126, "actor_loss": -51.18666857147217, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.960482358932495, "step": 111000}
{"episode_reward": 587.8801466384317, "episode": 112.0, "batch_reward": 0.4420755331814289, "critic_loss": 0.3847283063530922, "actor_loss": -51.24695665740967, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.835326671600342, "step": 112000}
{"episode_reward": 551.2144820685709, "episode": 113.0, "batch_reward": 0.44424353510141373, "critic_loss": 0.3652353278696537, "actor_loss": -51.31070679473877, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.840519905090332, "step": 113000}
{"episode_reward": 545.0592030491938, "episode": 114.0, "batch_reward": 0.4444003180265427, "critic_loss": 0.37479273256659507, "actor_loss": -51.40742639160156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.859443187713623, "step": 114000}
{"episode_reward": 578.6723543037241, "episode": 115.0, "batch_reward": 0.44562222561240195, "critic_loss": 0.40122757540643217, "actor_loss": -51.555633895874024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.854386568069458, "step": 115000}
{"episode_reward": 566.2729017069514, "episode": 116.0, "batch_reward": 0.44684250277280807, "critic_loss": 0.3840036841332912, "actor_loss": -51.52160354614258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.85619282722473, "step": 116000}
{"episode_reward": 562.351511991872, "episode": 117.0, "batch_reward": 0.44771002638339996, "critic_loss": 0.39741465835273265, "actor_loss": -51.74252735900879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.873871326446533, "step": 117000}
{"episode_reward": 556.0764129033173, "episode": 118.0, "batch_reward": 0.449443692445755, "critic_loss": 0.38895489418506624, "actor_loss": -51.66836319732666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.83741283416748, "step": 118000}
{"episode_reward": 551.1304584969178, "episode": 119.0, "batch_reward": 0.4487512274980545, "critic_loss": 0.3825694508254528, "actor_loss": -51.711050590515136, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.842520475387573, "step": 119000}
{"episode_reward": 560.70627566236, "episode": 120.0, "batch_reward": 0.4498938589096069, "critic_loss": 0.3908352082818747, "actor_loss": -51.85332299804688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.843647241592407, "step": 120000}
{"episode_reward": 570.891935984518, "episode": 121.0, "batch_reward": 0.45199905228614806, "critic_loss": 0.39602435831725596, "actor_loss": -51.9360517578125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.97191882133484, "step": 121000}
{"episode_reward": 567.3372366357778, "episode": 122.0, "batch_reward": 0.45351696985960005, "critic_loss": 0.3805730013102293, "actor_loss": -52.02210422515869, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.82897162437439, "step": 122000}
{"episode_reward": 598.0517484854046, "episode": 123.0, "batch_reward": 0.45322990375757216, "critic_loss": 0.4034782606214285, "actor_loss": -52.10697946929932, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.83628797531128, "step": 123000}
{"episode_reward": 514.7394528075931, "episode": 124.0, "batch_reward": 0.4541725974082947, "critic_loss": 0.39781888619065287, "actor_loss": -52.037512008666994, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.836092948913574, "step": 124000}
{"episode_reward": 358.2562630993117, "episode": 125.0, "batch_reward": 0.4540307238698006, "critic_loss": 0.4011883724927902, "actor_loss": -51.970420936584475, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.82280731201172, "step": 125000}
{"episode_reward": 574.3344908313458, "episode": 126.0, "batch_reward": 0.45398678895831107, "critic_loss": 0.39598582707345487, "actor_loss": -52.06555264282227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.847811937332153, "step": 126000}
{"episode_reward": 136.8315857395453, "episode": 127.0, "batch_reward": 0.451778937369585, "critic_loss": 0.39994282740354536, "actor_loss": -51.698834197998046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.836289882659912, "step": 127000}
{"episode_reward": 575.6770305530135, "episode": 128.0, "batch_reward": 0.4506280639767647, "critic_loss": 0.3880611795037985, "actor_loss": -51.498364585876466, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.84630560874939, "step": 128000}
{"episode_reward": 129.43492971924152, "episode": 129.0, "batch_reward": 0.4493869241774082, "critic_loss": 0.41308836740255356, "actor_loss": -51.38565488433838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.841808080673218, "step": 129000}
{"episode_reward": 541.4944091527012, "episode": 130.0, "batch_reward": 0.4505926648378372, "critic_loss": 0.4320297115445137, "actor_loss": -51.47090803527832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.850861072540283, "step": 130000}
{"episode_reward": 550.7477668661753, "episode": 131.0, "batch_reward": 0.45102696081995963, "critic_loss": 0.41024177192151545, "actor_loss": -51.19757544708252, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.00204348564148, "step": 131000}
{"episode_reward": 532.6632296755754, "episode": 132.0, "batch_reward": 0.451130438387394, "critic_loss": 0.41184077252447604, "actor_loss": -51.46968503570557, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.830638647079468, "step": 132000}
{"episode_reward": 559.4828593335313, "episode": 133.0, "batch_reward": 0.451465141415596, "critic_loss": 0.4270500636994839, "actor_loss": -51.5689686126709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.83035707473755, "step": 133000}
{"episode_reward": 544.4606845261125, "episode": 134.0, "batch_reward": 0.45265284794569016, "critic_loss": 0.4282219944149256, "actor_loss": -51.64712465667725, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.839017152786255, "step": 134000}
{"episode_reward": 571.5541907669102, "episode": 135.0, "batch_reward": 0.4541410156786442, "critic_loss": 0.4061509656906128, "actor_loss": -51.73476491546631, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.839881896972656, "step": 135000}
{"episode_reward": 531.0457533985339, "episode": 136.0, "batch_reward": 0.45541006007790563, "critic_loss": 0.43465446032583716, "actor_loss": -51.92387062072754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.838019132614136, "step": 136000}
{"episode_reward": 553.8263947406788, "episode": 137.0, "batch_reward": 0.45626968374848365, "critic_loss": 0.41517576774954795, "actor_loss": -51.83171500396728, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.84041476249695, "step": 137000}
{"episode_reward": 573.6193938733271, "episode": 138.0, "batch_reward": 0.4572990652024746, "critic_loss": 0.40912575820088387, "actor_loss": -51.695568969726565, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.84626603126526, "step": 138000}
{"episode_reward": 598.3507592006429, "episode": 139.0, "batch_reward": 0.4585694353580475, "critic_loss": 0.4051225285679102, "actor_loss": -51.72929760742188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.133735179901123, "step": 139000}
{"episode_reward": 559.2007099404603, "episode": 140.0, "batch_reward": 0.4570238136649132, "critic_loss": 0.3857086575329304, "actor_loss": -51.76043022918701, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.812619924545288, "step": 140000}
{"episode_reward": 578.4909637687666, "episode": 141.0, "batch_reward": 0.4588113095164299, "critic_loss": 0.39376642914116383, "actor_loss": -52.03009027862549, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.92642402648926, "step": 141000}
{"episode_reward": 549.5448253375758, "episode": 142.0, "batch_reward": 0.4600570193231106, "critic_loss": 0.3874473060667515, "actor_loss": -52.011653877258304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.138468027114868, "step": 142000}
{"episode_reward": 564.2508019411258, "episode": 143.0, "batch_reward": 0.46102911353111264, "critic_loss": 0.3722293934375048, "actor_loss": -52.22015941619873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.833292245864868, "step": 143000}
{"episode_reward": 573.4557096517731, "episode": 144.0, "batch_reward": 0.46271006879210475, "critic_loss": 0.3684805774986744, "actor_loss": -52.18013647460938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.814571380615234, "step": 144000}
{"episode_reward": 592.311542905876, "episode": 145.0, "batch_reward": 0.46268209582567216, "critic_loss": 0.38408490795642136, "actor_loss": -52.44677542877197, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.807031869888306, "step": 145000}
{"episode_reward": 549.1276410794221, "episode": 146.0, "batch_reward": 0.46320529958605766, "critic_loss": 0.3955490856319666, "actor_loss": -52.19864360809326, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.82545828819275, "step": 146000}
{"episode_reward": 576.450586203606, "episode": 147.0, "batch_reward": 0.46374976137280466, "critic_loss": 0.3657144835740328, "actor_loss": -52.20434674835205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.81473159790039, "step": 147000}
{"episode_reward": 571.6820713204529, "episode": 148.0, "batch_reward": 0.4653773912191391, "critic_loss": 0.4127992246299982, "actor_loss": -52.46011637878418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.82944345474243, "step": 148000}
{"episode_reward": 575.1136984700105, "episode": 149.0, "batch_reward": 0.46467598670721055, "critic_loss": 0.39139117860794065, "actor_loss": -52.31318264007568, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.129992961883545, "step": 149000}
{"episode_reward": 560.6776207350641, "episode": 150.0, "batch_reward": 0.46667643171548845, "critic_loss": 0.40247728211432693, "actor_loss": -52.45662448883056, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
