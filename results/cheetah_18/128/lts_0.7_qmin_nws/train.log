{"episode_reward": 0.0, "episode": 1.0, "duration": 17.353805541992188, "step": 1000}
{"episode_reward": 4.20996189079657, "episode": 2.0, "duration": 1.5027892589569092, "step": 2000}
{"episode_reward": 252.2457487418515, "episode": 3.0, "batch_reward": 0.12258680678951259, "critic_loss": 0.0922312024333609, "actor_loss": -24.973601712959677, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 59.93900966644287, "step": 3000}
{"episode_reward": 26.03020134797132, "episode": 4.0, "batch_reward": 0.0877913425900042, "critic_loss": 0.06333540519699454, "actor_loss": -21.71800626564026, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.84699034690857, "step": 4000}
{"episode_reward": 38.28584581157697, "episode": 5.0, "batch_reward": 0.07570982272550464, "critic_loss": 0.06406982593238354, "actor_loss": -21.866316771507265, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.849283933639526, "step": 5000}
{"episode_reward": 38.66588106182282, "episode": 6.0, "batch_reward": 0.07041067080944777, "critic_loss": 0.07783666456490755, "actor_loss": -20.140173274993895, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.805251121520996, "step": 6000}
{"episode_reward": 35.21843829079659, "episode": 7.0, "batch_reward": 0.0648592082746327, "critic_loss": 0.06329819633066654, "actor_loss": -19.27116903400421, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.82872724533081, "step": 7000}
{"episode_reward": 51.76410880296069, "episode": 8.0, "batch_reward": 0.06404296753928065, "critic_loss": 0.08047054381296039, "actor_loss": -18.210289665222167, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.85425591468811, "step": 8000}
{"episode_reward": 61.15556181444322, "episode": 9.0, "batch_reward": 0.06501626427099108, "critic_loss": 0.11133763194829226, "actor_loss": -18.147202756881715, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.81528067588806, "step": 9000}
{"episode_reward": 90.1815031191688, "episode": 10.0, "batch_reward": 0.06712959114834666, "critic_loss": 0.11726548010110856, "actor_loss": -19.716638451576234, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.819225072860718, "step": 10000}
{"episode_reward": 50.62761993398172, "episode": 11.0, "batch_reward": 0.06504879147931933, "critic_loss": 0.101757931612432, "actor_loss": -17.364367807388305, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.14028596878052, "step": 11000}
{"episode_reward": 47.03912687427313, "episode": 12.0, "batch_reward": 0.06318214301764966, "critic_loss": 0.1041252209842205, "actor_loss": -17.164680860519407, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.822385549545288, "step": 12000}
{"episode_reward": 37.549079823152915, "episode": 13.0, "batch_reward": 0.06261435704305768, "critic_loss": 0.0970794758759439, "actor_loss": -17.027033619403838, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.82276153564453, "step": 13000}
{"episode_reward": 68.45635529507445, "episode": 14.0, "batch_reward": 0.06464794873446227, "critic_loss": 0.11509144243597984, "actor_loss": -16.880255776882173, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.836204290390015, "step": 14000}
{"episode_reward": 152.4687842120151, "episode": 15.0, "batch_reward": 0.0694812051653862, "critic_loss": 0.14439355377852917, "actor_loss": -17.01084731388092, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.837870121002197, "step": 15000}
{"episode_reward": 59.26165787525221, "episode": 16.0, "batch_reward": 0.07184855857491493, "critic_loss": 0.15140761310607195, "actor_loss": -16.1391297249794, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.805303812026978, "step": 16000}
{"episode_reward": 121.58666546249536, "episode": 17.0, "batch_reward": 0.07673873056843877, "critic_loss": 0.17144475215673446, "actor_loss": -16.939971366643906, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.819446563720703, "step": 17000}
{"episode_reward": 208.16500497929707, "episode": 18.0, "batch_reward": 0.0830222269371152, "critic_loss": 0.18286737404763698, "actor_loss": -16.95933629512787, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.8392333984375, "step": 18000}
{"episode_reward": 150.78787421056245, "episode": 19.0, "batch_reward": 0.08414940158650279, "critic_loss": 0.18370874843746424, "actor_loss": -17.299061833173038, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.806714057922363, "step": 19000}
{"episode_reward": 87.00873202755798, "episode": 20.0, "batch_reward": 0.08476179185137153, "critic_loss": 0.19240029944479464, "actor_loss": -17.05944618871808, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.801318407058716, "step": 20000}
{"episode_reward": 92.15370434915437, "episode": 21.0, "batch_reward": 0.08411817752569914, "critic_loss": 0.1820581010580063, "actor_loss": -15.624683113634587, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.06911039352417, "step": 21000}
{"episode_reward": 63.61812422870947, "episode": 22.0, "batch_reward": 0.08594721347466111, "critic_loss": 0.17962888320535422, "actor_loss": -17.098612607747317, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.802025318145752, "step": 22000}
{"episode_reward": 213.65229512154895, "episode": 23.0, "batch_reward": 0.08969997833296657, "critic_loss": 0.1849431638866663, "actor_loss": -17.4504335924685, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.82815194129944, "step": 23000}
{"episode_reward": 77.73829555218894, "episode": 24.0, "batch_reward": 0.08829575086385012, "critic_loss": 0.1998411827161908, "actor_loss": -15.800343339085579, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.82465171813965, "step": 24000}
{"episode_reward": 68.5678011414539, "episode": 25.0, "batch_reward": 0.0884603498838842, "critic_loss": 0.22754736196994782, "actor_loss": -17.030705869987607, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.812575101852417, "step": 25000}
{"episode_reward": 127.59600107830892, "episode": 26.0, "batch_reward": 0.08891529332846403, "critic_loss": 0.22084141222387552, "actor_loss": -16.11144759811461, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.819451093673706, "step": 26000}
{"episode_reward": 54.45069748322067, "episode": 27.0, "batch_reward": 0.08817152686417103, "critic_loss": 0.23142131657153367, "actor_loss": -16.397569024443627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.99205446243286, "step": 27000}
{"episode_reward": 85.32836505025449, "episode": 28.0, "batch_reward": 0.09073103646934032, "critic_loss": 0.24300781823694706, "actor_loss": -16.6165306943655, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.989150524139404, "step": 28000}
{"episode_reward": 219.2064022968514, "episode": 29.0, "batch_reward": 0.09242057864367961, "critic_loss": 0.24780710557103158, "actor_loss": -16.891456337451935, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.80518674850464, "step": 29000}
{"episode_reward": 70.72078352917785, "episode": 30.0, "batch_reward": 0.09401826383173466, "critic_loss": 0.24384630175679922, "actor_loss": -16.429534914016724, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.783406019210815, "step": 30000}
{"episode_reward": 155.70381775755902, "episode": 31.0, "batch_reward": 0.09461587783694267, "critic_loss": 0.22766296567767857, "actor_loss": -16.800670231342316, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.06727886199951, "step": 31000}
{"episode_reward": 102.50576716647424, "episode": 32.0, "batch_reward": 0.09618361081928015, "critic_loss": 0.20678252638876438, "actor_loss": -16.704706614494324, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.783125638961792, "step": 32000}
{"episode_reward": 241.58194739848565, "episode": 33.0, "batch_reward": 0.1010709513053298, "critic_loss": 0.23726714399456977, "actor_loss": -17.615993589162827, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.812600135803223, "step": 33000}
{"episode_reward": 270.30885894724184, "episode": 34.0, "batch_reward": 0.10609003216028214, "critic_loss": 0.22978611700981855, "actor_loss": -18.273602061748505, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.765299081802368, "step": 34000}
{"episode_reward": 189.02236250136684, "episode": 35.0, "batch_reward": 0.10766050925850869, "critic_loss": 0.2394508805498481, "actor_loss": -17.87564718389511, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.79133367538452, "step": 35000}
{"episode_reward": 177.1585791827863, "episode": 36.0, "batch_reward": 0.10792832013219594, "critic_loss": 0.22993312291055917, "actor_loss": -17.970205461025238, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.799839973449707, "step": 36000}
{"episode_reward": 41.2881352545761, "episode": 37.0, "batch_reward": 0.1093839251846075, "critic_loss": 0.21519324826449157, "actor_loss": -17.739974644184112, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.78850507736206, "step": 37000}
{"episode_reward": 208.947188364509, "episode": 38.0, "batch_reward": 0.10901447293907404, "critic_loss": 0.19979410737007858, "actor_loss": -18.10239575624466, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.825936794281006, "step": 38000}
{"episode_reward": 53.618857055765766, "episode": 39.0, "batch_reward": 0.10820951102674008, "critic_loss": 0.20304611806571485, "actor_loss": -18.07735197496414, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.847357034683228, "step": 39000}
{"episode_reward": 71.38302683004851, "episode": 40.0, "batch_reward": 0.10684986486285925, "critic_loss": 0.21422422059625387, "actor_loss": -18.44827126121521, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.766597986221313, "step": 40000}
{"episode_reward": 66.48799646766794, "episode": 41.0, "batch_reward": 0.10906189088523388, "critic_loss": 0.22994779662787915, "actor_loss": -18.133060894489287, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.12318658828735, "step": 41000}
{"episode_reward": 294.08814562058546, "episode": 42.0, "batch_reward": 0.11288066687434911, "critic_loss": 0.23901066418737174, "actor_loss": -18.306872800350188, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.827687740325928, "step": 42000}
{"episode_reward": 185.9264231855259, "episode": 43.0, "batch_reward": 0.11305066609382629, "critic_loss": 0.24370192724466325, "actor_loss": -18.844155118465423, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.812756061553955, "step": 43000}
{"episode_reward": 127.71600203943765, "episode": 44.0, "batch_reward": 0.11533609034866095, "critic_loss": 0.24057730531692506, "actor_loss": -18.391666295051575, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.814736127853394, "step": 44000}
{"episode_reward": 285.79242134097154, "episode": 45.0, "batch_reward": 0.11699145457148552, "critic_loss": 0.25638110235333444, "actor_loss": -18.010684553146362, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.83765983581543, "step": 45000}
{"episode_reward": 95.83363012171225, "episode": 46.0, "batch_reward": 0.11794779792428017, "critic_loss": 0.27454816038906577, "actor_loss": -18.462675300598143, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.822248935699463, "step": 46000}
{"episode_reward": 179.52728882138163, "episode": 47.0, "batch_reward": 0.1186088772341609, "critic_loss": 0.28787874552607534, "actor_loss": -18.517076565742492, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.8564453125, "step": 47000}
{"episode_reward": 162.62313902408692, "episode": 48.0, "batch_reward": 0.12061054878681898, "critic_loss": 0.2956202996522188, "actor_loss": -18.43074283027649, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.857789993286133, "step": 48000}
{"episode_reward": 332.1795788010453, "episode": 49.0, "batch_reward": 0.1255843378379941, "critic_loss": 0.29143426317721605, "actor_loss": -19.40390568161011, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.83885645866394, "step": 49000}
{"episode_reward": 390.9666730777497, "episode": 50.0, "batch_reward": 0.12866540287435055, "critic_loss": 0.27880984523892405, "actor_loss": -19.20159105682373, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.842573642730713, "step": 50000}
{"episode_reward": 80.13060332737061, "episode": 51.0, "batch_reward": 0.12921656004339457, "critic_loss": 0.28251848550140857, "actor_loss": -20.359934191703797, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.25379705429077, "step": 51000}
{"episode_reward": 303.23761713059986, "episode": 52.0, "batch_reward": 0.13364167857170106, "critic_loss": 0.2869563660621643, "actor_loss": -19.69845484542847, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.795952558517456, "step": 52000}
{"episode_reward": 373.21489433819295, "episode": 53.0, "batch_reward": 0.13800926514714956, "critic_loss": 0.3063129512667656, "actor_loss": -20.601251958847048, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.792603492736816, "step": 53000}
{"episode_reward": 381.9240265594331, "episode": 54.0, "batch_reward": 0.14187291689962148, "critic_loss": 0.31580355554819106, "actor_loss": -21.238202865600584, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.811974048614502, "step": 54000}
{"episode_reward": 381.9124297959119, "episode": 55.0, "batch_reward": 0.14644956387579441, "critic_loss": 0.32804299192130565, "actor_loss": -21.52184562397003, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.837897062301636, "step": 55000}
{"episode_reward": 368.1691391456646, "episode": 56.0, "batch_reward": 0.15094768487662077, "critic_loss": 0.3150787125378847, "actor_loss": -21.956610950469972, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06796622276306, "step": 56000}
{"episode_reward": 415.07183204001257, "episode": 57.0, "batch_reward": 0.15476911421865225, "critic_loss": 0.3351187819391489, "actor_loss": -22.03693054008484, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.78164768218994, "step": 57000}
{"episode_reward": 381.3387090933979, "episode": 58.0, "batch_reward": 0.15949963220208882, "critic_loss": 0.31899769557267427, "actor_loss": -22.646904891967772, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.722561836242676, "step": 58000}
{"episode_reward": 324.4613679972105, "episode": 59.0, "batch_reward": 0.16049372042715548, "critic_loss": 0.32640677332133056, "actor_loss": -23.26447972869873, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.7683687210083, "step": 59000}
{"episode_reward": 68.31020629361583, "episode": 60.0, "batch_reward": 0.1593814777955413, "critic_loss": 0.32280031575262547, "actor_loss": -22.612514125823974, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.7657310962677, "step": 60000}
{"episode_reward": 413.6086861157851, "episode": 61.0, "batch_reward": 0.16444472770392896, "critic_loss": 0.3176927357316017, "actor_loss": -22.550501291275026, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.098644971847534, "step": 61000}
{"episode_reward": 427.1751753372288, "episode": 62.0, "batch_reward": 0.1696116262972355, "critic_loss": 0.3206133647635579, "actor_loss": -23.259370990753172, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.78194832801819, "step": 62000}
{"episode_reward": 420.4374606952525, "episode": 63.0, "batch_reward": 0.17346335116028785, "critic_loss": 0.31656443735957146, "actor_loss": -23.53945572090149, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.797305822372437, "step": 63000}
{"episode_reward": 431.28372438531113, "episode": 64.0, "batch_reward": 0.17784990173578263, "critic_loss": 0.3231188768595457, "actor_loss": -24.47458036804199, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.795610666275024, "step": 64000}
{"episode_reward": 415.85220696191254, "episode": 65.0, "batch_reward": 0.18141061551868914, "critic_loss": 0.3307851317226887, "actor_loss": -24.5125046081543, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.800366401672363, "step": 65000}
{"episode_reward": 433.7876550814542, "episode": 66.0, "batch_reward": 0.184551199644804, "critic_loss": 0.3471817788779736, "actor_loss": -25.01102293395996, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.80100679397583, "step": 66000}
{"episode_reward": 418.8746931196088, "episode": 67.0, "batch_reward": 0.18713036060333252, "critic_loss": 0.36201604424417017, "actor_loss": -24.928105682373047, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.82852840423584, "step": 67000}
{"episode_reward": 165.98532746983915, "episode": 68.0, "batch_reward": 0.1872543007284403, "critic_loss": 0.3486599394828081, "actor_loss": -25.311735467910765, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.75808548927307, "step": 68000}
{"episode_reward": 226.49441320891205, "episode": 69.0, "batch_reward": 0.1895583516508341, "critic_loss": 0.35754179243743417, "actor_loss": -24.8495519695282, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.787113666534424, "step": 69000}
{"episode_reward": 486.5643346580565, "episode": 70.0, "batch_reward": 0.19251005356013776, "critic_loss": 0.3624543470293283, "actor_loss": -25.80536887741089, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.814423322677612, "step": 70000}
{"episode_reward": 423.7915985752219, "episode": 71.0, "batch_reward": 0.19721574963629246, "critic_loss": 0.353719426587224, "actor_loss": -26.005894357681274, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.09201765060425, "step": 71000}
{"episode_reward": 426.7433248301836, "episode": 72.0, "batch_reward": 0.199037620767951, "critic_loss": 0.3425285811275244, "actor_loss": -26.037376756668092, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.81262469291687, "step": 72000}
{"episode_reward": 404.36456623349386, "episode": 73.0, "batch_reward": 0.2026374276727438, "critic_loss": 0.31973755538463594, "actor_loss": -26.76811706542969, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.778192281723022, "step": 73000}
{"episode_reward": 435.0842585915278, "episode": 74.0, "batch_reward": 0.20532203681766986, "critic_loss": 0.32001081997156144, "actor_loss": -26.350379789352417, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.77652931213379, "step": 74000}
{"episode_reward": 374.33556351621485, "episode": 75.0, "batch_reward": 0.207175870642066, "critic_loss": 0.3282602236717939, "actor_loss": -27.801178644180297, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.78550887107849, "step": 75000}
{"episode_reward": 327.31015668967933, "episode": 76.0, "batch_reward": 0.20947699785232543, "critic_loss": 0.3207692403048277, "actor_loss": -27.526619857788084, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.818930864334106, "step": 76000}
{"episode_reward": 410.2867578387985, "episode": 77.0, "batch_reward": 0.21271191072463988, "critic_loss": 0.32068012438714505, "actor_loss": -27.941186044692994, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.801246404647827, "step": 77000}
{"episode_reward": 507.44407934588963, "episode": 78.0, "batch_reward": 0.21547283132374287, "critic_loss": 0.32898340333998205, "actor_loss": -27.800807317733764, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.762661457061768, "step": 78000}
{"episode_reward": 442.4474940164109, "episode": 79.0, "batch_reward": 0.2189343977123499, "critic_loss": 0.34683882470428945, "actor_loss": -28.524869239807128, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.76989459991455, "step": 79000}
{"episode_reward": 449.93415404743615, "episode": 80.0, "batch_reward": 0.2196391642987728, "critic_loss": 0.34327000644803046, "actor_loss": -28.622488636016847, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.790597677230835, "step": 80000}
{"episode_reward": 110.01212612711085, "episode": 81.0, "batch_reward": 0.22028839060664177, "critic_loss": 0.34657236468046904, "actor_loss": -28.395646469116212, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.03660774230957, "step": 81000}
{"episode_reward": 444.6430698279519, "episode": 82.0, "batch_reward": 0.22320448534190654, "critic_loss": 0.35492260187864305, "actor_loss": -28.580244817733764, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.862935304641724, "step": 82000}
{"episode_reward": 439.1337782268504, "episode": 83.0, "batch_reward": 0.2238587363809347, "critic_loss": 0.3412490114569664, "actor_loss": -28.90835969734192, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.062549829483032, "step": 83000}
{"episode_reward": 80.43821167556861, "episode": 84.0, "batch_reward": 0.22380726759135722, "critic_loss": 0.33897078578174117, "actor_loss": -28.871919219970703, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.779234409332275, "step": 84000}
{"episode_reward": 474.10899607594166, "episode": 85.0, "batch_reward": 0.22494644148647785, "critic_loss": 0.34515886433422566, "actor_loss": -29.14506188964844, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.773062705993652, "step": 85000}
{"episode_reward": 108.23614559025953, "episode": 86.0, "batch_reward": 0.22483189429342748, "critic_loss": 0.38889801877737046, "actor_loss": -28.699196260452272, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.787572860717773, "step": 86000}
{"episode_reward": 436.00426172170665, "episode": 87.0, "batch_reward": 0.22689120948314667, "critic_loss": 0.38057210212945936, "actor_loss": -28.64845986175537, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.826176404953003, "step": 87000}
{"episode_reward": 202.45529926062417, "episode": 88.0, "batch_reward": 0.22785190476477146, "critic_loss": 0.3560061765909195, "actor_loss": -28.90517590713501, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.833253622055054, "step": 88000}
{"episode_reward": 485.1338174556144, "episode": 89.0, "batch_reward": 0.22814663065969945, "critic_loss": 0.390675436258316, "actor_loss": -29.171153339385988, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.81124472618103, "step": 89000}
{"episode_reward": 57.673029941592034, "episode": 90.0, "batch_reward": 0.22929419720172883, "critic_loss": 0.3555194929242134, "actor_loss": -28.822646919250488, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.817612648010254, "step": 90000}
{"episode_reward": 493.3293419187217, "episode": 91.0, "batch_reward": 0.23004631400108339, "critic_loss": 0.36934909683465955, "actor_loss": -29.698238708496095, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.0687096118927, "step": 91000}
{"episode_reward": 96.92992357611973, "episode": 92.0, "batch_reward": 0.23019125325977802, "critic_loss": 0.38064583797752854, "actor_loss": -28.91603217315674, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.82658553123474, "step": 92000}
{"episode_reward": 338.44095674261604, "episode": 93.0, "batch_reward": 0.22996458360552788, "critic_loss": 0.39844670735299587, "actor_loss": -29.117725522994995, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.781120538711548, "step": 93000}
{"episode_reward": 147.83365770116248, "episode": 94.0, "batch_reward": 0.23040305180847645, "critic_loss": 0.42073068346083164, "actor_loss": -28.788744035720825, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.829517602920532, "step": 94000}
{"episode_reward": 214.94577841002808, "episode": 95.0, "batch_reward": 0.2289579316675663, "critic_loss": 0.4014114284068346, "actor_loss": -29.118537517547608, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.827839851379395, "step": 95000}
{"episode_reward": 221.43429769141875, "episode": 96.0, "batch_reward": 0.2301695058941841, "critic_loss": 0.39229167452454566, "actor_loss": -29.043519302368164, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.809181451797485, "step": 96000}
{"episode_reward": 430.09336966620026, "episode": 97.0, "batch_reward": 0.23085646195709705, "critic_loss": 0.3887969114035368, "actor_loss": -29.095917778015135, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.81797742843628, "step": 97000}
{"episode_reward": 131.57830761819804, "episode": 98.0, "batch_reward": 0.23065157276391984, "critic_loss": 0.3809311760365963, "actor_loss": -29.214387718200683, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.79990553855896, "step": 98000}
{"episode_reward": 218.5022872037083, "episode": 99.0, "batch_reward": 0.23112082113325597, "critic_loss": 0.39839004614949225, "actor_loss": -29.20531188964844, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.7822105884552, "step": 99000}
{"episode_reward": 307.6244232946996, "episode": 100.0, "batch_reward": 0.2303255804479122, "critic_loss": 0.4273071703016758, "actor_loss": -29.148483030319213, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.810048580169678, "step": 100000}
{"episode_reward": 203.79222368556546, "episode": 101.0, "batch_reward": 0.23062954495847227, "critic_loss": 0.42543445071578023, "actor_loss": -28.81208459854126, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.07809662818909, "step": 101000}
{"episode_reward": 171.66105623468047, "episode": 102.0, "batch_reward": 0.22987383949756623, "critic_loss": 0.4847399944961071, "actor_loss": -29.432433628082276, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.809680938720703, "step": 102000}
{"episode_reward": 119.42148372035724, "episode": 103.0, "batch_reward": 0.22938920153677464, "critic_loss": 0.49708628173172476, "actor_loss": -28.671451278686522, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.797109842300415, "step": 103000}
{"episode_reward": 263.1468473829115, "episode": 104.0, "batch_reward": 0.22967583686113358, "critic_loss": 0.5222361899763346, "actor_loss": -29.30243757247925, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.802177667617798, "step": 104000}
{"episode_reward": 80.58560017456392, "episode": 105.0, "batch_reward": 0.22737900204956532, "critic_loss": 0.49051808822154996, "actor_loss": -28.296738903045654, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.828952074050903, "step": 105000}
{"episode_reward": 237.30647569101853, "episode": 106.0, "batch_reward": 0.22879059663414955, "critic_loss": 0.4972316231280565, "actor_loss": -28.87799569129944, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.776267766952515, "step": 106000}
{"episode_reward": 451.1657071066084, "episode": 107.0, "batch_reward": 0.22936347979307176, "critic_loss": 0.5447960346192121, "actor_loss": -28.93779934692383, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.792093515396118, "step": 107000}
{"episode_reward": 218.93021626947842, "episode": 108.0, "batch_reward": 0.22957919001579286, "critic_loss": 0.5484186788350344, "actor_loss": -28.876078477859497, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.822450876235962, "step": 108000}
{"episode_reward": 276.34955940940466, "episode": 109.0, "batch_reward": 0.23075823529064654, "critic_loss": 0.5563661813437939, "actor_loss": -28.819367889404298, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.80540895462036, "step": 109000}
{"episode_reward": 157.8669507589358, "episode": 110.0, "batch_reward": 0.231138854727149, "critic_loss": 0.637520298153162, "actor_loss": -28.911554943084717, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.788298845291138, "step": 110000}
{"episode_reward": 447.83032833302553, "episode": 111.0, "batch_reward": 0.23327685990929603, "critic_loss": 0.5580568391978741, "actor_loss": -28.67246142578125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.10911560058594, "step": 111000}
{"episode_reward": 479.97057624160516, "episode": 112.0, "batch_reward": 0.2348529672026634, "critic_loss": 0.5881399626284838, "actor_loss": -29.37919717025757, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.807672023773193, "step": 112000}
{"episode_reward": 459.2945603293587, "episode": 113.0, "batch_reward": 0.2368663134276867, "critic_loss": 0.6111845457702875, "actor_loss": -28.823180034637453, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.80301785469055, "step": 113000}
{"episode_reward": 462.31343588547753, "episode": 114.0, "batch_reward": 0.2385320250093937, "critic_loss": 0.6085375088006258, "actor_loss": -29.480817010879516, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.80124521255493, "step": 114000}
{"episode_reward": 492.34204646235503, "episode": 115.0, "batch_reward": 0.24044649508595467, "critic_loss": 0.5732488223165274, "actor_loss": -30.00983151245117, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.805945873260498, "step": 115000}
{"episode_reward": 310.8930138270927, "episode": 116.0, "batch_reward": 0.241845079600811, "critic_loss": 0.5758255556374788, "actor_loss": -29.916939437866212, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.7899067401886, "step": 116000}
{"episode_reward": 435.7296758393762, "episode": 117.0, "batch_reward": 0.24299601651728153, "critic_loss": 0.5639180674403906, "actor_loss": -30.018834709167482, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.8254132270813, "step": 117000}
{"episode_reward": 435.3143830106711, "episode": 118.0, "batch_reward": 0.2447701299637556, "critic_loss": 0.5507821533530951, "actor_loss": -30.08610092163086, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.813703060150146, "step": 118000}
{"episode_reward": 492.67039222064574, "episode": 119.0, "batch_reward": 0.24585706861317158, "critic_loss": 0.5764874570816755, "actor_loss": -30.242302349090576, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.77636742591858, "step": 119000}
{"episode_reward": 480.8157376581016, "episode": 120.0, "batch_reward": 0.24774518302083015, "critic_loss": 0.6267471823841333, "actor_loss": -30.691528339385986, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.800044298171997, "step": 120000}
{"episode_reward": 259.3800973561286, "episode": 121.0, "batch_reward": 0.24932310891151427, "critic_loss": 0.6304096928685904, "actor_loss": -30.672004276275636, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.080111026763916, "step": 121000}
{"episode_reward": 479.8971446902355, "episode": 122.0, "batch_reward": 0.25087871301174164, "critic_loss": 0.6012083089947701, "actor_loss": -31.143858337402342, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.801862239837646, "step": 122000}
{"episode_reward": 510.42622893902046, "episode": 123.0, "batch_reward": 0.25295888191461563, "critic_loss": 0.6236119482815266, "actor_loss": -31.37432473373413, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.82184338569641, "step": 123000}
{"episode_reward": 256.6028964476933, "episode": 124.0, "batch_reward": 0.2527530058175325, "critic_loss": 0.5620495828539133, "actor_loss": -31.217583499908446, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.78309655189514, "step": 124000}
{"episode_reward": 478.3758898997168, "episode": 125.0, "batch_reward": 0.2549120056182146, "critic_loss": 0.5371595153510571, "actor_loss": -31.496308902740477, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.781144857406616, "step": 125000}
{"episode_reward": 478.5755363577489, "episode": 126.0, "batch_reward": 0.25606267277896405, "critic_loss": 0.6335781739205122, "actor_loss": -31.820644866943358, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.80657958984375, "step": 126000}
{"episode_reward": 199.94673937728925, "episode": 127.0, "batch_reward": 0.25639771273732187, "critic_loss": 0.6186308424174786, "actor_loss": -31.302068477630616, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.797603368759155, "step": 127000}
{"episode_reward": 487.30639486571334, "episode": 128.0, "batch_reward": 0.2569785842448473, "critic_loss": 0.6502784520238638, "actor_loss": -31.34977202987671, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.80354380607605, "step": 128000}
{"episode_reward": 482.87211479224106, "episode": 129.0, "batch_reward": 0.25878987500071526, "critic_loss": 0.6875809121578932, "actor_loss": -31.664043300628663, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.81043815612793, "step": 129000}
{"episode_reward": 218.37519118969507, "episode": 130.0, "batch_reward": 0.2602948214113712, "critic_loss": 0.6495814024657011, "actor_loss": -31.7845099067688, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.800668239593506, "step": 130000}
{"episode_reward": 483.2514655872612, "episode": 131.0, "batch_reward": 0.2606253008246422, "critic_loss": 0.6708470136672259, "actor_loss": -31.09898364639282, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.08931922912598, "step": 131000}
{"episode_reward": 264.52823435105375, "episode": 132.0, "batch_reward": 0.26091698852181433, "critic_loss": 0.6507687791734934, "actor_loss": -31.502581317901612, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.82770609855652, "step": 132000}
{"episode_reward": 488.9757438950584, "episode": 133.0, "batch_reward": 0.2628537004441023, "critic_loss": 0.6395805434882641, "actor_loss": -32.167941772460935, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.78132724761963, "step": 133000}
{"episode_reward": 451.6464790127539, "episode": 134.0, "batch_reward": 0.2646813382804394, "critic_loss": 0.7210434998571873, "actor_loss": -32.46503734588623, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.798560857772827, "step": 134000}
{"episode_reward": 503.4949036786276, "episode": 135.0, "batch_reward": 0.2652883428484201, "critic_loss": 0.5964042839705944, "actor_loss": -32.38809100341797, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.810293436050415, "step": 135000}
{"episode_reward": 462.4457816206268, "episode": 136.0, "batch_reward": 0.26673805025219915, "critic_loss": 0.6444548353552818, "actor_loss": -32.75667153549195, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.806694507598877, "step": 136000}
{"episode_reward": 452.13750950738284, "episode": 137.0, "batch_reward": 0.26976131500303746, "critic_loss": 0.6708298160433769, "actor_loss": -32.94167102432251, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.781864404678345, "step": 137000}
{"episode_reward": 454.8302147498466, "episode": 138.0, "batch_reward": 0.27019131600856783, "critic_loss": 0.6271432628184557, "actor_loss": -32.37375224685669, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.801889181137085, "step": 138000}
{"episode_reward": 500.158480911024, "episode": 139.0, "batch_reward": 0.27275689178705215, "critic_loss": 0.6345222981274128, "actor_loss": -32.15038733673096, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.80274987220764, "step": 139000}
{"episode_reward": 504.5252054946323, "episode": 140.0, "batch_reward": 0.27360581466555595, "critic_loss": 0.5298601299971342, "actor_loss": -32.447833728790286, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.805928468704224, "step": 140000}
{"episode_reward": 480.84809914063726, "episode": 141.0, "batch_reward": 0.2753293971270323, "critic_loss": 0.5421453944444656, "actor_loss": -33.08091239929199, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.0801842212677, "step": 141000}
{"episode_reward": 498.3466592352595, "episode": 142.0, "batch_reward": 0.2778841003924608, "critic_loss": 0.5317825804203749, "actor_loss": -33.26262999343872, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.826179265975952, "step": 142000}
{"episode_reward": 486.0013087468676, "episode": 143.0, "batch_reward": 0.27752528309822083, "critic_loss": 0.5736474419236183, "actor_loss": -33.67940711975098, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.8071186542511, "step": 143000}
{"episode_reward": 344.4975569918256, "episode": 144.0, "batch_reward": 0.27891681768000126, "critic_loss": 0.5396111532002688, "actor_loss": -33.44265552139282, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.796589374542236, "step": 144000}
{"episode_reward": 324.5791233823272, "episode": 145.0, "batch_reward": 0.2783930891603231, "critic_loss": 0.5828622304648161, "actor_loss": -34.17597431182861, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.77915048599243, "step": 145000}
{"episode_reward": 139.4126193699289, "episode": 146.0, "batch_reward": 0.2759853471964598, "critic_loss": 0.6039977426528931, "actor_loss": -32.897571891784665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.815505743026733, "step": 146000}
{"episode_reward": 157.3196578752937, "episode": 147.0, "batch_reward": 0.2772554945498705, "critic_loss": 0.6233512584269046, "actor_loss": -33.02369694137573, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.77785563468933, "step": 147000}
{"episode_reward": 448.637520805073, "episode": 148.0, "batch_reward": 0.27872750271856783, "critic_loss": 0.6066479762792587, "actor_loss": -33.3886137008667, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.829830646514893, "step": 148000}
{"episode_reward": 485.3649799684337, "episode": 149.0, "batch_reward": 0.27912740272283554, "critic_loss": 0.6382827392965555, "actor_loss": -33.58556069183349, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.806070566177368, "step": 149000}
{"episode_reward": 476.7348484743502, "episode": 150.0, "batch_reward": 0.28105939719080925, "critic_loss": 0.6391870411932469, "actor_loss": -33.549851680755616, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
