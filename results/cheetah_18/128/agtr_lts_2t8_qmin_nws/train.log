{"episode_reward": 0.0, "episode": 1.0, "duration": 13.864819288253784, "step": 1000}
{"episode_reward": 4.20996189079657, "episode": 2.0, "duration": 1.222487211227417, "step": 2000}
{"episode_reward": 252.2457487418515, "episode": 3.0, "batch_reward": 0.12272445397670764, "critic_loss": 0.09259671023629155, "actor_loss": -27.938243699716587, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 73.63652300834656, "step": 3000}
{"episode_reward": 22.60156778994711, "episode": 4.0, "batch_reward": 0.0808620444610715, "critic_loss": 0.05056486796960235, "actor_loss": -24.014384843826296, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.250629901885986, "step": 4000}
{"episode_reward": 2.899321644100878, "episode": 5.0, "batch_reward": 0.0631250503603369, "critic_loss": 0.05061363391764462, "actor_loss": -23.655783628463745, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.83698797225952, "step": 5000}
{"episode_reward": 3.640777890458261, "episode": 6.0, "batch_reward": 0.05287818183377385, "critic_loss": 0.0476602070722729, "actor_loss": -23.683364448547362, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.47930073738098, "step": 6000}
{"episode_reward": 8.689444067703413, "episode": 7.0, "batch_reward": 0.05059949367679656, "critic_loss": 0.08431838142499327, "actor_loss": -24.29605178451538, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.383911609649658, "step": 7000}
{"episode_reward": 64.09137365431465, "episode": 8.0, "batch_reward": 0.0508288953024894, "critic_loss": 0.1055497733950615, "actor_loss": -20.504813064575195, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.972936153411865, "step": 8000}
{"episode_reward": 42.6681082857001, "episode": 9.0, "batch_reward": 0.051726997694000604, "critic_loss": 0.1209388044551015, "actor_loss": -21.166112354278564, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.52268695831299, "step": 9000}
{"episode_reward": 78.82934418218551, "episode": 10.0, "batch_reward": 0.057147358793765306, "critic_loss": 0.1221871904656291, "actor_loss": -19.887897519111633, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.23780369758606, "step": 10000}
{"episode_reward": 103.21015556434564, "episode": 11.0, "batch_reward": 0.057992021841928365, "critic_loss": 0.11634667478129268, "actor_loss": -20.830755799293517, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.22316551208496, "step": 11000}
{"episode_reward": 43.710901801113735, "episode": 12.0, "batch_reward": 0.058664733830839394, "critic_loss": 0.09878718013688922, "actor_loss": -17.85225322341919, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.567158937454224, "step": 12000}
{"episode_reward": 57.76713761612379, "episode": 13.0, "batch_reward": 0.06118925127387047, "critic_loss": 0.09921987745910883, "actor_loss": -17.784312700271606, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.386931657791138, "step": 13000}
{"episode_reward": 104.73790060609903, "episode": 14.0, "batch_reward": 0.06403740881383418, "critic_loss": 0.09941337582096457, "actor_loss": -15.780123605251312, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.861942768096924, "step": 14000}
{"episode_reward": 113.2689246392722, "episode": 15.0, "batch_reward": 0.06679233472049237, "critic_loss": 0.10205341248586774, "actor_loss": -16.6166233921051, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.556795835494995, "step": 15000}
{"episode_reward": 85.55952611971628, "episode": 16.0, "batch_reward": 0.06866454838961362, "critic_loss": 0.10215246936678886, "actor_loss": -15.76041983985901, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.105943202972412, "step": 16000}
{"episode_reward": 88.12378698957974, "episode": 17.0, "batch_reward": 0.07002095891535282, "critic_loss": 0.09666222091577947, "actor_loss": -14.77433775138855, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.39173460006714, "step": 17000}
{"episode_reward": 83.24906744915535, "episode": 18.0, "batch_reward": 0.0693471455425024, "critic_loss": 0.1311103832796216, "actor_loss": -13.343285783529282, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.30613398551941, "step": 18000}
{"episode_reward": 69.82133204922299, "episode": 19.0, "batch_reward": 0.06834873690083623, "critic_loss": 0.15362967448681594, "actor_loss": -14.111478050619365, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.27678680419922, "step": 19000}
{"episode_reward": 46.10630842157869, "episode": 20.0, "batch_reward": 0.06715411904081703, "critic_loss": 0.18470823819935323, "actor_loss": -13.164790575370192, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.46000909805298, "step": 20000}
{"episode_reward": 45.997152764260484, "episode": 21.0, "batch_reward": 0.06641087310016155, "critic_loss": 0.18495139786973597, "actor_loss": -13.099484306439757, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.462610483169556, "step": 21000}
{"episode_reward": 57.08745373759675, "episode": 22.0, "batch_reward": 0.06518698040768504, "critic_loss": 0.17721884610503913, "actor_loss": -12.07830024291575, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.317010402679443, "step": 22000}
{"episode_reward": 33.82477962795154, "episode": 23.0, "batch_reward": 0.06454231386817992, "critic_loss": 0.21752655587345363, "actor_loss": -12.438545396395028, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.88492488861084, "step": 23000}
{"episode_reward": 49.755623487827556, "episode": 24.0, "batch_reward": 0.06538710681721568, "critic_loss": 0.23197809363901614, "actor_loss": -12.795322457790375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.22694492340088, "step": 24000}
{"episode_reward": 97.2150926952408, "episode": 25.0, "batch_reward": 0.06612565159052611, "critic_loss": 0.2750030420050025, "actor_loss": -11.643989736258984, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.260428190231323, "step": 25000}
{"episode_reward": 94.88138514918897, "episode": 26.0, "batch_reward": 0.0666195453889668, "critic_loss": 0.28918318890035155, "actor_loss": -12.325202030539513, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.84113621711731, "step": 26000}
{"episode_reward": 51.01572194144901, "episode": 27.0, "batch_reward": 0.06622658726200462, "critic_loss": 0.25502743195742367, "actor_loss": -11.865415506482124, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.5460147857666, "step": 27000}
{"episode_reward": 75.25347777342921, "episode": 28.0, "batch_reward": 0.0678939988091588, "critic_loss": 0.2541106043830514, "actor_loss": -11.390843863248826, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.98299813270569, "step": 28000}
{"episode_reward": 105.03608534378299, "episode": 29.0, "batch_reward": 0.06917435529083013, "critic_loss": 0.22926329785585403, "actor_loss": -11.695477380037307, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.987910747528076, "step": 29000}
{"episode_reward": 205.773195857463, "episode": 30.0, "batch_reward": 0.0725465098284185, "critic_loss": 0.2210013621672988, "actor_loss": -12.534009759426118, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.629276275634766, "step": 30000}
{"episode_reward": 66.55764211555946, "episode": 31.0, "batch_reward": 0.07342427648976445, "critic_loss": 0.2164244670048356, "actor_loss": -11.58568696975708, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.317734241485596, "step": 31000}
{"episode_reward": 83.9627076785876, "episode": 32.0, "batch_reward": 0.07429725840687752, "critic_loss": 0.21334136892855168, "actor_loss": -11.65123364019394, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.293606519699097, "step": 32000}
{"episode_reward": 150.21638262644788, "episode": 33.0, "batch_reward": 0.07466548086702823, "critic_loss": 0.19707265055924655, "actor_loss": -11.245806042194367, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.006439685821533, "step": 33000}
{"episode_reward": 41.77750332527146, "episode": 34.0, "batch_reward": 0.07508643354848027, "critic_loss": 0.19290746166557074, "actor_loss": -11.194207074165345, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.275681734085083, "step": 34000}
{"episode_reward": 98.48106893625096, "episode": 35.0, "batch_reward": 0.07449663147702813, "critic_loss": 0.2095562117472291, "actor_loss": -12.201627876758575, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.369093656539917, "step": 35000}
{"episode_reward": 51.12177190235485, "episode": 36.0, "batch_reward": 0.07485022307187318, "critic_loss": 0.2044077305458486, "actor_loss": -11.277211947441101, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.175320148468018, "step": 36000}
{"episode_reward": 84.35603473424293, "episode": 37.0, "batch_reward": 0.07522624112665653, "critic_loss": 0.1867009099125862, "actor_loss": -11.689536007881165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.593127965927124, "step": 37000}
{"episode_reward": 82.71696989482086, "episode": 38.0, "batch_reward": 0.07752325526997447, "critic_loss": 0.2560974149033427, "actor_loss": -11.861062957763671, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.20265531539917, "step": 38000}
{"episode_reward": 219.23256615461355, "episode": 39.0, "batch_reward": 0.08008087939396501, "critic_loss": 0.19821510082483293, "actor_loss": -11.43595063304901, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.96788454055786, "step": 39000}
{"episode_reward": 157.9376164746691, "episode": 40.0, "batch_reward": 0.08273833949118853, "critic_loss": 0.24827479138970376, "actor_loss": -11.294291207313538, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.718018293380737, "step": 40000}
{"episode_reward": 158.5804394553171, "episode": 41.0, "batch_reward": 0.085756810169667, "critic_loss": 0.2322146779447794, "actor_loss": -12.073326706886292, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.27043318748474, "step": 41000}
{"episode_reward": 305.03858038627465, "episode": 42.0, "batch_reward": 0.08926625792309642, "critic_loss": 0.22092369642853737, "actor_loss": -12.236240961074829, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.62697720527649, "step": 42000}
{"episode_reward": 132.70783491921856, "episode": 43.0, "batch_reward": 0.0908104011528194, "critic_loss": 0.304745704241097, "actor_loss": -12.149173162460327, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.14599061012268, "step": 43000}
{"episode_reward": 218.67015874858788, "episode": 44.0, "batch_reward": 0.0941102096401155, "critic_loss": 0.28470183616131545, "actor_loss": -12.818366541862488, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.452252864837646, "step": 44000}
{"episode_reward": 121.63829409152144, "episode": 45.0, "batch_reward": 0.09341879059374332, "critic_loss": 0.2739732659831643, "actor_loss": -13.159506330490112, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.531168222427368, "step": 45000}
{"episode_reward": 94.8495864181267, "episode": 46.0, "batch_reward": 0.09346571470052004, "critic_loss": 0.2370452535301447, "actor_loss": -12.942374997138977, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.222484588623047, "step": 46000}
{"episode_reward": 92.43679437513718, "episode": 47.0, "batch_reward": 0.09434105698019266, "critic_loss": 0.25496465504914523, "actor_loss": -13.196555583953858, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.6478054523468, "step": 47000}
{"episode_reward": 142.25841450528202, "episode": 48.0, "batch_reward": 0.0950507038384676, "critic_loss": 0.272745355039835, "actor_loss": -13.206205432891846, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.789020538330078, "step": 48000}
{"episode_reward": 257.95584356781256, "episode": 49.0, "batch_reward": 0.09942501974478364, "critic_loss": 0.27459353075921533, "actor_loss": -13.298255388259888, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.918204069137573, "step": 49000}
{"episode_reward": 193.22369728153083, "episode": 50.0, "batch_reward": 0.10103468505293131, "critic_loss": 0.2813612659648061, "actor_loss": -13.618453378677367, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.67769503593445, "step": 50000}
{"episode_reward": 286.0160874652294, "episode": 51.0, "batch_reward": 0.10476613437384368, "critic_loss": 0.29204726541042325, "actor_loss": -13.752357038497925, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.301347732543945, "step": 51000}
{"episode_reward": 366.90815308409094, "episode": 52.0, "batch_reward": 0.1111358314231038, "critic_loss": 0.3094233765974641, "actor_loss": -14.633615566253662, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.32263994216919, "step": 52000}
{"episode_reward": 365.9933923590868, "episode": 53.0, "batch_reward": 0.1159021443426609, "critic_loss": 0.29045328537374737, "actor_loss": -15.11825358390808, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.187107801437378, "step": 53000}
{"episode_reward": 421.58336044413124, "episode": 54.0, "batch_reward": 0.12125640378147363, "critic_loss": 0.28395569436252116, "actor_loss": -15.565017749786376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.480540990829468, "step": 54000}
{"episode_reward": 432.9868502057403, "episode": 55.0, "batch_reward": 0.12637577306479217, "critic_loss": 0.27585159873217346, "actor_loss": -15.938652410507203, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.55272603034973, "step": 55000}
{"episode_reward": 343.28022243727656, "episode": 56.0, "batch_reward": 0.13052110821008683, "critic_loss": 0.2932672252804041, "actor_loss": -16.430898355484008, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.65548610687256, "step": 56000}
{"episode_reward": 289.942514948402, "episode": 57.0, "batch_reward": 0.13309378949552775, "critic_loss": 0.2913300142735243, "actor_loss": -16.805341009140015, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.568331480026245, "step": 57000}
{"episode_reward": 384.784253812446, "episode": 58.0, "batch_reward": 0.13831828586012124, "critic_loss": 0.31016343148052694, "actor_loss": -17.20527141189575, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.91729736328125, "step": 58000}
{"episode_reward": 454.0121977629042, "episode": 59.0, "batch_reward": 0.1442391323968768, "critic_loss": 0.30782347893714906, "actor_loss": -17.81087819480896, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.793903827667236, "step": 59000}
{"episode_reward": 485.4810644261126, "episode": 60.0, "batch_reward": 0.14717924849689007, "critic_loss": 0.32106437012553213, "actor_loss": -18.84057092666626, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.74288558959961, "step": 60000}
{"episode_reward": 212.4381835045102, "episode": 61.0, "batch_reward": 0.15018072164803745, "critic_loss": 0.342028927333653, "actor_loss": -19.716695497512816, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.57701110839844, "step": 61000}
{"episode_reward": 471.8882472029951, "episode": 62.0, "batch_reward": 0.1564902193620801, "critic_loss": 0.3060587486848235, "actor_loss": -20.385511966705323, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.60378932952881, "step": 62000}
{"episode_reward": 515.5536614830878, "episode": 63.0, "batch_reward": 0.16245190795511008, "critic_loss": 0.2995685145109892, "actor_loss": -20.800344217300417, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.270422220230103, "step": 63000}
{"episode_reward": 424.9118336815008, "episode": 64.0, "batch_reward": 0.1660638834834099, "critic_loss": 0.2906729882135987, "actor_loss": -21.334240184783937, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.265038013458252, "step": 64000}
{"episode_reward": 474.218475950933, "episode": 65.0, "batch_reward": 0.17029114356637, "critic_loss": 0.2757549875751138, "actor_loss": -21.83302081680298, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.726266384124756, "step": 65000}
{"episode_reward": 459.91023211503136, "episode": 66.0, "batch_reward": 0.1752251183912158, "critic_loss": 0.288794184692204, "actor_loss": -22.310707809448243, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.29796838760376, "step": 66000}
{"episode_reward": 529.4077317607693, "episode": 67.0, "batch_reward": 0.17781440436840057, "critic_loss": 0.3026273836493492, "actor_loss": -22.677518947601317, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.31864285469055, "step": 67000}
{"episode_reward": 125.61899900512843, "episode": 68.0, "batch_reward": 0.17846605002135038, "critic_loss": 0.28326622990518807, "actor_loss": -22.73571660232544, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.063249111175537, "step": 68000}
{"episode_reward": 188.02779551708272, "episode": 69.0, "batch_reward": 0.18033179957419634, "critic_loss": 0.2645800101682544, "actor_loss": -22.9654100189209, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.188032388687134, "step": 69000}
{"episode_reward": 524.6550494857178, "episode": 70.0, "batch_reward": 0.18498500378429888, "critic_loss": 0.29254310435801745, "actor_loss": -23.26218659210205, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.46183133125305, "step": 70000}
{"episode_reward": 490.0149040984156, "episode": 71.0, "batch_reward": 0.1901143930852413, "critic_loss": 0.2907482785061002, "actor_loss": -23.579180324554443, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.38507962226868, "step": 71000}
{"episode_reward": 523.4886176524374, "episode": 72.0, "batch_reward": 0.1938032400459051, "critic_loss": 0.27497188388556243, "actor_loss": -23.81184591293335, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.68568515777588, "step": 72000}
{"episode_reward": 476.4401408677107, "episode": 73.0, "batch_reward": 0.19814357219636441, "critic_loss": 0.28771134206652643, "actor_loss": -24.366682498931883, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.178609132766724, "step": 73000}
{"episode_reward": 494.93142788620105, "episode": 74.0, "batch_reward": 0.19866635270416735, "critic_loss": 0.285748125217855, "actor_loss": -24.427911865234375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.237729787826538, "step": 74000}
{"episode_reward": 61.80304592273597, "episode": 75.0, "batch_reward": 0.20032762916386126, "critic_loss": 0.2959185094758868, "actor_loss": -24.13696671295166, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.723821878433228, "step": 75000}
{"episode_reward": 533.8858447109367, "episode": 76.0, "batch_reward": 0.20525573681294917, "critic_loss": 0.29825472132116554, "actor_loss": -24.66170014190674, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.186325311660767, "step": 76000}
{"episode_reward": 554.8153974896597, "episode": 77.0, "batch_reward": 0.2100618636906147, "critic_loss": 0.2994754869863391, "actor_loss": -25.162941291809084, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.51915407180786, "step": 77000}
{"episode_reward": 532.9055219958923, "episode": 78.0, "batch_reward": 0.21183237132430077, "critic_loss": 0.2978721809536219, "actor_loss": -25.3613572845459, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.721414804458618, "step": 78000}
{"episode_reward": 139.04028740581282, "episode": 79.0, "batch_reward": 0.21290909001231192, "critic_loss": 0.35007481307536364, "actor_loss": -25.24717070388794, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.014975786209106, "step": 79000}
{"episode_reward": 520.3477677984866, "episode": 80.0, "batch_reward": 0.2165007749646902, "critic_loss": 0.2759668165370822, "actor_loss": -25.532929447174073, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.141076803207397, "step": 80000}
{"episode_reward": 572.0083797013958, "episode": 81.0, "batch_reward": 0.2203838562965393, "critic_loss": 0.3244871869832277, "actor_loss": -25.865799369812013, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.52375292778015, "step": 81000}
{"episode_reward": 509.63144995229555, "episode": 82.0, "batch_reward": 0.22339298087358475, "critic_loss": 0.3163875625804067, "actor_loss": -26.24936512374878, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.264816522598267, "step": 82000}
{"episode_reward": 516.2161245646713, "episode": 83.0, "batch_reward": 0.22875133337080478, "critic_loss": 0.32068294885754584, "actor_loss": -26.457747837066652, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.410320520401, "step": 83000}
{"episode_reward": 546.6656407239564, "episode": 84.0, "batch_reward": 0.23096608598530294, "critic_loss": 0.3116767799109221, "actor_loss": -26.86739884185791, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.57035803794861, "step": 84000}
{"episode_reward": 518.5042548257098, "episode": 85.0, "batch_reward": 0.23487645655870437, "critic_loss": 0.3561312234699726, "actor_loss": -26.976692104339598, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.937813758850098, "step": 85000}
{"episode_reward": 508.51390626742904, "episode": 86.0, "batch_reward": 0.23702621938288213, "critic_loss": 0.40175530524551867, "actor_loss": -27.293981357574463, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.49326992034912, "step": 86000}
{"episode_reward": 546.3062407864631, "episode": 87.0, "batch_reward": 0.240990000680089, "critic_loss": 0.40174174673855306, "actor_loss": -27.756988994598387, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.772486925125122, "step": 87000}
{"episode_reward": 506.83243965978005, "episode": 88.0, "batch_reward": 0.24494217666983603, "critic_loss": 0.41149775474518535, "actor_loss": -28.170211559295655, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.982625484466553, "step": 88000}
{"episode_reward": 530.9962287049328, "episode": 89.0, "batch_reward": 0.24673936021327972, "critic_loss": 0.4741059731990099, "actor_loss": -28.40243423080444, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.101906299591064, "step": 89000}
{"episode_reward": 265.75493619456034, "episode": 90.0, "batch_reward": 0.2486604450941086, "critic_loss": 0.6229019465297461, "actor_loss": -29.15877471923828, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.345749855041504, "step": 90000}
{"episode_reward": 532.8915121628304, "episode": 91.0, "batch_reward": 0.2508867857903242, "critic_loss": 0.7351298094391823, "actor_loss": -29.866081993103027, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.72519636154175, "step": 91000}
{"episode_reward": 574.8192244491394, "episode": 92.0, "batch_reward": 0.2539809850156307, "critic_loss": 0.7256618910431862, "actor_loss": -31.526964481353758, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.45081853866577, "step": 92000}
{"episode_reward": 552.232569609778, "episode": 93.0, "batch_reward": 0.25750148360431196, "critic_loss": 0.6482727449536324, "actor_loss": -32.712150482177734, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.313365697860718, "step": 93000}
{"episode_reward": 380.09712659994983, "episode": 94.0, "batch_reward": 0.25768246354162694, "critic_loss": 0.6724042484015227, "actor_loss": -33.65012337875366, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.43498969078064, "step": 94000}
{"episode_reward": 20.91591373706409, "episode": 95.0, "batch_reward": 0.25274285113811495, "critic_loss": 0.6570353019535542, "actor_loss": -34.33337535858154, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.19654870033264, "step": 95000}
{"episode_reward": 16.309570794586353, "episode": 96.0, "batch_reward": 0.2516824503391981, "critic_loss": 0.6443402492105961, "actor_loss": -34.91785873031616, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.1995210647583, "step": 96000}
{"episode_reward": 12.20743574260078, "episode": 97.0, "batch_reward": 0.24841301327943802, "critic_loss": 0.6223606060892344, "actor_loss": -35.30125225830078, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.4919753074646, "step": 97000}
{"episode_reward": 15.7675452824228, "episode": 98.0, "batch_reward": 0.24739675535261632, "critic_loss": 0.5363420729935169, "actor_loss": -35.58561819076538, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.951784372329712, "step": 98000}
{"episode_reward": 12.143836263174032, "episode": 99.0, "batch_reward": 0.2443358867317438, "critic_loss": 0.45618639515340326, "actor_loss": -35.55467449951172, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.472113847732544, "step": 99000}
{"episode_reward": 17.401604910150844, "episode": 100.0, "batch_reward": 0.24171704584360124, "critic_loss": 0.4519531183242798, "actor_loss": -35.56193909072876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.27048373222351, "step": 100000}
{"episode_reward": 20.199380820425795, "episode": 101.0, "batch_reward": 0.2404040226638317, "critic_loss": 0.46075298312306406, "actor_loss": -35.62339037322998, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.554099321365356, "step": 101000}
{"episode_reward": 26.002592152828754, "episode": 102.0, "batch_reward": 0.23836818605661392, "critic_loss": 0.4106781144887209, "actor_loss": -35.50185639953613, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.311278820037842, "step": 102000}
{"episode_reward": 33.605922322523355, "episode": 103.0, "batch_reward": 0.2364892530441284, "critic_loss": 0.3397677367180586, "actor_loss": -35.24934068679809, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.633361339569092, "step": 103000}
{"episode_reward": 25.356711837301734, "episode": 104.0, "batch_reward": 0.23412859934568406, "critic_loss": 0.3101589217931032, "actor_loss": -34.93334722900391, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.76712441444397, "step": 104000}
{"episode_reward": 27.170347614270007, "episode": 105.0, "batch_reward": 0.23176610031723976, "critic_loss": 0.28418364336341617, "actor_loss": -34.53480544662476, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.441387176513672, "step": 105000}
{"episode_reward": 101.40257969869312, "episode": 106.0, "batch_reward": 0.23154043707251548, "critic_loss": 0.25082979555428025, "actor_loss": -34.18598288726807, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.36380624771118, "step": 106000}
{"episode_reward": 177.12510937342526, "episode": 107.0, "batch_reward": 0.23145523780584334, "critic_loss": 0.2585429811105132, "actor_loss": -33.807533988952635, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.453536987304688, "step": 107000}
{"episode_reward": 449.7785987321704, "episode": 108.0, "batch_reward": 0.23281861881911756, "critic_loss": 0.2619949600994587, "actor_loss": -33.532296905517576, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.640979766845703, "step": 108000}
{"episode_reward": 360.09612738439, "episode": 109.0, "batch_reward": 0.23529125215113164, "critic_loss": 0.28998802953958513, "actor_loss": -33.23474378204346, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.610921382904053, "step": 109000}
{"episode_reward": 160.86353585250117, "episode": 110.0, "batch_reward": 0.23401815882325172, "critic_loss": 0.34659612526744604, "actor_loss": -32.889612796783446, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.792736768722534, "step": 110000}
{"episode_reward": 476.9191373894205, "episode": 111.0, "batch_reward": 0.23765068985521792, "critic_loss": 0.3885957348048687, "actor_loss": -32.73975150680542, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.56900978088379, "step": 111000}
{"episode_reward": 538.5296307815462, "episode": 112.0, "batch_reward": 0.24042481315135955, "critic_loss": 0.4934034735709429, "actor_loss": -32.715910732269286, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.463302850723267, "step": 112000}
{"episode_reward": 553.0164918130454, "episode": 113.0, "batch_reward": 0.24312195217609406, "critic_loss": 0.5064599141478539, "actor_loss": -32.74168711090088, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.664318323135376, "step": 113000}
{"episode_reward": 410.1321242246393, "episode": 114.0, "batch_reward": 0.24294234023988248, "critic_loss": 0.5985113506168127, "actor_loss": -32.84355918502808, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.776294231414795, "step": 114000}
{"episode_reward": 223.66820190275786, "episode": 115.0, "batch_reward": 0.24391749961674214, "critic_loss": 0.6080070808529854, "actor_loss": -32.95292601776123, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.216466426849365, "step": 115000}
{"episode_reward": 415.6517430640303, "episode": 116.0, "batch_reward": 0.24484840597212315, "critic_loss": 0.5645233631581068, "actor_loss": -33.138757526397704, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.557575225830078, "step": 116000}
{"episode_reward": 423.81822019753395, "episode": 117.0, "batch_reward": 0.24719085846841335, "critic_loss": 0.535007477119565, "actor_loss": -33.66199817276001, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.439293384552002, "step": 117000}
{"episode_reward": 391.6671562734784, "episode": 118.0, "batch_reward": 0.24699284407496452, "critic_loss": 0.516613642424345, "actor_loss": -33.8851650390625, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.162620782852173, "step": 118000}
{"episode_reward": 380.83187897509873, "episode": 119.0, "batch_reward": 0.24781169439852238, "critic_loss": 0.44920985542237757, "actor_loss": -34.112219261169436, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.371236085891724, "step": 119000}
{"episode_reward": 296.2954342074835, "episode": 120.0, "batch_reward": 0.24866558706760405, "critic_loss": 0.4563154964894056, "actor_loss": -34.259998378753664, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.26783800125122, "step": 120000}
{"episode_reward": 457.4011540496166, "episode": 121.0, "batch_reward": 0.25003852988779546, "critic_loss": 0.43369371227920056, "actor_loss": -34.37822381973267, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.76181173324585, "step": 121000}
{"episode_reward": 10.848412227231211, "episode": 122.0, "batch_reward": 0.24678473311662674, "critic_loss": 0.3977520769238472, "actor_loss": -34.0013797416687, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.298532485961914, "step": 122000}
{"episode_reward": 3.408727936536525, "episode": 123.0, "batch_reward": 0.24618959651887418, "critic_loss": 0.38371386481821534, "actor_loss": -34.060826839447024, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.171086072921753, "step": 123000}
{"episode_reward": 1.78944285569728, "episode": 124.0, "batch_reward": 0.24268045309185982, "critic_loss": 0.33816694559156896, "actor_loss": -33.72677741622925, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.274517059326172, "step": 124000}
{"episode_reward": 2.7708758896488694, "episode": 125.0, "batch_reward": 0.24176564472913742, "critic_loss": 0.33500409399718045, "actor_loss": -33.635584869384765, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.98998522758484, "step": 125000}
{"episode_reward": 2.80492337829335, "episode": 126.0, "batch_reward": 0.23916387136280537, "critic_loss": 0.361657135553658, "actor_loss": -33.33871356582642, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.293169498443604, "step": 126000}
{"episode_reward": 3.0751197197104245, "episode": 127.0, "batch_reward": 0.23853015945851802, "critic_loss": 0.4087182626277208, "actor_loss": -33.303934619903565, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.160536527633667, "step": 127000}
{"episode_reward": 4.6845484124171195, "episode": 128.0, "batch_reward": 0.2378316300213337, "critic_loss": 0.3625936083868146, "actor_loss": -33.129337661743165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.930808305740356, "step": 128000}
{"episode_reward": 557.1466608222352, "episode": 129.0, "batch_reward": 0.24177821405231953, "critic_loss": 0.34135232987999914, "actor_loss": -33.198092067718505, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.29270839691162, "step": 129000}
{"episode_reward": 588.0809007513838, "episode": 130.0, "batch_reward": 0.2437976113408804, "critic_loss": 0.41684508976340295, "actor_loss": -33.26745669937134, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.199671745300293, "step": 130000}
{"episode_reward": 585.7223144834691, "episode": 131.0, "batch_reward": 0.24590253947675228, "critic_loss": 0.36685901211202143, "actor_loss": -33.32748072814941, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.91408634185791, "step": 131000}
{"episode_reward": 569.1026964522532, "episode": 132.0, "batch_reward": 0.247108792334795, "critic_loss": 0.3792125797122717, "actor_loss": -33.08871133804321, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.44614028930664, "step": 132000}
{"episode_reward": 552.6794537017861, "episode": 133.0, "batch_reward": 0.24846431256830692, "critic_loss": 0.38588026221841576, "actor_loss": -33.046188358306885, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.333001613616943, "step": 133000}
{"episode_reward": 534.9405441027608, "episode": 134.0, "batch_reward": 0.25118629720807073, "critic_loss": 0.3785566863194108, "actor_loss": -33.26371906661987, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.70481586456299, "step": 134000}
{"episode_reward": 560.896903921086, "episode": 135.0, "batch_reward": 0.2551307625323534, "critic_loss": 0.3679666614830494, "actor_loss": -33.187700374603274, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.986817121505737, "step": 135000}
{"episode_reward": 594.9489691016923, "episode": 136.0, "batch_reward": 0.2556991326957941, "critic_loss": 0.36928994151204825, "actor_loss": -33.22255586242676, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.70672869682312, "step": 136000}
{"episode_reward": 578.2708984376399, "episode": 137.0, "batch_reward": 0.25953957335650923, "critic_loss": 0.3662923135906458, "actor_loss": -33.623447635650635, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.50162625312805, "step": 137000}
{"episode_reward": 553.8343654422114, "episode": 138.0, "batch_reward": 0.26133443497121334, "critic_loss": 0.38448127497732637, "actor_loss": -33.778588306427004, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.634265184402466, "step": 138000}
{"episode_reward": 545.5481856393801, "episode": 139.0, "batch_reward": 0.26419268813729285, "critic_loss": 0.38312276017665864, "actor_loss": -33.94694067764282, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.241830110549927, "step": 139000}
{"episode_reward": 535.1742401821987, "episode": 140.0, "batch_reward": 0.26521000209450724, "critic_loss": 0.41605870927870275, "actor_loss": -33.939607337951664, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.274689435958862, "step": 140000}
{"episode_reward": 572.2470456991299, "episode": 141.0, "batch_reward": 0.2685397112071514, "critic_loss": 0.4164456867277622, "actor_loss": -34.06401110839844, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.655123233795166, "step": 141000}
{"episode_reward": 577.2135041610725, "episode": 142.0, "batch_reward": 0.27085739715397356, "critic_loss": 0.40685333622992037, "actor_loss": -34.31595580291748, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.965523958206177, "step": 142000}
{"episode_reward": 577.9596649980649, "episode": 143.0, "batch_reward": 0.27214903883636, "critic_loss": 0.3927280695438385, "actor_loss": -34.19051506042481, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.734238386154175, "step": 143000}
{"episode_reward": 573.2950879761506, "episode": 144.0, "batch_reward": 0.2761354258209467, "critic_loss": 0.40909918788075444, "actor_loss": -34.55676782226563, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.317092895507812, "step": 144000}
{"episode_reward": 571.9009093370204, "episode": 145.0, "batch_reward": 0.2767398649305105, "critic_loss": 0.37825782218575477, "actor_loss": -34.50687281799316, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.266230821609497, "step": 145000}
{"episode_reward": 581.6840057544664, "episode": 146.0, "batch_reward": 0.2791466693878174, "critic_loss": 0.4065737703293562, "actor_loss": -34.916663635253904, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.236282348632812, "step": 146000}
{"episode_reward": 571.1513487254897, "episode": 147.0, "batch_reward": 0.2817713392525911, "critic_loss": 0.390221816457808, "actor_loss": -35.15293677902222, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.475714921951294, "step": 147000}
{"episode_reward": 531.7435392318507, "episode": 148.0, "batch_reward": 0.28217222525179386, "critic_loss": 0.39559148797392846, "actor_loss": -35.08330735397339, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.65798306465149, "step": 148000}
{"episode_reward": 621.7784584023929, "episode": 149.0, "batch_reward": 0.28437967725098134, "critic_loss": 0.37738387179374694, "actor_loss": -35.38759025192261, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.555036067962646, "step": 149000}
{"episode_reward": 587.2319739632951, "episode": 150.0, "batch_reward": 0.2872547052651644, "critic_loss": 0.3802108516544104, "actor_loss": -35.46250963973999, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
