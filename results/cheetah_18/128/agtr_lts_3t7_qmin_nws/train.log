{"episode_reward": 0.0, "episode": 1.0, "duration": 12.94733452796936, "step": 1000}
{"episode_reward": 4.20996189079657, "episode": 2.0, "duration": 1.1045119762420654, "step": 2000}
{"episode_reward": 252.2457487418515, "episode": 3.0, "batch_reward": 0.12255943318870553, "critic_loss": 0.11548772765427241, "actor_loss": -31.723078554894936, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 70.29364824295044, "step": 3000}
{"episode_reward": 52.498557665808185, "episode": 4.0, "batch_reward": 0.10086014767736197, "critic_loss": 0.23259542337805034, "actor_loss": -24.25244223213196, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.39781379699707, "step": 4000}
{"episode_reward": 82.89005937256762, "episode": 5.0, "batch_reward": 0.08946118604019285, "critic_loss": 0.1932992340326309, "actor_loss": -22.38040871810913, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.249512910842896, "step": 5000}
{"episode_reward": 25.38761328720343, "episode": 6.0, "batch_reward": 0.08073703664913774, "critic_loss": 0.16746107607334854, "actor_loss": -22.145128112792968, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.17903184890747, "step": 6000}
{"episode_reward": 46.75286166805281, "episode": 7.0, "batch_reward": 0.07415445762127638, "critic_loss": 0.15151038548350335, "actor_loss": -22.606313552856445, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.379276990890503, "step": 7000}
{"episode_reward": 21.83663747685183, "episode": 8.0, "batch_reward": 0.06555888538062572, "critic_loss": 0.11191212279349566, "actor_loss": -19.419437313079833, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.014765977859497, "step": 8000}
{"episode_reward": 4.732126783960463, "episode": 9.0, "batch_reward": 0.05858325774595141, "critic_loss": 0.08990799749642611, "actor_loss": -21.311213256835938, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.0692081451416, "step": 9000}
{"episode_reward": 7.695457732291336, "episode": 10.0, "batch_reward": 0.052455923343077304, "critic_loss": 0.07138287024572491, "actor_loss": -19.12561449813843, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.46376943588257, "step": 10000}
{"episode_reward": 6.538282151961347, "episode": 11.0, "batch_reward": 0.04764827936701477, "critic_loss": 0.06804314767196774, "actor_loss": -20.309399185180663, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 33.52258348464966, "step": 11000}
{"episode_reward": 11.581023212405558, "episode": 12.0, "batch_reward": 0.04582242037542164, "critic_loss": 0.0635062918420881, "actor_loss": -17.714285911560058, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.50118112564087, "step": 12000}
{"episode_reward": 17.84922271794617, "episode": 13.0, "batch_reward": 0.04349141421355307, "critic_loss": 0.06710446260869503, "actor_loss": -17.62331880760193, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.269379377365112, "step": 13000}
{"episode_reward": 40.96403636859785, "episode": 14.0, "batch_reward": 0.045337459135800603, "critic_loss": 0.08931627557426691, "actor_loss": -15.165880952835083, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.170005559921265, "step": 14000}
{"episode_reward": 43.78089828568073, "episode": 15.0, "batch_reward": 0.046977002365514636, "critic_loss": 0.09960125090554356, "actor_loss": -14.876321477890015, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.72033405303955, "step": 15000}
{"episode_reward": 86.69128544698286, "episode": 16.0, "batch_reward": 0.047634109104052184, "critic_loss": 0.12744232800230385, "actor_loss": -13.085439947128297, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.441442012786865, "step": 16000}
{"episode_reward": 39.75369461453621, "episode": 17.0, "batch_reward": 0.04889500571414828, "critic_loss": 0.14008758265152574, "actor_loss": -12.695625171661376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.551589965820312, "step": 17000}
{"episode_reward": 122.68298183190608, "episode": 18.0, "batch_reward": 0.05074099596776068, "critic_loss": 0.17077123561501503, "actor_loss": -11.175027265548707, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.507255792617798, "step": 18000}
{"episode_reward": 26.28883351413159, "episode": 19.0, "batch_reward": 0.05023009310476482, "critic_loss": 0.13174772819131614, "actor_loss": -11.758228982925415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.1655056476593, "step": 19000}
{"episode_reward": 47.80441627403421, "episode": 20.0, "batch_reward": 0.05204323311336338, "critic_loss": 0.16027263703197242, "actor_loss": -10.745345010757447, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.10952138900757, "step": 20000}
{"episode_reward": 114.87688037747047, "episode": 21.0, "batch_reward": 0.053390228971838954, "critic_loss": 0.14632528254762292, "actor_loss": -10.540386129379273, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.45813298225403, "step": 21000}
{"episode_reward": 50.85832179005437, "episode": 22.0, "batch_reward": 0.05378371094726026, "critic_loss": 0.16636806028708814, "actor_loss": -9.017001913070679, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.89167618751526, "step": 22000}
{"episode_reward": 85.54791688382619, "episode": 23.0, "batch_reward": 0.05476713812164962, "critic_loss": 0.18343720012903214, "actor_loss": -9.751748435974122, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.68422555923462, "step": 23000}
{"episode_reward": 56.43801768781132, "episode": 24.0, "batch_reward": 0.054414195157587525, "critic_loss": 0.17844712122529746, "actor_loss": -9.985844458580017, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.00121259689331, "step": 24000}
{"episode_reward": 41.109300244941444, "episode": 25.0, "batch_reward": 0.05286575959436596, "critic_loss": 0.17146824432164431, "actor_loss": -8.011869881629943, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.69390559196472, "step": 25000}
{"episode_reward": 27.014514552297385, "episode": 26.0, "batch_reward": 0.05304665201716125, "critic_loss": 0.17562697995454074, "actor_loss": -9.2161366853714, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.692220449447632, "step": 26000}
{"episode_reward": 42.31601065550307, "episode": 27.0, "batch_reward": 0.05536507896706462, "critic_loss": 0.19127696304768324, "actor_loss": -9.019712572097779, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.49861240386963, "step": 27000}
{"episode_reward": 179.43768409869747, "episode": 28.0, "batch_reward": 0.060593193076550964, "critic_loss": 0.17994948142766953, "actor_loss": -8.464132302284241, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.00310778617859, "step": 28000}
{"episode_reward": 169.74000837750316, "episode": 29.0, "batch_reward": 0.06484418968856334, "critic_loss": 0.17370807266235352, "actor_loss": -9.062477222919464, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.260668516159058, "step": 29000}
{"episode_reward": 278.6071865091142, "episode": 30.0, "batch_reward": 0.06958732737228274, "critic_loss": 0.17520932342857123, "actor_loss": -9.719139000594616, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.207456350326538, "step": 30000}
{"episode_reward": 70.1104751457815, "episode": 31.0, "batch_reward": 0.07172057810798288, "critic_loss": 0.18076829690486193, "actor_loss": -9.071552960574627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.75718426704407, "step": 31000}
{"episode_reward": 258.2040200380305, "episode": 32.0, "batch_reward": 0.07804835772141815, "critic_loss": 0.20258906919509173, "actor_loss": -9.991441097915173, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.41001009941101, "step": 32000}
{"episode_reward": 291.63504003348424, "episode": 33.0, "batch_reward": 0.08083082173019647, "critic_loss": 0.210701096072793, "actor_loss": -9.438849474638701, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.595141172409058, "step": 33000}
{"episode_reward": 36.34850071059789, "episode": 34.0, "batch_reward": 0.0821689493842423, "critic_loss": 0.18463175448030233, "actor_loss": -9.553588024795056, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.237095594406128, "step": 34000}
{"episode_reward": 145.2911426304344, "episode": 35.0, "batch_reward": 0.08443193531781434, "critic_loss": 0.18349474276602268, "actor_loss": -10.89813814610243, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.49864888191223, "step": 35000}
{"episode_reward": 177.2653907468544, "episode": 36.0, "batch_reward": 0.0847562745064497, "critic_loss": 0.17012311047315598, "actor_loss": -10.040681416630745, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.390960454940796, "step": 36000}
{"episode_reward": 43.96859263123135, "episode": 37.0, "batch_reward": 0.08742647476866841, "critic_loss": 0.18240453028678894, "actor_loss": -10.425454768419266, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.677944898605347, "step": 37000}
{"episode_reward": 301.998781431954, "episode": 38.0, "batch_reward": 0.09096200992166996, "critic_loss": 0.19610715011507274, "actor_loss": -10.35590603351593, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.72494912147522, "step": 38000}
{"episode_reward": 121.31399308090572, "episode": 39.0, "batch_reward": 0.09269716461747884, "critic_loss": 0.1881110725775361, "actor_loss": -10.051571141719817, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.560611963272095, "step": 39000}
{"episode_reward": 188.7416725035686, "episode": 40.0, "batch_reward": 0.09277630285918713, "critic_loss": 0.2036606255620718, "actor_loss": -9.712128207683563, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.653096914291382, "step": 40000}
{"episode_reward": 50.31973156123559, "episode": 41.0, "batch_reward": 0.09047400303184987, "critic_loss": 0.19689889366179705, "actor_loss": -10.261280018806458, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.070067405700684, "step": 41000}
{"episode_reward": 36.06890200725798, "episode": 42.0, "batch_reward": 0.09405097586661577, "critic_loss": 0.18267867809534072, "actor_loss": -10.436676480293274, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.265443325042725, "step": 42000}
{"episode_reward": 353.9043931763832, "episode": 43.0, "batch_reward": 0.09549054448306561, "critic_loss": 0.17275669761747123, "actor_loss": -10.506905952453613, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.872852325439453, "step": 43000}
{"episode_reward": 32.1300529146398, "episode": 44.0, "batch_reward": 0.09851394028216601, "critic_loss": 0.19421740179136396, "actor_loss": -11.330712316513061, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.254079580307007, "step": 44000}
{"episode_reward": 294.0999124082367, "episode": 45.0, "batch_reward": 0.10054305037111044, "critic_loss": 0.18679837166517974, "actor_loss": -11.47650839805603, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.617072343826294, "step": 45000}
{"episode_reward": 113.87413860795057, "episode": 46.0, "batch_reward": 0.10156543672829867, "critic_loss": 0.21520124112069608, "actor_loss": -11.434319688796997, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.807387828826904, "step": 46000}
{"episode_reward": 143.3210844621798, "episode": 47.0, "batch_reward": 0.10402424344420433, "critic_loss": 0.20445661486685276, "actor_loss": -11.776506462097167, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.61515712738037, "step": 47000}
{"episode_reward": 355.94767950515893, "episode": 48.0, "batch_reward": 0.10647649633139372, "critic_loss": 0.2033934299722314, "actor_loss": -12.087451111793518, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.81992793083191, "step": 48000}
{"episode_reward": 76.97009919453116, "episode": 49.0, "batch_reward": 0.1090513724386692, "critic_loss": 0.1938765621483326, "actor_loss": -12.253339695930482, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.831795692443848, "step": 49000}
{"episode_reward": 391.25801190331293, "episode": 50.0, "batch_reward": 0.11359734600782394, "critic_loss": 0.18578348818421364, "actor_loss": -12.92229433631897, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.70752215385437, "step": 50000}
{"episode_reward": 284.9893781105533, "episode": 51.0, "batch_reward": 0.11712561926245689, "critic_loss": 0.20610937421768905, "actor_loss": -12.663514699935913, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.123968839645386, "step": 51000}
{"episode_reward": 402.28070331652384, "episode": 52.0, "batch_reward": 0.12386040928214788, "critic_loss": 0.23056785023212434, "actor_loss": -14.003287998199463, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.405590534210205, "step": 52000}
{"episode_reward": 429.0929368516061, "episode": 53.0, "batch_reward": 0.1303563536927104, "critic_loss": 0.2160114279165864, "actor_loss": -14.828552463531494, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.177451133728027, "step": 53000}
{"episode_reward": 451.6958683847902, "episode": 54.0, "batch_reward": 0.13496632742881776, "critic_loss": 0.19280495151132346, "actor_loss": -15.193213148117065, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.027595043182373, "step": 54000}
{"episode_reward": 386.18789595893315, "episode": 55.0, "batch_reward": 0.13909861692786216, "critic_loss": 0.2058193811699748, "actor_loss": -15.624452365875245, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.248739004135132, "step": 55000}
{"episode_reward": 401.30255687546753, "episode": 56.0, "batch_reward": 0.14204134894907475, "critic_loss": 0.1866413565799594, "actor_loss": -16.499425491333007, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.889694929122925, "step": 56000}
{"episode_reward": 70.034924407096, "episode": 57.0, "batch_reward": 0.14201574913412332, "critic_loss": 0.2018430854603648, "actor_loss": -16.290306316375734, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.565723180770874, "step": 57000}
{"episode_reward": 270.54146934801474, "episode": 58.0, "batch_reward": 0.14568838942050935, "critic_loss": 0.2214050742983818, "actor_loss": -16.88214835548401, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.45415997505188, "step": 58000}
{"episode_reward": 445.7030210954257, "episode": 59.0, "batch_reward": 0.15005323058366776, "critic_loss": 0.24448080744594336, "actor_loss": -17.169468786239623, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.92536234855652, "step": 59000}
{"episode_reward": 183.3552623378257, "episode": 60.0, "batch_reward": 0.151553015306592, "critic_loss": 0.23653582479059695, "actor_loss": -18.012706983566286, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.671326637268066, "step": 60000}
{"episode_reward": 458.2181634513086, "episode": 61.0, "batch_reward": 0.15583733919262885, "critic_loss": 0.26130499520152806, "actor_loss": -18.57133259963989, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.095996379852295, "step": 61000}
{"episode_reward": 366.3989883312277, "episode": 62.0, "batch_reward": 0.15947062946856022, "critic_loss": 0.25107686472684143, "actor_loss": -19.09946033477783, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.580540657043457, "step": 62000}
{"episode_reward": 474.9557882424261, "episode": 63.0, "batch_reward": 0.16374836119264363, "critic_loss": 0.27028722013533113, "actor_loss": -19.79381212425232, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.387542724609375, "step": 63000}
{"episode_reward": 189.65267746354556, "episode": 64.0, "batch_reward": 0.1639109647795558, "critic_loss": 0.28297216302901507, "actor_loss": -19.753992347717286, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.638155937194824, "step": 64000}
{"episode_reward": 362.1572161224278, "episode": 65.0, "batch_reward": 0.16841612090915442, "critic_loss": 0.2934681884944439, "actor_loss": -20.126213676452636, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.523260354995728, "step": 65000}
{"episode_reward": 520.8461887839559, "episode": 66.0, "batch_reward": 0.17415519592165946, "critic_loss": 0.2909073364362121, "actor_loss": -20.89134872817993, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.773544788360596, "step": 66000}
{"episode_reward": 501.9884829519942, "episode": 67.0, "batch_reward": 0.17917942522466182, "critic_loss": 0.2851630445867777, "actor_loss": -21.289408405303956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.57298731803894, "step": 67000}
{"episode_reward": 505.7490287791659, "episode": 68.0, "batch_reward": 0.1839539188593626, "critic_loss": 0.2821534467115998, "actor_loss": -21.9625196685791, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.205540657043457, "step": 68000}
{"episode_reward": 448.01316803998344, "episode": 69.0, "batch_reward": 0.18601425045728684, "critic_loss": 0.27368798515200615, "actor_loss": -22.214279483795167, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.018664836883545, "step": 69000}
{"episode_reward": 93.83661638140359, "episode": 70.0, "batch_reward": 0.18673465022444724, "critic_loss": 0.28444385842978953, "actor_loss": -22.34465104675293, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.376442193984985, "step": 70000}
{"episode_reward": 495.63992302346935, "episode": 71.0, "batch_reward": 0.1911068204343319, "critic_loss": 0.30989347433298825, "actor_loss": -22.802378204345704, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.74048590660095, "step": 71000}
{"episode_reward": 480.4603739431294, "episode": 72.0, "batch_reward": 0.1956678627729416, "critic_loss": 0.2954655271023512, "actor_loss": -23.240796592712403, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.885605573654175, "step": 72000}
{"episode_reward": 538.6417281003684, "episode": 73.0, "batch_reward": 0.2005845936089754, "critic_loss": 0.27739648236334324, "actor_loss": -23.684318244934083, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.116092920303345, "step": 73000}
{"episode_reward": 514.4993890485392, "episode": 74.0, "batch_reward": 0.20243484763801098, "critic_loss": 0.2706350565850735, "actor_loss": -24.158969341278077, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.998608589172363, "step": 74000}
{"episode_reward": 532.3716282223116, "episode": 75.0, "batch_reward": 0.20841957740485667, "critic_loss": 0.28642061591148377, "actor_loss": -24.573429424285887, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.24691390991211, "step": 75000}
{"episode_reward": 507.60756645084734, "episode": 76.0, "batch_reward": 0.2126874911636114, "critic_loss": 0.28335851527750494, "actor_loss": -25.094944259643555, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.509843349456787, "step": 76000}
{"episode_reward": 502.2122059458769, "episode": 77.0, "batch_reward": 0.2164886549413204, "critic_loss": 0.2851287494972348, "actor_loss": -25.33642420959473, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.3653085231781, "step": 77000}
{"episode_reward": 529.7255226492706, "episode": 78.0, "batch_reward": 0.22025130657851696, "critic_loss": 0.28292395662516356, "actor_loss": -26.00174906539917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.864805698394775, "step": 78000}
{"episode_reward": 518.325123186765, "episode": 79.0, "batch_reward": 0.22453035432100296, "critic_loss": 0.2747566893622279, "actor_loss": -26.05768868255615, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.868663787841797, "step": 79000}
{"episode_reward": 539.2414499068948, "episode": 80.0, "batch_reward": 0.22863768082857133, "critic_loss": 0.286469881914556, "actor_loss": -26.729198780059814, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.046912670135498, "step": 80000}
{"episode_reward": 558.132868272261, "episode": 81.0, "batch_reward": 0.2325767042040825, "critic_loss": 0.2620911845341325, "actor_loss": -27.04603519821167, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.961923122406006, "step": 81000}
{"episode_reward": 536.9766138286876, "episode": 82.0, "batch_reward": 0.23527709391713142, "critic_loss": 0.2750176752731204, "actor_loss": -27.598801029205323, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.75872015953064, "step": 82000}
{"episode_reward": 279.06854879834026, "episode": 83.0, "batch_reward": 0.2346090390086174, "critic_loss": 0.26658660355210306, "actor_loss": -27.499279708862304, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.5743350982666, "step": 83000}
{"episode_reward": 146.68365642258775, "episode": 84.0, "batch_reward": 0.23468940454721451, "critic_loss": 0.27924670950323344, "actor_loss": -27.53550026702881, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.889097213745117, "step": 84000}
{"episode_reward": 544.84365070846, "episode": 85.0, "batch_reward": 0.23925272130966185, "critic_loss": 0.28699123997986314, "actor_loss": -28.058867057800292, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.21172857284546, "step": 85000}
{"episode_reward": 560.2174722581216, "episode": 86.0, "batch_reward": 0.24150905181467533, "critic_loss": 0.2921201135888696, "actor_loss": -28.311929416656493, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.421753406524658, "step": 86000}
{"episode_reward": 564.4967921945914, "episode": 87.0, "batch_reward": 0.2462071940153837, "critic_loss": 0.27356525188684466, "actor_loss": -28.743647422790527, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.071824073791504, "step": 87000}
{"episode_reward": 538.8729278950215, "episode": 88.0, "batch_reward": 0.24973448605835438, "critic_loss": 0.26690847223252057, "actor_loss": -29.270458137512207, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.950609922409058, "step": 88000}
{"episode_reward": 538.3419838497095, "episode": 89.0, "batch_reward": 0.25391616697609426, "critic_loss": 0.275070701777935, "actor_loss": -29.580334644317627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.0612370967865, "step": 89000}
{"episode_reward": 517.6342180535706, "episode": 90.0, "batch_reward": 0.25656928454339506, "critic_loss": 0.2796769540309906, "actor_loss": -30.025091300964355, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.17337417602539, "step": 90000}
{"episode_reward": 530.9041954911061, "episode": 91.0, "batch_reward": 0.25875222533941267, "critic_loss": 0.27435594296455384, "actor_loss": -30.258937191009522, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.72069549560547, "step": 91000}
{"episode_reward": 566.8150531159222, "episode": 92.0, "batch_reward": 0.26222651709616185, "critic_loss": 0.29923131384700535, "actor_loss": -30.609038913726806, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.345250129699707, "step": 92000}
{"episode_reward": 528.2525125736607, "episode": 93.0, "batch_reward": 0.2655928286015987, "critic_loss": 0.2737445011362433, "actor_loss": -30.943994873046876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.80969548225403, "step": 93000}
{"episode_reward": 534.8512101504232, "episode": 94.0, "batch_reward": 0.26966365811228754, "critic_loss": 0.3023893763795495, "actor_loss": -31.329271995544435, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.68645668029785, "step": 94000}
{"episode_reward": 569.4105004479576, "episode": 95.0, "batch_reward": 0.27055461844801904, "critic_loss": 0.2582561399936676, "actor_loss": -31.60093969345093, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.98279881477356, "step": 95000}
{"episode_reward": 565.6547384299748, "episode": 96.0, "batch_reward": 0.2753458601236343, "critic_loss": 0.28991094255447386, "actor_loss": -31.801431003570556, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.901381731033325, "step": 96000}
{"episode_reward": 541.4743739746516, "episode": 97.0, "batch_reward": 0.2774176285117865, "critic_loss": 0.2768095187395811, "actor_loss": -32.36593017196655, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.258898496627808, "step": 97000}
{"episode_reward": 559.8298877898784, "episode": 98.0, "batch_reward": 0.2814483668208122, "critic_loss": 0.28213840790838, "actor_loss": -32.64656005477905, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.405107736587524, "step": 98000}
{"episode_reward": 510.35952443241206, "episode": 99.0, "batch_reward": 0.2817890492081642, "critic_loss": 0.27478947781026364, "actor_loss": -32.684406467437746, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.54672360420227, "step": 99000}
{"episode_reward": 571.5219217154882, "episode": 100.0, "batch_reward": 0.2846114593297243, "critic_loss": 0.27628825131058693, "actor_loss": -32.930683490753175, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.05584955215454, "step": 100000}
{"episode_reward": 560.0894600010329, "episode": 101.0, "batch_reward": 0.28803109164536, "critic_loss": 0.29095555178076027, "actor_loss": -33.55575369644165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.85029315948486, "step": 101000}
{"episode_reward": 566.6856968483792, "episode": 102.0, "batch_reward": 0.2913845945000649, "critic_loss": 0.27219507183879615, "actor_loss": -33.58782572174072, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.12530517578125, "step": 102000}
{"episode_reward": 524.529584326374, "episode": 103.0, "batch_reward": 0.2932284211963415, "critic_loss": 0.2732093298733234, "actor_loss": -33.94580248260498, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.714308261871338, "step": 103000}
{"episode_reward": 517.9669993192693, "episode": 104.0, "batch_reward": 0.2963913058936596, "critic_loss": 0.28859176409989595, "actor_loss": -34.12729895019531, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.144002676010132, "step": 104000}
{"episode_reward": 558.3864374721873, "episode": 105.0, "batch_reward": 0.2969510357230902, "critic_loss": 0.281271093390882, "actor_loss": -34.40029304122925, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.097314834594727, "step": 105000}
{"episode_reward": 585.9850713003119, "episode": 106.0, "batch_reward": 0.30078994333744047, "critic_loss": 0.2782783896252513, "actor_loss": -34.64015595626831, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.019330263137817, "step": 106000}
{"episode_reward": 576.505136007665, "episode": 107.0, "batch_reward": 0.3019342695325613, "critic_loss": 0.2754882439672947, "actor_loss": -34.925149555206296, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.51114583015442, "step": 107000}
{"episode_reward": 355.5493324383304, "episode": 108.0, "batch_reward": 0.3035535534620285, "critic_loss": 0.2995843962356448, "actor_loss": -34.98629312133789, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.114895820617676, "step": 108000}
{"episode_reward": 577.2946504513021, "episode": 109.0, "batch_reward": 0.3067517410069704, "critic_loss": 0.3134706191569567, "actor_loss": -35.23528722000122, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.086467266082764, "step": 109000}
{"episode_reward": 534.0348238651591, "episode": 110.0, "batch_reward": 0.30863773231208325, "critic_loss": 0.28485774839669464, "actor_loss": -35.56740586090088, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.754249811172485, "step": 110000}
{"episode_reward": 575.1296909604599, "episode": 111.0, "batch_reward": 0.30949584251642226, "critic_loss": 0.29047863741219043, "actor_loss": -35.71981344985962, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.0462486743927, "step": 111000}
{"episode_reward": 110.02469169407075, "episode": 112.0, "batch_reward": 0.30898614294826987, "critic_loss": 0.3121409495100379, "actor_loss": -35.78051301574707, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.662845611572266, "step": 112000}
{"episode_reward": 566.587946591492, "episode": 113.0, "batch_reward": 0.3123216080069542, "critic_loss": 0.2893931081518531, "actor_loss": -36.05633225631714, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.197717905044556, "step": 113000}
{"episode_reward": 559.9253274794877, "episode": 114.0, "batch_reward": 0.31415598084032537, "critic_loss": 0.31451816868782045, "actor_loss": -36.349146816253665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.669331550598145, "step": 114000}
{"episode_reward": 571.5629325692279, "episode": 115.0, "batch_reward": 0.3156357413828373, "critic_loss": 0.315927623860538, "actor_loss": -36.406573020935056, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.162224531173706, "step": 115000}
{"episode_reward": 567.7765041265166, "episode": 116.0, "batch_reward": 0.31727625776827334, "critic_loss": 0.29131629697978495, "actor_loss": -36.564723445892334, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.233003854751587, "step": 116000}
{"episode_reward": 587.2844910132371, "episode": 117.0, "batch_reward": 0.32122928139567375, "critic_loss": 0.298186097510159, "actor_loss": -36.92257745361328, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.512999773025513, "step": 117000}
{"episode_reward": 579.6668886695674, "episode": 118.0, "batch_reward": 0.3229988033771515, "critic_loss": 0.29359177031368017, "actor_loss": -36.96593170166015, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.006682872772217, "step": 118000}
{"episode_reward": 490.8629128803833, "episode": 119.0, "batch_reward": 0.3234770834743977, "critic_loss": 0.30077132422477004, "actor_loss": -37.13747855377197, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.95772671699524, "step": 119000}
{"episode_reward": 576.2570182605664, "episode": 120.0, "batch_reward": 0.32656279054284093, "critic_loss": 0.31304935857653615, "actor_loss": -37.37066120147705, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.591707944869995, "step": 120000}
{"episode_reward": 591.0085698046196, "episode": 121.0, "batch_reward": 0.3297644994854927, "critic_loss": 0.3049194886907935, "actor_loss": -37.73886415863037, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.03644561767578, "step": 121000}
{"episode_reward": 586.8076230325231, "episode": 122.0, "batch_reward": 0.3310258324146271, "critic_loss": 0.2869196033999324, "actor_loss": -37.54283316040039, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.834020853042603, "step": 122000}
{"episode_reward": 575.5939313124454, "episode": 123.0, "batch_reward": 0.3318293550312519, "critic_loss": 0.3193963374719024, "actor_loss": -37.7625246887207, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.355895280838013, "step": 123000}
{"episode_reward": 558.7102648334837, "episode": 124.0, "batch_reward": 0.33438527935743334, "critic_loss": 0.31490209834277627, "actor_loss": -38.05737908935547, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.93315863609314, "step": 124000}
{"episode_reward": 577.3956372987224, "episode": 125.0, "batch_reward": 0.3368537432849407, "critic_loss": 0.3083313117325306, "actor_loss": -38.1940348739624, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.245693922042847, "step": 125000}
{"episode_reward": 588.2361744615339, "episode": 126.0, "batch_reward": 0.33864936837553977, "critic_loss": 0.3057260063290596, "actor_loss": -38.32388033294678, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.650023937225342, "step": 126000}
{"episode_reward": 614.719696764061, "episode": 127.0, "batch_reward": 0.34025216302275657, "critic_loss": 0.27239303529262543, "actor_loss": -38.46867221832275, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.912118196487427, "step": 127000}
{"episode_reward": 582.4802275185883, "episode": 128.0, "batch_reward": 0.34172783768177034, "critic_loss": 0.291652239061892, "actor_loss": -38.5171695022583, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.794736623764038, "step": 128000}
{"episode_reward": 577.3597792499808, "episode": 129.0, "batch_reward": 0.3442076790332794, "critic_loss": 0.30371618266403677, "actor_loss": -38.8206754989624, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.069993495941162, "step": 129000}
{"episode_reward": 593.2615227908046, "episode": 130.0, "batch_reward": 0.3464344317317009, "critic_loss": 0.2769608537629247, "actor_loss": -39.139693359375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.814488410949707, "step": 130000}
{"episode_reward": 609.1819256227793, "episode": 131.0, "batch_reward": 0.3482762534022331, "critic_loss": 0.2793552644699812, "actor_loss": -39.23224495697021, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.75612187385559, "step": 131000}
{"episode_reward": 560.3794747156214, "episode": 132.0, "batch_reward": 0.3485165445804596, "critic_loss": 0.2714391544833779, "actor_loss": -39.20312506103516, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.325427293777466, "step": 132000}
{"episode_reward": 584.6033055564209, "episode": 133.0, "batch_reward": 0.35054433956742287, "critic_loss": 0.2659011647030711, "actor_loss": -39.397939208984376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.488083124160767, "step": 133000}
{"episode_reward": 602.5000595068927, "episode": 134.0, "batch_reward": 0.352756022810936, "critic_loss": 0.2736709223687649, "actor_loss": -39.62312436676025, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.2751145362854, "step": 134000}
{"episode_reward": 559.2625271447091, "episode": 135.0, "batch_reward": 0.35425414058566096, "critic_loss": 0.2983987491130829, "actor_loss": -39.70814601135254, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.462074518203735, "step": 135000}
{"episode_reward": 600.8835987393771, "episode": 136.0, "batch_reward": 0.3563819363117218, "critic_loss": 0.2916080432161689, "actor_loss": -40.00628295135498, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.351282358169556, "step": 136000}
{"episode_reward": 571.2265365541972, "episode": 137.0, "batch_reward": 0.3588365088403225, "critic_loss": 0.26048432718962433, "actor_loss": -40.235704986572266, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.10261631011963, "step": 137000}
{"episode_reward": 586.3970926488118, "episode": 138.0, "batch_reward": 0.36038801008462906, "critic_loss": 0.2740159271806478, "actor_loss": -40.52338985443115, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.907855987548828, "step": 138000}
{"episode_reward": 626.4386511843074, "episode": 139.0, "batch_reward": 0.36169549930095674, "critic_loss": 0.31229916390031576, "actor_loss": -40.58254726409912, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.48935055732727, "step": 139000}
{"episode_reward": 543.1607603383477, "episode": 140.0, "batch_reward": 0.36337669017910956, "critic_loss": 0.27527312793582676, "actor_loss": -40.74243700408935, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.569562673568726, "step": 140000}
{"episode_reward": 596.7398587708002, "episode": 141.0, "batch_reward": 0.3640082187652588, "critic_loss": 0.29297475688904523, "actor_loss": -40.772358047485355, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.83487844467163, "step": 141000}
{"episode_reward": 584.7820046485706, "episode": 142.0, "batch_reward": 0.3666079835295677, "critic_loss": 0.28583119916915894, "actor_loss": -40.95642457580566, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.673542976379395, "step": 142000}
{"episode_reward": 606.8770690038941, "episode": 143.0, "batch_reward": 0.3672824268043041, "critic_loss": 0.2734480075389147, "actor_loss": -40.92802254486084, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.395917177200317, "step": 143000}
{"episode_reward": 630.0964265966749, "episode": 144.0, "batch_reward": 0.3712128490507603, "critic_loss": 0.28248960068821904, "actor_loss": -41.40682766723633, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.49795150756836, "step": 144000}
{"episode_reward": 613.3314706951804, "episode": 145.0, "batch_reward": 0.3725203474164009, "critic_loss": 0.28426150070875883, "actor_loss": -41.329819389343264, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.611612796783447, "step": 145000}
{"episode_reward": 604.3162665238466, "episode": 146.0, "batch_reward": 0.37252758038043976, "critic_loss": 0.26906647285074, "actor_loss": -41.57631221008301, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.642748594284058, "step": 146000}
{"episode_reward": 623.0837756892427, "episode": 147.0, "batch_reward": 0.3748402059972286, "critic_loss": 0.27739063419401644, "actor_loss": -41.599717407226564, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.32828187942505, "step": 147000}
{"episode_reward": 588.3047264081513, "episode": 148.0, "batch_reward": 0.37598924899101255, "critic_loss": 0.26494361548870804, "actor_loss": -41.88635224914551, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.454429388046265, "step": 148000}
{"episode_reward": 618.7140942003517, "episode": 149.0, "batch_reward": 0.37742262494564055, "critic_loss": 0.28510026345402, "actor_loss": -41.95905283355713, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.211716890335083, "step": 149000}
{"episode_reward": 612.0884634300239, "episode": 150.0, "batch_reward": 0.3799095712900162, "critic_loss": 0.2746470809727907, "actor_loss": -42.14704859924316, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
