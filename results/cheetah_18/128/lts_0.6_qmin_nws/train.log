{"episode_reward": 0.0, "episode": 1.0, "duration": 17.415321826934814, "step": 1000}
{"episode_reward": 4.20996189079657, "episode": 2.0, "duration": 1.5095608234405518, "step": 2000}
{"episode_reward": 252.2457487418515, "episode": 3.0, "batch_reward": 0.12160952236700869, "critic_loss": 0.06599607045981795, "actor_loss": -21.210203651644413, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 60.92411756515503, "step": 3000}
{"episode_reward": 21.575227574419763, "episode": 4.0, "batch_reward": 0.08082459349557758, "critic_loss": 0.03138247747998685, "actor_loss": -18.668658581733702, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.16523814201355, "step": 4000}
{"episode_reward": 5.657255885122347, "episode": 5.0, "batch_reward": 0.06633977007493377, "critic_loss": 0.03466504003852606, "actor_loss": -18.543648879051208, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.15143585205078, "step": 5000}
{"episode_reward": 33.81563842571135, "episode": 6.0, "batch_reward": 0.06300809914618731, "critic_loss": 0.05220765885524452, "actor_loss": -18.49916148519516, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.151708126068115, "step": 6000}
{"episode_reward": 56.22741898255899, "episode": 7.0, "batch_reward": 0.06282462367042899, "critic_loss": 0.0625179279781878, "actor_loss": -18.720248279094697, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.140974044799805, "step": 7000}
{"episode_reward": 64.21118478254438, "episode": 8.0, "batch_reward": 0.06404565063863993, "critic_loss": 0.061899417502805594, "actor_loss": -18.030336456298826, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.129671812057495, "step": 8000}
{"episode_reward": 81.4005051287597, "episode": 9.0, "batch_reward": 0.06742743982747197, "critic_loss": 0.08260897525399924, "actor_loss": -17.772126574039458, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.1322181224823, "step": 9000}
{"episode_reward": 116.47034703875327, "episode": 10.0, "batch_reward": 0.07098672987893223, "critic_loss": 0.10832443813979625, "actor_loss": -18.711099569797515, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.11701202392578, "step": 10000}
{"episode_reward": 44.56781717655641, "episode": 11.0, "batch_reward": 0.06676949118822813, "critic_loss": 0.10778741607815027, "actor_loss": -15.858657359600068, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.522156715393066, "step": 11000}
{"episode_reward": 31.5147287104659, "episode": 12.0, "batch_reward": 0.0661840919032693, "critic_loss": 0.1289615182392299, "actor_loss": -16.648035758733748, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.130424737930298, "step": 12000}
{"episode_reward": 67.42906716316332, "episode": 13.0, "batch_reward": 0.06497972229868174, "critic_loss": 0.13923668342083692, "actor_loss": -16.145934711933137, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.13991093635559, "step": 13000}
{"episode_reward": 43.21399227455888, "episode": 14.0, "batch_reward": 0.06338763613626361, "critic_loss": 0.1522192147746682, "actor_loss": -15.052633821487428, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.126579761505127, "step": 14000}
{"episode_reward": 44.65463933386674, "episode": 15.0, "batch_reward": 0.06166842894628644, "critic_loss": 0.16683320849388839, "actor_loss": -13.775862619221211, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.14336347579956, "step": 15000}
{"episode_reward": 28.185500478178547, "episode": 16.0, "batch_reward": 0.06177517322823405, "critic_loss": 0.2137089788839221, "actor_loss": -14.122772873573005, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.164005517959595, "step": 16000}
{"episode_reward": 70.09866478513226, "episode": 17.0, "batch_reward": 0.06573404464498163, "critic_loss": 0.27103760009258987, "actor_loss": -15.002434301778674, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.123430013656616, "step": 17000}
{"episode_reward": 141.6535675664724, "episode": 18.0, "batch_reward": 0.06635664851590992, "critic_loss": 0.22776188378036022, "actor_loss": -14.256019630521536, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.14247751235962, "step": 18000}
{"episode_reward": 67.55322872281245, "episode": 19.0, "batch_reward": 0.06552039787173271, "critic_loss": 0.23074195801466704, "actor_loss": -14.332878617487848, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.15435218811035, "step": 19000}
{"episode_reward": 47.855012912217, "episode": 20.0, "batch_reward": 0.06428591345250606, "critic_loss": 0.21465195980668067, "actor_loss": -14.410511742308735, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.13255524635315, "step": 20000}
{"episode_reward": 47.19543107835749, "episode": 21.0, "batch_reward": 0.06520179251767695, "critic_loss": 0.24481542648375035, "actor_loss": -13.408299755237996, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.571232318878174, "step": 21000}
{"episode_reward": 109.51996846079564, "episode": 22.0, "batch_reward": 0.06616738955676556, "critic_loss": 0.23858183961361645, "actor_loss": -14.59743945966661, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.145496129989624, "step": 22000}
{"episode_reward": 62.56897463856073, "episode": 23.0, "batch_reward": 0.06650616808235646, "critic_loss": 0.21897961191833018, "actor_loss": -13.986980066776276, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.146509408950806, "step": 23000}
{"episode_reward": 58.54735234751046, "episode": 24.0, "batch_reward": 0.0654479611441493, "critic_loss": 0.20283954581990837, "actor_loss": -13.089108440697194, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.134458541870117, "step": 24000}
{"episode_reward": 62.56918030430143, "episode": 25.0, "batch_reward": 0.0652203300409019, "critic_loss": 0.2063472753763199, "actor_loss": -13.66416705159843, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.12663745880127, "step": 25000}
{"episode_reward": 54.49788463039325, "episode": 26.0, "batch_reward": 0.06985005797818303, "critic_loss": 0.24309008345752955, "actor_loss": -13.653992210626603, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.127798080444336, "step": 26000}
{"episode_reward": 336.5585499475903, "episode": 27.0, "batch_reward": 0.07850036167353391, "critic_loss": 0.24825064297765492, "actor_loss": -14.755388645648956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.105627298355103, "step": 27000}
{"episode_reward": 274.7794377322722, "episode": 28.0, "batch_reward": 0.08482081303372979, "critic_loss": 0.2307955090776086, "actor_loss": -15.759768535137177, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.5796000957489, "step": 28000}
{"episode_reward": 148.95930313716687, "episode": 29.0, "batch_reward": 0.08788809026405216, "critic_loss": 0.2022807646691799, "actor_loss": -15.806175841808319, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.11546301841736, "step": 29000}
{"episode_reward": 243.45851060936437, "episode": 30.0, "batch_reward": 0.09353107639402151, "critic_loss": 0.2008991645500064, "actor_loss": -15.836967233657838, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.087273836135864, "step": 30000}
{"episode_reward": 335.88080799586726, "episode": 31.0, "batch_reward": 0.10072838442772628, "critic_loss": 0.19107366938889025, "actor_loss": -17.073209157943726, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.48069906234741, "step": 31000}
{"episode_reward": 131.1087025501728, "episode": 32.0, "batch_reward": 0.10100229378789663, "critic_loss": 0.17697145203500986, "actor_loss": -16.719639644622802, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.13795781135559, "step": 32000}
{"episode_reward": 122.8723668751685, "episode": 33.0, "batch_reward": 0.10113500005751848, "critic_loss": 0.18949326610565184, "actor_loss": -17.134372146606445, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.159780263900757, "step": 33000}
{"episode_reward": 70.43816590054884, "episode": 34.0, "batch_reward": 0.1038635485097766, "critic_loss": 0.19084665106236934, "actor_loss": -17.124114137649535, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.155130863189697, "step": 34000}
{"episode_reward": 319.5325601782368, "episode": 35.0, "batch_reward": 0.1094499436467886, "critic_loss": 0.2367150429263711, "actor_loss": -16.591841358184816, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.11163854598999, "step": 35000}
{"episode_reward": 259.25884686843165, "episode": 36.0, "batch_reward": 0.11306597276031971, "critic_loss": 0.2418865664228797, "actor_loss": -18.009715980529784, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.14825439453125, "step": 36000}
{"episode_reward": 275.6971981352406, "episode": 37.0, "batch_reward": 0.11673397558182477, "critic_loss": 0.25705004604160786, "actor_loss": -17.80748284816742, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.14726185798645, "step": 37000}
{"episode_reward": 144.39690658704217, "episode": 38.0, "batch_reward": 0.11641033793985843, "critic_loss": 0.25943187437951565, "actor_loss": -17.533777206420897, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.138668298721313, "step": 38000}
{"episode_reward": 101.51951790252346, "episode": 39.0, "batch_reward": 0.11615934136509895, "critic_loss": 0.2884556889533997, "actor_loss": -18.18603796195984, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.130926370620728, "step": 39000}
{"episode_reward": 130.4377285748504, "episode": 40.0, "batch_reward": 0.11583400840312243, "critic_loss": 0.29303551790118215, "actor_loss": -18.66394075012207, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.12405276298523, "step": 40000}
{"episode_reward": 89.76702044326039, "episode": 41.0, "batch_reward": 0.11660561820864677, "critic_loss": 0.2699660794958472, "actor_loss": -18.41559694862366, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.5202693939209, "step": 41000}
{"episode_reward": 180.70650985487575, "episode": 42.0, "batch_reward": 0.11944384748488665, "critic_loss": 0.27163318590074775, "actor_loss": -18.39379696559906, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.172020435333252, "step": 42000}
{"episode_reward": 240.83399597201918, "episode": 43.0, "batch_reward": 0.12275804401189089, "critic_loss": 0.2760205783843994, "actor_loss": -18.892637264251707, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.116654634475708, "step": 43000}
{"episode_reward": 408.66066423343267, "episode": 44.0, "batch_reward": 0.12979749490320683, "critic_loss": 0.2924037676379085, "actor_loss": -18.691625856399536, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.142529487609863, "step": 44000}
{"episode_reward": 427.87005593119414, "episode": 45.0, "batch_reward": 0.13597743997722864, "critic_loss": 0.2823592270389199, "actor_loss": -19.303551141738893, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.155848264694214, "step": 45000}
{"episode_reward": 379.94157547009195, "episode": 46.0, "batch_reward": 0.13876905189454555, "critic_loss": 0.3001173640117049, "actor_loss": -19.95574132347107, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.138500928878784, "step": 46000}
{"episode_reward": 86.03494411807603, "episode": 47.0, "batch_reward": 0.1400746794268489, "critic_loss": 0.2817556376308203, "actor_loss": -19.92365636444092, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.16051197052002, "step": 47000}
{"episode_reward": 386.1094971498813, "episode": 48.0, "batch_reward": 0.1417060160264373, "critic_loss": 0.28182627832889556, "actor_loss": -20.10897786140442, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.17334794998169, "step": 48000}
{"episode_reward": 48.79581600231475, "episode": 49.0, "batch_reward": 0.14165932136774062, "critic_loss": 0.2778948953077197, "actor_loss": -20.21141796875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.149157524108887, "step": 49000}
{"episode_reward": 198.9936836330863, "episode": 50.0, "batch_reward": 0.14398974001407625, "critic_loss": 0.30204852002859117, "actor_loss": -20.28851330757141, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.167419910430908, "step": 50000}
{"episode_reward": 379.58380713362993, "episode": 51.0, "batch_reward": 0.147889313749969, "critic_loss": 0.2811577496081591, "actor_loss": -20.95927663230896, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.5325448513031, "step": 51000}
{"episode_reward": 375.6361017611392, "episode": 52.0, "batch_reward": 0.1524599443152547, "critic_loss": 0.3198443460687995, "actor_loss": -21.089342765808105, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.166415691375732, "step": 52000}
{"episode_reward": 154.6454041024962, "episode": 53.0, "batch_reward": 0.1536839936003089, "critic_loss": 0.30177410910278557, "actor_loss": -21.380755958557128, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.157939195632935, "step": 53000}
{"episode_reward": 402.229800948576, "episode": 54.0, "batch_reward": 0.15705213303118945, "critic_loss": 0.31533625001460314, "actor_loss": -21.76962607383728, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.150660753250122, "step": 54000}
{"episode_reward": 86.34164492381858, "episode": 55.0, "batch_reward": 0.15752148970961571, "critic_loss": 0.3020947818607092, "actor_loss": -21.746208917617796, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.21607780456543, "step": 55000}
{"episode_reward": 494.0957534674529, "episode": 56.0, "batch_reward": 0.16260889813303947, "critic_loss": 0.32873080592602494, "actor_loss": -22.664554243087768, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.421757459640503, "step": 56000}
{"episode_reward": 414.9423973273673, "episode": 57.0, "batch_reward": 0.16488913883268833, "critic_loss": 0.3940565977320075, "actor_loss": -22.553836765289308, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.11400818824768, "step": 57000}
{"episode_reward": 56.273296957717285, "episode": 58.0, "batch_reward": 0.16493238120526074, "critic_loss": 0.4239824240282178, "actor_loss": -22.704513778686522, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.12459921836853, "step": 58000}
{"episode_reward": 167.06576609130698, "episode": 59.0, "batch_reward": 0.16673022238910198, "critic_loss": 0.3942663921415806, "actor_loss": -22.974965045928954, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.12694811820984, "step": 59000}
{"episode_reward": 419.3897051915466, "episode": 60.0, "batch_reward": 0.16934120228886604, "critic_loss": 0.3855085716098547, "actor_loss": -22.979286067962647, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.136983394622803, "step": 60000}
{"episode_reward": 386.76220748426215, "episode": 61.0, "batch_reward": 0.17178127728402615, "critic_loss": 0.4601029810458422, "actor_loss": -22.716039966583253, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.487666606903076, "step": 61000}
{"episode_reward": 104.60821588122305, "episode": 62.0, "batch_reward": 0.17197958497703075, "critic_loss": 0.4300709652677178, "actor_loss": -22.959196434020996, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.168837547302246, "step": 62000}
{"episode_reward": 222.47487776317232, "episode": 63.0, "batch_reward": 0.17334062422066926, "critic_loss": 0.40295030434429646, "actor_loss": -23.08952603149414, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.144513607025146, "step": 63000}
{"episode_reward": 258.3546949632889, "episode": 64.0, "batch_reward": 0.17329902978241443, "critic_loss": 0.40788264115154743, "actor_loss": -23.483394790649413, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.1332049369812, "step": 64000}
{"episode_reward": 203.1446678196823, "episode": 65.0, "batch_reward": 0.1733336855173111, "critic_loss": 0.4011299211084843, "actor_loss": -23.463224283218384, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.164297342300415, "step": 65000}
{"episode_reward": 117.05665003809416, "episode": 66.0, "batch_reward": 0.17440770656615495, "critic_loss": 0.3861155286207795, "actor_loss": -23.44037997817993, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.122819900512695, "step": 66000}
{"episode_reward": 308.45160060247184, "episode": 67.0, "batch_reward": 0.17601334905624388, "critic_loss": 0.41273252752423284, "actor_loss": -23.00285348892212, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.119612216949463, "step": 67000}
{"episode_reward": 443.22735719535916, "episode": 68.0, "batch_reward": 0.18169852429628372, "critic_loss": 0.3921955927014351, "actor_loss": -23.99407077598572, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.1513888835907, "step": 68000}
{"episode_reward": 497.2527031393617, "episode": 69.0, "batch_reward": 0.18246941678225995, "critic_loss": 0.380833584189415, "actor_loss": -23.776851417541504, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.148561239242554, "step": 69000}
{"episode_reward": 116.21817671600652, "episode": 70.0, "batch_reward": 0.18393556079268455, "critic_loss": 0.4395165500789881, "actor_loss": -23.829036973953247, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.12925887107849, "step": 70000}
{"episode_reward": 430.66205005042815, "episode": 71.0, "batch_reward": 0.18780464498698712, "critic_loss": 0.3837455434948206, "actor_loss": -24.179897550582886, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.5657274723053, "step": 71000}
{"episode_reward": 501.24471405252217, "episode": 72.0, "batch_reward": 0.19191423805058003, "critic_loss": 0.3614612599685788, "actor_loss": -24.69111615180969, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.096219062805176, "step": 72000}
{"episode_reward": 471.80841584080144, "episode": 73.0, "batch_reward": 0.19539688052237034, "critic_loss": 0.4032400934398174, "actor_loss": -25.048726291656493, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.114951133728027, "step": 73000}
{"episode_reward": 437.5730916399803, "episode": 74.0, "batch_reward": 0.19665108768641948, "critic_loss": 0.46476381793618204, "actor_loss": -25.341219741821288, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.161415576934814, "step": 74000}
{"episode_reward": 84.49081746846895, "episode": 75.0, "batch_reward": 0.1971772063821554, "critic_loss": 0.432930137783289, "actor_loss": -25.762865756988525, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.10820174217224, "step": 75000}
{"episode_reward": 321.46310297008705, "episode": 76.0, "batch_reward": 0.1993372955620289, "critic_loss": 0.4505548249185085, "actor_loss": -25.460488201141356, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.128146409988403, "step": 76000}
{"episode_reward": 447.4615786955881, "episode": 77.0, "batch_reward": 0.20299844063818454, "critic_loss": 0.42700636959075927, "actor_loss": -25.903477123260497, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.12029218673706, "step": 77000}
{"episode_reward": 476.3279114446854, "episode": 78.0, "batch_reward": 0.20632312110066414, "critic_loss": 0.43265909393131735, "actor_loss": -26.178013889312744, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.109527587890625, "step": 78000}
{"episode_reward": 421.1884490655387, "episode": 79.0, "batch_reward": 0.2092858802676201, "critic_loss": 0.45676698222756384, "actor_loss": -26.71505763244629, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.14848518371582, "step": 79000}
{"episode_reward": 509.3242547622511, "episode": 80.0, "batch_reward": 0.2126774733811617, "critic_loss": 0.4986698387861252, "actor_loss": -26.912204811096192, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.189408540725708, "step": 80000}
{"episode_reward": 388.1587421380532, "episode": 81.0, "batch_reward": 0.21505182301998138, "critic_loss": 0.4293347350358963, "actor_loss": -26.917904445648194, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.632466554641724, "step": 81000}
{"episode_reward": 402.5611676447863, "episode": 82.0, "batch_reward": 0.21696771182119845, "critic_loss": 0.43956146934628487, "actor_loss": -27.21469964981079, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.118175506591797, "step": 82000}
{"episode_reward": 498.60840172751267, "episode": 83.0, "batch_reward": 0.2204458021223545, "critic_loss": 0.4078564729988575, "actor_loss": -27.330713626861574, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.12533164024353, "step": 83000}
{"episode_reward": 478.391266586472, "episode": 84.0, "batch_reward": 0.22064025963842868, "critic_loss": 0.46905530171096327, "actor_loss": -27.453084259033204, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.144366979599, "step": 84000}
{"episode_reward": 151.32011930686622, "episode": 85.0, "batch_reward": 0.22291017089784146, "critic_loss": 0.4869564428776503, "actor_loss": -27.831683906555178, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.14303731918335, "step": 85000}
{"episode_reward": 513.2203159085093, "episode": 86.0, "batch_reward": 0.22551656775176526, "critic_loss": 0.46946614296734335, "actor_loss": -27.640515155792237, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.1421537399292, "step": 86000}
{"episode_reward": 464.3951398568583, "episode": 87.0, "batch_reward": 0.22787930729985237, "critic_loss": 0.47018802012503147, "actor_loss": -27.90724415206909, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.155226230621338, "step": 87000}
{"episode_reward": 328.3964941821611, "episode": 88.0, "batch_reward": 0.2293006018847227, "critic_loss": 0.45166633877158163, "actor_loss": -28.122402053833007, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.146692752838135, "step": 88000}
{"episode_reward": 151.9670003376897, "episode": 89.0, "batch_reward": 0.22871537266671657, "critic_loss": 0.4667236697822809, "actor_loss": -28.449674449920654, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.140403747558594, "step": 89000}
{"episode_reward": 461.2167040517171, "episode": 90.0, "batch_reward": 0.23225446809828282, "critic_loss": 0.5325651035904885, "actor_loss": -28.385269512176514, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.15554976463318, "step": 90000}
{"episode_reward": 381.14556504961865, "episode": 91.0, "batch_reward": 0.23244053208827972, "critic_loss": 0.4882820640951395, "actor_loss": -28.5700739402771, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.50164723396301, "step": 91000}
{"episode_reward": 493.40598626154934, "episode": 92.0, "batch_reward": 0.23644983372092246, "critic_loss": 0.49690677477419376, "actor_loss": -28.195220470428467, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.167243003845215, "step": 92000}
{"episode_reward": 509.99871830336957, "episode": 93.0, "batch_reward": 0.2386466637402773, "critic_loss": 0.5179635587632656, "actor_loss": -29.089727542877196, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.13393473625183, "step": 93000}
{"episode_reward": 470.33616408615154, "episode": 94.0, "batch_reward": 0.2426027484983206, "critic_loss": 0.46547262167930603, "actor_loss": -29.011076374053957, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.144693851470947, "step": 94000}
{"episode_reward": 477.8672747336142, "episode": 95.0, "batch_reward": 0.24289018562436104, "critic_loss": 0.48363601480424406, "actor_loss": -29.463306632995604, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.1431303024292, "step": 95000}
{"episode_reward": 230.61985248175446, "episode": 96.0, "batch_reward": 0.24424856796860694, "critic_loss": 0.5290629018843174, "actor_loss": -29.26577486419678, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.12282967567444, "step": 96000}
{"episode_reward": 444.6763029425959, "episode": 97.0, "batch_reward": 0.2452499098032713, "critic_loss": 0.5314279498457909, "actor_loss": -29.723951076507568, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.143399000167847, "step": 97000}
{"episode_reward": 493.6557708116904, "episode": 98.0, "batch_reward": 0.24894856029748916, "critic_loss": 0.5361828531324864, "actor_loss": -30.294430625915528, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.13103699684143, "step": 98000}
{"episode_reward": 387.0764024842464, "episode": 99.0, "batch_reward": 0.2487369498461485, "critic_loss": 0.532932301312685, "actor_loss": -29.999916667938233, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.141060829162598, "step": 99000}
{"episode_reward": 507.0918029043211, "episode": 100.0, "batch_reward": 0.25107412913441657, "critic_loss": 0.4840897606611252, "actor_loss": -30.21775667190552, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.149070501327515, "step": 100000}
{"episode_reward": 129.59437729987656, "episode": 101.0, "batch_reward": 0.2515223462283611, "critic_loss": 0.48831506249308587, "actor_loss": -29.917366416931152, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.50764584541321, "step": 101000}
{"episode_reward": 460.6466717338059, "episode": 102.0, "batch_reward": 0.2515549048036337, "critic_loss": 0.5015641231685877, "actor_loss": -30.311643184661865, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.116296768188477, "step": 102000}
{"episode_reward": 141.66674273044922, "episode": 103.0, "batch_reward": 0.25193769647181036, "critic_loss": 0.5046600475162267, "actor_loss": -30.119003715515138, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.15437626838684, "step": 103000}
{"episode_reward": 468.7493300730101, "episode": 104.0, "batch_reward": 0.2557059247940779, "critic_loss": 0.48366667598485946, "actor_loss": -30.97968468093872, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.108973503112793, "step": 104000}
{"episode_reward": 495.90035419676946, "episode": 105.0, "batch_reward": 0.25656654992699623, "critic_loss": 0.5003453956767917, "actor_loss": -30.432156440734865, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.147332429885864, "step": 105000}
{"episode_reward": 489.2026839259553, "episode": 106.0, "batch_reward": 0.25813329857587813, "critic_loss": 0.47011910226941106, "actor_loss": -30.86390996170044, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.158997774124146, "step": 106000}
{"episode_reward": 459.1978045623139, "episode": 107.0, "batch_reward": 0.2593829738795757, "critic_loss": 0.4939888152480125, "actor_loss": -31.143641956329347, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.133098125457764, "step": 107000}
{"episode_reward": 507.98065832040663, "episode": 108.0, "batch_reward": 0.26283958289027215, "critic_loss": 0.5268951528221368, "actor_loss": -31.3143803024292, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.117016792297363, "step": 108000}
{"episode_reward": 472.29988611387813, "episode": 109.0, "batch_reward": 0.2659325529932976, "critic_loss": 0.5431269353032112, "actor_loss": -31.651475872039796, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.174440145492554, "step": 109000}
{"episode_reward": 525.1320412158692, "episode": 110.0, "batch_reward": 0.2679262897670269, "critic_loss": 0.5273444314748049, "actor_loss": -31.968243030548095, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.129498720169067, "step": 110000}
{"episode_reward": 483.1395527406105, "episode": 111.0, "batch_reward": 0.27029334062337873, "critic_loss": 0.4980151586383581, "actor_loss": -31.698360202789306, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.52250576019287, "step": 111000}
{"episode_reward": 524.5690591704721, "episode": 112.0, "batch_reward": 0.27112285602092745, "critic_loss": 0.48589859379827977, "actor_loss": -32.03881934738159, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.159415245056152, "step": 112000}
{"episode_reward": 513.0607568466683, "episode": 113.0, "batch_reward": 0.27465079705417156, "critic_loss": 0.5236591795235872, "actor_loss": -31.88412047958374, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.145270824432373, "step": 113000}
{"episode_reward": 524.8944769980678, "episode": 114.0, "batch_reward": 0.27498941746354105, "critic_loss": 0.530582869052887, "actor_loss": -32.3631725769043, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.12882947921753, "step": 114000}
{"episode_reward": 137.88515444596158, "episode": 115.0, "batch_reward": 0.2747026004642248, "critic_loss": 0.5003064214140177, "actor_loss": -32.763820369720456, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.189777374267578, "step": 115000}
{"episode_reward": 436.49815029279017, "episode": 116.0, "batch_reward": 0.2755354165136814, "critic_loss": 0.5148413410782814, "actor_loss": -32.376153442382815, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.195713996887207, "step": 116000}
{"episode_reward": 494.899559130742, "episode": 117.0, "batch_reward": 0.2797172376662493, "critic_loss": 0.5074571956992149, "actor_loss": -32.93565718460083, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.135015964508057, "step": 117000}
{"episode_reward": 503.6824477174345, "episode": 118.0, "batch_reward": 0.28055557914078233, "critic_loss": 0.4632334678322077, "actor_loss": -32.86511095428467, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.155112504959106, "step": 118000}
{"episode_reward": 418.1833164153854, "episode": 119.0, "batch_reward": 0.28117308861017226, "critic_loss": 0.4695278491675854, "actor_loss": -33.041715576171875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.18937921524048, "step": 119000}
{"episode_reward": 486.1820070772573, "episode": 120.0, "batch_reward": 0.2823147564679384, "critic_loss": 0.47367745397984984, "actor_loss": -33.31534234619141, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.156296253204346, "step": 120000}
{"episode_reward": 510.1071022329525, "episode": 121.0, "batch_reward": 0.2853181475996971, "critic_loss": 0.4832984295934439, "actor_loss": -33.572664531707765, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.548335313797, "step": 121000}
{"episode_reward": 499.3667697211553, "episode": 122.0, "batch_reward": 0.2875187844187021, "critic_loss": 0.47435477292537687, "actor_loss": -33.81346607208252, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.114976167678833, "step": 122000}
{"episode_reward": 506.01138906476876, "episode": 123.0, "batch_reward": 0.2879311693161726, "critic_loss": 0.4670773665457964, "actor_loss": -33.992099956512455, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.125643253326416, "step": 123000}
{"episode_reward": 476.75867264900427, "episode": 124.0, "batch_reward": 0.2893694189488888, "critic_loss": 0.5467599251717329, "actor_loss": -33.98001475524902, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.147875547409058, "step": 124000}
{"episode_reward": 522.58295318957, "episode": 125.0, "batch_reward": 0.2924030389040709, "critic_loss": 0.49569240874052045, "actor_loss": -34.289224937438966, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.10481357574463, "step": 125000}
{"episode_reward": 484.3298802454251, "episode": 126.0, "batch_reward": 0.2920835134088993, "critic_loss": 0.5143786967545748, "actor_loss": -34.401417781829835, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.126431703567505, "step": 126000}
{"episode_reward": 527.0066077848679, "episode": 127.0, "batch_reward": 0.29481506343185904, "critic_loss": 0.5144526306688786, "actor_loss": -34.286572303771976, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.154301643371582, "step": 127000}
{"episode_reward": 504.76975627266677, "episode": 128.0, "batch_reward": 0.297495216012001, "critic_loss": 0.5005490601956845, "actor_loss": -34.281700298309325, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.13960552215576, "step": 128000}
{"episode_reward": 527.3009986258132, "episode": 129.0, "batch_reward": 0.2980096636265516, "critic_loss": 0.4801516316831112, "actor_loss": -34.67799766540527, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.145854473114014, "step": 129000}
{"episode_reward": 217.88218835778753, "episode": 130.0, "batch_reward": 0.2978982556313276, "critic_loss": 0.5097380188852548, "actor_loss": -34.46318016052246, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.158950090408325, "step": 130000}
{"episode_reward": 348.0195801120563, "episode": 131.0, "batch_reward": 0.29827033513784407, "critic_loss": 0.4765063369721174, "actor_loss": -33.99802724456787, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.585862159729004, "step": 131000}
{"episode_reward": 446.9094627486959, "episode": 132.0, "batch_reward": 0.29853685963153836, "critic_loss": 0.5198470948189498, "actor_loss": -34.469911628723146, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.170467138290405, "step": 132000}
{"episode_reward": 518.2684947921164, "episode": 133.0, "batch_reward": 0.30003770741820335, "critic_loss": 0.514937197431922, "actor_loss": -34.743335803985595, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.199466466903687, "step": 133000}
{"episode_reward": 255.436280290381, "episode": 134.0, "batch_reward": 0.3018700109273195, "critic_loss": 0.4659881895631552, "actor_loss": -34.943419883728026, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.129249095916748, "step": 134000}
{"episode_reward": 510.7697834591191, "episode": 135.0, "batch_reward": 0.30224102245271206, "critic_loss": 0.5136093430519104, "actor_loss": -35.16808763885498, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.15285611152649, "step": 135000}
{"episode_reward": 516.7514085560656, "episode": 136.0, "batch_reward": 0.3034483626782894, "critic_loss": 0.5091703673303127, "actor_loss": -35.278702800750736, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.131256818771362, "step": 136000}
{"episode_reward": 502.13701379951834, "episode": 137.0, "batch_reward": 0.30630580212175845, "critic_loss": 0.5523498811423778, "actor_loss": -35.562436363220215, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.141623735427856, "step": 137000}
{"episode_reward": 479.35301456307707, "episode": 138.0, "batch_reward": 0.30604466252028945, "critic_loss": 0.5505310198366642, "actor_loss": -34.71299564743042, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.17529034614563, "step": 138000}
{"episode_reward": 527.3783171137676, "episode": 139.0, "batch_reward": 0.3084526229500771, "critic_loss": 0.5429006822407245, "actor_loss": -34.796997611999515, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.130292415618896, "step": 139000}
{"episode_reward": 521.2316888447821, "episode": 140.0, "batch_reward": 0.3089324278831482, "critic_loss": 0.5162709135711193, "actor_loss": -35.3069040184021, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.149057149887085, "step": 140000}
{"episode_reward": 520.7278047380843, "episode": 141.0, "batch_reward": 0.3111480952501297, "critic_loss": 0.5079641040563584, "actor_loss": -35.90769700241089, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.51278877258301, "step": 141000}
{"episode_reward": 521.0324236222472, "episode": 142.0, "batch_reward": 0.31332437479496, "critic_loss": 0.4967511772364378, "actor_loss": -35.7723631362915, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.127357959747314, "step": 142000}
{"episode_reward": 531.0521625213408, "episode": 143.0, "batch_reward": 0.3138066198378801, "critic_loss": 0.4978969314992428, "actor_loss": -36.17192898178101, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.11562204360962, "step": 143000}
{"episode_reward": 537.0244491012002, "episode": 144.0, "batch_reward": 0.31694221860170363, "critic_loss": 0.4975078696757555, "actor_loss": -36.229546981811524, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.15946936607361, "step": 144000}
{"episode_reward": 487.18557448039445, "episode": 145.0, "batch_reward": 0.31737916058301924, "critic_loss": 0.5143085549175739, "actor_loss": -36.8515894317627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.125596284866333, "step": 145000}
{"episode_reward": 504.8823578543215, "episode": 146.0, "batch_reward": 0.31778707274794576, "critic_loss": 0.46950643296539785, "actor_loss": -35.995720695495606, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.127408981323242, "step": 146000}
{"episode_reward": 483.6903761316766, "episode": 147.0, "batch_reward": 0.31935194858908655, "critic_loss": 0.48582553455233574, "actor_loss": -36.45651754760742, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.14750385284424, "step": 147000}
{"episode_reward": 519.7237193868224, "episode": 148.0, "batch_reward": 0.32114298176765443, "critic_loss": 0.4751777838021517, "actor_loss": -36.61078001022339, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.16191554069519, "step": 148000}
{"episode_reward": 546.5871658452116, "episode": 149.0, "batch_reward": 0.32145958751440046, "critic_loss": 0.5103469421267509, "actor_loss": -36.58951205062866, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.145936727523804, "step": 149000}
{"episode_reward": 398.66993895002, "episode": 150.0, "batch_reward": 0.3225894529521465, "critic_loss": 0.4647521836310625, "actor_loss": -36.54309794998169, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
