{"episode": 1.0, "duration": 19.64395785331726, "episode_reward": 4.20996189079657, "step": 1000}
{"episode": 2.0, "duration": 1.789954423904419, "episode_reward": 252.2457487418515, "step": 2000}
{"episode": 3.0, "batch_reward": 0.13228645226624697, "actor_loss": -36.07710623922421, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254236, "duration": 50.325740814208984, "episode_reward": 192.50852858565824, "step": 3000}
{"episode": 4.0, "batch_reward": 0.15067821299284698, "actor_loss": -36.91199538421631, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.044983386993408, "episode_reward": 125.85745601129716, "step": 4000}
{"episode": 5.0, "batch_reward": 0.14015622533857822, "actor_loss": -33.957845905303955, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 15.52030086517334, "episode_reward": 73.869956027314, "step": 5000}
{"episode": 6.0, "batch_reward": 0.12718511608988048, "actor_loss": -30.489144920349123, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.418553352355957, "episode_reward": 55.820231766751846, "step": 6000}
{"episode": 7.0, "batch_reward": 0.12573251133412122, "actor_loss": -29.059906044006347, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.545893669128418, "episode_reward": 160.75154832368747, "step": 7000}
{"episode": 8.0, "batch_reward": 0.12184051265567541, "actor_loss": -27.663104530334472, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.7730450630188, "episode_reward": 62.367099183838405, "step": 8000}
{"episode": 9.0, "batch_reward": 0.12167558355629444, "actor_loss": -27.094494422912597, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.631898641586304, "episode_reward": 238.1132316116706, "step": 9000}
{"episode": 10.0, "batch_reward": 0.1353102655634284, "actor_loss": -25.418863548278807, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 3845.626905441284, "episode_reward": 212.48401464907758, "step": 10000}
{"episode": 11.0, "batch_reward": 0.14082684902101755, "actor_loss": -26.243002952575683, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 34.67874813079834, "episode_reward": 199.75473227901483, "step": 11000}
{"episode": 12.0, "batch_reward": 0.14642524795234205, "actor_loss": -24.581152267456055, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 446.94541454315186, "episode_reward": 228.6979790713989, "step": 12000}
{"episode": 13.0, "batch_reward": 0.1544498415365815, "actor_loss": -24.89774478149414, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.266437530517578, "episode_reward": 159.13299428532616, "step": 13000}
{"episode": 14.0, "batch_reward": 0.1562086633965373, "actor_loss": -23.23230369567871, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 446.8592619895935, "episode_reward": 303.94565330898837, "step": 14000}
{"episode": 15.0, "batch_reward": 0.17016261951625347, "actor_loss": -24.36404001235962, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.70416831970215, "episode_reward": 369.8888335562456, "step": 15000}
{"episode": 16.0, "batch_reward": 0.17880002036690712, "actor_loss": -23.64092250061035, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 450.8524384498596, "episode_reward": 331.67617904934247, "step": 16000}
{"episode": 17.0, "batch_reward": 0.19170385971665382, "actor_loss": -24.73473885345459, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.57046127319336, "episode_reward": 386.809879669314, "step": 17000}
{"episode": 18.0, "batch_reward": 0.20161284530162812, "actor_loss": -24.38353136444092, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 420.3732089996338, "episode_reward": 341.57223161125245, "step": 18000}
{"episode": 19.0, "batch_reward": 0.20960949790477754, "actor_loss": -25.086639556884766, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.41904926300049, "episode_reward": 358.0878798913264, "step": 19000}
{"episode": 20.0, "batch_reward": 0.21366869619488715, "actor_loss": -23.58900866317749, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 404.62786769866943, "episode_reward": 168.40643986746625, "step": 20000}
{"episode": 21.0, "batch_reward": 0.21457771529257297, "actor_loss": -23.558236587524416, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 35.598458766937256, "episode_reward": 367.2152465587367, "step": 21000}
{"episode": 22.0, "batch_reward": 0.22228510591387748, "actor_loss": -22.855625087738037, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 418.57167863845825, "episode_reward": 375.4886572975471, "step": 22000}
{"episode": 23.0, "batch_reward": 0.2286787928342819, "actor_loss": -23.431241512298584, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.58248805999756, "episode_reward": 315.24478428189343, "step": 23000}
{"episode": 24.0, "batch_reward": 0.2332139844149351, "actor_loss": -22.575719718933104, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 407.16701793670654, "episode_reward": 440.6570187335207, "step": 24000}
{"episode": 25.0, "batch_reward": 0.2406001415401697, "actor_loss": -23.194639335632324, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.89919948577881, "episode_reward": 265.8755140070618, "step": 25000}
{"episode": 26.0, "batch_reward": 0.24288407741487025, "actor_loss": -22.17723650741577, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 417.58992075920105, "episode_reward": 425.6686773885413, "step": 26000}
{"episode": 27.0, "batch_reward": 0.2497499874830246, "actor_loss": -22.889686428070068, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.207497119903564, "episode_reward": 403.8592810786383, "step": 27000}
{"episode": 28.0, "batch_reward": 0.2541773520112038, "actor_loss": -22.541173851013184, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 415.3506474494934, "episode_reward": 381.45924178382256, "step": 28000}
{"episode": 29.0, "batch_reward": 0.25977091114223005, "actor_loss": -22.976590709686278, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.00638461112976, "episode_reward": 415.39733248390485, "step": 29000}
{"episode": 30.0, "batch_reward": 0.26442452004551886, "actor_loss": -22.73834327316284, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 443.66775918006897, "episode_reward": 401.962118368989, "step": 30000}
{"episode": 31.0, "batch_reward": 0.2686286348849535, "actor_loss": -22.982361576080322, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 34.7333710193634, "episode_reward": 302.46813062540105, "step": 31000}
{"episode": 32.0, "batch_reward": 0.2709618811309338, "actor_loss": -22.515235828399657, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 447.5308599472046, "episode_reward": 431.9798003908266, "step": 32000}
{"episode": 33.0, "batch_reward": 0.27566793155670166, "actor_loss": -22.98667444229126, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.459885120391846, "episode_reward": 423.4411649083393, "step": 33000}
{"episode": 34.0, "batch_reward": 0.27999126620590686, "actor_loss": -22.68796572113037, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 412.9485402107239, "episode_reward": 417.9341994456183, "step": 34000}
{"episode": 35.0, "batch_reward": 0.28364025278389454, "actor_loss": -22.934781646728517, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.562520027160645, "episode_reward": 429.2583207170588, "step": 35000}
{"episode": 36.0, "batch_reward": 0.28884114561975005, "actor_loss": -23.13023147583008, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 410.5996971130371, "episode_reward": 430.25718014519657, "step": 36000}
{"episode": 37.0, "batch_reward": 0.29264280131459236, "actor_loss": -23.450352947235107, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.83472752571106, "episode_reward": 452.4503534796294, "step": 37000}
{"episode": 38.0, "batch_reward": 0.29685655541718003, "actor_loss": -23.352842987060548, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 414.3359353542328, "episode_reward": 448.90042243021935, "step": 38000}
{"episode": 39.0, "batch_reward": 0.29983225697278976, "actor_loss": -23.66503408432007, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.74622893333435, "episode_reward": 435.950927826891, "step": 39000}
{"episode": 40.0, "batch_reward": 0.30409723526239396, "actor_loss": -23.947713565826415, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 415.921875, "episode_reward": 432.61104760568605, "step": 40000}
{"episode": 41.0, "batch_reward": 0.30614063403010366, "actor_loss": -24.096151988983156, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 31.285696268081665, "episode_reward": 380.37790410609534, "step": 41000}
{"episode": 42.0, "batch_reward": 0.30818192893266677, "actor_loss": -23.853279960632324, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 418.06722354888916, "episode_reward": 435.50502136594605, "step": 42000}
{"episode": 43.0, "batch_reward": 0.31270236846804617, "actor_loss": -24.15355679321289, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.30601739883423, "episode_reward": 462.51476811810954, "step": 43000}
{"episode": 44.0, "batch_reward": 0.3163181543648243, "actor_loss": -24.53648355102539, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 414.9197254180908, "episode_reward": 449.44889919553304, "step": 44000}
{"episode": 45.0, "batch_reward": 0.3193943041265011, "actor_loss": -24.807763164520264, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.57988929748535, "episode_reward": 450.8870268123018, "step": 45000}
{"episode": 46.0, "batch_reward": 0.32019308909773825, "actor_loss": -25.00976049041748, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 412.5462152957916, "episode_reward": 445.1037176255622, "step": 46000}
{"episode": 47.0, "batch_reward": 0.3236213516294956, "actor_loss": -25.276788402557372, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.589849948883057, "episode_reward": 457.3394493499803, "step": 47000}
{"episode": 48.0, "batch_reward": 0.3264366306364536, "actor_loss": -25.525140869140625, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 414.38650918006897, "episode_reward": 442.3289639464823, "step": 48000}
{"episode": 49.0, "batch_reward": 0.32962444016337394, "actor_loss": -25.79957511138916, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.628155946731567, "episode_reward": 435.48900653683216, "step": 49000}
{"episode": 50.0, "batch_reward": 0.32991087329387664, "actor_loss": -26.308240341186522, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 417.64934515953064, "episode_reward": 220.43678137978418, "step": 50000}
{"episode": 51.0, "batch_reward": 0.32735982930660246, "actor_loss": -25.993444038391115, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 37.24931716918945, "episode_reward": 213.84070846755986, "step": 51000}
{"episode": 52.0, "batch_reward": 0.32597069573402404, "actor_loss": -26.097843448638915, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 447.4912450313568, "episode_reward": 358.0860898926482, "step": 52000}
{"episode": 53.0, "batch_reward": 0.3268499737977982, "actor_loss": -26.347657180786133, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.361537218093872, "episode_reward": 385.16906785299955, "step": 53000}
{"episode": 54.0, "batch_reward": 0.3268462511599064, "actor_loss": -26.657552745819093, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 442.91752004623413, "episode_reward": 309.059069676625, "step": 54000}
{"episode": 55.0, "batch_reward": 0.32822148263454437, "actor_loss": -26.74913540649414, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.423490285873413, "episode_reward": 445.26865154968056, "step": 55000}
{"episode": 56.0, "batch_reward": 0.3303695633709431, "actor_loss": -27.884857189178465, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 450.47275829315186, "episode_reward": 456.05955459425314, "step": 56000}
{"episode": 57.0, "batch_reward": 0.3325411404371262, "actor_loss": -28.105464702606202, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.496638774871826, "episode_reward": 484.8944653757117, "step": 57000}
{"episode": 58.0, "batch_reward": 0.3348233247697353, "actor_loss": -28.329579414367675, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 447.06321001052856, "episode_reward": 408.92015893668554, "step": 58000}
{"episode": 59.0, "batch_reward": 0.3360110077857971, "actor_loss": -28.355730464935302, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.456554651260376, "episode_reward": 253.6965643052415, "step": 59000}
{"episode": 60.0, "batch_reward": 0.33480267533659935, "actor_loss": -28.89625992202759, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 442.67091393470764, "episode_reward": 401.92105079620626, "step": 60000}
{"episode": 61.0, "batch_reward": 0.3355471408069134, "actor_loss": -28.912337062835693, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 39.02245569229126, "episode_reward": 409.3874321451844, "step": 61000}
{"episode": 62.0, "batch_reward": 0.33551718908548356, "actor_loss": -29.270841861724854, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 450.78834342956543, "episode_reward": 172.68884264885236, "step": 62000}
{"episode": 63.0, "batch_reward": 0.33108819991350175, "actor_loss": -28.753265182495117, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.687530040740967, "episode_reward": 28.787208028711415, "step": 63000}
{"episode": 64.0, "batch_reward": 0.32819372990727425, "actor_loss": -28.696860050201416, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 447.30478048324585, "episode_reward": 234.3637680053689, "step": 64000}
{"episode": 65.0, "batch_reward": 0.32680527260899545, "actor_loss": -28.599414333343507, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.823286533355713, "episode_reward": 88.93818645208954, "step": 65000}
{"episode": 66.0, "batch_reward": 0.323232271194458, "actor_loss": -28.25066320037842, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 445.4662628173828, "episode_reward": 218.0949386509106, "step": 66000}
{"episode": 67.0, "batch_reward": 0.3224239242970943, "actor_loss": -28.203368656158446, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.114910364151, "episode_reward": 182.43486985609, "step": 67000}
{"episode": 68.0, "batch_reward": 0.3200152407884598, "actor_loss": -28.170526664733888, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 451.1265184879303, "episode_reward": 202.6885351818242, "step": 68000}
{"episode": 69.0, "batch_reward": 0.31733231568336484, "actor_loss": -27.99550336074829, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.42026948928833, "episode_reward": 60.7818911842427, "step": 69000}
{"episode": 70.0, "batch_reward": 0.31373201361298564, "actor_loss": -27.823540363311768, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 448.73037934303284, "episode_reward": 370.3616474741946, "step": 70000}
{"episode": 71.0, "batch_reward": 0.3150252340734005, "actor_loss": -27.88734656524658, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 38.178903102874756, "episode_reward": 152.79082987001675, "step": 71000}
{"episode": 72.0, "batch_reward": 0.31331567430496216, "actor_loss": -27.75497759628296, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 447.22678565979004, "episode_reward": 378.6997957231844, "step": 72000}
{"episode": 73.0, "batch_reward": 0.31520604035258293, "actor_loss": -27.99787791442871, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.37020468711853, "episode_reward": 346.70478611306567, "step": 73000}
{"episode": 74.0, "batch_reward": 0.31456110724806785, "actor_loss": -27.923426662445067, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 450.04733896255493, "episode_reward": 381.51720231862976, "step": 74000}
{"episode": 75.0, "batch_reward": 0.3159601122736931, "actor_loss": -28.01497843170166, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.968101739883423, "episode_reward": 327.4836137122791, "step": 75000}
{"episode": 76.0, "batch_reward": 0.31556666022539137, "actor_loss": -27.943208335876466, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 452.55400133132935, "episode_reward": 134.04564182445586, "step": 76000}
{"episode": 77.0, "batch_reward": 0.31390625938773153, "actor_loss": -27.732479583740233, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.033517360687256, "episode_reward": 370.08142772831235, "step": 77000}
{"episode": 78.0, "batch_reward": 0.3141142656803131, "actor_loss": -27.862437107086183, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 444.2850708961487, "episode_reward": 260.4893524715257, "step": 78000}
{"episode": 79.0, "batch_reward": 0.31332563489675525, "actor_loss": -27.810609504699705, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.124422788619995, "episode_reward": 365.90257229666844, "step": 79000}
{"episode": 80.0, "batch_reward": 0.31527402573823926, "actor_loss": -28.075419506072997, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 449.2997827529907, "episode_reward": 426.98572117343275, "step": 80000}
{"episode": 81.0, "batch_reward": 0.3151852982342243, "actor_loss": -27.92088508605957, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 38.918891191482544, "episode_reward": 369.3929979098401, "step": 81000}
{"episode": 82.0, "batch_reward": 0.3159208059608936, "actor_loss": -27.80731233215332, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 448.83390522003174, "episode_reward": 428.93839174215134, "step": 82000}
{"episode": 83.0, "batch_reward": 0.31740158540010455, "actor_loss": -27.902564105987548, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.01416802406311, "episode_reward": 414.71987238993796, "step": 83000}
{"episode": 84.0, "batch_reward": 0.319555016040802, "actor_loss": -28.158422973632813, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 445.36780285835266, "episode_reward": 430.6855332680163, "step": 84000}
{"episode": 85.0, "batch_reward": 0.32074828270077704, "actor_loss": -28.399006103515624, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.85293221473694, "episode_reward": 422.34423377825937, "step": 85000}
{"episode": 86.0, "batch_reward": 0.3210295223891735, "actor_loss": -28.32319451522827, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 448.91997623443604, "episode_reward": 384.43384032829096, "step": 86000}
{"episode": 87.0, "batch_reward": 0.32215795665979385, "actor_loss": -28.596445598602294, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.37372660636902, "episode_reward": 377.3834080828656, "step": 87000}
{"episode": 88.0, "batch_reward": 0.3231622630059719, "actor_loss": -28.890021377563478, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 440.8179473876953, "episode_reward": 346.4955764043251, "step": 88000}
{"episode": 89.0, "batch_reward": 0.3232697577774525, "actor_loss": -28.994033897399902, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.575074434280396, "episode_reward": 377.1942576549272, "step": 89000}
{"episode": 90.0, "batch_reward": 0.32387023386359215, "actor_loss": -29.052906898498534, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 418.55063247680664, "episode_reward": 405.00494897656836, "step": 90000}
{"episode": 91.0, "batch_reward": 0.32425237786769867, "actor_loss": -28.945011844635008, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 36.784387826919556, "episode_reward": 391.6249968578353, "step": 91000}
{"episode": 92.0, "batch_reward": 0.3253394575417042, "actor_loss": -29.05942406463623, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 432.5415391921997, "episode_reward": 381.1971241952476, "step": 92000}
{"episode": 93.0, "batch_reward": 0.32526104646921156, "actor_loss": -29.018767349243163, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.72455406188965, "episode_reward": 338.01440434053524, "step": 93000}
{"episode": 94.0, "batch_reward": 0.32614243510365487, "actor_loss": -29.359986591339112, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 456.1408803462982, "episode_reward": 387.1903531886131, "step": 94000}
{"episode": 95.0, "batch_reward": 0.327062235891819, "actor_loss": -29.450270294189455, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.435795068740845, "episode_reward": 389.84878702928495, "step": 95000}
{"episode": 96.0, "batch_reward": 0.3275017762184143, "actor_loss": -29.419275554656984, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 446.9708275794983, "episode_reward": 305.7207518347017, "step": 96000}
{"episode": 97.0, "batch_reward": 0.32708709567785266, "actor_loss": -29.324909351348875, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.344706058502197, "episode_reward": 353.22128240663574, "step": 97000}
{"episode": 98.0, "batch_reward": 0.32740797525644305, "actor_loss": -29.226606285095215, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 444.74450635910034, "episode_reward": 391.4151526338192, "step": 98000}
{"episode": 99.0, "batch_reward": 0.3283319041132927, "actor_loss": -29.447138427734377, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.457710027694702, "episode_reward": 395.03016173391404, "step": 99000}
{"episode": 100.0, "batch_reward": 0.328661406815052, "actor_loss": -29.28231583023071, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 455.6662619113922, "episode_reward": 342.87760182564983, "step": 100000}
{"episode": 101.0, "batch_reward": 0.32844853270053864, "actor_loss": -29.301929306030274, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 35.191086530685425, "episode_reward": 341.431262584859, "step": 101000}
{"episode": 102.0, "batch_reward": 0.3279034729897976, "actor_loss": -29.12771001434326, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 427.546528339386, "episode_reward": 94.72760331581306, "step": 102000}
{"episode": 103.0, "batch_reward": 0.3261000315845013, "actor_loss": -28.927749938964844, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.15288233757019, "episode_reward": 329.9850858749722, "step": 103000}
{"episode": 104.0, "batch_reward": 0.32658081337809564, "actor_loss": -28.78242798614502, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 409.79728055000305, "episode_reward": 399.11032410438753, "step": 104000}
{"episode": 105.0, "batch_reward": 0.3276901477873325, "actor_loss": -28.878200523376464, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.658759593963623, "episode_reward": 433.84068533232266, "step": 105000}
{"episode": 106.0, "batch_reward": 0.32841369780898094, "actor_loss": -28.85220487976074, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 416.179395198822, "episode_reward": 172.88464964298865, "step": 106000}
{"episode": 107.0, "batch_reward": 0.32634677648544314, "actor_loss": -28.47954179382324, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.628395318984985, "episode_reward": 219.32853855807076, "step": 107000}
{"episode": 108.0, "batch_reward": 0.3254257636666298, "actor_loss": -27.997975734710693, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 409.84176683425903, "episode_reward": 429.7713706816823, "step": 108000}
{"episode": 109.0, "batch_reward": 0.3270575134754181, "actor_loss": -28.176648769378662, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.812565803527832, "episode_reward": 446.4986008616037, "step": 109000}
{"episode": 110.0, "batch_reward": 0.32933457815647127, "actor_loss": -28.6249441986084, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 412.36240243911743, "episode_reward": 434.89310840640314, "step": 110000}
{"episode": 111.0, "batch_reward": 0.32839178285002707, "actor_loss": -28.55340783691406, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 36.18523597717285, "episode_reward": 456.160760083445, "step": 111000}
{"episode": 112.0, "batch_reward": 0.3302903782129288, "actor_loss": -29.00028715133667, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 409.1615903377533, "episode_reward": 427.4354343486294, "step": 112000}
{"episode": 113.0, "batch_reward": 0.3307864771485329, "actor_loss": -28.983497032165527, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.17784023284912, "episode_reward": 428.0684016160036, "step": 113000}
{"episode": 114.0, "batch_reward": 0.33241547057032583, "actor_loss": -29.570630310058593, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 421.7002372741699, "episode_reward": 428.55838043296865, "step": 114000}
{"episode": 115.0, "batch_reward": 0.33322094422578813, "actor_loss": -29.596074504852297, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.641362190246582, "episode_reward": 421.8896861024207, "step": 115000}
{"episode": 116.0, "batch_reward": 0.33414816960692406, "actor_loss": -30.20861178970337, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 409.69536805152893, "episode_reward": 452.16192749873335, "step": 116000}
{"episode": 117.0, "batch_reward": 0.33512751197814944, "actor_loss": -30.443722606658934, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.688686847686768, "episode_reward": 446.05004217188497, "step": 117000}
{"episode": 118.0, "batch_reward": 0.33611406522989273, "actor_loss": -30.37262836456299, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 422.3494577407837, "episode_reward": 460.5266772731671, "step": 118000}
{"episode": 119.0, "batch_reward": 0.33670623528957366, "actor_loss": -30.508872707366944, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.240700244903564, "episode_reward": 469.6177061297402, "step": 119000}
{"episode": 120.0, "batch_reward": 0.3380445429682732, "actor_loss": -31.24239490890503, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 406.93511605262756, "episode_reward": 459.9868298620379, "step": 120000}
{"episode": 121.0, "batch_reward": 0.3380478048324585, "actor_loss": -31.302578868865968, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 33.007121562957764, "episode_reward": 128.73145768915455, "step": 121000}
{"episode": 122.0, "batch_reward": 0.3371767416596413, "actor_loss": -31.002390354156493, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 413.51413011550903, "episode_reward": 426.50055807898764, "step": 122000}
{"episode": 123.0, "batch_reward": 0.33734244233369826, "actor_loss": -30.9631911277771, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 15.592936992645264, "episode_reward": 440.9181531438608, "step": 123000}
{"episode": 124.0, "batch_reward": 0.3383717400729656, "actor_loss": -31.31734468460083, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 411.53761768341064, "episode_reward": 410.4552405841759, "step": 124000}
{"episode": 125.0, "batch_reward": 0.33910371020436286, "actor_loss": -31.435594959259035, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.460609436035156, "episode_reward": 439.3382475471961, "step": 125000}
{"episode": 126.0, "batch_reward": 0.34076524269580843, "actor_loss": -31.372533493041992, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 409.42316722869873, "episode_reward": 426.206326112277, "step": 126000}
{"episode": 127.0, "batch_reward": 0.3399014795124531, "actor_loss": -31.293197982788087, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.260326862335205, "episode_reward": 392.53656004119176, "step": 127000}
{"episode": 128.0, "batch_reward": 0.34123813965916633, "actor_loss": -31.49665156555176, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 406.9102232456207, "episode_reward": 445.01905964968284, "step": 128000}
{"episode": 129.0, "batch_reward": 0.34197532254457474, "actor_loss": -31.495976211547852, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.781586170196533, "episode_reward": 451.26654894441003, "step": 129000}
{"episode": 130.0, "batch_reward": 0.342968976944685, "actor_loss": -31.79132315444946, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 439.6593761444092, "episode_reward": 387.0827197021238, "step": 130000}
{"episode": 131.0, "batch_reward": 0.34396784141659736, "actor_loss": -31.80252596282959, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 34.109204053878784, "episode_reward": 402.11263350662944, "step": 131000}
{"episode": 132.0, "batch_reward": 0.34376804780960085, "actor_loss": -31.901573837280274, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 448.5028808116913, "episode_reward": 411.65187770057827, "step": 132000}
{"episode": 133.0, "batch_reward": 0.34384275433421135, "actor_loss": -31.932444435119628, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.834975242614746, "episode_reward": 413.7816639027017, "step": 133000}
{"episode": 134.0, "batch_reward": 0.3450181983113289, "actor_loss": -32.40212616348266, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 444.9012396335602, "episode_reward": 450.17049388194937, "step": 134000}
{"episode": 135.0, "batch_reward": 0.3444894903898239, "actor_loss": -32.29549914550781, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.78806447982788, "episode_reward": 106.95377907785019, "step": 135000}
{"episode": 136.0, "batch_reward": 0.34439326924085617, "actor_loss": -32.349678981781004, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 453.794650554657, "episode_reward": 482.0259544333334, "step": 136000}
{"episode": 137.0, "batch_reward": 0.3452682037651539, "actor_loss": -32.30622423171997, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.579188108444214, "episode_reward": 227.74141152404553, "step": 137000}
{"episode": 138.0, "batch_reward": 0.3441411810815334, "actor_loss": -32.06306803131103, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 455.4432842731476, "episode_reward": 451.3890393560053, "step": 138000}
{"episode": 139.0, "batch_reward": 0.3449542949795723, "actor_loss": -32.16837117767334, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 19.635509967803955, "episode_reward": 448.411510223275, "step": 139000}
{"episode": 140.0, "batch_reward": 0.34556779155135153, "actor_loss": -31.64938709640503, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 450.9969747066498, "episode_reward": 480.7269708438673, "step": 140000}
{"episode": 141.0, "batch_reward": 0.34643046641349795, "actor_loss": -31.737847526550294, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 37.11615490913391, "episode_reward": 505.35216898965376, "step": 141000}
{"episode": 142.0, "batch_reward": 0.3475055233836174, "actor_loss": -31.76961417388916, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 443.2735629081726, "episode_reward": 366.18013242714443, "step": 142000}
{"episode": 143.0, "batch_reward": 0.34835686764121054, "actor_loss": -32.00452362060547, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 17.978716373443604, "episode_reward": 467.5996287888301, "step": 143000}
{"episode": 144.0, "batch_reward": 0.3488161656856537, "actor_loss": -31.566800762176513, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 453.3356249332428, "episode_reward": 179.3974628865862, "step": 144000}
{"episode": 145.0, "batch_reward": 0.3467037463188171, "actor_loss": -31.342233600616456, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 16.280503511428833, "episode_reward": 393.97519799477254, "step": 145000}
{"episode": 146.0, "batch_reward": 0.3474723873436451, "actor_loss": -31.143490112304686, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 457.49973154067993, "episode_reward": 420.2782217757269, "step": 146000}
{"episode": 147.0, "batch_reward": 0.347928993999958, "actor_loss": -31.14731090927124, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.13635015487671, "episode_reward": 436.4744138131119, "step": 147000}
{"episode": 148.0, "batch_reward": 0.34812966683506963, "actor_loss": -31.013140438079834, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 448.99136447906494, "episode_reward": 442.7573968918759, "step": 148000}
{"episode": 149.0, "batch_reward": 0.349126356869936, "actor_loss": -31.026223449707032, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "duration": 18.22957682609558, "episode_reward": 390.9943334309021, "step": 149000}
{"episode": 150.0, "batch_reward": 0.34970377576351164, "actor_loss": -31.154251636505126, "actor_target_entropy": -6.0, "alpha_value": 0.009385736297254166, "step": 150000}
