{"episode_reward": 0.0, "episode": 1.0, "duration": 17.288798570632935, "step": 1000}
{"episode_reward": 4.20996189079657, "episode": 2.0, "duration": 1.4945621490478516, "step": 2000}
{"episode_reward": 252.2457487418515, "episode": 3.0, "batch_reward": 0.12138497780122809, "critic_loss": 0.12409308682797988, "actor_loss": -28.5624183726554, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 59.07029628753662, "step": 3000}
{"episode_reward": 10.637711442003255, "episode": 4.0, "batch_reward": 0.07751054072380066, "critic_loss": 0.05615609796717763, "actor_loss": -24.8364100856781, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.532755374908447, "step": 4000}
{"episode_reward": 2.932831354707051, "episode": 5.0, "batch_reward": 0.06049565185233951, "critic_loss": 0.034895370884798466, "actor_loss": -25.759403703689575, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.55424690246582, "step": 5000}
{"episode_reward": 3.7919383597677805, "episode": 6.0, "batch_reward": 0.050509468801319596, "critic_loss": 0.03054275875352323, "actor_loss": -25.000762590408325, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.55216956138611, "step": 6000}
{"episode_reward": 3.4912455914215466, "episode": 7.0, "batch_reward": 0.043700116449967026, "critic_loss": 0.03207582406233996, "actor_loss": -25.74798864555359, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.56479287147522, "step": 7000}
{"episode_reward": 5.642595060286991, "episode": 8.0, "batch_reward": 0.040537185141816735, "critic_loss": 0.04237384910415858, "actor_loss": -26.589199478149414, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.55747389793396, "step": 8000}
{"episode_reward": 62.009004005703126, "episode": 9.0, "batch_reward": 0.043149891808629035, "critic_loss": 0.0764634877089411, "actor_loss": -22.771193517684935, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.516666412353516, "step": 9000}
{"episode_reward": 27.514516944043002, "episode": 10.0, "batch_reward": 0.04302189588919282, "critic_loss": 0.05717332481592893, "actor_loss": -22.91473288154602, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.54621720314026, "step": 10000}
{"episode_reward": 46.08349572820006, "episode": 11.0, "batch_reward": 0.04481640864163637, "critic_loss": 0.07601095477119088, "actor_loss": -20.89455152130127, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.876259088516235, "step": 11000}
{"episode_reward": 136.36189731359346, "episode": 12.0, "batch_reward": 0.05618661414086819, "critic_loss": 0.09331000714749098, "actor_loss": -22.418307691574096, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.513007879257202, "step": 12000}
{"episode_reward": 168.0552231567328, "episode": 13.0, "batch_reward": 0.061748451083898544, "critic_loss": 0.09981593574211002, "actor_loss": -23.14157369041443, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.51275873184204, "step": 13000}
{"episode_reward": 95.87336453639922, "episode": 14.0, "batch_reward": 0.06713934506848454, "critic_loss": 0.10951278112828731, "actor_loss": -23.43181083869934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.535574436187744, "step": 14000}
{"episode_reward": 167.76180011710773, "episode": 15.0, "batch_reward": 0.0745688734613359, "critic_loss": 0.10935963957011699, "actor_loss": -22.662271070480347, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.544546604156494, "step": 15000}
{"episode_reward": 163.08952453406903, "episode": 16.0, "batch_reward": 0.07765515479445458, "critic_loss": 0.14098988492786885, "actor_loss": -23.116205748558045, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.52101469039917, "step": 16000}
{"episode_reward": 72.23889248831009, "episode": 17.0, "batch_reward": 0.07783845447003841, "critic_loss": 0.14813700127601623, "actor_loss": -22.75667443943024, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.553406953811646, "step": 17000}
{"episode_reward": 74.96885682557053, "episode": 18.0, "batch_reward": 0.08200288369134069, "critic_loss": 0.1732717457935214, "actor_loss": -22.72371362400055, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.54325842857361, "step": 18000}
{"episode_reward": 218.8297321027152, "episode": 19.0, "batch_reward": 0.0853572995737195, "critic_loss": 0.15857980658113957, "actor_loss": -22.35702804851532, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.50493812561035, "step": 19000}
{"episode_reward": 86.6952308327936, "episode": 20.0, "batch_reward": 0.08586751451715827, "critic_loss": 0.15118188959360124, "actor_loss": -22.828705151557923, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.528496503829956, "step": 20000}
{"episode_reward": 143.99810794986382, "episode": 21.0, "batch_reward": 0.08769460259005428, "critic_loss": 0.1533703565746546, "actor_loss": -20.759776679515838, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.84096670150757, "step": 21000}
{"episode_reward": 66.7538933245819, "episode": 22.0, "batch_reward": 0.08869505658373236, "critic_loss": 0.1672393012419343, "actor_loss": -22.517430418491365, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.497612714767456, "step": 22000}
{"episode_reward": 251.0545286185689, "episode": 23.0, "batch_reward": 0.09434949887916445, "critic_loss": 0.18688500402867794, "actor_loss": -22.638049061775206, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.502190828323364, "step": 23000}
{"episode_reward": 59.61326484883826, "episode": 24.0, "batch_reward": 0.09586495550721884, "critic_loss": 0.19371735348552466, "actor_loss": -21.55657841014862, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.557148933410645, "step": 24000}
{"episode_reward": 194.69850750788058, "episode": 25.0, "batch_reward": 0.09858212142810226, "critic_loss": 0.1822891928255558, "actor_loss": -22.95276994985342, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.54494023323059, "step": 25000}
{"episode_reward": 138.8036814463325, "episode": 26.0, "batch_reward": 0.09860973383486271, "critic_loss": 0.18579465478658677, "actor_loss": -21.863063753291964, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.505133152008057, "step": 26000}
{"episode_reward": 66.24795417136131, "episode": 27.0, "batch_reward": 0.09873614845424891, "critic_loss": 0.20068619267642498, "actor_loss": -21.590146859794856, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.531402111053467, "step": 27000}
{"episode_reward": 235.39855743108615, "episode": 28.0, "batch_reward": 0.10521404367685318, "critic_loss": 0.23153985340893268, "actor_loss": -21.954567470885813, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.91121506690979, "step": 28000}
{"episode_reward": 279.9593926649916, "episode": 29.0, "batch_reward": 0.10863798223435879, "critic_loss": 0.22327323462069035, "actor_loss": -22.89731029880047, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.483864784240723, "step": 29000}
{"episode_reward": 74.10861991555706, "episode": 30.0, "batch_reward": 0.10874848144501448, "critic_loss": 0.19378871797025204, "actor_loss": -22.39012999430299, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.505324363708496, "step": 30000}
{"episode_reward": 112.4875347464708, "episode": 31.0, "batch_reward": 0.10877557626366616, "critic_loss": 0.19024424344301225, "actor_loss": -22.19964120182395, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.81046199798584, "step": 31000}
{"episode_reward": 85.91864624370812, "episode": 32.0, "batch_reward": 0.10898548277467489, "critic_loss": 0.21166177685558796, "actor_loss": -21.958141208186746, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.502925634384155, "step": 32000}
{"episode_reward": 172.4353474389569, "episode": 33.0, "batch_reward": 0.11063238844275475, "critic_loss": 0.2181841331422329, "actor_loss": -22.351312586307525, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.489381074905396, "step": 33000}
{"episode_reward": 300.002587086241, "episode": 34.0, "batch_reward": 0.11738764405995607, "critic_loss": 0.23903971381485462, "actor_loss": -22.584582067728043, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.53267550468445, "step": 34000}
{"episode_reward": 308.99790386373996, "episode": 35.0, "batch_reward": 0.1225757293254137, "critic_loss": 0.2558991365805268, "actor_loss": -22.995612615346907, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.53682279586792, "step": 35000}
{"episode_reward": 203.99494447289314, "episode": 36.0, "batch_reward": 0.12296507684886455, "critic_loss": 0.2880146647319198, "actor_loss": -23.29174179005623, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.485939741134644, "step": 36000}
{"episode_reward": 61.71485555605097, "episode": 37.0, "batch_reward": 0.12244562889635563, "critic_loss": 0.2848816091045737, "actor_loss": -22.854509147644045, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.52829670906067, "step": 37000}
{"episode_reward": 130.15661377238592, "episode": 38.0, "batch_reward": 0.12396016954630613, "critic_loss": 0.2974896715283394, "actor_loss": -23.782782907009125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.549227952957153, "step": 38000}
{"episode_reward": 359.58917242931676, "episode": 39.0, "batch_reward": 0.12828950622677804, "critic_loss": 0.3224522072225809, "actor_loss": -24.3166446185112, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.519041538238525, "step": 39000}
{"episode_reward": 109.56653272535625, "episode": 40.0, "batch_reward": 0.12959902653098107, "critic_loss": 0.33191698679327963, "actor_loss": -24.619786571502686, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.540920734405518, "step": 40000}
{"episode_reward": 280.1051483177931, "episode": 41.0, "batch_reward": 0.13458021867275238, "critic_loss": 0.32912178812921045, "actor_loss": -24.007472856521606, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.88150477409363, "step": 41000}
{"episode_reward": 395.7060135195121, "episode": 42.0, "batch_reward": 0.14017091786116362, "critic_loss": 0.36510717202723025, "actor_loss": -24.702936606407164, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.530409812927246, "step": 42000}
{"episode_reward": 354.72246380828005, "episode": 43.0, "batch_reward": 0.14542756415158511, "critic_loss": 0.357504041954875, "actor_loss": -25.531607692718506, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.48827838897705, "step": 43000}
{"episode_reward": 430.9366417626878, "episode": 44.0, "batch_reward": 0.15329252694547177, "critic_loss": 0.413439667224884, "actor_loss": -25.608656312942504, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.521130323410034, "step": 44000}
{"episode_reward": 356.4915296292185, "episode": 45.0, "batch_reward": 0.15465575295686723, "critic_loss": 0.39230283454060555, "actor_loss": -25.600807019233702, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.527958631515503, "step": 45000}
{"episode_reward": 102.039695065846, "episode": 46.0, "batch_reward": 0.1547708613574505, "critic_loss": 0.38641250543296335, "actor_loss": -25.744900455474852, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.491468906402588, "step": 46000}
{"episode_reward": 283.6379915627319, "episode": 47.0, "batch_reward": 0.1577676000073552, "critic_loss": 0.34109286381304266, "actor_loss": -25.344224749565125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.526300191879272, "step": 47000}
{"episode_reward": 311.6408946301747, "episode": 48.0, "batch_reward": 0.16025657668709756, "critic_loss": 0.3719597892463207, "actor_loss": -26.060154552459718, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.53788661956787, "step": 48000}
{"episode_reward": 402.26600978122286, "episode": 49.0, "batch_reward": 0.16712055837363005, "critic_loss": 0.3845040657222271, "actor_loss": -26.688136390686036, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.484119415283203, "step": 49000}
{"episode_reward": 442.17733895454995, "episode": 50.0, "batch_reward": 0.1711816942989826, "critic_loss": 0.4399157240241766, "actor_loss": -26.339014791488648, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.53512954711914, "step": 50000}
{"episode_reward": 233.6702755227042, "episode": 51.0, "batch_reward": 0.17084899707138537, "critic_loss": 0.4204102580398321, "actor_loss": -27.28841827964783, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.81699466705322, "step": 51000}
{"episode_reward": 178.20496731776723, "episode": 52.0, "batch_reward": 0.174215028449893, "critic_loss": 0.42023105144500733, "actor_loss": -26.87811287879944, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.53965187072754, "step": 52000}
{"episode_reward": 424.70645972553103, "episode": 53.0, "batch_reward": 0.17743510195612908, "critic_loss": 0.47594015471637247, "actor_loss": -27.517413431167604, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.49222493171692, "step": 53000}
{"episode_reward": 219.85592691194458, "episode": 54.0, "batch_reward": 0.17619465845823287, "critic_loss": 0.48169240686297415, "actor_loss": -27.538327312469484, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.527881622314453, "step": 54000}
{"episode_reward": 107.9996580802348, "episode": 55.0, "batch_reward": 0.17816429921984672, "critic_loss": 0.49625617668032646, "actor_loss": -27.886226976394653, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.541945934295654, "step": 55000}
{"episode_reward": 378.5213716186944, "episode": 56.0, "batch_reward": 0.1802784938663244, "critic_loss": 0.48562088203430176, "actor_loss": -27.962028469085695, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.498478412628174, "step": 56000}
{"episode_reward": 225.0268100295006, "episode": 57.0, "batch_reward": 0.18169766126573086, "critic_loss": 0.509123623713851, "actor_loss": -27.875644855499267, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.54080629348755, "step": 57000}
{"episode_reward": 395.92442899915824, "episode": 58.0, "batch_reward": 0.18478564408421516, "critic_loss": 0.5788648154437542, "actor_loss": -28.289341701507567, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.53137493133545, "step": 58000}
{"episode_reward": 187.07878095765, "episode": 59.0, "batch_reward": 0.18646237599849702, "critic_loss": 0.5914623970538377, "actor_loss": -28.968286870956423, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.54611825942993, "step": 59000}
{"episode_reward": 308.11004586749476, "episode": 60.0, "batch_reward": 0.1864945782274008, "critic_loss": 0.5668430287390948, "actor_loss": -28.16539669418335, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.825958490371704, "step": 60000}
{"episode_reward": 183.04877958909947, "episode": 61.0, "batch_reward": 0.18618438309431076, "critic_loss": 0.5864994820654392, "actor_loss": -27.86277198600769, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.86869549751282, "step": 61000}
{"episode_reward": 177.92327934165067, "episode": 62.0, "batch_reward": 0.18656304471194743, "critic_loss": 0.7474780197292566, "actor_loss": -27.925152154922486, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.509631395339966, "step": 62000}
{"episode_reward": 187.99793515547117, "episode": 63.0, "batch_reward": 0.18650672577321528, "critic_loss": 0.7685072021186352, "actor_loss": -27.850706264495848, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.495192289352417, "step": 63000}
{"episode_reward": 232.45113813803522, "episode": 64.0, "batch_reward": 0.18668400068581104, "critic_loss": 0.7787728750705719, "actor_loss": -28.00349652671814, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.555191040039062, "step": 64000}
{"episode_reward": 145.3980223618966, "episode": 65.0, "batch_reward": 0.1881544349193573, "critic_loss": 0.7581416971832514, "actor_loss": -28.083345541000366, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.539133310317993, "step": 65000}
{"episode_reward": 477.26834051830025, "episode": 66.0, "batch_reward": 0.19299962002038956, "critic_loss": 0.8222653910517692, "actor_loss": -28.62470316886902, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.520031452178955, "step": 66000}
{"episode_reward": 454.230597993111, "episode": 67.0, "batch_reward": 0.1942306984513998, "critic_loss": 0.7947068198919296, "actor_loss": -28.494615705490112, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.535326957702637, "step": 67000}
{"episode_reward": 119.46686755509378, "episode": 68.0, "batch_reward": 0.19290524899959563, "critic_loss": 0.7981564966887236, "actor_loss": -28.39270842552185, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.522716522216797, "step": 68000}
{"episode_reward": 99.1775687909604, "episode": 69.0, "batch_reward": 0.19173711302876473, "critic_loss": 0.7622674214541912, "actor_loss": -27.850915218353272, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.534260749816895, "step": 69000}
{"episode_reward": 107.99333955167127, "episode": 70.0, "batch_reward": 0.19127124314010144, "critic_loss": 0.6834752196967602, "actor_loss": -27.971402366638184, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.53110909461975, "step": 70000}
{"episode_reward": 191.2368816805018, "episode": 71.0, "batch_reward": 0.1900072160065174, "critic_loss": 0.7178129128664732, "actor_loss": -27.708261024475096, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.987250089645386, "step": 71000}
{"episode_reward": 43.822779889807315, "episode": 72.0, "batch_reward": 0.19055518670380114, "critic_loss": 0.7897435119599104, "actor_loss": -28.104747297286988, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.541175842285156, "step": 72000}
{"episode_reward": 255.0268739621403, "episode": 73.0, "batch_reward": 0.19033771902322769, "critic_loss": 0.7573988656699657, "actor_loss": -27.397532178878784, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.598195552825928, "step": 73000}
{"episode_reward": 211.30305107340126, "episode": 74.0, "batch_reward": 0.189338180154562, "critic_loss": 0.7498081151247025, "actor_loss": -27.20773398399353, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.55431032180786, "step": 74000}
{"episode_reward": 91.362650624074, "episode": 75.0, "batch_reward": 0.19021693402528764, "critic_loss": 0.8201679998785257, "actor_loss": -28.128554889678956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.563291788101196, "step": 75000}
{"episode_reward": 293.47173965477, "episode": 76.0, "batch_reward": 0.18998735502362252, "critic_loss": 0.8399810297042132, "actor_loss": -27.51280555534363, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.568962812423706, "step": 76000}
{"episode_reward": 82.49023841447158, "episode": 77.0, "batch_reward": 0.1888952194005251, "critic_loss": 0.9502347209304571, "actor_loss": -27.28754566192627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.554569005966187, "step": 77000}
{"episode_reward": 211.30648127222995, "episode": 78.0, "batch_reward": 0.19016432125866414, "critic_loss": 0.9982117034047842, "actor_loss": -27.26143197631836, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.554038524627686, "step": 78000}
{"episode_reward": 390.7909038806456, "episode": 79.0, "batch_reward": 0.19260801036655903, "critic_loss": 0.9212472338378429, "actor_loss": -27.685762376785277, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.51382613182068, "step": 79000}
{"episode_reward": 292.4241230419325, "episode": 80.0, "batch_reward": 0.19359382708370684, "critic_loss": 0.9559317507147789, "actor_loss": -27.955719213485718, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.55074644088745, "step": 80000}
{"episode_reward": 242.6447689823561, "episode": 81.0, "batch_reward": 0.1951328916400671, "critic_loss": 1.0058896441459655, "actor_loss": -27.91038424873352, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.84165048599243, "step": 81000}
{"episode_reward": 278.30797618014606, "episode": 82.0, "batch_reward": 0.19588268938660622, "critic_loss": 1.0282229718863964, "actor_loss": -27.61818035697937, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.549256324768066, "step": 82000}
{"episode_reward": 464.1303184169284, "episode": 83.0, "batch_reward": 0.19802078707516194, "critic_loss": 1.0662684694826603, "actor_loss": -28.24473475265503, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.528436183929443, "step": 83000}
{"episode_reward": 111.76937106508485, "episode": 84.0, "batch_reward": 0.19799814154207707, "critic_loss": 0.9286617688536644, "actor_loss": -27.81842304420471, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.525482416152954, "step": 84000}
{"episode_reward": 382.9667006355849, "episode": 85.0, "batch_reward": 0.19853126280009747, "critic_loss": 0.9227446361631155, "actor_loss": -28.324162439346313, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.527241706848145, "step": 85000}
{"episode_reward": 159.39909829204356, "episode": 86.0, "batch_reward": 0.19865837633609773, "critic_loss": 1.124188396513462, "actor_loss": -28.194152866363524, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.51118302345276, "step": 86000}
{"episode_reward": 335.4983426932291, "episode": 87.0, "batch_reward": 0.20121312868595123, "critic_loss": 1.2541667756438255, "actor_loss": -28.24052442932129, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.532873153686523, "step": 87000}
{"episode_reward": 467.95802207677764, "episode": 88.0, "batch_reward": 0.203796001419425, "critic_loss": 1.3247540357112884, "actor_loss": -28.480669620513915, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.866198778152466, "step": 88000}
{"episode_reward": 128.60360467385235, "episode": 89.0, "batch_reward": 0.20386282593011856, "critic_loss": 1.3263309258818627, "actor_loss": -28.570744318008423, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.49789810180664, "step": 89000}
{"episode_reward": 365.91594744587843, "episode": 90.0, "batch_reward": 0.20503579485416412, "critic_loss": 1.28648955437541, "actor_loss": -28.000829370498657, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.51772975921631, "step": 90000}
{"episode_reward": 452.59150666548845, "episode": 91.0, "batch_reward": 0.20783462692797183, "critic_loss": 1.160106998026371, "actor_loss": -28.873899633407593, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.84023952484131, "step": 91000}
{"episode_reward": 483.896302980772, "episode": 92.0, "batch_reward": 0.20939317266643048, "critic_loss": 1.0967991599142553, "actor_loss": -28.751061693191527, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.50184178352356, "step": 92000}
{"episode_reward": 116.98527452359319, "episode": 93.0, "batch_reward": 0.21032114240527153, "critic_loss": 1.0524638900756835, "actor_loss": -29.03070260810852, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.525826692581177, "step": 93000}
{"episode_reward": 495.69422211869386, "episode": 94.0, "batch_reward": 0.2134655510187149, "critic_loss": 0.9833831625580788, "actor_loss": -28.76486265563965, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.521517038345337, "step": 94000}
{"episode_reward": 450.41340635132207, "episode": 95.0, "batch_reward": 0.21494372975826265, "critic_loss": 0.8834989280104637, "actor_loss": -29.388246959686278, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.512528896331787, "step": 95000}
{"episode_reward": 481.39407458140676, "episode": 96.0, "batch_reward": 0.21823685556650163, "critic_loss": 0.7554169271439314, "actor_loss": -29.590588388442992, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.506904363632202, "step": 96000}
{"episode_reward": 140.71557221855574, "episode": 97.0, "batch_reward": 0.21666141217947008, "critic_loss": 0.7007223005443811, "actor_loss": -29.345165327072145, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.524712324142456, "step": 97000}
{"episode_reward": 463.0185630332185, "episode": 98.0, "batch_reward": 0.22021916487812995, "critic_loss": 0.7098377913087607, "actor_loss": -29.43019003677368, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.509557723999023, "step": 98000}
{"episode_reward": 490.2799317211097, "episode": 99.0, "batch_reward": 0.2215704963505268, "critic_loss": 0.6568453053236007, "actor_loss": -29.70224181365967, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.517589330673218, "step": 99000}
{"episode_reward": 459.3006561516693, "episode": 100.0, "batch_reward": 0.22536817629635333, "critic_loss": 0.685921384960413, "actor_loss": -30.110376489639282, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.505237340927124, "step": 100000}
{"episode_reward": 482.20483061015574, "episode": 101.0, "batch_reward": 0.22731207691133024, "critic_loss": 0.6988235577791929, "actor_loss": -29.81475254249573, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.81809902191162, "step": 101000}
{"episode_reward": 468.7063471201371, "episode": 102.0, "batch_reward": 0.2292426516264677, "critic_loss": 0.7236728745549917, "actor_loss": -30.550900806427002, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.544212341308594, "step": 102000}
{"episode_reward": 291.88392740891777, "episode": 103.0, "batch_reward": 0.23015037940442562, "critic_loss": 0.7026168449670076, "actor_loss": -30.18438946723938, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.547497034072876, "step": 103000}
{"episode_reward": 167.4479898857007, "episode": 104.0, "batch_reward": 0.23105943231284617, "critic_loss": 0.781287521764636, "actor_loss": -30.663034364700316, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.504908323287964, "step": 104000}
{"episode_reward": 441.2570143777768, "episode": 105.0, "batch_reward": 0.23169843249022962, "critic_loss": 0.8598382050991058, "actor_loss": -30.591958797454833, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.515156984329224, "step": 105000}
{"episode_reward": 421.5777696653129, "episode": 106.0, "batch_reward": 0.23234062738716602, "critic_loss": 0.869646408289671, "actor_loss": -30.812417238235472, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.490053176879883, "step": 106000}
{"episode_reward": 100.2919608511956, "episode": 107.0, "batch_reward": 0.23155172054469586, "critic_loss": 0.9796725933551789, "actor_loss": -30.69585644721985, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.49427580833435, "step": 107000}
{"episode_reward": 289.60732984566584, "episode": 108.0, "batch_reward": 0.23155419521033763, "critic_loss": 0.8991893176883459, "actor_loss": -30.62150310707092, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.547423839569092, "step": 108000}
{"episode_reward": 58.08037461701875, "episode": 109.0, "batch_reward": 0.23142654933035373, "critic_loss": 0.8588584000766277, "actor_loss": -30.632070652008057, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.522398948669434, "step": 109000}
{"episode_reward": 365.0959807735519, "episode": 110.0, "batch_reward": 0.23274678906798363, "critic_loss": 1.019718217998743, "actor_loss": -30.643595376968385, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.529666662216187, "step": 110000}
{"episode_reward": 464.7317618796039, "episode": 111.0, "batch_reward": 0.2352886953651905, "critic_loss": 0.9374333256781101, "actor_loss": -30.801968982696533, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.86470603942871, "step": 111000}
{"episode_reward": 506.61899446327027, "episode": 112.0, "batch_reward": 0.23712542162835598, "critic_loss": 0.9570956222712994, "actor_loss": -31.218260320663454, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.531996488571167, "step": 112000}
{"episode_reward": 492.40981256767685, "episode": 113.0, "batch_reward": 0.2392467743754387, "critic_loss": 0.8800572438687086, "actor_loss": -30.955642555236818, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.568126440048218, "step": 113000}
{"episode_reward": 490.0265639384598, "episode": 114.0, "batch_reward": 0.24222011524438858, "critic_loss": 0.7465814776867629, "actor_loss": -31.666687900543213, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.551007747650146, "step": 114000}
{"episode_reward": 482.657383327139, "episode": 115.0, "batch_reward": 0.2453105175793171, "critic_loss": 0.9065510025322437, "actor_loss": -32.156667854309084, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.548689603805542, "step": 115000}
{"episode_reward": 469.67400022659075, "episode": 116.0, "batch_reward": 0.24445830580592157, "critic_loss": 0.9028637149631977, "actor_loss": -32.00895505142212, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.55635404586792, "step": 116000}
{"episode_reward": 222.3589010633442, "episode": 117.0, "batch_reward": 0.24595428216457366, "critic_loss": 0.9193888285458088, "actor_loss": -32.0037905960083, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.57568907737732, "step": 117000}
{"episode_reward": 280.68859349863334, "episode": 118.0, "batch_reward": 0.24565242306888105, "critic_loss": 0.9796770529448986, "actor_loss": -31.778014400482178, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.565284967422485, "step": 118000}
{"episode_reward": 125.60343033430509, "episode": 119.0, "batch_reward": 0.24492037269473077, "critic_loss": 0.9189818609952927, "actor_loss": -31.620347332000733, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.55087661743164, "step": 119000}
{"episode_reward": 500.27836202750524, "episode": 120.0, "batch_reward": 0.24669981445372105, "critic_loss": 0.8705735711753368, "actor_loss": -32.429169605255126, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.54599928855896, "step": 120000}
{"episode_reward": 463.07288058996875, "episode": 121.0, "batch_reward": 0.2483058128654957, "critic_loss": 0.8544832423180342, "actor_loss": -32.2090820350647, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.153541803359985, "step": 121000}
{"episode_reward": 319.64080855641265, "episode": 122.0, "batch_reward": 0.24921685953438283, "critic_loss": 0.8670824276804924, "actor_loss": -32.27585647964477, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.542574644088745, "step": 122000}
{"episode_reward": 153.3377160729109, "episode": 123.0, "batch_reward": 0.24892162857949734, "critic_loss": 1.0170421919822692, "actor_loss": -32.4035588760376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.56206512451172, "step": 123000}
{"episode_reward": 363.60081775452176, "episode": 124.0, "batch_reward": 0.25021505877375605, "critic_loss": 0.9917193968594075, "actor_loss": -32.20247518920898, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.556051015853882, "step": 124000}
{"episode_reward": 489.25494609575674, "episode": 125.0, "batch_reward": 0.2518109452575445, "critic_loss": 0.9175076914131641, "actor_loss": -32.79697361755371, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.532323837280273, "step": 125000}
{"episode_reward": 471.23526499324356, "episode": 126.0, "batch_reward": 0.25457247480750084, "critic_loss": 0.9933071409165859, "actor_loss": -32.857870342254635, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.53667688369751, "step": 126000}
{"episode_reward": 491.57178399848806, "episode": 127.0, "batch_reward": 0.2543484760224819, "critic_loss": 0.9938336116075516, "actor_loss": -32.63552347183227, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.58776879310608, "step": 127000}
{"episode_reward": 159.98220852453179, "episode": 128.0, "batch_reward": 0.25401621291041376, "critic_loss": 0.8655641485750675, "actor_loss": -32.56194992828369, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.57044291496277, "step": 128000}
{"episode_reward": 471.65423247324463, "episode": 129.0, "batch_reward": 0.2557019181549549, "critic_loss": 0.7823275758624076, "actor_loss": -32.774632522583005, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.540470123291016, "step": 129000}
{"episode_reward": 397.3035815930366, "episode": 130.0, "batch_reward": 0.25771405300498007, "critic_loss": 0.8726067322641611, "actor_loss": -32.77855475997925, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.5565664768219, "step": 130000}
{"episode_reward": 419.9409378236691, "episode": 131.0, "batch_reward": 0.2590068660378456, "critic_loss": 0.9752883163392544, "actor_loss": -32.21788916015625, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.12467408180237, "step": 131000}
{"episode_reward": 468.01944309645614, "episode": 132.0, "batch_reward": 0.25987895515561105, "critic_loss": 0.9316552755236626, "actor_loss": -32.54686108779907, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.51656413078308, "step": 132000}
{"episode_reward": 505.51799878320975, "episode": 133.0, "batch_reward": 0.2612776432335377, "critic_loss": 0.874875484675169, "actor_loss": -33.419164794921876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.529067277908325, "step": 133000}
{"episode_reward": 390.7818489810445, "episode": 134.0, "batch_reward": 0.2627889644354582, "critic_loss": 0.9467703835070134, "actor_loss": -33.580331283569336, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.50789213180542, "step": 134000}
{"episode_reward": 457.69661309721226, "episode": 135.0, "batch_reward": 0.26387634444236757, "critic_loss": 0.9400021272599697, "actor_loss": -33.54616730499268, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.503902673721313, "step": 135000}
{"episode_reward": 483.14144354856995, "episode": 136.0, "batch_reward": 0.26541036275029184, "critic_loss": 0.9001995847523212, "actor_loss": -33.70928786087036, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.49511218070984, "step": 136000}
{"episode_reward": 158.89269846813286, "episode": 137.0, "batch_reward": 0.2657145810723305, "critic_loss": 0.8723606635928154, "actor_loss": -33.71113386917114, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.529794454574585, "step": 137000}
{"episode_reward": 440.57813797030803, "episode": 138.0, "batch_reward": 0.2665681308656931, "critic_loss": 0.9929035938382149, "actor_loss": -32.862796295166014, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.533450603485107, "step": 138000}
{"episode_reward": 487.9859253084971, "episode": 139.0, "batch_reward": 0.26782885614037516, "critic_loss": 0.9109232717305422, "actor_loss": -33.06191036987305, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.482495069503784, "step": 139000}
{"episode_reward": 475.815904002751, "episode": 140.0, "batch_reward": 0.2698127688765526, "critic_loss": 0.8415794602185488, "actor_loss": -33.53252871704102, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.500277996063232, "step": 140000}
{"episode_reward": 397.8275064983278, "episode": 141.0, "batch_reward": 0.2708749033361673, "critic_loss": 0.7616094380319118, "actor_loss": -33.55722310638428, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.78058123588562, "step": 141000}
{"episode_reward": 492.6723260888993, "episode": 142.0, "batch_reward": 0.2723088951408863, "critic_loss": 0.746155481159687, "actor_loss": -33.97000149917603, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.519473791122437, "step": 142000}
{"episode_reward": 498.7484184589871, "episode": 143.0, "batch_reward": 0.27284461726248266, "critic_loss": 0.7894110382646322, "actor_loss": -34.62669633483887, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.53288960456848, "step": 143000}
{"episode_reward": 286.26749797134664, "episode": 144.0, "batch_reward": 0.2742234645336866, "critic_loss": 0.9014444268643856, "actor_loss": -34.37987507247925, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.512605905532837, "step": 144000}
{"episode_reward": 143.30899563454082, "episode": 145.0, "batch_reward": 0.27321713402867315, "critic_loss": 0.8630046170204878, "actor_loss": -34.88306613922119, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.5004301071167, "step": 145000}
{"episode_reward": 385.6359485201253, "episode": 146.0, "batch_reward": 0.2729034562408924, "critic_loss": 0.8972975004315377, "actor_loss": -33.95658642578125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.496108531951904, "step": 146000}
{"episode_reward": 481.2237826741077, "episode": 147.0, "batch_reward": 0.27561583913862703, "critic_loss": 0.8570405002236366, "actor_loss": -34.10903461456299, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.535234928131104, "step": 147000}
{"episode_reward": 472.12242374870266, "episode": 148.0, "batch_reward": 0.2760468575656414, "critic_loss": 0.8384813210368156, "actor_loss": -34.30688957595825, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.51056933403015, "step": 148000}
{"episode_reward": 481.7037769100902, "episode": 149.0, "batch_reward": 0.27778986120224, "critic_loss": 0.8462317412346602, "actor_loss": -34.394255275726316, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.51395010948181, "step": 149000}
{"episode_reward": 486.24045364940343, "episode": 150.0, "batch_reward": 0.2792036860883236, "critic_loss": 0.8972298142164946, "actor_loss": -34.55808944320679, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
