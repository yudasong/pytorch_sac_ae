{"episode_reward": 0.0, "episode": 1.0, "duration": 17.528756856918335, "step": 1000}
{"episode_reward": 4.20996189079657, "episode": 2.0, "duration": 1.492396593093872, "step": 2000}
{"episode_reward": 252.2457487418515, "episode": 3.0, "batch_reward": 0.12117869301477684, "critic_loss": 0.009793163494881001, "actor_loss": -8.505369628485546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.6222825050354, "step": 3000}
{"episode_reward": 7.5964965164161775, "episode": 4.0, "batch_reward": 0.07689477883651853, "critic_loss": 0.004642877469712403, "actor_loss": -8.574180523872375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.70548105239868, "step": 4000}
{"episode_reward": 4.254426109744743, "episode": 5.0, "batch_reward": 0.06047554493136704, "critic_loss": 0.003877895671175793, "actor_loss": -8.053735898017884, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.482962131500244, "step": 5000}
{"episode_reward": 6.110998080728734, "episode": 6.0, "batch_reward": 0.051032513108104464, "critic_loss": 0.008506206962047146, "actor_loss": -7.405463455438614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.681180000305176, "step": 6000}
{"episode_reward": 7.124959091327538, "episode": 7.0, "batch_reward": 0.044836635787039995, "critic_loss": 0.005835978974006139, "actor_loss": -6.333303324222564, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.0759174823761, "step": 7000}
{"episode_reward": 8.983413003413638, "episode": 8.0, "batch_reward": 0.04004981570132077, "critic_loss": 0.006833881688420661, "actor_loss": -7.196554983854294, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.505933046340942, "step": 8000}
{"episode_reward": 10.405385401834716, "episode": 9.0, "batch_reward": 0.03610429963283241, "critic_loss": 0.0059435472835320975, "actor_loss": -5.871636412382125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.4987051486969, "step": 9000}
{"episode_reward": 7.898866384745747, "episode": 10.0, "batch_reward": 0.033060683728195726, "critic_loss": 0.0038565628782962448, "actor_loss": -5.791390981912613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.234556198120117, "step": 10000}
{"episode_reward": 8.975639604451326, "episode": 11.0, "batch_reward": 0.030085825421847404, "critic_loss": 0.0037279252675944006, "actor_loss": -5.116184732556343, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.74348521232605, "step": 11000}
{"episode_reward": 8.35333972254592, "episode": 12.0, "batch_reward": 0.028937633235007525, "critic_loss": 0.005232789187808521, "actor_loss": -5.226991061449051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.527506589889526, "step": 12000}
{"episode_reward": 7.242282263354002, "episode": 13.0, "batch_reward": 0.026800658385269342, "critic_loss": 0.009203146687359548, "actor_loss": -5.504328717112541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.213780164718628, "step": 13000}
{"episode_reward": 2.970550247049846, "episode": 14.0, "batch_reward": 0.025295666323043406, "critic_loss": 0.012308568175067194, "actor_loss": -6.244126508712768, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.23455810546875, "step": 14000}
{"episode_reward": 7.819532168932447, "episode": 15.0, "batch_reward": 0.024242239740677178, "critic_loss": 0.008155578497098758, "actor_loss": -6.838973997592926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.538779735565186, "step": 15000}
{"episode_reward": 5.447520415427303, "episode": 16.0, "batch_reward": 0.022980812328867613, "critic_loss": 0.006127582937944681, "actor_loss": -6.8862665748596195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.976113080978394, "step": 16000}
{"episode_reward": 6.255196640946571, "episode": 17.0, "batch_reward": 0.022017385637387633, "critic_loss": 0.004286751277046278, "actor_loss": -6.360385740280152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.438785791397095, "step": 17000}
{"episode_reward": 6.735027821359847, "episode": 18.0, "batch_reward": 0.02108636318380013, "critic_loss": 0.003520915981498547, "actor_loss": -6.600677639722824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.787562608718872, "step": 18000}
{"episode_reward": 6.227141409256709, "episode": 19.0, "batch_reward": 0.019976348064374178, "critic_loss": 0.0031583538675913586, "actor_loss": -6.89172879242897, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.51571297645569, "step": 19000}
{"episode_reward": 5.747380169021133, "episode": 20.0, "batch_reward": 0.019386773891281336, "critic_loss": 0.002874304286640836, "actor_loss": -6.7935557372570035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.17853093147278, "step": 20000}
{"episode_reward": 5.925897426025382, "episode": 21.0, "batch_reward": 0.0184051934403833, "critic_loss": 0.0027964604240260085, "actor_loss": -6.362919546842575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.98643779754639, "step": 21000}
{"episode_reward": 6.287608993986257, "episode": 22.0, "batch_reward": 0.017813408355694265, "critic_loss": 0.003212934626149945, "actor_loss": -7.223540212631225, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.518627643585205, "step": 22000}
{"episode_reward": 6.068127724032988, "episode": 23.0, "batch_reward": 0.01777361897099763, "critic_loss": 0.0030576093284762464, "actor_loss": -6.03485371541977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.751737356185913, "step": 23000}
{"episode_reward": 6.440606319716529, "episode": 24.0, "batch_reward": 0.01686833723075688, "critic_loss": 0.003202226007124409, "actor_loss": -6.499723940849305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.75629425048828, "step": 24000}
{"episode_reward": 5.860912985376785, "episode": 25.0, "batch_reward": 0.016181727295741438, "critic_loss": 0.00277227581711486, "actor_loss": -6.387416392803192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.730310440063477, "step": 25000}
{"episode_reward": 6.222972173255029, "episode": 26.0, "batch_reward": 0.01626859827246517, "critic_loss": 0.003063632702222094, "actor_loss": -5.982501908302307, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.473048210144043, "step": 26000}
{"episode_reward": 6.045587058168344, "episode": 27.0, "batch_reward": 0.015783641362562776, "critic_loss": 0.003001210112182889, "actor_loss": -6.06746829533577, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.43114733695984, "step": 27000}
{"episode_reward": 6.955707134056817, "episode": 28.0, "batch_reward": 0.015804888885002585, "critic_loss": 0.002549671608750941, "actor_loss": -6.049327909946442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.25587487220764, "step": 28000}
{"episode_reward": 7.3157137513160295, "episode": 29.0, "batch_reward": 0.015196566276717931, "critic_loss": 0.0020380328482133337, "actor_loss": -5.7954427161216735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.56474804878235, "step": 29000}
{"episode_reward": 6.694421171393089, "episode": 30.0, "batch_reward": 0.015031024566385895, "critic_loss": 0.0020230178371421063, "actor_loss": -6.0898800847530365, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.484662532806396, "step": 30000}
{"episode_reward": 4.853009294542102, "episode": 31.0, "batch_reward": 0.014839579845778644, "critic_loss": 0.0016508069775882177, "actor_loss": -6.635487075090408, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.33599615097046, "step": 31000}
{"episode_reward": 4.934459224529849, "episode": 32.0, "batch_reward": 0.01455823225993663, "critic_loss": 0.0017630315722199157, "actor_loss": -6.089051888227463, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.7338764667511, "step": 32000}
{"episode_reward": 5.449265288714693, "episode": 33.0, "batch_reward": 0.013913786279037594, "critic_loss": 0.0015425702347420156, "actor_loss": -5.878522388696671, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.529690265655518, "step": 33000}
{"episode_reward": 6.017741694282309, "episode": 34.0, "batch_reward": 0.013696388720069081, "critic_loss": 0.0020963250682980287, "actor_loss": -6.5896162545681, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.601703643798828, "step": 34000}
{"episode_reward": 7.576165404450185, "episode": 35.0, "batch_reward": 0.013754043115535752, "critic_loss": 0.0021965054268948733, "actor_loss": -5.747469785690307, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.01720690727234, "step": 35000}
{"episode_reward": 18.16033066342548, "episode": 36.0, "batch_reward": 0.013804216478485613, "critic_loss": 0.002642641307145823, "actor_loss": -7.0176775207519535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.67415499687195, "step": 36000}
{"episode_reward": 10.69919652866615, "episode": 37.0, "batch_reward": 0.013724998048972339, "critic_loss": 0.002475722245115321, "actor_loss": -6.70503434419632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.57137680053711, "step": 37000}
{"episode_reward": 8.123356375002505, "episode": 38.0, "batch_reward": 0.013946567873936146, "critic_loss": 0.0024146548960125073, "actor_loss": -6.404227978229523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.745336294174194, "step": 38000}
{"episode_reward": 8.82105587935989, "episode": 39.0, "batch_reward": 0.013446969142183662, "critic_loss": 0.0023906152241979727, "actor_loss": -6.469884189128876, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.972059965133667, "step": 39000}
{"episode_reward": 8.659974482864484, "episode": 40.0, "batch_reward": 0.01338808656996116, "critic_loss": 0.0025759362460812552, "actor_loss": -6.587266279220581, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.50192165374756, "step": 40000}
{"episode_reward": 9.04337005548284, "episode": 41.0, "batch_reward": 0.013375733472872525, "critic_loss": 0.002623155437933747, "actor_loss": -6.121927450656891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.64256477355957, "step": 41000}
{"episode_reward": 9.103241869155804, "episode": 42.0, "batch_reward": 0.013237619296647608, "critic_loss": 0.003275825707416516, "actor_loss": -6.220775688409805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.989936351776123, "step": 42000}
{"episode_reward": 8.249072362595756, "episode": 43.0, "batch_reward": 0.013083970430772751, "critic_loss": 0.004151013154361863, "actor_loss": -6.710303748130799, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.551809310913086, "step": 43000}
{"episode_reward": 4.026031454141769, "episode": 44.0, "batch_reward": 0.012759801459498704, "critic_loss": 0.005014332278049551, "actor_loss": -6.420341736555099, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.49732732772827, "step": 44000}
{"episode_reward": 4.181356604574036, "episode": 45.0, "batch_reward": 0.012587671111803502, "critic_loss": 0.0036544725684798324, "actor_loss": -6.067240203142166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.455585718154907, "step": 45000}
{"episode_reward": 4.2953830857511335, "episode": 46.0, "batch_reward": 0.012511916311457753, "critic_loss": 0.0029203983276966028, "actor_loss": -5.681969384670258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.4398992061615, "step": 46000}
{"episode_reward": 4.45984011894102, "episode": 47.0, "batch_reward": 0.01216194544848986, "critic_loss": 0.0028235307561117226, "actor_loss": -6.183262116670608, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.501211166381836, "step": 47000}
{"episode_reward": 4.196685686685238, "episode": 48.0, "batch_reward": 0.01198815855733119, "critic_loss": 0.002824518537672702, "actor_loss": -5.501410482645035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.78927755355835, "step": 48000}
{"episode_reward": 6.382710392077113, "episode": 49.0, "batch_reward": 0.011918142090085893, "critic_loss": 0.0034522465151385403, "actor_loss": -6.6067221603393556, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.489699125289917, "step": 49000}
{"episode_reward": 8.838273922697118, "episode": 50.0, "batch_reward": 0.011922034435672685, "critic_loss": 0.0030627372425515204, "actor_loss": -6.670883858919144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.812920331954956, "step": 50000}
{"episode_reward": 7.6024939809375525, "episode": 51.0, "batch_reward": 0.011788411277346313, "critic_loss": 0.002239844702009577, "actor_loss": -6.356546755075454, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.648194551467896, "step": 51000}
{"episode_reward": 5.960631735852546, "episode": 52.0, "batch_reward": 0.01149369933991693, "critic_loss": 0.002439626508858055, "actor_loss": -6.024585049390793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.604490756988525, "step": 52000}
{"episode_reward": 6.027743738923085, "episode": 53.0, "batch_reward": 0.011752338861115277, "critic_loss": 0.0018747911531245337, "actor_loss": -6.850361141920089, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.774622917175293, "step": 53000}
{"episode_reward": 7.394401634271736, "episode": 54.0, "batch_reward": 0.011203460549004375, "critic_loss": 0.002568925593805034, "actor_loss": -6.567552491664887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.53700065612793, "step": 54000}
{"episode_reward": 10.21322226447684, "episode": 55.0, "batch_reward": 0.011374603984178975, "critic_loss": 0.00270890370500274, "actor_loss": -6.787705089569092, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.284773111343384, "step": 55000}
{"episode_reward": 8.033222011858886, "episode": 56.0, "batch_reward": 0.011298322333022952, "critic_loss": 0.002199762051284779, "actor_loss": -6.670625854969025, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.95862364768982, "step": 56000}
{"episode_reward": 6.079095943207352, "episode": 57.0, "batch_reward": 0.01110807698685676, "critic_loss": 0.0015501695415005088, "actor_loss": -6.108304467916489, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.499199867248535, "step": 57000}
{"episode_reward": 7.884941494871218, "episode": 58.0, "batch_reward": 0.011040637658443302, "critic_loss": 0.0010909290705312742, "actor_loss": -6.583665433168411, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.55980944633484, "step": 58000}
{"episode_reward": 5.7404947593799704, "episode": 59.0, "batch_reward": 0.011054695607163012, "critic_loss": 0.0011680468890117482, "actor_loss": -5.722694658279419, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.162648677825928, "step": 59000}
{"episode_reward": 6.063895892776075, "episode": 60.0, "batch_reward": 0.01110013770009391, "critic_loss": 0.0012338266492297406, "actor_loss": -5.395503882646561, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17997694015503, "step": 60000}
{"episode_reward": 6.530551983285943, "episode": 61.0, "batch_reward": 0.010819716122932732, "critic_loss": 0.0009933064344804733, "actor_loss": -6.141181912183762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.469897747039795, "step": 61000}
{"episode_reward": 9.524029205577914, "episode": 62.0, "batch_reward": 0.010899603215977549, "critic_loss": 0.0012389912632061169, "actor_loss": -5.607595836639404, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03440761566162, "step": 62000}
{"episode_reward": 6.621367262335107, "episode": 63.0, "batch_reward": 0.010807206832338125, "critic_loss": 0.0012955093563068658, "actor_loss": -5.874073497772216, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.06204652786255, "step": 63000}
{"episode_reward": 7.276191161805456, "episode": 64.0, "batch_reward": 0.010817674606805668, "critic_loss": 0.0012469159433385357, "actor_loss": -6.323820065021515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.070518732070923, "step": 64000}
{"episode_reward": 6.749874013016034, "episode": 65.0, "batch_reward": 0.010736490181647242, "critic_loss": 0.001723754737060517, "actor_loss": -6.243299667358398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03641176223755, "step": 65000}
{"episode_reward": 5.6762426482469275, "episode": 66.0, "batch_reward": 0.010609540364937857, "critic_loss": 0.0014439656278991606, "actor_loss": -5.854828068733215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.073129177093506, "step": 66000}
{"episode_reward": 5.485802494759188, "episode": 67.0, "batch_reward": 0.010752219145186245, "critic_loss": 0.001354527764749946, "actor_loss": -5.451849330425262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.06304931640625, "step": 67000}
{"episode_reward": 9.124570609008655, "episode": 68.0, "batch_reward": 0.010625368744833394, "critic_loss": 0.0015902195149683394, "actor_loss": -5.809322104930878, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.029120206832886, "step": 68000}
{"episode_reward": 6.254556430320488, "episode": 69.0, "batch_reward": 0.01046796255116351, "critic_loss": 0.0012253948118304834, "actor_loss": -5.388152787089348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.06417989730835, "step": 69000}
{"episode_reward": 6.335672138891079, "episode": 70.0, "batch_reward": 0.010373229290824383, "critic_loss": 0.0014163599330058788, "actor_loss": -5.2244296470880505, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.071250438690186, "step": 70000}
{"episode_reward": 7.438950424528512, "episode": 71.0, "batch_reward": 0.0103915413483046, "critic_loss": 0.0016346432610880584, "actor_loss": -5.930422701120377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.446717739105225, "step": 71000}
{"episode_reward": 5.0776686373533275, "episode": 72.0, "batch_reward": 0.010316721625626087, "critic_loss": 0.0013630665404198226, "actor_loss": -5.117564609646797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.045663118362427, "step": 72000}
{"episode_reward": 6.3959217174383936, "episode": 73.0, "batch_reward": 0.010174291792325676, "critic_loss": 0.0014514659930428024, "actor_loss": -5.763317947506905, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.053059577941895, "step": 73000}
{"episode_reward": 6.25139237264592, "episode": 74.0, "batch_reward": 0.01025338965957053, "critic_loss": 0.0012407915573567152, "actor_loss": -5.926211577415466, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.06222677230835, "step": 74000}
{"episode_reward": 6.975300363500252, "episode": 75.0, "batch_reward": 0.010095126561122015, "critic_loss": 0.001254309181647841, "actor_loss": -5.9967559758424756, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.051382780075073, "step": 75000}
{"episode_reward": 6.4294530078778624, "episode": 76.0, "batch_reward": 0.010179084733128547, "critic_loss": 0.0012669137059419882, "actor_loss": -6.055196696519852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.07531499862671, "step": 76000}
{"episode_reward": 6.5600932614940035, "episode": 77.0, "batch_reward": 0.010155928229447454, "critic_loss": 0.0012157113299763296, "actor_loss": -5.850048972725868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05558705329895, "step": 77000}
{"episode_reward": 5.375697526309582, "episode": 78.0, "batch_reward": 0.0100473837738391, "critic_loss": 0.001619279854610795, "actor_loss": -4.773028580307961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04076313972473, "step": 78000}
{"episode_reward": 11.457101987308349, "episode": 79.0, "batch_reward": 0.009717983189504594, "critic_loss": 0.0021854639793746173, "actor_loss": -5.532299751996994, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04727292060852, "step": 79000}
{"episode_reward": 7.509674361553317, "episode": 80.0, "batch_reward": 0.010090112104080617, "critic_loss": 0.001320983137964504, "actor_loss": -5.480371287703514, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.040955543518066, "step": 80000}
{"episode_reward": 5.8799759995782175, "episode": 81.0, "batch_reward": 0.009988362348172814, "critic_loss": 0.0017259552976174747, "actor_loss": -5.561299522399902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.461068630218506, "step": 81000}
{"episode_reward": 6.1878605656049395, "episode": 82.0, "batch_reward": 0.010001419447828085, "critic_loss": 0.0016729835672012997, "actor_loss": -5.49739102768898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.053213357925415, "step": 82000}
{"episode_reward": 5.550309283960034, "episode": 83.0, "batch_reward": 0.009899700841866433, "critic_loss": 0.001505910917883739, "actor_loss": -5.155234118700028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.043429851531982, "step": 83000}
{"episode_reward": 6.550461701999767, "episode": 84.0, "batch_reward": 0.009802575738867746, "critic_loss": 0.0012769797590444795, "actor_loss": -5.741560081362724, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.061609745025635, "step": 84000}
{"episode_reward": 7.0201366446686855, "episode": 85.0, "batch_reward": 0.009833005441818386, "critic_loss": 0.001020607061960618, "actor_loss": -4.903175674200058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.08321189880371, "step": 85000}
{"episode_reward": 6.483606895009852, "episode": 86.0, "batch_reward": 0.009751946028554812, "critic_loss": 0.0011819395269849337, "actor_loss": -5.66127507507801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.028510093688965, "step": 86000}
{"episode_reward": 6.069888329379328, "episode": 87.0, "batch_reward": 0.00987034613150172, "critic_loss": 0.001212695741414791, "actor_loss": -5.440729456782341, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.038275718688965, "step": 87000}
{"episode_reward": 6.791830408149612, "episode": 88.0, "batch_reward": 0.009941472405334934, "critic_loss": 0.0012570386558945757, "actor_loss": -4.843315389633179, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.067636489868164, "step": 88000}
{"episode_reward": 6.218610269972214, "episode": 89.0, "batch_reward": 0.009648164316080511, "critic_loss": 0.0014076929991279031, "actor_loss": -5.485399900615215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04151487350464, "step": 89000}
{"episode_reward": 7.86124966197478, "episode": 90.0, "batch_reward": 0.009676142359618098, "critic_loss": 0.0013679978430154733, "actor_loss": -5.91502329480648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.065220832824707, "step": 90000}
{"episode_reward": 6.1635908261288845, "episode": 91.0, "batch_reward": 0.009817504140315578, "critic_loss": 0.0012505708138633054, "actor_loss": -5.631586730897427, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.44137978553772, "step": 91000}
{"episode_reward": 6.620026676092936, "episode": 92.0, "batch_reward": 0.009627337120706216, "critic_loss": 0.0014600889900757467, "actor_loss": -5.409512239098549, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.061827898025513, "step": 92000}
{"episode_reward": 6.847630782496477, "episode": 93.0, "batch_reward": 0.009590276636183262, "critic_loss": 0.001317992839642102, "actor_loss": -4.903485276103019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.050696849822998, "step": 93000}
{"episode_reward": 6.747653256236655, "episode": 94.0, "batch_reward": 0.00951953527214937, "critic_loss": 0.0012358817762578838, "actor_loss": -5.006671193003655, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.056793451309204, "step": 94000}
{"episode_reward": 6.5786869543292426, "episode": 95.0, "batch_reward": 0.009583851132309064, "critic_loss": 0.0013486432884819806, "actor_loss": -5.761801704764366, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.06546449661255, "step": 95000}
{"episode_reward": 8.459947821082539, "episode": 96.0, "batch_reward": 0.009500426385318861, "critic_loss": 0.0013526222058280837, "actor_loss": -5.173105984330177, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.069444179534912, "step": 96000}
{"episode_reward": 8.021130014787616, "episode": 97.0, "batch_reward": 0.009547003023559228, "critic_loss": 0.0015164538850658573, "actor_loss": -6.566748024940491, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.08250093460083, "step": 97000}
{"episode_reward": 5.453197124319139, "episode": 98.0, "batch_reward": 0.009444756295531988, "critic_loss": 0.0013924015879747459, "actor_loss": -7.630254684209824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.060246229171753, "step": 98000}
{"episode_reward": 5.786524176454326, "episode": 99.0, "batch_reward": 0.009239094630349427, "critic_loss": 0.0016505459774925838, "actor_loss": -6.862535001277924, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.0392324924469, "step": 99000}
{"episode_reward": 5.3911195883799845, "episode": 100.0, "batch_reward": 0.009468267503427342, "critic_loss": 0.0015722231082618237, "actor_loss": -5.8750761642456055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.072338104248047, "step": 100000}
{"episode_reward": 6.075852122087262, "episode": 101.0, "batch_reward": 0.00925647243950516, "critic_loss": 0.0013861333042150363, "actor_loss": -5.916522647857666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.47676491737366, "step": 101000}
{"episode_reward": 5.762685786601222, "episode": 102.0, "batch_reward": 0.009182002169778571, "critic_loss": 0.0017127274208760355, "actor_loss": -6.705021734714508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.043251752853394, "step": 102000}
{"episode_reward": 4.872727293889583, "episode": 103.0, "batch_reward": 0.00917902217642404, "critic_loss": 0.0013214865215995814, "actor_loss": -5.553437114477157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.47458004951477, "step": 103000}
{"episode_reward": 5.665353602015863, "episode": 104.0, "batch_reward": 0.00912809275253676, "critic_loss": 0.0013499019355222117, "actor_loss": -6.006668445825577, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.06046485900879, "step": 104000}
{"episode_reward": 5.685608071522833, "episode": 105.0, "batch_reward": 0.009010691831354051, "critic_loss": 0.0013283940549590626, "actor_loss": -5.458068429470062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.054577827453613, "step": 105000}
{"episode_reward": 5.426433447996585, "episode": 106.0, "batch_reward": 0.009163437898736446, "critic_loss": 0.0013974223667464684, "actor_loss": -6.007707896709442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.09008264541626, "step": 106000}
{"episode_reward": 6.535564563772233, "episode": 107.0, "batch_reward": 0.009009983399650081, "critic_loss": 0.0014613289766712114, "actor_loss": -5.957655679225922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.053159952163696, "step": 107000}
{"episode_reward": 5.490978315526959, "episode": 108.0, "batch_reward": 0.009125897946534678, "critic_loss": 0.002186331715085544, "actor_loss": -5.930621698141098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.066760301589966, "step": 108000}
{"episode_reward": 13.137513327909243, "episode": 109.0, "batch_reward": 0.009164832810638473, "critic_loss": 0.0019317405126057566, "actor_loss": -6.637666041135788, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.076831102371216, "step": 109000}
{"episode_reward": 6.026350417933544, "episode": 110.0, "batch_reward": 0.00904008831945248, "critic_loss": 0.001842500840430148, "actor_loss": -6.808485618114472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.045035123825073, "step": 110000}
{"episode_reward": 5.7136840149539445, "episode": 111.0, "batch_reward": 0.009088979857740924, "critic_loss": 0.0013672481843386777, "actor_loss": -5.910329437971115, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.49746608734131, "step": 111000}
{"episode_reward": 5.363464155997378, "episode": 112.0, "batch_reward": 0.009081687904894352, "critic_loss": 0.001397246724111028, "actor_loss": -5.812289120197296, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.073801040649414, "step": 112000}
{"episode_reward": 5.642597131328775, "episode": 113.0, "batch_reward": 0.008973306346684693, "critic_loss": 0.0011923846704594324, "actor_loss": -5.2491952583789825, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.08369255065918, "step": 113000}
{"episode_reward": 6.546194099724926, "episode": 114.0, "batch_reward": 0.008998105313861743, "critic_loss": 0.001104833643999882, "actor_loss": -6.439115649938583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04747247695923, "step": 114000}
{"episode_reward": 6.393986029736794, "episode": 115.0, "batch_reward": 0.008931119271554053, "critic_loss": 0.0010639772946015001, "actor_loss": -5.925989981174469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.079352855682373, "step": 115000}
{"episode_reward": 5.894849892633276, "episode": 116.0, "batch_reward": 0.008826054078061134, "critic_loss": 0.0008259877599193715, "actor_loss": -6.415132079362869, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.089841604232788, "step": 116000}
{"episode_reward": 6.11120401988593, "episode": 117.0, "batch_reward": 0.008894638346275314, "critic_loss": 0.0008481119050848065, "actor_loss": -6.216523179292679, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.075026035308838, "step": 117000}
{"episode_reward": 5.719272911933873, "episode": 118.0, "batch_reward": 0.008920630172360689, "critic_loss": 0.0008229092060500989, "actor_loss": -5.398360966444016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.090309143066406, "step": 118000}
{"episode_reward": 6.20776684867049, "episode": 119.0, "batch_reward": 0.008845494202803821, "critic_loss": 0.0008531300297618146, "actor_loss": -5.663192879915237, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.060898065567017, "step": 119000}
{"episode_reward": 6.903490885881678, "episode": 120.0, "batch_reward": 0.008736233256757259, "critic_loss": 0.0008253092679951806, "actor_loss": -6.112377151012421, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.041177988052368, "step": 120000}
{"episode_reward": 6.423772671411876, "episode": 121.0, "batch_reward": 0.008830226860241965, "critic_loss": 0.000770045521639986, "actor_loss": -4.986152655124664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.48386073112488, "step": 121000}
{"episode_reward": 6.125728356117139, "episode": 122.0, "batch_reward": 0.008814025759696961, "critic_loss": 0.0007825348808837589, "actor_loss": -5.765235738992691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04941177368164, "step": 122000}
{"episode_reward": 5.341072480170093, "episode": 123.0, "batch_reward": 0.008786236506653949, "critic_loss": 0.0009284604660642799, "actor_loss": -6.603759391069413, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.06399130821228, "step": 123000}
{"episode_reward": 6.756386945869917, "episode": 124.0, "batch_reward": 0.008788820418296381, "critic_loss": 0.0009741992671479238, "actor_loss": -6.561899205207824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.056248903274536, "step": 124000}
{"episode_reward": 6.214110826145736, "episode": 125.0, "batch_reward": 0.008505136794177815, "critic_loss": 0.0009574772267369554, "actor_loss": -5.134519986987114, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03747320175171, "step": 125000}
{"episode_reward": 6.872382252237067, "episode": 126.0, "batch_reward": 0.008610416893381625, "critic_loss": 0.000862985233485233, "actor_loss": -6.073022147655487, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.073068618774414, "step": 126000}
{"episode_reward": 6.7674501150768, "episode": 127.0, "batch_reward": 0.0086327922064811, "critic_loss": 0.0009794109123322414, "actor_loss": -6.417437074422836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.417412519454956, "step": 127000}
{"episode_reward": 7.838835563243444, "episode": 128.0, "batch_reward": 0.008631904959212988, "critic_loss": 0.001428484765434405, "actor_loss": -5.269005821108818, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.068130493164062, "step": 128000}
{"episode_reward": 6.958394108671236, "episode": 129.0, "batch_reward": 0.008446444393368438, "critic_loss": 0.007951142780832015, "actor_loss": -5.608723973751068, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.033459424972534, "step": 129000}
{"episode_reward": 8.595288244858537, "episode": 130.0, "batch_reward": 0.008770735977217555, "critic_loss": 0.004392833390505985, "actor_loss": -6.633929219722748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.031961917877197, "step": 130000}
{"episode_reward": 11.415566938025314, "episode": 131.0, "batch_reward": 0.008669544637436048, "critic_loss": 0.00280694199167192, "actor_loss": -5.081427860736847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.40657639503479, "step": 131000}
{"episode_reward": 13.156548831469395, "episode": 132.0, "batch_reward": 0.008888180412352086, "critic_loss": 0.0030508599517634137, "actor_loss": -6.789831335544586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.043822050094604, "step": 132000}
{"episode_reward": 18.019359840639332, "episode": 133.0, "batch_reward": 0.00889867286104709, "critic_loss": 0.004031817140523344, "actor_loss": -5.543779677152633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05937623977661, "step": 133000}
{"episode_reward": 16.7746245593303, "episode": 134.0, "batch_reward": 0.00900241494947113, "critic_loss": 0.004230364796705544, "actor_loss": -6.121963122606277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.057787656784058, "step": 134000}
{"episode_reward": 16.114006840270324, "episode": 135.0, "batch_reward": 0.00908636829489842, "critic_loss": 0.0025826995203387924, "actor_loss": -6.594495887517929, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.056095361709595, "step": 135000}
{"episode_reward": 19.704211794232787, "episode": 136.0, "batch_reward": 0.009058259789366275, "critic_loss": 0.002487912308773957, "actor_loss": -6.5323328258991245, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04796314239502, "step": 136000}
{"episode_reward": 23.829608169140602, "episode": 137.0, "batch_reward": 0.009231613093754277, "critic_loss": 0.002177811440778896, "actor_loss": -7.128799739599228, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.075939893722534, "step": 137000}
{"episode_reward": 21.37981284010694, "episode": 138.0, "batch_reward": 0.009443856053985655, "critic_loss": 0.0021618274435168134, "actor_loss": -6.08534787774086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.06621479988098, "step": 138000}
{"episode_reward": 20.09098072944389, "episode": 139.0, "batch_reward": 0.009246715360321105, "critic_loss": 0.0023581396473164205, "actor_loss": -5.940747402667999, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.046692371368408, "step": 139000}
{"episode_reward": 13.550605713616097, "episode": 140.0, "batch_reward": 0.009437390578445047, "critic_loss": 0.0019133318645181134, "actor_loss": -6.1678826425075535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.042540550231934, "step": 140000}
{"episode_reward": 16.722344257010157, "episode": 141.0, "batch_reward": 0.009268268850864842, "critic_loss": 0.0019279936961829663, "actor_loss": -6.152941386938095, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 36.48168611526489, "step": 141000}
{"episode_reward": 14.256336136602288, "episode": 142.0, "batch_reward": 0.00939492671797052, "critic_loss": 0.0018552707985509188, "actor_loss": -6.032530458211899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.058680772781372, "step": 142000}
{"episode_reward": 12.22170026093498, "episode": 143.0, "batch_reward": 0.009559855938423425, "critic_loss": 0.0017454108810052275, "actor_loss": -6.0624208726882935, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03277564048767, "step": 143000}
{"episode_reward": 11.180426500618182, "episode": 144.0, "batch_reward": 0.009519320892170072, "critic_loss": 0.0014559573497390376, "actor_loss": -5.588215667963028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.07083821296692, "step": 144000}
{"episode_reward": 12.514974857587607, "episode": 145.0, "batch_reward": 0.009456314162816852, "critic_loss": 0.0014784853882156312, "actor_loss": -6.035047457695008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.049425840377808, "step": 145000}
{"episode_reward": 9.567417009168363, "episode": 146.0, "batch_reward": 0.009331685147481039, "critic_loss": 0.0014957958771847188, "actor_loss": -5.795617191314697, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.033151388168335, "step": 146000}
{"episode_reward": 6.4366284527284, "episode": 147.0, "batch_reward": 0.009400166374165565, "critic_loss": 0.0015972287509939634, "actor_loss": -5.633513658285141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.070813417434692, "step": 147000}
{"episode_reward": 9.985322465528574, "episode": 148.0, "batch_reward": 0.009351774421287701, "critic_loss": 0.004194291758642066, "actor_loss": -5.670042849779129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.062018394470215, "step": 148000}
{"episode_reward": 8.712433891756543, "episode": 149.0, "batch_reward": 0.009515489032957703, "critic_loss": 0.00486897330544889, "actor_loss": -5.831665734052658, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.02832269668579, "step": 149000}
{"episode_reward": 14.977022022102409, "episode": 150.0, "batch_reward": 0.009528149529825896, "critic_loss": 0.0027390091482084244, "actor_loss": -5.335974836349488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
