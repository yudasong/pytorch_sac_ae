{"episode_reward": 0.0, "episode": 1.0, "duration": 13.915984630584717, "step": 1000}
{"episode_reward": 4.20996189079657, "episode": 2.0, "duration": 1.2373700141906738, "step": 2000}
{"episode_reward": 252.2457487418515, "episode": 3.0, "batch_reward": 0.12310112611194697, "critic_loss": 0.0737193260092205, "actor_loss": -20.825613915389564, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 72.68740010261536, "step": 3000}
{"episode_reward": 30.635115288001757, "episode": 4.0, "batch_reward": 0.08459844963252544, "critic_loss": 0.037172519316896795, "actor_loss": -18.262200295448302, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.294695615768433, "step": 4000}
{"episode_reward": 19.977835818995594, "episode": 5.0, "batch_reward": 0.07242501890659332, "critic_loss": 0.04778735675290227, "actor_loss": -18.431621271133423, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.718693733215332, "step": 5000}
{"episode_reward": 34.1975458673254, "episode": 6.0, "batch_reward": 0.06630381996929645, "critic_loss": 0.048746601428836585, "actor_loss": -17.275013374328612, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.11841106414795, "step": 6000}
{"episode_reward": 41.84155629023454, "episode": 7.0, "batch_reward": 0.06416327319666744, "critic_loss": 0.05529018449224531, "actor_loss": -16.49702137184143, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.764246463775635, "step": 7000}
{"episode_reward": 76.25703641750135, "episode": 8.0, "batch_reward": 0.06424586355313659, "critic_loss": 0.07984023609012365, "actor_loss": -14.65080617237091, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.284684419631958, "step": 8000}
{"episode_reward": 24.679210368904272, "episode": 9.0, "batch_reward": 0.06254734677448869, "critic_loss": 0.08496073987334966, "actor_loss": -15.008692405223847, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.355045080184937, "step": 9000}
{"episode_reward": 91.79774888469397, "episode": 10.0, "batch_reward": 0.06759507479146123, "critic_loss": 0.14299690514802932, "actor_loss": -14.937567814826965, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.627235889434814, "step": 10000}
{"episode_reward": 144.52011492119988, "episode": 11.0, "batch_reward": 0.06976642073318362, "critic_loss": 0.1850139457806945, "actor_loss": -15.218754704475403, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.41499423980713, "step": 11000}
{"episode_reward": 31.991335405686414, "episode": 12.0, "batch_reward": 0.0687201933003962, "critic_loss": 0.19867943669855595, "actor_loss": -13.091938486099243, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.710907459259033, "step": 12000}
{"episode_reward": 58.05497794359434, "episode": 13.0, "batch_reward": 0.06707064416259527, "critic_loss": 0.18411184009164572, "actor_loss": -13.522452033996583, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.14554500579834, "step": 13000}
{"episode_reward": 36.63781239921057, "episode": 14.0, "batch_reward": 0.06480290530994534, "critic_loss": 0.1735936869084835, "actor_loss": -12.46275827114284, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.75610589981079, "step": 14000}
{"episode_reward": 41.058487504911234, "episode": 15.0, "batch_reward": 0.06360767012089491, "critic_loss": 0.1604612894207239, "actor_loss": -12.624403748840093, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.230546236038208, "step": 15000}
{"episode_reward": 33.762093095472196, "episode": 16.0, "batch_reward": 0.06123844200372696, "critic_loss": 0.16870007587969302, "actor_loss": -11.50003797289729, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.986377716064453, "step": 16000}
{"episode_reward": 29.915237410375354, "episode": 17.0, "batch_reward": 0.06174049768969417, "critic_loss": 0.1594716975912452, "actor_loss": -11.628278809264302, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.415184259414673, "step": 17000}
{"episode_reward": 90.86806379275072, "episode": 18.0, "batch_reward": 0.06440463545173407, "critic_loss": 0.2005144958794117, "actor_loss": -11.073020745389163, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.697426319122314, "step": 18000}
{"episode_reward": 113.6976457180284, "episode": 19.0, "batch_reward": 0.0667405584231019, "critic_loss": 0.2213197973370552, "actor_loss": -12.1188458391577, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.652411460876465, "step": 19000}
{"episode_reward": 117.0084024710068, "episode": 20.0, "batch_reward": 0.06753365081548691, "critic_loss": 0.18475971689075232, "actor_loss": -11.343239429488778, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.43295979499817, "step": 20000}
{"episode_reward": 58.20458543991636, "episode": 21.0, "batch_reward": 0.0677847374342382, "critic_loss": 0.21253883721679448, "actor_loss": -11.73478563478589, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.6029098033905, "step": 21000}
{"episode_reward": 141.92742371137402, "episode": 22.0, "batch_reward": 0.07137219624221325, "critic_loss": 0.24631551021337508, "actor_loss": -11.418518896907567, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.826658725738525, "step": 22000}
{"episode_reward": 140.51036674355572, "episode": 23.0, "batch_reward": 0.07367427967861295, "critic_loss": 0.23760418558865787, "actor_loss": -12.637253756046295, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.98667001724243, "step": 23000}
{"episode_reward": 51.77801236402294, "episode": 24.0, "batch_reward": 0.07451302846893668, "critic_loss": 0.3023637393862009, "actor_loss": -13.028259678602218, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.406697273254395, "step": 24000}
{"episode_reward": 133.5909235196455, "episode": 25.0, "batch_reward": 0.07704864784702659, "critic_loss": 0.27786001735180615, "actor_loss": -12.093105407238006, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.53349208831787, "step": 25000}
{"episode_reward": 128.414474744763, "episode": 26.0, "batch_reward": 0.07757886884734035, "critic_loss": 0.34617894601076843, "actor_loss": -12.88891158413887, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.038878202438354, "step": 26000}
{"episode_reward": 63.383137855093125, "episode": 27.0, "batch_reward": 0.07823952067643404, "critic_loss": 0.31184880059957504, "actor_loss": -12.733732887744903, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.895753383636475, "step": 27000}
{"episode_reward": 117.20798631615132, "episode": 28.0, "batch_reward": 0.07975938670709729, "critic_loss": 0.33211042331159113, "actor_loss": -12.600937779426575, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.997315168380737, "step": 28000}
{"episode_reward": 107.31430825986695, "episode": 29.0, "batch_reward": 0.08263806587457657, "critic_loss": 0.36323261791467665, "actor_loss": -13.016516541004181, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.40685510635376, "step": 29000}
{"episode_reward": 289.23242759249314, "episode": 30.0, "batch_reward": 0.08730772626027465, "critic_loss": 0.3668666064888239, "actor_loss": -14.166418260097503, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.66354990005493, "step": 30000}
{"episode_reward": 91.50195175571295, "episode": 31.0, "batch_reward": 0.08730932444706559, "critic_loss": 0.3433551171049476, "actor_loss": -13.319210097312927, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.203919410705566, "step": 31000}
{"episode_reward": 95.12772375413373, "episode": 32.0, "batch_reward": 0.08698827549442649, "critic_loss": 0.4143979130089283, "actor_loss": -13.6200120677948, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.318634510040283, "step": 32000}
{"episode_reward": 54.00230696231423, "episode": 33.0, "batch_reward": 0.08599851867556572, "critic_loss": 0.3622378159463406, "actor_loss": -13.215166310310364, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.041985034942627, "step": 33000}
{"episode_reward": 110.72632233207338, "episode": 34.0, "batch_reward": 0.08626620784029365, "critic_loss": 0.3711051390916109, "actor_loss": -13.162578996658326, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.30355477333069, "step": 34000}
{"episode_reward": 54.02026269879455, "episode": 35.0, "batch_reward": 0.08612359392642975, "critic_loss": 0.391483509927988, "actor_loss": -13.885550533294678, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.514191150665283, "step": 35000}
{"episode_reward": 66.17711253636016, "episode": 36.0, "batch_reward": 0.08775157234445215, "critic_loss": 0.3442355080395937, "actor_loss": -13.41606626701355, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.2955265045166, "step": 36000}
{"episode_reward": 229.97167689981652, "episode": 37.0, "batch_reward": 0.09128816604614258, "critic_loss": 0.36003475418686864, "actor_loss": -14.035291040420532, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.658335208892822, "step": 37000}
{"episode_reward": 195.51357451611457, "episode": 38.0, "batch_reward": 0.09335320821776986, "critic_loss": 0.35000205704569815, "actor_loss": -14.919280707359315, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.404260396957397, "step": 38000}
{"episode_reward": 115.2920870603821, "episode": 39.0, "batch_reward": 0.0951546272188425, "critic_loss": 0.31360549457371234, "actor_loss": -14.409437016487121, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.53774356842041, "step": 39000}
{"episode_reward": 264.5771505858525, "episode": 40.0, "batch_reward": 0.09850534880906343, "critic_loss": 0.32920544120669365, "actor_loss": -14.441257057189942, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.620142698287964, "step": 40000}
{"episode_reward": 145.33411438490347, "episode": 41.0, "batch_reward": 0.10037197175621987, "critic_loss": 0.3167738435789943, "actor_loss": -15.163758253097534, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.25234127044678, "step": 41000}
{"episode_reward": 251.88657931950826, "episode": 42.0, "batch_reward": 0.10512132481485605, "critic_loss": 0.3556501204371452, "actor_loss": -15.526323450088501, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.493014812469482, "step": 42000}
{"episode_reward": 334.21660393499815, "episode": 43.0, "batch_reward": 0.10959929499775171, "critic_loss": 0.3176283839419484, "actor_loss": -15.7567868642807, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.71463966369629, "step": 43000}
{"episode_reward": 312.40260182389005, "episode": 44.0, "batch_reward": 0.11297279094904661, "critic_loss": 0.331915579944849, "actor_loss": -16.635977252960206, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.417010068893433, "step": 44000}
{"episode_reward": 63.951361107929756, "episode": 45.0, "batch_reward": 0.1142637581154704, "critic_loss": 0.3632785958945751, "actor_loss": -16.7398589553833, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.11747407913208, "step": 45000}
{"episode_reward": 345.9644482842752, "episode": 46.0, "batch_reward": 0.11770585334300995, "critic_loss": 0.3660944082811475, "actor_loss": -16.887972087860106, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.591116905212402, "step": 46000}
{"episode_reward": 147.04512019169385, "episode": 47.0, "batch_reward": 0.11839385140687227, "critic_loss": 0.3601694718599319, "actor_loss": -16.846922019958495, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.687219381332397, "step": 47000}
{"episode_reward": 210.46116690227905, "episode": 48.0, "batch_reward": 0.12167296143621206, "critic_loss": 0.3435258554518223, "actor_loss": -17.11968351364136, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.473121881484985, "step": 48000}
{"episode_reward": 402.0977330549211, "episode": 49.0, "batch_reward": 0.12768932985514403, "critic_loss": 0.3237891932427883, "actor_loss": -17.475132284164427, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.135297775268555, "step": 49000}
{"episode_reward": 394.1206518945362, "episode": 50.0, "batch_reward": 0.13218221938610078, "critic_loss": 0.3145714780017734, "actor_loss": -17.949343994140627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.42438554763794, "step": 50000}
{"episode_reward": 408.95028540165305, "episode": 51.0, "batch_reward": 0.1380190473049879, "critic_loss": 0.34715088176727293, "actor_loss": -18.394636184692384, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.417288064956665, "step": 51000}
{"episode_reward": 318.5125870895525, "episode": 52.0, "batch_reward": 0.14235840561985968, "critic_loss": 0.335279505237937, "actor_loss": -18.959420360565186, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.96991991996765, "step": 52000}
{"episode_reward": 398.77030662448317, "episode": 53.0, "batch_reward": 0.14682474574446677, "critic_loss": 0.32227940298616886, "actor_loss": -19.29713148498535, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.828340530395508, "step": 53000}
{"episode_reward": 389.5072624354649, "episode": 54.0, "batch_reward": 0.149286288253963, "critic_loss": 0.3238511683046818, "actor_loss": -19.41782619857788, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.541041135787964, "step": 54000}
{"episode_reward": 102.08776197253599, "episode": 55.0, "batch_reward": 0.14897803742438553, "critic_loss": 0.3042011064738035, "actor_loss": -19.359225074768066, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.43408703804016, "step": 55000}
{"episode_reward": 206.3902846574606, "episode": 56.0, "batch_reward": 0.1516972080245614, "critic_loss": 0.2930924152508378, "actor_loss": -19.371977544784546, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.56916904449463, "step": 56000}
{"episode_reward": 434.0638658466195, "episode": 57.0, "batch_reward": 0.15685496933758258, "critic_loss": 0.28183458872139455, "actor_loss": -20.081726039886476, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.823893547058105, "step": 57000}
{"episode_reward": 452.14470101478594, "episode": 58.0, "batch_reward": 0.1615248640626669, "critic_loss": 0.29317623780667784, "actor_loss": -20.42148819732666, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.378294944763184, "step": 58000}
{"episode_reward": 414.56395077104474, "episode": 59.0, "batch_reward": 0.16609457432478666, "critic_loss": 0.30075468296557667, "actor_loss": -20.868761316299437, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.497000694274902, "step": 59000}
{"episode_reward": 389.94302284131254, "episode": 60.0, "batch_reward": 0.16998362213373183, "critic_loss": 0.28616490991413596, "actor_loss": -21.448452964782714, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.54861330986023, "step": 60000}
{"episode_reward": 452.4065376247522, "episode": 61.0, "batch_reward": 0.17338913048803806, "critic_loss": 0.28639196548610923, "actor_loss": -22.235235029220583, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.58371448516846, "step": 61000}
{"episode_reward": 389.4333744844998, "episode": 62.0, "batch_reward": 0.17764165146648883, "critic_loss": 0.28967339608818293, "actor_loss": -22.62909568977356, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.111391067504883, "step": 62000}
{"episode_reward": 222.8367301556765, "episode": 63.0, "batch_reward": 0.17902758204191924, "critic_loss": 0.2877835905700922, "actor_loss": -22.594204280853273, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.993392944335938, "step": 63000}
{"episode_reward": 365.16441036484076, "episode": 64.0, "batch_reward": 0.18187606289982797, "critic_loss": 0.29010471403598787, "actor_loss": -22.432301864624023, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.595175743103027, "step": 64000}
{"episode_reward": 425.18387536000137, "episode": 65.0, "batch_reward": 0.1856479892283678, "critic_loss": 0.30330390778928995, "actor_loss": -22.84842360305786, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.224724531173706, "step": 65000}
{"episode_reward": 480.3974895330409, "episode": 66.0, "batch_reward": 0.1911731142550707, "critic_loss": 0.3119881132468581, "actor_loss": -23.433395198822023, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.695554971694946, "step": 66000}
{"episode_reward": 496.89856131310523, "episode": 67.0, "batch_reward": 0.19459849962592124, "critic_loss": 0.3172073828279972, "actor_loss": -24.357810302734375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.3924343585968, "step": 67000}
{"episode_reward": 473.4636422785211, "episode": 68.0, "batch_reward": 0.2002095158547163, "critic_loss": 0.2991886790841818, "actor_loss": -24.485004249572754, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.287343978881836, "step": 68000}
{"episode_reward": 503.7381105083093, "episode": 69.0, "batch_reward": 0.20410980753600597, "critic_loss": 0.2791938717365265, "actor_loss": -24.973174579620363, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.39721441268921, "step": 69000}
{"episode_reward": 465.4550183479112, "episode": 70.0, "batch_reward": 0.20777123445272447, "critic_loss": 0.25049952141195536, "actor_loss": -25.5548451461792, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.056293725967407, "step": 70000}
{"episode_reward": 501.95574688218016, "episode": 71.0, "batch_reward": 0.2125603779256344, "critic_loss": 0.2831319501847029, "actor_loss": -25.87138798904419, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.25073027610779, "step": 71000}
{"episode_reward": 481.0588660772007, "episode": 72.0, "batch_reward": 0.21478032326698304, "critic_loss": 0.3052516690045595, "actor_loss": -25.901974395751953, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.351512670516968, "step": 72000}
{"episode_reward": 498.82878029562687, "episode": 73.0, "batch_reward": 0.2195464056879282, "critic_loss": 0.2985312484130263, "actor_loss": -26.41393850326538, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.8798348903656, "step": 73000}
{"episode_reward": 484.440049829758, "episode": 74.0, "batch_reward": 0.22170287714898587, "critic_loss": 0.3034895777106285, "actor_loss": -26.659098117828368, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.508535385131836, "step": 74000}
{"episode_reward": 303.85678014530043, "episode": 75.0, "batch_reward": 0.22442651203274727, "critic_loss": 0.2641212254911661, "actor_loss": -26.503236175537108, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.687580823898315, "step": 75000}
{"episode_reward": 485.04279267484134, "episode": 76.0, "batch_reward": 0.2280826498568058, "critic_loss": 0.2786998850107193, "actor_loss": -27.284739532470702, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.71906566619873, "step": 76000}
{"episode_reward": 514.3243339086536, "episode": 77.0, "batch_reward": 0.23107282646000385, "critic_loss": 0.29233090512454507, "actor_loss": -27.55369723892212, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.391804218292236, "step": 77000}
{"episode_reward": 248.68814696904394, "episode": 78.0, "batch_reward": 0.23186115758121015, "critic_loss": 0.3051727568283677, "actor_loss": -27.832126758575438, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.09210205078125, "step": 78000}
{"episode_reward": 509.76053714870653, "episode": 79.0, "batch_reward": 0.23529393310844898, "critic_loss": 0.2935390298888087, "actor_loss": -27.712572616577148, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.732243299484253, "step": 79000}
{"episode_reward": 534.8109557092491, "episode": 80.0, "batch_reward": 0.23851276470720767, "critic_loss": 0.31066756519675254, "actor_loss": -28.258024688720702, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.22022557258606, "step": 80000}
{"episode_reward": 494.9556672434165, "episode": 81.0, "batch_reward": 0.24197785867750646, "critic_loss": 0.2913833835199475, "actor_loss": -28.772716716766357, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.67578482627869, "step": 81000}
{"episode_reward": 499.5819636573643, "episode": 82.0, "batch_reward": 0.2450013816356659, "critic_loss": 0.29150332107394933, "actor_loss": -28.915346279144288, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.206785440444946, "step": 82000}
{"episode_reward": 515.7495758824798, "episode": 83.0, "batch_reward": 0.24860994985699653, "critic_loss": 0.30974736968427896, "actor_loss": -29.40196153640747, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.763174533843994, "step": 83000}
{"episode_reward": 491.13698190968034, "episode": 84.0, "batch_reward": 0.25033904777467253, "critic_loss": 0.33905396473407745, "actor_loss": -29.571257164001466, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.602338552474976, "step": 84000}
{"episode_reward": 492.99564361811326, "episode": 85.0, "batch_reward": 0.2545392022579908, "critic_loss": 0.3004579184949398, "actor_loss": -29.842879055023193, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.3012216091156, "step": 85000}
{"episode_reward": 528.9596551618179, "episode": 86.0, "batch_reward": 0.25562370839715004, "critic_loss": 0.2937977404668927, "actor_loss": -30.060463787078856, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.571716785430908, "step": 86000}
{"episode_reward": 291.99665213341325, "episode": 87.0, "batch_reward": 0.25723857718706133, "critic_loss": 0.31555155108869076, "actor_loss": -30.449941082000734, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.714393615722656, "step": 87000}
{"episode_reward": 523.5246297158825, "episode": 88.0, "batch_reward": 0.2596908221244812, "critic_loss": 0.308233259730041, "actor_loss": -30.649863262176513, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.477741718292236, "step": 88000}
{"episode_reward": 151.55817000943466, "episode": 89.0, "batch_reward": 0.2601930513381958, "critic_loss": 0.30180148128420115, "actor_loss": -30.497412326812743, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.701914310455322, "step": 89000}
{"episode_reward": 472.5441551815932, "episode": 90.0, "batch_reward": 0.2625789589583874, "critic_loss": 0.30939996874332426, "actor_loss": -30.8870329246521, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.19944930076599, "step": 90000}
{"episode_reward": 545.160647992564, "episode": 91.0, "batch_reward": 0.26449661517143247, "critic_loss": 0.30303040650486945, "actor_loss": -30.77572476577759, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.44404149055481, "step": 91000}
{"episode_reward": 547.6175153892843, "episode": 92.0, "batch_reward": 0.2671288986057043, "critic_loss": 0.28756705552339556, "actor_loss": -31.562465576171874, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.19561529159546, "step": 92000}
{"episode_reward": 534.6123723250729, "episode": 93.0, "batch_reward": 0.2710884798318148, "critic_loss": 0.2779207063540816, "actor_loss": -31.61591288757324, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.912882804870605, "step": 93000}
{"episode_reward": 537.2701344864, "episode": 94.0, "batch_reward": 0.27399181652069093, "critic_loss": 0.3021238425448537, "actor_loss": -32.08273043060303, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.685241222381592, "step": 94000}
{"episode_reward": 270.7234869521381, "episode": 95.0, "batch_reward": 0.27338478088378904, "critic_loss": 0.30361901595443486, "actor_loss": -31.766678466796876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.46564793586731, "step": 95000}
{"episode_reward": 534.762734757899, "episode": 96.0, "batch_reward": 0.27727644707262517, "critic_loss": 0.32799356369674204, "actor_loss": -32.1797831954956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.613422870635986, "step": 96000}
{"episode_reward": 541.5855114327353, "episode": 97.0, "batch_reward": 0.28004402174055576, "critic_loss": 0.35009024778008463, "actor_loss": -32.32914225769043, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.208433389663696, "step": 97000}
{"episode_reward": 528.999900172022, "episode": 98.0, "batch_reward": 0.2827930855304003, "critic_loss": 0.3217039055377245, "actor_loss": -32.39804650115967, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.63824701309204, "step": 98000}
{"episode_reward": 505.2048391050994, "episode": 99.0, "batch_reward": 0.28313258869946, "critic_loss": 0.3272010300979018, "actor_loss": -32.642262451171874, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.545871257781982, "step": 99000}
{"episode_reward": 534.451111017581, "episode": 100.0, "batch_reward": 0.2874001252651215, "critic_loss": 0.349681018024683, "actor_loss": -32.96434461593628, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.29830527305603, "step": 100000}
{"episode_reward": 565.6098299137369, "episode": 101.0, "batch_reward": 0.28929090206325053, "critic_loss": 0.34440836384892465, "actor_loss": -33.52410489273071, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.598872423172, "step": 101000}
{"episode_reward": 393.03130838600345, "episode": 102.0, "batch_reward": 0.29147624000906946, "critic_loss": 0.3237725014835596, "actor_loss": -33.29919313812256, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.388446807861328, "step": 102000}
{"episode_reward": 558.0072739469673, "episode": 103.0, "batch_reward": 0.2927658725231886, "critic_loss": 0.3242366150170565, "actor_loss": -33.76376706314087, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.903939247131348, "step": 103000}
{"episode_reward": 414.1037015095978, "episode": 104.0, "batch_reward": 0.2942656815201044, "critic_loss": 0.31365887221693994, "actor_loss": -33.33165016174316, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.692153930664062, "step": 104000}
{"episode_reward": 518.8316327624824, "episode": 105.0, "batch_reward": 0.2958893524557352, "critic_loss": 0.3455482857823372, "actor_loss": -34.040779022216796, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.32745599746704, "step": 105000}
{"episode_reward": 439.46123179941384, "episode": 106.0, "batch_reward": 0.2964737561941147, "critic_loss": 0.3793442663252354, "actor_loss": -33.945385913848874, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.56963038444519, "step": 106000}
{"episode_reward": 146.08866901421263, "episode": 107.0, "batch_reward": 0.2958298187404871, "critic_loss": 0.38064835938811303, "actor_loss": -33.78082832717895, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.325685739517212, "step": 107000}
{"episode_reward": 542.5896448556795, "episode": 108.0, "batch_reward": 0.29798508892953396, "critic_loss": 0.36219932751357553, "actor_loss": -33.921854377746584, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.703309059143066, "step": 108000}
{"episode_reward": 296.2536772848802, "episode": 109.0, "batch_reward": 0.3000069627463818, "critic_loss": 0.3785236101597548, "actor_loss": -34.16045867538452, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.69083023071289, "step": 109000}
{"episode_reward": 403.6538606589724, "episode": 110.0, "batch_reward": 0.29915782864391804, "critic_loss": 0.3810761378109455, "actor_loss": -33.963447109222415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.48733115196228, "step": 110000}
{"episode_reward": 276.47875999288283, "episode": 111.0, "batch_reward": 0.2993257371634245, "critic_loss": 0.3995408126562834, "actor_loss": -34.24173704910278, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.627721309661865, "step": 111000}
{"episode_reward": 524.1149559030359, "episode": 112.0, "batch_reward": 0.301094975695014, "critic_loss": 0.4363350520730019, "actor_loss": -34.361709838867185, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.663769960403442, "step": 112000}
{"episode_reward": 518.5299418614395, "episode": 113.0, "batch_reward": 0.30299983893334864, "critic_loss": 0.4254650404304266, "actor_loss": -34.63696782302856, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.673514366149902, "step": 113000}
{"episode_reward": 141.8283825211431, "episode": 114.0, "batch_reward": 0.30345923227071764, "critic_loss": 0.41596623477339745, "actor_loss": -34.54045262908936, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.633777856826782, "step": 114000}
{"episode_reward": 545.447156850116, "episode": 115.0, "batch_reward": 0.3038069545030594, "critic_loss": 0.4246012373566628, "actor_loss": -34.20668607711792, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.587207555770874, "step": 115000}
{"episode_reward": 519.6484305765468, "episode": 116.0, "batch_reward": 0.30592183688282965, "critic_loss": 0.4195708197504282, "actor_loss": -34.73808190917969, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.78543210029602, "step": 116000}
{"episode_reward": 532.4414468664223, "episode": 117.0, "batch_reward": 0.3090642737001181, "critic_loss": 0.41899114310741425, "actor_loss": -35.012773612976076, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.512152910232544, "step": 117000}
{"episode_reward": 565.6627636027614, "episode": 118.0, "batch_reward": 0.311041359603405, "critic_loss": 0.4434463057219982, "actor_loss": -35.112116619110104, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.822096347808838, "step": 118000}
{"episode_reward": 536.4254684691218, "episode": 119.0, "batch_reward": 0.3116371659934521, "critic_loss": 0.4027754758745432, "actor_loss": -35.01294723510742, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.61356210708618, "step": 119000}
{"episode_reward": 516.2636068901719, "episode": 120.0, "batch_reward": 0.3142987319231033, "critic_loss": 0.40151409614086153, "actor_loss": -35.32131962585449, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.684083700180054, "step": 120000}
{"episode_reward": 561.0672933279169, "episode": 121.0, "batch_reward": 0.31694371162354945, "critic_loss": 0.39668212467432024, "actor_loss": -35.5270484085083, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.51689028739929, "step": 121000}
{"episode_reward": 561.3750320307989, "episode": 122.0, "batch_reward": 0.31888860087096693, "critic_loss": 0.3758702328056097, "actor_loss": -35.345931911468504, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.419774532318115, "step": 122000}
{"episode_reward": 299.63753351815154, "episode": 123.0, "batch_reward": 0.3177666233778, "critic_loss": 0.37832633951306344, "actor_loss": -35.43438159561157, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.122135877609253, "step": 123000}
{"episode_reward": 561.6602698142905, "episode": 124.0, "batch_reward": 0.31987208127975464, "critic_loss": 0.3948844464123249, "actor_loss": -35.76544757461548, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.798305988311768, "step": 124000}
{"episode_reward": 556.1315723914555, "episode": 125.0, "batch_reward": 0.3222993858754635, "critic_loss": 0.381936083547771, "actor_loss": -36.00521559143066, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.59974956512451, "step": 125000}
{"episode_reward": 557.5872762535236, "episode": 126.0, "batch_reward": 0.32325919821858407, "critic_loss": 0.39033531095087526, "actor_loss": -35.95335040664673, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.587244033813477, "step": 126000}
{"episode_reward": 566.0461523161473, "episode": 127.0, "batch_reward": 0.3254971561729908, "critic_loss": 0.35564785611629485, "actor_loss": -36.41441885757446, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.13942003250122, "step": 127000}
{"episode_reward": 550.5756696216863, "episode": 128.0, "batch_reward": 0.3275075045228004, "critic_loss": 0.34540199471265076, "actor_loss": -36.7195746459961, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.824558973312378, "step": 128000}
{"episode_reward": 546.2862952766252, "episode": 129.0, "batch_reward": 0.32810565450787543, "critic_loss": 0.38047279572486875, "actor_loss": -36.64364142227173, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.493775606155396, "step": 129000}
{"episode_reward": 539.3582980102796, "episode": 130.0, "batch_reward": 0.3307498824894428, "critic_loss": 0.37301180383563043, "actor_loss": -36.8473245010376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.395129203796387, "step": 130000}
{"episode_reward": 532.7949383541122, "episode": 131.0, "batch_reward": 0.33223730298876764, "critic_loss": 0.34064726991951466, "actor_loss": -37.290295680999755, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.47162485122681, "step": 131000}
{"episode_reward": 527.8387833091025, "episode": 132.0, "batch_reward": 0.3323566453754902, "critic_loss": 0.37428541188687087, "actor_loss": -37.05927388381958, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.31883454322815, "step": 132000}
{"episode_reward": 561.1283359214195, "episode": 133.0, "batch_reward": 0.3341906936764717, "critic_loss": 0.34138098810613154, "actor_loss": -37.1753811416626, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.04044246673584, "step": 133000}
{"episode_reward": 539.5680336073326, "episode": 134.0, "batch_reward": 0.3362609090805054, "critic_loss": 0.33613741136342284, "actor_loss": -37.31261917495728, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.503915071487427, "step": 134000}
{"episode_reward": 547.6598375876677, "episode": 135.0, "batch_reward": 0.33780403271317483, "critic_loss": 0.3556988269761205, "actor_loss": -37.44327178192139, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.3036105632782, "step": 135000}
{"episode_reward": 534.672492137636, "episode": 136.0, "batch_reward": 0.3388943679332733, "critic_loss": 0.33100067883729933, "actor_loss": -37.475009128570555, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.851598501205444, "step": 136000}
{"episode_reward": 571.8533424660787, "episode": 137.0, "batch_reward": 0.3418024801313877, "critic_loss": 0.36469293691217897, "actor_loss": -37.90142709350586, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.032188892364502, "step": 137000}
{"episode_reward": 562.5667001031172, "episode": 138.0, "batch_reward": 0.3438954094052315, "critic_loss": 0.3467605949640274, "actor_loss": -38.45959094619751, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.6095187664032, "step": 138000}
{"episode_reward": 583.3573618193233, "episode": 139.0, "batch_reward": 0.34474929881095884, "critic_loss": 0.33436127819120887, "actor_loss": -38.66402802276611, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.30512309074402, "step": 139000}
{"episode_reward": 525.1327112669061, "episode": 140.0, "batch_reward": 0.3452743717432022, "critic_loss": 0.3511355544477701, "actor_loss": -38.466519870758056, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.559000253677368, "step": 140000}
{"episode_reward": 541.2019010916653, "episode": 141.0, "batch_reward": 0.34646468377113343, "critic_loss": 0.3371273351386189, "actor_loss": -38.1597765083313, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.535542488098145, "step": 141000}
{"episode_reward": 412.0025858403883, "episode": 142.0, "batch_reward": 0.3478077704310417, "critic_loss": 0.32389547654986384, "actor_loss": -38.6277745513916, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.46601152420044, "step": 142000}
{"episode_reward": 529.6263364792569, "episode": 143.0, "batch_reward": 0.34920628359913825, "critic_loss": 0.3037588821873069, "actor_loss": -38.365738319396975, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.943517208099365, "step": 143000}
{"episode_reward": 570.2629903636124, "episode": 144.0, "batch_reward": 0.3516640713214874, "critic_loss": 0.32347137039899826, "actor_loss": -38.93780612182617, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.584030151367188, "step": 144000}
{"episode_reward": 545.173167083359, "episode": 145.0, "batch_reward": 0.3520617665946484, "critic_loss": 0.3531877642571926, "actor_loss": -38.508112113952635, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.559155464172363, "step": 145000}
{"episode_reward": 554.4365658589163, "episode": 146.0, "batch_reward": 0.35283108812570574, "critic_loss": 0.34616989689320327, "actor_loss": -39.11801280212402, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.32417345046997, "step": 146000}
{"episode_reward": 259.65977687807776, "episode": 147.0, "batch_reward": 0.3529907283782959, "critic_loss": 0.34262258623540404, "actor_loss": -38.883965782165525, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.050246000289917, "step": 147000}
{"episode_reward": 527.8912678092737, "episode": 148.0, "batch_reward": 0.353869888484478, "critic_loss": 0.3422225268036127, "actor_loss": -38.84392549514771, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.580599784851074, "step": 148000}
{"episode_reward": 565.3291086285972, "episode": 149.0, "batch_reward": 0.35579595997929575, "critic_loss": 0.32619658412784336, "actor_loss": -39.30542630004883, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.314488410949707, "step": 149000}
{"episode_reward": 535.4384641107324, "episode": 150.0, "batch_reward": 0.35751055473089216, "critic_loss": 0.35565974313765764, "actor_loss": -39.42798596572876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
