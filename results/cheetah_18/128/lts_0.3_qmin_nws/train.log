{"episode_reward": 0.0, "episode": 1.0, "duration": 17.34853506088257, "step": 1000}
{"episode_reward": 4.20996189079657, "episode": 2.0, "duration": 1.4939525127410889, "step": 2000}
{"episode_reward": 252.2457487418515, "episode": 3.0, "batch_reward": 0.12239933408680023, "critic_loss": 0.026293156586870644, "actor_loss": -10.773111058067398, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 60.805673122406006, "step": 3000}
{"episode_reward": 39.555300551222466, "episode": 4.0, "batch_reward": 0.09489497013762593, "critic_loss": 0.045285203508101404, "actor_loss": -10.901189158756285, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.030902862548828, "step": 4000}
{"episode_reward": 86.48352215455577, "episode": 5.0, "batch_reward": 0.09731040770933032, "critic_loss": 0.0545516535975039, "actor_loss": -10.527619801789522, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.032256603240967, "step": 5000}
{"episode_reward": 100.66907193733795, "episode": 6.0, "batch_reward": 0.09381271715834737, "critic_loss": 0.06483388089388609, "actor_loss": -10.065927448570728, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.016092538833618, "step": 6000}
{"episode_reward": 43.40638998237786, "episode": 7.0, "batch_reward": 0.08482304099574685, "critic_loss": 0.06344789158925414, "actor_loss": -8.272896901965142, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.022175312042236, "step": 7000}
{"episode_reward": 26.972521656437863, "episode": 8.0, "batch_reward": 0.07682336873933673, "critic_loss": 0.06610106423869729, "actor_loss": -9.22679898238182, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.046620845794678, "step": 8000}
{"episode_reward": 27.574037650834914, "episode": 9.0, "batch_reward": 0.07199290746077895, "critic_loss": 0.08221556025743484, "actor_loss": -8.052771857142448, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.024275064468384, "step": 9000}
{"episode_reward": 38.351023204371565, "episode": 10.0, "batch_reward": 0.07373934131488204, "critic_loss": 0.13587240263074638, "actor_loss": -9.039948715686798, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.99008297920227, "step": 10000}
{"episode_reward": 120.82401416435857, "episode": 11.0, "batch_reward": 0.07728419238328933, "critic_loss": 0.13818290083482862, "actor_loss": -8.79787384223938, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.37791705131531, "step": 11000}
{"episode_reward": 107.43920226408484, "episode": 12.0, "batch_reward": 0.0778406665995717, "critic_loss": 0.10682724402472377, "actor_loss": -9.826182200908661, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.036176681518555, "step": 12000}
{"episode_reward": 51.65533606317569, "episode": 13.0, "batch_reward": 0.07599287610128522, "critic_loss": 0.1308595289811492, "actor_loss": -9.91804595375061, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.06640386581421, "step": 13000}
{"episode_reward": 92.4478858567236, "episode": 14.0, "batch_reward": 0.07335931909829378, "critic_loss": 0.11880677634850144, "actor_loss": -11.179889996528626, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.022393226623535, "step": 14000}
{"episode_reward": 7.739048498320523, "episode": 15.0, "batch_reward": 0.06942597511783243, "critic_loss": 0.119202910810709, "actor_loss": -11.80223965358734, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04146671295166, "step": 15000}
{"episode_reward": 22.686003502020277, "episode": 16.0, "batch_reward": 0.06837416642904282, "critic_loss": 0.11967629284411668, "actor_loss": -12.281124434471131, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.042984008789062, "step": 16000}
{"episode_reward": 46.698821173766746, "episode": 17.0, "batch_reward": 0.06659639836847782, "critic_loss": 0.10508105286210775, "actor_loss": -11.990655690193176, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.012435913085938, "step": 17000}
{"episode_reward": 34.447943860379894, "episode": 18.0, "batch_reward": 0.0665064185746014, "critic_loss": 0.13260165866091847, "actor_loss": -12.353679060935974, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.018858909606934, "step": 18000}
{"episode_reward": 96.61129130624441, "episode": 19.0, "batch_reward": 0.06572922372817994, "critic_loss": 0.16600254438444972, "actor_loss": -12.078009163856507, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.026876211166382, "step": 19000}
{"episode_reward": 26.971339979431185, "episode": 20.0, "batch_reward": 0.06444795919582248, "critic_loss": 0.18436780585348606, "actor_loss": -12.109714036941527, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.005240201950073, "step": 20000}
{"episode_reward": 42.873949712697545, "episode": 21.0, "batch_reward": 0.0651947434693575, "critic_loss": 0.23789862193912267, "actor_loss": -12.175074439048768, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.341498613357544, "step": 21000}
{"episode_reward": 97.34738755100143, "episode": 22.0, "batch_reward": 0.06886873583123088, "critic_loss": 0.2561002355068922, "actor_loss": -12.607247188568115, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.031121969223022, "step": 22000}
{"episode_reward": 148.46284275684727, "episode": 23.0, "batch_reward": 0.07374031399562955, "critic_loss": 0.236470448307693, "actor_loss": -12.851928859710693, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.08514714241028, "step": 23000}
{"episode_reward": 295.93544672542606, "episode": 24.0, "batch_reward": 0.0798891678005457, "critic_loss": 0.22542454315721988, "actor_loss": -13.586958381652831, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.341409921646118, "step": 24000}
{"episode_reward": 91.07962731340281, "episode": 25.0, "batch_reward": 0.08274406918883323, "critic_loss": 0.25003934030979874, "actor_loss": -14.028257249832153, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.010356187820435, "step": 25000}
{"episode_reward": 256.55910823940843, "episode": 26.0, "batch_reward": 0.08747884830832481, "critic_loss": 0.31070076730102303, "actor_loss": -14.315935771942138, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.984208822250366, "step": 26000}
{"episode_reward": 77.38649730566475, "episode": 27.0, "batch_reward": 0.08807202057912945, "critic_loss": 0.2863001670688391, "actor_loss": -14.55878572654724, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.987984657287598, "step": 27000}
{"episode_reward": 133.43938343114527, "episode": 28.0, "batch_reward": 0.09121340457722545, "critic_loss": 0.2659295304566622, "actor_loss": -15.182600198745728, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0222065448761, "step": 28000}
{"episode_reward": 178.2412692903086, "episode": 29.0, "batch_reward": 0.09202324083819985, "critic_loss": 0.2500434172451496, "actor_loss": -15.08735464477539, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.013766050338745, "step": 29000}
{"episode_reward": 119.48550123517937, "episode": 30.0, "batch_reward": 0.0930674070417881, "critic_loss": 0.22963610612601043, "actor_loss": -15.260869104385376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.99953055381775, "step": 30000}
{"episode_reward": 91.51405109565576, "episode": 31.0, "batch_reward": 0.09169110107049346, "critic_loss": 0.260512350551784, "actor_loss": -15.360344980239867, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.386112689971924, "step": 31000}
{"episode_reward": 43.60485450559844, "episode": 32.0, "batch_reward": 0.09388878145813942, "critic_loss": 0.2585888195335865, "actor_loss": -15.358851451873779, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.006096124649048, "step": 32000}
{"episode_reward": 380.25902416330445, "episode": 33.0, "batch_reward": 0.09816845905780792, "critic_loss": 0.2990593078956008, "actor_loss": -16.35505911064148, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.025277853012085, "step": 33000}
{"episode_reward": 34.21885308847723, "episode": 34.0, "batch_reward": 0.09953661435842515, "critic_loss": 0.23349962647259234, "actor_loss": -16.57396057510376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.024092197418213, "step": 34000}
{"episode_reward": 142.7415897456358, "episode": 35.0, "batch_reward": 0.10236569950729608, "critic_loss": 0.2331753581762314, "actor_loss": -16.85121704483032, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.001593828201294, "step": 35000}
{"episode_reward": 264.69496448367374, "episode": 36.0, "batch_reward": 0.1050968032553792, "critic_loss": 0.2446493629589677, "actor_loss": -17.287137866973875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.004366874694824, "step": 36000}
{"episode_reward": 168.8559059176449, "episode": 37.0, "batch_reward": 0.10647940061241389, "critic_loss": 0.28023503290116786, "actor_loss": -17.536606039047243, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.041663885116577, "step": 37000}
{"episode_reward": 101.73796366588631, "episode": 38.0, "batch_reward": 0.10763961716741323, "critic_loss": 0.24967206449061632, "actor_loss": -18.09831100845337, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.016874313354492, "step": 38000}
{"episode_reward": 179.27600112679568, "episode": 39.0, "batch_reward": 0.10948653022944928, "critic_loss": 0.27051203783601524, "actor_loss": -18.600000955581667, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.022697925567627, "step": 39000}
{"episode_reward": 205.5928761762258, "episode": 40.0, "batch_reward": 0.11193554980307817, "critic_loss": 0.2683925162181258, "actor_loss": -18.961446144104006, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.012427806854248, "step": 40000}
{"episode_reward": 244.19078063315007, "episode": 41.0, "batch_reward": 0.11498124295473099, "critic_loss": 0.2865909455120563, "actor_loss": -19.10442490005493, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.39570713043213, "step": 41000}
{"episode_reward": 194.5842448549669, "episode": 42.0, "batch_reward": 0.11929551389813423, "critic_loss": 0.33273150740563867, "actor_loss": -19.372713188171385, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.99945044517517, "step": 42000}
{"episode_reward": 376.4611796212159, "episode": 43.0, "batch_reward": 0.12424334420263768, "critic_loss": 0.3388763193115592, "actor_loss": -19.783718503952027, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02186918258667, "step": 43000}
{"episode_reward": 413.81021654497573, "episode": 44.0, "batch_reward": 0.13198560310155152, "critic_loss": 0.3139613303989172, "actor_loss": -20.419810052871703, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0080623626709, "step": 44000}
{"episode_reward": 421.18871844681854, "episode": 45.0, "batch_reward": 0.13825572066009045, "critic_loss": 0.27362953817844393, "actor_loss": -20.719165168762206, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.999440670013428, "step": 45000}
{"episode_reward": 448.06211422330574, "episode": 46.0, "batch_reward": 0.1451952534466982, "critic_loss": 0.2816476029008627, "actor_loss": -21.040629802703858, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.025527477264404, "step": 46000}
{"episode_reward": 449.3193951793852, "episode": 47.0, "batch_reward": 0.15161854714900255, "critic_loss": 0.2581449948698282, "actor_loss": -21.717523994445802, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.034393072128296, "step": 47000}
{"episode_reward": 423.6725223676386, "episode": 48.0, "batch_reward": 0.15316367428004743, "critic_loss": 0.3022827894315124, "actor_loss": -21.78567155075073, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.168439388275146, "step": 48000}
{"episode_reward": 65.3322069749862, "episode": 49.0, "batch_reward": 0.15330292037129403, "critic_loss": 0.2689136413037777, "actor_loss": -21.63155216217041, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.286245584487915, "step": 49000}
{"episode_reward": 166.89629328403066, "episode": 50.0, "batch_reward": 0.15359978199750185, "critic_loss": 0.27282250609248876, "actor_loss": -21.696578941345216, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01371169090271, "step": 50000}
{"episode_reward": 138.2040327331425, "episode": 51.0, "batch_reward": 0.15521418614685537, "critic_loss": 0.26249441085755826, "actor_loss": -21.67406739807129, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.3773307800293, "step": 51000}
{"episode_reward": 461.8211294735769, "episode": 52.0, "batch_reward": 0.16204816890507936, "critic_loss": 0.27734085550159215, "actor_loss": -22.133755249023437, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.012001514434814, "step": 52000}
{"episode_reward": 520.5555698843116, "episode": 53.0, "batch_reward": 0.16888521353900432, "critic_loss": 0.26346406746655704, "actor_loss": -22.853373348236083, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.007647037506104, "step": 53000}
{"episode_reward": 487.3706639729268, "episode": 54.0, "batch_reward": 0.17431684355437754, "critic_loss": 0.30393591729551556, "actor_loss": -23.225451950073243, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02250647544861, "step": 54000}
{"episode_reward": 459.4083734369722, "episode": 55.0, "batch_reward": 0.1797333939820528, "critic_loss": 0.28179774414747955, "actor_loss": -23.64699680328369, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.023884057998657, "step": 55000}
{"episode_reward": 500.0004668679329, "episode": 56.0, "batch_reward": 0.1848471547663212, "critic_loss": 0.3047235824018717, "actor_loss": -24.054536243438722, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.997604608535767, "step": 56000}
{"episode_reward": 488.59912769833744, "episode": 57.0, "batch_reward": 0.19046957594156266, "critic_loss": 0.29580936159938576, "actor_loss": -24.45443157196045, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.993170022964478, "step": 57000}
{"episode_reward": 496.9499860967277, "episode": 58.0, "batch_reward": 0.19329182267934084, "critic_loss": 0.3062011539936066, "actor_loss": -24.80843756866455, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.011470079421997, "step": 58000}
{"episode_reward": 65.19612862605094, "episode": 59.0, "batch_reward": 0.19468804687261582, "critic_loss": 0.3124397301673889, "actor_loss": -24.812098537445067, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.009767532348633, "step": 59000}
{"episode_reward": 498.9068060526523, "episode": 60.0, "batch_reward": 0.19839238183200358, "critic_loss": 0.3562488123774529, "actor_loss": -24.8793476600647, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02084445953369, "step": 60000}
{"episode_reward": 510.1182626640966, "episode": 61.0, "batch_reward": 0.201782356351614, "critic_loss": 0.32888975750654936, "actor_loss": -25.251750999450685, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.314284563064575, "step": 61000}
{"episode_reward": 214.52829169569426, "episode": 62.0, "batch_reward": 0.20448567068576812, "critic_loss": 0.2980054662898183, "actor_loss": -25.363716541290284, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.006468772888184, "step": 62000}
{"episode_reward": 516.3112960712494, "episode": 63.0, "batch_reward": 0.2099075321406126, "critic_loss": 0.3128195191472769, "actor_loss": -26.029551612854004, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.991429090499878, "step": 63000}
{"episode_reward": 492.05235016724237, "episode": 64.0, "batch_reward": 0.21388085733354092, "critic_loss": 0.321181917399168, "actor_loss": -26.642263931274414, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.021564483642578, "step": 64000}
{"episode_reward": 538.0173300922115, "episode": 65.0, "batch_reward": 0.21744918528199195, "critic_loss": 0.31923026163876056, "actor_loss": -26.619951511383057, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.029969215393066, "step": 65000}
{"episode_reward": 269.69810473178643, "episode": 66.0, "batch_reward": 0.21856181025505067, "critic_loss": 0.33659593798965215, "actor_loss": -26.5977897605896, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.982414484024048, "step": 66000}
{"episode_reward": 419.9882773169452, "episode": 67.0, "batch_reward": 0.22329537358880042, "critic_loss": 0.3502267748489976, "actor_loss": -27.105637748718262, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01702570915222, "step": 67000}
{"episode_reward": 532.7748641710575, "episode": 68.0, "batch_reward": 0.22810554705560207, "critic_loss": 0.32591919850558043, "actor_loss": -27.574246524810793, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.006776332855225, "step": 68000}
{"episode_reward": 494.2905401412212, "episode": 69.0, "batch_reward": 0.23057533894479273, "critic_loss": 0.33512614975869653, "actor_loss": -27.667402935028075, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.016636848449707, "step": 69000}
{"episode_reward": 475.6153370127347, "episode": 70.0, "batch_reward": 0.23435424281656742, "critic_loss": 0.311622869156301, "actor_loss": -27.90259314727783, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.037598371505737, "step": 70000}
{"episode_reward": 478.96729701230424, "episode": 71.0, "batch_reward": 0.23941665722429753, "critic_loss": 0.314833248347044, "actor_loss": -28.314914123535157, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.33353018760681, "step": 71000}
{"episode_reward": 535.9919438801531, "episode": 72.0, "batch_reward": 0.24185091273486614, "critic_loss": 0.32609259140491487, "actor_loss": -28.29958173751831, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.017700910568237, "step": 72000}
{"episode_reward": 522.018516286819, "episode": 73.0, "batch_reward": 0.2472916844934225, "critic_loss": 0.3130888575986028, "actor_loss": -29.192586669921877, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.027908325195312, "step": 73000}
{"episode_reward": 517.9291805244785, "episode": 74.0, "batch_reward": 0.24924304872751235, "critic_loss": 0.32717201349139213, "actor_loss": -29.164498149871825, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.118289947509766, "step": 74000}
{"episode_reward": 540.7400439857189, "episode": 75.0, "batch_reward": 0.2542250408679247, "critic_loss": 0.34851598501205444, "actor_loss": -29.73257246017456, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.244267463684082, "step": 75000}
{"episode_reward": 499.1532073580727, "episode": 76.0, "batch_reward": 0.25669360780715944, "critic_loss": 0.33546700440347194, "actor_loss": -30.043841388702393, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.99909257888794, "step": 76000}
{"episode_reward": 499.72069414636326, "episode": 77.0, "batch_reward": 0.2604821235835552, "critic_loss": 0.3854028781428933, "actor_loss": -30.30936538696289, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.95581841468811, "step": 77000}
{"episode_reward": 403.52796888430095, "episode": 78.0, "batch_reward": 0.26141421814262866, "critic_loss": 0.3728844854533672, "actor_loss": -30.2153878326416, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.00537657737732, "step": 78000}
{"episode_reward": 528.251455857585, "episode": 79.0, "batch_reward": 0.26539908622205255, "critic_loss": 0.40701816248893735, "actor_loss": -30.63078048324585, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.041189193725586, "step": 79000}
{"episode_reward": 521.0941789595485, "episode": 80.0, "batch_reward": 0.2686619962155819, "critic_loss": 0.3996107314676046, "actor_loss": -30.99120651245117, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.00386929512024, "step": 80000}
{"episode_reward": 543.0139356113676, "episode": 81.0, "batch_reward": 0.27254398514330386, "critic_loss": 0.37870844957232475, "actor_loss": -31.1731149559021, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.32242274284363, "step": 81000}
{"episode_reward": 557.0914538451191, "episode": 82.0, "batch_reward": 0.2757933008521795, "critic_loss": 0.3760037094801664, "actor_loss": -31.7153582611084, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.032310724258423, "step": 82000}
{"episode_reward": 543.5808620352561, "episode": 83.0, "batch_reward": 0.27947625559568406, "critic_loss": 0.370717050164938, "actor_loss": -31.62506409072876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.033363580703735, "step": 83000}
{"episode_reward": 375.8340322430527, "episode": 84.0, "batch_reward": 0.2792191645056009, "critic_loss": 0.37514634354412557, "actor_loss": -31.99942640686035, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.009589433670044, "step": 84000}
{"episode_reward": 545.4822716627556, "episode": 85.0, "batch_reward": 0.28348338671028617, "critic_loss": 0.42975384017825125, "actor_loss": -32.324205905914305, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.043423175811768, "step": 85000}
{"episode_reward": 509.1443554762572, "episode": 86.0, "batch_reward": 0.28485555347800257, "critic_loss": 0.4650927573889494, "actor_loss": -32.73120693588257, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.006133794784546, "step": 86000}
{"episode_reward": 518.0909620234745, "episode": 87.0, "batch_reward": 0.2883938561528921, "critic_loss": 0.5878914403617382, "actor_loss": -33.36316874313354, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.99779510498047, "step": 87000}
{"episode_reward": 516.0438764851044, "episode": 88.0, "batch_reward": 0.2912688081860542, "critic_loss": 0.898427079975605, "actor_loss": -34.44281704711914, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.030316591262817, "step": 88000}
{"episode_reward": 525.6656572300892, "episode": 89.0, "batch_reward": 0.2933000016361475, "critic_loss": 1.0354328127205372, "actor_loss": -35.57636322784424, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.03821897506714, "step": 89000}
{"episode_reward": 515.443118409399, "episode": 90.0, "batch_reward": 0.2964009456783533, "critic_loss": 1.1766949698626996, "actor_loss": -36.91777544403076, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.984235763549805, "step": 90000}
{"episode_reward": 531.9169164476995, "episode": 91.0, "batch_reward": 0.2987681582123041, "critic_loss": 1.2128110505342484, "actor_loss": -37.81115580749512, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.330652475357056, "step": 91000}
{"episode_reward": 520.1973382021198, "episode": 92.0, "batch_reward": 0.3012482358813286, "critic_loss": 0.9962753586173058, "actor_loss": -38.16105660247803, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.00195598602295, "step": 92000}
{"episode_reward": 527.0249424490905, "episode": 93.0, "batch_reward": 0.3032114486545324, "critic_loss": 0.9889679560661316, "actor_loss": -38.72897193145752, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.015825271606445, "step": 93000}
{"episode_reward": 430.1864727744688, "episode": 94.0, "batch_reward": 0.3036988824158907, "critic_loss": 1.0976160340607166, "actor_loss": -39.21215157318115, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.059019804000854, "step": 94000}
{"episode_reward": 16.99073895331399, "episode": 95.0, "batch_reward": 0.29893747355043887, "critic_loss": 1.1086086599826812, "actor_loss": -39.612493896484374, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.011416912078857, "step": 95000}
{"episode_reward": 7.8905071327318606, "episode": 96.0, "batch_reward": 0.2978502189666033, "critic_loss": 1.1271115407049657, "actor_loss": -40.27761150360107, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01893424987793, "step": 96000}
{"episode_reward": 9.374413998423174, "episode": 97.0, "batch_reward": 0.2924858845770359, "critic_loss": 1.0547430544793606, "actor_loss": -40.491277618408205, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0360107421875, "step": 97000}
{"episode_reward": 8.10989475923235, "episode": 98.0, "batch_reward": 0.2911158609241247, "critic_loss": 0.997688725143671, "actor_loss": -41.19033179473877, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.997767686843872, "step": 98000}
{"episode_reward": 11.963024921926287, "episode": 99.0, "batch_reward": 0.28723641313612464, "critic_loss": 0.8897702905237674, "actor_loss": -41.89356129455567, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.033337354660034, "step": 99000}
{"episode_reward": 15.440158519624843, "episode": 100.0, "batch_reward": 0.28491484695672986, "critic_loss": 0.7615976233184337, "actor_loss": -42.53926261138916, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04233980178833, "step": 100000}
{"episode_reward": 14.406781960704455, "episode": 101.0, "batch_reward": 0.2829909250885248, "critic_loss": 0.6900129939615727, "actor_loss": -43.0506138458252, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.394840478897095, "step": 101000}
{"episode_reward": 20.08679727730089, "episode": 102.0, "batch_reward": 0.27964863008260726, "critic_loss": 0.6905600723922253, "actor_loss": -43.43564208984375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.010618448257446, "step": 102000}
{"episode_reward": 21.952154548173024, "episode": 103.0, "batch_reward": 0.27728981065750125, "critic_loss": 0.6439134753644467, "actor_loss": -43.887442909240725, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04786491394043, "step": 103000}
{"episode_reward": 9.2916481027859, "episode": 104.0, "batch_reward": 0.27532370707392695, "critic_loss": 0.5734215219616889, "actor_loss": -43.36218894958496, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0141818523407, "step": 104000}
{"episode_reward": 42.57076478348108, "episode": 105.0, "batch_reward": 0.27120001696050167, "critic_loss": 0.47749245685338976, "actor_loss": -43.99117389678955, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.008789539337158, "step": 105000}
{"episode_reward": 28.225407198572533, "episode": 106.0, "batch_reward": 0.269953293800354, "critic_loss": 0.39499812166392806, "actor_loss": -43.41895234680176, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04416847229004, "step": 106000}
{"episode_reward": 25.98155359391136, "episode": 107.0, "batch_reward": 0.2669907080084086, "critic_loss": 0.372198475420475, "actor_loss": -42.796742637634274, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.030847311019897, "step": 107000}
{"episode_reward": 35.59098000114648, "episode": 108.0, "batch_reward": 0.2654620150029659, "critic_loss": 0.3557642764300108, "actor_loss": -42.23874988555908, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.996615409851074, "step": 108000}
{"episode_reward": 111.75175158257035, "episode": 109.0, "batch_reward": 0.2657553333938122, "critic_loss": 0.3549627055078745, "actor_loss": -41.258315376281736, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.041648864746094, "step": 109000}
{"episode_reward": 94.1810514337881, "episode": 110.0, "batch_reward": 0.2625092591643333, "critic_loss": 0.3387653458714485, "actor_loss": -40.81517003631592, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.024264097213745, "step": 110000}
{"episode_reward": 203.72261151347195, "episode": 111.0, "batch_reward": 0.2619951348155737, "critic_loss": 0.35425445780158044, "actor_loss": -40.40258503723145, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.349629640579224, "step": 111000}
{"episode_reward": 241.77956605845992, "episode": 112.0, "batch_reward": 0.26327813674509526, "critic_loss": 0.3425947192013264, "actor_loss": -40.16243027114868, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.053694486618042, "step": 112000}
{"episode_reward": 450.587037351532, "episode": 113.0, "batch_reward": 0.26475584475696085, "critic_loss": 0.3647295458763838, "actor_loss": -39.818413162231444, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01445436477661, "step": 113000}
{"episode_reward": 21.81597410038052, "episode": 114.0, "batch_reward": 0.26241876554489135, "critic_loss": 0.36710081304609776, "actor_loss": -39.21678698730469, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.028124809265137, "step": 114000}
{"episode_reward": 21.345199530986275, "episode": 115.0, "batch_reward": 0.26051261653006075, "critic_loss": 0.3803125522583723, "actor_loss": -38.800814647674564, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.041939735412598, "step": 115000}
{"episode_reward": 277.1779280155928, "episode": 116.0, "batch_reward": 0.2603033839315176, "critic_loss": 0.33685074777901175, "actor_loss": -38.45744566345215, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0231032371521, "step": 116000}
{"episode_reward": 117.80475559682752, "episode": 117.0, "batch_reward": 0.2590704558342695, "critic_loss": 0.315416905388236, "actor_loss": -38.18056137466431, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05804181098938, "step": 117000}
{"episode_reward": 91.14179778492333, "episode": 118.0, "batch_reward": 0.2577734908759594, "critic_loss": 0.29011781968176364, "actor_loss": -37.81653671646118, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.05657172203064, "step": 118000}
{"episode_reward": 139.5701258330333, "episode": 119.0, "batch_reward": 0.25588585548102855, "critic_loss": 0.267682555899024, "actor_loss": -37.24202350616455, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.009573936462402, "step": 119000}
{"episode_reward": 84.58074026340535, "episode": 120.0, "batch_reward": 0.25538685417175294, "critic_loss": 0.2694066026210785, "actor_loss": -36.755182094573975, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02844500541687, "step": 120000}
{"episode_reward": 130.28940876635127, "episode": 121.0, "batch_reward": 0.25492673766613005, "critic_loss": 0.2728993304222822, "actor_loss": -36.47176358032227, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.419495582580566, "step": 121000}
{"episode_reward": 208.72182037488963, "episode": 122.0, "batch_reward": 0.25372066673636434, "critic_loss": 0.2824256514906883, "actor_loss": -35.72967124557495, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.038984537124634, "step": 122000}
{"episode_reward": 86.89896298224642, "episode": 123.0, "batch_reward": 0.2533471409380436, "critic_loss": 0.3168819864690304, "actor_loss": -35.3269681968689, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.995068073272705, "step": 123000}
{"episode_reward": 84.01546534374594, "episode": 124.0, "batch_reward": 0.2510306418091059, "critic_loss": 0.33839554972946645, "actor_loss": -34.96238708114624, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.03057551383972, "step": 124000}
{"episode_reward": 368.3203026798704, "episode": 125.0, "batch_reward": 0.25404282808303835, "critic_loss": 0.3790222739726305, "actor_loss": -35.02136570358277, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.03474998474121, "step": 125000}
{"episode_reward": 562.3579392568217, "episode": 126.0, "batch_reward": 0.25472690488398075, "critic_loss": 0.4375619960129261, "actor_loss": -34.84782842636108, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02556800842285, "step": 126000}
{"episode_reward": 481.88685483123595, "episode": 127.0, "batch_reward": 0.2575645926594734, "critic_loss": 0.4429713611900806, "actor_loss": -34.859757472991944, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.042444467544556, "step": 127000}
{"episode_reward": 563.3892918033489, "episode": 128.0, "batch_reward": 0.25990143956243994, "critic_loss": 0.42252733433246614, "actor_loss": -34.822509178161624, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.033424377441406, "step": 128000}
{"episode_reward": 568.9774994880352, "episode": 129.0, "batch_reward": 0.2632191944718361, "critic_loss": 0.46087758892774583, "actor_loss": -34.88138108825684, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.993422508239746, "step": 129000}
{"episode_reward": 551.6338199066695, "episode": 130.0, "batch_reward": 0.2645042177438736, "critic_loss": 0.46363375429809095, "actor_loss": -34.96952923583984, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.036685466766357, "step": 130000}
{"episode_reward": 550.2847817758059, "episode": 131.0, "batch_reward": 0.26672081688046456, "critic_loss": 0.4403861222565174, "actor_loss": -34.87214486312866, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.33932614326477, "step": 131000}
{"episode_reward": 546.5575643968156, "episode": 132.0, "batch_reward": 0.26767882944643495, "critic_loss": 0.4735595418214798, "actor_loss": -34.789165489196776, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.022606134414673, "step": 132000}
{"episode_reward": 566.0971734418542, "episode": 133.0, "batch_reward": 0.2700328114032745, "critic_loss": 0.46308442343771455, "actor_loss": -34.958534690856936, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.041605710983276, "step": 133000}
{"episode_reward": 478.85109111880206, "episode": 134.0, "batch_reward": 0.27126552303135393, "critic_loss": 0.4172421271651983, "actor_loss": -34.94080563354492, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.01386833190918, "step": 134000}
{"episode_reward": 285.87459654564014, "episode": 135.0, "batch_reward": 0.2731837889552116, "critic_loss": 0.4391440712660551, "actor_loss": -35.00140880203247, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.039295196533203, "step": 135000}
{"episode_reward": 561.4435683714946, "episode": 136.0, "batch_reward": 0.2741738941222429, "critic_loss": 0.44800649204850196, "actor_loss": -34.981115295410156, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.04169249534607, "step": 136000}
{"episode_reward": 552.1094983372769, "episode": 137.0, "batch_reward": 0.2774859199821949, "critic_loss": 0.46997884909808635, "actor_loss": -35.13219420623779, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.019418001174927, "step": 137000}
{"episode_reward": 564.4818445006011, "episode": 138.0, "batch_reward": 0.2788889643847942, "critic_loss": 0.44569077223539355, "actor_loss": -35.08357804870605, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.038909673690796, "step": 138000}
{"episode_reward": 585.7689255296087, "episode": 139.0, "batch_reward": 0.28096045829355715, "critic_loss": 0.4277610868811607, "actor_loss": -35.156702026367185, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.035964250564575, "step": 139000}
{"episode_reward": 525.8226136674527, "episode": 140.0, "batch_reward": 0.28289431910216806, "critic_loss": 0.43866006143391134, "actor_loss": -35.32281722640991, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.013514041900635, "step": 140000}
{"episode_reward": 565.5375926439439, "episode": 141.0, "batch_reward": 0.28511523246765136, "critic_loss": 0.45065621638298037, "actor_loss": -35.34219563674927, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.33919930458069, "step": 141000}
{"episode_reward": 569.0387030822828, "episode": 142.0, "batch_reward": 0.2875822511911392, "critic_loss": 0.46237737996131184, "actor_loss": -35.43317895507813, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.02015733718872, "step": 142000}
{"episode_reward": 551.2366366715999, "episode": 143.0, "batch_reward": 0.28752213905751706, "critic_loss": 0.4165845607072115, "actor_loss": -35.511396492004394, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.0139377117157, "step": 143000}
{"episode_reward": 565.7968676421518, "episode": 144.0, "batch_reward": 0.29158831726014617, "critic_loss": 0.43755004634708167, "actor_loss": -35.670662803649904, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.034051656723022, "step": 144000}
{"episode_reward": 577.780894416749, "episode": 145.0, "batch_reward": 0.29388325253129005, "critic_loss": 0.4097577100545168, "actor_loss": -35.85715644073486, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.025547981262207, "step": 145000}
{"episode_reward": 560.4687649408498, "episode": 146.0, "batch_reward": 0.29476601220667364, "critic_loss": 0.39264546551555396, "actor_loss": -35.83728210830689, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.030251264572144, "step": 146000}
{"episode_reward": 553.4180275943874, "episode": 147.0, "batch_reward": 0.29632535757124423, "critic_loss": 0.41918865175545217, "actor_loss": -35.830618545532225, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.014373302459717, "step": 147000}
{"episode_reward": 585.7139243216089, "episode": 148.0, "batch_reward": 0.2988056395500898, "critic_loss": 0.38367358799278733, "actor_loss": -35.93665530395508, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.041717052459717, "step": 148000}
{"episode_reward": 555.9166962024137, "episode": 149.0, "batch_reward": 0.3003489592373371, "critic_loss": 0.40031984536349774, "actor_loss": -36.112464847564695, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.042847394943237, "step": 149000}
{"episode_reward": 486.4065466779025, "episode": 150.0, "batch_reward": 0.3021701285243034, "critic_loss": 0.36188734935224054, "actor_loss": -36.05770404815674, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
