{"episode_reward": 0.0, "episode": 1.0, "duration": 17.297969102859497, "step": 1000}
{"episode_reward": 4.20996189079657, "episode": 2.0, "duration": 1.4932184219360352, "step": 2000}
{"episode_reward": 252.2457487418515, "episode": 3.0, "batch_reward": 0.12183012983011142, "critic_loss": 0.03946562143363787, "actor_loss": -17.47718927576667, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 60.30688428878784, "step": 3000}
{"episode_reward": 17.207132871021827, "episode": 4.0, "batch_reward": 0.07978885654360056, "critic_loss": 0.025655097809620202, "actor_loss": -16.05301667547226, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.904587268829346, "step": 4000}
{"episode_reward": 7.420514162717274, "episode": 5.0, "batch_reward": 0.06695743413455785, "critic_loss": 0.034967221171595154, "actor_loss": -15.706208907604218, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.92664122581482, "step": 5000}
{"episode_reward": 51.41678144419501, "episode": 6.0, "batch_reward": 0.07181336297094822, "critic_loss": 0.07241791015677154, "actor_loss": -16.156676092386245, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.883853435516357, "step": 6000}
{"episode_reward": 106.39414861220766, "episode": 7.0, "batch_reward": 0.07325998458266259, "critic_loss": 0.06687145341746509, "actor_loss": -15.875511543810367, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.92401933670044, "step": 7000}
{"episode_reward": 40.57536765408279, "episode": 8.0, "batch_reward": 0.07198830246180296, "critic_loss": 0.08453368923068047, "actor_loss": -15.048292924106121, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.917075872421265, "step": 8000}
{"episode_reward": 134.869096494182, "episode": 9.0, "batch_reward": 0.07591670772060752, "critic_loss": 0.09208534143865109, "actor_loss": -14.04346903961897, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.894426345825195, "step": 9000}
{"episode_reward": 37.687926560993695, "episode": 10.0, "batch_reward": 0.0710127246491611, "critic_loss": 0.10791495315358043, "actor_loss": -14.186539541825653, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.898833751678467, "step": 10000}
{"episode_reward": 25.088680448722982, "episode": 11.0, "batch_reward": 0.06590404324606061, "critic_loss": 0.1203192686624825, "actor_loss": -12.271638112038374, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.23654246330261, "step": 11000}
{"episode_reward": 26.2513399415982, "episode": 12.0, "batch_reward": 0.06616757279634476, "critic_loss": 0.15114028911292554, "actor_loss": -13.303839918248356, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.867444276809692, "step": 12000}
{"episode_reward": 77.17103780232691, "episode": 13.0, "batch_reward": 0.06801670249924063, "critic_loss": 0.187779223151505, "actor_loss": -12.690541345000266, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.88727068901062, "step": 13000}
{"episode_reward": 119.35285317804063, "episode": 14.0, "batch_reward": 0.06993390009179712, "critic_loss": 0.2029182768166065, "actor_loss": -13.09845563018322, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.897763967514038, "step": 14000}
{"episode_reward": 58.1591763406155, "episode": 15.0, "batch_reward": 0.06802469443529845, "critic_loss": 0.18413164592534303, "actor_loss": -12.490171881437302, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.881279706954956, "step": 15000}
{"episode_reward": 31.56241985187412, "episode": 16.0, "batch_reward": 0.06884489419683815, "critic_loss": 0.22842177015542983, "actor_loss": -13.35232242155075, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.90875744819641, "step": 16000}
{"episode_reward": 105.03912953873576, "episode": 17.0, "batch_reward": 0.07087535260245204, "critic_loss": 0.2757120218127966, "actor_loss": -13.040172270536424, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.902218341827393, "step": 17000}
{"episode_reward": 89.65963848600671, "episode": 18.0, "batch_reward": 0.07137459618225693, "critic_loss": 0.271885374084115, "actor_loss": -13.296618159770965, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.904178380966187, "step": 18000}
{"episode_reward": 76.00939407683487, "episode": 19.0, "batch_reward": 0.07128085360676051, "critic_loss": 0.31148486287891863, "actor_loss": -12.633177268981933, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.899569272994995, "step": 19000}
{"episode_reward": 78.35933472908822, "episode": 20.0, "batch_reward": 0.07173445572331548, "critic_loss": 0.303894139572978, "actor_loss": -13.191626443386077, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.87963604927063, "step": 20000}
{"episode_reward": 86.86725390332025, "episode": 21.0, "batch_reward": 0.07121835420653223, "critic_loss": 0.30163016875088217, "actor_loss": -12.634751319885254, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.19189119338989, "step": 21000}
{"episode_reward": 64.56642101902494, "episode": 22.0, "batch_reward": 0.07265328791365028, "critic_loss": 0.30319188625365495, "actor_loss": -13.488196658134461, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.8887779712677, "step": 22000}
{"episode_reward": 149.38345696949187, "episode": 23.0, "batch_reward": 0.07821067508682608, "critic_loss": 0.3319650234505534, "actor_loss": -13.63725612306595, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.938417196273804, "step": 23000}
{"episode_reward": 242.27760977167273, "episode": 24.0, "batch_reward": 0.08198615342006087, "critic_loss": 0.3578919099122286, "actor_loss": -13.67251974773407, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.90097665786743, "step": 24000}
{"episode_reward": 69.78287379568876, "episode": 25.0, "batch_reward": 0.0826181437857449, "critic_loss": 0.35600956530869005, "actor_loss": -14.54296683883667, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.90910243988037, "step": 25000}
{"episode_reward": 122.88872701429199, "episode": 26.0, "batch_reward": 0.08364178745448589, "critic_loss": 0.3773001408353448, "actor_loss": -13.87818473625183, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.931559324264526, "step": 26000}
{"episode_reward": 57.38707293832563, "episode": 27.0, "batch_reward": 0.08219760927185417, "critic_loss": 0.3499506771415472, "actor_loss": -13.805537616729737, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.086973190307617, "step": 27000}
{"episode_reward": 61.360871071837835, "episode": 28.0, "batch_reward": 0.08418048464879394, "critic_loss": 0.36906866332143545, "actor_loss": -14.391354740142821, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.033052682876587, "step": 28000}
{"episode_reward": 174.93096662827676, "episode": 29.0, "batch_reward": 0.08712599422782659, "critic_loss": 0.4145778789371252, "actor_loss": -14.597985677719116, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.894882202148438, "step": 29000}
{"episode_reward": 181.72987031442383, "episode": 30.0, "batch_reward": 0.08874278350174428, "critic_loss": 0.42513738489151, "actor_loss": -14.399414399147034, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.84552764892578, "step": 30000}
{"episode_reward": 96.69074080045817, "episode": 31.0, "batch_reward": 0.09074040577188135, "critic_loss": 0.42256947605311873, "actor_loss": -15.406581552505493, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.21637034416199, "step": 31000}
{"episode_reward": 130.84668205577313, "episode": 32.0, "batch_reward": 0.09244980504736304, "critic_loss": 0.38265428003668783, "actor_loss": -15.05823002910614, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.870184183120728, "step": 32000}
{"episode_reward": 239.2490421369002, "episode": 33.0, "batch_reward": 0.09597771484404802, "critic_loss": 0.33227110126614573, "actor_loss": -15.637068248748779, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.910940885543823, "step": 33000}
{"episode_reward": 152.9923278121146, "episode": 34.0, "batch_reward": 0.09887586308270693, "critic_loss": 0.35392494951188563, "actor_loss": -15.805602880477906, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.901493072509766, "step": 34000}
{"episode_reward": 298.8549850950386, "episode": 35.0, "batch_reward": 0.10417297214269639, "critic_loss": 0.3750087704360485, "actor_loss": -16.01303025150299, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.90771484375, "step": 35000}
{"episode_reward": 273.9172752674221, "episode": 36.0, "batch_reward": 0.10951152755320072, "critic_loss": 0.39973830431699753, "actor_loss": -17.119044810295104, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.89943552017212, "step": 36000}
{"episode_reward": 247.0856663605533, "episode": 37.0, "batch_reward": 0.11339710109680891, "critic_loss": 0.3994091119170189, "actor_loss": -17.22276481819153, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.90833330154419, "step": 37000}
{"episode_reward": 202.70339112443625, "episode": 38.0, "batch_reward": 0.11546722383797169, "critic_loss": 0.3515643816292286, "actor_loss": -17.24649062538147, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.909882307052612, "step": 38000}
{"episode_reward": 255.89587554487866, "episode": 39.0, "batch_reward": 0.12030163239687681, "critic_loss": 0.3932698345631361, "actor_loss": -18.02402540588379, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.888418674468994, "step": 39000}
{"episode_reward": 359.0064386051889, "episode": 40.0, "batch_reward": 0.1265683441385627, "critic_loss": 0.34866346372663976, "actor_loss": -19.108126708984376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.87176489830017, "step": 40000}
{"episode_reward": 383.4206339822929, "episode": 41.0, "batch_reward": 0.13270881213992833, "critic_loss": 0.3869608401358128, "actor_loss": -19.353128952026367, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.19377279281616, "step": 41000}
{"episode_reward": 377.23493764019264, "episode": 42.0, "batch_reward": 0.13948683542013168, "critic_loss": 0.4085120649039745, "actor_loss": -19.69069122314453, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.87921977043152, "step": 42000}
{"episode_reward": 403.98440294231506, "episode": 43.0, "batch_reward": 0.14530594813078643, "critic_loss": 0.41226423817873004, "actor_loss": -20.42986930847168, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.87287449836731, "step": 43000}
{"episode_reward": 425.3297267820654, "episode": 44.0, "batch_reward": 0.1480290495380759, "critic_loss": 0.38405266286432743, "actor_loss": -20.266837478637694, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.898424863815308, "step": 44000}
{"episode_reward": 52.163673325311336, "episode": 45.0, "batch_reward": 0.14763920199871064, "critic_loss": 0.3763251589536667, "actor_loss": -20.05317383003235, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.87243890762329, "step": 45000}
{"episode_reward": 164.12108733180636, "episode": 46.0, "batch_reward": 0.15046179669350385, "critic_loss": 0.3828901849985123, "actor_loss": -20.464646017074585, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.88429093360901, "step": 46000}
{"episode_reward": 408.6740468701891, "episode": 47.0, "batch_reward": 0.15401536151766776, "critic_loss": 0.3959954262673855, "actor_loss": -20.91952445411682, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.92693567276001, "step": 47000}
{"episode_reward": 152.31322214374126, "episode": 48.0, "batch_reward": 0.15185444137454032, "critic_loss": 0.36688382445275786, "actor_loss": -20.410057943344118, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.883487224578857, "step": 48000}
{"episode_reward": 71.40186468170876, "episode": 49.0, "batch_reward": 0.15402414199709893, "critic_loss": 0.37115909151732923, "actor_loss": -20.569032958984376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.87436294555664, "step": 49000}
{"episode_reward": 465.85325606516227, "episode": 50.0, "batch_reward": 0.16085530969500542, "critic_loss": 0.37662334114313123, "actor_loss": -21.186319664001466, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.88654589653015, "step": 50000}
{"episode_reward": 520.6512015785228, "episode": 51.0, "batch_reward": 0.1669817039743066, "critic_loss": 0.3804638198763132, "actor_loss": -21.978118778228758, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.271674156188965, "step": 51000}
{"episode_reward": 340.8866085994633, "episode": 52.0, "batch_reward": 0.17142689730226993, "critic_loss": 0.40435407845675947, "actor_loss": -22.3518234500885, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.2077579498291, "step": 52000}
{"episode_reward": 500.84966831333657, "episode": 53.0, "batch_reward": 0.17464425976574421, "critic_loss": 0.3746473154872656, "actor_loss": -22.92137763977051, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.994909048080444, "step": 53000}
{"episode_reward": 80.23943460061415, "episode": 54.0, "batch_reward": 0.17329711279273033, "critic_loss": 0.3863203700333834, "actor_loss": -22.704221225738525, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.908349752426147, "step": 54000}
{"episode_reward": 162.9653593372019, "episode": 55.0, "batch_reward": 0.1758977389037609, "critic_loss": 0.422917437300086, "actor_loss": -23.10264801597595, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.89122486114502, "step": 55000}
{"episode_reward": 475.5269987709891, "episode": 56.0, "batch_reward": 0.18133802142739297, "critic_loss": 0.4147655217349529, "actor_loss": -23.89490238761902, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.928500413894653, "step": 56000}
{"episode_reward": 487.5539491201616, "episode": 57.0, "batch_reward": 0.18496676939725876, "critic_loss": 0.5094300841093063, "actor_loss": -23.981828189849853, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.915903091430664, "step": 57000}
{"episode_reward": 166.60009857042036, "episode": 58.0, "batch_reward": 0.18580950751900674, "critic_loss": 0.46754995636641977, "actor_loss": -24.293517810821534, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.878496170043945, "step": 58000}
{"episode_reward": 448.1733934899924, "episode": 59.0, "batch_reward": 0.19070244048535823, "critic_loss": 0.43421500785648826, "actor_loss": -24.78490929031372, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.888043642044067, "step": 59000}
{"episode_reward": 413.45862826510415, "episode": 60.0, "batch_reward": 0.19329638580977918, "critic_loss": 0.468611574858427, "actor_loss": -25.029762351989746, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.91835594177246, "step": 60000}
{"episode_reward": 288.86171206646213, "episode": 61.0, "batch_reward": 0.1934617201834917, "critic_loss": 0.4655551055371761, "actor_loss": -25.06840729522705, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.15710687637329, "step": 61000}
{"episode_reward": 351.09555177982384, "episode": 62.0, "batch_reward": 0.19769911496341228, "critic_loss": 0.4905729580372572, "actor_loss": -25.136189575195313, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.927945613861084, "step": 62000}
{"episode_reward": 456.7509868644178, "episode": 63.0, "batch_reward": 0.20258913205564022, "critic_loss": 0.47830755001306535, "actor_loss": -25.921701938629152, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.91326332092285, "step": 63000}
{"episode_reward": 488.1736456900511, "episode": 64.0, "batch_reward": 0.2043011499941349, "critic_loss": 0.44718798115849495, "actor_loss": -26.51344585800171, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.888537406921387, "step": 64000}
{"episode_reward": 96.27138442773645, "episode": 65.0, "batch_reward": 0.20386516535282134, "critic_loss": 0.4576772494614124, "actor_loss": -26.124302284240724, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.903311014175415, "step": 65000}
{"episode_reward": 217.86825164707116, "episode": 66.0, "batch_reward": 0.20637054327130316, "critic_loss": 0.46149526700377463, "actor_loss": -26.393047592163086, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.894547939300537, "step": 66000}
{"episode_reward": 490.9601716602358, "episode": 67.0, "batch_reward": 0.20763415022194384, "critic_loss": 0.4653180208355188, "actor_loss": -26.300843669891357, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.913594961166382, "step": 67000}
{"episode_reward": 170.79639665119257, "episode": 68.0, "batch_reward": 0.20855132971704007, "critic_loss": 0.4980936869233847, "actor_loss": -26.732441383361817, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.894850969314575, "step": 68000}
{"episode_reward": 326.9665328979207, "episode": 69.0, "batch_reward": 0.20902725277841092, "critic_loss": 0.5265505005568266, "actor_loss": -26.469191085815428, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.899989128112793, "step": 69000}
{"episode_reward": 212.90642795623864, "episode": 70.0, "batch_reward": 0.20940222610533238, "critic_loss": 0.50410009367764, "actor_loss": -26.336514137268065, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.89488387107849, "step": 70000}
{"episode_reward": 134.2300374739479, "episode": 71.0, "batch_reward": 0.2095843103826046, "critic_loss": 0.48163476549088957, "actor_loss": -26.51119849395752, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.17591643333435, "step": 71000}
{"episode_reward": 467.2892281417994, "episode": 72.0, "batch_reward": 0.21330384704470634, "critic_loss": 0.48100548745691774, "actor_loss": -26.92926230239868, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.916712760925293, "step": 72000}
{"episode_reward": 458.82232127169584, "episode": 73.0, "batch_reward": 0.21658657959103583, "critic_loss": 0.4937717330753803, "actor_loss": -27.068393142700195, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.880542039871216, "step": 73000}
{"episode_reward": 508.5458017070508, "episode": 74.0, "batch_reward": 0.22021176150441168, "critic_loss": 0.5012754951417446, "actor_loss": -27.55443878173828, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.916004180908203, "step": 74000}
{"episode_reward": 403.19904721275844, "episode": 75.0, "batch_reward": 0.22158904249966144, "critic_loss": 0.5041537020504475, "actor_loss": -27.79709404373169, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.918134450912476, "step": 75000}
{"episode_reward": 117.03272378960995, "episode": 76.0, "batch_reward": 0.21993662542104722, "critic_loss": 0.4758265341296792, "actor_loss": -27.477343742370607, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.866920232772827, "step": 76000}
{"episode_reward": 124.57564826518373, "episode": 77.0, "batch_reward": 0.22038902808725833, "critic_loss": 0.49568621326982976, "actor_loss": -27.341529529571535, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.877800941467285, "step": 77000}
{"episode_reward": 474.0779179679372, "episode": 78.0, "batch_reward": 0.22395624440908432, "critic_loss": 0.4637471597194672, "actor_loss": -27.536235961914063, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.93632698059082, "step": 78000}
{"episode_reward": 472.9926932719466, "episode": 79.0, "batch_reward": 0.22651009848713874, "critic_loss": 0.5003398114293813, "actor_loss": -27.95972149658203, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.980406284332275, "step": 79000}
{"episode_reward": 514.4382115480688, "episode": 80.0, "batch_reward": 0.23087856017053127, "critic_loss": 0.5089733382612467, "actor_loss": -28.389499027252196, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.137253999710083, "step": 80000}
{"episode_reward": 526.3061038129355, "episode": 81.0, "batch_reward": 0.23400354287028313, "critic_loss": 0.4764728528857231, "actor_loss": -28.65015217590332, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.360899925231934, "step": 81000}
{"episode_reward": 504.61380637238324, "episode": 82.0, "batch_reward": 0.23762558661401273, "critic_loss": 0.5581720109730959, "actor_loss": -29.031499073028563, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.953855752944946, "step": 82000}
{"episode_reward": 494.8330083199559, "episode": 83.0, "batch_reward": 0.24002951814234258, "critic_loss": 0.5184636663049459, "actor_loss": -29.008116054534913, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.967559814453125, "step": 83000}
{"episode_reward": 501.2967348213326, "episode": 84.0, "batch_reward": 0.2449787879139185, "critic_loss": 0.5225082382112741, "actor_loss": -29.54951312637329, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.980621337890625, "step": 84000}
{"episode_reward": 542.0711660048379, "episode": 85.0, "batch_reward": 0.24722139289975167, "critic_loss": 0.5081918630599975, "actor_loss": -29.650941642761232, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.92367124557495, "step": 85000}
{"episode_reward": 519.0014715239448, "episode": 86.0, "batch_reward": 0.24923203621804715, "critic_loss": 0.4932746309787035, "actor_loss": -29.628148345947267, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.952688455581665, "step": 86000}
{"episode_reward": 502.5673586146473, "episode": 87.0, "batch_reward": 0.2524700922369957, "critic_loss": 0.49159130854904654, "actor_loss": -30.003049076080323, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.957023859024048, "step": 87000}
{"episode_reward": 487.8694297777677, "episode": 88.0, "batch_reward": 0.25585757271945475, "critic_loss": 0.5088108850717544, "actor_loss": -30.198777694702148, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.976557970046997, "step": 88000}
{"episode_reward": 533.4565282418539, "episode": 89.0, "batch_reward": 0.25936526884138583, "critic_loss": 0.5213558560162783, "actor_loss": -30.576351543426515, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.97335457801819, "step": 89000}
{"episode_reward": 526.6382088950373, "episode": 90.0, "batch_reward": 0.26257633620500564, "critic_loss": 0.5029481061547995, "actor_loss": -31.01623139953613, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.963233947753906, "step": 90000}
{"episode_reward": 510.4578247908682, "episode": 91.0, "batch_reward": 0.26464931926131247, "critic_loss": 0.48351095847785475, "actor_loss": -31.066925872802734, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.554574489593506, "step": 91000}
{"episode_reward": 372.37433258022645, "episode": 92.0, "batch_reward": 0.26546128098666666, "critic_loss": 0.479569023296237, "actor_loss": -30.763567180633544, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.95181369781494, "step": 92000}
{"episode_reward": 512.4912304637236, "episode": 93.0, "batch_reward": 0.2678399287313223, "critic_loss": 0.4643293938934803, "actor_loss": -31.261014949798582, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.93661594390869, "step": 93000}
{"episode_reward": 525.8598392601846, "episode": 94.0, "batch_reward": 0.2722327902764082, "critic_loss": 0.438486040443182, "actor_loss": -31.320984436035157, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.94600009918213, "step": 94000}
{"episode_reward": 316.5799980316383, "episode": 95.0, "batch_reward": 0.2705530375689268, "critic_loss": 0.4336983416378498, "actor_loss": -31.799197368621826, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.962004899978638, "step": 95000}
{"episode_reward": 518.2293885211958, "episode": 96.0, "batch_reward": 0.2750240923166275, "critic_loss": 0.5188418981581926, "actor_loss": -31.59082789993286, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.992279767990112, "step": 96000}
{"episode_reward": 520.1429635628978, "episode": 97.0, "batch_reward": 0.2766855818033218, "critic_loss": 0.5489969631135464, "actor_loss": -32.19577629470825, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.925499439239502, "step": 97000}
{"episode_reward": 509.24449781967127, "episode": 98.0, "batch_reward": 0.2806738629490137, "critic_loss": 0.5098699126690626, "actor_loss": -32.79023029327393, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.946673154830933, "step": 98000}
{"episode_reward": 507.2658360267354, "episode": 99.0, "batch_reward": 0.28038854643702504, "critic_loss": 0.4877597551941872, "actor_loss": -32.53876666641235, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.982468605041504, "step": 99000}
{"episode_reward": 557.975002207761, "episode": 100.0, "batch_reward": 0.2843235016167164, "critic_loss": 0.4885394853204489, "actor_loss": -32.7883371887207, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.962368965148926, "step": 100000}
{"episode_reward": 522.5828806524707, "episode": 101.0, "batch_reward": 0.2867595379501581, "critic_loss": 0.46727372132241723, "actor_loss": -32.66888806533814, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.22673439979553, "step": 101000}
{"episode_reward": 475.58361519986505, "episode": 102.0, "batch_reward": 0.2885447448939085, "critic_loss": 0.47871441508829593, "actor_loss": -33.147155811309815, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.916876554489136, "step": 102000}
{"episode_reward": 505.17621682201576, "episode": 103.0, "batch_reward": 0.2911664484292269, "critic_loss": 0.4592479480952024, "actor_loss": -33.1939891166687, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.92067241668701, "step": 103000}
{"episode_reward": 545.0458915253755, "episode": 104.0, "batch_reward": 0.29436109386384485, "critic_loss": 0.5304580267518759, "actor_loss": -33.6973768196106, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.89350175857544, "step": 104000}
{"episode_reward": 535.0625381052675, "episode": 105.0, "batch_reward": 0.29584403496980666, "critic_loss": 0.4955930766016245, "actor_loss": -33.60144758224487, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.91985297203064, "step": 105000}
{"episode_reward": 549.4752034153837, "episode": 106.0, "batch_reward": 0.29812079113721845, "critic_loss": 0.47426981930434703, "actor_loss": -33.992958030700684, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.89639115333557, "step": 106000}
{"episode_reward": 539.3683611587775, "episode": 107.0, "batch_reward": 0.2999270133972168, "critic_loss": 0.47417530792951584, "actor_loss": -34.3873316078186, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.883264780044556, "step": 107000}
{"episode_reward": 554.363345124161, "episode": 108.0, "batch_reward": 0.3025283432602882, "critic_loss": 0.4946855614185333, "actor_loss": -34.422649932861326, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.92402219772339, "step": 108000}
{"episode_reward": 551.6501765469073, "episode": 109.0, "batch_reward": 0.3054549343585968, "critic_loss": 0.484991090208292, "actor_loss": -34.71281200408936, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.903647899627686, "step": 109000}
{"episode_reward": 537.0442119890918, "episode": 110.0, "batch_reward": 0.30770329070091246, "critic_loss": 0.47934116449952124, "actor_loss": -34.86406550598144, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.882859468460083, "step": 110000}
{"episode_reward": 428.5807251850287, "episode": 111.0, "batch_reward": 0.30841930654644967, "critic_loss": 0.5004542711824179, "actor_loss": -34.65539100646973, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.226526737213135, "step": 111000}
{"episode_reward": 554.3052877035745, "episode": 112.0, "batch_reward": 0.30967988102138044, "critic_loss": 0.4760870266407728, "actor_loss": -34.8484398727417, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.89141607284546, "step": 112000}
{"episode_reward": 501.8682447853323, "episode": 113.0, "batch_reward": 0.3135625472664833, "critic_loss": 0.530795436963439, "actor_loss": -34.96146357345581, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.913809537887573, "step": 113000}
{"episode_reward": 506.78347643585346, "episode": 114.0, "batch_reward": 0.31410794180631635, "critic_loss": 0.5248598260134458, "actor_loss": -35.33164253616333, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.930047750473022, "step": 114000}
{"episode_reward": 508.66940247781923, "episode": 115.0, "batch_reward": 0.31547266454994677, "critic_loss": 0.537060965359211, "actor_loss": -35.98255400848389, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.895193815231323, "step": 115000}
{"episode_reward": 525.8241102948872, "episode": 116.0, "batch_reward": 0.3161641316711903, "critic_loss": 0.522346817061305, "actor_loss": -35.72146207046509, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.881117343902588, "step": 116000}
{"episode_reward": 539.6876250788807, "episode": 117.0, "batch_reward": 0.3198623995184898, "critic_loss": 0.5791780907213688, "actor_loss": -36.33622265625, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.94090175628662, "step": 117000}
{"episode_reward": 506.84655128145243, "episode": 118.0, "batch_reward": 0.32205498024821283, "critic_loss": 0.5812919473946094, "actor_loss": -36.334041492462156, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.913036584854126, "step": 118000}
{"episode_reward": 567.0823488623921, "episode": 119.0, "batch_reward": 0.3225758925676346, "critic_loss": 0.5860391392409802, "actor_loss": -36.564304386138915, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.926814794540405, "step": 119000}
{"episode_reward": 549.7552945204587, "episode": 120.0, "batch_reward": 0.3258184222877026, "critic_loss": 0.6050082136541605, "actor_loss": -37.0384405670166, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.902557373046875, "step": 120000}
{"episode_reward": 570.7033763878594, "episode": 121.0, "batch_reward": 0.32833961486816404, "critic_loss": 0.7245412835180759, "actor_loss": -37.253583293914794, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.20805835723877, "step": 121000}
{"episode_reward": 556.5846181931935, "episode": 122.0, "batch_reward": 0.3305179787278175, "critic_loss": 0.7864228790700436, "actor_loss": -37.60888953399658, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.899920225143433, "step": 122000}
{"episode_reward": 577.3780786171086, "episode": 123.0, "batch_reward": 0.3300117385685444, "critic_loss": 0.8902538340985775, "actor_loss": -37.73019538497925, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.923733234405518, "step": 123000}
{"episode_reward": 258.6675696053649, "episode": 124.0, "batch_reward": 0.33066904321312907, "critic_loss": 1.0587405018210412, "actor_loss": -37.724291763305665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.920191764831543, "step": 124000}
{"episode_reward": 563.0148144474571, "episode": 125.0, "batch_reward": 0.3329761303961277, "critic_loss": 1.2425429156124592, "actor_loss": -38.28503139877319, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.883564233779907, "step": 125000}
{"episode_reward": 484.5783409843039, "episode": 126.0, "batch_reward": 0.3330848878324032, "critic_loss": 1.6449519760608673, "actor_loss": -38.605870849609374, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.89861011505127, "step": 126000}
{"episode_reward": 594.6501094316966, "episode": 127.0, "batch_reward": 0.3349274399280548, "critic_loss": 1.7420061314404012, "actor_loss": -39.28531576538086, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.920352458953857, "step": 127000}
{"episode_reward": 401.4548469067164, "episode": 128.0, "batch_reward": 0.3337849875688553, "critic_loss": 2.4054404523968698, "actor_loss": -39.98926881408691, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.9159939289093, "step": 128000}
{"episode_reward": 16.947519630779023, "episode": 129.0, "batch_reward": 0.33143992838263514, "critic_loss": 2.2169838003516196, "actor_loss": -40.902282829284665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.909082412719727, "step": 129000}
{"episode_reward": 10.333752156554267, "episode": 130.0, "batch_reward": 0.32968617901206015, "critic_loss": 2.3108787595033644, "actor_loss": -41.6742160949707, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.934327840805054, "step": 130000}
{"episode_reward": 9.632568116980478, "episode": 131.0, "batch_reward": 0.32718129473924634, "critic_loss": 2.436554499566555, "actor_loss": -42.712888778686526, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.267953634262085, "step": 131000}
{"episode_reward": 8.607991098750519, "episode": 132.0, "batch_reward": 0.324304065823555, "critic_loss": 2.2971651691198347, "actor_loss": -44.04494842529297, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.93917751312256, "step": 132000}
{"episode_reward": 10.590451826911979, "episode": 133.0, "batch_reward": 0.3206849637925625, "critic_loss": 2.1525754099488257, "actor_loss": -45.367618522644044, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.90592050552368, "step": 133000}
{"episode_reward": 14.645249097629621, "episode": 134.0, "batch_reward": 0.32023364992439746, "critic_loss": 1.9482680376768111, "actor_loss": -46.262608200073245, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.921568632125854, "step": 134000}
{"episode_reward": 13.459083127648022, "episode": 135.0, "batch_reward": 0.31580405244231224, "critic_loss": 1.6231020405292511, "actor_loss": -46.26722949981689, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.924184322357178, "step": 135000}
{"episode_reward": 27.144120336522402, "episode": 136.0, "batch_reward": 0.3153062446117401, "critic_loss": 1.2877644044756889, "actor_loss": -46.40010655212402, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.91063952445984, "step": 136000}
{"episode_reward": 50.01827449000921, "episode": 137.0, "batch_reward": 0.314117870926857, "critic_loss": 1.0001440073847772, "actor_loss": -47.234695205688475, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.90979313850403, "step": 137000}
{"episode_reward": 86.50273990874973, "episode": 138.0, "batch_reward": 0.31279505153000353, "critic_loss": 0.8723908166289329, "actor_loss": -47.044560325622555, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.88281226158142, "step": 138000}
{"episode_reward": 85.68182611978865, "episode": 139.0, "batch_reward": 0.30938782592117786, "critic_loss": 0.7410080291032791, "actor_loss": -46.757886421203615, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.93721652030945, "step": 139000}
{"episode_reward": 35.06596056602931, "episode": 140.0, "batch_reward": 0.3067793923467398, "critic_loss": 0.6132498897016049, "actor_loss": -46.074565467834475, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.92538809776306, "step": 140000}
{"episode_reward": 84.70326829332235, "episode": 141.0, "batch_reward": 0.306239526540041, "critic_loss": 0.5038818573951721, "actor_loss": -44.860501945495606, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.222487926483154, "step": 141000}
{"episode_reward": 139.27737078039854, "episode": 142.0, "batch_reward": 0.30440128257870674, "critic_loss": 0.3778598774373531, "actor_loss": -44.802095642089846, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.921743154525757, "step": 142000}
{"episode_reward": 193.69685624105398, "episode": 143.0, "batch_reward": 0.30439837236702444, "critic_loss": 0.2769522285461426, "actor_loss": -43.70100323486328, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.863377332687378, "step": 143000}
{"episode_reward": 81.03427294827725, "episode": 144.0, "batch_reward": 0.3038312087357044, "critic_loss": 0.21369684332609176, "actor_loss": -43.47642557525635, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.90673542022705, "step": 144000}
{"episode_reward": 287.56771083676597, "episode": 145.0, "batch_reward": 0.30162730953097344, "critic_loss": 0.20524691825360059, "actor_loss": -42.67521630096436, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.917125940322876, "step": 145000}
{"episode_reward": 128.48491298765174, "episode": 146.0, "batch_reward": 0.3015239349901676, "critic_loss": 0.22208521531522274, "actor_loss": -42.31840824890137, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.919734716415405, "step": 146000}
{"episode_reward": 80.39158103556231, "episode": 147.0, "batch_reward": 0.30132972039282324, "critic_loss": 0.24200619423389436, "actor_loss": -41.60688371276856, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.909590244293213, "step": 147000}
{"episode_reward": 87.47548935812011, "episode": 148.0, "batch_reward": 0.30026445569098, "critic_loss": 0.2723599976077676, "actor_loss": -41.15624250793457, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.90225577354431, "step": 148000}
{"episode_reward": 451.71773839132504, "episode": 149.0, "batch_reward": 0.3009211247563362, "critic_loss": 0.2885180023089051, "actor_loss": -40.87769854736328, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 19.88509225845337, "step": 149000}
{"episode_reward": 355.7118504108509, "episode": 150.0, "batch_reward": 0.3012879975140095, "critic_loss": 0.348479107812047, "actor_loss": -40.327779266357425, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
