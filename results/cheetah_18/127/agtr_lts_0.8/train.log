{"episode_reward": 0.0, "episode": 1.0, "duration": 17.242453813552856, "step": 1000}
{"episode_reward": 7.051849146674556, "episode": 2.0, "duration": 1.494349718093872, "step": 2000}
{"episode_reward": 365.4711839680396, "episode": 3.0, "batch_reward": 0.1908931791802254, "critic_loss": 0.3596702705138363, "actor_loss": -36.02913575098008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.53219509124756, "step": 3000}
{"episode_reward": 302.0138341538519, "episode": 4.0, "batch_reward": 0.24577561993896963, "critic_loss": 0.5147179076969624, "actor_loss": -38.185941116333005, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.145419597625732, "step": 4000}
{"episode_reward": 403.2133413936797, "episode": 5.0, "batch_reward": 0.2817810931056738, "critic_loss": 0.6354625079929829, "actor_loss": -39.770471168518064, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.131399154663086, "step": 5000}
{"episode_reward": 419.9372469551341, "episode": 6.0, "batch_reward": 0.31139799444377425, "critic_loss": 0.6082828339338303, "actor_loss": -41.33902620697022, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13265061378479, "step": 6000}
{"episode_reward": 427.12075024472915, "episode": 7.0, "batch_reward": 0.32608370661735536, "critic_loss": 0.6533098454475403, "actor_loss": -42.07044458770752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.141416549682617, "step": 7000}
{"episode_reward": 422.53754388662475, "episode": 8.0, "batch_reward": 0.3422907100021839, "critic_loss": 0.6587824423611164, "actor_loss": -42.79609353637695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12479305267334, "step": 8000}
{"episode_reward": 449.1390463850898, "episode": 9.0, "batch_reward": 0.34993696358799936, "critic_loss": 0.729951689362526, "actor_loss": -43.06789933013916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.133796215057373, "step": 9000}
{"episode_reward": 359.17756667939517, "episode": 10.0, "batch_reward": 0.3517396164834499, "critic_loss": 0.7156820341050625, "actor_loss": -43.10054463195801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.130887031555176, "step": 10000}
{"episode_reward": 366.44892435277137, "episode": 11.0, "batch_reward": 0.3522048901617527, "critic_loss": 0.7481582269966602, "actor_loss": -42.864341751098635, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.387218952178955, "step": 11000}
{"episode_reward": 395.0472758452919, "episode": 12.0, "batch_reward": 0.35638588935136795, "critic_loss": 0.7444109183847905, "actor_loss": -42.99294655609131, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.128073930740356, "step": 12000}
{"episode_reward": 376.56909534235393, "episode": 13.0, "batch_reward": 0.3601860391199589, "critic_loss": 0.7267541066408157, "actor_loss": -43.11197486877441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.133674383163452, "step": 13000}
{"episode_reward": 440.8513072441581, "episode": 14.0, "batch_reward": 0.36580007371306417, "critic_loss": 0.6823719583749771, "actor_loss": -43.298329010009766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12479519844055, "step": 14000}
{"episode_reward": 436.8699376552506, "episode": 15.0, "batch_reward": 0.3610997754335403, "critic_loss": 0.6478108893930912, "actor_loss": -42.539103408813475, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13433289527893, "step": 15000}
{"episode_reward": 72.17494507627396, "episode": 16.0, "batch_reward": 0.3524668508172035, "critic_loss": 0.6119206426441669, "actor_loss": -41.364168663024905, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11734700202942, "step": 16000}
{"episode_reward": 432.04952152664777, "episode": 17.0, "batch_reward": 0.3567057606577873, "critic_loss": 0.6821666948199272, "actor_loss": -41.42330297851562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14033818244934, "step": 17000}
{"episode_reward": 399.2062471778998, "episode": 18.0, "batch_reward": 0.35961820116639137, "critic_loss": 0.6521540352106094, "actor_loss": -41.61690380096436, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.131582736968994, "step": 18000}
{"episode_reward": 431.8900148102864, "episode": 19.0, "batch_reward": 0.36173134464025497, "critic_loss": 0.7162762226760387, "actor_loss": -41.82473126983643, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13730502128601, "step": 19000}
{"episode_reward": 391.42076097735713, "episode": 20.0, "batch_reward": 0.36440567481517794, "critic_loss": 0.6945003368556499, "actor_loss": -42.10714463043213, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13059163093567, "step": 20000}
{"episode_reward": 385.19198668765586, "episode": 21.0, "batch_reward": 0.36677689296007154, "critic_loss": 0.6723789876103401, "actor_loss": -41.6684358291626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.39455986022949, "step": 21000}
{"episode_reward": 476.6355693553075, "episode": 22.0, "batch_reward": 0.3711435545086861, "critic_loss": 0.6805636840462684, "actor_loss": -42.308861557006836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12675976753235, "step": 22000}
{"episode_reward": 412.0767919745824, "episode": 23.0, "batch_reward": 0.3729563992321491, "critic_loss": 0.6961000596582889, "actor_loss": -42.02050859832764, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.117948055267334, "step": 23000}
{"episode_reward": 450.80655813549583, "episode": 24.0, "batch_reward": 0.3753462009727955, "critic_loss": 0.6908556352555751, "actor_loss": -42.37457540130615, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.126688957214355, "step": 24000}
{"episode_reward": 418.8649567159415, "episode": 25.0, "batch_reward": 0.3775199865102768, "critic_loss": 0.7212579674124717, "actor_loss": -42.70499865722656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.125673294067383, "step": 25000}
{"episode_reward": 451.6694677523709, "episode": 26.0, "batch_reward": 0.38120585307478905, "critic_loss": 0.7087924187481404, "actor_loss": -42.61622270202637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.130027055740356, "step": 26000}
{"episode_reward": 504.1838654310825, "episode": 27.0, "batch_reward": 0.38456580752134323, "critic_loss": 0.7146417411863804, "actor_loss": -43.0390643081665, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.127493858337402, "step": 27000}
{"episode_reward": 422.64067377759966, "episode": 28.0, "batch_reward": 0.38516702657938, "critic_loss": 0.7756587020158767, "actor_loss": -42.72791688919067, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.136899948120117, "step": 28000}
{"episode_reward": 412.66214131477386, "episode": 29.0, "batch_reward": 0.3877253296673298, "critic_loss": 0.7223594040572643, "actor_loss": -42.98287306213379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.121213912963867, "step": 29000}
{"episode_reward": 441.8242211485334, "episode": 30.0, "batch_reward": 0.38882191291451457, "critic_loss": 0.7957520590722561, "actor_loss": -42.60364663696289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.121187686920166, "step": 30000}
{"episode_reward": 411.04442640483376, "episode": 31.0, "batch_reward": 0.3894574548006058, "critic_loss": 0.7577131874263286, "actor_loss": -43.07671798706055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.37768864631653, "step": 31000}
{"episode_reward": 466.03978242872967, "episode": 32.0, "batch_reward": 0.392779834061861, "critic_loss": 0.7470259099304676, "actor_loss": -43.501926040649415, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12555980682373, "step": 32000}
{"episode_reward": 452.56416253369974, "episode": 33.0, "batch_reward": 0.39515818828344346, "critic_loss": 0.7455054070055485, "actor_loss": -43.55565554046631, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.118799924850464, "step": 33000}
{"episode_reward": 461.5277858046833, "episode": 34.0, "batch_reward": 0.3957451523542404, "critic_loss": 0.8428215160667897, "actor_loss": -43.632722633361816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.124314308166504, "step": 34000}
{"episode_reward": 394.67667143342743, "episode": 35.0, "batch_reward": 0.3965414414405823, "critic_loss": 0.8343037346601486, "actor_loss": -43.59344738006592, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.128220796585083, "step": 35000}
{"episode_reward": 447.03532824644645, "episode": 36.0, "batch_reward": 0.3978365169465542, "critic_loss": 0.894367514282465, "actor_loss": -43.900642944335935, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.121994256973267, "step": 36000}
{"episode_reward": 373.91804560353944, "episode": 37.0, "batch_reward": 0.39677187204360964, "critic_loss": 0.9001745707094669, "actor_loss": -43.4152546043396, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.130124807357788, "step": 37000}
{"episode_reward": 476.50279710709066, "episode": 38.0, "batch_reward": 0.40016599726676944, "critic_loss": 0.8926230996847153, "actor_loss": -43.4470030670166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.123443603515625, "step": 38000}
{"episode_reward": 477.26380153729536, "episode": 39.0, "batch_reward": 0.40128131371736525, "critic_loss": 0.919875684440136, "actor_loss": -43.4641541519165, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.131313800811768, "step": 39000}
{"episode_reward": 450.6556964746769, "episode": 40.0, "batch_reward": 0.40310872679948806, "critic_loss": 0.8821397139728069, "actor_loss": -43.97705376434326, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.126196146011353, "step": 40000}
{"episode_reward": 480.14791716675444, "episode": 41.0, "batch_reward": 0.40515361273288725, "critic_loss": 0.8947162018716335, "actor_loss": -43.91254086303711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.352261781692505, "step": 41000}
{"episode_reward": 488.2756168809067, "episode": 42.0, "batch_reward": 0.407144692659378, "critic_loss": 0.8610304479002953, "actor_loss": -44.04837173461914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.127423524856567, "step": 42000}
{"episode_reward": 474.9851500642826, "episode": 43.0, "batch_reward": 0.40801061859726906, "critic_loss": 0.8522601429522038, "actor_loss": -44.192235122680664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.129084825515747, "step": 43000}
{"episode_reward": 473.1924514226691, "episode": 44.0, "batch_reward": 0.4097285001277924, "critic_loss": 0.886238835811615, "actor_loss": -45.02109587860107, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.123891592025757, "step": 44000}
{"episode_reward": 466.40126632668387, "episode": 45.0, "batch_reward": 0.41091480147838594, "critic_loss": 0.9009929488301277, "actor_loss": -44.49753954315185, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.135406970977783, "step": 45000}
{"episode_reward": 466.388855703647, "episode": 46.0, "batch_reward": 0.4120358974337578, "critic_loss": 0.8769445112943649, "actor_loss": -44.06440562438965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.129144430160522, "step": 46000}
{"episode_reward": 509.3478395841195, "episode": 47.0, "batch_reward": 0.414293810158968, "critic_loss": 0.8885806978940963, "actor_loss": -44.49295658111572, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.131432056427002, "step": 47000}
{"episode_reward": 471.727356722533, "episode": 48.0, "batch_reward": 0.4155912399291992, "critic_loss": 0.8446599211990833, "actor_loss": -44.417568031311035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12722873687744, "step": 48000}
{"episode_reward": 489.2812298426948, "episode": 49.0, "batch_reward": 0.41583709153532983, "critic_loss": 0.8962448710799217, "actor_loss": -45.026720611572266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.128014087677002, "step": 49000}
{"episode_reward": 442.96857611857405, "episode": 50.0, "batch_reward": 0.4179209239780903, "critic_loss": 0.913588773548603, "actor_loss": -44.89846852111816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12438941001892, "step": 50000}
{"episode_reward": 475.67931315197427, "episode": 51.0, "batch_reward": 0.41908909115195275, "critic_loss": 0.8906852786242961, "actor_loss": -44.889764511108396, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.36395740509033, "step": 51000}
{"episode_reward": 461.46994124108085, "episode": 52.0, "batch_reward": 0.4195974221229553, "critic_loss": 0.8786058961451053, "actor_loss": -44.638872127532956, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.129912614822388, "step": 52000}
{"episode_reward": 527.1740143565826, "episode": 53.0, "batch_reward": 0.42163162112236025, "critic_loss": 0.8878337351977825, "actor_loss": -45.21537766265869, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.127843141555786, "step": 53000}
{"episode_reward": 469.1727996869678, "episode": 54.0, "batch_reward": 0.4223031548559666, "critic_loss": 0.9530902197659016, "actor_loss": -45.394523735046384, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.130570650100708, "step": 54000}
{"episode_reward": 451.17791459320637, "episode": 55.0, "batch_reward": 0.4229673582911491, "critic_loss": 0.9353583725094795, "actor_loss": -45.24840579986572, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.123141765594482, "step": 55000}
{"episode_reward": 447.1908569066035, "episode": 56.0, "batch_reward": 0.42283903911709786, "critic_loss": 0.9584111969470978, "actor_loss": -45.22322737121582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13670563697815, "step": 56000}
{"episode_reward": 445.6507548959552, "episode": 57.0, "batch_reward": 0.42474577492475507, "critic_loss": 0.9953365922570229, "actor_loss": -45.36550553131104, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14633059501648, "step": 57000}
{"episode_reward": 476.75209827966603, "episode": 58.0, "batch_reward": 0.4244901048541069, "critic_loss": 0.9966379123032093, "actor_loss": -45.456776176452635, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.142290115356445, "step": 58000}
{"episode_reward": 459.40304903528187, "episode": 59.0, "batch_reward": 0.4251903880536556, "critic_loss": 0.9643853623270988, "actor_loss": -45.380382133483884, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.132346153259277, "step": 59000}
{"episode_reward": 362.4730199108953, "episode": 60.0, "batch_reward": 0.4246835018694401, "critic_loss": 0.980833659440279, "actor_loss": -45.38635008239746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12812304496765, "step": 60000}
{"episode_reward": 482.4678713335527, "episode": 61.0, "batch_reward": 0.42577271950244905, "critic_loss": 0.916901222974062, "actor_loss": -45.38377081298828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.38465452194214, "step": 61000}
{"episode_reward": 487.7569305498667, "episode": 62.0, "batch_reward": 0.4257889912426472, "critic_loss": 0.9282951086759568, "actor_loss": -45.35969401550293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14425015449524, "step": 62000}
{"episode_reward": 337.0139262633605, "episode": 63.0, "batch_reward": 0.42445711439847944, "critic_loss": 0.8967350731492043, "actor_loss": -45.32254133605957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.139617681503296, "step": 63000}
{"episode_reward": 472.1750516810792, "episode": 64.0, "batch_reward": 0.42594028094410896, "critic_loss": 0.921119855850935, "actor_loss": -45.661783531188966, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.128479719161987, "step": 64000}
{"episode_reward": 459.6640074374261, "episode": 65.0, "batch_reward": 0.4257010961174965, "critic_loss": 0.9174635887742043, "actor_loss": -45.36153799438477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13365864753723, "step": 65000}
{"episode_reward": 469.2403632373115, "episode": 66.0, "batch_reward": 0.42752261382341383, "critic_loss": 0.8975373775959015, "actor_loss": -45.37138051605225, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13805890083313, "step": 66000}
{"episode_reward": 501.53303942261584, "episode": 67.0, "batch_reward": 0.42795254749059675, "critic_loss": 0.9157209748029709, "actor_loss": -45.83810366821289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.135624408721924, "step": 67000}
{"episode_reward": 487.91813556180244, "episode": 68.0, "batch_reward": 0.4297283007800579, "critic_loss": 0.9052960159480572, "actor_loss": -46.22996109008789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.136090755462646, "step": 68000}
{"episode_reward": 492.62747411337034, "episode": 69.0, "batch_reward": 0.4295154022276402, "critic_loss": 0.8948102053403855, "actor_loss": -45.44048107147217, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.138264656066895, "step": 69000}
{"episode_reward": 478.63521061646765, "episode": 70.0, "batch_reward": 0.4301390146613121, "critic_loss": 0.8856494075655937, "actor_loss": -45.57992520904541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.135066032409668, "step": 70000}
{"episode_reward": 381.4721773530262, "episode": 71.0, "batch_reward": 0.43023485532402994, "critic_loss": 0.8686701989769936, "actor_loss": -45.473324378967284, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.40076947212219, "step": 71000}
{"episode_reward": 505.60457401980574, "episode": 72.0, "batch_reward": 0.4309619466662407, "critic_loss": 0.8694674436151981, "actor_loss": -45.97706246185303, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.135151386260986, "step": 72000}
{"episode_reward": 516.4153193554479, "episode": 73.0, "batch_reward": 0.43209826144576075, "critic_loss": 0.9112953080236912, "actor_loss": -46.149740417480466, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13492202758789, "step": 73000}
{"episode_reward": 447.73775315179466, "episode": 74.0, "batch_reward": 0.43184167504310605, "critic_loss": 0.8550349207222462, "actor_loss": -45.77431191253662, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13043999671936, "step": 74000}
{"episode_reward": 494.3611027740982, "episode": 75.0, "batch_reward": 0.43340846106410025, "critic_loss": 0.8053033184409142, "actor_loss": -45.87900727844238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.128352403640747, "step": 75000}
{"episode_reward": 488.48010116734764, "episode": 76.0, "batch_reward": 0.4337857522070408, "critic_loss": 0.7959882088303566, "actor_loss": -46.153692474365236, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1350200176239, "step": 76000}
{"episode_reward": 450.9891861438974, "episode": 77.0, "batch_reward": 0.4339602748155594, "critic_loss": 0.848976972490549, "actor_loss": -45.99806513977051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.139002799987793, "step": 77000}
{"episode_reward": 488.8501771050727, "episode": 78.0, "batch_reward": 0.4346534210443497, "critic_loss": 0.8378914827108384, "actor_loss": -46.26475060272217, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.147650480270386, "step": 78000}
{"episode_reward": 492.0006774761633, "episode": 79.0, "batch_reward": 0.4360149471461773, "critic_loss": 0.8629417187273503, "actor_loss": -46.685893615722655, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.128812789916992, "step": 79000}
{"episode_reward": 455.6442313899956, "episode": 80.0, "batch_reward": 0.43580090075731276, "critic_loss": 0.8294148509800434, "actor_loss": -46.427211769104005, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.133195161819458, "step": 80000}
{"episode_reward": 489.0615941693158, "episode": 81.0, "batch_reward": 0.43684228307008743, "critic_loss": 0.8597813635468483, "actor_loss": -46.08338436126709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.393356800079346, "step": 81000}
{"episode_reward": 466.1527050884189, "episode": 82.0, "batch_reward": 0.43648687124252317, "critic_loss": 0.817951403349638, "actor_loss": -46.22312683868408, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.147583961486816, "step": 82000}
{"episode_reward": 512.1716082308922, "episode": 83.0, "batch_reward": 0.43707535982131956, "critic_loss": 0.8726985111236573, "actor_loss": -46.39696305847168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.133780241012573, "step": 83000}
{"episode_reward": 357.12247915316584, "episode": 84.0, "batch_reward": 0.4367104876041412, "critic_loss": 0.8044605538845062, "actor_loss": -46.581644706726074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13820481300354, "step": 84000}
{"episode_reward": 465.0762936320915, "episode": 85.0, "batch_reward": 0.43734911623597145, "critic_loss": 0.7710941299796105, "actor_loss": -46.52595320892334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13036322593689, "step": 85000}
{"episode_reward": 487.4548396443229, "episode": 86.0, "batch_reward": 0.43748111322522165, "critic_loss": 0.8007813224196434, "actor_loss": -46.44288567352295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.143054008483887, "step": 86000}
{"episode_reward": 464.2344565770135, "episode": 87.0, "batch_reward": 0.4375905638039112, "critic_loss": 0.7910766933560371, "actor_loss": -46.627833694458005, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.138574600219727, "step": 87000}
{"episode_reward": 428.16114305208987, "episode": 88.0, "batch_reward": 0.4379810854792595, "critic_loss": 0.755681922763586, "actor_loss": -46.303423301696775, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.140428066253662, "step": 88000}
{"episode_reward": 409.59223384886906, "episode": 89.0, "batch_reward": 0.4373189698755741, "critic_loss": 0.8078353788554669, "actor_loss": -46.4719902267456, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13684606552124, "step": 89000}
{"episode_reward": 472.4270403042566, "episode": 90.0, "batch_reward": 0.4386925055086613, "critic_loss": 0.7771051754057408, "actor_loss": -46.41043404388428, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.132786989212036, "step": 90000}
{"episode_reward": 482.5351888610006, "episode": 91.0, "batch_reward": 0.4381666340827942, "critic_loss": 0.7851360968649387, "actor_loss": -46.399086845397946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.38559341430664, "step": 91000}
{"episode_reward": 490.0733321250435, "episode": 92.0, "batch_reward": 0.4387278654575348, "critic_loss": 0.7918550879955292, "actor_loss": -46.84045212554932, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.132652759552002, "step": 92000}
{"episode_reward": 487.3516911421013, "episode": 93.0, "batch_reward": 0.4395281796455383, "critic_loss": 0.8147779678702355, "actor_loss": -46.401437736511234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13833713531494, "step": 93000}
{"episode_reward": 337.01323443857683, "episode": 94.0, "batch_reward": 0.4378095581829548, "critic_loss": 0.7936598220467568, "actor_loss": -46.479157852172854, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.132588863372803, "step": 94000}
{"episode_reward": 466.46228912105516, "episode": 95.0, "batch_reward": 0.43833478769659995, "critic_loss": 0.8528578237891197, "actor_loss": -46.75879495239258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13666033744812, "step": 95000}
{"episode_reward": 458.00660974652595, "episode": 96.0, "batch_reward": 0.4397092470228672, "critic_loss": 0.8543503686785698, "actor_loss": -46.79880216979981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.132169485092163, "step": 96000}
{"episode_reward": 469.4379302349069, "episode": 97.0, "batch_reward": 0.43896710604429245, "critic_loss": 0.8018750922679901, "actor_loss": -46.5612414855957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.138686180114746, "step": 97000}
{"episode_reward": 494.71351678842325, "episode": 98.0, "batch_reward": 0.43941103798151016, "critic_loss": 0.8090924959480762, "actor_loss": -46.87969291687012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14246654510498, "step": 98000}
{"episode_reward": 475.66782147253355, "episode": 99.0, "batch_reward": 0.44017378959059716, "critic_loss": 0.803183156400919, "actor_loss": -46.55710031890869, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13359785079956, "step": 99000}
{"episode_reward": 487.19513524704496, "episode": 100.0, "batch_reward": 0.4408084836900234, "critic_loss": 0.8125589762628078, "actor_loss": -46.90949299621582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.144762754440308, "step": 100000}
{"episode_reward": 483.84689663206547, "episode": 101.0, "batch_reward": 0.44134625542163847, "critic_loss": 0.781951534718275, "actor_loss": -46.48471315765381, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.387120485305786, "step": 101000}
{"episode_reward": 513.6242489297287, "episode": 102.0, "batch_reward": 0.44186464038491247, "critic_loss": 0.7404430318772793, "actor_loss": -46.89198666381836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.135979652404785, "step": 102000}
{"episode_reward": 467.94175013140574, "episode": 103.0, "batch_reward": 0.44201557290554044, "critic_loss": 0.8096752941906452, "actor_loss": -46.55033261108399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.139698266983032, "step": 103000}
{"episode_reward": 544.8242088076771, "episode": 104.0, "batch_reward": 0.44301215836405755, "critic_loss": 0.8185119132995605, "actor_loss": -46.60931079101562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13150906562805, "step": 104000}
{"episode_reward": 466.93053940992803, "episode": 105.0, "batch_reward": 0.44306215968728063, "critic_loss": 0.8551323937773705, "actor_loss": -46.784813438415526, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14562702178955, "step": 105000}
{"episode_reward": 474.4821467977073, "episode": 106.0, "batch_reward": 0.44336694034934043, "critic_loss": 0.846252722144127, "actor_loss": -46.843998046875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13769817352295, "step": 106000}
{"episode_reward": 470.82266795618483, "episode": 107.0, "batch_reward": 0.4433769076168537, "critic_loss": 0.8386799615323544, "actor_loss": -46.570058044433594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.141523122787476, "step": 107000}
{"episode_reward": 509.9654222098853, "episode": 108.0, "batch_reward": 0.44439854407310486, "critic_loss": 0.8365863915979862, "actor_loss": -47.13193199920654, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.148014068603516, "step": 108000}
{"episode_reward": 483.33391231242337, "episode": 109.0, "batch_reward": 0.4456000052094459, "critic_loss": 0.8107149648368359, "actor_loss": -46.99840850067139, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.135851621627808, "step": 109000}
{"episode_reward": 491.1288409146903, "episode": 110.0, "batch_reward": 0.44474533560872076, "critic_loss": 0.8722804332375527, "actor_loss": -47.40084790039062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13492488861084, "step": 110000}
{"episode_reward": 473.02699139296533, "episode": 111.0, "batch_reward": 0.445576624840498, "critic_loss": 0.8421905421316623, "actor_loss": -47.043883033752444, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.38416290283203, "step": 111000}
{"episode_reward": 513.0943128584067, "episode": 112.0, "batch_reward": 0.4454663000404835, "critic_loss": 0.8474030682146549, "actor_loss": -47.10178211212158, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.148791790008545, "step": 112000}
{"episode_reward": 514.2983966206455, "episode": 113.0, "batch_reward": 0.4472775091528893, "critic_loss": 0.8461038991510869, "actor_loss": -47.163795349121095, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.141111135482788, "step": 113000}
{"episode_reward": 502.71325313240203, "episode": 114.0, "batch_reward": 0.4473947833776474, "critic_loss": 0.8192153518795967, "actor_loss": -47.438659385681156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1860933303833, "step": 114000}
{"episode_reward": 482.2980001891796, "episode": 115.0, "batch_reward": 0.4474812785387039, "critic_loss": 0.8113718610703945, "actor_loss": -47.370783874511716, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.405686140060425, "step": 115000}
{"episode_reward": 477.81868703321265, "episode": 116.0, "batch_reward": 0.44742395904660226, "critic_loss": 0.7867832868993282, "actor_loss": -47.39812863922119, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.115859031677246, "step": 116000}
{"episode_reward": 492.9930404312511, "episode": 117.0, "batch_reward": 0.4485827324986458, "critic_loss": 0.7998698113262653, "actor_loss": -47.19397485351563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.107855081558228, "step": 117000}
{"episode_reward": 495.66173640300985, "episode": 118.0, "batch_reward": 0.44866751590371134, "critic_loss": 0.8336955147087574, "actor_loss": -47.36834484100342, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12253475189209, "step": 118000}
{"episode_reward": 473.7075420562124, "episode": 119.0, "batch_reward": 0.4492595325112343, "critic_loss": 0.7978716533482074, "actor_loss": -47.543030700683595, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.459917306900024, "step": 119000}
{"episode_reward": 502.2545519007587, "episode": 120.0, "batch_reward": 0.44961840456724167, "critic_loss": 0.8155005879402161, "actor_loss": -47.16299501037598, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.128937005996704, "step": 120000}
{"episode_reward": 509.23437662526555, "episode": 121.0, "batch_reward": 0.45005226773023604, "critic_loss": 0.7484563712477684, "actor_loss": -47.493993591308595, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.37050747871399, "step": 121000}
{"episode_reward": 485.53585971577576, "episode": 122.0, "batch_reward": 0.45039397150278093, "critic_loss": 0.7520455967783928, "actor_loss": -47.730578575134274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.149054527282715, "step": 122000}
{"episode_reward": 494.61143544491796, "episode": 123.0, "batch_reward": 0.4505027663707733, "critic_loss": 0.8001382962763309, "actor_loss": -47.89166136932373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.144975900650024, "step": 123000}
{"episode_reward": 493.19661300238687, "episode": 124.0, "batch_reward": 0.44986456590890883, "critic_loss": 0.8261777559816837, "actor_loss": -47.63727138519287, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1399986743927, "step": 124000}
{"episode_reward": 468.56167606325045, "episode": 125.0, "batch_reward": 0.45046671053767207, "critic_loss": 0.8100440055727959, "actor_loss": -47.63525518798828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.147594690322876, "step": 125000}
{"episode_reward": 502.0824095967867, "episode": 126.0, "batch_reward": 0.4509018698036671, "critic_loss": 0.7914543891251087, "actor_loss": -47.90649082946777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14674210548401, "step": 126000}
{"episode_reward": 453.3365096949612, "episode": 127.0, "batch_reward": 0.4506300759613514, "critic_loss": 0.7945351520776749, "actor_loss": -47.73031526947022, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14737582206726, "step": 127000}
{"episode_reward": 482.7062960833463, "episode": 128.0, "batch_reward": 0.4517552527487278, "critic_loss": 0.7894277466833591, "actor_loss": -47.60821006011963, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.148243188858032, "step": 128000}
{"episode_reward": 466.14812766051693, "episode": 129.0, "batch_reward": 0.45200052031874655, "critic_loss": 0.7691694717109203, "actor_loss": -47.83846913909912, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13664984703064, "step": 129000}
{"episode_reward": 464.4340344677204, "episode": 130.0, "batch_reward": 0.4516491510272026, "critic_loss": 0.7992851393520832, "actor_loss": -47.95659773254395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.148451328277588, "step": 130000}
{"episode_reward": 494.97392200995347, "episode": 131.0, "batch_reward": 0.45229610151052474, "critic_loss": 0.8188591609299183, "actor_loss": -47.39827162933349, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.40027976036072, "step": 131000}
{"episode_reward": 497.45088967836733, "episode": 132.0, "batch_reward": 0.4524149489402771, "critic_loss": 0.7812704230844975, "actor_loss": -48.13690691375732, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13744282722473, "step": 132000}
{"episode_reward": 471.70750291959206, "episode": 133.0, "batch_reward": 0.4530788383483887, "critic_loss": 0.8040133488178253, "actor_loss": -47.68851170349121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14905571937561, "step": 133000}
{"episode_reward": 515.8875858980533, "episode": 134.0, "batch_reward": 0.45253403759002686, "critic_loss": 0.8052222759723663, "actor_loss": -47.94994805145264, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14708399772644, "step": 134000}
{"episode_reward": 481.3135607313091, "episode": 135.0, "batch_reward": 0.4530315478742123, "critic_loss": 0.8185422447025776, "actor_loss": -48.084818389892575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.146896839141846, "step": 135000}
{"episode_reward": 470.3878447900954, "episode": 136.0, "batch_reward": 0.45318481719493864, "critic_loss": 0.7919608985185623, "actor_loss": -47.89475054168701, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15491008758545, "step": 136000}
{"episode_reward": 466.83396437612674, "episode": 137.0, "batch_reward": 0.4533970000743866, "critic_loss": 0.8047111048698425, "actor_loss": -48.11748289489746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.146129369735718, "step": 137000}
{"episode_reward": 479.4531024644656, "episode": 138.0, "batch_reward": 0.45358053398132325, "critic_loss": 0.8026136565208435, "actor_loss": -48.37963092803955, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.149667978286743, "step": 138000}
{"episode_reward": 442.5338049621073, "episode": 139.0, "batch_reward": 0.4535966682434082, "critic_loss": 0.8171709511578084, "actor_loss": -47.83699074554443, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15560221672058, "step": 139000}
{"episode_reward": 463.11187959749265, "episode": 140.0, "batch_reward": 0.4531705087125301, "critic_loss": 0.85678430300951, "actor_loss": -48.24358172607422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.144752502441406, "step": 140000}
{"episode_reward": 439.32730778075614, "episode": 141.0, "batch_reward": 0.45391937425732615, "critic_loss": 0.8487213024795055, "actor_loss": -48.03658757781982, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.3909957408905, "step": 141000}
{"episode_reward": 469.2983425162613, "episode": 142.0, "batch_reward": 0.45258468225598336, "critic_loss": 0.8465683333277703, "actor_loss": -47.93241168212891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.142122268676758, "step": 142000}
{"episode_reward": 160.25734230689977, "episode": 143.0, "batch_reward": 0.4516975818872452, "critic_loss": 0.8327829561531543, "actor_loss": -47.90269519042969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.142717361450195, "step": 143000}
{"episode_reward": 472.0659091509555, "episode": 144.0, "batch_reward": 0.4512607229053974, "critic_loss": 0.8477338836193085, "actor_loss": -47.996620697021484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.459599018096924, "step": 144000}
{"episode_reward": 464.5482722219817, "episode": 145.0, "batch_reward": 0.4521910214722156, "critic_loss": 0.88098286819458, "actor_loss": -48.001444793701175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.135784149169922, "step": 145000}
{"episode_reward": 456.38864205464705, "episode": 146.0, "batch_reward": 0.451778787702322, "critic_loss": 0.8848980971574784, "actor_loss": -47.61247359466553, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.125315189361572, "step": 146000}
{"episode_reward": 501.8990754980804, "episode": 147.0, "batch_reward": 0.45190259954333306, "critic_loss": 0.8523794290721416, "actor_loss": -47.8564778137207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.135468006134033, "step": 147000}
{"episode_reward": 506.7366236862336, "episode": 148.0, "batch_reward": 0.4529658677279949, "critic_loss": 0.8257301578819751, "actor_loss": -47.86599056243897, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14432406425476, "step": 148000}
{"episode_reward": 490.4575598861678, "episode": 149.0, "batch_reward": 0.4531802258193493, "critic_loss": 0.8211635032594204, "actor_loss": -48.07213050842285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.144315481185913, "step": 149000}
{"episode_reward": 499.8337667346072, "episode": 150.0, "batch_reward": 0.4526362818479538, "critic_loss": 0.8711865929663182, "actor_loss": -48.19909791564941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
