{"episode": 1.0, "duration": 18.310085773468018, "episode_reward": 7.051849146674556, "step": 1000}
{"episode": 2.0, "duration": 1.5851750373840332, "episode_reward": 365.4711839680396, "step": 2000}
{"episode": 3.0, "batch_reward": 0.183214707965253, "actor_loss": -35.921832365148205, "actor_target_entropy": -6.0, "alpha_value": 0.01377813086574139, "duration": 53.193519830703735, "episode_reward": 146.38433527683839, "step": 3000}
{"episode": 4.0, "batch_reward": 0.17292676018178463, "actor_loss": -34.73471450805664, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.564236164093018, "episode_reward": 185.92348817742, "step": 4000}
{"episode": 5.0, "batch_reward": 0.1807300883680582, "actor_loss": -34.824362037658695, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.80742883682251, "episode_reward": 209.34611875669137, "step": 5000}
{"episode": 6.0, "batch_reward": 0.1809334874600172, "actor_loss": -34.66160326385498, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.462589979171753, "episode_reward": 183.20666597504822, "step": 6000}
{"episode": 7.0, "batch_reward": 0.18337022604048253, "actor_loss": -34.677992332458494, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.473471641540527, "episode_reward": 196.9049690675923, "step": 7000}
{"episode": 8.0, "batch_reward": 0.18429672513902187, "actor_loss": -34.701367561340334, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.195791482925415, "episode_reward": 182.26046274096933, "step": 8000}
{"episode": 9.0, "batch_reward": 0.18391869600117206, "actor_loss": -34.684424163818356, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.031442642211914, "episode_reward": 177.49424456736784, "step": 9000}
{"episode": 10.0, "batch_reward": 0.18502091446518898, "actor_loss": -29.57781164550781, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 3978.2291457653046, "episode_reward": 199.76087509012248, "step": 10000}
{"episode": 11.0, "batch_reward": 0.19237671694159508, "actor_loss": -30.041787631988527, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.79629039764404, "episode_reward": 332.2720423709105, "step": 11000}
{"episode": 12.0, "batch_reward": 0.20199366465210913, "actor_loss": -27.40882689666748, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 436.4219181537628, "episode_reward": 295.9123614460816, "step": 12000}
{"episode": 13.0, "batch_reward": 0.21170985612273216, "actor_loss": -28.056073093414305, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.592561721801758, "episode_reward": 347.0575585566911, "step": 13000}
{"episode": 14.0, "batch_reward": 0.22102316857874393, "actor_loss": -26.198038276672364, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 430.3545699119568, "episode_reward": 338.8362803170454, "step": 14000}
{"episode": 15.0, "batch_reward": 0.22974129313230515, "actor_loss": -26.829418273925782, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 15.54300594329834, "episode_reward": 341.6599779872724, "step": 15000}
{"episode": 16.0, "batch_reward": 0.23803817607462407, "actor_loss": -24.809932415008547, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 420.52077651023865, "episode_reward": 358.7758645038326, "step": 16000}
{"episode": 17.0, "batch_reward": 0.2438227635771036, "actor_loss": -25.23868264389038, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.886672258377075, "episode_reward": 312.68866275266964, "step": 17000}
{"episode": 18.0, "batch_reward": 0.24653065237402916, "actor_loss": -23.21559046936035, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 429.82832288742065, "episode_reward": 262.4182816380573, "step": 18000}
{"episode": 19.0, "batch_reward": 0.24922268930077554, "actor_loss": -23.471495429992675, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.448244333267212, "episode_reward": 371.7198145706578, "step": 19000}
{"episode": 20.0, "batch_reward": 0.2552293292135, "actor_loss": -22.422608715057372, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 438.81713032722473, "episode_reward": 341.15258750006586, "step": 20000}
{"episode": 21.0, "batch_reward": 0.2602386039942503, "actor_loss": -22.855838722229002, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.71643280982971, "episode_reward": 346.5536614796962, "step": 21000}
{"episode": 22.0, "batch_reward": 0.26338011398911476, "actor_loss": -21.604642177581788, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 431.5230805873871, "episode_reward": 327.1857025225954, "step": 22000}
{"episode": 23.0, "batch_reward": 0.2679940626621246, "actor_loss": -22.013007610321043, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.504942178726196, "episode_reward": 394.34849313185686, "step": 23000}
{"episode": 24.0, "batch_reward": 0.2736054648309946, "actor_loss": -21.3045615234375, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 413.8794438838959, "episode_reward": 392.10773836342645, "step": 24000}
{"episode": 25.0, "batch_reward": 0.27722579984366896, "actor_loss": -21.669667457580566, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.435943365097046, "episode_reward": 393.7506595207182, "step": 25000}
{"episode": 26.0, "batch_reward": 0.2826501157283783, "actor_loss": -20.87987317276001, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 407.0804409980774, "episode_reward": 416.732848647951, "step": 26000}
{"episode": 27.0, "batch_reward": 0.28631723305583, "actor_loss": -21.247718185424805, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.38451385498047, "episode_reward": 367.8117199185688, "step": 27000}
{"episode": 28.0, "batch_reward": 0.2884075649082661, "actor_loss": -20.608728717803956, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 405.9752399921417, "episode_reward": 352.7929696294878, "step": 28000}
{"episode": 29.0, "batch_reward": 0.29247936576604844, "actor_loss": -20.935992332458497, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.61761975288391, "episode_reward": 386.0655888899861, "step": 29000}
{"episode": 30.0, "batch_reward": 0.29442065373063087, "actor_loss": -20.26432838821411, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 415.35043573379517, "episode_reward": 345.8819269350376, "step": 30000}
{"episode": 31.0, "batch_reward": 0.2962629099488258, "actor_loss": -20.370802337646484, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.55566883087158, "episode_reward": 340.02752989361653, "step": 31000}
{"episode": 32.0, "batch_reward": 0.29825396940112114, "actor_loss": -19.54524462890625, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 434.46449971199036, "episode_reward": 374.72094385999526, "step": 32000}
{"episode": 33.0, "batch_reward": 0.3007781054675579, "actor_loss": -19.711289768218993, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.919129848480225, "episode_reward": 390.0356135291509, "step": 33000}
{"episode": 34.0, "batch_reward": 0.3032373504936695, "actor_loss": -19.35888766860962, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 438.7100102901459, "episode_reward": 375.2627611183205, "step": 34000}
{"episode": 35.0, "batch_reward": 0.3036027189791203, "actor_loss": -19.403354034423828, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.03142523765564, "episode_reward": 274.64470002834327, "step": 35000}
{"episode": 36.0, "batch_reward": 0.30273797816038134, "actor_loss": -18.635621240615844, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 437.1450309753418, "episode_reward": 294.8844409190123, "step": 36000}
{"episode": 37.0, "batch_reward": 0.30210086214542387, "actor_loss": -18.568720417022703, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.828514337539673, "episode_reward": 270.15205236075394, "step": 37000}
{"episode": 38.0, "batch_reward": 0.3026955141425133, "actor_loss": -18.336619480133056, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 435.9088251590729, "episode_reward": 370.3270301556032, "step": 38000}
{"episode": 39.0, "batch_reward": 0.3049858403205872, "actor_loss": -18.590108772277834, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.115883111953735, "episode_reward": 372.70971859900754, "step": 39000}
{"episode": 40.0, "batch_reward": 0.3070873251259327, "actor_loss": -18.375017055511474, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 440.8032457828522, "episode_reward": 369.5255048451248, "step": 40000}
{"episode": 41.0, "batch_reward": 0.3079492435157299, "actor_loss": -18.364677688598633, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.62932014465332, "episode_reward": 344.8099461903409, "step": 41000}
{"episode": 42.0, "batch_reward": 0.30886479011178014, "actor_loss": -18.303879581451415, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 423.1910095214844, "episode_reward": 335.97427076732555, "step": 42000}
{"episode": 43.0, "batch_reward": 0.3082556182742119, "actor_loss": -18.23905849838257, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.8957998752594, "episode_reward": 257.7017041407343, "step": 43000}
{"episode": 44.0, "batch_reward": 0.3092429993748665, "actor_loss": -18.268519309997558, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 439.09407925605774, "episode_reward": 389.36630223318224, "step": 44000}
{"episode": 45.0, "batch_reward": 0.310455220580101, "actor_loss": -18.356697423934936, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.89569091796875, "episode_reward": 374.2219724166382, "step": 45000}
{"episode": 46.0, "batch_reward": 0.3124434947371483, "actor_loss": -18.522780235290526, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 441.3961400985718, "episode_reward": 380.50186786522244, "step": 46000}
{"episode": 47.0, "batch_reward": 0.31323248594999314, "actor_loss": -18.609852230072022, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.0508234500885, "episode_reward": 372.2098879963439, "step": 47000}
{"episode": 48.0, "batch_reward": 0.3145891697108746, "actor_loss": -18.389542392730714, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 434.45711064338684, "episode_reward": 364.1673132867743, "step": 48000}
{"episode": 49.0, "batch_reward": 0.31556088185310366, "actor_loss": -18.48995149230957, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.205034971237183, "episode_reward": 373.71751642102225, "step": 49000}
{"episode": 50.0, "batch_reward": 0.31643304285407065, "actor_loss": -18.109941255569456, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 440.7293927669525, "episode_reward": 334.96451131356815, "step": 50000}
{"episode": 51.0, "batch_reward": 0.3168585423231125, "actor_loss": -18.071651151657104, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.71354675292969, "episode_reward": 352.4044296666641, "step": 51000}
{"episode": 52.0, "batch_reward": 0.3158718612790108, "actor_loss": -18.635068729400636, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 434.9555540084839, "episode_reward": 283.48471459865846, "step": 52000}
{"episode": 53.0, "batch_reward": 0.3174609519541264, "actor_loss": -18.68184201049805, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.472168684005737, "episode_reward": 358.95167443559353, "step": 53000}
{"episode": 54.0, "batch_reward": 0.3183004787266254, "actor_loss": -18.583551147460938, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 412.69357228279114, "episode_reward": 404.6344993538065, "step": 54000}
{"episode": 55.0, "batch_reward": 0.3196963346898556, "actor_loss": -18.683735885620116, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.302144289016724, "episode_reward": 392.6287016302787, "step": 55000}
{"episode": 56.0, "batch_reward": 0.31982235208153725, "actor_loss": -17.982291107177733, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 441.2610330581665, "episode_reward": 334.2825666751983, "step": 56000}
{"episode": 57.0, "batch_reward": 0.3207946788072586, "actor_loss": -18.076864517211913, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.02825951576233, "episode_reward": 353.2124185597446, "step": 57000}
{"episode": 58.0, "batch_reward": 0.321710559040308, "actor_loss": -17.971681732177736, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 439.86952352523804, "episode_reward": 384.2403202811744, "step": 58000}
{"episode": 59.0, "batch_reward": 0.32102168115973473, "actor_loss": -17.9556121635437, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.929033517837524, "episode_reward": 291.8383432934764, "step": 59000}
{"episode": 60.0, "batch_reward": 0.3225983016192913, "actor_loss": -18.2968306388855, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 432.6328730583191, "episode_reward": 375.36893515791746, "step": 60000}
{"episode": 61.0, "batch_reward": 0.3211182580292225, "actor_loss": -18.25280420303345, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 34.282551527023315, "episode_reward": 286.04203602411513, "step": 61000}
{"episode": 62.0, "batch_reward": 0.3200575492680073, "actor_loss": -17.83023502922058, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 441.106910943985, "episode_reward": 183.03003401801885, "step": 62000}
{"episode": 63.0, "batch_reward": 0.32012260174751284, "actor_loss": -17.829163955688475, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.037025690078735, "episode_reward": 373.87099125369946, "step": 63000}
{"episode": 64.0, "batch_reward": 0.321035214304924, "actor_loss": -18.054831132888793, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 438.62080216407776, "episode_reward": 377.0667900993738, "step": 64000}
{"episode": 65.0, "batch_reward": 0.32136816185712813, "actor_loss": -18.04661884689331, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.162015199661255, "episode_reward": 355.059076729467, "step": 65000}
{"episode": 66.0, "batch_reward": 0.3212923454046249, "actor_loss": -18.163675086975097, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 431.6286518573761, "episode_reward": 266.85650341414083, "step": 66000}
{"episode": 67.0, "batch_reward": 0.320540856808424, "actor_loss": -18.161967418670653, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.827671766281128, "episode_reward": 354.690669253777, "step": 67000}
{"episode": 68.0, "batch_reward": 0.31930596217513085, "actor_loss": -18.303714069366457, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 445.07083010673523, "episode_reward": 14.968382345976964, "step": 68000}
{"episode": 69.0, "batch_reward": 0.3169569135904312, "actor_loss": -18.140235469818116, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.73779559135437, "episode_reward": 351.40289931719394, "step": 69000}
{"episode": 70.0, "batch_reward": 0.31560601824522017, "actor_loss": -17.926965135574342, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 443.98762607574463, "episode_reward": 16.00092752188128, "step": 70000}
{"episode": 71.0, "batch_reward": 0.3113317365348339, "actor_loss": -17.73535452079773, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 38.486117362976074, "episode_reward": 14.596453643079672, "step": 71000}
{"episode": 72.0, "batch_reward": 0.3075172180533409, "actor_loss": -17.61282127571106, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 439.48454093933105, "episode_reward": 6.626536007450831, "step": 72000}
{"episode": 73.0, "batch_reward": 0.30357161059975624, "actor_loss": -17.457197303771974, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.00773525238037, "episode_reward": 8.095716168333933, "step": 73000}
{"episode": 74.0, "batch_reward": 0.29847242423892023, "actor_loss": -17.097947088241575, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 436.0320963859558, "episode_reward": 12.209518635310086, "step": 74000}
{"episode": 75.0, "batch_reward": 0.29734043797850607, "actor_loss": -17.031007705688477, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 15.858009815216064, "episode_reward": 357.56713836946756, "step": 75000}
{"episode": 76.0, "batch_reward": 0.29814698635041714, "actor_loss": -17.56293914604187, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 440.2544059753418, "episode_reward": 233.9081706382421, "step": 76000}
{"episode": 77.0, "batch_reward": 0.2959764277040958, "actor_loss": -17.4386591091156, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.903352975845337, "episode_reward": 237.39091263643894, "step": 77000}
{"episode": 78.0, "batch_reward": 0.29635137382149696, "actor_loss": -17.90704539680481, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 429.0713493824005, "episode_reward": 359.3157230246552, "step": 78000}
{"episode": 79.0, "batch_reward": 0.2966351290345192, "actor_loss": -17.896835426330565, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.5134596824646, "episode_reward": 392.085990496008, "step": 79000}
{"episode": 80.0, "batch_reward": 0.2983721358180046, "actor_loss": -18.305527841567994, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 441.1408975124359, "episode_reward": 367.83585275429306, "step": 80000}
{"episode": 81.0, "batch_reward": 0.29894252279400824, "actor_loss": -18.353056243896486, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 34.4922251701355, "episode_reward": 349.90736617568086, "step": 81000}
{"episode": 82.0, "batch_reward": 0.3007487293481827, "actor_loss": -18.70394450378418, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 441.22625756263733, "episode_reward": 357.38156018366635, "step": 82000}
{"episode": 83.0, "batch_reward": 0.2999831711053848, "actor_loss": -18.743925689697267, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.084989309310913, "episode_reward": 310.94674700780007, "step": 83000}
{"episode": 84.0, "batch_reward": 0.3011136598587036, "actor_loss": -19.753122707366945, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 429.75964641571045, "episode_reward": 380.93221582445443, "step": 84000}
{"episode": 85.0, "batch_reward": 0.30281989273428916, "actor_loss": -19.905138500213624, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.196204900741577, "episode_reward": 408.0525078490666, "step": 85000}
{"episode": 86.0, "batch_reward": 0.30300963762402533, "actor_loss": -20.301963733673094, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 439.73506331443787, "episode_reward": 403.5322018618015, "step": 86000}
{"episode": 87.0, "batch_reward": 0.3041428714692593, "actor_loss": -20.31831175994873, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.45676827430725, "episode_reward": 388.1789877141089, "step": 87000}
{"episode": 88.0, "batch_reward": 0.3050578003525734, "actor_loss": -21.378260261535644, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 435.92672204971313, "episode_reward": 386.513221189847, "step": 88000}
{"episode": 89.0, "batch_reward": 0.30660817140340807, "actor_loss": -21.496795974731445, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.21918272972107, "episode_reward": 389.53064207160395, "step": 89000}
{"episode": 90.0, "batch_reward": 0.30722832736372946, "actor_loss": -21.43745267486572, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 436.1708526611328, "episode_reward": 408.3838477724359, "step": 90000}
{"episode": 91.0, "batch_reward": 0.3076473526656628, "actor_loss": -21.446558475494385, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 38.60250544548035, "episode_reward": 412.91024646669695, "step": 91000}
{"episode": 92.0, "batch_reward": 0.3087558861374855, "actor_loss": -21.99545121383667, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 437.08395648002625, "episode_reward": 387.31704812949863, "step": 92000}
{"episode": 93.0, "batch_reward": 0.3104598372876644, "actor_loss": -22.172774417877196, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.830345630645752, "episode_reward": 421.32681977868697, "step": 93000}
{"episode": 94.0, "batch_reward": 0.3116117478311062, "actor_loss": -21.92456911468506, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 441.815566778183, "episode_reward": 388.81742980094697, "step": 94000}
{"episode": 95.0, "batch_reward": 0.31228671687841414, "actor_loss": -21.904903324127197, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.342320203781128, "episode_reward": 407.255435239375, "step": 95000}
{"episode": 96.0, "batch_reward": 0.31307383280992507, "actor_loss": -21.680780750274657, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 440.7324821949005, "episode_reward": 391.0010315276751, "step": 96000}
{"episode": 97.0, "batch_reward": 0.3150686219036579, "actor_loss": -21.827068565368652, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.801560401916504, "episode_reward": 320.52324709670097, "step": 97000}
{"episode": 98.0, "batch_reward": 0.31400258815288545, "actor_loss": -21.306902828216554, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 436.6206774711609, "episode_reward": 395.9242955921811, "step": 98000}
{"episode": 99.0, "batch_reward": 0.31494276735186577, "actor_loss": -21.438309539794922, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.268399715423584, "episode_reward": 415.18709581039946, "step": 99000}
{"episode": 100.0, "batch_reward": 0.3147418242096901, "actor_loss": -21.273585536956787, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 443.3390471935272, "episode_reward": 298.91903147789924, "step": 100000}
{"episode": 101.0, "batch_reward": 0.31553012773394584, "actor_loss": -21.378773593902586, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 34.7758846282959, "episode_reward": 390.9033688246342, "step": 101000}
{"episode": 102.0, "batch_reward": 0.3167506692111492, "actor_loss": -20.98679483795166, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 439.03280663490295, "episode_reward": 350.02498391148504, "step": 102000}
{"episode": 103.0, "batch_reward": 0.3154980190992355, "actor_loss": -20.98531875991821, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.176761388778687, "episode_reward": 8.094391624970472, "step": 103000}
{"episode": 104.0, "batch_reward": 0.3118864494264126, "actor_loss": -20.738206653594972, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 438.1672511100769, "episode_reward": 5.633554076581942, "step": 104000}
{"episode": 105.0, "batch_reward": 0.31101073989272116, "actor_loss": -20.64795291519165, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.73219633102417, "episode_reward": 350.8588721441983, "step": 105000}
{"episode": 106.0, "batch_reward": 0.30915466985106466, "actor_loss": -20.425147144317627, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 441.2868905067444, "episode_reward": 5.6181930512208, "step": 106000}
{"episode": 107.0, "batch_reward": 0.30668460682034493, "actor_loss": -20.349656101226806, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.67954921722412, "episode_reward": 13.225965130050845, "step": 107000}
{"episode": 108.0, "batch_reward": 0.30570040532946585, "actor_loss": -20.099088577270507, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 438.1595802307129, "episode_reward": 360.6768391409852, "step": 108000}
{"episode": 109.0, "batch_reward": 0.30598170644044875, "actor_loss": -20.14649157714844, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.614919662475586, "episode_reward": 378.6100096458043, "step": 109000}
{"episode": 110.0, "batch_reward": 0.3065765353143215, "actor_loss": -20.19873946762085, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 433.54911375045776, "episode_reward": 443.2265546279351, "step": 110000}
{"episode": 111.0, "batch_reward": 0.308485451310873, "actor_loss": -20.26597463989258, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 32.38315010070801, "episode_reward": 419.0105003917843, "step": 111000}
{"episode": 112.0, "batch_reward": 0.3090462256968021, "actor_loss": -20.66628552246094, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 443.40633058547974, "episode_reward": 373.6877290485915, "step": 112000}
{"episode": 113.0, "batch_reward": 0.3101120361685753, "actor_loss": -20.719973903656005, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.756752967834473, "episode_reward": 406.8207214199821, "step": 113000}
{"episode": 114.0, "batch_reward": 0.3094394237101078, "actor_loss": -20.680473823547363, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 434.5964984893799, "episode_reward": 8.244217893523627, "step": 114000}
{"episode": 115.0, "batch_reward": 0.30605265372991564, "actor_loss": -20.485754669189454, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.778462171554565, "episode_reward": 5.903902424034778, "step": 115000}
{"episode": 116.0, "batch_reward": 0.3038543449640274, "actor_loss": -21.133968223571777, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 443.47220158576965, "episode_reward": 10.195073507908178, "step": 116000}
{"episode": 117.0, "batch_reward": 0.30258863779902456, "actor_loss": -21.078176219940186, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.26773238182068, "episode_reward": 385.31380840836295, "step": 117000}
{"episode": 118.0, "batch_reward": 0.3039041192531586, "actor_loss": -20.34309928512573, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 432.35151505470276, "episode_reward": 406.8362981653614, "step": 118000}
{"episode": 119.0, "batch_reward": 0.304283756673336, "actor_loss": -20.367847511291505, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.263282775878906, "episode_reward": 411.4457283166594, "step": 119000}
{"episode": 120.0, "batch_reward": 0.30509684747457505, "actor_loss": -20.850958026885987, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 439.04401183128357, "episode_reward": 368.156076195259, "step": 120000}
{"episode": 121.0, "batch_reward": 0.3054318460673094, "actor_loss": -20.837080837249754, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 32.81454849243164, "episode_reward": 413.7013699503281, "step": 121000}
{"episode": 122.0, "batch_reward": 0.3069591136276722, "actor_loss": -20.93245489883423, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 441.10429787635803, "episode_reward": 442.92636672581045, "step": 122000}
{"episode": 123.0, "batch_reward": 0.3067540649175644, "actor_loss": -20.92010619354248, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.015069484710693, "episode_reward": 407.2704065301332, "step": 123000}
{"episode": 124.0, "batch_reward": 0.3086373221576214, "actor_loss": -20.764963386535644, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 428.99578881263733, "episode_reward": 432.87019792726517, "step": 124000}
{"episode": 125.0, "batch_reward": 0.30927932819724085, "actor_loss": -20.8310362739563, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.0972158908844, "episode_reward": 312.28133560091914, "step": 125000}
{"episode": 126.0, "batch_reward": 0.30921615490317345, "actor_loss": -20.56049532699585, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 444.9979238510132, "episode_reward": 323.06987219489554, "step": 126000}
{"episode": 127.0, "batch_reward": 0.30999939224123957, "actor_loss": -20.523368045806883, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.739630699157715, "episode_reward": 389.4115454265018, "step": 127000}
{"episode": 128.0, "batch_reward": 0.31063454717397687, "actor_loss": -21.4305654296875, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 441.9170048236847, "episode_reward": 358.55143738359203, "step": 128000}
{"episode": 129.0, "batch_reward": 0.31075232833623884, "actor_loss": -21.32543468093872, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.74860954284668, "episode_reward": 380.40132442203407, "step": 129000}
{"episode": 130.0, "batch_reward": 0.3103040643632412, "actor_loss": -21.388189544677733, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 435.8157813549042, "episode_reward": 286.3858560768751, "step": 130000}
{"episode": 131.0, "batch_reward": 0.3111398811638355, "actor_loss": -21.352808994293213, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.56368899345398, "episode_reward": 393.95447263576887, "step": 131000}
{"episode": 132.0, "batch_reward": 0.310927058249712, "actor_loss": -21.63593285369873, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 444.03335332870483, "episode_reward": 286.2637158296616, "step": 132000}
{"episode": 133.0, "batch_reward": 0.31102208158373834, "actor_loss": -21.637717609405517, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.474807024002075, "episode_reward": 251.81825225583674, "step": 133000}
{"episode": 134.0, "batch_reward": 0.3101990655660629, "actor_loss": -21.858133800506593, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 442.5703275203705, "episode_reward": 83.09283180556199, "step": 134000}
{"episode": 135.0, "batch_reward": 0.3082737820148468, "actor_loss": -21.69092081451416, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.114400625228882, "episode_reward": 221.8040517492789, "step": 135000}
{"episode": 136.0, "batch_reward": 0.3086732903122902, "actor_loss": -21.598565143585205, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 448.20462250709534, "episode_reward": 331.8396921826102, "step": 136000}
{"episode": 137.0, "batch_reward": 0.3086366344988346, "actor_loss": -21.605794761657716, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.652485370635986, "episode_reward": 298.8662671951993, "step": 137000}
{"episode": 138.0, "batch_reward": 0.30871182277798653, "actor_loss": -21.62801366043091, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 445.35230326652527, "episode_reward": 411.49999285162943, "step": 138000}
{"episode": 139.0, "batch_reward": 0.30886296290159226, "actor_loss": -21.65648705291748, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.290324687957764, "episode_reward": 35.476212138771174, "step": 139000}
{"episode": 140.0, "batch_reward": 0.3071395857334137, "actor_loss": -21.782718551635742, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 446.37268805503845, "episode_reward": 288.09681869541856, "step": 140000}
{"episode": 141.0, "batch_reward": 0.3069174626171589, "actor_loss": -21.75525406265259, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.189124584198, "episode_reward": 415.54484500106855, "step": 141000}
{"episode": 142.0, "batch_reward": 0.3085967147946358, "actor_loss": -21.695298027038575, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 431.9803829193115, "episode_reward": 378.56964228044757, "step": 142000}
{"episode": 143.0, "batch_reward": 0.30829871997237207, "actor_loss": -21.727353275299073, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.388325929641724, "episode_reward": 310.15939080283397, "step": 143000}
{"episode": 144.0, "batch_reward": 0.30797636434435843, "actor_loss": -21.790018096923827, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 442.23809456825256, "episode_reward": 322.94681327171986, "step": 144000}
{"episode": 145.0, "batch_reward": 0.30873140788078307, "actor_loss": -21.781831352233887, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.09085512161255, "episode_reward": 398.39440911439544, "step": 145000}
{"episode": 146.0, "batch_reward": 0.30837229546904565, "actor_loss": -22.069897636413575, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 441.6042079925537, "episode_reward": 80.3723277327511, "step": 146000}
{"episode": 147.0, "batch_reward": 0.30807209727168083, "actor_loss": -22.071337783813476, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.985567808151245, "episode_reward": 297.64140087678265, "step": 147000}
{"episode": 148.0, "batch_reward": 0.30671822556853295, "actor_loss": -21.933662010192872, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 427.89861035346985, "episode_reward": 269.9847374863635, "step": 148000}
{"episode": 149.0, "batch_reward": 0.3060055091381073, "actor_loss": -21.919335918426512, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.39936637878418, "episode_reward": 20.174500030019367, "step": 149000}
{"episode": 150.0, "batch_reward": 0.3055433166921139, "actor_loss": -21.98861227798462, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "step": 150000}
