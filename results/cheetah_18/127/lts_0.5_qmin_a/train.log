{"episode_reward": 0.0, "episode": 1.0, "duration": 17.687362909317017, "step": 1000}
{"episode_reward": 7.051849146674556, "episode": 2.0, "duration": 1.57783842086792, "step": 2000}
{"episode_reward": 365.4711839680396, "episode": 3.0, "batch_reward": 0.17556512351332604, "critic_loss": 0.04854023235496947, "actor_loss": -19.387709104422466, "actor_target_entropy": -6.0, "alpha_value": 0.01377813086574139, "duration": 63.00331664085388, "step": 3000}
{"episode_reward": 17.21100875211488, "episode": 4.0, "batch_reward": 0.11875767233967781, "critic_loss": 0.05776613561622798, "actor_loss": -15.301979962348938, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.48306965827942, "step": 4000}
{"episode_reward": 43.429718586210996, "episode": 5.0, "batch_reward": 0.1009647139981389, "critic_loss": 0.05635992994718254, "actor_loss": -14.871199567198753, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.637161016464233, "step": 5000}
{"episode_reward": 40.63992180544588, "episode": 6.0, "batch_reward": 0.08882670699059964, "critic_loss": 0.046730395955964926, "actor_loss": -15.807505551338195, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.865378856658936, "step": 6000}
{"episode_reward": 36.15225970284484, "episode": 7.0, "batch_reward": 0.0826337291970849, "critic_loss": 0.06069555974751711, "actor_loss": -14.257621786534786, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.69937753677368, "step": 7000}
{"episode_reward": 59.156410787282816, "episode": 8.0, "batch_reward": 0.08186668586730957, "critic_loss": 0.07976668981090188, "actor_loss": -14.190615915492177, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.781790256500244, "step": 8000}
{"episode_reward": 91.79859656801237, "episode": 9.0, "batch_reward": 0.08741371581330895, "critic_loss": 0.09820565189421177, "actor_loss": -15.796187737062574, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.717509031295776, "step": 9000}
{"episode_reward": 185.82506962514717, "episode": 10.0, "batch_reward": 0.09714775743335485, "critic_loss": 0.09216249446943402, "actor_loss": -16.230808407463133, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.5842068195343, "step": 10000}
{"episode_reward": 101.1122710169667, "episode": 11.0, "batch_reward": 0.09464392795413733, "critic_loss": 0.09308526930958033, "actor_loss": -15.189741825222969, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.2165150642395, "step": 11000}
{"episode_reward": 48.16961621701845, "episode": 12.0, "batch_reward": 0.08903687328472734, "critic_loss": 0.09858439278975129, "actor_loss": -14.319445630222559, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.63178324699402, "step": 12000}
{"episode_reward": 41.87337664929122, "episode": 13.0, "batch_reward": 0.09224757484719157, "critic_loss": 0.10756258953735233, "actor_loss": -14.135858226537705, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.352976083755493, "step": 13000}
{"episode_reward": 173.82715507099752, "episode": 14.0, "batch_reward": 0.09124848105758429, "critic_loss": 0.09508685057982802, "actor_loss": -13.766338307499886, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.89959454536438, "step": 14000}
{"episode_reward": 35.11106266309278, "episode": 15.0, "batch_reward": 0.08988313380256295, "critic_loss": 0.09865207456052304, "actor_loss": -14.00616708278656, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.138732433319092, "step": 15000}
{"episode_reward": 73.47841106895467, "episode": 16.0, "batch_reward": 0.0897202716358006, "critic_loss": 0.10122792588174342, "actor_loss": -13.723959021091462, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.149622678756714, "step": 16000}
{"episode_reward": 88.20451245625775, "episode": 17.0, "batch_reward": 0.08637167043238879, "critic_loss": 0.1035308932736516, "actor_loss": -12.983559708356857, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.295928716659546, "step": 17000}
{"episode_reward": 21.819062947840006, "episode": 18.0, "batch_reward": 0.08350301686674357, "critic_loss": 0.10171654815226794, "actor_loss": -12.68294816017151, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.179630041122437, "step": 18000}
{"episode_reward": 39.66382778210723, "episode": 19.0, "batch_reward": 0.08253330358117819, "critic_loss": 0.11954693773388862, "actor_loss": -12.362033000469207, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.413227558135986, "step": 19000}
{"episode_reward": 74.02721181357931, "episode": 20.0, "batch_reward": 0.08548913305625319, "critic_loss": 0.11673890127241611, "actor_loss": -13.332896038770675, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.549819707870483, "step": 20000}
{"episode_reward": 251.84022860048987, "episode": 21.0, "batch_reward": 0.0893280707038939, "critic_loss": 0.10991277454048395, "actor_loss": -12.108575131893158, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.93460488319397, "step": 21000}
{"episode_reward": 45.1442426156392, "episode": 22.0, "batch_reward": 0.09171914876997471, "critic_loss": 0.12927047631144523, "actor_loss": -13.72796719121933, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.041978120803833, "step": 22000}
{"episode_reward": 290.0606128785266, "episode": 23.0, "batch_reward": 0.09971220023930073, "critic_loss": 0.1455053413286805, "actor_loss": -13.886728918075562, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.246134042739868, "step": 23000}
{"episode_reward": 162.10208286758987, "episode": 24.0, "batch_reward": 0.10179375501722097, "critic_loss": 0.1464194765985012, "actor_loss": -14.024287051677703, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.415426015853882, "step": 24000}
{"episode_reward": 243.07278623590702, "episode": 25.0, "batch_reward": 0.10652656976133584, "critic_loss": 0.1437420468851924, "actor_loss": -14.768685626983643, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.327651977539062, "step": 25000}
{"episode_reward": 92.03387719525526, "episode": 26.0, "batch_reward": 0.10740100385993719, "critic_loss": 0.15266368629038335, "actor_loss": -14.492830245494842, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.61430025100708, "step": 26000}
{"episode_reward": 141.02166162805798, "episode": 27.0, "batch_reward": 0.10990930616110563, "critic_loss": 0.19481667985767126, "actor_loss": -14.400392822265625, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.03609848022461, "step": 27000}
{"episode_reward": 212.4125219746503, "episode": 28.0, "batch_reward": 0.11413299552351236, "critic_loss": 0.19825333865731953, "actor_loss": -15.19542666053772, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.131011724472046, "step": 28000}
{"episode_reward": 301.5904416281947, "episode": 29.0, "batch_reward": 0.11796796718239784, "critic_loss": 0.2291354162991047, "actor_loss": -15.323888566017152, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.38616943359375, "step": 29000}
{"episode_reward": 133.97573721097308, "episode": 30.0, "batch_reward": 0.11698252004384994, "critic_loss": 0.2288302778825164, "actor_loss": -14.48678296661377, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.547540187835693, "step": 30000}
{"episode_reward": 33.59180321737867, "episode": 31.0, "batch_reward": 0.1172283372208476, "critic_loss": 0.234467203207314, "actor_loss": -15.172194884300232, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.43405604362488, "step": 31000}
{"episode_reward": 214.80903164446175, "episode": 32.0, "batch_reward": 0.11952720753848553, "critic_loss": 0.24074169406294824, "actor_loss": -15.854341956138612, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.45748281478882, "step": 32000}
{"episode_reward": 72.61682606000254, "episode": 33.0, "batch_reward": 0.11802715589851141, "critic_loss": 0.2442604393735528, "actor_loss": -15.554296050071716, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.285648107528687, "step": 33000}
{"episode_reward": 152.06963943133397, "episode": 34.0, "batch_reward": 0.12047467368841171, "critic_loss": 0.24701270914077758, "actor_loss": -15.210152382850646, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.413366317749023, "step": 34000}
{"episode_reward": 302.52220646764, "episode": 35.0, "batch_reward": 0.12616837755590676, "critic_loss": 0.23942783800512552, "actor_loss": -16.283889773368834, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.530519723892212, "step": 35000}
{"episode_reward": 319.9398135064652, "episode": 36.0, "batch_reward": 0.1309597425684333, "critic_loss": 0.25903140734881164, "actor_loss": -16.88091801261902, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.19143557548523, "step": 36000}
{"episode_reward": 300.9393119559611, "episode": 37.0, "batch_reward": 0.13520299629122018, "critic_loss": 0.2787924439907074, "actor_loss": -16.83768649196625, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.830694437026978, "step": 37000}
{"episode_reward": 298.266304418199, "episode": 38.0, "batch_reward": 0.14072727593034506, "critic_loss": 0.30039313293993475, "actor_loss": -17.624312291145326, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.56932282447815, "step": 38000}
{"episode_reward": 315.2187582943443, "episode": 39.0, "batch_reward": 0.14557346671074628, "critic_loss": 0.3028214389234781, "actor_loss": -17.841820039749145, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.257378578186035, "step": 39000}
{"episode_reward": 402.54859571085484, "episode": 40.0, "batch_reward": 0.152137361317873, "critic_loss": 0.2887389249056578, "actor_loss": -18.46022822380066, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.8515408039093, "step": 40000}
{"episode_reward": 361.1898284254282, "episode": 41.0, "batch_reward": 0.1569989058971405, "critic_loss": 0.2842449853718281, "actor_loss": -18.58453157043457, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.66135358810425, "step": 41000}
{"episode_reward": 343.0275014388687, "episode": 42.0, "batch_reward": 0.1624749685898423, "critic_loss": 0.3091726043075323, "actor_loss": -19.26940726661682, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.34160876274109, "step": 42000}
{"episode_reward": 374.4097255429343, "episode": 43.0, "batch_reward": 0.16687733720242978, "critic_loss": 0.3064928362518549, "actor_loss": -20.20719285964966, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.356353282928467, "step": 43000}
{"episode_reward": 411.1115079135417, "episode": 44.0, "batch_reward": 0.17164632532000543, "critic_loss": 0.3268579501062632, "actor_loss": -21.141136449813843, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.505693674087524, "step": 44000}
{"episode_reward": 353.84090685802624, "episode": 45.0, "batch_reward": 0.1764947460591793, "critic_loss": 0.34194868640601633, "actor_loss": -20.948959577560426, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.145887851715088, "step": 45000}
{"episode_reward": 378.4148966901118, "episode": 46.0, "batch_reward": 0.17960846571624278, "critic_loss": 0.40722168777883055, "actor_loss": -20.950108186721803, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.226919412612915, "step": 46000}
{"episode_reward": 200.93768682774933, "episode": 47.0, "batch_reward": 0.18170284686982632, "critic_loss": 0.3905025498569012, "actor_loss": -21.472153894424437, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.426237106323242, "step": 47000}
{"episode_reward": 363.9780957121396, "episode": 48.0, "batch_reward": 0.18619046768546105, "critic_loss": 0.3793733180612326, "actor_loss": -21.829357202529906, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.22251319885254, "step": 48000}
{"episode_reward": 419.2278319173843, "episode": 49.0, "batch_reward": 0.18970874543488025, "critic_loss": 0.4059802912026644, "actor_loss": -22.836610597610473, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.740079641342163, "step": 49000}
{"episode_reward": 363.6910481208266, "episode": 50.0, "batch_reward": 0.1939919965863228, "critic_loss": 0.4374533125013113, "actor_loss": -22.784084615707396, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.541775226593018, "step": 50000}
{"episode_reward": 409.19280225508106, "episode": 51.0, "batch_reward": 0.1984088804125786, "critic_loss": 0.4170901729464531, "actor_loss": -22.881132190704346, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.568910121917725, "step": 51000}
{"episode_reward": 434.4858484366553, "episode": 52.0, "batch_reward": 0.20338040237128735, "critic_loss": 0.3938878956884146, "actor_loss": -23.57411747741699, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.640984773635864, "step": 52000}
{"episode_reward": 412.60070976972065, "episode": 53.0, "batch_reward": 0.20493728072941303, "critic_loss": 0.4227133472710848, "actor_loss": -24.384665395736693, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.588775157928467, "step": 53000}
{"episode_reward": 101.9430821927528, "episode": 54.0, "batch_reward": 0.20484314462542533, "critic_loss": 0.393236385807395, "actor_loss": -24.487806522369386, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.150776863098145, "step": 54000}
{"episode_reward": 424.728160949254, "episode": 55.0, "batch_reward": 0.20699779197573662, "critic_loss": 0.3976266223490238, "actor_loss": -24.032472835540773, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.470653295516968, "step": 55000}
{"episode_reward": 170.85737962117886, "episode": 56.0, "batch_reward": 0.20838924054801464, "critic_loss": 0.42908962351083757, "actor_loss": -24.323210418701173, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.94220995903015, "step": 56000}
{"episode_reward": 467.18400913214504, "episode": 57.0, "batch_reward": 0.213200973957777, "critic_loss": 0.3841668240725994, "actor_loss": -24.564738185882568, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.15304470062256, "step": 57000}
{"episode_reward": 465.0951614602811, "episode": 58.0, "batch_reward": 0.217189570248127, "critic_loss": 0.37221004070341585, "actor_loss": -25.556554466247558, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.29750967025757, "step": 58000}
{"episode_reward": 469.8100903883788, "episode": 59.0, "batch_reward": 0.22182314172387124, "critic_loss": 0.37407316160202025, "actor_loss": -25.643201732635497, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.61750817298889, "step": 59000}
{"episode_reward": 434.80496013899824, "episode": 60.0, "batch_reward": 0.22445641422271728, "critic_loss": 0.3830492900013924, "actor_loss": -26.295914989471434, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.154155492782593, "step": 60000}
{"episode_reward": 424.918377730424, "episode": 61.0, "batch_reward": 0.22857751132547854, "critic_loss": 0.3720644435286522, "actor_loss": -26.216425659179688, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.98822617530823, "step": 61000}
{"episode_reward": 404.65090468526193, "episode": 62.0, "batch_reward": 0.23133466105163097, "critic_loss": 0.3924869469702244, "actor_loss": -27.190962265014647, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.13480496406555, "step": 62000}
{"episode_reward": 392.990328035107, "episode": 63.0, "batch_reward": 0.23429337106645107, "critic_loss": 0.4072619910985231, "actor_loss": -26.67853448486328, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.961110591888428, "step": 63000}
{"episode_reward": 453.32257328167543, "episode": 64.0, "batch_reward": 0.2384553169757128, "critic_loss": 0.39133596025407313, "actor_loss": -27.6853571434021, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.407111167907715, "step": 64000}
{"episode_reward": 427.5793212648855, "episode": 65.0, "batch_reward": 0.24108517956733705, "critic_loss": 0.391055949896574, "actor_loss": -27.647116394042968, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.132904529571533, "step": 65000}
{"episode_reward": 386.58762182908634, "episode": 66.0, "batch_reward": 0.24235462740063668, "critic_loss": 0.376144910171628, "actor_loss": -27.916361488342286, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.47645139694214, "step": 66000}
{"episode_reward": 480.09649466203376, "episode": 67.0, "batch_reward": 0.2467413864582777, "critic_loss": 0.4160109316557646, "actor_loss": -28.719310039520263, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.583820819854736, "step": 67000}
{"episode_reward": 354.87617792364347, "episode": 68.0, "batch_reward": 0.2477267649769783, "critic_loss": 0.40628048065304756, "actor_loss": -28.8707317237854, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.647981643676758, "step": 68000}
{"episode_reward": 437.89465073242275, "episode": 69.0, "batch_reward": 0.249324482396245, "critic_loss": 0.3838463539630175, "actor_loss": -28.45540486907959, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.355344772338867, "step": 69000}
{"episode_reward": 461.06462280228834, "episode": 70.0, "batch_reward": 0.2535136031806469, "critic_loss": 0.3829661912471056, "actor_loss": -28.865895908355714, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.683497428894043, "step": 70000}
{"episode_reward": 440.3001337683096, "episode": 71.0, "batch_reward": 0.25616970397531985, "critic_loss": 0.3710021935105324, "actor_loss": -28.988732776641847, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.92401146888733, "step": 71000}
{"episode_reward": 397.611618239492, "episode": 72.0, "batch_reward": 0.2579367104023695, "critic_loss": 0.3782376589477062, "actor_loss": -29.277985820770265, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.491443157196045, "step": 72000}
{"episode_reward": 457.6827338927633, "episode": 73.0, "batch_reward": 0.26163961017131804, "critic_loss": 0.4251973168104887, "actor_loss": -29.61901149749756, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.72699284553528, "step": 73000}
{"episode_reward": 324.66189942265385, "episode": 74.0, "batch_reward": 0.26105559304356574, "critic_loss": 0.4493253655731678, "actor_loss": -29.72161222076416, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.10755944252014, "step": 74000}
{"episode_reward": 470.321165633847, "episode": 75.0, "batch_reward": 0.26425340497493743, "critic_loss": 0.4217671634405851, "actor_loss": -30.01871801376343, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.404789209365845, "step": 75000}
{"episode_reward": 500.50166208936855, "episode": 76.0, "batch_reward": 0.2673916382193565, "critic_loss": 0.39513829070329665, "actor_loss": -30.08053931427002, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.733142852783203, "step": 76000}
{"episode_reward": 443.8041210898666, "episode": 77.0, "batch_reward": 0.2703893335610628, "critic_loss": 0.4065740977823734, "actor_loss": -30.571726112365724, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.114218950271606, "step": 77000}
{"episode_reward": 495.6932907974622, "episode": 78.0, "batch_reward": 0.2725277585685253, "critic_loss": 0.39115622361004354, "actor_loss": -30.55416765975952, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.191962242126465, "step": 78000}
{"episode_reward": 473.55588524341584, "episode": 79.0, "batch_reward": 0.2744675866663456, "critic_loss": 0.43882091081142427, "actor_loss": -31.28393941116333, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.964794635772705, "step": 79000}
{"episode_reward": 128.9865282099119, "episode": 80.0, "batch_reward": 0.2738870238661766, "critic_loss": 0.4199751947373152, "actor_loss": -31.218012409210203, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.130170822143555, "step": 80000}
{"episode_reward": 447.98339603084054, "episode": 81.0, "batch_reward": 0.275814116448164, "critic_loss": 0.4317188360095024, "actor_loss": -31.330008865356444, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 38.19191861152649, "step": 81000}
{"episode_reward": 221.58173948693747, "episode": 82.0, "batch_reward": 0.2749688324928284, "critic_loss": 0.4377921308577061, "actor_loss": -31.00359903717041, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.13463592529297, "step": 82000}
{"episode_reward": 511.36521402949586, "episode": 83.0, "batch_reward": 0.27840737845003605, "critic_loss": 0.46624421802163124, "actor_loss": -31.663565864562987, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.262904405593872, "step": 83000}
{"episode_reward": 443.2309128590308, "episode": 84.0, "batch_reward": 0.2808873489648104, "critic_loss": 0.47553098706901076, "actor_loss": -32.00206303405762, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.055908203125, "step": 84000}
{"episode_reward": 486.75983670638493, "episode": 85.0, "batch_reward": 0.2822498289346695, "critic_loss": 0.4772687237858772, "actor_loss": -31.758035625457765, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.151947021484375, "step": 85000}
{"episode_reward": 478.7041039357626, "episode": 86.0, "batch_reward": 0.2852973770499229, "critic_loss": 0.44366213558614254, "actor_loss": -32.0770895576477, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.3270263671875, "step": 86000}
{"episode_reward": 496.1180520322032, "episode": 87.0, "batch_reward": 0.28719682160019877, "critic_loss": 0.4408227735310793, "actor_loss": -32.578388118743895, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.78314971923828, "step": 87000}
{"episode_reward": 491.18639533612856, "episode": 88.0, "batch_reward": 0.28933712500333786, "critic_loss": 0.41917344865202905, "actor_loss": -32.59945375061035, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.17630386352539, "step": 88000}
{"episode_reward": 455.610467496154, "episode": 89.0, "batch_reward": 0.2911667857468128, "critic_loss": 0.4959847577661276, "actor_loss": -32.35254636764526, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.51444935798645, "step": 89000}
{"episode_reward": 476.97651287789193, "episode": 90.0, "batch_reward": 0.2943557608276606, "critic_loss": 0.45180003650486467, "actor_loss": -32.66008379745483, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.949134588241577, "step": 90000}
{"episode_reward": 532.5285461492665, "episode": 91.0, "batch_reward": 0.2964276773780584, "critic_loss": 0.4226666998565197, "actor_loss": -32.802231044769286, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.696534872055054, "step": 91000}
{"episode_reward": 511.0459880364937, "episode": 92.0, "batch_reward": 0.29936916825175286, "critic_loss": 0.4653569601178169, "actor_loss": -33.5553786315918, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.695817947387695, "step": 92000}
{"episode_reward": 415.9466463530875, "episode": 93.0, "batch_reward": 0.2991835505068302, "critic_loss": 0.4552819081544876, "actor_loss": -33.03912364578247, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.70294976234436, "step": 93000}
{"episode_reward": 493.2306115087529, "episode": 94.0, "batch_reward": 0.30188221326470377, "critic_loss": 0.4705779673010111, "actor_loss": -33.77455965042114, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.885613203048706, "step": 94000}
{"episode_reward": 426.5413495727016, "episode": 95.0, "batch_reward": 0.3037483651340008, "critic_loss": 0.46070375959575177, "actor_loss": -34.248342025756834, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.38884925842285, "step": 95000}
{"episode_reward": 461.07377962639845, "episode": 96.0, "batch_reward": 0.3059897753894329, "critic_loss": 0.46213339830935, "actor_loss": -33.85415179443359, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.235828161239624, "step": 96000}
{"episode_reward": 518.4599798137923, "episode": 97.0, "batch_reward": 0.30709711360931397, "critic_loss": 0.4116589549332857, "actor_loss": -33.99773803329468, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.14263916015625, "step": 97000}
{"episode_reward": 523.2022877690129, "episode": 98.0, "batch_reward": 0.30787487789988516, "critic_loss": 0.4546124022901058, "actor_loss": -34.59767918395996, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.339380979537964, "step": 98000}
{"episode_reward": 147.280804529491, "episode": 99.0, "batch_reward": 0.3064874755293131, "critic_loss": 0.46804024460911753, "actor_loss": -34.25428285217285, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.198617458343506, "step": 99000}
{"episode_reward": 129.1733279147421, "episode": 100.0, "batch_reward": 0.3064784607440233, "critic_loss": 0.44697389684617517, "actor_loss": -34.18636787414551, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.426450967788696, "step": 100000}
{"episode_reward": 515.8634432023307, "episode": 101.0, "batch_reward": 0.3075406054854393, "critic_loss": 0.44367764531075954, "actor_loss": -34.17065017700195, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.75170969963074, "step": 101000}
{"episode_reward": 474.6976473039979, "episode": 102.0, "batch_reward": 0.30905750128626824, "critic_loss": 0.45998035350441935, "actor_loss": -34.47107213973999, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.70767879486084, "step": 102000}
{"episode_reward": 469.83443193547, "episode": 103.0, "batch_reward": 0.31074600079655645, "critic_loss": 0.4931004470139742, "actor_loss": -34.595164890289304, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.679956436157227, "step": 103000}
{"episode_reward": 334.313201437326, "episode": 104.0, "batch_reward": 0.31159243679046633, "critic_loss": 0.4826830292344093, "actor_loss": -34.169564273834226, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.229686498641968, "step": 104000}
{"episode_reward": 491.74341542974616, "episode": 105.0, "batch_reward": 0.3138451056778431, "critic_loss": 0.48055885888636113, "actor_loss": -34.68314613723755, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.955345392227173, "step": 105000}
{"episode_reward": 492.38257235494507, "episode": 106.0, "batch_reward": 0.31441033381223676, "critic_loss": 0.5336200852394104, "actor_loss": -34.682492206573485, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.37343692779541, "step": 106000}
{"episode_reward": 271.85140376401597, "episode": 107.0, "batch_reward": 0.3146576448380947, "critic_loss": 0.47941186420619486, "actor_loss": -34.64146091079712, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.185449361801147, "step": 107000}
{"episode_reward": 496.8433155786107, "episode": 108.0, "batch_reward": 0.31567606756091116, "critic_loss": 0.4974188968539238, "actor_loss": -35.243505084991455, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.839980363845825, "step": 108000}
{"episode_reward": 514.0740243790128, "episode": 109.0, "batch_reward": 0.31872795802354814, "critic_loss": 0.45232075971364977, "actor_loss": -35.18210302734375, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.647266149520874, "step": 109000}
{"episode_reward": 469.9836471558976, "episode": 110.0, "batch_reward": 0.32027361330389975, "critic_loss": 0.49300384198129177, "actor_loss": -35.527339569091794, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.672809600830078, "step": 110000}
{"episode_reward": 509.32934758465467, "episode": 111.0, "batch_reward": 0.3207414684295654, "critic_loss": 0.49823486852645876, "actor_loss": -35.38614602279663, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 38.540160179138184, "step": 111000}
{"episode_reward": 478.0485908394526, "episode": 112.0, "batch_reward": 0.32175196427106856, "critic_loss": 0.4576852014809847, "actor_loss": -35.76189303207398, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.653449058532715, "step": 112000}
{"episode_reward": 474.9501858280421, "episode": 113.0, "batch_reward": 0.323942081451416, "critic_loss": 0.420405800640583, "actor_loss": -35.38052319335937, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.15607476234436, "step": 113000}
{"episode_reward": 493.27606154405004, "episode": 114.0, "batch_reward": 0.325616462290287, "critic_loss": 0.47507865585386755, "actor_loss": -35.961523029327395, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.85258460044861, "step": 114000}
{"episode_reward": 429.12153081515487, "episode": 115.0, "batch_reward": 0.3266046341359615, "critic_loss": 0.4359865707755089, "actor_loss": -35.95886148071289, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.790841817855835, "step": 115000}
{"episode_reward": 514.2884561894905, "episode": 116.0, "batch_reward": 0.32838985133171084, "critic_loss": 0.4540075845718384, "actor_loss": -36.059256324768064, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.35434889793396, "step": 116000}
{"episode_reward": 524.6121926114191, "episode": 117.0, "batch_reward": 0.3306071951389313, "critic_loss": 0.4698209068030119, "actor_loss": -35.9951965713501, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.62263298034668, "step": 117000}
{"episode_reward": 496.2006124498515, "episode": 118.0, "batch_reward": 0.33083074605464935, "critic_loss": 0.4379433773458004, "actor_loss": -36.08774251174927, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.948707580566406, "step": 118000}
{"episode_reward": 485.524560138455, "episode": 119.0, "batch_reward": 0.3325098760724068, "critic_loss": 0.438311210103333, "actor_loss": -36.16609762573242, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.15183448791504, "step": 119000}
{"episode_reward": 509.91648354231415, "episode": 120.0, "batch_reward": 0.3331658842563629, "critic_loss": 0.4263372839540243, "actor_loss": -36.30517975997925, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.32283115386963, "step": 120000}
{"episode_reward": 523.1797220618157, "episode": 121.0, "batch_reward": 0.33552840739488604, "critic_loss": 0.42999197293818, "actor_loss": -36.542816078186036, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.17288422584534, "step": 121000}
{"episode_reward": 463.2080229578384, "episode": 122.0, "batch_reward": 0.3359617297053337, "critic_loss": 0.4637636997103691, "actor_loss": -36.7825475730896, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.337546348571777, "step": 122000}
{"episode_reward": 490.1144513301735, "episode": 123.0, "batch_reward": 0.3382263997793198, "critic_loss": 0.47199012751877306, "actor_loss": -36.9846946105957, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.520462036132812, "step": 123000}
{"episode_reward": 497.1812294108233, "episode": 124.0, "batch_reward": 0.33960573717951775, "critic_loss": 0.47100383272767066, "actor_loss": -37.18594468307495, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.192782640457153, "step": 124000}
{"episode_reward": 506.28863203266764, "episode": 125.0, "batch_reward": 0.3388254670202732, "critic_loss": 0.5086458944380283, "actor_loss": -36.85937080764771, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.20886540412903, "step": 125000}
{"episode_reward": 224.04193983832377, "episode": 126.0, "batch_reward": 0.339642775952816, "critic_loss": 0.49970309902727605, "actor_loss": -37.17839376068115, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.325337171554565, "step": 126000}
{"episode_reward": 465.7467361099816, "episode": 127.0, "batch_reward": 0.3402635547220707, "critic_loss": 0.5119221612662077, "actor_loss": -37.22474055862427, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.500675916671753, "step": 127000}
{"episode_reward": 485.70679017605283, "episode": 128.0, "batch_reward": 0.341385342746973, "critic_loss": 0.4826430014371872, "actor_loss": -37.18165760421753, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.185641288757324, "step": 128000}
{"episode_reward": 500.6849381267118, "episode": 129.0, "batch_reward": 0.34323690918087957, "critic_loss": 0.48308334086835386, "actor_loss": -37.22531108856201, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.18380641937256, "step": 129000}
{"episode_reward": 487.03615076464143, "episode": 130.0, "batch_reward": 0.34325798112154005, "critic_loss": 0.4535610150843859, "actor_loss": -37.1229927482605, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.3419132232666, "step": 130000}
{"episode_reward": 466.99672763735634, "episode": 131.0, "batch_reward": 0.34624712765216825, "critic_loss": 0.4581928072720766, "actor_loss": -37.31469286346436, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.896912813186646, "step": 131000}
{"episode_reward": 493.7431104349781, "episode": 132.0, "batch_reward": 0.345705071747303, "critic_loss": 0.43284622180461885, "actor_loss": -37.281039253234866, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.656784772872925, "step": 132000}
{"episode_reward": 311.03205033114, "episode": 133.0, "batch_reward": 0.34604797619581223, "critic_loss": 0.4385227423012257, "actor_loss": -37.08535066986084, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.60011100769043, "step": 133000}
{"episode_reward": 513.8616447066088, "episode": 134.0, "batch_reward": 0.3466688313782215, "critic_loss": 0.42950216464698315, "actor_loss": -37.270394104003906, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.91554832458496, "step": 134000}
{"episode_reward": 495.20910069430096, "episode": 135.0, "batch_reward": 0.3476138060986996, "critic_loss": 0.4240791887640953, "actor_loss": -37.587825790405276, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.281108379364014, "step": 135000}
{"episode_reward": 499.27246444269394, "episode": 136.0, "batch_reward": 0.3494721799790859, "critic_loss": 0.4266095544248819, "actor_loss": -37.65844628143311, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.162850379943848, "step": 136000}
{"episode_reward": 502.2479639535955, "episode": 137.0, "batch_reward": 0.3509667221903801, "critic_loss": 0.4332140332907438, "actor_loss": -37.62597842788696, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.74660873413086, "step": 137000}
{"episode_reward": 450.9803890819476, "episode": 138.0, "batch_reward": 0.35093438053131104, "critic_loss": 0.45511845034360887, "actor_loss": -37.56331707382202, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.54708504676819, "step": 138000}
{"episode_reward": 499.2928299253354, "episode": 139.0, "batch_reward": 0.35276187044382096, "critic_loss": 0.43004084019362926, "actor_loss": -37.663124561309814, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.413886070251465, "step": 139000}
{"episode_reward": 521.8310876401298, "episode": 140.0, "batch_reward": 0.35253634384274485, "critic_loss": 0.399134050399065, "actor_loss": -37.7113578414917, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.84258723258972, "step": 140000}
{"episode_reward": 510.0685712821091, "episode": 141.0, "batch_reward": 0.3564907721579075, "critic_loss": 0.42014070707559587, "actor_loss": -37.98615621185303, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.47009778022766, "step": 141000}
{"episode_reward": 522.3746490488437, "episode": 142.0, "batch_reward": 0.3563217467069626, "critic_loss": 0.4108200289607048, "actor_loss": -37.93399615097046, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.70947527885437, "step": 142000}
{"episode_reward": 471.28415967201266, "episode": 143.0, "batch_reward": 0.35670214718580245, "critic_loss": 0.41228275007009507, "actor_loss": -38.112012317657474, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.46388840675354, "step": 143000}
{"episode_reward": 481.1648315894947, "episode": 144.0, "batch_reward": 0.3581650638282299, "critic_loss": 0.398693483248353, "actor_loss": -38.24515140914917, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.954619884490967, "step": 144000}
{"episode_reward": 474.7760116484747, "episode": 145.0, "batch_reward": 0.3586002326607704, "critic_loss": 0.389038120418787, "actor_loss": -38.404254444122316, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.249995946884155, "step": 145000}
{"episode_reward": 499.3545619761886, "episode": 146.0, "batch_reward": 0.35856789991259574, "critic_loss": 0.34164352459460495, "actor_loss": -37.89470469284058, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.786725282669067, "step": 146000}
{"episode_reward": 503.6257142517126, "episode": 147.0, "batch_reward": 0.35864793583750726, "critic_loss": 0.37600098517537117, "actor_loss": -38.168302921295165, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.73600721359253, "step": 147000}
{"episode_reward": 490.1751560869233, "episode": 148.0, "batch_reward": 0.3610693242251873, "critic_loss": 0.35100861245393755, "actor_loss": -38.38636025619507, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.251441478729248, "step": 148000}
{"episode_reward": 475.52618530694946, "episode": 149.0, "batch_reward": 0.3619525579810143, "critic_loss": 0.3598319869041443, "actor_loss": -38.42589663314819, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.681127786636353, "step": 149000}
{"episode_reward": 477.77072927753284, "episode": 150.0, "batch_reward": 0.3618095093667507, "critic_loss": 0.35085697039961816, "actor_loss": -38.55106513214111, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "step": 150000}
