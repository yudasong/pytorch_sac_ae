{"episode_reward": 0.0, "episode": 1.0, "duration": 20.33294177055359, "step": 1000}
{"episode_reward": 7.051849146674556, "episode": 2.0, "duration": 1.7068345546722412, "step": 2000}
{"episode_reward": 365.4711839680396, "episode": 3.0, "batch_reward": 0.17552618935291828, "critic_loss": 0.029013127106403053, "actor_loss": -7.978717417254218, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 67.84504747390747, "step": 3000}
{"episode_reward": 14.677361702170042, "episode": 4.0, "batch_reward": 0.11418216487020254, "critic_loss": 0.030301614564843475, "actor_loss": -7.977642812728882, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.651893138885498, "step": 4000}
{"episode_reward": 13.595477650238372, "episode": 5.0, "batch_reward": 0.09472276494652034, "critic_loss": 0.03603948508854955, "actor_loss": -7.243002275466919, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.120136737823486, "step": 5000}
{"episode_reward": 57.6461368905167, "episode": 6.0, "batch_reward": 0.08958120726048946, "critic_loss": 0.05234937802143395, "actor_loss": -8.677011843442918, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.91500496864319, "step": 6000}
{"episode_reward": 82.38906583184918, "episode": 7.0, "batch_reward": 0.08805213140696287, "critic_loss": 0.04964852400124073, "actor_loss": -7.910515199661255, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.00021743774414, "step": 7000}
{"episode_reward": 39.99856572683371, "episode": 8.0, "batch_reward": 0.08989435777068139, "critic_loss": 0.07230699300207198, "actor_loss": -8.318933731555939, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.103392601013184, "step": 8000}
{"episode_reward": 173.1645083769145, "episode": 9.0, "batch_reward": 0.0948892949745059, "critic_loss": 0.08172871981188655, "actor_loss": -9.023477160930634, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.562402963638306, "step": 9000}
{"episode_reward": 69.55862045120097, "episode": 10.0, "batch_reward": 0.08904557624459267, "critic_loss": 0.08326068828627467, "actor_loss": -9.287059634685516, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.279714345932007, "step": 10000}
{"episode_reward": 34.93432567822834, "episode": 11.0, "batch_reward": 0.08845808017626405, "critic_loss": 0.08626596657931805, "actor_loss": -9.283697423934937, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.152145862579346, "step": 11000}
{"episode_reward": 78.18860756017584, "episode": 12.0, "batch_reward": 0.08333120366185903, "critic_loss": 0.08500415562093258, "actor_loss": -9.506028005599976, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.683469772338867, "step": 12000}
{"episode_reward": 30.51225052976137, "episode": 13.0, "batch_reward": 0.0830705562531948, "critic_loss": 0.10756529920548201, "actor_loss": -9.11917217731476, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.98124408721924, "step": 13000}
{"episode_reward": 90.83031824546296, "episode": 14.0, "batch_reward": 0.08537312522530556, "critic_loss": 0.1400349248573184, "actor_loss": -9.846517896652221, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.40053701400757, "step": 14000}
{"episode_reward": 210.63959056426083, "episode": 15.0, "batch_reward": 0.0900796161442995, "critic_loss": 0.16211368695646525, "actor_loss": -10.172674337387084, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.223693370819092, "step": 15000}
{"episode_reward": 53.74022484388669, "episode": 16.0, "batch_reward": 0.09083789797872305, "critic_loss": 0.1736751225851476, "actor_loss": -10.289178824424743, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.930822372436523, "step": 16000}
{"episode_reward": 112.88603114693724, "episode": 17.0, "batch_reward": 0.09238955225050449, "critic_loss": 0.15838061795011163, "actor_loss": -10.67204889011383, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.89088487625122, "step": 17000}
{"episode_reward": 129.46651667052737, "episode": 18.0, "batch_reward": 0.09345030954107642, "critic_loss": 0.17630355984717608, "actor_loss": -10.702807607650756, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.987988233566284, "step": 18000}
{"episode_reward": 89.75629759686856, "episode": 19.0, "batch_reward": 0.0908673187457025, "critic_loss": 0.1843310371413827, "actor_loss": -10.602537088394165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.561960220336914, "step": 19000}
{"episode_reward": 35.87896340355185, "episode": 20.0, "batch_reward": 0.09161175137385726, "critic_loss": 0.18957700929790736, "actor_loss": -10.61679816532135, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.959688186645508, "step": 20000}
{"episode_reward": 129.11694766282898, "episode": 21.0, "batch_reward": 0.09641413719952106, "critic_loss": 0.2456658919453621, "actor_loss": -11.11314727973938, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.89016246795654, "step": 21000}
{"episode_reward": 346.84911430998403, "episode": 22.0, "batch_reward": 0.10338125615566969, "critic_loss": 0.2523661120459437, "actor_loss": -12.461159593582153, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.473204374313354, "step": 22000}
{"episode_reward": 62.194198157174924, "episode": 23.0, "batch_reward": 0.1019270928055048, "critic_loss": 0.20744169375300409, "actor_loss": -11.904741142272949, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.138718128204346, "step": 23000}
{"episode_reward": 87.28974911286765, "episode": 24.0, "batch_reward": 0.10225095107778907, "critic_loss": 0.2248600967824459, "actor_loss": -12.405637932777404, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.817298889160156, "step": 24000}
{"episode_reward": 123.20091609487511, "episode": 25.0, "batch_reward": 0.10590669943392277, "critic_loss": 0.22752376621961592, "actor_loss": -12.50889245414734, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.00585913658142, "step": 25000}
{"episode_reward": 283.19465890287125, "episode": 26.0, "batch_reward": 0.10880966112017632, "critic_loss": 0.2324650816768408, "actor_loss": -12.8263641872406, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.0829074382782, "step": 26000}
{"episode_reward": 55.34583498334943, "episode": 27.0, "batch_reward": 0.10841800713539124, "critic_loss": 0.25544122748821974, "actor_loss": -13.124246482849122, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.082254648208618, "step": 27000}
{"episode_reward": 179.6677552017548, "episode": 28.0, "batch_reward": 0.10982074697315693, "critic_loss": 0.2795133951753378, "actor_loss": -13.444152925491332, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.16937017440796, "step": 28000}
{"episode_reward": 63.27749080840693, "episode": 29.0, "batch_reward": 0.1063179465867579, "critic_loss": 0.25331159356981514, "actor_loss": -13.327196523666382, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.645896196365356, "step": 29000}
{"episode_reward": 41.12825257389535, "episode": 30.0, "batch_reward": 0.10661385184526444, "critic_loss": 0.2959970447868109, "actor_loss": -13.123300420761108, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.515216827392578, "step": 30000}
{"episode_reward": 122.63065515081495, "episode": 31.0, "batch_reward": 0.11036970605701209, "critic_loss": 0.3367439210265875, "actor_loss": -13.961971113204957, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.26264262199402, "step": 31000}
{"episode_reward": 295.40056213744197, "episode": 32.0, "batch_reward": 0.11416619329154491, "critic_loss": 0.3796537510231137, "actor_loss": -14.677420434951783, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.853947401046753, "step": 32000}
{"episode_reward": 135.1958230930072, "episode": 33.0, "batch_reward": 0.11394328800588846, "critic_loss": 0.37564655010402204, "actor_loss": -14.748566677093505, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.318714380264282, "step": 33000}
{"episode_reward": 132.12085175717257, "episode": 34.0, "batch_reward": 0.11775647073239089, "critic_loss": 0.37885837426036595, "actor_loss": -14.835034420013427, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.161755561828613, "step": 34000}
{"episode_reward": 325.9722694328122, "episode": 35.0, "batch_reward": 0.12360673076659441, "critic_loss": 0.42694538140296934, "actor_loss": -16.290488679885865, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.892260551452637, "step": 35000}
{"episode_reward": 362.1743760926988, "episode": 36.0, "batch_reward": 0.1297434502094984, "critic_loss": 0.44521831929683686, "actor_loss": -17.308304252624513, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.18771982192993, "step": 36000}
{"episode_reward": 387.4799583321818, "episode": 37.0, "batch_reward": 0.13466785702109338, "critic_loss": 0.427274152636528, "actor_loss": -17.992158014297484, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.57278823852539, "step": 37000}
{"episode_reward": 150.05684304686406, "episode": 38.0, "batch_reward": 0.13282628965377807, "critic_loss": 0.4825999286919832, "actor_loss": -18.380876621246337, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.130334854125977, "step": 38000}
{"episode_reward": 9.816518565509316, "episode": 39.0, "batch_reward": 0.13325404577702285, "critic_loss": 0.4690306876897812, "actor_loss": -19.37352463531494, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.00573420524597, "step": 39000}
{"episode_reward": 235.70203048945945, "episode": 40.0, "batch_reward": 0.13274775660037993, "critic_loss": 0.4762019863277674, "actor_loss": -20.227248783111573, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.233596563339233, "step": 40000}
{"episode_reward": 12.49715982747519, "episode": 41.0, "batch_reward": 0.12874709712713958, "critic_loss": 0.4034168565273285, "actor_loss": -21.540953086853026, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.05392670631409, "step": 41000}
{"episode_reward": 16.847532075555915, "episode": 42.0, "batch_reward": 0.12779845590889455, "critic_loss": 0.4455525953620672, "actor_loss": -22.778302089691163, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.84152317047119, "step": 42000}
{"episode_reward": 24.171221792328534, "episode": 43.0, "batch_reward": 0.12459865779429674, "critic_loss": 0.3615707802474499, "actor_loss": -23.341224922180174, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.837037563323975, "step": 43000}
{"episode_reward": 30.642076399896453, "episode": 44.0, "batch_reward": 0.12174342044442892, "critic_loss": 0.302439339235425, "actor_loss": -23.65967509841919, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.126577854156494, "step": 44000}
{"episode_reward": 29.268564529655524, "episode": 45.0, "batch_reward": 0.12029127121716737, "critic_loss": 0.26291936902701857, "actor_loss": -23.895591831207277, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.782891750335693, "step": 45000}
{"episode_reward": 27.65114159448866, "episode": 46.0, "batch_reward": 0.1184064952135086, "critic_loss": 0.2506132447645068, "actor_loss": -23.996982959747314, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.092331647872925, "step": 46000}
{"episode_reward": 21.73018215106182, "episode": 47.0, "batch_reward": 0.11587356343865395, "critic_loss": 0.23638889138400554, "actor_loss": -23.86647301483154, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.267597436904907, "step": 47000}
{"episode_reward": 15.611182835077141, "episode": 48.0, "batch_reward": 0.11469679476320743, "critic_loss": 0.21172053749859332, "actor_loss": -23.819945194244386, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.585384130477905, "step": 48000}
{"episode_reward": 25.302943172368565, "episode": 49.0, "batch_reward": 0.11637229607999325, "critic_loss": 0.24541786897182466, "actor_loss": -23.74937289428711, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.840604543685913, "step": 49000}
{"episode_reward": 418.1887546739325, "episode": 50.0, "batch_reward": 0.117501874409616, "critic_loss": 0.247730448551476, "actor_loss": -23.46792156982422, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.31068253517151, "step": 50000}
{"episode_reward": 58.778146409694614, "episode": 51.0, "batch_reward": 0.11788549714535475, "critic_loss": 0.26663411100953816, "actor_loss": -23.264017475128174, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.57466149330139, "step": 51000}
{"episode_reward": 76.4490373844697, "episode": 52.0, "batch_reward": 0.11933844631165266, "critic_loss": 0.28273210882395505, "actor_loss": -23.17407227706909, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.95517635345459, "step": 52000}
{"episode_reward": 377.402239743762, "episode": 53.0, "batch_reward": 0.12552118702977896, "critic_loss": 0.29800547218322754, "actor_loss": -23.352701629638673, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.388619422912598, "step": 53000}
{"episode_reward": 456.3604791684201, "episode": 54.0, "batch_reward": 0.1309137989655137, "critic_loss": 0.3230235289633274, "actor_loss": -23.4942003364563, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.51257848739624, "step": 54000}
{"episode_reward": 458.7227715725062, "episode": 55.0, "batch_reward": 0.13655106016248464, "critic_loss": 0.3281392029821873, "actor_loss": -23.848401420593262, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.794753313064575, "step": 55000}
{"episode_reward": 437.04425302877524, "episode": 56.0, "batch_reward": 0.14303466518223285, "critic_loss": 0.31191844917833805, "actor_loss": -24.18782166290283, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.78092360496521, "step": 56000}
{"episode_reward": 499.5960981608594, "episode": 57.0, "batch_reward": 0.14934125243872404, "critic_loss": 0.32254070763289927, "actor_loss": -24.49739019393921, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.576173305511475, "step": 57000}
{"episode_reward": 509.45997183752405, "episode": 58.0, "batch_reward": 0.15571235860139132, "critic_loss": 0.31237314408272504, "actor_loss": -24.9300443611145, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.071977138519287, "step": 58000}
{"episode_reward": 479.85811722197, "episode": 59.0, "batch_reward": 0.16186288739740848, "critic_loss": 0.32203745836764575, "actor_loss": -25.327592063903808, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.829285383224487, "step": 59000}
{"episode_reward": 480.6599092806367, "episode": 60.0, "batch_reward": 0.16514349199831485, "critic_loss": 0.3270163650661707, "actor_loss": -25.540625972747804, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.17936420440674, "step": 60000}
{"episode_reward": 405.8254366013936, "episode": 61.0, "batch_reward": 0.17109976667910815, "critic_loss": 0.3080812216848135, "actor_loss": -25.969746326446533, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.18297028541565, "step": 61000}
{"episode_reward": 499.9957509697027, "episode": 62.0, "batch_reward": 0.17689484202861785, "critic_loss": 0.3032361399531364, "actor_loss": -26.35232151412964, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.122844219207764, "step": 62000}
{"episode_reward": 513.2950784282305, "episode": 63.0, "batch_reward": 0.1818446911126375, "critic_loss": 0.32775191113352775, "actor_loss": -26.656901023864744, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.599876403808594, "step": 63000}
{"episode_reward": 509.2749050432105, "episode": 64.0, "batch_reward": 0.18637106017768382, "critic_loss": 0.3062430018559098, "actor_loss": -27.004028747558593, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.05333113670349, "step": 64000}
{"episode_reward": 487.9088391712442, "episode": 65.0, "batch_reward": 0.19097112235426902, "critic_loss": 0.2970209986716509, "actor_loss": -27.23706175994873, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.78879189491272, "step": 65000}
{"episode_reward": 440.6154528802316, "episode": 66.0, "batch_reward": 0.1950210479646921, "critic_loss": 0.2924402938857675, "actor_loss": -27.54608255004883, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.025115251541138, "step": 66000}
{"episode_reward": 475.64244758580355, "episode": 67.0, "batch_reward": 0.19990676863491535, "critic_loss": 0.2952683702260256, "actor_loss": -27.87384581756592, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.82638931274414, "step": 67000}
{"episode_reward": 456.83443772113696, "episode": 68.0, "batch_reward": 0.2027444543838501, "critic_loss": 0.3349828373640776, "actor_loss": -28.047034114837647, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.071601629257202, "step": 68000}
{"episode_reward": 472.7520554756575, "episode": 69.0, "batch_reward": 0.2053704907298088, "critic_loss": 0.3028913880810142, "actor_loss": -28.10679857635498, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.839638710021973, "step": 69000}
{"episode_reward": 292.7623445854548, "episode": 70.0, "batch_reward": 0.2075812507867813, "critic_loss": 0.30567709601670506, "actor_loss": -28.19471190261841, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.50939416885376, "step": 70000}
{"episode_reward": 291.10705270406964, "episode": 71.0, "batch_reward": 0.2099379302561283, "critic_loss": 0.32989191107451915, "actor_loss": -28.288219451904297, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.050384521484375, "step": 71000}
{"episode_reward": 458.6825141987536, "episode": 72.0, "batch_reward": 0.2128172340989113, "critic_loss": 0.3522238600552082, "actor_loss": -28.48985436630249, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.358140468597412, "step": 72000}
{"episode_reward": 482.97091430227215, "episode": 73.0, "batch_reward": 0.21690275594592096, "critic_loss": 0.34499841735512016, "actor_loss": -28.889640281677245, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.8270161151886, "step": 73000}
{"episode_reward": 459.2057712401917, "episode": 74.0, "batch_reward": 0.2174419963657856, "critic_loss": 0.34086455444991587, "actor_loss": -28.779657238006592, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.120790481567383, "step": 74000}
{"episode_reward": 192.31775265533943, "episode": 75.0, "batch_reward": 0.21842678421735764, "critic_loss": 0.3646295511871576, "actor_loss": -28.84061285018921, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.560789823532104, "step": 75000}
{"episode_reward": 505.79646713149225, "episode": 76.0, "batch_reward": 0.22346826453506946, "critic_loss": 0.36012158812582495, "actor_loss": -29.203866859436037, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.112887859344482, "step": 76000}
{"episode_reward": 491.1356960402106, "episode": 77.0, "batch_reward": 0.22749461767077445, "critic_loss": 0.342360147446394, "actor_loss": -29.490284812927246, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.645628929138184, "step": 77000}
{"episode_reward": 530.3001793587125, "episode": 78.0, "batch_reward": 0.23054524479806424, "critic_loss": 0.36770460473001004, "actor_loss": -29.752942821502685, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.404338359832764, "step": 78000}
{"episode_reward": 475.1716892988243, "episode": 79.0, "batch_reward": 0.23312559781968595, "critic_loss": 0.3685748986899853, "actor_loss": -29.906282554626465, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.255735158920288, "step": 79000}
{"episode_reward": 239.85227683731188, "episode": 80.0, "batch_reward": 0.2331997299939394, "critic_loss": 0.3809315986931324, "actor_loss": -29.970020481109618, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.561587810516357, "step": 80000}
{"episode_reward": 240.9501732259109, "episode": 81.0, "batch_reward": 0.2344238066971302, "critic_loss": 0.4127921180129051, "actor_loss": -29.862674503326417, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.14813494682312, "step": 81000}
{"episode_reward": 534.5318516610537, "episode": 82.0, "batch_reward": 0.23646992693841457, "critic_loss": 0.386797061085701, "actor_loss": -30.05038195800781, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.665207862854004, "step": 82000}
{"episode_reward": 552.0684656950799, "episode": 83.0, "batch_reward": 0.24128535798192025, "critic_loss": 0.37608787094056606, "actor_loss": -30.429006381988525, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.56905722618103, "step": 83000}
{"episode_reward": 506.09033474453526, "episode": 84.0, "batch_reward": 0.24430662167072295, "critic_loss": 0.3795753256827593, "actor_loss": -30.547814422607424, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.79882574081421, "step": 84000}
{"episode_reward": 473.4166749015565, "episode": 85.0, "batch_reward": 0.24738773381710052, "critic_loss": 0.37100372004508975, "actor_loss": -30.98850938415527, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.282559156417847, "step": 85000}
{"episode_reward": 518.9883530473884, "episode": 86.0, "batch_reward": 0.25073492267727854, "critic_loss": 0.38282012669742105, "actor_loss": -31.250315521240235, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.892216444015503, "step": 86000}
{"episode_reward": 515.6633452282464, "episode": 87.0, "batch_reward": 0.2536463139504194, "critic_loss": 0.3712111576497555, "actor_loss": -31.581341999053954, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.962251901626587, "step": 87000}
{"episode_reward": 546.7471393697823, "episode": 88.0, "batch_reward": 0.25679602593183515, "critic_loss": 0.3639392467588186, "actor_loss": -31.746150959014894, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.196383953094482, "step": 88000}
{"episode_reward": 537.5708673811357, "episode": 89.0, "batch_reward": 0.2598303734362125, "critic_loss": 0.3597644919976592, "actor_loss": -32.06023803329468, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.26429271697998, "step": 89000}
{"episode_reward": 549.7371601906298, "episode": 90.0, "batch_reward": 0.2646046285927296, "critic_loss": 0.3487762695401907, "actor_loss": -32.50286066818237, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.86392879486084, "step": 90000}
{"episode_reward": 553.2455884089031, "episode": 91.0, "batch_reward": 0.2664097748696804, "critic_loss": 0.3396384126096964, "actor_loss": -32.60261365890503, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.37708353996277, "step": 91000}
{"episode_reward": 540.7349812572746, "episode": 92.0, "batch_reward": 0.27038584449887276, "critic_loss": 0.3378882003128529, "actor_loss": -33.072532096862794, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.099975109100342, "step": 92000}
{"episode_reward": 536.1907401660828, "episode": 93.0, "batch_reward": 0.2732704952806234, "critic_loss": 0.32480859925597905, "actor_loss": -33.25686908340454, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.96045994758606, "step": 93000}
{"episode_reward": 522.7811550974093, "episode": 94.0, "batch_reward": 0.275571062669158, "critic_loss": 0.3444065418019891, "actor_loss": -33.521390995025634, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.123868227005005, "step": 94000}
{"episode_reward": 542.9602879587981, "episode": 95.0, "batch_reward": 0.2773945429772139, "critic_loss": 0.33386314412206414, "actor_loss": -33.802063018798826, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.91701054573059, "step": 95000}
{"episode_reward": 555.7678509048988, "episode": 96.0, "batch_reward": 0.28188468955457213, "critic_loss": 0.31400447826087474, "actor_loss": -34.043238101959226, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.028594970703125, "step": 96000}
{"episode_reward": 568.3105199136035, "episode": 97.0, "batch_reward": 0.28453702315688134, "critic_loss": 0.32578645542263984, "actor_loss": -34.43111736679077, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.71602201461792, "step": 97000}
{"episode_reward": 553.4290943124251, "episode": 98.0, "batch_reward": 0.286106696203351, "critic_loss": 0.34336654618382456, "actor_loss": -34.58409308242798, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.62960934638977, "step": 98000}
{"episode_reward": 556.1219858041845, "episode": 99.0, "batch_reward": 0.29049615205824375, "critic_loss": 0.32515074221044776, "actor_loss": -34.84017493057251, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.839036226272583, "step": 99000}
{"episode_reward": 593.5661914812619, "episode": 100.0, "batch_reward": 0.2934964773952961, "critic_loss": 0.31792595698684456, "actor_loss": -35.18196085739136, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.91132664680481, "step": 100000}
{"episode_reward": 574.3055511872675, "episode": 101.0, "batch_reward": 0.2959305412322283, "critic_loss": 0.30004429449141024, "actor_loss": -35.223731853485106, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.88988471031189, "step": 101000}
{"episode_reward": 582.4370522583929, "episode": 102.0, "batch_reward": 0.29756301683187486, "critic_loss": 0.3153690776154399, "actor_loss": -35.41697799301147, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.194942712783813, "step": 102000}
{"episode_reward": 555.2066506781255, "episode": 103.0, "batch_reward": 0.29984053403139116, "critic_loss": 0.2870117493867874, "actor_loss": -35.4843313293457, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.851184368133545, "step": 103000}
{"episode_reward": 560.3302973519833, "episode": 104.0, "batch_reward": 0.3033245269358158, "critic_loss": 0.29143816167861225, "actor_loss": -35.66215422821045, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.713831186294556, "step": 104000}
{"episode_reward": 528.1486637186412, "episode": 105.0, "batch_reward": 0.30481697387993334, "critic_loss": 0.3016142598837614, "actor_loss": -35.8627596206665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.45961880683899, "step": 105000}
{"episode_reward": 535.0682297330561, "episode": 106.0, "batch_reward": 0.30750702346861364, "critic_loss": 0.29519645614176987, "actor_loss": -36.12703483581543, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.422654628753662, "step": 106000}
{"episode_reward": 527.9156145358946, "episode": 107.0, "batch_reward": 0.31017287948727607, "critic_loss": 0.2944434270486236, "actor_loss": -36.32326426315308, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.02881407737732, "step": 107000}
{"episode_reward": 541.2114120796978, "episode": 108.0, "batch_reward": 0.3121452417820692, "critic_loss": 0.30514825085550545, "actor_loss": -36.55931982421875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.366827726364136, "step": 108000}
{"episode_reward": 539.1990539001124, "episode": 109.0, "batch_reward": 0.3142476099580526, "critic_loss": 0.3182290520071983, "actor_loss": -36.80562382888794, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.96423649787903, "step": 109000}
{"episode_reward": 512.5329506353344, "episode": 110.0, "batch_reward": 0.3165502620637417, "critic_loss": 0.327946718506515, "actor_loss": -37.02744944000244, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.5925555229187, "step": 110000}
{"episode_reward": 520.3669074705681, "episode": 111.0, "batch_reward": 0.31789713102579115, "critic_loss": 0.3277416013404727, "actor_loss": -37.19973637390137, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.92369985580444, "step": 111000}
{"episode_reward": 557.1932413397774, "episode": 112.0, "batch_reward": 0.31979522316157816, "critic_loss": 0.34869137305021286, "actor_loss": -37.529417388916016, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.259832620620728, "step": 112000}
{"episode_reward": 591.3548728111767, "episode": 113.0, "batch_reward": 0.3215849827528, "critic_loss": 0.30299961046874524, "actor_loss": -37.906450187683106, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.17160177230835, "step": 113000}
{"episode_reward": 543.900546565757, "episode": 114.0, "batch_reward": 0.3248357966095209, "critic_loss": 0.3404382400661707, "actor_loss": -38.26129287719726, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.10950541496277, "step": 114000}
{"episode_reward": 584.3024196418161, "episode": 115.0, "batch_reward": 0.3260213728696108, "critic_loss": 0.3316921564042568, "actor_loss": -38.255251152038575, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.460533142089844, "step": 115000}
{"episode_reward": 557.7543463568317, "episode": 116.0, "batch_reward": 0.3282337760925293, "critic_loss": 0.28144357293844224, "actor_loss": -38.38724502563477, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.64219069480896, "step": 116000}
{"episode_reward": 564.0438364504627, "episode": 117.0, "batch_reward": 0.3314976760149002, "critic_loss": 0.32206295043230054, "actor_loss": -38.62131623077393, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.323862075805664, "step": 117000}
{"episode_reward": 561.6170074991563, "episode": 118.0, "batch_reward": 0.33245507764816284, "critic_loss": 0.3186739910170436, "actor_loss": -38.682778663635254, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.339523792266846, "step": 118000}
{"episode_reward": 572.4233850161816, "episode": 119.0, "batch_reward": 0.33436737114191056, "critic_loss": 0.3046967916563153, "actor_loss": -38.75987344360352, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.125311136245728, "step": 119000}
{"episode_reward": 568.6946020135767, "episode": 120.0, "batch_reward": 0.3356043761074543, "critic_loss": 0.30837961081415416, "actor_loss": -38.94977619934082, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.585997819900513, "step": 120000}
{"episode_reward": 230.22311836329462, "episode": 121.0, "batch_reward": 0.33409014317393304, "critic_loss": 0.31777661050856115, "actor_loss": -38.82497192382812, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.5743772983551, "step": 121000}
{"episode_reward": 580.477524742941, "episode": 122.0, "batch_reward": 0.33840515053272247, "critic_loss": 0.3188305863589048, "actor_loss": -39.12997322082519, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.67842388153076, "step": 122000}
{"episode_reward": 535.1502694427575, "episode": 123.0, "batch_reward": 0.33973082280158995, "critic_loss": 0.3388396434932947, "actor_loss": -39.206430618286134, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.36586594581604, "step": 123000}
{"episode_reward": 593.6996557332118, "episode": 124.0, "batch_reward": 0.3416395428776741, "critic_loss": 0.3493019793182611, "actor_loss": -39.35695844268799, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.41982913017273, "step": 124000}
{"episode_reward": 567.7569092984063, "episode": 125.0, "batch_reward": 0.3421621450483799, "critic_loss": 0.297770961150527, "actor_loss": -39.3460086517334, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.30006432533264, "step": 125000}
{"episode_reward": 568.9886659216872, "episode": 126.0, "batch_reward": 0.34513175573945043, "critic_loss": 0.3522499239072204, "actor_loss": -39.600579345703125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.154834985733032, "step": 126000}
{"episode_reward": 572.0645442729572, "episode": 127.0, "batch_reward": 0.3464160006940365, "critic_loss": 0.3142887209057808, "actor_loss": -39.554399017333985, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.495872020721436, "step": 127000}
{"episode_reward": 593.0543756275076, "episode": 128.0, "batch_reward": 0.3480251017808914, "critic_loss": 0.3540814850926399, "actor_loss": -39.808570762634275, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.135786294937134, "step": 128000}
{"episode_reward": 573.328709552608, "episode": 129.0, "batch_reward": 0.35028303799033167, "critic_loss": 0.3308259285762906, "actor_loss": -39.81766239929199, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.917279958724976, "step": 129000}
{"episode_reward": 575.2275563036421, "episode": 130.0, "batch_reward": 0.35252846759557727, "critic_loss": 0.33024326591193676, "actor_loss": -40.02717769622803, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.941082000732422, "step": 130000}
{"episode_reward": 601.7093970993527, "episode": 131.0, "batch_reward": 0.35484959989786147, "critic_loss": 0.30616275072842836, "actor_loss": -40.09367178344726, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.77351117134094, "step": 131000}
{"episode_reward": 558.3027788504661, "episode": 132.0, "batch_reward": 0.3558026274740696, "critic_loss": 0.3011026484966278, "actor_loss": -40.181329696655276, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.944445371627808, "step": 132000}
{"episode_reward": 575.4389530179982, "episode": 133.0, "batch_reward": 0.3574165797829628, "critic_loss": 0.30589044111967084, "actor_loss": -40.29165352630615, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.36189079284668, "step": 133000}
{"episode_reward": 572.6326595804602, "episode": 134.0, "batch_reward": 0.35774844348430634, "critic_loss": 0.33616319052129984, "actor_loss": -40.41758924865723, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.432528495788574, "step": 134000}
{"episode_reward": 562.194180861945, "episode": 135.0, "batch_reward": 0.3597743667662144, "critic_loss": 0.32646316638588907, "actor_loss": -40.66778949737549, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.83093810081482, "step": 135000}
{"episode_reward": 570.0515855400499, "episode": 136.0, "batch_reward": 0.3635942249298096, "critic_loss": 0.32772042153030634, "actor_loss": -40.84506569671631, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.24248194694519, "step": 136000}
{"episode_reward": 575.4546047263887, "episode": 137.0, "batch_reward": 0.3641104693114757, "critic_loss": 0.31496255061030387, "actor_loss": -40.940138137817385, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.558897018432617, "step": 137000}
{"episode_reward": 603.6030180424494, "episode": 138.0, "batch_reward": 0.3653190398216248, "critic_loss": 0.31603811167925594, "actor_loss": -40.80629299163818, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.17908263206482, "step": 138000}
{"episode_reward": 569.3512618471907, "episode": 139.0, "batch_reward": 0.3676551668047905, "critic_loss": 0.3165198337286711, "actor_loss": -41.08002202606201, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.8438937664032, "step": 139000}
{"episode_reward": 605.9217035376756, "episode": 140.0, "batch_reward": 0.36704921805858615, "critic_loss": 0.32491728069633247, "actor_loss": -40.99124456787109, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.272772312164307, "step": 140000}
{"episode_reward": 573.311201502936, "episode": 141.0, "batch_reward": 0.371181439101696, "critic_loss": 0.3041916278898716, "actor_loss": -41.26032717895508, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.674540996551514, "step": 141000}
{"episode_reward": 552.7274491148153, "episode": 142.0, "batch_reward": 0.3718949412703514, "critic_loss": 0.3345491183698177, "actor_loss": -41.37917713165283, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.571852207183838, "step": 142000}
{"episode_reward": 552.5275588993144, "episode": 143.0, "batch_reward": 0.37215024247765544, "critic_loss": 0.3110383297726512, "actor_loss": -41.36021027374267, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.416107892990112, "step": 143000}
{"episode_reward": 565.1168219995795, "episode": 144.0, "batch_reward": 0.37426804181933404, "critic_loss": 0.34490729177743196, "actor_loss": -41.58503532409668, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.440667867660522, "step": 144000}
{"episode_reward": 580.8657783708488, "episode": 145.0, "batch_reward": 0.3747996675372124, "critic_loss": 0.3120348203629255, "actor_loss": -41.60109503936768, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.324815273284912, "step": 145000}
{"episode_reward": 536.7125701282883, "episode": 146.0, "batch_reward": 0.3759607098698616, "critic_loss": 0.3173225900828838, "actor_loss": -41.60825074005127, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.60003113746643, "step": 146000}
{"episode_reward": 554.1293898713777, "episode": 147.0, "batch_reward": 0.37633860456943513, "critic_loss": 0.3021932278200984, "actor_loss": -41.79545512390137, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.268994331359863, "step": 147000}
{"episode_reward": 570.0269433697008, "episode": 148.0, "batch_reward": 0.3802078860998154, "critic_loss": 0.2900741572901607, "actor_loss": -42.03868196868896, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.351874113082886, "step": 148000}
{"episode_reward": 561.2308039203924, "episode": 149.0, "batch_reward": 0.3800127813220024, "critic_loss": 0.30551927362382414, "actor_loss": -41.926759590148926, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.91330647468567, "step": 149000}
{"episode_reward": 428.70945811569567, "episode": 150.0, "batch_reward": 0.38040788331627845, "critic_loss": 0.33673126764595507, "actor_loss": -41.92854916381836, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
