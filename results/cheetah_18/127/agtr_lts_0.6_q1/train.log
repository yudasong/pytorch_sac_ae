{"episode_reward": 0.0, "episode": 1.0, "duration": 19.189780473709106, "step": 1000}
{"episode_reward": 7.051849146674556, "episode": 2.0, "duration": 1.6788196563720703, "step": 2000}
{"episode_reward": 365.4711839680396, "episode": 3.0, "batch_reward": 0.1808109236418426, "critic_loss": 0.5636557038275947, "actor_loss": -35.990393800037104, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 69.33847951889038, "step": 3000}
{"episode_reward": 97.66201191220334, "episode": 4.0, "batch_reward": 0.15787886836379766, "critic_loss": 1.00247013553977, "actor_loss": -33.583515544891355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.524877786636353, "step": 4000}
{"episode_reward": 174.37069481406198, "episode": 5.0, "batch_reward": 0.164246326982975, "critic_loss": 0.9188263474106788, "actor_loss": -33.721077632904056, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.248878717422485, "step": 5000}
{"episode_reward": 216.98474603825957, "episode": 6.0, "batch_reward": 0.1580621080622077, "critic_loss": 0.6906678786575794, "actor_loss": -33.44132945251465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.931544303894043, "step": 6000}
{"episode_reward": 7.339221696835965, "episode": 7.0, "batch_reward": 0.13383053727447985, "critic_loss": 0.5594239897727966, "actor_loss": -32.31961375427246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.426547050476074, "step": 7000}
{"episode_reward": 3.523434563823603, "episode": 8.0, "batch_reward": 0.11695932245254517, "critic_loss": 0.4551296993792057, "actor_loss": -31.46864312362671, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.337063550949097, "step": 8000}
{"episode_reward": 7.85254287619166, "episode": 9.0, "batch_reward": 0.10655479606240988, "critic_loss": 0.40906013996899127, "actor_loss": -30.662771476745604, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.28589677810669, "step": 9000}
{"episode_reward": 123.55119617802015, "episode": 10.0, "batch_reward": 0.11341116604954005, "critic_loss": 0.47978185042738913, "actor_loss": -30.30999150466919, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.980616807937622, "step": 10000}
{"episode_reward": 183.8560655810693, "episode": 11.0, "batch_reward": 0.1254091612547636, "critic_loss": 0.49424941995739935, "actor_loss": -30.332112228393555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.56761431694031, "step": 11000}
{"episode_reward": 275.1558841221866, "episode": 12.0, "batch_reward": 0.1388320359364152, "critic_loss": 0.48773770821094514, "actor_loss": -30.57584302520752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.153614044189453, "step": 12000}
{"episode_reward": 292.3344367271609, "episode": 13.0, "batch_reward": 0.1499665801078081, "critic_loss": 0.4873877275437117, "actor_loss": -30.570645496368407, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.473392963409424, "step": 13000}
{"episode_reward": 270.11517057123143, "episode": 14.0, "batch_reward": 0.1643004627674818, "critic_loss": 0.4401463004797697, "actor_loss": -30.84565975189209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.141730546951294, "step": 14000}
{"episode_reward": 368.9700928741582, "episode": 15.0, "batch_reward": 0.17390236899256706, "critic_loss": 0.42881940269470215, "actor_loss": -31.228523365020752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.432040452957153, "step": 15000}
{"episode_reward": 326.36600592874396, "episode": 16.0, "batch_reward": 0.18836123145371675, "critic_loss": 0.38049571964144707, "actor_loss": -31.40880601119995, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.623151779174805, "step": 16000}
{"episode_reward": 419.0816555557603, "episode": 17.0, "batch_reward": 0.2024934556633234, "critic_loss": 0.38336355331540106, "actor_loss": -31.834134925842285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.153663396835327, "step": 17000}
{"episode_reward": 403.48273774293347, "episode": 18.0, "batch_reward": 0.21467121417820453, "critic_loss": 0.38511645647883413, "actor_loss": -32.24075937271118, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.96722650527954, "step": 18000}
{"episode_reward": 425.99772043547455, "episode": 19.0, "batch_reward": 0.22423668532073499, "critic_loss": 0.3908306512087584, "actor_loss": -32.64912570953369, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.068267583847046, "step": 19000}
{"episode_reward": 365.9766904567146, "episode": 20.0, "batch_reward": 0.22526910695433616, "critic_loss": 0.40953997905552386, "actor_loss": -32.71470763015747, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.656250953674316, "step": 20000}
{"episode_reward": 83.28310629298198, "episode": 21.0, "batch_reward": 0.22648240903019906, "critic_loss": 0.36455759128928183, "actor_loss": -31.40701667404175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.50875926017761, "step": 21000}
{"episode_reward": 423.4167560189562, "episode": 22.0, "batch_reward": 0.2341607678681612, "critic_loss": 0.34537515735626223, "actor_loss": -32.47633869934082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.317908763885498, "step": 22000}
{"episode_reward": 433.0203953754649, "episode": 23.0, "batch_reward": 0.24440689405798913, "critic_loss": 0.32830325011909006, "actor_loss": -32.50693468093872, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.45474600791931, "step": 23000}
{"episode_reward": 435.150318630161, "episode": 24.0, "batch_reward": 0.2503051922917366, "critic_loss": 0.34783356231451035, "actor_loss": -33.13628255844116, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.5388023853302, "step": 24000}
{"episode_reward": 331.3441695733594, "episode": 25.0, "batch_reward": 0.25316910807788373, "critic_loss": 0.36059084491431714, "actor_loss": -33.4350683631897, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.281920433044434, "step": 25000}
{"episode_reward": 331.9832553678395, "episode": 26.0, "batch_reward": 0.2555125399082899, "critic_loss": 0.39500195561349394, "actor_loss": -33.31265280532837, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.367553234100342, "step": 26000}
{"episode_reward": 330.5588273118712, "episode": 27.0, "batch_reward": 0.26083034977316855, "critic_loss": 0.4121559306681156, "actor_loss": -33.29264989471436, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.25035858154297, "step": 27000}
{"episode_reward": 445.697167014816, "episode": 28.0, "batch_reward": 0.26679477003216745, "critic_loss": 0.4429018157124519, "actor_loss": -34.066593746185305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.293858766555786, "step": 28000}
{"episode_reward": 383.3441819958087, "episode": 29.0, "batch_reward": 0.27109361727535725, "critic_loss": 0.4704877057373524, "actor_loss": -33.99036918640137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.725614547729492, "step": 29000}
{"episode_reward": 425.43464654222436, "episode": 30.0, "batch_reward": 0.2768540625423193, "critic_loss": 0.47593849992752074, "actor_loss": -34.06883562850952, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.794317960739136, "step": 30000}
{"episode_reward": 405.1748629500855, "episode": 31.0, "batch_reward": 0.28082147088646886, "critic_loss": 0.4622320454567671, "actor_loss": -34.4784984703064, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.7167444229126, "step": 31000}
{"episode_reward": 439.2080497378699, "episode": 32.0, "batch_reward": 0.2867919805943966, "critic_loss": 0.4898630786240101, "actor_loss": -35.027943187713625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.927844524383545, "step": 32000}
{"episode_reward": 456.30872438086703, "episode": 33.0, "batch_reward": 0.29099957130849363, "critic_loss": 0.4748962736725807, "actor_loss": -35.248905986785886, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.692976474761963, "step": 33000}
{"episode_reward": 272.9452117644427, "episode": 34.0, "batch_reward": 0.2916836777329445, "critic_loss": 0.49014690166711805, "actor_loss": -35.04560754013062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.610645532608032, "step": 34000}
{"episode_reward": 487.98204487034263, "episode": 35.0, "batch_reward": 0.2973150225579739, "critic_loss": 0.5058981073498726, "actor_loss": -35.62882448196411, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.17579674720764, "step": 35000}
{"episode_reward": 434.34449859575426, "episode": 36.0, "batch_reward": 0.30107298734784127, "critic_loss": 0.516055863916874, "actor_loss": -36.32483666229248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.78005075454712, "step": 36000}
{"episode_reward": 465.6482466599353, "episode": 37.0, "batch_reward": 0.30498853585124014, "critic_loss": 0.5327340796887875, "actor_loss": -35.9343632850647, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.87367582321167, "step": 37000}
{"episode_reward": 465.5319196530167, "episode": 38.0, "batch_reward": 0.30650433081388473, "critic_loss": 0.5924881953001022, "actor_loss": -35.997853637695314, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.30845284461975, "step": 38000}
{"episode_reward": 157.70042631145944, "episode": 39.0, "batch_reward": 0.30574010574817656, "critic_loss": 0.5373225974142551, "actor_loss": -35.85498106765747, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.161351680755615, "step": 39000}
{"episode_reward": 431.74714117911765, "episode": 40.0, "batch_reward": 0.3098754639774561, "critic_loss": 0.563895588338375, "actor_loss": -36.285985530853274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.18706750869751, "step": 40000}
{"episode_reward": 473.4679391085588, "episode": 41.0, "batch_reward": 0.3123156425356865, "critic_loss": 0.573941112101078, "actor_loss": -35.89577032470703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.472949743270874, "step": 41000}
{"episode_reward": 467.0849681943082, "episode": 42.0, "batch_reward": 0.3137770833969116, "critic_loss": 0.5352456632554531, "actor_loss": -36.341022682189944, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.718159914016724, "step": 42000}
{"episode_reward": 112.83412201532488, "episode": 43.0, "batch_reward": 0.3119545300900936, "critic_loss": 0.5273346975445747, "actor_loss": -36.41364259719849, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.16035008430481, "step": 43000}
{"episode_reward": 479.08717381107755, "episode": 44.0, "batch_reward": 0.315852260351181, "critic_loss": 0.5427766663134098, "actor_loss": -37.17864043045044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.122222661972046, "step": 44000}
{"episode_reward": 485.96583132294296, "episode": 45.0, "batch_reward": 0.31967633950710295, "critic_loss": 0.5644734505712986, "actor_loss": -37.05023820495605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.77771282196045, "step": 45000}
{"episode_reward": 485.0880024493543, "episode": 46.0, "batch_reward": 0.32303027975559234, "critic_loss": 0.5607947423160076, "actor_loss": -36.65875833129883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.593029022216797, "step": 46000}
{"episode_reward": 502.49182937801805, "episode": 47.0, "batch_reward": 0.32745290502905844, "critic_loss": 0.5703587652146817, "actor_loss": -37.25658150100708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.069376945495605, "step": 47000}
{"episode_reward": 494.4728468523085, "episode": 48.0, "batch_reward": 0.3304591439664364, "critic_loss": 0.5761940278410912, "actor_loss": -37.422865844726566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.4910728931427, "step": 48000}
{"episode_reward": 465.6998164267083, "episode": 49.0, "batch_reward": 0.33271955120563507, "critic_loss": 0.5500311831533908, "actor_loss": -38.22452185058594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.994134664535522, "step": 49000}
{"episode_reward": 464.2854623101896, "episode": 50.0, "batch_reward": 0.33530121755599973, "critic_loss": 0.5883677569627762, "actor_loss": -38.12726597213745, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.019684076309204, "step": 50000}
{"episode_reward": 433.64716688979706, "episode": 51.0, "batch_reward": 0.3381451157927513, "critic_loss": 0.5658776643872261, "actor_loss": -38.33641728973389, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.21061444282532, "step": 51000}
{"episode_reward": 508.8709604463153, "episode": 52.0, "batch_reward": 0.3416268673837185, "critic_loss": 0.6222094867527485, "actor_loss": -38.21240275192261, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.22806215286255, "step": 52000}
{"episode_reward": 467.958890704893, "episode": 53.0, "batch_reward": 0.34373406746983526, "critic_loss": 0.5821017735600471, "actor_loss": -38.84011897659302, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.0172598361969, "step": 53000}
{"episode_reward": 545.1941017123025, "episode": 54.0, "batch_reward": 0.34774268940091135, "critic_loss": 0.5910750935077668, "actor_loss": -39.45328200531006, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.945406913757324, "step": 54000}
{"episode_reward": 449.42173125633406, "episode": 55.0, "batch_reward": 0.3493111092150211, "critic_loss": 0.5960067299306393, "actor_loss": -39.012338985443115, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.200819492340088, "step": 55000}
{"episode_reward": 504.9936967561987, "episode": 56.0, "batch_reward": 0.3515465567111969, "critic_loss": 0.6167974190711976, "actor_loss": -39.28463283157349, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.637697219848633, "step": 56000}
{"episode_reward": 492.0610910809169, "episode": 57.0, "batch_reward": 0.3550612127482891, "critic_loss": 0.6028966355323792, "actor_loss": -39.4477060508728, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.413720846176147, "step": 57000}
{"episode_reward": 481.4038302558168, "episode": 58.0, "batch_reward": 0.3574011469483376, "critic_loss": 0.6138068076074124, "actor_loss": -39.721348518371585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.247678756713867, "step": 58000}
{"episode_reward": 527.2315053340246, "episode": 59.0, "batch_reward": 0.3598466301858425, "critic_loss": 0.6021613509058953, "actor_loss": -40.0503711013794, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.921021461486816, "step": 59000}
{"episode_reward": 486.8817374156295, "episode": 60.0, "batch_reward": 0.36213719642162323, "critic_loss": 0.6456359657943249, "actor_loss": -40.43620407485962, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.746503114700317, "step": 60000}
{"episode_reward": 461.3693611964079, "episode": 61.0, "batch_reward": 0.36378305494785307, "critic_loss": 0.6883861554861068, "actor_loss": -40.149083206176755, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.935521364212036, "step": 61000}
{"episode_reward": 494.9223696111353, "episode": 62.0, "batch_reward": 0.36637717121839525, "critic_loss": 0.6593968542814255, "actor_loss": -40.78517461776733, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.940115690231323, "step": 62000}
{"episode_reward": 521.193610951225, "episode": 63.0, "batch_reward": 0.36809149557352067, "critic_loss": 0.6550560732781887, "actor_loss": -40.54624486541748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.21276545524597, "step": 63000}
{"episode_reward": 450.87294151602896, "episode": 64.0, "batch_reward": 0.3690655752122402, "critic_loss": 0.670206449508667, "actor_loss": -40.82701476287842, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.75055241584778, "step": 64000}
{"episode_reward": 508.3658711165851, "episode": 65.0, "batch_reward": 0.37133264538645744, "critic_loss": 0.6508326673209667, "actor_loss": -41.12958353424072, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.141138315200806, "step": 65000}
{"episode_reward": 450.44199583975035, "episode": 66.0, "batch_reward": 0.3730015514791012, "critic_loss": 0.7190824375450611, "actor_loss": -41.14425196838379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.26980233192444, "step": 66000}
{"episode_reward": 516.5553941203709, "episode": 67.0, "batch_reward": 0.37503244149684906, "critic_loss": 0.6656537911891938, "actor_loss": -41.53815384674072, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.927485704421997, "step": 67000}
{"episode_reward": 510.8215672912572, "episode": 68.0, "batch_reward": 0.3775581361949444, "critic_loss": 0.6682135998606682, "actor_loss": -42.070766723632815, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.943717002868652, "step": 68000}
{"episode_reward": 523.9154213229856, "episode": 69.0, "batch_reward": 0.3789772077202797, "critic_loss": 0.6719872813522816, "actor_loss": -41.60364585876465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.62312650680542, "step": 69000}
{"episode_reward": 532.2334460704391, "episode": 70.0, "batch_reward": 0.3824119846522808, "critic_loss": 0.6382168453931808, "actor_loss": -41.78147267913818, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.37530279159546, "step": 70000}
{"episode_reward": 495.92013068949046, "episode": 71.0, "batch_reward": 0.3834845913052559, "critic_loss": 0.6714541750848293, "actor_loss": -41.85856162261963, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.9328339099884, "step": 71000}
{"episode_reward": 514.9572924313142, "episode": 72.0, "batch_reward": 0.3852707172930241, "critic_loss": 0.6901669623553753, "actor_loss": -42.23405149078369, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.844486474990845, "step": 72000}
{"episode_reward": 504.1399033478003, "episode": 73.0, "batch_reward": 0.3865844534337521, "critic_loss": 0.6236309992671013, "actor_loss": -42.4644379196167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.14780831336975, "step": 73000}
{"episode_reward": 520.5437284845084, "episode": 74.0, "batch_reward": 0.38843262860178945, "critic_loss": 0.6350656750798226, "actor_loss": -42.58596588897705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.949297428131104, "step": 74000}
{"episode_reward": 521.2244396190645, "episode": 75.0, "batch_reward": 0.38979587170481683, "critic_loss": 0.6297663272023201, "actor_loss": -42.74636248779297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.934553146362305, "step": 75000}
{"episode_reward": 511.2928595144325, "episode": 76.0, "batch_reward": 0.39169750356674193, "critic_loss": 0.6296518405675888, "actor_loss": -42.903031929016116, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.067198276519775, "step": 76000}
{"episode_reward": 474.07980838498776, "episode": 77.0, "batch_reward": 0.3928548141717911, "critic_loss": 0.6308835545778274, "actor_loss": -43.09896771240234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.155735969543457, "step": 77000}
{"episode_reward": 521.8542726702148, "episode": 78.0, "batch_reward": 0.3946218129992485, "critic_loss": 0.629695401608944, "actor_loss": -43.14215087890625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.889926433563232, "step": 78000}
{"episode_reward": 518.065031696219, "episode": 79.0, "batch_reward": 0.39651835525035856, "critic_loss": 0.6728595259189606, "actor_loss": -43.592100723266604, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.372191905975342, "step": 79000}
{"episode_reward": 546.6570021927437, "episode": 80.0, "batch_reward": 0.3983722747266293, "critic_loss": 0.6611547013223171, "actor_loss": -43.80402792358399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.042251586914062, "step": 80000}
{"episode_reward": 532.8817140308212, "episode": 81.0, "batch_reward": 0.40009712854027746, "critic_loss": 0.6736045836508274, "actor_loss": -43.76650012969971, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.88600254058838, "step": 81000}
{"episode_reward": 489.11904983614454, "episode": 82.0, "batch_reward": 0.40069472101330755, "critic_loss": 0.6314222762584686, "actor_loss": -43.58333707427978, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.295379877090454, "step": 82000}
{"episode_reward": 532.520513475046, "episode": 83.0, "batch_reward": 0.403350291788578, "critic_loss": 0.6860354576408864, "actor_loss": -44.180606552124026, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.44410014152527, "step": 83000}
{"episode_reward": 497.1496396980158, "episode": 84.0, "batch_reward": 0.4037585309445858, "critic_loss": 0.6547431723475456, "actor_loss": -44.2837596206665, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.23966884613037, "step": 84000}
{"episode_reward": 541.4376164685672, "episode": 85.0, "batch_reward": 0.4044181776940823, "critic_loss": 0.6925498175323009, "actor_loss": -44.191835342407224, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.567650318145752, "step": 85000}
{"episode_reward": 541.2234344929839, "episode": 86.0, "batch_reward": 0.40703259691596033, "critic_loss": 0.6696287791728973, "actor_loss": -44.310783599853515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.81299352645874, "step": 86000}
{"episode_reward": 554.6155475216451, "episode": 87.0, "batch_reward": 0.40855562037229537, "critic_loss": 0.662514391630888, "actor_loss": -44.82078251647949, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.829603910446167, "step": 87000}
{"episode_reward": 521.1596967401555, "episode": 88.0, "batch_reward": 0.41000098893046377, "critic_loss": 0.6343553595244884, "actor_loss": -44.44545625305176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.757754802703857, "step": 88000}
{"episode_reward": 499.9324333090957, "episode": 89.0, "batch_reward": 0.41129682594537736, "critic_loss": 0.6406768825054169, "actor_loss": -44.47691900634766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.956499576568604, "step": 89000}
{"episode_reward": 542.1984992487539, "episode": 90.0, "batch_reward": 0.41285276141762733, "critic_loss": 0.6543028815090657, "actor_loss": -44.69554988861084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.376604080200195, "step": 90000}
{"episode_reward": 441.74684725221306, "episode": 91.0, "batch_reward": 0.4124293794929981, "critic_loss": 0.7031322917640209, "actor_loss": -44.67302500152588, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.37760066986084, "step": 91000}
{"episode_reward": 556.6950074099651, "episode": 92.0, "batch_reward": 0.41430947118997574, "critic_loss": 0.6737688930928707, "actor_loss": -45.1571901550293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.309563636779785, "step": 92000}
{"episode_reward": 529.6699713266246, "episode": 93.0, "batch_reward": 0.41590052369236946, "critic_loss": 0.6509692167639732, "actor_loss": -45.00316844177246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.239262342453003, "step": 93000}
{"episode_reward": 566.5913283655, "episode": 94.0, "batch_reward": 0.41757409220933916, "critic_loss": 0.6728668113052845, "actor_loss": -45.527045906066895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.286484003067017, "step": 94000}
{"episode_reward": 535.3014217833596, "episode": 95.0, "batch_reward": 0.4185719219148159, "critic_loss": 0.6927405406236649, "actor_loss": -45.769545143127445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.111523628234863, "step": 95000}
{"episode_reward": 522.9972033221746, "episode": 96.0, "batch_reward": 0.42019137305021287, "critic_loss": 0.6846655759215355, "actor_loss": -45.53562063598633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.89910578727722, "step": 96000}
{"episode_reward": 509.8272629099364, "episode": 97.0, "batch_reward": 0.42034554335474966, "critic_loss": 0.6892330665886403, "actor_loss": -45.38323444366455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.174390077590942, "step": 97000}
{"episode_reward": 544.5084987569127, "episode": 98.0, "batch_reward": 0.42079374265670777, "critic_loss": 0.6742342504560948, "actor_loss": -46.03155165863037, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.52268385887146, "step": 98000}
{"episode_reward": 492.70601852263127, "episode": 99.0, "batch_reward": 0.4221100116968155, "critic_loss": 0.7015354248285294, "actor_loss": -45.624669219970706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.689176082611084, "step": 99000}
{"episode_reward": 520.6564391899442, "episode": 100.0, "batch_reward": 0.42348710817098617, "critic_loss": 0.7062507675290107, "actor_loss": -45.914394371032714, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.147719860076904, "step": 100000}
{"episode_reward": 529.2899016779405, "episode": 101.0, "batch_reward": 0.4247348028421402, "critic_loss": 0.6876714645624161, "actor_loss": -45.92429251861572, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.66864562034607, "step": 101000}
{"episode_reward": 552.4615169923794, "episode": 102.0, "batch_reward": 0.42626640394330023, "critic_loss": 0.6599107025563717, "actor_loss": -46.19520567321777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.493682146072388, "step": 102000}
{"episode_reward": 522.768743884351, "episode": 103.0, "batch_reward": 0.426402112364769, "critic_loss": 0.6484457255899906, "actor_loss": -46.27185846710205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.250184059143066, "step": 103000}
{"episode_reward": 514.8407793729539, "episode": 104.0, "batch_reward": 0.42742943450808524, "critic_loss": 0.6419646328091622, "actor_loss": -46.05070597839355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.67630434036255, "step": 104000}
{"episode_reward": 554.671198616486, "episode": 105.0, "batch_reward": 0.4294051846563816, "critic_loss": 0.6343598693013192, "actor_loss": -46.24528628540039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.993652820587158, "step": 105000}
{"episode_reward": 521.4246051648003, "episode": 106.0, "batch_reward": 0.4295815733373165, "critic_loss": 0.5996015948355198, "actor_loss": -46.361478843688964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.841190576553345, "step": 106000}
{"episode_reward": 485.23108323314847, "episode": 107.0, "batch_reward": 0.4308743294477463, "critic_loss": 0.6164727970063686, "actor_loss": -46.314631858825685, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.424494981765747, "step": 107000}
{"episode_reward": 543.6712444043116, "episode": 108.0, "batch_reward": 0.43081797751784323, "critic_loss": 0.6221566091179848, "actor_loss": -46.908920066833495, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.016181230545044, "step": 108000}
{"episode_reward": 492.5208678821932, "episode": 109.0, "batch_reward": 0.43206665882468226, "critic_loss": 0.6547163353562355, "actor_loss": -46.69772465515137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.980896472930908, "step": 109000}
{"episode_reward": 517.2644835726952, "episode": 110.0, "batch_reward": 0.43242904299497603, "critic_loss": 0.6344954236745834, "actor_loss": -47.14037804412842, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.48593783378601, "step": 110000}
{"episode_reward": 516.1167063524525, "episode": 111.0, "batch_reward": 0.43318942132592203, "critic_loss": 0.660816143065691, "actor_loss": -46.72970568084717, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.93415427207947, "step": 111000}
{"episode_reward": 524.2014071116243, "episode": 112.0, "batch_reward": 0.4335700607895851, "critic_loss": 0.6686140761822462, "actor_loss": -47.13177857971191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.02328610420227, "step": 112000}
{"episode_reward": 523.0492055833306, "episode": 113.0, "batch_reward": 0.43490381291508673, "critic_loss": 0.6832690986692905, "actor_loss": -46.92933424377441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.98014259338379, "step": 113000}
{"episode_reward": 546.607526086779, "episode": 114.0, "batch_reward": 0.4359402087032795, "critic_loss": 0.715924849063158, "actor_loss": -47.18641788482666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.036808252334595, "step": 114000}
{"episode_reward": 507.7221766866388, "episode": 115.0, "batch_reward": 0.43711447605490683, "critic_loss": 0.6765656473636628, "actor_loss": -47.256351371765135, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.83373522758484, "step": 115000}
{"episode_reward": 531.1865776031684, "episode": 116.0, "batch_reward": 0.43796575948596, "critic_loss": 0.667153559088707, "actor_loss": -47.23972589111328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.745238542556763, "step": 116000}
{"episode_reward": 555.9821615508889, "episode": 117.0, "batch_reward": 0.43889146667718887, "critic_loss": 0.6811274191141129, "actor_loss": -47.173924797058106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.408270359039307, "step": 117000}
{"episode_reward": 524.2548902013822, "episode": 118.0, "batch_reward": 0.4399692562520504, "critic_loss": 0.659503742069006, "actor_loss": -47.350197456359865, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.810394287109375, "step": 118000}
{"episode_reward": 509.56150503094807, "episode": 119.0, "batch_reward": 0.4400493795573711, "critic_loss": 0.6397456419020892, "actor_loss": -47.25394761657715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.907036781311035, "step": 119000}
{"episode_reward": 536.6129381608418, "episode": 120.0, "batch_reward": 0.440158822953701, "critic_loss": 0.640959547817707, "actor_loss": -47.40713275146484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.654082775115967, "step": 120000}
{"episode_reward": 526.5624476900074, "episode": 121.0, "batch_reward": 0.4412344076037407, "critic_loss": 0.642468443006277, "actor_loss": -47.55898216247559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.884607791900635, "step": 121000}
{"episode_reward": 530.6507569766834, "episode": 122.0, "batch_reward": 0.44255790624022484, "critic_loss": 0.6583881717026233, "actor_loss": -47.74897334289551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.045804738998413, "step": 122000}
{"episode_reward": 552.0406368347872, "episode": 123.0, "batch_reward": 0.44307877305150034, "critic_loss": 0.6359271687865258, "actor_loss": -47.789332878112795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.205405473709106, "step": 123000}
{"episode_reward": 554.0322864747137, "episode": 124.0, "batch_reward": 0.44350306460261346, "critic_loss": 0.6199586549550294, "actor_loss": -47.96551591491699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.503591537475586, "step": 124000}
{"episode_reward": 543.8425158818063, "episode": 125.0, "batch_reward": 0.4436859347820282, "critic_loss": 0.5901721844375134, "actor_loss": -47.79013788604736, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.290284633636475, "step": 125000}
{"episode_reward": 516.3158443683465, "episode": 126.0, "batch_reward": 0.44528204506635666, "critic_loss": 0.5705005805343389, "actor_loss": -48.049474838256835, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.18818426132202, "step": 126000}
{"episode_reward": 514.6985554376422, "episode": 127.0, "batch_reward": 0.44569701090455055, "critic_loss": 0.6162006661295891, "actor_loss": -48.09138294219971, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.972238779067993, "step": 127000}
{"episode_reward": 532.7812241953118, "episode": 128.0, "batch_reward": 0.4464040772020817, "critic_loss": 0.6097812303602695, "actor_loss": -48.10575518798828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.962451696395874, "step": 128000}
{"episode_reward": 501.91868933654365, "episode": 129.0, "batch_reward": 0.4460521259009838, "critic_loss": 0.5851099429726601, "actor_loss": -48.01914158630371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.638180255889893, "step": 129000}
{"episode_reward": 514.8460839874102, "episode": 130.0, "batch_reward": 0.4472551248967648, "critic_loss": 0.6032794483751058, "actor_loss": -48.08842541503906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.533590078353882, "step": 130000}
{"episode_reward": 543.1138394153331, "episode": 131.0, "batch_reward": 0.4481386947929859, "critic_loss": 0.5823269541710615, "actor_loss": -47.9801563949585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.436328649520874, "step": 131000}
{"episode_reward": 534.3765917173653, "episode": 132.0, "batch_reward": 0.44869460493326185, "critic_loss": 0.6039669033586978, "actor_loss": -48.34319794464111, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.194235801696777, "step": 132000}
{"episode_reward": 524.4916712104149, "episode": 133.0, "batch_reward": 0.4496628026664257, "critic_loss": 0.5666824718415737, "actor_loss": -48.20246775817871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.929072856903076, "step": 133000}
{"episode_reward": 546.5460635214802, "episode": 134.0, "batch_reward": 0.4504574343562126, "critic_loss": 0.6047283395826817, "actor_loss": -48.32331079864502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.037027835845947, "step": 134000}
{"episode_reward": 552.2687148205167, "episode": 135.0, "batch_reward": 0.45015014109015467, "critic_loss": 0.6022779372632503, "actor_loss": -48.53752171325684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.082913398742676, "step": 135000}
{"episode_reward": 521.4354149558554, "episode": 136.0, "batch_reward": 0.4516735853850842, "critic_loss": 0.5801871863007545, "actor_loss": -48.64816805267334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.52472162246704, "step": 136000}
{"episode_reward": 498.6021846820723, "episode": 137.0, "batch_reward": 0.45180895882844924, "critic_loss": 0.5756105060130358, "actor_loss": -48.55300919342041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.50903582572937, "step": 137000}
{"episode_reward": 513.1959178647213, "episode": 138.0, "batch_reward": 0.4525103388726711, "critic_loss": 0.6089131691753864, "actor_loss": -48.64350873565674, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.382208824157715, "step": 138000}
{"episode_reward": 557.2791082139322, "episode": 139.0, "batch_reward": 0.4525604435503483, "critic_loss": 0.5962297114133834, "actor_loss": -48.61613493347168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.655006408691406, "step": 139000}
{"episode_reward": 541.6379772306022, "episode": 140.0, "batch_reward": 0.45219289088249204, "critic_loss": 0.6023397728949785, "actor_loss": -48.81696583557129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.808480262756348, "step": 140000}
{"episode_reward": 515.854448999317, "episode": 141.0, "batch_reward": 0.4551389181315899, "critic_loss": 0.5888305749744177, "actor_loss": -48.82265162658691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.715585470199585, "step": 141000}
{"episode_reward": 516.5854234143657, "episode": 142.0, "batch_reward": 0.4543735926747322, "critic_loss": 0.5740770881772042, "actor_loss": -48.816928833007815, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.590997219085693, "step": 142000}
{"episode_reward": 295.9498220880857, "episode": 143.0, "batch_reward": 0.4533749622106552, "critic_loss": 0.5928843683153391, "actor_loss": -48.66022612762451, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.175707817077637, "step": 143000}
{"episode_reward": 548.1959358049353, "episode": 144.0, "batch_reward": 0.4539921434521675, "critic_loss": 0.575218603014946, "actor_loss": -48.86836273956299, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.189689874649048, "step": 144000}
{"episode_reward": 526.5035492821899, "episode": 145.0, "batch_reward": 0.4547645568549633, "critic_loss": 0.5959308827370405, "actor_loss": -48.90557427215576, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.865126848220825, "step": 145000}
{"episode_reward": 533.9289908723636, "episode": 146.0, "batch_reward": 0.454138499468565, "critic_loss": 0.5642386537492275, "actor_loss": -48.69316482543945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.369189739227295, "step": 146000}
{"episode_reward": 547.7111041890399, "episode": 147.0, "batch_reward": 0.4546834087073803, "critic_loss": 0.5728509489744902, "actor_loss": -48.851863945007324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.006730794906616, "step": 147000}
{"episode_reward": 541.0593655522583, "episode": 148.0, "batch_reward": 0.45665017384290696, "critic_loss": 0.5723398367464543, "actor_loss": -49.10804923248291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.172084093093872, "step": 148000}
{"episode_reward": 503.33643051694554, "episode": 149.0, "batch_reward": 0.4561719175875187, "critic_loss": 0.5671340642422438, "actor_loss": -49.0314391708374, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.653095245361328, "step": 149000}
