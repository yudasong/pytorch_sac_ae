{"episode_reward": 0.0, "episode": 1.0, "duration": 18.67618179321289, "step": 1000}
{"episode_reward": 7.051849146674556, "episode": 2.0, "duration": 1.516458511352539, "step": 2000}
{"episode_reward": 365.4711839680396, "episode": 3.0, "batch_reward": 0.17479153769230515, "critic_loss": 0.018292556443304773, "actor_loss": -30.024695154063316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.936421155929565, "step": 3000}
{"episode_reward": 2.468801858456115, "episode": 4.0, "batch_reward": 0.10852946476638317, "critic_loss": 0.008790434451773762, "actor_loss": -27.616843102931977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.556034326553345, "step": 4000}
{"episode_reward": 1.8175285005734383, "episode": 5.0, "batch_reward": 0.08437088515982032, "critic_loss": 0.006036192452767864, "actor_loss": -25.530052769184113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.781476974487305, "step": 5000}
{"episode_reward": 1.728944321199985, "episode": 6.0, "batch_reward": 0.06852242193743587, "critic_loss": 0.00675659752311185, "actor_loss": -26.200137583494186, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.47730827331543, "step": 6000}
{"episode_reward": 1.83304294418867, "episode": 7.0, "batch_reward": 0.05861303737387061, "critic_loss": 0.006853890118654817, "actor_loss": -25.342479746818544, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.389601230621338, "step": 7000}
{"episode_reward": 2.4920234295847625, "episode": 8.0, "batch_reward": 0.051501962557435034, "critic_loss": 0.006936118294484914, "actor_loss": -24.94697195124626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.35143494606018, "step": 8000}
{"episode_reward": 3.21937809579581, "episode": 9.0, "batch_reward": 0.04554062889330089, "critic_loss": 0.0052171781616052616, "actor_loss": -25.18887398982048, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.68338441848755, "step": 9000}
{"episode_reward": 2.4397796585721223, "episode": 10.0, "batch_reward": 0.04120370679441839, "critic_loss": 0.005004075243021362, "actor_loss": -25.276877686738967, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.45351815223694, "step": 10000}
{"episode_reward": 2.258088404418314, "episode": 11.0, "batch_reward": 0.0378341524284333, "critic_loss": 0.005870612606056966, "actor_loss": -24.932416060686112, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.21674609184265, "step": 11000}
{"episode_reward": 2.507844698067068, "episode": 12.0, "batch_reward": 0.03398797262459993, "critic_loss": 0.004591895055084024, "actor_loss": -24.697674484968186, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.6834716796875, "step": 12000}
{"episode_reward": 2.854697682795334, "episode": 13.0, "batch_reward": 0.031556744371540844, "critic_loss": 0.004558528750319965, "actor_loss": -24.631655623793602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.480956554412842, "step": 13000}
{"episode_reward": 2.7566488136299587, "episode": 14.0, "batch_reward": 0.029767399759031834, "critic_loss": 0.003824546578922309, "actor_loss": -24.268373438954352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.469261407852173, "step": 14000}
{"episode_reward": 2.8001847701573865, "episode": 15.0, "batch_reward": 0.02750995723763481, "critic_loss": 0.00387565203475242, "actor_loss": -25.002325225591658, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.957473754882812, "step": 15000}
{"episode_reward": 2.0300075405049722, "episode": 16.0, "batch_reward": 0.026078206630889327, "critic_loss": 0.0034203517268615543, "actor_loss": -24.554257729053496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.918023586273193, "step": 16000}
{"episode_reward": 2.74277266493045, "episode": 17.0, "batch_reward": 0.02456147461733781, "critic_loss": 0.004306523628882133, "actor_loss": -23.911551375627518, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.503941297531128, "step": 17000}
{"episode_reward": 1.7547700806255628, "episode": 18.0, "batch_reward": 0.023874041534028948, "critic_loss": 0.0033860702985548416, "actor_loss": -24.2746740680933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.840851545333862, "step": 18000}
{"episode_reward": 3.488025040020188, "episode": 19.0, "batch_reward": 0.022507979782298206, "critic_loss": 0.0028956031419074863, "actor_loss": -24.536116042852402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.460323572158813, "step": 19000}
{"episode_reward": 2.8591638265982238, "episode": 20.0, "batch_reward": 0.02135007644817233, "critic_loss": 0.0031532095768488943, "actor_loss": -25.31245555639267, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.836883068084717, "step": 20000}
{"episode_reward": 2.1989933290276675, "episode": 21.0, "batch_reward": 0.019960532599128784, "critic_loss": 0.0029009113498032093, "actor_loss": -23.449936231136324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.49373650550842, "step": 21000}
{"episode_reward": 2.4289430625208013, "episode": 22.0, "batch_reward": 0.019598040238954128, "critic_loss": 0.002824177456277539, "actor_loss": -24.433197552323342, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.510339736938477, "step": 22000}
{"episode_reward": 3.597864388591334, "episode": 23.0, "batch_reward": 0.018895594222005457, "critic_loss": 0.002811544633223093, "actor_loss": -23.759789276361467, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.523719787597656, "step": 23000}
{"episode_reward": 2.716421957610729, "episode": 24.0, "batch_reward": 0.018033444826724008, "critic_loss": 0.002656839426155784, "actor_loss": -24.329885423779487, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.406468152999878, "step": 24000}
{"episode_reward": 2.640200180919085, "episode": 25.0, "batch_reward": 0.017719438808970152, "critic_loss": 0.0025387846160883783, "actor_loss": -24.797184036135672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.86318349838257, "step": 25000}
{"episode_reward": 2.792624857853972, "episode": 26.0, "batch_reward": 0.017002930176910014, "critic_loss": 0.0024044035186379913, "actor_loss": -23.875044670641422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.557036638259888, "step": 26000}
{"episode_reward": 2.571064650976764, "episode": 27.0, "batch_reward": 0.01677254336560145, "critic_loss": 0.002347945226938464, "actor_loss": -24.26857431870699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.44407820701599, "step": 27000}
{"episode_reward": 2.6630920286510484, "episode": 28.0, "batch_reward": 0.01612266275053844, "critic_loss": 0.002140309035225073, "actor_loss": -23.77469207406044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.513211727142334, "step": 28000}
{"episode_reward": 2.6053872607714124, "episode": 29.0, "batch_reward": 0.015293758232146501, "critic_loss": 0.0030589159943847336, "actor_loss": -24.04819460952282, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.43041968345642, "step": 29000}
{"episode_reward": 2.294583194773635, "episode": 30.0, "batch_reward": 0.015046447742031887, "critic_loss": 0.0030925804520302337, "actor_loss": -23.04647483766079, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.944191217422485, "step": 30000}
{"episode_reward": 2.4219213437563223, "episode": 31.0, "batch_reward": 0.0144942626664415, "critic_loss": 0.0015271171553831663, "actor_loss": -24.133854259073733, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.104304790496826, "step": 31000}
{"episode_reward": 2.1435049772783072, "episode": 32.0, "batch_reward": 0.01425230360403657, "critic_loss": 0.002327980233290873, "actor_loss": -24.48651394212246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.30534529685974, "step": 32000}
{"episode_reward": 2.5680668124232184, "episode": 33.0, "batch_reward": 0.013777825795114041, "critic_loss": 0.0024873323874926427, "actor_loss": -24.4648606094718, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91674494743347, "step": 33000}
{"episode_reward": 2.290325844083749, "episode": 34.0, "batch_reward": 0.013714305815286935, "critic_loss": 0.0021956255947297902, "actor_loss": -24.40130956673622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.512007236480713, "step": 34000}
{"episode_reward": 3.1085421242473568, "episode": 35.0, "batch_reward": 0.012689299985882826, "critic_loss": 0.0018586146840898436, "actor_loss": -24.30819107979536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.43105173110962, "step": 35000}
{"episode_reward": 2.6485595708834215, "episode": 36.0, "batch_reward": 0.01255040296446532, "critic_loss": 0.0014577285699051573, "actor_loss": -24.701111163437368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.16197943687439, "step": 36000}
{"episode_reward": 2.3665330478612256, "episode": 37.0, "batch_reward": 0.012635105354711414, "critic_loss": 0.00155771882028057, "actor_loss": -23.77289634668827, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.555463790893555, "step": 37000}
{"episode_reward": 2.482254518810039, "episode": 38.0, "batch_reward": 0.01229729931964539, "critic_loss": 0.0020108127175990378, "actor_loss": -23.34330435371399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.500513315200806, "step": 38000}
{"episode_reward": 2.1988248558498458, "episode": 39.0, "batch_reward": 0.012131480897776782, "critic_loss": 0.0016783304060481897, "actor_loss": -23.238432821989058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.94319438934326, "step": 39000}
{"episode_reward": 2.5284578938947844, "episode": 40.0, "batch_reward": 0.011834980612853542, "critic_loss": 0.0021560611729000813, "actor_loss": -23.98178233039379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.292617082595825, "step": 40000}
{"episode_reward": 2.5441308010680364, "episode": 41.0, "batch_reward": 0.011506882281391882, "critic_loss": 0.0014970994902978418, "actor_loss": -23.678597338855266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.150171756744385, "step": 41000}
{"episode_reward": 2.605564311247226, "episode": 42.0, "batch_reward": 0.01133762416872196, "critic_loss": 0.0018262747194166878, "actor_loss": -23.67161523872614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.628246068954468, "step": 42000}
{"episode_reward": 2.787803393290467, "episode": 43.0, "batch_reward": 0.01110536487621721, "critic_loss": 0.0016578892708130296, "actor_loss": -23.72688658863306, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.73904061317444, "step": 43000}
{"episode_reward": 2.2862976625570584, "episode": 44.0, "batch_reward": 0.01111162134888582, "critic_loss": 0.001972684218388167, "actor_loss": -25.474253751575947, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.472091674804688, "step": 44000}
{"episode_reward": 2.9146047414823455, "episode": 45.0, "batch_reward": 0.010715632071485744, "critic_loss": 0.0014267298948507233, "actor_loss": -24.119267886936665, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.575982332229614, "step": 45000}
{"episode_reward": 1.9043464709289917, "episode": 46.0, "batch_reward": 0.010239003572962247, "critic_loss": 0.0013868352857753052, "actor_loss": -22.916005311399697, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.07834506034851, "step": 46000}
{"episode_reward": 2.2414579110306088, "episode": 47.0, "batch_reward": 0.01023889334872365, "critic_loss": 0.0015038731862805435, "actor_loss": -23.62533849978447, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.518195152282715, "step": 47000}
{"episode_reward": 2.744121385790527, "episode": 48.0, "batch_reward": 0.010253712039324455, "critic_loss": 0.0013709087998140604, "actor_loss": -23.257657898545265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.46705198287964, "step": 48000}
{"episode_reward": 3.051909288537618, "episode": 49.0, "batch_reward": 0.010242542916093953, "critic_loss": 0.0014124939748508042, "actor_loss": -24.568432248979807, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.955076217651367, "step": 49000}
{"episode_reward": 2.7688972562476515, "episode": 50.0, "batch_reward": 0.009895776887657122, "critic_loss": 0.0017669699917605612, "actor_loss": -23.912880383729934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.37880253791809, "step": 50000}
{"episode_reward": 2.423159461072144, "episode": 51.0, "batch_reward": 0.009758886353345589, "critic_loss": 0.0009251317138187005, "actor_loss": -23.659226616978646, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.08100342750549, "step": 51000}
{"episode_reward": 2.3685970821726907, "episode": 52.0, "batch_reward": 0.00973285499936901, "critic_loss": 0.0010400721780933963, "actor_loss": -23.189177915811538, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.51233696937561, "step": 52000}
{"episode_reward": 2.393209483758558, "episode": 53.0, "batch_reward": 0.009468023008084856, "critic_loss": 0.0017337360742749298, "actor_loss": -24.120056195020677, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.611149787902832, "step": 53000}
{"episode_reward": 2.1591171469557757, "episode": 54.0, "batch_reward": 0.009371202438953332, "critic_loss": 0.0010701545476258616, "actor_loss": -24.468475844025612, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.466042518615723, "step": 54000}
{"episode_reward": 2.331074352957927, "episode": 55.0, "batch_reward": 0.00936736719449982, "critic_loss": 0.0014262479111785068, "actor_loss": -24.12462333995104, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.50985074043274, "step": 55000}
{"episode_reward": 2.366084056250994, "episode": 56.0, "batch_reward": 0.00906073600461241, "critic_loss": 0.0013950821108956006, "actor_loss": -23.996312159240247, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.119210481643677, "step": 56000}
{"episode_reward": 2.7770556297044253, "episode": 57.0, "batch_reward": 0.009003882013144903, "critic_loss": 0.0012028841155406554, "actor_loss": -23.989386783063413, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.923818111419678, "step": 57000}
{"episode_reward": 2.604315260047617, "episode": 58.0, "batch_reward": 0.008786253009573556, "critic_loss": 0.0011060560242258362, "actor_loss": -24.111741084218025, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.509807348251343, "step": 58000}
{"episode_reward": 3.474714199077333, "episode": 59.0, "batch_reward": 0.008781826180405915, "critic_loss": 0.0014243683209024312, "actor_loss": -23.928624807476996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.497570991516113, "step": 59000}
{"episode_reward": 2.309201067688921, "episode": 60.0, "batch_reward": 0.008773108399356716, "critic_loss": 0.001058082184063096, "actor_loss": -23.80688271138072, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.18516445159912, "step": 60000}
{"episode_reward": 1.851156979127773, "episode": 61.0, "batch_reward": 0.008713886088109576, "critic_loss": 0.0012977926282219414, "actor_loss": -23.68549748030305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.19772791862488, "step": 61000}
{"episode_reward": 1.7733222190229285, "episode": 62.0, "batch_reward": 0.008761499295011162, "critic_loss": 0.0007763107939754263, "actor_loss": -23.74110152694583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.414570808410645, "step": 62000}
{"episode_reward": 3.366815278312659, "episode": 63.0, "batch_reward": 0.008334866026067174, "critic_loss": 0.0010810541536084202, "actor_loss": -23.848904893368484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.82848620414734, "step": 63000}
{"episode_reward": 2.3067405640038268, "episode": 64.0, "batch_reward": 0.008215826385538093, "critic_loss": 0.0013496666141327295, "actor_loss": -24.317527192175387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.520233869552612, "step": 64000}
{"episode_reward": 2.1776249571192565, "episode": 65.0, "batch_reward": 0.008191222765599377, "critic_loss": 0.001460924288890965, "actor_loss": -23.666860485613345, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.445401668548584, "step": 65000}
{"episode_reward": 3.299774188700872, "episode": 66.0, "batch_reward": 0.007983862768975086, "critic_loss": 0.0014772759946681618, "actor_loss": -23.53895761333406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.523901224136353, "step": 66000}
{"episode_reward": 2.353248089360434, "episode": 67.0, "batch_reward": 0.008061119866208173, "critic_loss": 0.0018118217192713928, "actor_loss": -24.305747925668953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.968981981277466, "step": 67000}
{"episode_reward": 2.39027516695815, "episode": 68.0, "batch_reward": 0.007957200462231412, "critic_loss": 0.0009573059186877799, "actor_loss": -25.00655983607471, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.476163387298584, "step": 68000}
{"episode_reward": 2.53089172317328, "episode": 69.0, "batch_reward": 0.007940599498455412, "critic_loss": 0.001303947496577166, "actor_loss": -23.17305450133979, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.149340867996216, "step": 69000}
{"episode_reward": 1.819882155314453, "episode": 70.0, "batch_reward": 0.0077724751983769234, "critic_loss": 0.0008711294633576472, "actor_loss": -23.466133019417523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.203598022460938, "step": 70000}
{"episode_reward": 2.6379561995437504, "episode": 71.0, "batch_reward": 0.007816607253742404, "critic_loss": 0.0011789186791720566, "actor_loss": -22.993243181437254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.10623621940613, "step": 71000}
{"episode_reward": 2.4731551501236093, "episode": 72.0, "batch_reward": 0.0077431063954718415, "critic_loss": 0.001151116188888409, "actor_loss": -24.0501177713722, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.59809374809265, "step": 72000}
{"episode_reward": 2.4323857842440937, "episode": 73.0, "batch_reward": 0.007715580751188099, "critic_loss": 0.0010826404815197747, "actor_loss": -24.23695825009048, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.886098861694336, "step": 73000}
{"episode_reward": 2.792605779494502, "episode": 74.0, "batch_reward": 0.007405062817968428, "critic_loss": 0.0009022690348938341, "actor_loss": -23.283281434819102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.420519828796387, "step": 74000}
{"episode_reward": 2.034913942555338, "episode": 75.0, "batch_reward": 0.007246002201456577, "critic_loss": 0.001117860904927511, "actor_loss": -23.26201513579488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.522576332092285, "step": 75000}
{"episode_reward": 2.1317297152525487, "episode": 76.0, "batch_reward": 0.007492434267187491, "critic_loss": 0.0007535095077910227, "actor_loss": -23.8726781373322, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.158770322799683, "step": 76000}
{"episode_reward": 2.538719556057837, "episode": 77.0, "batch_reward": 0.007455858361208811, "critic_loss": 0.0010347634081517754, "actor_loss": -23.33849745284021, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.568313121795654, "step": 77000}
{"episode_reward": 2.499612539052745, "episode": 78.0, "batch_reward": 0.007538459258968942, "critic_loss": 0.0010767747368008714, "actor_loss": -23.743520758196713, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.46544122695923, "step": 78000}
{"episode_reward": 2.6104199564100767, "episode": 79.0, "batch_reward": 0.00714085974835325, "critic_loss": 0.0013067588273625007, "actor_loss": -24.687173713177444, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.509070873260498, "step": 79000}
{"episode_reward": 2.4938961280054346, "episode": 80.0, "batch_reward": 0.007205094849690795, "critic_loss": 0.0011028101769916248, "actor_loss": -24.03237285105884, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.3772714138031, "step": 80000}
{"episode_reward": 2.0659708924111806, "episode": 81.0, "batch_reward": 0.006949560221168213, "critic_loss": 0.0008520558519012411, "actor_loss": -23.01417082335055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.354368686676025, "step": 81000}
{"episode_reward": 2.520863416827245, "episode": 82.0, "batch_reward": 0.0068626979837426915, "critic_loss": 0.0005780119582050247, "actor_loss": -23.140386078476904, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.528600692749023, "step": 82000}
{"episode_reward": 1.8953384666178574, "episode": 83.0, "batch_reward": 0.006901887789950706, "critic_loss": 0.0010512657457184104, "actor_loss": -23.72812436032295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.323668956756592, "step": 83000}
{"episode_reward": 2.317841652127407, "episode": 84.0, "batch_reward": 0.006867897683172487, "critic_loss": 0.0009766723385728256, "actor_loss": -24.193298468098046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.094265699386597, "step": 84000}
{"episode_reward": 3.0484192584010765, "episode": 85.0, "batch_reward": 0.006746381561155431, "critic_loss": 0.0007318235377169913, "actor_loss": -23.788370404690504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.52075171470642, "step": 85000}
{"episode_reward": 3.3659194149604517, "episode": 86.0, "batch_reward": 0.0069316774077015, "critic_loss": 0.0009446713892612024, "actor_loss": -23.616900257378816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.87418246269226, "step": 86000}
{"episode_reward": 2.3082955418295965, "episode": 87.0, "batch_reward": 0.006756767420214601, "critic_loss": 0.0007053553492478386, "actor_loss": -23.965093309089543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.562908411026, "step": 87000}
{"episode_reward": 2.0803333061597393, "episode": 88.0, "batch_reward": 0.006428475326159969, "critic_loss": 0.000673099030420417, "actor_loss": -23.118046725481747, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.696133375167847, "step": 88000}
{"episode_reward": 2.3673585930994605, "episode": 89.0, "batch_reward": 0.006659885624889284, "critic_loss": 0.0007884131419068581, "actor_loss": -23.658395060807468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.497398853302002, "step": 89000}
{"episode_reward": 2.160132195666146, "episode": 90.0, "batch_reward": 0.006716054804506712, "critic_loss": 0.0010097829294281838, "actor_loss": -23.255200465336443, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.64078640937805, "step": 90000}
{"episode_reward": 2.999300011013728, "episode": 91.0, "batch_reward": 0.006553564030211419, "critic_loss": 0.0008228622996030026, "actor_loss": -23.4229515196234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.34984564781189, "step": 91000}
{"episode_reward": 2.335453569363094, "episode": 92.0, "batch_reward": 0.006487657664110884, "critic_loss": 0.0008538954222021858, "actor_loss": -24.377659848555922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.4474093914032, "step": 92000}
{"episode_reward": 2.9880149667270923, "episode": 93.0, "batch_reward": 0.0064197014153469355, "critic_loss": 0.000989303187983751, "actor_loss": -23.06673120726645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.60946011543274, "step": 93000}
{"episode_reward": 2.2061675461952834, "episode": 94.0, "batch_reward": 0.0063168514599092306, "critic_loss": 0.000910194525244151, "actor_loss": -23.826059746697545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.038547039031982, "step": 94000}
{"episode_reward": 2.6865549537685425, "episode": 95.0, "batch_reward": 0.006269907531794161, "critic_loss": 0.0007918693670508219, "actor_loss": -24.469848360702397, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.445334911346436, "step": 95000}
{"episode_reward": 2.5384488990566325, "episode": 96.0, "batch_reward": 0.006502484583761543, "critic_loss": 0.0012829697399465657, "actor_loss": -24.420207756206395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.530341386795044, "step": 96000}
{"episode_reward": 1.8539370717827577, "episode": 97.0, "batch_reward": 0.006402833284460939, "critic_loss": 0.0007341438138937519, "actor_loss": -23.76570760165155, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.204264879226685, "step": 97000}
{"episode_reward": 2.3012633328096888, "episode": 98.0, "batch_reward": 0.0061401220326079056, "critic_loss": 0.0006291292913920188, "actor_loss": -24.536432993128894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.919357776641846, "step": 98000}
{"episode_reward": 2.326862020050739, "episode": 99.0, "batch_reward": 0.006187883074628189, "critic_loss": 0.0009587133628083393, "actor_loss": -23.464702319428326, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.484476327896118, "step": 99000}
{"episode_reward": 2.3907644855368626, "episode": 100.0, "batch_reward": 0.006172270060749724, "critic_loss": 0.0008827977308028494, "actor_loss": -24.2282595397532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.51226019859314, "step": 100000}
{"episode_reward": 2.1990721475186543, "episode": 101.0, "batch_reward": 0.006146345774643123, "critic_loss": 0.0009282165546501347, "actor_loss": -22.99696419149637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.37010645866394, "step": 101000}
{"episode_reward": 2.0231516297906675, "episode": 102.0, "batch_reward": 0.006264707818045281, "critic_loss": 0.0008561847854325606, "actor_loss": -24.00687836268544, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.554441213607788, "step": 102000}
{"episode_reward": 2.47413025333378, "episode": 103.0, "batch_reward": 0.006228092118864879, "critic_loss": 0.0006269669631728903, "actor_loss": -22.998992760308088, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.81074619293213, "step": 103000}
{"episode_reward": 2.5048610349358382, "episode": 104.0, "batch_reward": 0.006195573124336079, "critic_loss": 0.0008772540096797457, "actor_loss": -22.990742804571987, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.719011306762695, "step": 104000}
{"episode_reward": 2.194353896211335, "episode": 105.0, "batch_reward": 0.006077561821788549, "critic_loss": 0.0008347005474734033, "actor_loss": -23.45892629247904, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.602267742156982, "step": 105000}
{"episode_reward": 2.303616241178471, "episode": 106.0, "batch_reward": 0.005758314027218148, "critic_loss": 0.0005634974093209166, "actor_loss": -23.335739988692104, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.45907688140869, "step": 106000}
{"episode_reward": 2.020624704513712, "episode": 107.0, "batch_reward": 0.005913347054156475, "critic_loss": 0.0010432403647755563, "actor_loss": -22.57505180440843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.523887872695923, "step": 107000}
{"episode_reward": 2.410231618764313, "episode": 108.0, "batch_reward": 0.006054311736254022, "critic_loss": 0.0008630761277254351, "actor_loss": -23.94224680764973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.54636311531067, "step": 108000}
{"episode_reward": 1.9792008912612848, "episode": 109.0, "batch_reward": 0.005736482050619088, "critic_loss": 0.0007073666342148499, "actor_loss": -23.387685847938062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.48235511779785, "step": 109000}
{"episode_reward": 2.7951599195890315, "episode": 110.0, "batch_reward": 0.006052489747409709, "critic_loss": 0.0011677450848037551, "actor_loss": -24.522436772212387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.48543953895569, "step": 110000}
{"episode_reward": 2.2306684360413684, "episode": 111.0, "batch_reward": 0.005735712250461802, "critic_loss": 0.0006004770082763571, "actor_loss": -23.400015007063747, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.436938524246216, "step": 111000}
{"episode_reward": 2.7895228186398167, "episode": 112.0, "batch_reward": 0.005865467898081988, "critic_loss": 0.0006416600191114412, "actor_loss": -23.575176920227708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.83680248260498, "step": 112000}
{"episode_reward": 2.3328055621746167, "episode": 113.0, "batch_reward": 0.0057340591325191785, "critic_loss": 0.0006149286030304211, "actor_loss": -23.33849589844048, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.48143196105957, "step": 113000}
{"episode_reward": 3.1123931202883526, "episode": 114.0, "batch_reward": 0.005800012415740639, "critic_loss": 0.0008416790398114245, "actor_loss": -23.873371012948454, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.549527883529663, "step": 114000}
{"episode_reward": 2.6278342239344687, "episode": 115.0, "batch_reward": 0.0055023339916951955, "critic_loss": 0.0006212344812593074, "actor_loss": -23.736353825427592, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.01255178451538, "step": 115000}
{"episode_reward": 2.5751473210717504, "episode": 116.0, "batch_reward": 0.00572183112881612, "critic_loss": 0.0008034128239451093, "actor_loss": -23.806920133031905, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.604159355163574, "step": 116000}
{"episode_reward": 1.7523629075542533, "episode": 117.0, "batch_reward": 0.0056117995305685325, "critic_loss": 0.0005722047888120869, "actor_loss": -22.859427601508795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.521243572235107, "step": 117000}
{"episode_reward": 2.8077985015418907, "episode": 118.0, "batch_reward": 0.005573763999156654, "critic_loss": 0.0006082576831540792, "actor_loss": -23.33273922686279, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.54544448852539, "step": 118000}
{"episode_reward": 2.3062039292777303, "episode": 119.0, "batch_reward": 0.005690152372000739, "critic_loss": 0.0006611477105070662, "actor_loss": -23.804814614251256, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.386369943618774, "step": 119000}
{"episode_reward": 2.3345417775234987, "episode": 120.0, "batch_reward": 0.005652108930982649, "critic_loss": 0.000628573774742108, "actor_loss": -22.387980990320443, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20225477218628, "step": 120000}
{"episode_reward": 2.6662078850317084, "episode": 121.0, "batch_reward": 0.005457251797197387, "critic_loss": 0.0007844893594738096, "actor_loss": -23.266794178418817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.15876007080078, "step": 121000}
{"episode_reward": 2.717593858068362, "episode": 122.0, "batch_reward": 0.0054887038110755385, "critic_loss": 0.0006654500517724955, "actor_loss": -23.860878212600948, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.54470944404602, "step": 122000}
{"episode_reward": 2.041531710252014, "episode": 123.0, "batch_reward": 0.005505024222424254, "critic_loss": 0.0007326050110477809, "actor_loss": -24.161719890125095, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.987731456756592, "step": 123000}
{"episode_reward": 2.549511600167305, "episode": 124.0, "batch_reward": 0.005554661179077811, "critic_loss": 0.0009245848464797746, "actor_loss": -23.80464411711693, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.529345750808716, "step": 124000}
{"episode_reward": 3.017694912496985, "episode": 125.0, "batch_reward": 0.005345583522110246, "critic_loss": 0.0005263628723423608, "actor_loss": -23.374490167081355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.000597715377808, "step": 125000}
{"episode_reward": 2.072128367423832, "episode": 126.0, "batch_reward": 0.005526079328265041, "critic_loss": 0.0007610688356253376, "actor_loss": -24.150827956721187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.221734046936035, "step": 126000}
{"episode_reward": 3.1173259296122695, "episode": 127.0, "batch_reward": 0.005405314077390358, "critic_loss": 0.0007038230769067013, "actor_loss": -23.61894217120111, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.57171392440796, "step": 127000}
{"episode_reward": 2.829876846234053, "episode": 128.0, "batch_reward": 0.005378361213952303, "critic_loss": 0.0006533095653358032, "actor_loss": -22.7904348134771, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.45799493789673, "step": 128000}
{"episode_reward": 2.669493713724499, "episode": 129.0, "batch_reward": 0.005416271413327195, "critic_loss": 0.0006796218021481764, "actor_loss": -23.62359525602311, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.321277856826782, "step": 129000}
{"episode_reward": 3.0096433270977476, "episode": 130.0, "batch_reward": 0.005246531664044597, "critic_loss": 0.0007722455351286044, "actor_loss": -24.028397365421057, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04437255859375, "step": 130000}
{"episode_reward": 1.8744724207460963, "episode": 131.0, "batch_reward": 0.00527544105972629, "critic_loss": 0.0005899837400556862, "actor_loss": -22.257248679175973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.15566802024841, "step": 131000}
{"episode_reward": 2.284352303708065, "episode": 132.0, "batch_reward": 0.005239280627225526, "critic_loss": 0.0007196468222900876, "actor_loss": -24.3791432101056, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.463461875915527, "step": 132000}
{"episode_reward": 2.747433438465469, "episode": 133.0, "batch_reward": 0.005196017693146132, "critic_loss": 0.0005626915658649523, "actor_loss": -22.785732903786002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.981468200683594, "step": 133000}
{"episode_reward": 2.3254756636846245, "episode": 134.0, "batch_reward": 0.005372743630898185, "critic_loss": 0.0004393953709732159, "actor_loss": -23.489005627408623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.529269695281982, "step": 134000}
{"episode_reward": 2.8014890567369597, "episode": 135.0, "batch_reward": 0.005066038283403031, "critic_loss": 0.0005519441547512542, "actor_loss": -24.02018091740459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.975342988967896, "step": 135000}
{"episode_reward": 2.562258110365214, "episode": 136.0, "batch_reward": 0.005281017976114527, "critic_loss": 0.0008767969008913497, "actor_loss": -23.203449822857976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.605416297912598, "step": 136000}
{"episode_reward": 2.3266866374895905, "episode": 137.0, "batch_reward": 0.00513638980302494, "critic_loss": 0.0006267498920060462, "actor_loss": -23.965932436570526, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.117472648620605, "step": 137000}
{"episode_reward": 2.4369959225003726, "episode": 138.0, "batch_reward": 0.005197728477534838, "critic_loss": 0.0007642639549594605, "actor_loss": -24.85514190147072, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.510987043380737, "step": 138000}
{"episode_reward": 2.3771710484565753, "episode": 139.0, "batch_reward": 0.005063640560256317, "critic_loss": 0.001086197550794168, "actor_loss": -22.66763058081269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.05374050140381, "step": 139000}
{"episode_reward": 2.4910675779657225, "episode": 140.0, "batch_reward": 0.005297295594587922, "critic_loss": 0.0005431855237911804, "actor_loss": -24.44525548299402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.143611192703247, "step": 140000}
{"episode_reward": 2.666822390862336, "episode": 141.0, "batch_reward": 0.005075978078180924, "critic_loss": 0.0007586908356570348, "actor_loss": -23.606343832679094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.20499324798584, "step": 141000}
{"episode_reward": 2.545933336106898, "episode": 142.0, "batch_reward": 0.005059316242579371, "critic_loss": 0.0007984117117084679, "actor_loss": -23.43397062242776, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.224792957305908, "step": 142000}
{"episode_reward": 2.307628659246869, "episode": 143.0, "batch_reward": 0.0051698675061343236, "critic_loss": 0.0006214443001463224, "actor_loss": -23.61572692388296, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.29809308052063, "step": 143000}
{"episode_reward": 2.9734045701259157, "episode": 144.0, "batch_reward": 0.005017629612586461, "critic_loss": 0.0007106684750851855, "actor_loss": -24.13448819408566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.322402477264404, "step": 144000}
{"episode_reward": 2.3955625299904653, "episode": 145.0, "batch_reward": 0.0049224997728597375, "critic_loss": 0.0005282775723881059, "actor_loss": -24.07575925631821, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.518207788467407, "step": 145000}
{"episode_reward": 3.6183711215200374, "episode": 146.0, "batch_reward": 0.004958803539630026, "critic_loss": 0.0005973081660686148, "actor_loss": -22.837268306441604, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.47267484664917, "step": 146000}
{"episode_reward": 2.461315473925545, "episode": 147.0, "batch_reward": 0.0050270881277974695, "critic_loss": 0.0005871568019138067, "actor_loss": -23.485493493959307, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.045645475387573, "step": 147000}
{"episode_reward": 2.355287579526562, "episode": 148.0, "batch_reward": 0.004890241859480738, "critic_loss": 0.0005458808181010681, "actor_loss": -23.18576646398753, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.889597415924072, "step": 148000}
{"episode_reward": 2.844107688646543, "episode": 149.0, "batch_reward": 0.004978500933153555, "critic_loss": 0.0006859834287533886, "actor_loss": -23.83720967295766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.43953037261963, "step": 149000}
{"episode_reward": 2.770471075678706, "episode": 150.0, "batch_reward": 0.004778551560244523, "critic_loss": 0.0004416630970354163, "actor_loss": -24.36811311018467, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
