{"episode_reward": 0.0, "episode": 1.0, "duration": 17.598618984222412, "step": 1000}
{"episode_reward": 7.051849146674556, "episode": 2.0, "duration": 1.5277669429779053, "step": 2000}
{"episode_reward": 365.4711839680396, "episode": 3.0, "batch_reward": 0.17575821530405542, "critic_loss": 0.04391991526755483, "actor_loss": -30.644170887836843, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 64.19195461273193, "step": 3000}
{"episode_reward": 15.679733148141372, "episode": 4.0, "batch_reward": 0.1125420082733035, "critic_loss": 0.022526363075710834, "actor_loss": -26.492987034797668, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.380629062652588, "step": 4000}
{"episode_reward": 3.0774105127060896, "episode": 5.0, "batch_reward": 0.08771741216816008, "critic_loss": 0.022504991518333555, "actor_loss": -24.211065066814424, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.404031991958618, "step": 5000}
{"episode_reward": 3.220378446755481, "episode": 6.0, "batch_reward": 0.07162987221777439, "critic_loss": 0.029342748837545514, "actor_loss": -24.951577434539796, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.494771003723145, "step": 6000}
{"episode_reward": 4.689721230512621, "episode": 7.0, "batch_reward": 0.06160786488652229, "critic_loss": 0.025796217158436774, "actor_loss": -23.891946182250976, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.92454481124878, "step": 7000}
{"episode_reward": 3.972286662746495, "episode": 8.0, "batch_reward": 0.05494459984637797, "critic_loss": 0.03673189051169902, "actor_loss": -23.231731475830077, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.344229698181152, "step": 8000}
{"episode_reward": 19.230973964822233, "episode": 9.0, "batch_reward": 0.051503019995987415, "critic_loss": 0.04546081326995045, "actor_loss": -23.21904829311371, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.18028998374939, "step": 9000}
{"episode_reward": 25.650415549547276, "episode": 10.0, "batch_reward": 0.04904572819173336, "critic_loss": 0.04763148333877325, "actor_loss": -23.096573373794556, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.219569444656372, "step": 10000}
{"episode_reward": 38.71416933063168, "episode": 11.0, "batch_reward": 0.04934912085905671, "critic_loss": 0.0656508552711457, "actor_loss": -22.56489399719238, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.0257511138916, "step": 11000}
{"episode_reward": 50.89611891268028, "episode": 12.0, "batch_reward": 0.04915732072852552, "critic_loss": 0.08547912904620171, "actor_loss": -22.3960432677269, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.332386255264282, "step": 12000}
{"episode_reward": 59.3542124557374, "episode": 13.0, "batch_reward": 0.05008076208084822, "critic_loss": 0.08601005185954273, "actor_loss": -22.431794491052628, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.057398319244385, "step": 13000}
{"episode_reward": 62.53661964324596, "episode": 14.0, "batch_reward": 0.05077995187602937, "critic_loss": 0.10586098321899771, "actor_loss": -22.087754704236986, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.513702869415283, "step": 14000}
{"episode_reward": 54.06113930627142, "episode": 15.0, "batch_reward": 0.05055499565601349, "critic_loss": 0.11302161495387554, "actor_loss": -22.898857012510298, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.38289189338684, "step": 15000}
{"episode_reward": 46.66487349952304, "episode": 16.0, "batch_reward": 0.05150953266583383, "critic_loss": 0.10951262207143009, "actor_loss": -22.443912096500398, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.461665391921997, "step": 16000}
{"episode_reward": 86.35537791080121, "episode": 17.0, "batch_reward": 0.055137253534048795, "critic_loss": 0.15681747271120547, "actor_loss": -21.94117064547539, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.113125562667847, "step": 17000}
{"episode_reward": 128.41817225889912, "episode": 18.0, "batch_reward": 0.060371261401101946, "critic_loss": 0.18111164057999848, "actor_loss": -22.460705747544765, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.388218641281128, "step": 18000}
{"episode_reward": 156.0602771338061, "episode": 19.0, "batch_reward": 0.06502753334492445, "critic_loss": 0.24080234783142804, "actor_loss": -22.616844377815724, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.377825021743774, "step": 19000}
{"episode_reward": 94.88239386660788, "episode": 20.0, "batch_reward": 0.06697698030620813, "critic_loss": 0.2570185125172138, "actor_loss": -22.851940046608448, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.85226535797119, "step": 20000}
{"episode_reward": 109.50170266783616, "episode": 21.0, "batch_reward": 0.06981170746311545, "critic_loss": 0.2653710798919201, "actor_loss": -20.91697603213787, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.976107120513916, "step": 21000}
{"episode_reward": 179.91510812825018, "episode": 22.0, "batch_reward": 0.07488296648487448, "critic_loss": 0.2705356535986066, "actor_loss": -22.12930455188453, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.32160758972168, "step": 22000}
{"episode_reward": 147.7420732231936, "episode": 23.0, "batch_reward": 0.07952311048284173, "critic_loss": 0.28413002064824106, "actor_loss": -21.672314889639615, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.376543283462524, "step": 23000}
{"episode_reward": 231.769613099107, "episode": 24.0, "batch_reward": 0.08581061306223273, "critic_loss": 0.25129597867280246, "actor_loss": -22.715223477602006, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.919645071029663, "step": 24000}
{"episode_reward": 272.207443863321, "episode": 25.0, "batch_reward": 0.09075648081302642, "critic_loss": 0.24024192033708094, "actor_loss": -23.168434926986695, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.347074031829834, "step": 25000}
{"episode_reward": 63.077659363538466, "episode": 26.0, "batch_reward": 0.09190705444291233, "critic_loss": 0.21889188255369663, "actor_loss": -22.146528345704077, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.544087409973145, "step": 26000}
{"episode_reward": 168.8613619233614, "episode": 27.0, "batch_reward": 0.0939074174389243, "critic_loss": 0.20973375727981328, "actor_loss": -22.474952672064305, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.540175437927246, "step": 27000}
{"episode_reward": 162.3823335023002, "episode": 28.0, "batch_reward": 0.09718054545670748, "critic_loss": 0.21380819480866195, "actor_loss": -22.284472301006318, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.474653959274292, "step": 28000}
{"episode_reward": 207.58327160453044, "episode": 29.0, "batch_reward": 0.09835919093340635, "critic_loss": 0.22802094915509225, "actor_loss": -22.45526718521118, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.37325644493103, "step": 29000}
{"episode_reward": 57.4696855035681, "episode": 30.0, "batch_reward": 0.10110724202543497, "critic_loss": 0.24157037506252527, "actor_loss": -21.572456876039507, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.415032863616943, "step": 30000}
{"episode_reward": 305.6393992078054, "episode": 31.0, "batch_reward": 0.1072141151279211, "critic_loss": 0.2558893438130617, "actor_loss": -23.012733785629273, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.914873361587524, "step": 31000}
{"episode_reward": 234.41965098297092, "episode": 32.0, "batch_reward": 0.10913201519101857, "critic_loss": 0.23872604266554118, "actor_loss": -23.2010454249382, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.358778715133667, "step": 32000}
{"episode_reward": 73.6323894435832, "episode": 33.0, "batch_reward": 0.10961116707324982, "critic_loss": 0.24472572369128465, "actor_loss": -23.22092415904999, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.37651824951172, "step": 33000}
{"episode_reward": 267.1267154703645, "episode": 34.0, "batch_reward": 0.11407645596563816, "critic_loss": 0.24240765420347452, "actor_loss": -23.438748426914216, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.32120442390442, "step": 34000}
{"episode_reward": 165.48895567125962, "episode": 35.0, "batch_reward": 0.1130577532351017, "critic_loss": 0.24158271633833647, "actor_loss": -23.155070102214815, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.106383323669434, "step": 35000}
{"episode_reward": 39.14264393701948, "episode": 36.0, "batch_reward": 0.11325195822119713, "critic_loss": 0.24602508680522442, "actor_loss": -23.358668827056885, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.36626124382019, "step": 36000}
{"episode_reward": 179.03174854555888, "episode": 37.0, "batch_reward": 0.11482365958392621, "critic_loss": 0.2611823358088732, "actor_loss": -22.5928870844841, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.92713189125061, "step": 37000}
{"episode_reward": 160.98419801874545, "episode": 38.0, "batch_reward": 0.11608470474928617, "critic_loss": 0.29986579670012, "actor_loss": -22.129360568523406, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.135037899017334, "step": 38000}
{"episode_reward": 141.44201625255107, "episode": 39.0, "batch_reward": 0.11891688615828752, "critic_loss": 0.27420145747065544, "actor_loss": -22.1578271279335, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.610662698745728, "step": 39000}
{"episode_reward": 359.63574506628794, "episode": 40.0, "batch_reward": 0.12272954523563386, "critic_loss": 0.25051954966783524, "actor_loss": -22.93065817451477, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.334579944610596, "step": 40000}
{"episode_reward": 111.19090031017375, "episode": 41.0, "batch_reward": 0.1233376717492938, "critic_loss": 0.29724911001324655, "actor_loss": -22.657947276592253, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.91356110572815, "step": 41000}
{"episode_reward": 248.95694595498585, "episode": 42.0, "batch_reward": 0.1275736313611269, "critic_loss": 0.27020111770927907, "actor_loss": -22.969074981212614, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.330063819885254, "step": 42000}
{"episode_reward": 343.32760446134046, "episode": 43.0, "batch_reward": 0.13192543827742337, "critic_loss": 0.28577422426640986, "actor_loss": -23.31315070915222, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.429620504379272, "step": 43000}
{"episode_reward": 214.5857854844582, "episode": 44.0, "batch_reward": 0.13288898527622223, "critic_loss": 0.2759624822586775, "actor_loss": -24.57156149673462, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.931524515151978, "step": 44000}
{"episode_reward": 284.37175124552215, "episode": 45.0, "batch_reward": 0.13551291497051715, "critic_loss": 0.3019650106728077, "actor_loss": -23.8841726102829, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.20609951019287, "step": 45000}
{"episode_reward": 79.64051656212686, "episode": 46.0, "batch_reward": 0.13474327287077903, "critic_loss": 0.3033063100129366, "actor_loss": -22.87770728111267, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.579997539520264, "step": 46000}
{"episode_reward": 260.8352862590204, "episode": 47.0, "batch_reward": 0.13829798083007336, "critic_loss": 0.33038929107785225, "actor_loss": -23.66304760360718, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.36446452140808, "step": 47000}
{"episode_reward": 279.6133573248654, "episode": 48.0, "batch_reward": 0.14186104856431483, "critic_loss": 0.3474844070822001, "actor_loss": -23.71728742980957, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.798807621002197, "step": 48000}
{"episode_reward": 330.96809427709326, "episode": 49.0, "batch_reward": 0.14424376583099366, "critic_loss": 0.3448986053913832, "actor_loss": -24.829528950691223, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.77535057067871, "step": 49000}
{"episode_reward": 114.91666137832135, "episode": 50.0, "batch_reward": 0.14396326211839913, "critic_loss": 0.38889621959626675, "actor_loss": -24.40978684425354, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.340824365615845, "step": 50000}
{"episode_reward": 186.136177854087, "episode": 51.0, "batch_reward": 0.1449135838970542, "critic_loss": 0.39666752287745477, "actor_loss": -24.258036400794982, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.17819142341614, "step": 51000}
{"episode_reward": 247.59662802672983, "episode": 52.0, "batch_reward": 0.14781157050281762, "critic_loss": 0.40603780722618105, "actor_loss": -24.177907192230226, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.444398164749146, "step": 52000}
{"episode_reward": 314.81882455910005, "episode": 53.0, "batch_reward": 0.15130653440207242, "critic_loss": 0.4067391748130321, "actor_loss": -25.07197316455841, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.576908349990845, "step": 53000}
{"episode_reward": 302.6944020361718, "episode": 54.0, "batch_reward": 0.15326391995698213, "critic_loss": 0.3853400308042765, "actor_loss": -25.517498962402342, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.43379235267639, "step": 54000}
{"episode_reward": 245.9338195484256, "episode": 55.0, "batch_reward": 0.1545645542293787, "critic_loss": 0.455238254532218, "actor_loss": -25.474426635742187, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.631200551986694, "step": 55000}
{"episode_reward": 135.3776017419069, "episode": 56.0, "batch_reward": 0.15363027388602496, "critic_loss": 0.4149298133701086, "actor_loss": -25.155975839614868, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.12878942489624, "step": 56000}
{"episode_reward": 107.29725235774325, "episode": 57.0, "batch_reward": 0.15481319655478, "critic_loss": 0.4559999620318413, "actor_loss": -25.134983297348022, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.52765727043152, "step": 57000}
{"episode_reward": 327.23173790611196, "episode": 58.0, "batch_reward": 0.1575520202293992, "critic_loss": 0.45227665689587593, "actor_loss": -25.486595859527586, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.348615169525146, "step": 58000}
{"episode_reward": 297.12909446728895, "episode": 59.0, "batch_reward": 0.15892406542599202, "critic_loss": 0.5013886537402868, "actor_loss": -25.456443103790285, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.590035915374756, "step": 59000}
{"episode_reward": 116.5604543976389, "episode": 60.0, "batch_reward": 0.1585864262357354, "critic_loss": 0.48972663095593455, "actor_loss": -25.285422716140747, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.81532621383667, "step": 60000}
{"episode_reward": 338.9394900653919, "episode": 61.0, "batch_reward": 0.1615707426071167, "critic_loss": 0.4808136961609125, "actor_loss": -25.462020608901977, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.92062950134277, "step": 61000}
{"episode_reward": 185.13886443820286, "episode": 62.0, "batch_reward": 0.1625520466864109, "critic_loss": 0.491971750870347, "actor_loss": -25.474626626968384, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.619739532470703, "step": 62000}
{"episode_reward": 240.32502492650303, "episode": 63.0, "batch_reward": 0.16309075352549554, "critic_loss": 0.48800282356143, "actor_loss": -25.60329147529602, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.732856512069702, "step": 63000}
{"episode_reward": 248.58217835974418, "episode": 64.0, "batch_reward": 0.16454049726575612, "critic_loss": 0.4910160621702671, "actor_loss": -25.963432903289796, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.75246834754944, "step": 64000}
{"episode_reward": 330.78033568923667, "episode": 65.0, "batch_reward": 0.16782390853762627, "critic_loss": 0.48664179594814777, "actor_loss": -25.9059420003891, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.39200234413147, "step": 65000}
{"episode_reward": 321.29596922896326, "episode": 66.0, "batch_reward": 0.16954210045933724, "critic_loss": 0.49404474449157715, "actor_loss": -25.99419372177124, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.948076725006104, "step": 66000}
{"episode_reward": 264.3893919793566, "episode": 67.0, "batch_reward": 0.17042157661914825, "critic_loss": 0.493622447386384, "actor_loss": -26.432569456100463, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.33504295349121, "step": 67000}
{"episode_reward": 59.1826997301617, "episode": 68.0, "batch_reward": 0.16860542540252207, "critic_loss": 0.5624487919807434, "actor_loss": -26.687918807983397, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.559200048446655, "step": 68000}
{"episode_reward": 106.76609646269245, "episode": 69.0, "batch_reward": 0.16819318210333586, "critic_loss": 0.5737291745841503, "actor_loss": -25.527698711395264, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.41390037536621, "step": 69000}
{"episode_reward": 310.43584137875774, "episode": 70.0, "batch_reward": 0.17126089696586133, "critic_loss": 0.5735384410321712, "actor_loss": -25.922561460494997, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.4367196559906, "step": 70000}
{"episode_reward": 312.0326903812924, "episode": 71.0, "batch_reward": 0.17259267081320287, "critic_loss": 0.5521452295780181, "actor_loss": -25.70437588310242, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.91126728057861, "step": 71000}
{"episode_reward": 357.6820249785829, "episode": 72.0, "batch_reward": 0.17514586313068867, "critic_loss": 0.5383195677399635, "actor_loss": -26.62325358581543, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.35498881340027, "step": 72000}
{"episode_reward": 245.67412972219677, "episode": 73.0, "batch_reward": 0.17534242092072963, "critic_loss": 0.5604126368761062, "actor_loss": -26.68168062210083, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.831046104431152, "step": 73000}
{"episode_reward": 212.185177913984, "episode": 74.0, "batch_reward": 0.17665105618536472, "critic_loss": 0.5007874233573675, "actor_loss": -26.298328388214113, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.415398359298706, "step": 74000}
{"episode_reward": 352.6892084626829, "episode": 75.0, "batch_reward": 0.17877248698472978, "critic_loss": 0.582641076400876, "actor_loss": -26.409958873748778, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.3480486869812, "step": 75000}
{"episode_reward": 324.5112346843405, "episode": 76.0, "batch_reward": 0.18010095454752445, "critic_loss": 0.5410838288515806, "actor_loss": -26.935939096450806, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.43492555618286, "step": 76000}
{"episode_reward": 318.4055612889581, "episode": 77.0, "batch_reward": 0.1826873834580183, "critic_loss": 0.5051326002329588, "actor_loss": -26.83026717376709, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.375852823257446, "step": 77000}
{"episode_reward": 371.25757476207184, "episode": 78.0, "batch_reward": 0.18526356461644172, "critic_loss": 0.5032561474442482, "actor_loss": -27.31284518814087, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.828831911087036, "step": 78000}
{"episode_reward": 357.8755684503931, "episode": 79.0, "batch_reward": 0.18752475802600382, "critic_loss": 0.5347445822060108, "actor_loss": -28.069661998748778, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.371609449386597, "step": 79000}
{"episode_reward": 243.77506078025561, "episode": 80.0, "batch_reward": 0.1885423082113266, "critic_loss": 0.5183968010693788, "actor_loss": -27.724176948547363, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.65551233291626, "step": 80000}
{"episode_reward": 370.6266146346056, "episode": 81.0, "batch_reward": 0.18976981629431247, "critic_loss": 0.5128430780470371, "actor_loss": -27.16934524345398, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.40879487991333, "step": 81000}
{"episode_reward": 140.81663216361014, "episode": 82.0, "batch_reward": 0.18928985758125783, "critic_loss": 0.5248444952070713, "actor_loss": -27.321114137649538, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.430646657943726, "step": 82000}
{"episode_reward": 262.4861429862933, "episode": 83.0, "batch_reward": 0.18991334550082684, "critic_loss": 0.5436655614674092, "actor_loss": -27.589987548828127, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.27186107635498, "step": 83000}
{"episode_reward": 272.2146517223538, "episode": 84.0, "batch_reward": 0.19176018811762333, "critic_loss": 0.5535473387539387, "actor_loss": -28.086954319000245, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.19707179069519, "step": 84000}
{"episode_reward": 320.3920886313084, "episode": 85.0, "batch_reward": 0.19326390145719052, "critic_loss": 0.5511926550865174, "actor_loss": -27.9297850151062, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.418489933013916, "step": 85000}
{"episode_reward": 397.36003140038355, "episode": 86.0, "batch_reward": 0.19615381762385367, "critic_loss": 0.5906971761584282, "actor_loss": -28.046698453903197, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.392733097076416, "step": 86000}
{"episode_reward": 362.6634864902069, "episode": 87.0, "batch_reward": 0.19800810599327087, "critic_loss": 0.5586704328656197, "actor_loss": -28.425329872131346, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.758106231689453, "step": 87000}
{"episode_reward": 376.56721406135193, "episode": 88.0, "batch_reward": 0.2002234792113304, "critic_loss": 0.5250036490410567, "actor_loss": -28.17556810760498, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.28433609008789, "step": 88000}
{"episode_reward": 432.7373532206896, "episode": 89.0, "batch_reward": 0.2024316408187151, "critic_loss": 0.5310610246062278, "actor_loss": -28.623611042022706, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.420119524002075, "step": 89000}
{"episode_reward": 366.70063487772586, "episode": 90.0, "batch_reward": 0.20478519980609416, "critic_loss": 0.5475576907992363, "actor_loss": -28.584211122512816, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.667311191558838, "step": 90000}
{"episode_reward": 387.64529116704654, "episode": 91.0, "batch_reward": 0.2063208554685116, "critic_loss": 0.5386624793112278, "actor_loss": -28.797709463119507, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.70739388465881, "step": 91000}
{"episode_reward": 344.925983196706, "episode": 92.0, "batch_reward": 0.2080393046736717, "critic_loss": 0.5276780257523059, "actor_loss": -29.50877543640137, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.380881786346436, "step": 92000}
{"episode_reward": 366.5280016370298, "episode": 93.0, "batch_reward": 0.20981279034912587, "critic_loss": 0.4862136680781841, "actor_loss": -28.982593015670776, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.32636594772339, "step": 93000}
{"episode_reward": 410.5789023707303, "episode": 94.0, "batch_reward": 0.21173443932831287, "critic_loss": 0.5249837329536676, "actor_loss": -29.597919010162354, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.1447856426239, "step": 94000}
{"episode_reward": 326.7800034946881, "episode": 95.0, "batch_reward": 0.21326627878844737, "critic_loss": 0.5099688039273024, "actor_loss": -30.05237943649292, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.462653398513794, "step": 95000}
{"episode_reward": 328.75108884550576, "episode": 96.0, "batch_reward": 0.21475654952228068, "critic_loss": 0.5173327713161707, "actor_loss": -30.087227239608765, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.380398988723755, "step": 96000}
{"episode_reward": 337.15545468637134, "episode": 97.0, "batch_reward": 0.21543359600007533, "critic_loss": 0.5593461605608463, "actor_loss": -29.934382522583007, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.687764644622803, "step": 97000}
{"episode_reward": 372.45590266447124, "episode": 98.0, "batch_reward": 0.21596641285717488, "critic_loss": 0.5852606951892376, "actor_loss": -30.368196159362792, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.526082515716553, "step": 98000}
{"episode_reward": 388.0967653251581, "episode": 99.0, "batch_reward": 0.21882173730432988, "critic_loss": 0.5696863467544317, "actor_loss": -30.086465312957763, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.38423728942871, "step": 99000}
{"episode_reward": 395.86111966826854, "episode": 100.0, "batch_reward": 0.22078560391068458, "critic_loss": 0.601562071621418, "actor_loss": -30.630936624526978, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.40178418159485, "step": 100000}
{"episode_reward": 416.0135517535983, "episode": 101.0, "batch_reward": 0.22215032756328582, "critic_loss": 0.5815279042124748, "actor_loss": -30.091719522476197, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.57240033149719, "step": 101000}
{"episode_reward": 441.854685538912, "episode": 102.0, "batch_reward": 0.22543473529815675, "critic_loss": 0.553033563837409, "actor_loss": -30.83268498802185, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.441098928451538, "step": 102000}
{"episode_reward": 378.97498387908894, "episode": 103.0, "batch_reward": 0.22652267591655253, "critic_loss": 0.5937790309935809, "actor_loss": -30.420836013793945, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.399681329727173, "step": 103000}
{"episode_reward": 383.0445836640559, "episode": 104.0, "batch_reward": 0.22747301262617112, "critic_loss": 0.5923423107266426, "actor_loss": -30.458883827209473, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.6187527179718, "step": 104000}
{"episode_reward": 432.2419222160249, "episode": 105.0, "batch_reward": 0.23017979650199413, "critic_loss": 0.6060533434450627, "actor_loss": -30.99993775177002, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.219756364822388, "step": 105000}
{"episode_reward": 401.88755749618684, "episode": 106.0, "batch_reward": 0.23078845535218714, "critic_loss": 0.6268630731850863, "actor_loss": -31.02791047668457, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.41447901725769, "step": 106000}
{"episode_reward": 189.78855917741203, "episode": 107.0, "batch_reward": 0.2306479078680277, "critic_loss": 0.6316052278131247, "actor_loss": -30.601001037597655, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.960243940353394, "step": 107000}
{"episode_reward": 413.1931037905684, "episode": 108.0, "batch_reward": 0.23288218046724796, "critic_loss": 0.6335718876123428, "actor_loss": -31.463977968215943, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.316781044006348, "step": 108000}
{"episode_reward": 422.4818943628151, "episode": 109.0, "batch_reward": 0.23458446253836154, "critic_loss": 0.6348451028466224, "actor_loss": -31.332328018188477, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.735527276992798, "step": 109000}
{"episode_reward": 388.04772533230204, "episode": 110.0, "batch_reward": 0.23605580900609494, "critic_loss": 0.6611189549416303, "actor_loss": -31.99892488670349, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.367976665496826, "step": 110000}
{"episode_reward": 364.3636367950966, "episode": 111.0, "batch_reward": 0.23672922298312188, "critic_loss": 0.6263302465826273, "actor_loss": -31.4310373878479, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.00761389732361, "step": 111000}
{"episode_reward": 370.4132861426581, "episode": 112.0, "batch_reward": 0.23788619677722453, "critic_loss": 0.6251771623790264, "actor_loss": -31.662805084228516, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.416526317596436, "step": 112000}
{"episode_reward": 317.63899226301186, "episode": 113.0, "batch_reward": 0.238946257263422, "critic_loss": 0.6022827410846948, "actor_loss": -31.57579591178894, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.352802991867065, "step": 113000}
{"episode_reward": 353.1688048074498, "episode": 114.0, "batch_reward": 0.23987559348344803, "critic_loss": 0.5894440131038428, "actor_loss": -31.885186180114747, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.968461513519287, "step": 114000}
{"episode_reward": 338.03470155022353, "episode": 115.0, "batch_reward": 0.24051865075528622, "critic_loss": 0.5741542175114155, "actor_loss": -32.02442269897461, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.375309705734253, "step": 115000}
{"episode_reward": 392.7399140328038, "episode": 116.0, "batch_reward": 0.2422395073324442, "critic_loss": 0.5902082640230656, "actor_loss": -32.06578059577942, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.318923711776733, "step": 116000}
{"episode_reward": 373.5784488792804, "episode": 117.0, "batch_reward": 0.24400275622308254, "critic_loss": 0.6092403668910265, "actor_loss": -31.70155206298828, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.581127882003784, "step": 117000}
{"episode_reward": 408.3004995381161, "episode": 118.0, "batch_reward": 0.24469433197379112, "critic_loss": 0.5528411656469107, "actor_loss": -32.098439182281496, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.373451948165894, "step": 118000}
{"episode_reward": 348.5522381378855, "episode": 119.0, "batch_reward": 0.24576899820566178, "critic_loss": 0.5836901666820049, "actor_loss": -32.30879372024536, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.69298529624939, "step": 119000}
{"episode_reward": 342.14635207347044, "episode": 120.0, "batch_reward": 0.24526395565271378, "critic_loss": 0.5735296853631735, "actor_loss": -31.543293323516846, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.328726768493652, "step": 120000}
{"episode_reward": 389.2268942149228, "episode": 121.0, "batch_reward": 0.2473826074451208, "critic_loss": 0.5780130564570427, "actor_loss": -32.21706790161133, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.060057163238525, "step": 121000}
{"episode_reward": 374.3050694023381, "episode": 122.0, "batch_reward": 0.24921819692850114, "critic_loss": 0.579615402430296, "actor_loss": -32.63130854797363, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.515568733215332, "step": 122000}
{"episode_reward": 391.60771934962105, "episode": 123.0, "batch_reward": 0.2493865330964327, "critic_loss": 0.5857416254580021, "actor_loss": -32.77457318878174, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.427042245864868, "step": 123000}
{"episode_reward": 405.2932543901844, "episode": 124.0, "batch_reward": 0.25097584262490275, "critic_loss": 0.6003987805247307, "actor_loss": -32.80277876281738, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.436018705368042, "step": 124000}
{"episode_reward": 366.3433170116539, "episode": 125.0, "batch_reward": 0.25156459091603756, "critic_loss": 0.5805797441005707, "actor_loss": -32.52403458786011, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.010257244110107, "step": 125000}
{"episode_reward": 394.4079820219514, "episode": 126.0, "batch_reward": 0.2528898211866617, "critic_loss": 0.6255774999707937, "actor_loss": -33.14504987335205, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.46573805809021, "step": 126000}
{"episode_reward": 295.96319276426794, "episode": 127.0, "batch_reward": 0.25297578671574594, "critic_loss": 0.5870783690214157, "actor_loss": -32.815509078979495, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.398603677749634, "step": 127000}
{"episode_reward": 406.65191996640914, "episode": 128.0, "batch_reward": 0.25468282230198386, "critic_loss": 0.5953240367621183, "actor_loss": -32.56005382537842, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.592551469802856, "step": 128000}
{"episode_reward": 433.8803164495888, "episode": 129.0, "batch_reward": 0.2554424248635769, "critic_loss": 0.5756229266226291, "actor_loss": -33.04587642288208, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.68106198310852, "step": 129000}
{"episode_reward": 366.9604022073277, "episode": 130.0, "batch_reward": 0.25617911499738694, "critic_loss": 0.5751419983655214, "actor_loss": -33.33171936035156, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.379602193832397, "step": 130000}
{"episode_reward": 389.4267247767951, "episode": 131.0, "batch_reward": 0.25849795785546303, "critic_loss": 0.5663334978967905, "actor_loss": -32.54524021530151, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.21918773651123, "step": 131000}
{"episode_reward": 397.1922488824079, "episode": 132.0, "batch_reward": 0.2596527735888958, "critic_loss": 0.6181700275689364, "actor_loss": -33.77216162109375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.5690598487854, "step": 132000}
{"episode_reward": 376.7385254439699, "episode": 133.0, "batch_reward": 0.26027615040540697, "critic_loss": 0.633301342561841, "actor_loss": -33.03676069259644, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.349109411239624, "step": 133000}
{"episode_reward": 416.0426780491074, "episode": 134.0, "batch_reward": 0.26071027456223966, "critic_loss": 0.6273758418858051, "actor_loss": -33.43417454147339, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.39265251159668, "step": 134000}
{"episode_reward": 421.83197332701366, "episode": 135.0, "batch_reward": 0.262053564414382, "critic_loss": 0.559519898608327, "actor_loss": -33.810198329925534, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.24824857711792, "step": 135000}
{"episode_reward": 438.89121809979395, "episode": 136.0, "batch_reward": 0.26396221221983435, "critic_loss": 0.5524905282407999, "actor_loss": -33.551456436157224, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.216278076171875, "step": 136000}
{"episode_reward": 254.70519837868963, "episode": 137.0, "batch_reward": 0.26454081684350966, "critic_loss": 0.6046508677899838, "actor_loss": -33.8963289642334, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.31959342956543, "step": 137000}
{"episode_reward": 383.0165963641755, "episode": 138.0, "batch_reward": 0.2641039888858795, "critic_loss": 0.6324338195323944, "actor_loss": -34.258694625854496, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.84947657585144, "step": 138000}
{"episode_reward": 385.71565407502106, "episode": 139.0, "batch_reward": 0.2651105593889952, "critic_loss": 0.576699491545558, "actor_loss": -33.35455324554443, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.431199073791504, "step": 139000}
{"episode_reward": 390.3371762676588, "episode": 140.0, "batch_reward": 0.26506141148507595, "critic_loss": 0.5653914738297462, "actor_loss": -34.261553653717044, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.671483278274536, "step": 140000}
{"episode_reward": 427.62529439458194, "episode": 141.0, "batch_reward": 0.26805481538176534, "critic_loss": 0.585970987483859, "actor_loss": -34.048134449005126, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.34404182434082, "step": 141000}
{"episode_reward": 397.201689799949, "episode": 142.0, "batch_reward": 0.2679094987362623, "critic_loss": 0.5848849393576384, "actor_loss": -33.931108722686766, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.319694995880127, "step": 142000}
{"episode_reward": 362.1873998881756, "episode": 143.0, "batch_reward": 0.26851289826631547, "critic_loss": 0.6208426490575075, "actor_loss": -34.119302181243896, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.709340810775757, "step": 143000}
{"episode_reward": 420.4667044925808, "episode": 144.0, "batch_reward": 0.2699348296225071, "critic_loss": 0.6077971622049808, "actor_loss": -34.41302813720703, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.41863751411438, "step": 144000}
{"episode_reward": 365.80552496929477, "episode": 145.0, "batch_reward": 0.2704740090668201, "critic_loss": 0.6157882409095764, "actor_loss": -34.45566394042969, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.242477416992188, "step": 145000}
{"episode_reward": 411.9241004180937, "episode": 146.0, "batch_reward": 0.270679029405117, "critic_loss": 0.5925031597316265, "actor_loss": -33.82466690063477, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.366098642349243, "step": 146000}
{"episode_reward": 409.2020816972191, "episode": 147.0, "batch_reward": 0.27189826156198976, "critic_loss": 0.6652600711584091, "actor_loss": -34.346293594360354, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.726728677749634, "step": 147000}
{"episode_reward": 398.9822430285529, "episode": 148.0, "batch_reward": 0.27407554575800896, "critic_loss": 0.6107196909189224, "actor_loss": -34.30925643539429, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.384204387664795, "step": 148000}
{"episode_reward": 411.82875730205643, "episode": 149.0, "batch_reward": 0.2745945817232132, "critic_loss": 0.5848094944804907, "actor_loss": -34.65732288360596, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.94434905052185, "step": 149000}
{"episode_reward": 364.52622595489424, "episode": 150.0, "batch_reward": 0.274378874450922, "critic_loss": 0.6054411759227514, "actor_loss": -34.92556493759155, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
