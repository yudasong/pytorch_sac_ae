{"episode_reward": 0.0, "episode": 1.0, "duration": 17.383079767227173, "step": 1000}
{"episode_reward": 7.051849146674556, "episode": 2.0, "duration": 1.515533447265625, "step": 2000}
{"episode_reward": 365.4711839680396, "episode": 3.0, "batch_reward": 0.1756367131560872, "critic_loss": 0.04401399748708535, "actor_loss": -15.362022153092544, "actor_target_entropy": -6.0, "alpha_value": 0.01377813086574139, "duration": 61.81440329551697, "step": 3000}
{"episode_reward": 20.39107993147094, "episode": 4.0, "batch_reward": 0.11807134145498276, "critic_loss": 0.05056732777878642, "actor_loss": -12.076505332559346, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.001461029052734, "step": 4000}
{"episode_reward": 35.93850164460303, "episode": 5.0, "batch_reward": 0.09866368565708399, "critic_loss": 0.046526843197643754, "actor_loss": -12.099372166104615, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.678350687026978, "step": 5000}
{"episode_reward": 34.73406187960151, "episode": 6.0, "batch_reward": 0.08988664127141237, "critic_loss": 0.049270556878298524, "actor_loss": -12.963702806074172, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.890474796295166, "step": 6000}
{"episode_reward": 61.88375067520381, "episode": 7.0, "batch_reward": 0.08834978194534779, "critic_loss": 0.05803345180116594, "actor_loss": -11.827132661312818, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.95110845565796, "step": 7000}
{"episode_reward": 108.69102958945177, "episode": 8.0, "batch_reward": 0.09664974599331617, "critic_loss": 0.09357757646217943, "actor_loss": -13.170245561629534, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.355939626693726, "step": 8000}
{"episode_reward": 171.60397051535176, "episode": 9.0, "batch_reward": 0.10074535432085395, "critic_loss": 0.10183060232549906, "actor_loss": -13.97211707496643, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.956603050231934, "step": 9000}
{"episode_reward": 62.03048966577117, "episode": 10.0, "batch_reward": 0.09552995238453149, "critic_loss": 0.0873130949139595, "actor_loss": -13.40682293510437, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.361155033111572, "step": 10000}
{"episode_reward": 50.314472107402345, "episode": 11.0, "batch_reward": 0.09030890951305628, "critic_loss": 0.08221055081114173, "actor_loss": -13.170403043270111, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.466543436050415, "step": 11000}
{"episode_reward": 30.896901772735895, "episode": 12.0, "batch_reward": 0.08587854336574674, "critic_loss": 0.07726614174991846, "actor_loss": -12.54620493888855, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.26625967025757, "step": 12000}
{"episode_reward": 54.612581526325044, "episode": 13.0, "batch_reward": 0.08496648431569338, "critic_loss": 0.09507444574311376, "actor_loss": -11.56877311372757, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.489762544631958, "step": 13000}
{"episode_reward": 68.42189456437458, "episode": 14.0, "batch_reward": 0.08245196968689561, "critic_loss": 0.097978641692549, "actor_loss": -12.00109489250183, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.860628604888916, "step": 14000}
{"episode_reward": 48.87589486234875, "episode": 15.0, "batch_reward": 0.08112912683561445, "critic_loss": 0.12046579023823142, "actor_loss": -12.153179175376891, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.011410236358643, "step": 15000}
{"episode_reward": 64.52870323905316, "episode": 16.0, "batch_reward": 0.07773878647387028, "critic_loss": 0.11523122791200877, "actor_loss": -11.197311014175416, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.864383697509766, "step": 16000}
{"episode_reward": 25.401326527325313, "episode": 17.0, "batch_reward": 0.07505142318457365, "critic_loss": 0.10883202305436135, "actor_loss": -11.16367377948761, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.897839069366455, "step": 17000}
{"episode_reward": 39.59994003751727, "episode": 18.0, "batch_reward": 0.07604571578279137, "critic_loss": 0.11720070736110211, "actor_loss": -11.142627425670623, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.194084882736206, "step": 18000}
{"episode_reward": 114.92125997381258, "episode": 19.0, "batch_reward": 0.08036040043458342, "critic_loss": 0.1459124402180314, "actor_loss": -11.22808897972107, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.649978637695312, "step": 19000}
{"episode_reward": 227.86122159632097, "episode": 20.0, "batch_reward": 0.08574759056046605, "critic_loss": 0.15597334841266275, "actor_loss": -11.871910329341889, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.906203985214233, "step": 20000}
{"episode_reward": 98.9364756728291, "episode": 21.0, "batch_reward": 0.08893011594191194, "critic_loss": 0.17082081050053238, "actor_loss": -11.360475877285003, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.757752656936646, "step": 21000}
{"episode_reward": 204.48034730138443, "episode": 22.0, "batch_reward": 0.09133962907642126, "critic_loss": 0.17321376924961807, "actor_loss": -12.671045143127442, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.89451837539673, "step": 22000}
{"episode_reward": 83.85856624423351, "episode": 23.0, "batch_reward": 0.09002034946531057, "critic_loss": 0.17206925527006386, "actor_loss": -11.829044746398926, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.348025798797607, "step": 23000}
{"episode_reward": 50.123023317737555, "episode": 24.0, "batch_reward": 0.08865090135857463, "critic_loss": 0.1632025717869401, "actor_loss": -11.807218655586242, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.324445486068726, "step": 24000}
{"episode_reward": 112.64534136120642, "episode": 25.0, "batch_reward": 0.08882702868804336, "critic_loss": 0.18407252163439988, "actor_loss": -11.78624165725708, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.025611400604248, "step": 25000}
{"episode_reward": 35.591451164149824, "episode": 26.0, "batch_reward": 0.0874712650179863, "critic_loss": 0.2000415977537632, "actor_loss": -11.36053809261322, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.50016713142395, "step": 26000}
{"episode_reward": 61.53159018981953, "episode": 27.0, "batch_reward": 0.08561732459440827, "critic_loss": 0.21215798141807318, "actor_loss": -11.003341833114623, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.010313510894775, "step": 27000}
{"episode_reward": 37.13603515197326, "episode": 28.0, "batch_reward": 0.08561560197547079, "critic_loss": 0.20722283877432346, "actor_loss": -11.74611658859253, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.85235619544983, "step": 28000}
{"episode_reward": 81.2689663380072, "episode": 29.0, "batch_reward": 0.08402671460807323, "critic_loss": 0.21148918741941453, "actor_loss": -11.385787724494934, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.028199911117554, "step": 29000}
{"episode_reward": 40.39407067703993, "episode": 30.0, "batch_reward": 0.0829285959675908, "critic_loss": 0.2284428453966975, "actor_loss": -10.731745163917541, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.691193342208862, "step": 30000}
{"episode_reward": 43.90786762783709, "episode": 31.0, "batch_reward": 0.08099042320623993, "critic_loss": 0.21513595686852932, "actor_loss": -11.195144337654114, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.433053970336914, "step": 31000}
{"episode_reward": 36.67628521447114, "episode": 32.0, "batch_reward": 0.0795527286529541, "critic_loss": 0.23948454585671425, "actor_loss": -11.138299288749694, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.80731439590454, "step": 32000}
{"episode_reward": 39.83619931014589, "episode": 33.0, "batch_reward": 0.08137152123451233, "critic_loss": 0.27448256050795317, "actor_loss": -11.57142854309082, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.87893319129944, "step": 33000}
{"episode_reward": 265.82136175719563, "episode": 34.0, "batch_reward": 0.08599647367373109, "critic_loss": 0.27846106731891634, "actor_loss": -11.49368069267273, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.919809103012085, "step": 34000}
{"episode_reward": 168.4678070999356, "episode": 35.0, "batch_reward": 0.0862051914036274, "critic_loss": 0.2769522086381912, "actor_loss": -12.082368717193603, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.95587682723999, "step": 35000}
{"episode_reward": 65.42273017527191, "episode": 36.0, "batch_reward": 0.08844752948731184, "critic_loss": 0.26687139679491517, "actor_loss": -12.41519676208496, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.22303581237793, "step": 36000}
{"episode_reward": 191.69439658411233, "episode": 37.0, "batch_reward": 0.09053208129107952, "critic_loss": 0.29293616278469564, "actor_loss": -12.171246213912964, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.336109399795532, "step": 37000}
{"episode_reward": 123.8921443969144, "episode": 38.0, "batch_reward": 0.09234452565014363, "critic_loss": 0.29263656108081343, "actor_loss": -12.605784814834594, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.95826554298401, "step": 38000}
{"episode_reward": 257.679063206411, "episode": 39.0, "batch_reward": 0.09699122138321399, "critic_loss": 0.30897857470810414, "actor_loss": -13.023384426116943, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.25058650970459, "step": 39000}
{"episode_reward": 240.27073514535098, "episode": 40.0, "batch_reward": 0.10110652232542634, "critic_loss": 0.25901976180821656, "actor_loss": -13.079921887397767, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.150811433792114, "step": 40000}
{"episode_reward": 343.08784442730746, "episode": 41.0, "batch_reward": 0.1071706181243062, "critic_loss": 0.292353563465178, "actor_loss": -12.990696287155151, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.57489728927612, "step": 41000}
{"episode_reward": 342.8218809843232, "episode": 42.0, "batch_reward": 0.11302375906705857, "critic_loss": 0.3077527801245451, "actor_loss": -14.2854660282135, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.128270864486694, "step": 42000}
{"episode_reward": 348.1794113122799, "episode": 43.0, "batch_reward": 0.11704519487172366, "critic_loss": 0.3045335891991854, "actor_loss": -14.873050783157348, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.688944339752197, "step": 43000}
{"episode_reward": 131.12523962992148, "episode": 44.0, "batch_reward": 0.1156236881762743, "critic_loss": 0.2761611748561263, "actor_loss": -15.092518817901611, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.87710404396057, "step": 44000}
{"episode_reward": 67.33335035799321, "episode": 45.0, "batch_reward": 0.11568244887143374, "critic_loss": 0.2917192735075951, "actor_loss": -14.976795007705688, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.341827630996704, "step": 45000}
{"episode_reward": 86.86735249518325, "episode": 46.0, "batch_reward": 0.1170205792710185, "critic_loss": 0.27979069189727307, "actor_loss": -14.535416149139404, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.474624633789062, "step": 46000}
{"episode_reward": 398.1343783445589, "episode": 47.0, "batch_reward": 0.12114323952794075, "critic_loss": 0.2830700548887253, "actor_loss": -15.129240127563477, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.926754474639893, "step": 47000}
{"episode_reward": 114.70318576108069, "episode": 48.0, "batch_reward": 0.12345379392802715, "critic_loss": 0.28042784504592416, "actor_loss": -15.6827991771698, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.292712450027466, "step": 48000}
{"episode_reward": 336.4099370623352, "episode": 49.0, "batch_reward": 0.1268670959994197, "critic_loss": 0.32489192025363445, "actor_loss": -16.140682655334473, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.67796230316162, "step": 49000}
{"episode_reward": 293.8716088688495, "episode": 50.0, "batch_reward": 0.1306010811701417, "critic_loss": 0.33327133148908616, "actor_loss": -16.112607444763185, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.19865870475769, "step": 50000}
{"episode_reward": 372.52854391779124, "episode": 51.0, "batch_reward": 0.13593254965543747, "critic_loss": 0.3158054473400116, "actor_loss": -16.398835441589355, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.14453172683716, "step": 51000}
{"episode_reward": 335.20551772123827, "episode": 52.0, "batch_reward": 0.13932616098225117, "critic_loss": 0.3579793544262648, "actor_loss": -16.787324909210206, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.03175163269043, "step": 52000}
{"episode_reward": 377.7271005034309, "episode": 53.0, "batch_reward": 0.14385732480883598, "critic_loss": 0.36862545377016065, "actor_loss": -17.909924547195434, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.321685075759888, "step": 53000}
{"episode_reward": 249.57901717801295, "episode": 54.0, "batch_reward": 0.14452519049495458, "critic_loss": 0.32463150956481696, "actor_loss": -17.64704989242554, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.841552734375, "step": 54000}
{"episode_reward": 141.01917706279463, "episode": 55.0, "batch_reward": 0.14319299557060003, "critic_loss": 0.37418300135433674, "actor_loss": -17.702970291137696, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.883493661880493, "step": 55000}
{"episode_reward": 78.70405250021179, "episode": 56.0, "batch_reward": 0.14332167208194732, "critic_loss": 0.403915358170867, "actor_loss": -17.535978286743163, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.261126279830933, "step": 56000}
{"episode_reward": 130.58751219449297, "episode": 57.0, "batch_reward": 0.14368379925936461, "critic_loss": 0.38821329101920127, "actor_loss": -17.72709727859497, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.870362758636475, "step": 57000}
{"episode_reward": 120.4191098710648, "episode": 58.0, "batch_reward": 0.14220416317135096, "critic_loss": 0.3988719660639763, "actor_loss": -17.84536699295044, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.122198343276978, "step": 58000}
{"episode_reward": 89.65706183500862, "episode": 59.0, "batch_reward": 0.1437918408289552, "critic_loss": 0.3948497234210372, "actor_loss": -17.815459066390993, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.407774925231934, "step": 59000}
{"episode_reward": 310.3180536148966, "episode": 60.0, "batch_reward": 0.1463452364653349, "critic_loss": 0.38815628035366534, "actor_loss": -18.110275896072388, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.424952507019043, "step": 60000}
{"episode_reward": 372.57868965560056, "episode": 61.0, "batch_reward": 0.15103015438467265, "critic_loss": 0.4081950508356094, "actor_loss": -18.401421018600463, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.75682997703552, "step": 61000}
{"episode_reward": 391.46684609360744, "episode": 62.0, "batch_reward": 0.15215938088297845, "critic_loss": 0.4360473624765873, "actor_loss": -18.743288230895995, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.293954133987427, "step": 62000}
{"episode_reward": 103.47745787551085, "episode": 63.0, "batch_reward": 0.15294737528264524, "critic_loss": 0.43886435362696646, "actor_loss": -18.381344484329222, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.949875831604004, "step": 63000}
{"episode_reward": 374.8812666510366, "episode": 64.0, "batch_reward": 0.1543940483480692, "critic_loss": 0.4041611735969782, "actor_loss": -18.91286682510376, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.056636810302734, "step": 64000}
{"episode_reward": 65.22113741861581, "episode": 65.0, "batch_reward": 0.15543129289895297, "critic_loss": 0.3691023458093405, "actor_loss": -18.914143701553346, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.29479169845581, "step": 65000}
{"episode_reward": 375.8305075239795, "episode": 66.0, "batch_reward": 0.157100841216743, "critic_loss": 0.4095664989054203, "actor_loss": -19.070842931747436, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.578165769577026, "step": 66000}
{"episode_reward": 103.98499351237038, "episode": 67.0, "batch_reward": 0.1575598324239254, "critic_loss": 0.4173940327912569, "actor_loss": -19.664269187927246, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.134456157684326, "step": 67000}
{"episode_reward": 379.783678870219, "episode": 68.0, "batch_reward": 0.15923912976682186, "critic_loss": 0.4264949032366276, "actor_loss": -19.69054994392395, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.36176562309265, "step": 68000}
{"episode_reward": 94.25218562216708, "episode": 69.0, "batch_reward": 0.1596935094371438, "critic_loss": 0.46692702327668667, "actor_loss": -19.267881393432617, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.47612977027893, "step": 69000}
{"episode_reward": 484.97710166471734, "episode": 70.0, "batch_reward": 0.16417182423919438, "critic_loss": 0.4771191579401493, "actor_loss": -19.97435345840454, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.21516728401184, "step": 70000}
{"episode_reward": 420.60853454288116, "episode": 71.0, "batch_reward": 0.1687889060229063, "critic_loss": 0.48320482817292215, "actor_loss": -20.28548342514038, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.97696018218994, "step": 71000}
{"episode_reward": 478.16573557756686, "episode": 72.0, "batch_reward": 0.1736907349973917, "critic_loss": 0.491183222040534, "actor_loss": -20.67918821144104, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.863260746002197, "step": 72000}
{"episode_reward": 435.6094956144652, "episode": 73.0, "batch_reward": 0.1765858951061964, "critic_loss": 0.4779618658423424, "actor_loss": -21.09299866294861, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.20665693283081, "step": 73000}
{"episode_reward": 450.90461920141354, "episode": 74.0, "batch_reward": 0.17918072071671487, "critic_loss": 0.46269974192976954, "actor_loss": -21.387801156997682, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.211926460266113, "step": 74000}
{"episode_reward": 396.9256110887113, "episode": 75.0, "batch_reward": 0.18209415870904921, "critic_loss": 0.5183950355798006, "actor_loss": -21.554109657287597, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.28565788269043, "step": 75000}
{"episode_reward": 405.96056986823174, "episode": 76.0, "batch_reward": 0.1861905914992094, "critic_loss": 0.5407127914130687, "actor_loss": -21.983804206848145, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.52001428604126, "step": 76000}
{"episode_reward": 451.11671881680553, "episode": 77.0, "batch_reward": 0.18866733768582344, "critic_loss": 0.5948732234835624, "actor_loss": -22.494508850097656, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.154447078704834, "step": 77000}
{"episode_reward": 434.68223481690586, "episode": 78.0, "batch_reward": 0.19274201466143132, "critic_loss": 0.5495928143113852, "actor_loss": -22.851103477478027, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.08431911468506, "step": 78000}
{"episode_reward": 469.2097571504599, "episode": 79.0, "batch_reward": 0.1967571546882391, "critic_loss": 0.5207824721038341, "actor_loss": -23.38177285385132, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.174246549606323, "step": 79000}
{"episode_reward": 440.0982757585674, "episode": 80.0, "batch_reward": 0.19862058927118778, "critic_loss": 0.43143255305290223, "actor_loss": -23.781098552703856, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.371841192245483, "step": 80000}
{"episode_reward": 412.8572550659343, "episode": 81.0, "batch_reward": 0.2018155070245266, "critic_loss": 0.43692201125621793, "actor_loss": -23.942569702148436, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.60032057762146, "step": 81000}
{"episode_reward": 418.7567193297811, "episode": 82.0, "batch_reward": 0.20524032308161258, "critic_loss": 0.4013462748229504, "actor_loss": -23.98097805404663, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.352492332458496, "step": 82000}
{"episode_reward": 462.1438808608888, "episode": 83.0, "batch_reward": 0.20746988493204116, "critic_loss": 0.39566652968525884, "actor_loss": -24.35608625793457, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.4353609085083, "step": 83000}
{"episode_reward": 408.3368393629297, "episode": 84.0, "batch_reward": 0.2104497139751911, "critic_loss": 0.4475396364629269, "actor_loss": -24.77945471572876, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.971990823745728, "step": 84000}
{"episode_reward": 456.80740384276646, "episode": 85.0, "batch_reward": 0.21230588187277316, "critic_loss": 0.43925951835513116, "actor_loss": -24.706959716796874, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.090912580490112, "step": 85000}
{"episode_reward": 431.6789282457411, "episode": 86.0, "batch_reward": 0.21556619364023208, "critic_loss": 0.46290688242018224, "actor_loss": -25.10480159378052, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.23905372619629, "step": 86000}
{"episode_reward": 467.7636425503441, "episode": 87.0, "batch_reward": 0.21882512392103673, "critic_loss": 0.4449958615452051, "actor_loss": -25.364924438476564, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.447206497192383, "step": 87000}
{"episode_reward": 361.76842667749986, "episode": 88.0, "batch_reward": 0.21926194828748702, "critic_loss": 0.44545957769453526, "actor_loss": -25.41277938461304, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.263811588287354, "step": 88000}
{"episode_reward": 403.2959060190289, "episode": 89.0, "batch_reward": 0.2221644821316004, "critic_loss": 0.49832931531965735, "actor_loss": -25.531032012939452, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.42014169692993, "step": 89000}
{"episode_reward": 263.7604462871319, "episode": 90.0, "batch_reward": 0.2242198502123356, "critic_loss": 0.5076868767142296, "actor_loss": -25.614531787872316, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.60478687286377, "step": 90000}
{"episode_reward": 480.9884172863857, "episode": 91.0, "batch_reward": 0.2264932918548584, "critic_loss": 0.47765072543919085, "actor_loss": -25.79684730911255, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.329997062683105, "step": 91000}
{"episode_reward": 502.93456768758426, "episode": 92.0, "batch_reward": 0.22907563221454622, "critic_loss": 0.46892224246263503, "actor_loss": -26.386858249664307, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.9004328250885, "step": 92000}
{"episode_reward": 454.46703624886675, "episode": 93.0, "batch_reward": 0.2306407247930765, "critic_loss": 0.4572529101073742, "actor_loss": -26.19034685897827, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.277164459228516, "step": 93000}
{"episode_reward": 484.9717256790355, "episode": 94.0, "batch_reward": 0.23420449469983579, "critic_loss": 0.4630391932427883, "actor_loss": -26.686751094818113, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.084134340286255, "step": 94000}
{"episode_reward": 460.1243972175634, "episode": 95.0, "batch_reward": 0.2358431712090969, "critic_loss": 0.44367342633008955, "actor_loss": -27.1014879989624, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.01309895515442, "step": 95000}
{"episode_reward": 449.3994843220661, "episode": 96.0, "batch_reward": 0.2396651150882244, "critic_loss": 0.45847439393401146, "actor_loss": -27.059712287902833, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.4004385471344, "step": 96000}
{"episode_reward": 487.1534420496586, "episode": 97.0, "batch_reward": 0.24101531004905702, "critic_loss": 0.45088622108101845, "actor_loss": -27.296391567230224, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.662244081497192, "step": 97000}
{"episode_reward": 478.88312457634265, "episode": 98.0, "batch_reward": 0.24267679332196712, "critic_loss": 0.4348937709182501, "actor_loss": -27.81768109893799, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.887478351593018, "step": 98000}
{"episode_reward": 451.8708486895473, "episode": 99.0, "batch_reward": 0.2457582503259182, "critic_loss": 0.469441833153367, "actor_loss": -27.874839939117432, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.843481063842773, "step": 99000}
{"episode_reward": 467.79283882183955, "episode": 100.0, "batch_reward": 0.24896182577311993, "critic_loss": 0.43700488276779653, "actor_loss": -28.344336254119874, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.105308055877686, "step": 100000}
{"episode_reward": 462.2942293135301, "episode": 101.0, "batch_reward": 0.2499667865484953, "critic_loss": 0.4333785408735275, "actor_loss": -28.027298892974855, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.37309694290161, "step": 101000}
{"episode_reward": 487.22350395656696, "episode": 102.0, "batch_reward": 0.2523635310381651, "critic_loss": 0.4360085228383541, "actor_loss": -28.538894481658936, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.775017976760864, "step": 102000}
{"episode_reward": 491.63703381382464, "episode": 103.0, "batch_reward": 0.25467285646498206, "critic_loss": 0.406824707403779, "actor_loss": -28.664117851257323, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.04425024986267, "step": 103000}
{"episode_reward": 470.7080181679051, "episode": 104.0, "batch_reward": 0.2576767705380917, "critic_loss": 0.4074681701660156, "actor_loss": -28.69844221115112, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.36422061920166, "step": 104000}
{"episode_reward": 482.5189031668005, "episode": 105.0, "batch_reward": 0.2580852340608835, "critic_loss": 0.42620980079472065, "actor_loss": -28.799735927581786, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.47384262084961, "step": 105000}
{"episode_reward": 129.48688806920242, "episode": 106.0, "batch_reward": 0.2575058247298002, "critic_loss": 0.42028233632445333, "actor_loss": -28.897067852020264, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.444135189056396, "step": 106000}
{"episode_reward": 487.8505731752342, "episode": 107.0, "batch_reward": 0.2600525655597448, "critic_loss": 0.42291394236683844, "actor_loss": -28.921761222839354, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.205337524414062, "step": 107000}
{"episode_reward": 519.5414513863649, "episode": 108.0, "batch_reward": 0.26277484858036043, "critic_loss": 0.42535437279939653, "actor_loss": -29.503609748840333, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.190640687942505, "step": 108000}
{"episode_reward": 435.5485028869071, "episode": 109.0, "batch_reward": 0.2645765002369881, "critic_loss": 0.40180751189589503, "actor_loss": -29.334999893188478, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.88750147819519, "step": 109000}
{"episode_reward": 478.1068751614399, "episode": 110.0, "batch_reward": 0.26732188802957535, "critic_loss": 0.4160744794011116, "actor_loss": -29.95928875732422, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.397707223892212, "step": 110000}
{"episode_reward": 482.7966538001098, "episode": 111.0, "batch_reward": 0.26707151244580746, "critic_loss": 0.41447621284425257, "actor_loss": -29.74435866165161, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.00559878349304, "step": 111000}
{"episode_reward": 469.0999527213059, "episode": 112.0, "batch_reward": 0.26792917008697986, "critic_loss": 0.45299969594180584, "actor_loss": -29.988201778411867, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.552195072174072, "step": 112000}
{"episode_reward": 128.48617767759248, "episode": 113.0, "batch_reward": 0.26859160207211974, "critic_loss": 0.42415902695059776, "actor_loss": -29.79424264907837, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.862181425094604, "step": 113000}
{"episode_reward": 470.5627277896187, "episode": 114.0, "batch_reward": 0.27062786115705967, "critic_loss": 0.45965317675471307, "actor_loss": -30.256597129821778, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.87056040763855, "step": 114000}
{"episode_reward": 478.3466283970705, "episode": 115.0, "batch_reward": 0.2723020404279232, "critic_loss": 0.4202584799975157, "actor_loss": -30.41080270385742, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.59635591506958, "step": 115000}
{"episode_reward": 468.72797137672654, "episode": 116.0, "batch_reward": 0.273632522597909, "critic_loss": 0.4377385062277317, "actor_loss": -30.483227485656737, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.352679014205933, "step": 116000}
{"episode_reward": 494.7249375066019, "episode": 117.0, "batch_reward": 0.2764321678876877, "critic_loss": 0.44629459919035436, "actor_loss": -30.499783596038817, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.060994625091553, "step": 117000}
{"episode_reward": 501.10052798468166, "episode": 118.0, "batch_reward": 0.27790460869669914, "critic_loss": 0.44837728041410446, "actor_loss": -30.706837871551514, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.51917052268982, "step": 118000}
{"episode_reward": 495.4580723438481, "episode": 119.0, "batch_reward": 0.2786812095940113, "critic_loss": 0.46692395670711995, "actor_loss": -30.72570138168335, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.307750463485718, "step": 119000}
{"episode_reward": 491.88007639537994, "episode": 120.0, "batch_reward": 0.2800313019752502, "critic_loss": 0.43247551926970484, "actor_loss": -30.91795848083496, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.91863465309143, "step": 120000}
{"episode_reward": 440.48934404203834, "episode": 121.0, "batch_reward": 0.2818614816367626, "critic_loss": 0.4377798639088869, "actor_loss": -31.012572219848632, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 38.08735179901123, "step": 121000}
{"episode_reward": 470.4510881109644, "episode": 122.0, "batch_reward": 0.28363025598227976, "critic_loss": 0.42316079647839067, "actor_loss": -31.562314842224122, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.298065185546875, "step": 122000}
{"episode_reward": 492.71177928536093, "episode": 123.0, "batch_reward": 0.28572183541953566, "critic_loss": 0.4652398711591959, "actor_loss": -31.57924669265747, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.72037434577942, "step": 123000}
{"episode_reward": 491.1739010197513, "episode": 124.0, "batch_reward": 0.28823573818802833, "critic_loss": 0.4531881716698408, "actor_loss": -31.824882385253908, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.26290225982666, "step": 124000}
{"episode_reward": 454.23177461825003, "episode": 125.0, "batch_reward": 0.2888881744593382, "critic_loss": 0.4444516088813543, "actor_loss": -31.874696128845216, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.98170518875122, "step": 125000}
{"episode_reward": 524.9157355910397, "episode": 126.0, "batch_reward": 0.2900205069631338, "critic_loss": 0.4452881391495466, "actor_loss": -32.0547340965271, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.756653785705566, "step": 126000}
{"episode_reward": 481.99206960671336, "episode": 127.0, "batch_reward": 0.2918706185221672, "critic_loss": 0.44613302262127397, "actor_loss": -32.32495226287842, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.834677696228027, "step": 127000}
{"episode_reward": 528.4004581944489, "episode": 128.0, "batch_reward": 0.2940768022537231, "critic_loss": 0.42361515475064515, "actor_loss": -32.366775074005126, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.89760732650757, "step": 128000}
{"episode_reward": 511.4116958705466, "episode": 129.0, "batch_reward": 0.29653635013103485, "critic_loss": 0.4187610225975513, "actor_loss": -32.52732915878296, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.06151247024536, "step": 129000}
{"episode_reward": 510.81401791167127, "episode": 130.0, "batch_reward": 0.2966845233142376, "critic_loss": 0.46150283808261156, "actor_loss": -32.533782119750974, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.283822536468506, "step": 130000}
{"episode_reward": 466.30539117495886, "episode": 131.0, "batch_reward": 0.2989701258391142, "critic_loss": 0.4675404274612665, "actor_loss": -32.660837104797366, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.53868746757507, "step": 131000}
{"episode_reward": 505.3615246299655, "episode": 132.0, "batch_reward": 0.3003665963858366, "critic_loss": 0.39361659659445286, "actor_loss": -32.88081247329712, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.4238543510437, "step": 132000}
{"episode_reward": 517.4502407080107, "episode": 133.0, "batch_reward": 0.30193608567118646, "critic_loss": 0.432293450281024, "actor_loss": -32.735889823913574, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.085456132888794, "step": 133000}
{"episode_reward": 514.912131453945, "episode": 134.0, "batch_reward": 0.3033370524793863, "critic_loss": 0.44609743113815786, "actor_loss": -33.14075890350342, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.30596113204956, "step": 134000}
{"episode_reward": 531.3057626904019, "episode": 135.0, "batch_reward": 0.30493252366781237, "critic_loss": 0.43994752141833304, "actor_loss": -33.456830505371094, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.412333726882935, "step": 135000}
{"episode_reward": 554.3443384084134, "episode": 136.0, "batch_reward": 0.30790084233880044, "critic_loss": 0.42445444168150426, "actor_loss": -33.636667804718016, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.175711631774902, "step": 136000}
{"episode_reward": 541.7791621732664, "episode": 137.0, "batch_reward": 0.30848806554079056, "critic_loss": 0.4440031486302614, "actor_loss": -33.70433652114868, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.191458702087402, "step": 137000}
{"episode_reward": 492.8186580693425, "episode": 138.0, "batch_reward": 0.3100905287265778, "critic_loss": 0.43594653138518336, "actor_loss": -33.689440399169925, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.413172006607056, "step": 138000}
{"episode_reward": 546.9905608786122, "episode": 139.0, "batch_reward": 0.312540053665638, "critic_loss": 0.45266277350485323, "actor_loss": -33.94749787139892, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.345600843429565, "step": 139000}
{"episode_reward": 486.7019814604423, "episode": 140.0, "batch_reward": 0.31183532840013506, "critic_loss": 0.4330122246444225, "actor_loss": -33.867026313781736, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.335302114486694, "step": 140000}
{"episode_reward": 494.4305324918985, "episode": 141.0, "batch_reward": 0.3160389036536217, "critic_loss": 0.428846034437418, "actor_loss": -34.370590606689454, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.46910524368286, "step": 141000}
{"episode_reward": 503.8340343450585, "episode": 142.0, "batch_reward": 0.31626473253965376, "critic_loss": 0.4496109101474285, "actor_loss": -34.35814910888672, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.887497901916504, "step": 142000}
{"episode_reward": 503.49782369646715, "episode": 143.0, "batch_reward": 0.3157692676484585, "critic_loss": 0.4336183290183544, "actor_loss": -34.35919183349609, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.373107433319092, "step": 143000}
{"episode_reward": 481.1410184303007, "episode": 144.0, "batch_reward": 0.3182233138680458, "critic_loss": 0.441707578599453, "actor_loss": -34.41228466033935, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.245543241500854, "step": 144000}
{"episode_reward": 516.6930519267712, "episode": 145.0, "batch_reward": 0.31966520904004575, "critic_loss": 0.4215446095764637, "actor_loss": -34.6389481086731, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.450142860412598, "step": 145000}
{"episode_reward": 517.4575881172462, "episode": 146.0, "batch_reward": 0.32029080966115, "critic_loss": 0.4684976794272661, "actor_loss": -34.58867945480347, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.39824914932251, "step": 146000}
{"episode_reward": 521.235774580523, "episode": 147.0, "batch_reward": 0.320941675901413, "critic_loss": 0.4379151898175478, "actor_loss": -34.69743900299072, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.053010940551758, "step": 147000}
{"episode_reward": 525.6744459068616, "episode": 148.0, "batch_reward": 0.3243023978173733, "critic_loss": 0.431920832619071, "actor_loss": -34.89454586791992, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.178568363189697, "step": 148000}
{"episode_reward": 513.5585866370882, "episode": 149.0, "batch_reward": 0.32623146916925905, "critic_loss": 0.42848879820108415, "actor_loss": -35.23394522857666, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.984246730804443, "step": 149000}
{"episode_reward": 497.54163113944884, "episode": 150.0, "batch_reward": 0.32622019696235655, "critic_loss": 0.42935699108242986, "actor_loss": -35.41565737152099, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "step": 150000}
