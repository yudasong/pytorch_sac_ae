{"episode_reward": 0.0, "episode": 1.0, "duration": 12.998833656311035, "step": 1000}
{"episode_reward": 7.051849146674556, "episode": 2.0, "duration": 1.1115317344665527, "step": 2000}
{"episode_reward": 365.4711839680396, "episode": 3.0, "batch_reward": 0.17550372029988517, "critic_loss": 0.06526233393123802, "actor_loss": -32.71651771201903, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 68.8755555152893, "step": 3000}
{"episode_reward": 15.642674652715147, "episode": 4.0, "batch_reward": 0.11380347874760628, "critic_loss": 0.04065597078576684, "actor_loss": -26.62989204502106, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.794692039489746, "step": 4000}
{"episode_reward": 19.609498884181914, "episode": 5.0, "batch_reward": 0.0946302879601717, "critic_loss": 0.06720698062703014, "actor_loss": -24.429338116645813, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.64939856529236, "step": 5000}
{"episode_reward": 21.88657995465051, "episode": 6.0, "batch_reward": 0.08341749443858862, "critic_loss": 0.05757831668294966, "actor_loss": -20.492506721496582, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.07761287689209, "step": 6000}
{"episode_reward": 84.04660657321531, "episode": 7.0, "batch_reward": 0.08839091552793979, "critic_loss": 0.06106123349629342, "actor_loss": -21.37896000576019, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.65928602218628, "step": 7000}
{"episode_reward": 126.69302344209625, "episode": 8.0, "batch_reward": 0.09310697965323925, "critic_loss": 0.053929681688547136, "actor_loss": -20.511763607025145, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.63315773010254, "step": 8000}
{"episode_reward": 78.09378817513249, "episode": 9.0, "batch_reward": 0.09502856666594743, "critic_loss": 0.06731215787678957, "actor_loss": -19.47527640914917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.850959539413452, "step": 9000}
{"episode_reward": 168.95810216422797, "episode": 10.0, "batch_reward": 0.09966609933972359, "critic_loss": 0.07179687065258622, "actor_loss": -19.266437516212463, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.81241464614868, "step": 10000}
{"episode_reward": 110.88464465148257, "episode": 11.0, "batch_reward": 0.09965290477871895, "critic_loss": 0.07476414798945188, "actor_loss": -18.939538437366487, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.91160821914673, "step": 11000}
{"episode_reward": 102.34460628242185, "episode": 12.0, "batch_reward": 0.10067223750799895, "critic_loss": 0.07581470407173038, "actor_loss": -17.73778666782379, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.518168449401855, "step": 12000}
{"episode_reward": 98.77112240106439, "episode": 13.0, "batch_reward": 0.10191998463869095, "critic_loss": 0.07900496391579509, "actor_loss": -19.05567110967636, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.86022639274597, "step": 13000}
{"episode_reward": 143.63533559936423, "episode": 14.0, "batch_reward": 0.1045819986909628, "critic_loss": 0.0841397593729198, "actor_loss": -17.842866973400117, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.02128291130066, "step": 14000}
{"episode_reward": 135.07106419181105, "episode": 15.0, "batch_reward": 0.10680197291076184, "critic_loss": 0.10314354544505477, "actor_loss": -17.89175109910965, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.55975365638733, "step": 15000}
{"episode_reward": 149.73895193932375, "episode": 16.0, "batch_reward": 0.11112995343655348, "critic_loss": 0.12203628653660417, "actor_loss": -18.295415834784507, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.771478414535522, "step": 16000}
{"episode_reward": 186.38316978375528, "episode": 17.0, "batch_reward": 0.11155403075367212, "critic_loss": 0.1291503698527813, "actor_loss": -17.22052527526021, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.617075204849243, "step": 17000}
{"episode_reward": 26.548175042500297, "episode": 18.0, "batch_reward": 0.10924873388558626, "critic_loss": 0.14499413233995437, "actor_loss": -16.54148644787818, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.352585315704346, "step": 18000}
{"episode_reward": 114.56762454155896, "episode": 19.0, "batch_reward": 0.10957662100344896, "critic_loss": 0.13928915289789437, "actor_loss": -16.537010729402304, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.931958436965942, "step": 19000}
{"episode_reward": 91.94165463130591, "episode": 20.0, "batch_reward": 0.10896577019244433, "critic_loss": 0.14322248163819312, "actor_loss": -15.696306171804666, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.246248960494995, "step": 20000}
{"episode_reward": 98.7639290701729, "episode": 21.0, "batch_reward": 0.11035307748615741, "critic_loss": 0.13890042554587126, "actor_loss": -16.902300406694412, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.55010771751404, "step": 21000}
{"episode_reward": 198.5455643866111, "episode": 22.0, "batch_reward": 0.11169229075312614, "critic_loss": 0.13578439248353244, "actor_loss": -14.23049735969305, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.41023850440979, "step": 22000}
{"episode_reward": 84.29709062451143, "episode": 23.0, "batch_reward": 0.11447375900298357, "critic_loss": 0.14301637656241656, "actor_loss": -14.889285645246506, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.401216745376587, "step": 23000}
{"episode_reward": 246.99406952705954, "episode": 24.0, "batch_reward": 0.11620951680839062, "critic_loss": 0.1445516939535737, "actor_loss": -15.072247389316558, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.702313661575317, "step": 24000}
{"episode_reward": 86.06659665787232, "episode": 25.0, "batch_reward": 0.11590495125949382, "critic_loss": 0.13368747648596763, "actor_loss": -14.500922171592713, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.241208791732788, "step": 25000}
{"episode_reward": 85.21046805095821, "episode": 26.0, "batch_reward": 0.11302706676721573, "critic_loss": 0.13131351584941148, "actor_loss": -14.133859576702118, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.924057245254517, "step": 26000}
{"episode_reward": 41.4417072883067, "episode": 27.0, "batch_reward": 0.11203403528779746, "critic_loss": 0.14175195430219173, "actor_loss": -14.083999022960663, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.866132736206055, "step": 27000}
{"episode_reward": 93.39713050435984, "episode": 28.0, "batch_reward": 0.1097935021519661, "critic_loss": 0.14101300068944692, "actor_loss": -13.16865462732315, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.607890129089355, "step": 28000}
{"episode_reward": 38.28120020183671, "episode": 29.0, "batch_reward": 0.1090516279861331, "critic_loss": 0.16015876967459916, "actor_loss": -13.239868606567383, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.26368522644043, "step": 29000}
{"episode_reward": 95.7145160367335, "episode": 30.0, "batch_reward": 0.10734476159512997, "critic_loss": 0.1422180645056069, "actor_loss": -13.331486782550812, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.62591004371643, "step": 30000}
{"episode_reward": 51.94444238273707, "episode": 31.0, "batch_reward": 0.10528155606985092, "critic_loss": 0.14684652199596165, "actor_loss": -12.702225170612335, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.68945288658142, "step": 31000}
{"episode_reward": 57.05540251066315, "episode": 32.0, "batch_reward": 0.10381187038123607, "critic_loss": 0.1522385328114033, "actor_loss": -12.225416588783265, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.678661108016968, "step": 32000}
{"episode_reward": 55.31012810480043, "episode": 33.0, "batch_reward": 0.10489754784852266, "critic_loss": 0.1575743354037404, "actor_loss": -12.131831144332885, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.30763268470764, "step": 33000}
{"episode_reward": 266.59220340087944, "episode": 34.0, "batch_reward": 0.11050142203271389, "critic_loss": 0.17283955705910922, "actor_loss": -12.3776712141037, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.95679473876953, "step": 34000}
{"episode_reward": 185.7120400339766, "episode": 35.0, "batch_reward": 0.11147755213081836, "critic_loss": 0.16650083241984248, "actor_loss": -12.11342828464508, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.680885553359985, "step": 35000}
{"episode_reward": 294.51289819815895, "episode": 36.0, "batch_reward": 0.11718616397678852, "critic_loss": 0.1621676162853837, "actor_loss": -12.018100666999818, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.258301258087158, "step": 36000}
{"episode_reward": 282.7623406991054, "episode": 37.0, "batch_reward": 0.11948011694848537, "critic_loss": 0.14770667299628257, "actor_loss": -12.939173072814942, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.59070611000061, "step": 37000}
{"episode_reward": 70.97777976557492, "episode": 38.0, "batch_reward": 0.119347506955266, "critic_loss": 0.15583293148130178, "actor_loss": -13.209123141288757, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.033266305923462, "step": 38000}
{"episode_reward": 140.94834674664332, "episode": 39.0, "batch_reward": 0.11941473219543695, "critic_loss": 0.14962223050370813, "actor_loss": -12.552404063224792, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.338874101638794, "step": 39000}
{"episode_reward": 58.873434719311945, "episode": 40.0, "batch_reward": 0.11722460444271564, "critic_loss": 0.1746280088722706, "actor_loss": -12.003309320449828, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.94697880744934, "step": 40000}
{"episode_reward": 68.56177278248892, "episode": 41.0, "batch_reward": 0.11558737955242396, "critic_loss": 0.160151025891304, "actor_loss": -12.329004610061645, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 35.494587659835815, "step": 41000}
{"episode_reward": 64.67997956521027, "episode": 42.0, "batch_reward": 0.11840622167289257, "critic_loss": 0.18578829534351826, "actor_loss": -12.302244234085084, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.943799257278442, "step": 42000}
{"episode_reward": 382.1347693915037, "episode": 43.0, "batch_reward": 0.12174995097517967, "critic_loss": 0.18156579157710076, "actor_loss": -12.402247142791747, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.86574125289917, "step": 43000}
{"episode_reward": 81.23425928779548, "episode": 44.0, "batch_reward": 0.12117851608246565, "critic_loss": 0.18407546202093364, "actor_loss": -11.6856597032547, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.346338033676147, "step": 44000}
{"episode_reward": 133.7134554908467, "episode": 45.0, "batch_reward": 0.1199956674799323, "critic_loss": 0.18470084072649479, "actor_loss": -12.106264255523682, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.303759574890137, "step": 45000}
{"episode_reward": 55.25571448648703, "episode": 46.0, "batch_reward": 0.12011785522848367, "critic_loss": 0.20308071125298738, "actor_loss": -12.56189448928833, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.210283756256104, "step": 46000}
{"episode_reward": 110.07114037019525, "episode": 47.0, "batch_reward": 0.12088490328192711, "critic_loss": 0.18751412189751865, "actor_loss": -12.41324621963501, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.222896575927734, "step": 47000}
{"episode_reward": 267.4932162161566, "episode": 48.0, "batch_reward": 0.1254888359680772, "critic_loss": 0.1971906645298004, "actor_loss": -12.809127388000489, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.927473306655884, "step": 48000}
{"episode_reward": 349.7772738748841, "episode": 49.0, "batch_reward": 0.12874275343120098, "critic_loss": 0.19518756821751596, "actor_loss": -13.114682956695557, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.363297700881958, "step": 49000}
{"episode_reward": 137.58832297063717, "episode": 50.0, "batch_reward": 0.1268264577910304, "critic_loss": 0.19876285748928785, "actor_loss": -13.005054265975952, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.47172212600708, "step": 50000}
{"episode_reward": 58.198199844165565, "episode": 51.0, "batch_reward": 0.12850580802559852, "critic_loss": 0.18039809928834438, "actor_loss": -13.348361923217773, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.85014319419861, "step": 51000}
{"episode_reward": 419.6947595694766, "episode": 52.0, "batch_reward": 0.13415139836072923, "critic_loss": 0.19415540551394225, "actor_loss": -14.109865879058837, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.46380639076233, "step": 52000}
{"episode_reward": 388.6049051583229, "episode": 53.0, "batch_reward": 0.13729761904478074, "critic_loss": 0.2093205603286624, "actor_loss": -14.116254776000977, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.09513282775879, "step": 53000}
{"episode_reward": 213.52200001220243, "episode": 54.0, "batch_reward": 0.13840627120435237, "critic_loss": 0.20837629319727421, "actor_loss": -14.329209913253784, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.4850652217865, "step": 54000}
{"episode_reward": 131.9244475123295, "episode": 55.0, "batch_reward": 0.13677696312218904, "critic_loss": 0.20641343475878238, "actor_loss": -14.715255786895751, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.41968870162964, "step": 55000}
{"episode_reward": 57.4133702850392, "episode": 56.0, "batch_reward": 0.13848475600779056, "critic_loss": 0.19980660981684922, "actor_loss": -14.976238904953004, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.272661924362183, "step": 56000}
{"episode_reward": 418.44810142637084, "episode": 57.0, "batch_reward": 0.14398619613051414, "critic_loss": 0.2136948189213872, "actor_loss": -15.380884552001953, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.437251329421997, "step": 57000}
{"episode_reward": 460.86553527723345, "episode": 58.0, "batch_reward": 0.1490979913547635, "critic_loss": 0.1816296153962612, "actor_loss": -15.956496797561645, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.319978713989258, "step": 58000}
{"episode_reward": 349.24398138736666, "episode": 59.0, "batch_reward": 0.15296851766109468, "critic_loss": 0.2076893148124218, "actor_loss": -16.44173680305481, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.364338636398315, "step": 59000}
{"episode_reward": 475.71082021206877, "episode": 60.0, "batch_reward": 0.15814539570361374, "critic_loss": 0.19893569465726613, "actor_loss": -17.074580837249755, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.826027154922485, "step": 60000}
{"episode_reward": 452.62341733078966, "episode": 61.0, "batch_reward": 0.16233952126652001, "critic_loss": 0.20272011458873748, "actor_loss": -17.559782737731933, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.49938082695007, "step": 61000}
{"episode_reward": 222.62487777750044, "episode": 62.0, "batch_reward": 0.16409257110953332, "critic_loss": 0.21974661262333392, "actor_loss": -17.754206844329833, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.874987840652466, "step": 62000}
{"episode_reward": 471.02361852695725, "episode": 63.0, "batch_reward": 0.1693922063112259, "critic_loss": 0.20449681853875518, "actor_loss": -18.554494173049928, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.88391900062561, "step": 63000}
{"episode_reward": 485.5933142299107, "episode": 64.0, "batch_reward": 0.17391448959708214, "critic_loss": 0.21949070251733066, "actor_loss": -18.83166460418701, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.958638906478882, "step": 64000}
{"episode_reward": 483.8478643347805, "episode": 65.0, "batch_reward": 0.17824405446648597, "critic_loss": 0.2226602503657341, "actor_loss": -19.387721019744873, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.628612995147705, "step": 65000}
{"episode_reward": 336.4109056445718, "episode": 66.0, "batch_reward": 0.18164662401378154, "critic_loss": 0.20392288854718207, "actor_loss": -19.907868198394777, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.929617881774902, "step": 66000}
{"episode_reward": 486.0308748002247, "episode": 67.0, "batch_reward": 0.18615058454871178, "critic_loss": 0.21769290491938592, "actor_loss": -20.17831231689453, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.238203525543213, "step": 67000}
{"episode_reward": 452.33795495779754, "episode": 68.0, "batch_reward": 0.19035313652455807, "critic_loss": 0.21197568548470735, "actor_loss": -20.50829376602173, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.446528911590576, "step": 68000}
{"episode_reward": 499.6755526805519, "episode": 69.0, "batch_reward": 0.19364476323127747, "critic_loss": 0.22056319393217563, "actor_loss": -21.20800020980835, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.32268476486206, "step": 69000}
{"episode_reward": 464.6427752531002, "episode": 70.0, "batch_reward": 0.19958861844241618, "critic_loss": 0.22129329050332308, "actor_loss": -21.689503173828125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.037408113479614, "step": 70000}
{"episode_reward": 495.91047176552814, "episode": 71.0, "batch_reward": 0.2032354125827551, "critic_loss": 0.2212689242064953, "actor_loss": -22.335757629394532, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.597726583480835, "step": 71000}
{"episode_reward": 521.9558832530367, "episode": 72.0, "batch_reward": 0.20461884367465974, "critic_loss": 0.2016107423827052, "actor_loss": -22.317152500152588, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.655319213867188, "step": 72000}
{"episode_reward": 98.45592792957041, "episode": 73.0, "batch_reward": 0.20594499322772025, "critic_loss": 0.21088436959683896, "actor_loss": -22.60802938079834, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.718599319458008, "step": 73000}
{"episode_reward": 516.3437309371218, "episode": 74.0, "batch_reward": 0.20957601840794088, "critic_loss": 0.21962828782200813, "actor_loss": -23.05220596694946, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.51372218132019, "step": 74000}
{"episode_reward": 493.89797785472973, "episode": 75.0, "batch_reward": 0.21294233006238938, "critic_loss": 0.23042987716197968, "actor_loss": -23.46374426269531, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.41936206817627, "step": 75000}
{"episode_reward": 526.5860377402814, "episode": 76.0, "batch_reward": 0.21853902401030065, "critic_loss": 0.23399164512753487, "actor_loss": -24.008955562591552, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.37975239753723, "step": 76000}
{"episode_reward": 504.56482131639416, "episode": 77.0, "batch_reward": 0.22194060477614402, "critic_loss": 0.2194601426795125, "actor_loss": -24.265304859161375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.570760250091553, "step": 77000}
{"episode_reward": 536.2575986490599, "episode": 78.0, "batch_reward": 0.22564792853593826, "critic_loss": 0.2163015484958887, "actor_loss": -24.72256621170044, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.2577805519104, "step": 78000}
{"episode_reward": 528.6182932153513, "episode": 79.0, "batch_reward": 0.23022360803186895, "critic_loss": 0.227010001167655, "actor_loss": -25.08170000076294, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.176629066467285, "step": 79000}
{"episode_reward": 537.0837743273537, "episode": 80.0, "batch_reward": 0.23325935637950898, "critic_loss": 0.21700853427499533, "actor_loss": -25.70803815460205, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.9349205493927, "step": 80000}
{"episode_reward": 535.583939339528, "episode": 81.0, "batch_reward": 0.23819026318192482, "critic_loss": 0.21487911931425333, "actor_loss": -26.057298446655274, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.715659379959106, "step": 81000}
{"episode_reward": 522.9615565169402, "episode": 82.0, "batch_reward": 0.2401591172516346, "critic_loss": 0.23234722390025855, "actor_loss": -26.505893310546874, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.10655903816223, "step": 82000}
{"episode_reward": 509.14012045546, "episode": 83.0, "batch_reward": 0.2444210595935583, "critic_loss": 0.2335493930131197, "actor_loss": -26.709708087921143, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.603086709976196, "step": 83000}
{"episode_reward": 504.05568619003395, "episode": 84.0, "batch_reward": 0.24741745154559613, "critic_loss": 0.24393887156248092, "actor_loss": -27.194083171844483, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.10350799560547, "step": 84000}
{"episode_reward": 547.8808516874781, "episode": 85.0, "batch_reward": 0.25097139477729796, "critic_loss": 0.23617715998739003, "actor_loss": -27.568222991943358, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.428807020187378, "step": 85000}
{"episode_reward": 556.0385681570325, "episode": 86.0, "batch_reward": 0.25463604606688023, "critic_loss": 0.23996058394014835, "actor_loss": -28.01612395477295, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.290239334106445, "step": 86000}
{"episode_reward": 562.7682546320718, "episode": 87.0, "batch_reward": 0.25797883394360543, "critic_loss": 0.24916790839284658, "actor_loss": -28.476616886138917, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.086694955825806, "step": 87000}
{"episode_reward": 573.2684635531712, "episode": 88.0, "batch_reward": 0.2609048454016447, "critic_loss": 0.25052325435727835, "actor_loss": -28.72217067337036, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.192526817321777, "step": 88000}
{"episode_reward": 595.046354194396, "episode": 89.0, "batch_reward": 0.26480087360739707, "critic_loss": 0.22684071674197911, "actor_loss": -29.310694011688234, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.46088743209839, "step": 89000}
{"episode_reward": 541.0812680954987, "episode": 90.0, "batch_reward": 0.2692375680357218, "critic_loss": 0.25832213301211593, "actor_loss": -29.7427568359375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.114644527435303, "step": 90000}
{"episode_reward": 453.714983763254, "episode": 91.0, "batch_reward": 0.27022736325860025, "critic_loss": 0.23644102440774442, "actor_loss": -29.944930648803712, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.793867349624634, "step": 91000}
{"episode_reward": 548.6908300176462, "episode": 92.0, "batch_reward": 0.2737138523608446, "critic_loss": 0.2622564677670598, "actor_loss": -30.30707592010498, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.004074335098267, "step": 92000}
{"episode_reward": 535.558839597171, "episode": 93.0, "batch_reward": 0.27702927657961846, "critic_loss": 0.26160884568095205, "actor_loss": -30.805139095306398, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.668033361434937, "step": 93000}
{"episode_reward": 563.9222893391204, "episode": 94.0, "batch_reward": 0.27840569119155406, "critic_loss": 0.2324581089168787, "actor_loss": -31.01620838546753, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.302030324935913, "step": 94000}
{"episode_reward": 105.60734361149547, "episode": 95.0, "batch_reward": 0.27761334532499315, "critic_loss": 0.2781517901942134, "actor_loss": -31.092587322235108, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.126235008239746, "step": 95000}
{"episode_reward": 526.7174587248164, "episode": 96.0, "batch_reward": 0.2807542743980885, "critic_loss": 0.2668272240012884, "actor_loss": -31.382894523620607, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.711036443710327, "step": 96000}
{"episode_reward": 561.5751729148666, "episode": 97.0, "batch_reward": 0.2827429447770119, "critic_loss": 0.25883700397610665, "actor_loss": -31.897442722320555, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.16507887840271, "step": 97000}
{"episode_reward": 569.7282504472319, "episode": 98.0, "batch_reward": 0.28495577175915243, "critic_loss": 0.2556524986177683, "actor_loss": -32.012330406188966, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.779285430908203, "step": 98000}
{"episode_reward": 544.3917833039599, "episode": 99.0, "batch_reward": 0.28912562400102615, "critic_loss": 0.2730861532613635, "actor_loss": -32.45238595199585, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.4094398021698, "step": 99000}
{"episode_reward": 578.0970911793105, "episode": 100.0, "batch_reward": 0.29193793123960493, "critic_loss": 0.26873388908058404, "actor_loss": -32.70151536178589, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.972429513931274, "step": 100000}
{"episode_reward": 554.3279190318488, "episode": 101.0, "batch_reward": 0.2935305973887444, "critic_loss": 0.2539368661865592, "actor_loss": -32.968341732025145, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.631574630737305, "step": 101000}
{"episode_reward": 548.4454500890572, "episode": 102.0, "batch_reward": 0.2966219732016325, "critic_loss": 0.25229688300192354, "actor_loss": -33.23029321289062, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.760979652404785, "step": 102000}
{"episode_reward": 557.4146788932997, "episode": 103.0, "batch_reward": 0.29751584489643573, "critic_loss": 0.27222834416478875, "actor_loss": -33.47089713287353, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.158463716506958, "step": 103000}
{"episode_reward": 242.2457476147908, "episode": 104.0, "batch_reward": 0.2978144645690918, "critic_loss": 0.26526265377551317, "actor_loss": -33.31658020019531, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.032333612442017, "step": 104000}
{"episode_reward": 551.9323949047913, "episode": 105.0, "batch_reward": 0.3016818742901087, "critic_loss": 0.29329410783201454, "actor_loss": -33.825319778442385, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.00580334663391, "step": 105000}
{"episode_reward": 565.3260530945653, "episode": 106.0, "batch_reward": 0.30391078858077525, "critic_loss": 0.29245029113441706, "actor_loss": -34.09833958435058, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.575374364852905, "step": 106000}
{"episode_reward": 581.6190549097688, "episode": 107.0, "batch_reward": 0.3057186938673258, "critic_loss": 0.30333818566799164, "actor_loss": -34.227706897735594, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.448521375656128, "step": 107000}
{"episode_reward": 559.3308995913225, "episode": 108.0, "batch_reward": 0.30872794140875337, "critic_loss": 0.29727459705621007, "actor_loss": -34.54369854354859, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.91160488128662, "step": 108000}
{"episode_reward": 578.1678063514328, "episode": 109.0, "batch_reward": 0.3120115931928158, "critic_loss": 0.2780014688000083, "actor_loss": -34.91944881820679, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.932634115219116, "step": 109000}
{"episode_reward": 560.7019347592973, "episode": 110.0, "batch_reward": 0.31401544335484505, "critic_loss": 0.2929351343214512, "actor_loss": -35.05310633468628, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.0907723903656, "step": 110000}
{"episode_reward": 566.9740784594368, "episode": 111.0, "batch_reward": 0.3162078540027142, "critic_loss": 0.30028587583452465, "actor_loss": -35.3059305229187, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.35721039772034, "step": 111000}
{"episode_reward": 562.5855336329525, "episode": 112.0, "batch_reward": 0.31781595838069915, "critic_loss": 0.2695304569602013, "actor_loss": -35.452807205200195, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.138092041015625, "step": 112000}
{"episode_reward": 599.0565793687147, "episode": 113.0, "batch_reward": 0.32018669562041757, "critic_loss": 0.2982559644281864, "actor_loss": -35.72126695251465, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.89281153678894, "step": 113000}
{"episode_reward": 586.3855096098575, "episode": 114.0, "batch_reward": 0.3224142737090588, "critic_loss": 0.27036383119225504, "actor_loss": -35.9630099067688, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.371782779693604, "step": 114000}
{"episode_reward": 596.3383313875817, "episode": 115.0, "batch_reward": 0.32551590165495875, "critic_loss": 0.2888142073974013, "actor_loss": -36.27385941696167, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.018266201019287, "step": 115000}
{"episode_reward": 553.5585380940194, "episode": 116.0, "batch_reward": 0.32746268455684185, "critic_loss": 0.27590401367098094, "actor_loss": -36.44628702926636, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.140607595443726, "step": 116000}
{"episode_reward": 556.5583753069601, "episode": 117.0, "batch_reward": 0.33062801738083364, "critic_loss": 0.2983710279241204, "actor_loss": -36.73590203857422, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.946075439453125, "step": 117000}
{"episode_reward": 555.8278634820435, "episode": 118.0, "batch_reward": 0.3315412832200527, "critic_loss": 0.30927897519618275, "actor_loss": -36.908332485198976, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.207263231277466, "step": 118000}
{"episode_reward": 594.9716163117596, "episode": 119.0, "batch_reward": 0.33377135494351384, "critic_loss": 0.31271953823417425, "actor_loss": -37.059602684020994, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.49895143508911, "step": 119000}
{"episode_reward": 585.8244599443337, "episode": 120.0, "batch_reward": 0.3345116825997829, "critic_loss": 0.29027006727457044, "actor_loss": -37.237625839233395, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.599395275115967, "step": 120000}
{"episode_reward": 578.8130907590082, "episode": 121.0, "batch_reward": 0.3363054618239403, "critic_loss": 0.32554713971912863, "actor_loss": -37.388557010650636, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.57372188568115, "step": 121000}
{"episode_reward": 574.4454664777742, "episode": 122.0, "batch_reward": 0.33916111168265345, "critic_loss": 0.3177858035340905, "actor_loss": -37.7131357421875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.452518939971924, "step": 122000}
{"episode_reward": 541.8475679462061, "episode": 123.0, "batch_reward": 0.3407957636713982, "critic_loss": 0.3266940896585584, "actor_loss": -37.874397087097165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.119007110595703, "step": 123000}
{"episode_reward": 586.8357722663105, "episode": 124.0, "batch_reward": 0.34365875682234764, "critic_loss": 0.2923398796617985, "actor_loss": -38.21487998199463, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.41954016685486, "step": 124000}
{"episode_reward": 622.8878416284587, "episode": 125.0, "batch_reward": 0.3449271404445171, "critic_loss": 0.3111032592654228, "actor_loss": -38.30331800842285, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.567342281341553, "step": 125000}
{"episode_reward": 581.5894819212281, "episode": 126.0, "batch_reward": 0.34771800446510315, "critic_loss": 0.31390443398803475, "actor_loss": -38.78750838470459, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.409584760665894, "step": 126000}
{"episode_reward": 582.7911135955759, "episode": 127.0, "batch_reward": 0.3491082642674446, "critic_loss": 0.281608023814857, "actor_loss": -38.9560241394043, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.597452640533447, "step": 127000}
{"episode_reward": 612.2072728848794, "episode": 128.0, "batch_reward": 0.35069221252202987, "critic_loss": 0.2848152845352888, "actor_loss": -39.23985403442383, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.12649631500244, "step": 128000}
{"episode_reward": 593.8500449858858, "episode": 129.0, "batch_reward": 0.35250611558556555, "critic_loss": 0.2745082274153829, "actor_loss": -39.34726262664795, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.014141082763672, "step": 129000}
{"episode_reward": 582.2947961988864, "episode": 130.0, "batch_reward": 0.35483422976732254, "critic_loss": 0.2838174310326576, "actor_loss": -39.63415421295166, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.56531310081482, "step": 130000}
{"episode_reward": 618.8746250223904, "episode": 131.0, "batch_reward": 0.3576973476111889, "critic_loss": 0.29061971931159497, "actor_loss": -39.84500682830811, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.32489728927612, "step": 131000}
{"episode_reward": 547.4324779336615, "episode": 132.0, "batch_reward": 0.3570095681548119, "critic_loss": 0.31393419951200485, "actor_loss": -39.87115490722656, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.308398485183716, "step": 132000}
{"episode_reward": 120.4344292432622, "episode": 133.0, "batch_reward": 0.3570318723022938, "critic_loss": 0.3157038848772645, "actor_loss": -39.8713757019043, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.00795006752014, "step": 133000}
{"episode_reward": 546.3858870453488, "episode": 134.0, "batch_reward": 0.35660824862122537, "critic_loss": 0.32731224804371595, "actor_loss": -39.791543327331546, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.389492750167847, "step": 134000}
{"episode_reward": 442.9591910257337, "episode": 135.0, "batch_reward": 0.3578270782530308, "critic_loss": 0.3166550919190049, "actor_loss": -39.96846176147461, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.95067262649536, "step": 135000}
{"episode_reward": 589.2796103954047, "episode": 136.0, "batch_reward": 0.3610670546591282, "critic_loss": 0.3393782130777836, "actor_loss": -40.34470938110351, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.962625980377197, "step": 136000}
{"episode_reward": 529.1725747674841, "episode": 137.0, "batch_reward": 0.3628341879546642, "critic_loss": 0.3835009570047259, "actor_loss": -40.595967918396, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.230223655700684, "step": 137000}
{"episode_reward": 584.8392193608921, "episode": 138.0, "batch_reward": 0.36304727351665494, "critic_loss": 0.3560591184794903, "actor_loss": -40.639678588867184, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.60585069656372, "step": 138000}
{"episode_reward": 586.6783044000512, "episode": 139.0, "batch_reward": 0.3660187133848667, "critic_loss": 0.3736441607400775, "actor_loss": -40.995108642578124, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.27754831314087, "step": 139000}
{"episode_reward": 589.0940328553696, "episode": 140.0, "batch_reward": 0.3649992689192295, "critic_loss": 0.3961405208855867, "actor_loss": -40.9586122970581, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.772341012954712, "step": 140000}
{"episode_reward": 562.6624583848991, "episode": 141.0, "batch_reward": 0.36991524705290796, "critic_loss": 0.3442563355863094, "actor_loss": -41.32450582122803, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 34.2578604221344, "step": 141000}
{"episode_reward": 595.1589921091569, "episode": 142.0, "batch_reward": 0.37025816848874094, "critic_loss": 0.3410854245349765, "actor_loss": -41.55311483001709, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.294833421707153, "step": 142000}
{"episode_reward": 596.3799935296718, "episode": 143.0, "batch_reward": 0.370675463706255, "critic_loss": 0.3676661931499839, "actor_loss": -41.746600204467775, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.720030784606934, "step": 143000}
{"episode_reward": 581.3841545256946, "episode": 144.0, "batch_reward": 0.3729900641739368, "critic_loss": 0.3234525797367096, "actor_loss": -41.96545620727539, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.198175191879272, "step": 144000}
{"episode_reward": 592.3964304332972, "episode": 145.0, "batch_reward": 0.3742396065890789, "critic_loss": 0.3646734838336706, "actor_loss": -42.23054970550537, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.436431407928467, "step": 145000}
{"episode_reward": 613.4646550666693, "episode": 146.0, "batch_reward": 0.37439066725969317, "critic_loss": 0.3537756998836994, "actor_loss": -42.33696173095703, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.031951665878296, "step": 146000}
{"episode_reward": 606.8750582059694, "episode": 147.0, "batch_reward": 0.37605131804943087, "critic_loss": 0.3516933414712548, "actor_loss": -42.501067749023434, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.160041332244873, "step": 147000}
{"episode_reward": 619.8806330610987, "episode": 148.0, "batch_reward": 0.38032377591729166, "critic_loss": 0.361336648479104, "actor_loss": -42.76963014984131, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.687889337539673, "step": 148000}
{"episode_reward": 591.1061547067675, "episode": 149.0, "batch_reward": 0.3805903999209404, "critic_loss": 0.3110687243565917, "actor_loss": -42.93376708984375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.196075201034546, "step": 149000}
{"episode_reward": 607.3783533713332, "episode": 150.0, "batch_reward": 0.38140856942534446, "critic_loss": 0.30022684642672537, "actor_loss": -42.76330384063721, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
