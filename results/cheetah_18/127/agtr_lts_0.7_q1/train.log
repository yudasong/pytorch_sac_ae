{"episode_reward": 0.0, "episode": 1.0, "duration": 19.543611526489258, "step": 1000}
{"episode_reward": 7.051849146674556, "episode": 2.0, "duration": 1.7968299388885498, "step": 2000}
{"episode_reward": 365.4711839680396, "episode": 3.0, "batch_reward": 0.1826144946728519, "critic_loss": 0.43490709245165177, "actor_loss": -35.9564455008688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 69.241286277771, "step": 3000}
{"episode_reward": 156.25458084907422, "episode": 4.0, "batch_reward": 0.17428904515504837, "critic_loss": 0.5029029998183251, "actor_loss": -34.16047256088257, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.393781661987305, "step": 4000}
{"episode_reward": 178.83930669009655, "episode": 5.0, "batch_reward": 0.189635213509202, "critic_loss": 0.5347923676967621, "actor_loss": -34.35605150604248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.212775707244873, "step": 5000}
{"episode_reward": 314.39172517256685, "episode": 6.0, "batch_reward": 0.21328244258463383, "critic_loss": 0.5499326295256615, "actor_loss": -35.205607837677, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.323350429534912, "step": 6000}
{"episode_reward": 312.68518095740694, "episode": 7.0, "batch_reward": 0.23000482779741288, "critic_loss": 0.6141139953136444, "actor_loss": -35.57171747589111, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16985511779785, "step": 7000}
{"episode_reward": 347.64123846888356, "episode": 8.0, "batch_reward": 0.2432613094896078, "critic_loss": 0.625208695113659, "actor_loss": -35.87362451553345, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.993624687194824, "step": 8000}
{"episode_reward": 332.3590784751154, "episode": 9.0, "batch_reward": 0.2501675396710634, "critic_loss": 0.6182780313491821, "actor_loss": -35.67807008361817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.300507307052612, "step": 9000}
{"episode_reward": 167.60379652880408, "episode": 10.0, "batch_reward": 0.2476943131238222, "critic_loss": 0.6063013174533844, "actor_loss": -34.88538625717163, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.484164237976074, "step": 10000}
{"episode_reward": 319.0300224756305, "episode": 11.0, "batch_reward": 0.2560736113935709, "critic_loss": 0.7008356926441193, "actor_loss": -34.81530786132812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.79308581352234, "step": 11000}
{"episode_reward": 347.65528955380796, "episode": 12.0, "batch_reward": 0.2628224070519209, "critic_loss": 0.7412673845291138, "actor_loss": -35.16074493408203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.933507204055786, "step": 12000}
{"episode_reward": 390.7819468572341, "episode": 13.0, "batch_reward": 0.27448042641580106, "critic_loss": 0.7236486024558544, "actor_loss": -35.57577077484131, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.862004280090332, "step": 13000}
{"episode_reward": 397.47924081886816, "episode": 14.0, "batch_reward": 0.28335200722515586, "critic_loss": 0.7390754817128181, "actor_loss": -35.93889334487915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.136337518692017, "step": 14000}
{"episode_reward": 390.6633499825751, "episode": 15.0, "batch_reward": 0.28798630169034006, "critic_loss": 0.7275953932702541, "actor_loss": -36.06064723587036, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.659197330474854, "step": 15000}
{"episode_reward": 211.40124672361353, "episode": 16.0, "batch_reward": 0.28189419573545454, "critic_loss": 0.7235977458655835, "actor_loss": -35.380420185089115, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.204997777938843, "step": 16000}
{"episode_reward": 169.70246188152203, "episode": 17.0, "batch_reward": 0.27835933737456797, "critic_loss": 0.831726229608059, "actor_loss": -34.126844890594484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.98467254638672, "step": 17000}
{"episode_reward": 386.63000845182563, "episode": 18.0, "batch_reward": 0.2837154638469219, "critic_loss": 0.7377703017294407, "actor_loss": -34.5133554725647, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.014904260635376, "step": 18000}
{"episode_reward": 357.022828848819, "episode": 19.0, "batch_reward": 0.28821684804558756, "critic_loss": 0.7542525507807731, "actor_loss": -34.71293963241577, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.749703645706177, "step": 19000}
{"episode_reward": 376.80411952188666, "episode": 20.0, "batch_reward": 0.29227993297576904, "critic_loss": 0.8052486317455768, "actor_loss": -35.55438093185425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.624858617782593, "step": 20000}
{"episode_reward": 355.95670177801304, "episode": 21.0, "batch_reward": 0.29684267473220827, "critic_loss": 0.9107107196450234, "actor_loss": -34.917623279571536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.83165168762207, "step": 21000}
{"episode_reward": 404.272779121842, "episode": 22.0, "batch_reward": 0.2996759094297886, "critic_loss": 1.0245352499186993, "actor_loss": -35.67444729995727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.39866590499878, "step": 22000}
{"episode_reward": 329.29121926671564, "episode": 23.0, "batch_reward": 0.301743497133255, "critic_loss": 1.1465356557369233, "actor_loss": -35.19639689254761, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.484896183013916, "step": 23000}
{"episode_reward": 347.326727065566, "episode": 24.0, "batch_reward": 0.3031229266226292, "critic_loss": 1.2895955611765384, "actor_loss": -35.68027827835083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.183645486831665, "step": 24000}
{"episode_reward": 328.7252170949125, "episode": 25.0, "batch_reward": 0.3060201573967934, "critic_loss": 1.2997188365459442, "actor_loss": -36.136505184173586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.536972761154175, "step": 25000}
{"episode_reward": 415.77710403503795, "episode": 26.0, "batch_reward": 0.30709946382045744, "critic_loss": 1.4377145298421383, "actor_loss": -35.386671283721924, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.362993240356445, "step": 26000}
{"episode_reward": 132.28121111763858, "episode": 27.0, "batch_reward": 0.30203027865290644, "critic_loss": 0.9249038986861706, "actor_loss": -34.75208714294433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.12744688987732, "step": 27000}
{"episode_reward": 354.28133522901214, "episode": 28.0, "batch_reward": 0.3059044482409954, "critic_loss": 0.7017378877699375, "actor_loss": -34.971304084777834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.646902561187744, "step": 28000}
{"episode_reward": 441.6550843770848, "episode": 29.0, "batch_reward": 0.30980976855754855, "critic_loss": 0.6815669247508049, "actor_loss": -35.25789319992065, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.185676336288452, "step": 29000}
{"episode_reward": 414.1030567288117, "episode": 30.0, "batch_reward": 0.31370611664652825, "critic_loss": 0.67328654769063, "actor_loss": -35.30228606796265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.705249547958374, "step": 30000}
{"episode_reward": 384.89176724857947, "episode": 31.0, "batch_reward": 0.3153596134185791, "critic_loss": 0.6514537167549134, "actor_loss": -35.27132052230835, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.533092975616455, "step": 31000}
{"episode_reward": 363.4135126911991, "episode": 32.0, "batch_reward": 0.3176872328221798, "critic_loss": 0.6436307982206345, "actor_loss": -35.542716903686525, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.523022174835205, "step": 32000}
{"episode_reward": 389.7912882276631, "episode": 33.0, "batch_reward": 0.3196857104897499, "critic_loss": 0.6540735678076744, "actor_loss": -35.92229708099365, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.993481159210205, "step": 33000}
{"episode_reward": 356.42154172145274, "episode": 34.0, "batch_reward": 0.3201340910792351, "critic_loss": 0.6451389076411724, "actor_loss": -35.94463348770142, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.570330381393433, "step": 34000}
{"episode_reward": 348.2032283770999, "episode": 35.0, "batch_reward": 0.31768705412745474, "critic_loss": 0.6615917717516422, "actor_loss": -35.7896379737854, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.029093027114868, "step": 35000}
{"episode_reward": 89.31166864305358, "episode": 36.0, "batch_reward": 0.31458514711260793, "critic_loss": 0.6606991593241691, "actor_loss": -35.93691585159302, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.267367601394653, "step": 36000}
{"episode_reward": 361.26371737607553, "episode": 37.0, "batch_reward": 0.31602959817647935, "critic_loss": 0.6752218670845032, "actor_loss": -35.14681721496582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.605370044708252, "step": 37000}
{"episode_reward": 408.01398612067214, "episode": 38.0, "batch_reward": 0.318780754506588, "critic_loss": 0.6709215967655182, "actor_loss": -34.91379121017456, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.380871534347534, "step": 38000}
{"episode_reward": 393.0628225788217, "episode": 39.0, "batch_reward": 0.3195196097791195, "critic_loss": 0.6705403831005097, "actor_loss": -35.48707422637939, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.4318106174469, "step": 39000}
{"episode_reward": 245.88811986839505, "episode": 40.0, "batch_reward": 0.3188790277540684, "critic_loss": 0.6783708127439022, "actor_loss": -35.56427970123291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.10210156440735, "step": 40000}
{"episode_reward": 389.7719548593284, "episode": 41.0, "batch_reward": 0.32014141222834586, "critic_loss": 0.7012800277769565, "actor_loss": -35.249238208770755, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.487306118011475, "step": 41000}
{"episode_reward": 410.8241449182256, "episode": 42.0, "batch_reward": 0.3223228026032448, "critic_loss": 0.695948955565691, "actor_loss": -35.50154581451416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.59983801841736, "step": 42000}
{"episode_reward": 220.71167967331212, "episode": 43.0, "batch_reward": 0.32106611427664755, "critic_loss": 0.6917798809409141, "actor_loss": -35.492886505126954, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.817431449890137, "step": 43000}
{"episode_reward": 414.4821088264563, "episode": 44.0, "batch_reward": 0.3223056862950325, "critic_loss": 0.7222275179624558, "actor_loss": -36.68305852890015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.499147176742554, "step": 44000}
{"episode_reward": 392.4610020612687, "episode": 45.0, "batch_reward": 0.32437200817465783, "critic_loss": 0.7274492121934891, "actor_loss": -36.246371864318846, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.440300464630127, "step": 45000}
{"episode_reward": 446.2639300691244, "episode": 46.0, "batch_reward": 0.32612955155968665, "critic_loss": 0.7274423125088215, "actor_loss": -35.58525914001465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.291082859039307, "step": 46000}
{"episode_reward": 398.49630152091163, "episode": 47.0, "batch_reward": 0.3287408744394779, "critic_loss": 0.6993817359507084, "actor_loss": -36.21699254608154, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.96249222755432, "step": 47000}
{"episode_reward": 442.7483517613045, "episode": 48.0, "batch_reward": 0.33098471811413765, "critic_loss": 0.7007983667254448, "actor_loss": -36.180360355377196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.089008331298828, "step": 48000}
{"episode_reward": 447.8242975094614, "episode": 49.0, "batch_reward": 0.3331206709444523, "critic_loss": 0.710760551482439, "actor_loss": -37.201854358673096, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.29673743247986, "step": 49000}
{"episode_reward": 411.49860825843524, "episode": 50.0, "batch_reward": 0.3349524850845337, "critic_loss": 0.7028398405015469, "actor_loss": -36.7901077003479, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.895678997039795, "step": 50000}
{"episode_reward": 411.27635294028295, "episode": 51.0, "batch_reward": 0.33613353037834165, "critic_loss": 0.7029448601603508, "actor_loss": -36.63423446655273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.14753699302673, "step": 51000}
{"episode_reward": 390.6358930395591, "episode": 52.0, "batch_reward": 0.3370499058365822, "critic_loss": 0.6752634364068508, "actor_loss": -36.76124379348755, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.380983591079712, "step": 52000}
{"episode_reward": 438.6904510741884, "episode": 53.0, "batch_reward": 0.3369014711380005, "critic_loss": 0.6554090972244739, "actor_loss": -37.22026571273804, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.59235692024231, "step": 53000}
{"episode_reward": 91.9733362503017, "episode": 54.0, "batch_reward": 0.3352314824163914, "critic_loss": 0.6642224853038787, "actor_loss": -37.34634846115112, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.043590545654297, "step": 54000}
{"episode_reward": 397.5010016964355, "episode": 55.0, "batch_reward": 0.3358706010580063, "critic_loss": 0.653528539955616, "actor_loss": -36.962362014770505, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.91500186920166, "step": 55000}
{"episode_reward": 437.48151554541204, "episode": 56.0, "batch_reward": 0.3373251236975193, "critic_loss": 0.6477802539467812, "actor_loss": -36.94771440505981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.307345628738403, "step": 56000}
{"episode_reward": 387.58542545171537, "episode": 57.0, "batch_reward": 0.3393356558680534, "critic_loss": 0.6411360683441162, "actor_loss": -36.98675785827637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.351922750473022, "step": 57000}
{"episode_reward": 469.83548632753866, "episode": 58.0, "batch_reward": 0.340614853233099, "critic_loss": 0.6359270651638508, "actor_loss": -37.138604221343996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.460240840911865, "step": 58000}
{"episode_reward": 435.599865228494, "episode": 59.0, "batch_reward": 0.34296260318160054, "critic_loss": 0.6331875188350677, "actor_loss": -37.051406051635745, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.541836261749268, "step": 59000}
{"episode_reward": 438.3248310307721, "episode": 60.0, "batch_reward": 0.34419235652685165, "critic_loss": 0.6194739199876785, "actor_loss": -37.448114246368405, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.95717692375183, "step": 60000}
{"episode_reward": 409.2200037994781, "episode": 61.0, "batch_reward": 0.34551979157328605, "critic_loss": 0.614699288725853, "actor_loss": -37.300730739593504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.75129318237305, "step": 61000}
{"episode_reward": 424.210973223616, "episode": 62.0, "batch_reward": 0.3474836774766445, "critic_loss": 0.5915903845131397, "actor_loss": -37.71857339477539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.191974401474, "step": 62000}
{"episode_reward": 425.54536630136977, "episode": 63.0, "batch_reward": 0.34749189937114716, "critic_loss": 0.5824816959202289, "actor_loss": -37.82776874923706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.83104395866394, "step": 63000}
{"episode_reward": 443.63473293904354, "episode": 64.0, "batch_reward": 0.3488441344201565, "critic_loss": 0.5770620132684707, "actor_loss": -37.87542239379883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.503051042556763, "step": 64000}
{"episode_reward": 400.0549156660629, "episode": 65.0, "batch_reward": 0.34994920998811724, "critic_loss": 0.5773219262957573, "actor_loss": -37.678854763031005, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.5323543548584, "step": 65000}
{"episode_reward": 416.7867447829883, "episode": 66.0, "batch_reward": 0.3507418669760227, "critic_loss": 0.5571928145587445, "actor_loss": -37.8781051864624, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.056347370147705, "step": 66000}
{"episode_reward": 445.05531266442256, "episode": 67.0, "batch_reward": 0.35264505150914194, "critic_loss": 0.5670694295167923, "actor_loss": -38.54737077331543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.514350414276123, "step": 67000}
{"episode_reward": 404.2955256561194, "episode": 68.0, "batch_reward": 0.3537536169588566, "critic_loss": 0.5876356814801693, "actor_loss": -39.23140180206299, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.93717122077942, "step": 68000}
{"episode_reward": 433.26871735208954, "episode": 69.0, "batch_reward": 0.3540835309922695, "critic_loss": 0.5970969110429287, "actor_loss": -37.982426197052, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.191051959991455, "step": 69000}
{"episode_reward": 458.3528535439812, "episode": 70.0, "batch_reward": 0.35544203263521196, "critic_loss": 0.5900331301093101, "actor_loss": -38.40963701629639, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.98734402656555, "step": 70000}
{"episode_reward": 451.86532606883577, "episode": 71.0, "batch_reward": 0.35751065465807913, "critic_loss": 0.5694575168788433, "actor_loss": -38.183981609344485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.79074954986572, "step": 71000}
{"episode_reward": 461.0131185441377, "episode": 72.0, "batch_reward": 0.3580649194121361, "critic_loss": 0.5830080529153348, "actor_loss": -38.65432585144043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.10715627670288, "step": 72000}
{"episode_reward": 453.17444285583224, "episode": 73.0, "batch_reward": 0.3604241930544376, "critic_loss": 0.5540061458349228, "actor_loss": -38.98627632522583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.796905755996704, "step": 73000}
{"episode_reward": 445.75066282729307, "episode": 74.0, "batch_reward": 0.36118512743711473, "critic_loss": 0.5543485702574253, "actor_loss": -38.70487969970703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.977271795272827, "step": 74000}
{"episode_reward": 285.48289775937025, "episode": 75.0, "batch_reward": 0.3602929349243641, "critic_loss": 0.5778021857142448, "actor_loss": -38.87408317184448, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.360939502716064, "step": 75000}
{"episode_reward": 450.06395801798215, "episode": 76.0, "batch_reward": 0.35912451711297033, "critic_loss": 0.5871194849312306, "actor_loss": -38.650488494873045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.000377416610718, "step": 76000}
{"episode_reward": 83.94812402109159, "episode": 77.0, "batch_reward": 0.357572749376297, "critic_loss": 0.5899207883775234, "actor_loss": -38.67370215988159, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.25810408592224, "step": 77000}
{"episode_reward": 456.597693342659, "episode": 78.0, "batch_reward": 0.3591124986410141, "critic_loss": 0.5833939643204212, "actor_loss": -39.06311045455933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.40310263633728, "step": 78000}
{"episode_reward": 445.30687770309305, "episode": 79.0, "batch_reward": 0.3600800871253014, "critic_loss": 0.6153397468030453, "actor_loss": -39.372949726104736, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.349353313446045, "step": 79000}
{"episode_reward": 419.97056482615596, "episode": 80.0, "batch_reward": 0.3615096873641014, "critic_loss": 0.63365139067173, "actor_loss": -39.30515776062012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.872264862060547, "step": 80000}
{"episode_reward": 464.66552352794986, "episode": 81.0, "batch_reward": 0.3627312807738781, "critic_loss": 0.6145045118033886, "actor_loss": -39.021056827545166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.085848808288574, "step": 81000}
{"episode_reward": 459.9160653233667, "episode": 82.0, "batch_reward": 0.3635704374909401, "critic_loss": 0.6165912769138813, "actor_loss": -39.05685833358765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.002583503723145, "step": 82000}
{"episode_reward": 474.10101910287455, "episode": 83.0, "batch_reward": 0.3654927570819855, "critic_loss": 0.5762407115697861, "actor_loss": -39.48523046112061, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.45567560195923, "step": 83000}
{"episode_reward": 477.54384133709624, "episode": 84.0, "batch_reward": 0.3664855190813541, "critic_loss": 0.6110939907431603, "actor_loss": -39.98110706329346, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.019941329956055, "step": 84000}
{"episode_reward": 440.9177094477471, "episode": 85.0, "batch_reward": 0.36686581367254256, "critic_loss": 0.6229552331268787, "actor_loss": -39.92805138015747, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.702218055725098, "step": 85000}
{"episode_reward": 460.82135594331436, "episode": 86.0, "batch_reward": 0.3683717728257179, "critic_loss": 0.603521186709404, "actor_loss": -39.403733764648436, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.2403724193573, "step": 86000}
{"episode_reward": 499.57939346832615, "episode": 87.0, "batch_reward": 0.36949142161011694, "critic_loss": 0.5989831937551499, "actor_loss": -40.59588545227051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.22583818435669, "step": 87000}
{"episode_reward": 473.521161981944, "episode": 88.0, "batch_reward": 0.37070761501789096, "critic_loss": 0.594763876080513, "actor_loss": -39.70934177017212, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.463889360427856, "step": 88000}
{"episode_reward": 496.8228063125731, "episode": 89.0, "batch_reward": 0.37229159915447235, "critic_loss": 0.5982813023030757, "actor_loss": -39.98843190765381, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.306342601776123, "step": 89000}
{"episode_reward": 503.8243617751304, "episode": 90.0, "batch_reward": 0.3748162890970707, "critic_loss": 0.6041333442032337, "actor_loss": -40.14371322250366, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.166361331939697, "step": 90000}
{"episode_reward": 507.99319267522895, "episode": 91.0, "batch_reward": 0.37562821519374845, "critic_loss": 0.5941059925854206, "actor_loss": -40.21098092651367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.60416316986084, "step": 91000}
{"episode_reward": 493.6083783335111, "episode": 92.0, "batch_reward": 0.37606907650828364, "critic_loss": 0.5865975735187531, "actor_loss": -40.66514008331299, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.465657234191895, "step": 92000}
{"episode_reward": 443.374382349294, "episode": 93.0, "batch_reward": 0.3779484097659588, "critic_loss": 0.581829543530941, "actor_loss": -40.471586078643796, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.407813549041748, "step": 93000}
{"episode_reward": 544.1623412533277, "episode": 94.0, "batch_reward": 0.3785595083236694, "critic_loss": 0.6188223694562912, "actor_loss": -40.87989556884766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.759089946746826, "step": 94000}
{"episode_reward": 451.1103408665397, "episode": 95.0, "batch_reward": 0.37913867554068564, "critic_loss": 0.6078432260751724, "actor_loss": -41.32036110687256, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.96507239341736, "step": 95000}
{"episode_reward": 432.8176566562416, "episode": 96.0, "batch_reward": 0.3809372562468052, "critic_loss": 0.6272122614085675, "actor_loss": -41.23553460311889, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.971111536026, "step": 96000}
{"episode_reward": 510.47330987199996, "episode": 97.0, "batch_reward": 0.3816154339909554, "critic_loss": 0.6454873067736626, "actor_loss": -40.82948826599121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.01192617416382, "step": 97000}
{"episode_reward": 496.9748131672847, "episode": 98.0, "batch_reward": 0.3821975952088833, "critic_loss": 0.6372518120110034, "actor_loss": -41.93605699920654, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.91326093673706, "step": 98000}
{"episode_reward": 482.29071344897477, "episode": 99.0, "batch_reward": 0.3843914973735809, "critic_loss": 0.6493426149189472, "actor_loss": -41.19492141723633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.250855207443237, "step": 99000}
{"episode_reward": 489.67860150775647, "episode": 100.0, "batch_reward": 0.385226329356432, "critic_loss": 0.6376003141403198, "actor_loss": -41.425301696777346, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.856706619262695, "step": 100000}
{"episode_reward": 554.7377852463399, "episode": 101.0, "batch_reward": 0.38774451211094857, "critic_loss": 0.6306499424576759, "actor_loss": -41.56647338104248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.05730128288269, "step": 101000}
{"episode_reward": 525.3022935110063, "episode": 102.0, "batch_reward": 0.3884113756418228, "critic_loss": 0.6668663600683212, "actor_loss": -42.13487148284912, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.731358289718628, "step": 102000}
{"episode_reward": 441.694376844303, "episode": 103.0, "batch_reward": 0.3888802674114704, "critic_loss": 0.6453843052387238, "actor_loss": -41.777751647949216, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.82828450202942, "step": 103000}
{"episode_reward": 515.8153588512301, "episode": 104.0, "batch_reward": 0.39060985270142556, "critic_loss": 0.621657569795847, "actor_loss": -41.886483383178714, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.213539600372314, "step": 104000}
{"episode_reward": 443.4852156467105, "episode": 105.0, "batch_reward": 0.3914103995859623, "critic_loss": 0.617877386778593, "actor_loss": -42.16113972854614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.932096004486084, "step": 105000}
{"episode_reward": 510.2603938528848, "episode": 106.0, "batch_reward": 0.39141402411460874, "critic_loss": 0.6310210177600384, "actor_loss": -42.16225684738159, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.008013486862183, "step": 106000}
{"episode_reward": 504.21534501050706, "episode": 107.0, "batch_reward": 0.393075463116169, "critic_loss": 0.6732767914831639, "actor_loss": -41.863881034851076, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.803117990493774, "step": 107000}
{"episode_reward": 549.4826363756861, "episode": 108.0, "batch_reward": 0.39410505536198615, "critic_loss": 0.695637107104063, "actor_loss": -42.72919491195679, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.00161099433899, "step": 108000}
{"episode_reward": 487.76019736990656, "episode": 109.0, "batch_reward": 0.3955332221388817, "critic_loss": 0.6438503860533238, "actor_loss": -42.53821897125244, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.143561124801636, "step": 109000}
{"episode_reward": 514.0549602447261, "episode": 110.0, "batch_reward": 0.3959493700861931, "critic_loss": 0.6661826964318752, "actor_loss": -42.97866677856445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.990307092666626, "step": 110000}
{"episode_reward": 549.4936190559265, "episode": 111.0, "batch_reward": 0.3979544438421726, "critic_loss": 0.6911447690725326, "actor_loss": -42.58284922027588, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.79963803291321, "step": 111000}
{"episode_reward": 500.379862641695, "episode": 112.0, "batch_reward": 0.39765665036439896, "critic_loss": 0.6760816623568535, "actor_loss": -43.16604721832275, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.553351163864136, "step": 112000}
{"episode_reward": 515.6010562280624, "episode": 113.0, "batch_reward": 0.39910929852724075, "critic_loss": 0.740124974489212, "actor_loss": -42.885355377197264, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.952786922454834, "step": 113000}
{"episode_reward": 493.3647378193748, "episode": 114.0, "batch_reward": 0.40013410118222237, "critic_loss": 0.7072410982847214, "actor_loss": -43.242227088928225, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.33109474182129, "step": 114000}
{"episode_reward": 456.49891277870057, "episode": 115.0, "batch_reward": 0.4007555272579193, "critic_loss": 0.695043626666069, "actor_loss": -43.07599156951904, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.036622762680054, "step": 115000}
{"episode_reward": 480.4164540997994, "episode": 116.0, "batch_reward": 0.40203629556298254, "critic_loss": 0.747963670194149, "actor_loss": -43.389981292724606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03340792655945, "step": 116000}
{"episode_reward": 476.72896703212234, "episode": 117.0, "batch_reward": 0.40244643595814705, "critic_loss": 0.6754438441693783, "actor_loss": -43.13349920654297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.641046285629272, "step": 117000}
{"episode_reward": 527.1592518400607, "episode": 118.0, "batch_reward": 0.4033700815737247, "critic_loss": 0.6587832682430744, "actor_loss": -43.21920642852783, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.68351411819458, "step": 118000}
{"episode_reward": 501.18193867369854, "episode": 119.0, "batch_reward": 0.4038524405956268, "critic_loss": 0.6468058595955372, "actor_loss": -43.36812258911133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.77353286743164, "step": 119000}
{"episode_reward": 488.30780161334883, "episode": 120.0, "batch_reward": 0.4044974245429039, "critic_loss": 0.6668396838903428, "actor_loss": -43.38417702484131, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.28815507888794, "step": 120000}
{"episode_reward": 476.31228476906415, "episode": 121.0, "batch_reward": 0.4050175643861294, "critic_loss": 0.6931564672589302, "actor_loss": -43.56581794738769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.3326678276062, "step": 121000}
{"episode_reward": 471.7809120338632, "episode": 122.0, "batch_reward": 0.40601414170861244, "critic_loss": 0.6818430423736572, "actor_loss": -43.838667556762694, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.47800087928772, "step": 122000}
{"episode_reward": 489.3281719617648, "episode": 123.0, "batch_reward": 0.407176944822073, "critic_loss": 0.6743981111049652, "actor_loss": -44.01331817626953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.248344659805298, "step": 123000}
{"episode_reward": 531.974218321264, "episode": 124.0, "batch_reward": 0.4076058201491833, "critic_loss": 0.6543112072348595, "actor_loss": -44.147568969726564, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.934958457946777, "step": 124000}
{"episode_reward": 493.197823931632, "episode": 125.0, "batch_reward": 0.40752526724338534, "critic_loss": 0.6750030427575111, "actor_loss": -43.894956840515135, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.294127225875854, "step": 125000}
{"episode_reward": 505.2425504601332, "episode": 126.0, "batch_reward": 0.40857242470979693, "critic_loss": 0.6758394897282124, "actor_loss": -44.22192095184326, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.665120601654053, "step": 126000}
{"episode_reward": 517.0013981803456, "episode": 127.0, "batch_reward": 0.40986876040697096, "critic_loss": 0.6669651409685612, "actor_loss": -44.330202445983886, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.504549264907837, "step": 127000}
{"episode_reward": 507.86256028269224, "episode": 128.0, "batch_reward": 0.41041661381721495, "critic_loss": 0.7167793151736259, "actor_loss": -44.34368965911865, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.532302618026733, "step": 128000}
{"episode_reward": 424.70266216958566, "episode": 129.0, "batch_reward": 0.41066662326455117, "critic_loss": 0.7425208630561828, "actor_loss": -44.239319084167484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.8538236618042, "step": 129000}
{"episode_reward": 489.71256600881145, "episode": 130.0, "batch_reward": 0.41082363376021386, "critic_loss": 0.768935194671154, "actor_loss": -44.49769845581055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.391918659210205, "step": 130000}
{"episode_reward": 485.87359714771145, "episode": 131.0, "batch_reward": 0.41200554472208023, "critic_loss": 0.7499677981734276, "actor_loss": -43.96470946502686, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.74476361274719, "step": 131000}
{"episode_reward": 494.0142079080094, "episode": 132.0, "batch_reward": 0.4127187111675739, "critic_loss": 0.7721325491666794, "actor_loss": -44.648496757507324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.10390615463257, "step": 132000}
{"episode_reward": 479.62882457525274, "episode": 133.0, "batch_reward": 0.41277693352103234, "critic_loss": 0.7702931505441666, "actor_loss": -44.31717376708984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.197065830230713, "step": 133000}
{"episode_reward": 529.1323753146064, "episode": 134.0, "batch_reward": 0.41407931479811666, "critic_loss": 0.7458739701509476, "actor_loss": -44.65070597076416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.112358808517456, "step": 134000}
{"episode_reward": 525.308574123493, "episode": 135.0, "batch_reward": 0.4139545385241509, "critic_loss": 0.7333122336268425, "actor_loss": -44.812550575256346, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.904852628707886, "step": 135000}
{"episode_reward": 488.3192149190125, "episode": 136.0, "batch_reward": 0.4152330343425274, "critic_loss": 0.7366799559295177, "actor_loss": -44.725636474609374, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.24028968811035, "step": 136000}
{"episode_reward": 461.8134991814618, "episode": 137.0, "batch_reward": 0.41584379306435587, "critic_loss": 0.7433676644563675, "actor_loss": -44.84074457550049, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.42286992073059, "step": 137000}
{"episode_reward": 524.121096208498, "episode": 138.0, "batch_reward": 0.4165327453315258, "critic_loss": 0.7545560890436173, "actor_loss": -44.78733863067627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.073681831359863, "step": 138000}
{"episode_reward": 512.443561798482, "episode": 139.0, "batch_reward": 0.41642250213027, "critic_loss": 0.7425495005846023, "actor_loss": -44.747043128967285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.08434772491455, "step": 139000}
{"episode_reward": 521.7992647459207, "episode": 140.0, "batch_reward": 0.4165464223623276, "critic_loss": 0.7494379403591156, "actor_loss": -45.1832832107544, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.07029151916504, "step": 140000}
{"episode_reward": 489.52231102248135, "episode": 141.0, "batch_reward": 0.4192128275632858, "critic_loss": 0.7335611090958118, "actor_loss": -45.15245716094971, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.663530588150024, "step": 141000}
{"episode_reward": 468.2545451305757, "episode": 142.0, "batch_reward": 0.419279454678297, "critic_loss": 0.7617395183146, "actor_loss": -45.105479827880856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.432617902755737, "step": 142000}
{"episode_reward": 462.6532098293501, "episode": 143.0, "batch_reward": 0.41883074775338175, "critic_loss": 0.7320558860301971, "actor_loss": -45.20816750335693, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.74866485595703, "step": 143000}
{"episode_reward": 484.595781492972, "episode": 144.0, "batch_reward": 0.4194969317615032, "critic_loss": 0.7505961799919605, "actor_loss": -45.54416692352295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.416276931762695, "step": 144000}
{"episode_reward": 498.27880957819116, "episode": 145.0, "batch_reward": 0.4197529649436474, "critic_loss": 0.7338853504061699, "actor_loss": -45.325497985839846, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.988663911819458, "step": 145000}
{"episode_reward": 530.015602452203, "episode": 146.0, "batch_reward": 0.4199574372470379, "critic_loss": 0.7090979323387147, "actor_loss": -44.91345053100586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.66834306716919, "step": 146000}
{"episode_reward": 519.1478173634799, "episode": 147.0, "batch_reward": 0.42138041639328006, "critic_loss": 0.7018822629749775, "actor_loss": -45.39072105407715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.697393894195557, "step": 147000}
{"episode_reward": 523.132891925878, "episode": 148.0, "batch_reward": 0.42237245285511016, "critic_loss": 0.7124557946622372, "actor_loss": -45.636208572387694, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.353289365768433, "step": 148000}
{"episode_reward": 471.91194304591846, "episode": 149.0, "batch_reward": 0.42278928941488264, "critic_loss": 0.7312001422345639, "actor_loss": -45.58588493347168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.27164602279663, "step": 149000}
