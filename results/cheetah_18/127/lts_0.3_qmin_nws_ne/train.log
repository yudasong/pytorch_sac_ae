{"episode_reward": 0.0, "episode": 1.0, "duration": 17.816816329956055, "step": 1000}
{"episode_reward": 7.051849146674556, "episode": 2.0, "duration": 1.522996425628662, "step": 2000}
{"episode_reward": 365.4711839680396, "episode": 3.0, "batch_reward": 0.17479153758796226, "critic_loss": 0.01883080324647801, "actor_loss": -12.543339547688136, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 70.09188795089722, "step": 3000}
{"episode_reward": 2.4688009062509204, "episode": 4.0, "batch_reward": 0.10852946416288614, "critic_loss": 0.010928801132249645, "actor_loss": -11.862031606197357, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.887988090515137, "step": 4000}
{"episode_reward": 1.8175270908968995, "episode": 5.0, "batch_reward": 0.08437088464200497, "critic_loss": 0.00830556375917513, "actor_loss": -10.619963597536087, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.171834230422974, "step": 5000}
{"episode_reward": 1.7289447230422894, "episode": 6.0, "batch_reward": 0.06852242176607251, "critic_loss": 0.008206599461496808, "actor_loss": -11.17019585108757, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.19737410545349, "step": 6000}
{"episode_reward": 1.8330428595153592, "episode": 7.0, "batch_reward": 0.05861303693242371, "critic_loss": 0.007236358852125704, "actor_loss": -9.857169275045395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997463941574097, "step": 7000}
{"episode_reward": 2.492022524016862, "episode": 8.0, "batch_reward": 0.05150196211785078, "critic_loss": 0.006737143599137198, "actor_loss": -10.343493561029435, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.84165620803833, "step": 8000}
{"episode_reward": 3.219377809348247, "episode": 9.0, "batch_reward": 0.04554062848165631, "critic_loss": 0.005277122373459861, "actor_loss": -10.278780277252197, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.620912551879883, "step": 9000}
{"episode_reward": 2.439779709252497, "episode": 10.0, "batch_reward": 0.04120370644982904, "critic_loss": 0.005736568250518758, "actor_loss": -10.174962222337722, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.612869262695312, "step": 10000}
{"episode_reward": 2.258088050980409, "episode": 11.0, "batch_reward": 0.03783415210386738, "critic_loss": 0.005840816008625552, "actor_loss": -11.151429469585418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 37.506508350372314, "step": 11000}
{"episode_reward": 2.507844352756858, "episode": 12.0, "batch_reward": 0.03398797230422497, "critic_loss": 0.005372371522564208, "actor_loss": -11.042723557472229, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.93709683418274, "step": 12000}
{"episode_reward": 2.854697966891753, "episode": 13.0, "batch_reward": 0.0315567440809682, "critic_loss": 0.005236587676219642, "actor_loss": -9.701038207888603, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.84598708152771, "step": 13000}
{"episode_reward": 2.7566488724271014, "episode": 14.0, "batch_reward": 0.0297673995452933, "critic_loss": 0.004576130310975713, "actor_loss": -10.701208631515502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.829883575439453, "step": 14000}
{"episode_reward": 2.8001849434578894, "episode": 15.0, "batch_reward": 0.027509956935420632, "critic_loss": 0.004928744409466162, "actor_loss": -10.272210042834281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.469383001327515, "step": 15000}
{"episode_reward": 2.030007506130831, "episode": 16.0, "batch_reward": 0.02607820636453107, "critic_loss": 0.0033449980344448706, "actor_loss": -10.342673213720321, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.639137268066406, "step": 16000}
{"episode_reward": 2.7427727461658495, "episode": 17.0, "batch_reward": 0.024561474443646147, "critic_loss": 0.0043855352882819715, "actor_loss": -9.934792860388756, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.612191915512085, "step": 17000}
{"episode_reward": 1.7547700752345485, "episode": 18.0, "batch_reward": 0.023874041277915238, "critic_loss": 0.003893807066604495, "actor_loss": -9.5393958132267, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.403525590896606, "step": 18000}
{"episode_reward": 3.4880250277003664, "episode": 19.0, "batch_reward": 0.02250797963188961, "critic_loss": 0.0036451154617243445, "actor_loss": -9.213052481651307, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.531813859939575, "step": 19000}
{"episode_reward": 2.8591638003073108, "episode": 20.0, "batch_reward": 0.02135007631033659, "critic_loss": 0.003269804876472335, "actor_loss": -9.931543072462082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.796669483184814, "step": 20000}
{"episode_reward": 2.1989933269100743, "episode": 21.0, "batch_reward": 0.019960532447788865, "critic_loss": 0.003630183102301089, "actor_loss": -8.895163983702659, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.55844831466675, "step": 21000}
{"episode_reward": 2.428943066529831, "episode": 22.0, "batch_reward": 0.019598040108336136, "critic_loss": 0.0033365154162165707, "actor_loss": -10.915429946541787, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.91841435432434, "step": 22000}
{"episode_reward": 3.597864371756933, "episode": 23.0, "batch_reward": 0.0188955940825399, "critic_loss": 0.002372696012360393, "actor_loss": -9.172220234394073, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.35672879219055, "step": 23000}
{"episode_reward": 2.7164219405841314, "episode": 24.0, "batch_reward": 0.01803344470448792, "critic_loss": 0.002603433672600659, "actor_loss": -9.813225295305251, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.917620182037354, "step": 24000}
{"episode_reward": 2.640200183747749, "episode": 25.0, "batch_reward": 0.01771943868370727, "critic_loss": 0.0022092621174815575, "actor_loss": -9.072493062734605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.913461208343506, "step": 25000}
{"episode_reward": 2.792624840787923, "episode": 26.0, "batch_reward": 0.017002930011600255, "critic_loss": 0.0024473652479573504, "actor_loss": -8.571224073410034, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.968024015426636, "step": 26000}
{"episode_reward": 2.5710646442938145, "episode": 27.0, "batch_reward": 0.016772543278289958, "critic_loss": 0.002730059607303701, "actor_loss": -8.6143615270257, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.468278884887695, "step": 27000}
{"episode_reward": 2.663092029152116, "episode": 28.0, "batch_reward": 0.01612266264576465, "critic_loss": 0.00185715408269607, "actor_loss": -10.70653422743082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.32630467414856, "step": 28000}
{"episode_reward": 2.6053872616166682, "episode": 29.0, "batch_reward": 0.01529375818115659, "critic_loss": 0.002885947112183203, "actor_loss": -9.09152951055765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.858555793762207, "step": 29000}
{"episode_reward": 2.2945831943053836, "episode": 30.0, "batch_reward": 0.015046447648433969, "critic_loss": 0.002488100522408786, "actor_loss": -8.327046283721923, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.63969135284424, "step": 30000}
{"episode_reward": 2.4219213429420323, "episode": 31.0, "batch_reward": 0.01449426253628917, "critic_loss": 0.0013578331660537514, "actor_loss": -8.874230040609836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.03013825416565, "step": 31000}
{"episode_reward": 2.1435049738909155, "episode": 32.0, "batch_reward": 0.014252303499961271, "critic_loss": 0.0021705953886121277, "actor_loss": -9.987498863816262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.923631191253662, "step": 32000}
{"episode_reward": 2.5680668124232184, "episode": 33.0, "batch_reward": 0.013777825714321807, "critic_loss": 0.0017749499838755583, "actor_loss": -10.440944058299065, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.833937883377075, "step": 33000}
{"episode_reward": 2.2903258438578726, "episode": 34.0, "batch_reward": 0.013714305717963724, "critic_loss": 0.002204147134638333, "actor_loss": -8.250435597360134, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.589500427246094, "step": 34000}
{"episode_reward": 3.1085421242473568, "episode": 35.0, "batch_reward": 0.012689299879013561, "critic_loss": 0.0023541382589392017, "actor_loss": -10.291411912083626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.124383687973022, "step": 35000}
{"episode_reward": 2.6485595734458514, "episode": 36.0, "batch_reward": 0.012550402871682308, "critic_loss": 0.0017181654085143237, "actor_loss": -10.387249369561673, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.90754199028015, "step": 36000}
{"episode_reward": 2.3665330478612256, "episode": 37.0, "batch_reward": 0.012635105255641975, "critic_loss": 0.0020617957948707044, "actor_loss": -9.510585138499737, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.076086282730103, "step": 37000}
{"episode_reward": 2.482254518810039, "episode": 38.0, "batch_reward": 0.012297299246303737, "critic_loss": 0.00193172703908931, "actor_loss": -9.613028562426567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.30864691734314, "step": 38000}
{"episode_reward": 2.1988248583469385, "episode": 39.0, "batch_reward": 0.012131480783922597, "critic_loss": 0.0018883636607279187, "actor_loss": -9.962053144693375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.969934463500977, "step": 39000}
{"episode_reward": 2.5284578938947844, "episode": 40.0, "batch_reward": 0.011834980528918095, "critic_loss": 0.002189566237429972, "actor_loss": -8.414698720514775, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.480796575546265, "step": 40000}
{"episode_reward": 2.5441308010680364, "episode": 41.0, "batch_reward": 0.01150688217766583, "critic_loss": 0.0015630677392910002, "actor_loss": -7.996669186502695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.224069595336914, "step": 41000}
{"episode_reward": 2.605564311247226, "episode": 42.0, "batch_reward": 0.011337624054751359, "critic_loss": 0.00257376501638646, "actor_loss": -9.566715269774198, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.658060312271118, "step": 42000}
{"episode_reward": 2.787803393290467, "episode": 43.0, "batch_reward": 0.011105364808579907, "critic_loss": 0.0017849271860541193, "actor_loss": -9.395839237034322, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.61551308631897, "step": 43000}
{"episode_reward": 2.2862976625570584, "episode": 44.0, "batch_reward": 0.011111621257965453, "critic_loss": 0.002173005295509938, "actor_loss": -10.324877485245466, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15640139579773, "step": 44000}
{"episode_reward": 2.9146047414823455, "episode": 45.0, "batch_reward": 0.010715631989762187, "critic_loss": 0.0017218449168249208, "actor_loss": -9.895703799128533, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.093345165252686, "step": 45000}
{"episode_reward": 1.9043464709289917, "episode": 46.0, "batch_reward": 0.010239003479597159, "critic_loss": 0.001512390563315421, "actor_loss": -9.057749318301678, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.0907461643219, "step": 46000}
{"episode_reward": 2.2414579110306088, "episode": 47.0, "batch_reward": 0.010238893272471614, "critic_loss": 0.0011525555634871124, "actor_loss": -9.111515145868063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.416300058364868, "step": 47000}
{"episode_reward": 2.744121385790527, "episode": 48.0, "batch_reward": 0.010253711969708092, "critic_loss": 0.0014262663053741561, "actor_loss": -8.926262442678214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.849961042404175, "step": 48000}
{"episode_reward": 3.051909288537618, "episode": 49.0, "batch_reward": 0.010242542858351954, "critic_loss": 0.001743727737739391, "actor_loss": -9.933358875125647, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.294069528579712, "step": 49000}
{"episode_reward": 2.768897254674828, "episode": 50.0, "batch_reward": 0.009895776804187335, "critic_loss": 0.0016242449145574937, "actor_loss": -8.920368208557367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.051401615142822, "step": 50000}
{"episode_reward": 2.423159461072144, "episode": 51.0, "batch_reward": 0.009758886305149645, "critic_loss": 0.0010661623413543565, "actor_loss": -8.608382330149412, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.55129361152649, "step": 51000}
{"episode_reward": 2.3685970821726907, "episode": 52.0, "batch_reward": 0.00973285495385062, "critic_loss": 0.0010202183172041258, "actor_loss": -7.781223971664906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.522469758987427, "step": 52000}
{"episode_reward": 2.393209483758558, "episode": 53.0, "batch_reward": 0.009468022928806021, "critic_loss": 0.0015333325962419622, "actor_loss": -9.423770284026862, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.47970223426819, "step": 53000}
{"episode_reward": 2.1591171469557757, "episode": 54.0, "batch_reward": 0.009371202373178676, "critic_loss": 0.001173155142692849, "actor_loss": -9.06379049912095, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.957634925842285, "step": 54000}
{"episode_reward": 2.3310743552960744, "episode": 55.0, "batch_reward": 0.009367367140599527, "critic_loss": 0.001325360813363659, "actor_loss": -9.533653468489646, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.936346769332886, "step": 55000}
{"episode_reward": 2.366084056250994, "episode": 56.0, "batch_reward": 0.009060735933599063, "critic_loss": 0.0011743453013841644, "actor_loss": -8.927706358999014, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.425527811050415, "step": 56000}
{"episode_reward": 2.7770556297044253, "episode": 57.0, "batch_reward": 0.009003881942131557, "critic_loss": 0.0014957543864438775, "actor_loss": -9.62931043189764, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.88333249092102, "step": 57000}
{"episode_reward": 2.604315260047617, "episode": 58.0, "batch_reward": 0.00878625294403173, "critic_loss": 0.0009696851984990644, "actor_loss": -9.807933948755265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.171424627304077, "step": 58000}
{"episode_reward": 3.474714199042276, "episode": 59.0, "batch_reward": 0.008781826130580157, "critic_loss": 0.001396186757432588, "actor_loss": -8.508350895941257, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.71881365776062, "step": 59000}
{"episode_reward": 2.309201067688921, "episode": 60.0, "batch_reward": 0.008773108354071156, "critic_loss": 0.0010173183213191806, "actor_loss": -9.382365139842033, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.485706329345703, "step": 60000}
{"episode_reward": 1.851156979127773, "episode": 61.0, "batch_reward": 0.008713886017212645, "critic_loss": 0.0011372596457003964, "actor_loss": -8.435634461849927, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.14888143539429, "step": 61000}
{"episode_reward": 1.7733222190229285, "episode": 62.0, "batch_reward": 0.008761499236570672, "critic_loss": 0.0008960636172741942, "actor_loss": -9.489692029595375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.052542448043823, "step": 62000}
{"episode_reward": 3.366815278312659, "episode": 63.0, "batch_reward": 0.008334865959943273, "critic_loss": 0.001225255518227641, "actor_loss": -7.715613637328148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.034420013427734, "step": 63000}
{"episode_reward": 2.3067405640038268, "episode": 64.0, "batch_reward": 0.008215826356434263, "critic_loss": 0.0014646273522630508, "actor_loss": -9.066045839726925, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.50901198387146, "step": 64000}
{"episode_reward": 2.1776249571192565, "episode": 65.0, "batch_reward": 0.008191222702269442, "critic_loss": 0.00135128122036258, "actor_loss": -9.066834362149239, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.82922673225403, "step": 65000}
{"episode_reward": 3.299774188700872, "episode": 66.0, "batch_reward": 0.007983862713095731, "critic_loss": 0.0010277420703750978, "actor_loss": -9.114162080988288, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.134047508239746, "step": 66000}
{"episode_reward": 2.353248089360434, "episode": 67.0, "batch_reward": 0.008061119800549932, "critic_loss": 0.0018018683901136682, "actor_loss": -10.64478551158309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.64791178703308, "step": 67000}
{"episode_reward": 2.39027516695815, "episode": 68.0, "batch_reward": 0.007957200426608324, "critic_loss": 0.0008344617753100465, "actor_loss": -9.345696187004448, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.286506175994873, "step": 68000}
{"episode_reward": 2.53089172317328, "episode": 69.0, "batch_reward": 0.00794059943431057, "critic_loss": 0.0010852088595638633, "actor_loss": -7.854736063405872, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.822731733322144, "step": 69000}
{"episode_reward": 1.819882155314453, "episode": 70.0, "batch_reward": 0.00777247515541967, "critic_loss": 0.0007867548722679203, "actor_loss": -9.333636112049222, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.23397135734558, "step": 70000}
{"episode_reward": 2.6379561995437504, "episode": 71.0, "batch_reward": 0.007816607214976103, "critic_loss": 0.0010321336760353006, "actor_loss": -9.320465003803372, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.79534196853638, "step": 71000}
{"episode_reward": 2.4731551501236093, "episode": 72.0, "batch_reward": 0.007743106338311918, "critic_loss": 0.0009250678541684465, "actor_loss": -8.264820258185267, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.513216257095337, "step": 72000}
{"episode_reward": 2.4323857842440937, "episode": 73.0, "batch_reward": 0.007715580721385777, "critic_loss": 0.0010028783645066141, "actor_loss": -8.737844423905015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.19517970085144, "step": 73000}
{"episode_reward": 2.792605779494502, "episode": 74.0, "batch_reward": 0.007405062768142671, "critic_loss": 0.0009700989701123035, "actor_loss": -8.85202905100584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.51723027229309, "step": 74000}
{"episode_reward": 2.034913942555338, "episode": 75.0, "batch_reward": 0.00724600214289967, "critic_loss": 0.0008822928278568725, "actor_loss": -7.657790462985635, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.64018726348877, "step": 75000}
{"episode_reward": 2.1317297152525487, "episode": 76.0, "batch_reward": 0.007492434195242822, "critic_loss": 0.0007746535697224317, "actor_loss": -8.428692439854146, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.478918075561523, "step": 76000}
{"episode_reward": 2.538719556057837, "episode": 77.0, "batch_reward": 0.007455858329078182, "critic_loss": 0.000860598526585818, "actor_loss": -9.19711025749147, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.91659379005432, "step": 77000}
{"episode_reward": 2.499612539052745, "episode": 78.0, "batch_reward": 0.007538459216826596, "critic_loss": 0.0009813291911159468, "actor_loss": -9.135527635082603, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.816814422607422, "step": 78000}
{"episode_reward": 2.6104199564100767, "episode": 79.0, "batch_reward": 0.007140859711449593, "critic_loss": 0.0011177091078134254, "actor_loss": -9.784512104690075, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.676286458969116, "step": 79000}
{"episode_reward": 2.4938961280054346, "episode": 80.0, "batch_reward": 0.007205094801960513, "critic_loss": 0.0008121351823756414, "actor_loss": -9.902586337417365, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.62487506866455, "step": 80000}
{"episode_reward": 2.0659708924111806, "episode": 81.0, "batch_reward": 0.006949560187291354, "critic_loss": 0.0006708047719457682, "actor_loss": -9.832307277172804, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.53910160064697, "step": 81000}
{"episode_reward": 2.520863416827245, "episode": 82.0, "batch_reward": 0.006862697935197502, "critic_loss": 0.0008011030648485758, "actor_loss": -8.124780242457986, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.502726078033447, "step": 82000}
{"episode_reward": 1.8953384666178574, "episode": 83.0, "batch_reward": 0.0069018877388443796, "critic_loss": 0.0009132654001950868, "actor_loss": -10.066085719048976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.30453848838806, "step": 83000}
{"episode_reward": 2.317841652127407, "episode": 84.0, "batch_reward": 0.006867897640098817, "critic_loss": 0.0009232133020559559, "actor_loss": -8.764654385834932, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.67891526222229, "step": 84000}
{"episode_reward": 3.0484192584010765, "episode": 85.0, "batch_reward": 0.006746381535776891, "critic_loss": 0.000683451268247154, "actor_loss": -9.004040744408965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.96094560623169, "step": 85000}
{"episode_reward": 3.3659194149604517, "episode": 86.0, "batch_reward": 0.006931677366723307, "critic_loss": 0.0007578177638861234, "actor_loss": -9.06534117038548, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.886383295059204, "step": 86000}
{"episode_reward": 2.3082955418295965, "episode": 87.0, "batch_reward": 0.0067567673869198186, "critic_loss": 0.0008255949832018814, "actor_loss": -10.122911355905234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.783625602722168, "step": 87000}
{"episode_reward": 2.0803333061597393, "episode": 88.0, "batch_reward": 0.006428475307999179, "critic_loss": 0.0006369131173523783, "actor_loss": -8.15828581673652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.5719153881073, "step": 88000}
{"episode_reward": 2.3673585930994605, "episode": 89.0, "batch_reward": 0.006659885593224317, "critic_loss": 0.0007487970821712225, "actor_loss": -8.225711216658354, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.45459222793579, "step": 89000}
{"episode_reward": 2.160132195666146, "episode": 90.0, "batch_reward": 0.006716054777149111, "critic_loss": 0.0010677163371365169, "actor_loss": -8.703328318744898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.880675792694092, "step": 90000}
{"episode_reward": 2.999300011013728, "episode": 91.0, "batch_reward": 0.006553564003435895, "critic_loss": 0.0007427883350283082, "actor_loss": -7.928976729676127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.69477891921997, "step": 91000}
{"episode_reward": 2.335453569363094, "episode": 92.0, "batch_reward": 0.006487657604389824, "critic_loss": 0.0007726528324783431, "actor_loss": -8.81896419300884, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.571593761444092, "step": 92000}
{"episode_reward": 2.9880149667270923, "episode": 93.0, "batch_reward": 0.00641970137518365, "critic_loss": 0.0007669343873931211, "actor_loss": -8.224979820989072, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94894814491272, "step": 93000}
{"episode_reward": 2.2061675461952834, "episode": 94.0, "batch_reward": 0.006316851408686489, "critic_loss": 0.0009582101980486187, "actor_loss": -7.982939815483987, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.15093994140625, "step": 94000}
{"episode_reward": 2.6865549537685425, "episode": 95.0, "batch_reward": 0.006269907503854483, "critic_loss": 0.0009375144607183756, "actor_loss": -9.812397350534797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.138012409210205, "step": 95000}
{"episode_reward": 2.5384488990566325, "episode": 96.0, "batch_reward": 0.006502484537777491, "critic_loss": 0.000984861906254082, "actor_loss": -8.104713368080557, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.861400604248047, "step": 96000}
{"episode_reward": 1.8539370717827577, "episode": 97.0, "batch_reward": 0.006402833256172016, "critic_loss": 0.0008582869964884594, "actor_loss": -8.864180888719856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.26935648918152, "step": 97000}
{"episode_reward": 2.3012633328096888, "episode": 98.0, "batch_reward": 0.006140122001990676, "critic_loss": 0.0007569979189174774, "actor_loss": -10.458936328090727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.62229299545288, "step": 98000}
{"episode_reward": 2.326862020050739, "episode": 99.0, "batch_reward": 0.00618788303702604, "critic_loss": 0.0009008747720217798, "actor_loss": -8.917703531853855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.038960456848145, "step": 99000}
{"episode_reward": 2.3907644855368626, "episode": 100.0, "batch_reward": 0.006172270026057958, "critic_loss": 0.0007407358862183173, "actor_loss": -9.15342249906063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.859151601791382, "step": 100000}
{"episode_reward": 2.1990721475186543, "episode": 101.0, "batch_reward": 0.006146345744258724, "critic_loss": 0.0008966618380582077, "actor_loss": -7.92101086448133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.14755606651306, "step": 101000}
{"episode_reward": 2.0231516297906675, "episode": 102.0, "batch_reward": 0.006264707775437273, "critic_loss": 0.000994848001133505, "actor_loss": -9.51781895495206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.57713007926941, "step": 102000}
{"episode_reward": 2.47413025333378, "episode": 103.0, "batch_reward": 0.006228092067874968, "critic_loss": 0.0008025514748223941, "actor_loss": -9.279459924615919, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.167964220046997, "step": 103000}
{"episode_reward": 2.5048610349358382, "episode": 104.0, "batch_reward": 0.006195573097094893, "critic_loss": 0.0008781909603476378, "actor_loss": -8.322939788997173, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.378291845321655, "step": 104000}
{"episode_reward": 2.194353896211335, "episode": 105.0, "batch_reward": 0.00607756178744603, "critic_loss": 0.000742202973448002, "actor_loss": -8.327688428148628, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.31447958946228, "step": 105000}
{"episode_reward": 2.303616241178471, "episode": 106.0, "batch_reward": 0.005758314003003761, "critic_loss": 0.0006501508246547019, "actor_loss": -8.618410816252231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.88421130180359, "step": 106000}
{"episode_reward": 2.020624704513712, "episode": 107.0, "batch_reward": 0.005913347006659023, "critic_loss": 0.0009866092568881868, "actor_loss": -8.326822118483484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.11561346054077, "step": 107000}
{"episode_reward": 2.410231618764313, "episode": 108.0, "batch_reward": 0.006054311709362082, "critic_loss": 0.0008054447654612886, "actor_loss": -9.806621613539756, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.211241483688354, "step": 108000}
{"episode_reward": 1.9792008912612848, "episode": 109.0, "batch_reward": 0.005736482012202032, "critic_loss": 0.0007080935710291669, "actor_loss": -8.31366643409431, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.80103635787964, "step": 109000}
{"episode_reward": 2.7951599195890315, "episode": 110.0, "batch_reward": 0.006052489705034532, "critic_loss": 0.0010503881342629029, "actor_loss": -10.151600670598448, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.552557468414307, "step": 110000}
{"episode_reward": 2.2306684360413684, "episode": 111.0, "batch_reward": 0.005735712212393992, "critic_loss": 0.0005801937025607912, "actor_loss": -8.788976155593991, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.71168637275696, "step": 111000}
{"episode_reward": 2.7895228186398167, "episode": 112.0, "batch_reward": 0.005865467883879319, "critic_loss": 0.0005374451585648785, "actor_loss": -9.500661458671093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.71212673187256, "step": 112000}
{"episode_reward": 2.3328055621746167, "episode": 113.0, "batch_reward": 0.005734059099690057, "critic_loss": 0.0004708812816588761, "actor_loss": -8.433113332815468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.561057806015015, "step": 113000}
{"episode_reward": 3.1123931202883526, "episode": 114.0, "batch_reward": 0.005800012382445857, "critic_loss": 0.0008264877890069329, "actor_loss": -9.38371442078799, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.766141414642334, "step": 114000}
{"episode_reward": 2.6278342239344687, "episode": 115.0, "batch_reward": 0.0055023339570034295, "critic_loss": 0.0005272309010142635, "actor_loss": -9.550884453944862, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.308150053024292, "step": 115000}
{"episode_reward": 2.5751473210717504, "episode": 116.0, "batch_reward": 0.005721831100876443, "critic_loss": 0.0007600526568312489, "actor_loss": -8.966489915378391, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.199217557907104, "step": 116000}
{"episode_reward": 1.7523629075542533, "episode": 117.0, "batch_reward": 0.005611799494945444, "critic_loss": 0.0005899055583849986, "actor_loss": -8.550975448220969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.08153533935547, "step": 117000}
{"episode_reward": 2.8077985015418907, "episode": 118.0, "batch_reward": 0.005573763971915469, "critic_loss": 0.0006403907617386722, "actor_loss": -8.434574479155243, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.81347393989563, "step": 118000}
{"episode_reward": 2.3062039292777303, "episode": 119.0, "batch_reward": 0.005690152339753695, "critic_loss": 0.0007432596274120442, "actor_loss": -7.899098666518927, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.785186290740967, "step": 119000}
{"episode_reward": 2.3345417775234987, "episode": 120.0, "batch_reward": 0.005652108902926557, "critic_loss": 0.000627660087437107, "actor_loss": -8.258571214541792, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.095197200775146, "step": 120000}
{"episode_reward": 2.6662078850317084, "episode": 121.0, "batch_reward": 0.005457251769606955, "critic_loss": 0.0008746799190521415, "actor_loss": -8.253617585405708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.96167540550232, "step": 121000}
{"episode_reward": 2.717593858068362, "episode": 122.0, "batch_reward": 0.005488703784649261, "critic_loss": 0.0007460144623055385, "actor_loss": -9.083962058022617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.625654220581055, "step": 122000}
{"episode_reward": 2.041531710252014, "episode": 123.0, "batch_reward": 0.005505024198442698, "critic_loss": 0.0006620251495096454, "actor_loss": -9.023176392309368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.786369800567627, "step": 123000}
{"episode_reward": 2.549511600167305, "episode": 124.0, "batch_reward": 0.0055546611569589005, "critic_loss": 0.0008271075813245262, "actor_loss": -8.853583057686686, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.036930322647095, "step": 124000}
{"episode_reward": 3.017694912496985, "episode": 125.0, "batch_reward": 0.005345583503250964, "critic_loss": 0.0005535538366821128, "actor_loss": -9.186646786428987, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.981764793395996, "step": 125000}
{"episode_reward": 2.072128367423832, "episode": 126.0, "batch_reward": 0.005526079298462719, "critic_loss": 0.0007641833110319567, "actor_loss": -9.258743117786944, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.49868154525757, "step": 126000}
{"episode_reward": 3.1173259296122695, "episode": 127.0, "batch_reward": 0.0054053140518954025, "critic_loss": 0.0008134826722689468, "actor_loss": -10.263292194031179, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.698897123336792, "step": 127000}
{"episode_reward": 2.829876846234053, "episode": 128.0, "batch_reward": 0.005378361181705258, "critic_loss": 0.0006691777541836928, "actor_loss": -9.137485162004829, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.461507558822632, "step": 128000}
{"episode_reward": 2.669493713724499, "episode": 129.0, "batch_reward": 0.0054162713898113, "critic_loss": 0.0006013339508463104, "actor_loss": -9.02305769482255, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.384210109710693, "step": 129000}
{"episode_reward": 3.0096433270977476, "episode": 130.0, "batch_reward": 0.005246531630400568, "critic_loss": 0.0008036185632845445, "actor_loss": -9.256383538767695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.197503328323364, "step": 130000}
{"episode_reward": 1.8744724207460963, "episode": 131.0, "batch_reward": 0.005275441040401347, "critic_loss": 0.0005693660941105918, "actor_loss": -8.42709397379309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.0108323097229, "step": 131000}
{"episode_reward": 2.284352303708065, "episode": 132.0, "batch_reward": 0.0052392805983545255, "critic_loss": 0.0008324451910939388, "actor_loss": -8.835588596463204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.56507396697998, "step": 132000}
{"episode_reward": 2.747433438465469, "episode": 133.0, "batch_reward": 0.005196017664857209, "critic_loss": 0.000701359148202755, "actor_loss": -7.949584976814688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.396547079086304, "step": 133000}
{"episode_reward": 2.3254756636846245, "episode": 134.0, "batch_reward": 0.005372743611806072, "critic_loss": 0.0004580529087143077, "actor_loss": -9.06920802873373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.349358081817627, "step": 134000}
{"episode_reward": 2.8014890567369597, "episode": 135.0, "batch_reward": 0.005066038246499375, "critic_loss": 0.0004809821000235388, "actor_loss": -10.134581288971006, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.80743098258972, "step": 135000}
{"episode_reward": 2.562258110365214, "episode": 136.0, "batch_reward": 0.00528101795562543, "critic_loss": 0.0010054280136537273, "actor_loss": -9.311460439637303, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.54558753967285, "step": 136000}
{"episode_reward": 2.3266866374895905, "episode": 137.0, "batch_reward": 0.00513638978486415, "critic_loss": 0.00061201731374058, "actor_loss": -9.956274144463242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.993534326553345, "step": 137000}
{"episode_reward": 2.4369959225003726, "episode": 138.0, "batch_reward": 0.0051977284532040355, "critic_loss": 0.0007777083382243291, "actor_loss": -9.486356766857206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.53787899017334, "step": 138000}
{"episode_reward": 2.3771710484565753, "episode": 139.0, "batch_reward": 0.005063640538835898, "critic_loss": 0.0008479602061615878, "actor_loss": -8.954801035590469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.213110208511353, "step": 139000}
{"episode_reward": 2.4910675779657225, "episode": 140.0, "batch_reward": 0.005297295579453931, "critic_loss": 0.0004906117026293942, "actor_loss": -8.663716098360718, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.923527002334595, "step": 140000}
{"episode_reward": 2.666822390862336, "episode": 141.0, "batch_reward": 0.005075978051638231, "critic_loss": 0.0006084868080870365, "actor_loss": -9.425173067696393, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 38.9670832157135, "step": 141000}
{"episode_reward": 2.545933336106898, "episode": 142.0, "batch_reward": 0.005059316211263649, "critic_loss": 0.0007655618704702647, "actor_loss": -9.193282671324909, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.633634328842163, "step": 142000}
{"episode_reward": 2.307628659246869, "episode": 143.0, "batch_reward": 0.0051698674820363525, "critic_loss": 0.0005598509082137752, "actor_loss": -9.071529321432113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.624407052993774, "step": 143000}
{"episode_reward": 2.9734045701259157, "episode": 144.0, "batch_reward": 0.0050176295842975374, "critic_loss": 0.0005855545480008004, "actor_loss": -9.540951530046762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.462111711502075, "step": 144000}
{"episode_reward": 2.3955625299904653, "episode": 145.0, "batch_reward": 0.004922499755513854, "critic_loss": 0.0005495387335740816, "actor_loss": -9.423797004282475, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.72117042541504, "step": 145000}
{"episode_reward": 3.6183711215200374, "episode": 146.0, "batch_reward": 0.004958803508081473, "critic_loss": 0.00046434302061607014, "actor_loss": -8.657231241747738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.67210078239441, "step": 146000}
{"episode_reward": 2.461315473925545, "episode": 147.0, "batch_reward": 0.005027088111499324, "critic_loss": 0.0007324376654469233, "actor_loss": -9.006264851711691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.197944164276123, "step": 147000}
{"episode_reward": 2.355287579526562, "episode": 148.0, "batch_reward": 0.00489024183829315, "critic_loss": 0.000566512980076368, "actor_loss": -9.298561836257576, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.833717823028564, "step": 148000}
{"episode_reward": 2.844107688646543, "episode": 149.0, "batch_reward": 0.004978500906610861, "critic_loss": 0.0006289998300380831, "actor_loss": -8.473107109740376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.544495582580566, "step": 149000}
{"episode_reward": 2.770471075678706, "episode": 150.0, "batch_reward": 0.004778551531606354, "critic_loss": 0.0003727893469895207, "actor_loss": -10.245571348398924, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
