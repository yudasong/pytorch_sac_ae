{"episode_reward": 0.0, "episode": 1.0, "duration": 17.870479583740234, "step": 1000}
{"episode_reward": 7.051849146674556, "episode": 2.0, "duration": 1.47086763381958, "step": 2000}
{"episode_reward": 365.4711839680396, "episode": 3.0, "batch_reward": 0.17843369440004483, "critic_loss": 0.44250957939119173, "actor_loss": -34.96546570517245, "actor_target_entropy": -6.0, "alpha_value": 0.01377813086574139, "duration": 66.73432445526123, "step": 3000}
{"episode_reward": 51.73025909987169, "episode": 4.0, "batch_reward": 0.12993209259212016, "critic_loss": 0.25752668192982675, "actor_loss": -31.212689186096192, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.84035086631775, "step": 4000}
{"episode_reward": 54.22339989691282, "episode": 5.0, "batch_reward": 0.113718764744699, "critic_loss": 0.22100032015889884, "actor_loss": -29.665869106292725, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.7476749420166, "step": 5000}
{"episode_reward": 64.13077718076586, "episode": 6.0, "batch_reward": 0.10324561106413603, "critic_loss": 0.20205989443510772, "actor_loss": -29.161367881774904, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 23.629695892333984, "step": 6000}
{"episode_reward": 52.759182936469145, "episode": 7.0, "batch_reward": 0.09506223515048623, "critic_loss": 0.17089401020109654, "actor_loss": -28.194934993743896, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.853760480880737, "step": 7000}
{"episode_reward": 43.877548299274494, "episode": 8.0, "batch_reward": 0.08792385990172624, "critic_loss": 0.152545617595315, "actor_loss": -27.50296511077881, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.804803133010864, "step": 8000}
{"episode_reward": 37.72128981129154, "episode": 9.0, "batch_reward": 0.08195855228602886, "critic_loss": 0.1388472222201526, "actor_loss": -27.16065435409546, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.463040351867676, "step": 9000}
{"episode_reward": 41.28689253219676, "episode": 10.0, "batch_reward": 0.0787488058693707, "critic_loss": 0.11709311163425445, "actor_loss": -26.849206537246705, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.504270553588867, "step": 10000}
{"episode_reward": 55.76653553534758, "episode": 11.0, "batch_reward": 0.07625262542441487, "critic_loss": 0.10850250285863876, "actor_loss": -26.40836480522156, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 38.29283118247986, "step": 11000}
{"episode_reward": 39.625235263046925, "episode": 12.0, "batch_reward": 0.07265602250769734, "critic_loss": 0.08789493308588862, "actor_loss": -25.976814796447755, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.180530786514282, "step": 12000}
{"episode_reward": 44.0998617902876, "episode": 13.0, "batch_reward": 0.07026596404612065, "critic_loss": 0.07973162587732077, "actor_loss": -25.70034864807129, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.063438415527344, "step": 13000}
{"episode_reward": 41.29384358463686, "episode": 14.0, "batch_reward": 0.06844982086867094, "critic_loss": 0.06859100387617946, "actor_loss": -25.30093487739563, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.261049032211304, "step": 14000}
{"episode_reward": 55.03182315649518, "episode": 15.0, "batch_reward": 0.06710421359911561, "critic_loss": 0.06204007760807872, "actor_loss": -25.533536899566652, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.175854921340942, "step": 15000}
{"episode_reward": 54.886567049467146, "episode": 16.0, "batch_reward": 0.0667619715668261, "critic_loss": 0.05941762325912714, "actor_loss": -25.09820659828186, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.134241104125977, "step": 16000}
{"episode_reward": 52.558257494427004, "episode": 17.0, "batch_reward": 0.0654784224331379, "critic_loss": 0.05004876882396638, "actor_loss": -24.50970638847351, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.698811769485474, "step": 17000}
{"episode_reward": 54.98995779829148, "episode": 18.0, "batch_reward": 0.06624748781695962, "critic_loss": 0.04762934489734471, "actor_loss": -24.63879755973816, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.189093112945557, "step": 18000}
{"episode_reward": 70.14554670727635, "episode": 19.0, "batch_reward": 0.06558736019581557, "critic_loss": 0.04266783568263054, "actor_loss": -24.681886855125427, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.807326555252075, "step": 19000}
{"episode_reward": 52.47359780080108, "episode": 20.0, "batch_reward": 0.0652142213061452, "critic_loss": 0.03615945862792432, "actor_loss": -25.125334449768065, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.31867504119873, "step": 20000}
{"episode_reward": 66.59019556524733, "episode": 21.0, "batch_reward": 0.06511446446552872, "critic_loss": 0.03287342413701117, "actor_loss": -23.658662655830383, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.23027229309082, "step": 21000}
{"episode_reward": 64.4504761071756, "episode": 22.0, "batch_reward": 0.06502561797946692, "critic_loss": 0.03293688341602683, "actor_loss": -24.28277234554291, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.221296787261963, "step": 22000}
{"episode_reward": 55.9022426518341, "episode": 23.0, "batch_reward": 0.06494634333625436, "critic_loss": 0.03510816008597612, "actor_loss": -23.649305481910705, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 23.502258777618408, "step": 23000}
{"episode_reward": 60.939551963956696, "episode": 24.0, "batch_reward": 0.06426858315989376, "critic_loss": 0.03660883896797895, "actor_loss": -24.008013472557067, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.497859239578247, "step": 24000}
{"episode_reward": 67.38709933639642, "episode": 25.0, "batch_reward": 0.06471703280135989, "critic_loss": 0.03810218088701368, "actor_loss": -24.299914100646973, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.952184915542603, "step": 25000}
{"episode_reward": 60.20048244954673, "episode": 26.0, "batch_reward": 0.06476490585878492, "critic_loss": 0.03959585012495518, "actor_loss": -23.47334332227707, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.026106595993042, "step": 26000}
{"episode_reward": 61.064897930173885, "episode": 27.0, "batch_reward": 0.06471841883659363, "critic_loss": 0.04351532706990838, "actor_loss": -23.721056437492372, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.511534929275513, "step": 27000}
{"episode_reward": 60.008347772125006, "episode": 28.0, "batch_reward": 0.06493382503092289, "critic_loss": 0.049124148812144997, "actor_loss": -23.22186569738388, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.417816400527954, "step": 28000}
{"episode_reward": 79.65685990158545, "episode": 29.0, "batch_reward": 0.06471148789674043, "critic_loss": 0.053728794327005745, "actor_loss": -23.39854266023636, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.74527359008789, "step": 29000}
{"episode_reward": 71.7597155968556, "episode": 30.0, "batch_reward": 0.06581661228835582, "critic_loss": 0.060968662068247796, "actor_loss": -22.476821974754333, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.796937227249146, "step": 30000}
{"episode_reward": 83.81438984459854, "episode": 31.0, "batch_reward": 0.06616191344708204, "critic_loss": 0.06340025397762657, "actor_loss": -23.37804671907425, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 39.23886036872864, "step": 31000}
{"episode_reward": 82.9233784843204, "episode": 32.0, "batch_reward": 0.066594206944108, "critic_loss": 0.07269751423969865, "actor_loss": -23.619897317647933, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.824036121368408, "step": 32000}
{"episode_reward": 96.59475172831274, "episode": 33.0, "batch_reward": 0.0680134394057095, "critic_loss": 0.07956451582536102, "actor_loss": -23.621522432088852, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.18600606918335, "step": 33000}
{"episode_reward": 107.2180809698971, "episode": 34.0, "batch_reward": 0.06966638258099556, "critic_loss": 0.09217773336172104, "actor_loss": -23.54388498854637, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.90074896812439, "step": 34000}
{"episode_reward": 117.82340275280171, "episode": 35.0, "batch_reward": 0.07020795393362642, "critic_loss": 0.09854694303497671, "actor_loss": -23.447626474142076, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.086986541748047, "step": 35000}
{"episode_reward": 139.73569046742716, "episode": 36.0, "batch_reward": 0.07277815416827797, "critic_loss": 0.10392303711175918, "actor_loss": -23.875386306285858, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 23.17948842048645, "step": 36000}
{"episode_reward": 157.38446873121208, "episode": 37.0, "batch_reward": 0.07513775505498052, "critic_loss": 0.11604151435941458, "actor_loss": -23.047546231627464, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.87369394302368, "step": 37000}
{"episode_reward": 146.21528043265627, "episode": 38.0, "batch_reward": 0.07723679172620178, "critic_loss": 0.12946180314570666, "actor_loss": -22.662745084285735, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.294029235839844, "step": 38000}
{"episode_reward": 190.90998147437938, "episode": 39.0, "batch_reward": 0.08031187454238534, "critic_loss": 0.13153758195787668, "actor_loss": -22.64509724807739, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.48581886291504, "step": 39000}
{"episode_reward": 178.2170476927189, "episode": 40.0, "batch_reward": 0.08265793917700648, "critic_loss": 0.13401954070478678, "actor_loss": -23.446855190753936, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 23.91745400428772, "step": 40000}
{"episode_reward": 179.33038125727683, "episode": 41.0, "batch_reward": 0.08554039197042584, "critic_loss": 0.1355895730778575, "actor_loss": -23.2511760365963, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 38.776501417160034, "step": 41000}
{"episode_reward": 197.01890415860638, "episode": 42.0, "batch_reward": 0.08849546658247709, "critic_loss": 0.13800822382420302, "actor_loss": -23.383112380862237, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.091687440872192, "step": 42000}
{"episode_reward": 224.74018694746988, "episode": 43.0, "batch_reward": 0.09141147929430007, "critic_loss": 0.1424918467476964, "actor_loss": -23.566411044716833, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.056214570999146, "step": 43000}
{"episode_reward": 215.94041968995109, "episode": 44.0, "batch_reward": 0.09387371134757995, "critic_loss": 0.1527668245509267, "actor_loss": -25.308237913429735, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.55156636238098, "step": 44000}
{"episode_reward": 143.2449301423175, "episode": 45.0, "batch_reward": 0.0952609916701913, "critic_loss": 0.15118262845277786, "actor_loss": -23.907404494166375, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.004082679748535, "step": 45000}
{"episode_reward": 203.1524154423373, "episode": 46.0, "batch_reward": 0.0976989984959364, "critic_loss": 0.15725959096103906, "actor_loss": -22.826150719821452, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.494924068450928, "step": 46000}
{"episode_reward": 208.4051219867438, "episode": 47.0, "batch_reward": 0.10028190418332815, "critic_loss": 0.16150838265568018, "actor_loss": -23.645201394438743, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.14107370376587, "step": 47000}
{"episode_reward": 214.47528414023665, "episode": 48.0, "batch_reward": 0.10152626208215952, "critic_loss": 0.17413739529252054, "actor_loss": -23.26325371083617, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.856472730636597, "step": 48000}
{"episode_reward": 71.98914145310454, "episode": 49.0, "batch_reward": 0.10175952272862196, "critic_loss": 0.1691787542104721, "actor_loss": -24.37447127905488, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.719404458999634, "step": 49000}
{"episode_reward": 189.50752032462512, "episode": 50.0, "batch_reward": 0.10423524788022041, "critic_loss": 0.16647436735779048, "actor_loss": -23.836364120915533, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.913147926330566, "step": 50000}
{"episode_reward": 225.4962789006842, "episode": 51.0, "batch_reward": 0.10695866804569959, "critic_loss": 0.16494910813122987, "actor_loss": -23.763108577787875, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.37558317184448, "step": 51000}
{"episode_reward": 256.8770514479402, "episode": 52.0, "batch_reward": 0.10998636806756258, "critic_loss": 0.17238035464286805, "actor_loss": -23.47129481893778, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.79179310798645, "step": 52000}
{"episode_reward": 262.1238378719027, "episode": 53.0, "batch_reward": 0.11248807378858328, "critic_loss": 0.1890988121703267, "actor_loss": -24.48955844438076, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 23.965509176254272, "step": 53000}
{"episode_reward": 177.607996491628, "episode": 54.0, "batch_reward": 0.11372259223461151, "critic_loss": 0.20375913310796023, "actor_loss": -24.802488740563394, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.233485460281372, "step": 54000}
{"episode_reward": 256.93182011165396, "episode": 55.0, "batch_reward": 0.11564532584697008, "critic_loss": 0.2028547797501087, "actor_loss": -24.55858285331726, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.724111557006836, "step": 55000}
{"episode_reward": 247.721849026343, "episode": 56.0, "batch_reward": 0.11855548083037137, "critic_loss": 0.20385160038620234, "actor_loss": -24.647403284668922, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.088563203811646, "step": 56000}
{"episode_reward": 243.23969350344626, "episode": 57.0, "batch_reward": 0.1212947020381689, "critic_loss": 0.21577639865130185, "actor_loss": -24.73936982384324, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 23.092180013656616, "step": 57000}
{"episode_reward": 275.18131543543035, "episode": 58.0, "batch_reward": 0.12333695723116397, "critic_loss": 0.22090307971835135, "actor_loss": -25.01488070833683, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.58386540412903, "step": 58000}
{"episode_reward": 257.19978700822105, "episode": 59.0, "batch_reward": 0.1263948876261711, "critic_loss": 0.2253452807813883, "actor_loss": -25.03781995201111, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.83507537841797, "step": 59000}
{"episode_reward": 278.96775896968705, "episode": 60.0, "batch_reward": 0.12887669268995525, "critic_loss": 0.22202842807024717, "actor_loss": -25.043063084363936, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.50489044189453, "step": 60000}
{"episode_reward": 278.0406357573368, "episode": 61.0, "batch_reward": 0.13077551999688147, "critic_loss": 0.22630936162173748, "actor_loss": -25.04118950676918, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 38.74181032180786, "step": 61000}
{"episode_reward": 223.2101395529769, "episode": 62.0, "batch_reward": 0.1325344441756606, "critic_loss": 0.23631345772743226, "actor_loss": -25.211675708293914, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.326471090316772, "step": 62000}
{"episode_reward": 247.00917416188366, "episode": 63.0, "batch_reward": 0.13313028223067522, "critic_loss": 0.2560514283031225, "actor_loss": -25.289805199623107, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.557307720184326, "step": 63000}
{"episode_reward": 58.96387112189598, "episode": 64.0, "batch_reward": 0.1332988942861557, "critic_loss": 0.2668803820610046, "actor_loss": -25.637970770835878, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.069267511367798, "step": 64000}
{"episode_reward": 210.52564300264797, "episode": 65.0, "batch_reward": 0.13378756453841925, "critic_loss": 0.2969306639432907, "actor_loss": -25.018750831365587, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.3097186088562, "step": 65000}
{"episode_reward": 242.32927093887514, "episode": 66.0, "batch_reward": 0.13458980149775743, "critic_loss": 0.2996062227189541, "actor_loss": -24.936236318588257, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.142048120498657, "step": 66000}
{"episode_reward": 85.86658093711107, "episode": 67.0, "batch_reward": 0.13527743697166442, "critic_loss": 0.3154605794996023, "actor_loss": -25.525401366472245, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.495721101760864, "step": 67000}
{"episode_reward": 217.91092155030745, "episode": 68.0, "batch_reward": 0.13664673339575528, "critic_loss": 0.33788385286927225, "actor_loss": -26.234248836278915, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.996785640716553, "step": 68000}
{"episode_reward": 264.8248317110854, "episode": 69.0, "batch_reward": 0.13842624799162148, "critic_loss": 0.3216823806166649, "actor_loss": -24.649401207447053, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.71094822883606, "step": 69000}
{"episode_reward": 279.1763810617024, "episode": 70.0, "batch_reward": 0.14082607667148114, "critic_loss": 0.3328369000256062, "actor_loss": -25.044795552968978, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.745758056640625, "step": 70000}
{"episode_reward": 248.20668102922244, "episode": 71.0, "batch_reward": 0.14194216342270374, "critic_loss": 0.32621373361349104, "actor_loss": -24.677527999639512, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.492908000946045, "step": 71000}
{"episode_reward": 280.2803784032602, "episode": 72.0, "batch_reward": 0.14380879947543143, "critic_loss": 0.3069412986934185, "actor_loss": -25.813751013994217, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.602688789367676, "step": 72000}
{"episode_reward": 255.45099507455944, "episode": 73.0, "batch_reward": 0.14539621847867965, "critic_loss": 0.29132179702818395, "actor_loss": -26.051252513170244, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 23.59908676147461, "step": 73000}
{"episode_reward": 220.61646006854994, "episode": 74.0, "batch_reward": 0.1456566174775362, "critic_loss": 0.27318575330078604, "actor_loss": -25.209598757505418, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.88822603225708, "step": 74000}
{"episode_reward": 234.88540715712548, "episode": 75.0, "batch_reward": 0.1470412383824587, "critic_loss": 0.26307279838621617, "actor_loss": -25.32171740961075, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.231740474700928, "step": 75000}
{"episode_reward": 273.00976758941937, "episode": 76.0, "batch_reward": 0.1493436630964279, "critic_loss": 0.259177517414093, "actor_loss": -25.942873831272124, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.175410747528076, "step": 76000}
{"episode_reward": 260.14307658831825, "episode": 77.0, "batch_reward": 0.15095614060759543, "critic_loss": 0.26421186634898186, "actor_loss": -25.569825955867767, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.04534101486206, "step": 77000}
{"episode_reward": 284.18540974673715, "episode": 78.0, "batch_reward": 0.15255438558757306, "critic_loss": 0.24925735229253768, "actor_loss": -26.09993722295761, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.55590271949768, "step": 78000}
{"episode_reward": 267.68300980316627, "episode": 79.0, "batch_reward": 0.15431907892227173, "critic_loss": 0.2579832465648651, "actor_loss": -27.097794588088988, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.12866449356079, "step": 79000}
{"episode_reward": 280.3143888599014, "episode": 80.0, "batch_reward": 0.1552849095016718, "critic_loss": 0.28042017574608324, "actor_loss": -26.54937421798706, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.462393283843994, "step": 80000}
{"episode_reward": 287.5016646337512, "episode": 81.0, "batch_reward": 0.1571585566699505, "critic_loss": 0.26778513905406, "actor_loss": -25.672312945842744, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.50480031967163, "step": 81000}
{"episode_reward": 312.9052080210609, "episode": 82.0, "batch_reward": 0.1590640633404255, "critic_loss": 0.26330612652748825, "actor_loss": -26.01386116552353, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.30493664741516, "step": 82000}
{"episode_reward": 321.5967958285136, "episode": 83.0, "batch_reward": 0.1605202576071024, "critic_loss": 0.29424693221598863, "actor_loss": -26.52722339439392, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.216979026794434, "step": 83000}
{"episode_reward": 64.50302431211946, "episode": 84.0, "batch_reward": 0.16010687728226186, "critic_loss": 0.2817146718502045, "actor_loss": -26.875003508090973, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.271044731140137, "step": 84000}
{"episode_reward": 270.3381420079048, "episode": 85.0, "batch_reward": 0.1610494762212038, "critic_loss": 0.2986672352403402, "actor_loss": -26.579740232944488, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.971922636032104, "step": 85000}
{"episode_reward": 245.71387007615667, "episode": 86.0, "batch_reward": 0.16235079282522202, "critic_loss": 0.31926484571397307, "actor_loss": -26.505908262252806, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.616058826446533, "step": 86000}
{"episode_reward": 286.28691332854635, "episode": 87.0, "batch_reward": 0.16375894647836686, "critic_loss": 0.3228187802284956, "actor_loss": -26.888656744956972, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 23.340315580368042, "step": 87000}
{"episode_reward": 260.07661671277106, "episode": 88.0, "batch_reward": 0.1644357907772064, "critic_loss": 0.33817169013619425, "actor_loss": -26.22761374950409, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.90139675140381, "step": 88000}
{"episode_reward": 318.69266028239605, "episode": 89.0, "batch_reward": 0.16706598894298078, "critic_loss": 0.3359538963884115, "actor_loss": -26.86266767501831, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.726069927215576, "step": 89000}
{"episode_reward": 306.08146429220454, "episode": 90.0, "batch_reward": 0.1685846603512764, "critic_loss": 0.321631021887064, "actor_loss": -26.63225840473175, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.031080722808838, "step": 90000}
{"episode_reward": 304.57755526304055, "episode": 91.0, "batch_reward": 0.1691579835563898, "critic_loss": 0.3273534528464079, "actor_loss": -26.8944357585907, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 40.38815641403198, "step": 91000}
{"episode_reward": 298.81018946745854, "episode": 92.0, "batch_reward": 0.17113085304200648, "critic_loss": 0.3260068180114031, "actor_loss": -27.882689625740053, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.358370065689087, "step": 92000}
{"episode_reward": 307.9799950641318, "episode": 93.0, "batch_reward": 0.17251039245724678, "critic_loss": 0.33635767151415347, "actor_loss": -26.76973437309265, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.543980836868286, "step": 93000}
{"episode_reward": 334.8393612948801, "episode": 94.0, "batch_reward": 0.17425465467572213, "critic_loss": 0.328089050129056, "actor_loss": -27.573473230361937, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.319644927978516, "step": 94000}
{"episode_reward": 279.0144935424718, "episode": 95.0, "batch_reward": 0.1755577748864889, "critic_loss": 0.3296473273485899, "actor_loss": -28.262218779563902, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.83142590522766, "step": 95000}
{"episode_reward": 299.35966759111454, "episode": 96.0, "batch_reward": 0.17706075820326805, "critic_loss": 0.33458052602410315, "actor_loss": -28.249392636299135, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.494661808013916, "step": 96000}
{"episode_reward": 314.7001352449787, "episode": 97.0, "batch_reward": 0.1787252305150032, "critic_loss": 0.3259118359237909, "actor_loss": -27.86147856426239, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.90636134147644, "step": 97000}
{"episode_reward": 358.5530220046, "episode": 98.0, "batch_reward": 0.17966312085092068, "critic_loss": 0.33107642486691474, "actor_loss": -28.61442564201355, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.45601511001587, "step": 98000}
{"episode_reward": 276.71654911093117, "episode": 99.0, "batch_reward": 0.18053425247967242, "critic_loss": 0.3487695808708668, "actor_loss": -27.737856482505798, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.11156415939331, "step": 99000}
{"episode_reward": 285.9123636479128, "episode": 100.0, "batch_reward": 0.18218803313374518, "critic_loss": 0.34126662933826446, "actor_loss": -28.53931211280823, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 23.341803312301636, "step": 100000}
{"episode_reward": 373.5944584120289, "episode": 101.0, "batch_reward": 0.18345281456410883, "critic_loss": 0.382962322473526, "actor_loss": -27.564977387428282, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.9008674621582, "step": 101000}
{"episode_reward": 316.8590604051197, "episode": 102.0, "batch_reward": 0.18559297078847886, "critic_loss": 0.391515590146184, "actor_loss": -28.60684585094452, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.0615074634552, "step": 102000}
{"episode_reward": 330.49454120129457, "episode": 103.0, "batch_reward": 0.18655693973600865, "critic_loss": 0.35924051867425444, "actor_loss": -27.782178216934206, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.318325519561768, "step": 103000}
{"episode_reward": 358.1183802451518, "episode": 104.0, "batch_reward": 0.18862476013600826, "critic_loss": 0.3313065237998962, "actor_loss": -27.949267402648925, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.578804969787598, "step": 104000}
{"episode_reward": 287.93159373968444, "episode": 105.0, "batch_reward": 0.18998133251070976, "critic_loss": 0.3563672105371952, "actor_loss": -28.43561773109436, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.83695650100708, "step": 105000}
{"episode_reward": 297.93616381592597, "episode": 106.0, "batch_reward": 0.1901332550495863, "critic_loss": 0.356453670412302, "actor_loss": -28.381072818756103, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.509170532226562, "step": 106000}
{"episode_reward": 362.20921672255423, "episode": 107.0, "batch_reward": 0.19217199382185937, "critic_loss": 0.3551755641847849, "actor_loss": -27.866926412582398, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.37076473236084, "step": 107000}
{"episode_reward": 325.1477387211365, "episode": 108.0, "batch_reward": 0.1932756367176771, "critic_loss": 0.35760132835805414, "actor_loss": -29.15761218929291, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.930713176727295, "step": 108000}
{"episode_reward": 343.9240633564233, "episode": 109.0, "batch_reward": 0.1952107788026333, "critic_loss": 0.3624292671084404, "actor_loss": -28.77624691104889, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.128769874572754, "step": 109000}
{"episode_reward": 346.17367903432734, "episode": 110.0, "batch_reward": 0.19604469485580922, "critic_loss": 0.3905744418501854, "actor_loss": -29.77655904865265, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.34160280227661, "step": 110000}
{"episode_reward": 306.5982399172078, "episode": 111.0, "batch_reward": 0.1971905151158571, "critic_loss": 0.3872198419570923, "actor_loss": -28.95039486503601, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.500715017318726, "step": 111000}
{"episode_reward": 322.0239629054278, "episode": 112.0, "batch_reward": 0.19830931784212588, "critic_loss": 0.40236386355757714, "actor_loss": -29.16064609336853, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.52155303955078, "step": 112000}
{"episode_reward": 324.827744123166, "episode": 113.0, "batch_reward": 0.1994413237273693, "critic_loss": 0.3768227509111166, "actor_loss": -29.08577925300598, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.118319749832153, "step": 113000}
{"episode_reward": 367.8772460858415, "episode": 114.0, "batch_reward": 0.20053459794819356, "critic_loss": 0.3621162620037794, "actor_loss": -29.56227119064331, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.546252250671387, "step": 114000}
{"episode_reward": 117.66708329992237, "episode": 115.0, "batch_reward": 0.19960143876075745, "critic_loss": 0.36993622133135795, "actor_loss": -29.380031087875366, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.156327962875366, "step": 115000}
{"episode_reward": 293.5199796443573, "episode": 116.0, "batch_reward": 0.201398004129529, "critic_loss": 0.3886054248511791, "actor_loss": -29.53715602874756, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 23.359237670898438, "step": 116000}
{"episode_reward": 372.90913009144947, "episode": 117.0, "batch_reward": 0.20290151657164096, "critic_loss": 0.39113372467458246, "actor_loss": -28.914076780319213, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 24.07367753982544, "step": 117000}
{"episode_reward": 359.0375802854214, "episode": 118.0, "batch_reward": 0.20401265005767347, "critic_loss": 0.42820132699608804, "actor_loss": -29.388879234313965, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.375150442123413, "step": 118000}
{"episode_reward": 347.71838427887883, "episode": 119.0, "batch_reward": 0.20452943724393843, "critic_loss": 0.43670905436575413, "actor_loss": -29.776540071487428, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.56591796875, "step": 119000}
{"episode_reward": 309.6035013826181, "episode": 120.0, "batch_reward": 0.20534793697297574, "critic_loss": 0.4097290845513344, "actor_loss": -28.760249799728392, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.09820055961609, "step": 120000}
{"episode_reward": 381.32511155152514, "episode": 121.0, "batch_reward": 0.206778996899724, "critic_loss": 0.3981431452780962, "actor_loss": -29.593980295181275, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 39.82030177116394, "step": 121000}
{"episode_reward": 357.72385395276564, "episode": 122.0, "batch_reward": 0.2089070338308811, "critic_loss": 0.43680727724730967, "actor_loss": -30.2049657535553, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.32188320159912, "step": 122000}
{"episode_reward": 348.0998785839377, "episode": 123.0, "batch_reward": 0.21019711415469647, "critic_loss": 0.44685712096095087, "actor_loss": -30.481737480163574, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.172398328781128, "step": 123000}
{"episode_reward": 394.56409294223744, "episode": 124.0, "batch_reward": 0.211632449939847, "critic_loss": 0.4288913667798042, "actor_loss": -30.344267377853395, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.959607362747192, "step": 124000}
{"episode_reward": 409.28535265514375, "episode": 125.0, "batch_reward": 0.2128878749758005, "critic_loss": 0.4474638281315565, "actor_loss": -30.10612338066101, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 23.484033823013306, "step": 125000}
{"episode_reward": 351.2257338408049, "episode": 126.0, "batch_reward": 0.21436340890824795, "critic_loss": 0.45663742361962795, "actor_loss": -30.836587997436524, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 23.286049604415894, "step": 126000}
{"episode_reward": 305.9863157456996, "episode": 127.0, "batch_reward": 0.21412355810403824, "critic_loss": 0.4710029967725277, "actor_loss": -30.339959466934204, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.2072696685791, "step": 127000}
{"episode_reward": 367.4908326741769, "episode": 128.0, "batch_reward": 0.21597236874699594, "critic_loss": 0.45730334098637104, "actor_loss": -29.925340827941895, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.859639167785645, "step": 128000}
{"episode_reward": 352.5401837990921, "episode": 129.0, "batch_reward": 0.21714478440582752, "critic_loss": 0.471643441721797, "actor_loss": -30.654907285690307, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.98906445503235, "step": 129000}
{"episode_reward": 375.02682816316945, "episode": 130.0, "batch_reward": 0.2180851116925478, "critic_loss": 0.46531887020170687, "actor_loss": -31.000600076675415, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 23.532698154449463, "step": 130000}
{"episode_reward": 390.33952335708284, "episode": 131.0, "batch_reward": 0.22027753898501395, "critic_loss": 0.45364697264134884, "actor_loss": -29.811639364242552, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.38530921936035, "step": 131000}
{"episode_reward": 359.3936238545229, "episode": 132.0, "batch_reward": 0.22052103227376937, "critic_loss": 0.4439670775681734, "actor_loss": -31.497943645477296, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.2162127494812, "step": 132000}
{"episode_reward": 310.87473796599403, "episode": 133.0, "batch_reward": 0.22123327858746053, "critic_loss": 0.4609880177676678, "actor_loss": -30.297855045318602, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.876375675201416, "step": 133000}
{"episode_reward": 382.3534608188993, "episode": 134.0, "batch_reward": 0.22138114447891713, "critic_loss": 0.46945572878420355, "actor_loss": -30.89716794204712, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.328023433685303, "step": 134000}
{"episode_reward": 350.82031043791994, "episode": 135.0, "batch_reward": 0.22288234607875348, "critic_loss": 0.4737955156415701, "actor_loss": -31.406707265853882, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.460587978363037, "step": 135000}
{"episode_reward": 352.47664510936465, "episode": 136.0, "batch_reward": 0.22449404594302177, "critic_loss": 0.4825087876319885, "actor_loss": -30.93444067955017, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.479633331298828, "step": 136000}
{"episode_reward": 346.66043409526424, "episode": 137.0, "batch_reward": 0.22521882356703282, "critic_loss": 0.47310900200903416, "actor_loss": -31.49753284072876, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.226529359817505, "step": 137000}
{"episode_reward": 313.3083217967456, "episode": 138.0, "batch_reward": 0.2252752827256918, "critic_loss": 0.5262016255557537, "actor_loss": -32.12971241188049, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.680351495742798, "step": 138000}
{"episode_reward": 89.23107078710008, "episode": 139.0, "batch_reward": 0.22551994775235654, "critic_loss": 0.49568345829844473, "actor_loss": -30.514782733917237, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.4856059551239, "step": 139000}
{"episode_reward": 388.24708767348244, "episode": 140.0, "batch_reward": 0.22564680343866347, "critic_loss": 0.507072557553649, "actor_loss": -31.837421812057496, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.41314435005188, "step": 140000}
{"episode_reward": 355.667713190137, "episode": 141.0, "batch_reward": 0.22753803092241287, "critic_loss": 0.521781869083643, "actor_loss": -31.273904962539675, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 38.15229558944702, "step": 141000}
{"episode_reward": 361.90055347587185, "episode": 142.0, "batch_reward": 0.22834169761836529, "critic_loss": 0.5047073958814144, "actor_loss": -31.220717697143556, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.98483943939209, "step": 142000}
{"episode_reward": 365.98779162935926, "episode": 143.0, "batch_reward": 0.22801864036917688, "critic_loss": 0.49784834863245486, "actor_loss": -31.36334595298767, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.127557277679443, "step": 143000}
{"episode_reward": 53.74433105012032, "episode": 144.0, "batch_reward": 0.2278003946840763, "critic_loss": 0.4990209387242794, "actor_loss": -31.6748984375, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.365746021270752, "step": 144000}
{"episode_reward": 336.1391235289926, "episode": 145.0, "batch_reward": 0.22838170976936817, "critic_loss": 0.48555382399261, "actor_loss": -31.69633655357361, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.830676794052124, "step": 145000}
{"episode_reward": 323.77889926875565, "episode": 146.0, "batch_reward": 0.22868597242236138, "critic_loss": 0.4704718986004591, "actor_loss": -30.70429225921631, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.088308572769165, "step": 146000}
{"episode_reward": 379.68729238830247, "episode": 147.0, "batch_reward": 0.22912571419775485, "critic_loss": 0.47135824111104013, "actor_loss": -31.301528573989867, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.24104332923889, "step": 147000}
{"episode_reward": 144.3114832604553, "episode": 148.0, "batch_reward": 0.22944170454144477, "critic_loss": 0.4932345071434975, "actor_loss": -31.052065282821655, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.604635000228882, "step": 148000}
{"episode_reward": 361.8929528000855, "episode": 149.0, "batch_reward": 0.23092818784713745, "critic_loss": 0.5026613180488348, "actor_loss": -31.63131441497803, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.99997639656067, "step": 149000}
{"episode_reward": 388.61228343110065, "episode": 150.0, "batch_reward": 0.23098701351881026, "critic_loss": 0.5002595907747746, "actor_loss": -31.979780071258546, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "step": 150000}
