{"episode": 1.0, "duration": 20.484774589538574, "episode_reward": 7.051849146674556, "step": 1000}
{"episode": 2.0, "duration": 1.8617138862609863, "episode_reward": 365.4711839680396, "step": 2000}
{"episode": 3.0, "batch_reward": 0.17851088232310783, "actor_loss": -35.69949701071835, "actor_target_entropy": -6.0, "alpha_value": 0.01377813086574139, "duration": 66.72423124313354, "episode_reward": 62.584956264538036, "step": 3000}
{"episode": 4.0, "batch_reward": 0.1325987352281809, "actor_loss": -32.98684069824219, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.120546579360962, "episode_reward": 59.70379635521725, "step": 4000}
{"episode": 5.0, "batch_reward": 0.11672117285430432, "actor_loss": -31.944293354034425, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.039271116256714, "episode_reward": 72.36735277029008, "step": 5000}
{"episode": 6.0, "batch_reward": 0.10908063109219074, "actor_loss": -31.390827159881592, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.962324857711792, "episode_reward": 72.46270335378497, "step": 6000}
{"episode": 7.0, "batch_reward": 0.1054168496876955, "actor_loss": -31.07487364578247, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.312833309173584, "episode_reward": 91.72261560096155, "step": 7000}
{"episode": 8.0, "batch_reward": 0.10252428789436817, "actor_loss": -30.848109241485595, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.98184323310852, "episode_reward": 60.754580258132236, "step": 8000}
{"episode": 9.0, "batch_reward": 0.09627079606801271, "actor_loss": -30.49446348953247, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.056355237960815, "episode_reward": 58.00315049304046, "step": 9000}
{"episode": 10.0, "batch_reward": 0.09174274511635304, "actor_loss": -30.168344005584718, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.09897494316101, "episode_reward": 43.754395357321044, "step": 10000}
{"episode": 11.0, "batch_reward": 0.08806577926501631, "actor_loss": -29.912824203491212, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.56517720222473, "episode_reward": 54.037199809849376, "step": 11000}
{"episode": 12.0, "batch_reward": 0.08562672811746597, "actor_loss": -29.74669440460205, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.12432098388672, "episode_reward": 73.17492206560323, "step": 12000}
{"episode": 13.0, "batch_reward": 0.0841688214763999, "actor_loss": -29.59513971710205, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.18380641937256, "episode_reward": 70.28848902640465, "step": 13000}
{"episode": 14.0, "batch_reward": 0.08419296717271209, "actor_loss": -29.57048607635498, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.282315492630005, "episode_reward": 79.21867992803213, "step": 14000}
{"episode": 15.0, "batch_reward": 0.08368959012255073, "actor_loss": -29.493876487731935, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.998055696487427, "episode_reward": 86.39555021017524, "step": 15000}
{"episode": 16.0, "batch_reward": 0.08398035059124231, "actor_loss": -29.463843021392822, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.839372396469116, "episode_reward": 99.11354076913189, "step": 16000}
{"episode": 17.0, "batch_reward": 0.08438836343213915, "actor_loss": -29.438738998413086, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.663219451904297, "episode_reward": 71.71540830769106, "step": 17000}
{"episode": 18.0, "batch_reward": 0.08491417920589447, "actor_loss": -29.453368648529054, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.801666975021362, "episode_reward": 109.27756571378873, "step": 18000}
{"episode": 19.0, "batch_reward": 0.08592972365766764, "actor_loss": -29.50060968017578, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.004483699798584, "episode_reward": 88.37590562118804, "step": 19000}
{"episode": 20.0, "batch_reward": 0.08606236466765403, "actor_loss": -29.481351306915283, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.823934078216553, "episode_reward": 109.06265681404243, "step": 20000}
{"episode": 21.0, "batch_reward": 0.08713993110135197, "actor_loss": -29.511701976776124, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.86472845077515, "episode_reward": 97.28879318186839, "step": 21000}
{"episode": 22.0, "batch_reward": 0.08893283417075873, "actor_loss": -29.555700714111328, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.699912309646606, "episode_reward": 143.29782541833708, "step": 22000}
{"episode": 23.0, "batch_reward": 0.09043121254816651, "actor_loss": -29.646434555053713, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.651204109191895, "episode_reward": 104.33152051930558, "step": 23000}
{"episode": 24.0, "batch_reward": 0.09236907383799553, "actor_loss": -29.674118812561034, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.689923763275146, "episode_reward": 181.91487249677616, "step": 24000}
{"episode": 25.0, "batch_reward": 0.09584154032170772, "actor_loss": -29.829859802246094, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.954349994659424, "episode_reward": 160.28847588253106, "step": 25000}
{"episode": 26.0, "batch_reward": 0.09835506589710713, "actor_loss": -29.92200775527954, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.885483741760254, "episode_reward": 153.24308130909287, "step": 26000}
{"episode": 27.0, "batch_reward": 0.10006524188816547, "actor_loss": -29.76556435394287, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.62365698814392, "episode_reward": 122.78289727014511, "step": 27000}
{"episode": 28.0, "batch_reward": 0.10052029735594988, "actor_loss": -29.54859271621704, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.61853575706482, "episode_reward": 78.43655345742513, "step": 28000}
{"episode": 29.0, "batch_reward": 0.09942218393087388, "actor_loss": -29.245529079437254, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.763890743255615, "episode_reward": 129.30328692447404, "step": 29000}
{"episode": 30.0, "batch_reward": 0.10112335684150457, "actor_loss": -29.319061981201173, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.838290691375732, "episode_reward": 184.37813283039108, "step": 30000}
{"episode": 31.0, "batch_reward": 0.103628003180027, "actor_loss": -29.4530410194397, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.68812036514282, "episode_reward": 165.41554504474666, "step": 31000}
{"episode": 32.0, "batch_reward": 0.10623054242134095, "actor_loss": -29.578929149627687, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.9343843460083, "episode_reward": 156.34695222835967, "step": 32000}
{"episode": 33.0, "batch_reward": 0.10767073582112789, "actor_loss": -29.696203018188477, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.74794602394104, "episode_reward": 161.95580285678506, "step": 33000}
{"episode": 34.0, "batch_reward": 0.10898697971552611, "actor_loss": -29.81203059387207, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.08210825920105, "episode_reward": 156.28109145445833, "step": 34000}
{"episode": 35.0, "batch_reward": 0.11029140505939722, "actor_loss": -29.788407154083252, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.28494668006897, "episode_reward": 153.55929394879215, "step": 35000}
{"episode": 36.0, "batch_reward": 0.11075482534617186, "actor_loss": -29.84846128845215, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.78121519088745, "episode_reward": 140.1586926510637, "step": 36000}
{"episode": 37.0, "batch_reward": 0.11222504318505526, "actor_loss": -29.926503383636476, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.634811639785767, "episode_reward": 179.08166613503388, "step": 37000}
{"episode": 38.0, "batch_reward": 0.11410005114972592, "actor_loss": -30.03709011077881, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.744526386260986, "episode_reward": 122.30165181669192, "step": 38000}
{"episode": 39.0, "batch_reward": 0.11359516863524914, "actor_loss": -30.009655849456788, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.440473318099976, "episode_reward": 129.50239909616442, "step": 39000}
{"episode": 40.0, "batch_reward": 0.11418722485005856, "actor_loss": -30.080821334838866, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.48434567451477, "episode_reward": 123.66455004425102, "step": 40000}
{"episode": 41.0, "batch_reward": 0.11477904607355595, "actor_loss": -30.085034450531005, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 39.32855439186096, "episode_reward": 127.37838905445835, "step": 41000}
{"episode": 42.0, "batch_reward": 0.11498999997973441, "actor_loss": -30.1515216255188, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.853338718414307, "episode_reward": 160.59614625234306, "step": 42000}
{"episode": 43.0, "batch_reward": 0.1161761112883687, "actor_loss": -30.149122100830077, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.953859567642212, "episode_reward": 120.04454194066749, "step": 43000}
{"episode": 44.0, "batch_reward": 0.11634242440760136, "actor_loss": -29.987191955566406, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.591440677642822, "episode_reward": 152.79521177034945, "step": 44000}
{"episode": 45.0, "batch_reward": 0.1170432062074542, "actor_loss": -30.062840091705322, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 24.78458881378174, "episode_reward": 154.7391652788535, "step": 45000}
{"episode": 46.0, "batch_reward": 0.11780942448228597, "actor_loss": -30.06648850250244, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.055798292160034, "episode_reward": 143.74507667382113, "step": 46000}
{"episode": 47.0, "batch_reward": 0.11842981170117856, "actor_loss": -30.162151405334473, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.86034870147705, "episode_reward": 189.7969299257072, "step": 47000}
{"episode": 48.0, "batch_reward": 0.12038211684674024, "actor_loss": -30.272771114349364, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.816309213638306, "episode_reward": 151.39457534610614, "step": 48000}
{"episode": 49.0, "batch_reward": 0.12101966283470392, "actor_loss": -30.23669448852539, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.798870086669922, "episode_reward": 175.11447159280473, "step": 49000}
{"episode": 50.0, "batch_reward": 0.12105622565746307, "actor_loss": -30.267090217590333, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.707399129867554, "episode_reward": 109.19110309853109, "step": 50000}
{"episode": 51.0, "batch_reward": 0.12065757686644793, "actor_loss": -30.214564643859863, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 40.96506929397583, "episode_reward": 54.34305342862269, "step": 51000}
{"episode": 52.0, "batch_reward": 0.12060086759924889, "actor_loss": -30.01108921432495, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.130675792694092, "episode_reward": 160.5763891571647, "step": 52000}
{"episode": 53.0, "batch_reward": 0.12151266085356474, "actor_loss": -30.04269039154053, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.056060791015625, "episode_reward": 165.29187283895618, "step": 53000}
{"episode": 54.0, "batch_reward": 0.1217785657942295, "actor_loss": -30.117896522521974, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.80460524559021, "episode_reward": 114.50102595169545, "step": 54000}
{"episode": 55.0, "batch_reward": 0.12028985129296779, "actor_loss": -29.87008766937256, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.590085983276367, "episode_reward": 48.29895856898057, "step": 55000}
{"episode": 56.0, "batch_reward": 0.11998032063990831, "actor_loss": -29.71387128829956, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.421162605285645, "episode_reward": 170.01417293851782, "step": 56000}
{"episode": 57.0, "batch_reward": 0.12088378110527992, "actor_loss": -29.720584129333496, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.56164026260376, "episode_reward": 129.22101369543216, "step": 57000}
{"episode": 58.0, "batch_reward": 0.12098409690707922, "actor_loss": -29.665880390167235, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.84881019592285, "episode_reward": 164.78667475386834, "step": 58000}
{"episode": 59.0, "batch_reward": 0.12181457065790892, "actor_loss": -29.657229404449463, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.7145037651062, "episode_reward": 48.97640877847808, "step": 59000}
{"episode": 60.0, "batch_reward": 0.12070634116977454, "actor_loss": -29.418922199249266, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.86018991470337, "episode_reward": 108.6010833195684, "step": 60000}
{"episode": 61.0, "batch_reward": 0.1212037101984024, "actor_loss": -29.449218227386474, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 41.246201038360596, "episode_reward": 218.52251383103018, "step": 61000}
{"episode": 62.0, "batch_reward": 0.12373738870769739, "actor_loss": -29.53507524108887, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.16416645050049, "episode_reward": 215.6498428476115, "step": 62000}
{"episode": 63.0, "batch_reward": 0.1240620194002986, "actor_loss": -29.655323890686034, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.5784649848938, "episode_reward": 137.70393315194912, "step": 63000}
{"episode": 64.0, "batch_reward": 0.12436923541873693, "actor_loss": -29.643387210845948, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.689569234848022, "episode_reward": 141.88808658993597, "step": 64000}
{"episode": 65.0, "batch_reward": 0.12456573770940303, "actor_loss": -29.70283491897583, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.71839141845703, "episode_reward": 160.53872533995676, "step": 65000}
{"episode": 66.0, "batch_reward": 0.12536443077027798, "actor_loss": -29.71702555465698, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.7169189453125, "episode_reward": 231.40929626541686, "step": 66000}
{"episode": 67.0, "batch_reward": 0.12617635148763656, "actor_loss": -29.742630504608154, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.167925119400024, "episode_reward": 151.37410656563875, "step": 67000}
{"episode": 68.0, "batch_reward": 0.1277045090124011, "actor_loss": -29.855829856872557, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.966627597808838, "episode_reward": 212.69842979621055, "step": 68000}
{"episode": 69.0, "batch_reward": 0.12823544187098743, "actor_loss": -29.832082664489747, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.78146195411682, "episode_reward": 136.73547353307333, "step": 69000}
{"episode": 70.0, "batch_reward": 0.12856308948993683, "actor_loss": -29.80460860824585, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.71059775352478, "episode_reward": 222.0979903442177, "step": 70000}
{"episode": 71.0, "batch_reward": 0.1295096723139286, "actor_loss": -29.81407183456421, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 40.90064787864685, "episode_reward": 157.79947739308068, "step": 71000}
{"episode": 72.0, "batch_reward": 0.13050831499695778, "actor_loss": -29.923778541564943, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.48566722869873, "episode_reward": 153.58832768726538, "step": 72000}
{"episode": 73.0, "batch_reward": 0.13071376185119152, "actor_loss": -29.95998397064209, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.73571801185608, "episode_reward": 178.67535270786297, "step": 73000}
{"episode": 74.0, "batch_reward": 0.13111310556530953, "actor_loss": -30.046762542724608, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.650482416152954, "episode_reward": 178.93973436523942, "step": 74000}
{"episode": 75.0, "batch_reward": 0.13132926903665065, "actor_loss": -30.029592586517335, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.380584955215454, "episode_reward": 150.69704142703665, "step": 75000}
{"episode": 76.0, "batch_reward": 0.13222510731220247, "actor_loss": -30.116551723480224, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.90584659576416, "episode_reward": 276.2015617024449, "step": 76000}
{"episode": 77.0, "batch_reward": 0.133814157217741, "actor_loss": -30.142080276489256, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.87828302383423, "episode_reward": 226.72220913016446, "step": 77000}
{"episode": 78.0, "batch_reward": 0.13520649898797274, "actor_loss": -30.28556447982788, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 25.616520643234253, "episode_reward": 156.0775019597057, "step": 78000}
{"episode": 79.0, "batch_reward": 0.1353788734897971, "actor_loss": -30.293791690826417, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.00135111808777, "episode_reward": 151.20834280205045, "step": 79000}
{"episode": 80.0, "batch_reward": 0.13544786282628773, "actor_loss": -30.37292013168335, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.706911325454712, "episode_reward": 165.22355199228332, "step": 80000}
{"episode": 81.0, "batch_reward": 0.13566591001302003, "actor_loss": -30.35099353790283, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 41.81489658355713, "episode_reward": 149.41284667343876, "step": 81000}
{"episode": 82.0, "batch_reward": 0.13609416577965022, "actor_loss": -30.40835572052002, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.94244146347046, "episode_reward": 183.08089013366694, "step": 82000}
{"episode": 83.0, "batch_reward": 0.13588272701203824, "actor_loss": -30.39310004043579, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.57494568824768, "episode_reward": 142.28258148278218, "step": 83000}
{"episode": 84.0, "batch_reward": 0.1358235351368785, "actor_loss": -30.37216815185547, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.919799327850342, "episode_reward": 60.974992987326694, "step": 84000}
{"episode": 85.0, "batch_reward": 0.1357700717970729, "actor_loss": -30.32360068130493, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.381919384002686, "episode_reward": 195.5251872468004, "step": 85000}
{"episode": 86.0, "batch_reward": 0.1365047485306859, "actor_loss": -30.345379726409913, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.87343955039978, "episode_reward": 134.29891405997128, "step": 86000}
{"episode": 87.0, "batch_reward": 0.1362205960378051, "actor_loss": -30.27351222229004, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.675023078918457, "episode_reward": 195.76034258925253, "step": 87000}
{"episode": 88.0, "batch_reward": 0.13704453599452973, "actor_loss": -30.31524266433716, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.947020053863525, "episode_reward": 160.87402484435455, "step": 88000}
{"episode": 89.0, "batch_reward": 0.13784640984237195, "actor_loss": -30.395488018035888, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.76986002922058, "episode_reward": 166.5637181278865, "step": 89000}
{"episode": 90.0, "batch_reward": 0.13840767670422793, "actor_loss": -30.411986080169676, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.850537300109863, "episode_reward": 197.39159341226178, "step": 90000}
{"episode": 91.0, "batch_reward": 0.13858706998080014, "actor_loss": -30.442887020111083, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 41.73603916168213, "episode_reward": 229.25747481039076, "step": 91000}
{"episode": 92.0, "batch_reward": 0.13947431617230177, "actor_loss": -30.503768180847167, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.943793773651123, "episode_reward": 128.86365073622548, "step": 92000}
{"episode": 93.0, "batch_reward": 0.13895610058307648, "actor_loss": -30.475090606689452, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.280966758728027, "episode_reward": 70.37372136935716, "step": 93000}
{"episode": 94.0, "batch_reward": 0.1378686170130968, "actor_loss": -30.345411357879637, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.13186502456665, "episode_reward": 139.93652391804514, "step": 94000}
{"episode": 95.0, "batch_reward": 0.13854969821125268, "actor_loss": -30.36616170501709, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.787824869155884, "episode_reward": 95.02035278991185, "step": 95000}
{"episode": 96.0, "batch_reward": 0.13795800294727087, "actor_loss": -30.24492903137207, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.71961784362793, "episode_reward": 132.8951387942005, "step": 96000}
{"episode": 97.0, "batch_reward": 0.138619114510715, "actor_loss": -30.26605381774902, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.917197227478027, "episode_reward": 182.50539949836886, "step": 97000}
{"episode": 98.0, "batch_reward": 0.1385016710907221, "actor_loss": -30.311170539855958, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.74021816253662, "episode_reward": 187.65686213334777, "step": 98000}
{"episode": 99.0, "batch_reward": 0.1389554380774498, "actor_loss": -30.314362243652344, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.176514148712158, "episode_reward": 165.650783652758, "step": 99000}
{"episode": 100.0, "batch_reward": 0.1386267456486821, "actor_loss": -30.28349736404419, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.77241611480713, "episode_reward": 101.13281211614877, "step": 100000}
{"episode": 101.0, "batch_reward": 0.13885934705287217, "actor_loss": -30.212309940338134, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 41.06950402259827, "episode_reward": 175.66459196747613, "step": 101000}
{"episode": 102.0, "batch_reward": 0.1390456041544676, "actor_loss": -30.25238209915161, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.56059718132019, "episode_reward": 161.9215294535813, "step": 102000}
{"episode": 103.0, "batch_reward": 0.13997425047308207, "actor_loss": -30.290690780639647, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.420525312423706, "episode_reward": 187.71527718840625, "step": 103000}
{"episode": 104.0, "batch_reward": 0.14025455278903246, "actor_loss": -30.312630226135255, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.342732906341553, "episode_reward": 100.06186733482174, "step": 104000}
{"episode": 105.0, "batch_reward": 0.1401035137847066, "actor_loss": -30.239205226898193, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.36455726623535, "episode_reward": 241.9479874039056, "step": 105000}
{"episode": 106.0, "batch_reward": 0.14035828924179078, "actor_loss": -30.276600387573243, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.196667194366455, "episode_reward": 206.69907428863198, "step": 106000}
{"episode": 107.0, "batch_reward": 0.14089685485512018, "actor_loss": -30.29934820175171, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.80613398551941, "episode_reward": 123.24670631236043, "step": 107000}
{"episode": 108.0, "batch_reward": 0.1402274957001209, "actor_loss": -30.132192893981934, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.870482444763184, "episode_reward": 23.999370854735133, "step": 108000}
{"episode": 109.0, "batch_reward": 0.1406195166632533, "actor_loss": -30.0559190826416, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.981210470199585, "episode_reward": 233.54102727226285, "step": 109000}
{"episode": 110.0, "batch_reward": 0.14150582395493985, "actor_loss": -30.1402811126709, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.89696455001831, "episode_reward": 226.13712542127925, "step": 110000}
{"episode": 111.0, "batch_reward": 0.1414263358786702, "actor_loss": -30.081980606079103, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 41.76456832885742, "episode_reward": 91.30717969943053, "step": 111000}
{"episode": 112.0, "batch_reward": 0.14098200085759163, "actor_loss": -30.004903652191164, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.828675270080566, "episode_reward": 173.74697824440722, "step": 112000}
{"episode": 113.0, "batch_reward": 0.1408850574567914, "actor_loss": -29.959824802398682, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.727535247802734, "episode_reward": 28.62580925376191, "step": 113000}
{"episode": 114.0, "batch_reward": 0.14075949808210134, "actor_loss": -29.94870283126831, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.392546892166138, "episode_reward": 138.4616062242448, "step": 114000}
{"episode": 115.0, "batch_reward": 0.14012587924301625, "actor_loss": -29.833698162078857, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.119508028030396, "episode_reward": 65.4022051280901, "step": 115000}
{"episode": 116.0, "batch_reward": 0.13967718799412251, "actor_loss": -29.76245027542114, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.16062355041504, "episode_reward": 222.8490287314334, "step": 116000}
{"episode": 117.0, "batch_reward": 0.13976034234464169, "actor_loss": -29.705962478637694, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.461677312850952, "episode_reward": 63.46831261844225, "step": 117000}
{"episode": 118.0, "batch_reward": 0.13985725849866867, "actor_loss": -29.593124797821044, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.79019856452942, "episode_reward": 25.822284248323133, "step": 118000}
{"episode": 119.0, "batch_reward": 0.13838342152535915, "actor_loss": -29.483688175201415, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.79980444908142, "episode_reward": 128.11433275353107, "step": 119000}
{"episode": 120.0, "batch_reward": 0.13896826207637786, "actor_loss": -29.416323974609377, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.666566133499146, "episode_reward": 51.82432394784016, "step": 120000}
{"episode": 121.0, "batch_reward": 0.13776987827569245, "actor_loss": -29.27295325088501, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 41.63941955566406, "episode_reward": 49.26944070720213, "step": 121000}
{"episode": 122.0, "batch_reward": 0.13651941753178834, "actor_loss": -29.043148197174073, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.9176607131958, "episode_reward": 32.377266694284195, "step": 122000}
{"episode": 123.0, "batch_reward": 0.13636564181745053, "actor_loss": -29.04126131439209, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.77872943878174, "episode_reward": 114.82027551275601, "step": 123000}
{"episode": 124.0, "batch_reward": 0.13576985505968334, "actor_loss": -28.947340606689455, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.58689570426941, "episode_reward": 28.197456211290536, "step": 124000}
{"episode": 125.0, "batch_reward": 0.13514860254526137, "actor_loss": -28.857777015686036, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.232197761535645, "episode_reward": 79.99668456060587, "step": 125000}
{"episode": 126.0, "batch_reward": 0.1351631621643901, "actor_loss": -28.82083226394653, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.20255470275879, "episode_reward": 190.7067342221579, "step": 126000}
{"episode": 127.0, "batch_reward": 0.13585941694676876, "actor_loss": -28.780257179260254, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.27377223968506, "episode_reward": 29.818054779051298, "step": 127000}
{"episode": 128.0, "batch_reward": 0.134327020175755, "actor_loss": -28.586762046813966, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.626017808914185, "episode_reward": 139.06170278658607, "step": 128000}
{"episode": 129.0, "batch_reward": 0.1346289586350322, "actor_loss": -28.6363988571167, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.674187660217285, "episode_reward": 30.7897487809539, "step": 129000}
{"episode": 130.0, "batch_reward": 0.1334182683378458, "actor_loss": -28.439098369598387, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.968525886535645, "episode_reward": 69.764270311271, "step": 130000}
{"episode": 131.0, "batch_reward": 0.13316775949299337, "actor_loss": -28.425035373687745, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 41.182997703552246, "episode_reward": 32.71914637946688, "step": 131000}
{"episode": 132.0, "batch_reward": 0.1323873440474272, "actor_loss": -28.342781803131103, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.763391256332397, "episode_reward": 143.1456225480691, "step": 132000}
{"episode": 133.0, "batch_reward": 0.13235424515604974, "actor_loss": -28.29374357223511, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.517786264419556, "episode_reward": 186.5200703509288, "step": 133000}
{"episode": 134.0, "batch_reward": 0.13248754423111678, "actor_loss": -28.26519717025757, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.97983956336975, "episode_reward": 34.48519507072017, "step": 134000}
{"episode": 135.0, "batch_reward": 0.13271969512850046, "actor_loss": -28.187445880889893, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.535224676132202, "episode_reward": 270.36901938364093, "step": 135000}
{"episode": 136.0, "batch_reward": 0.13318106646835803, "actor_loss": -28.273970672607422, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.184614658355713, "episode_reward": 146.48876929850513, "step": 136000}
{"episode": 137.0, "batch_reward": 0.13420716162770988, "actor_loss": -28.363027923583985, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.53258967399597, "episode_reward": 234.62686012574414, "step": 137000}
{"episode": 138.0, "batch_reward": 0.13390296740829943, "actor_loss": -28.29302303314209, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.438101291656494, "episode_reward": 34.0327819063202, "step": 138000}
{"episode": 139.0, "batch_reward": 0.13344378313422203, "actor_loss": -28.230651016235353, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.995002508163452, "episode_reward": 74.6430439989602, "step": 139000}
{"episode": 140.0, "batch_reward": 0.13318569929152727, "actor_loss": -28.103259441375734, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.959364891052246, "episode_reward": 244.98743316152843, "step": 140000}
{"episode": 141.0, "batch_reward": 0.13344233142584563, "actor_loss": -28.09831566619873, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 41.814090728759766, "episode_reward": 179.2391389902763, "step": 141000}
{"episode": 142.0, "batch_reward": 0.13391251485794783, "actor_loss": -28.193149181365968, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.588358163833618, "episode_reward": 130.38460407069726, "step": 142000}
{"episode": 143.0, "batch_reward": 0.13406804340332745, "actor_loss": -28.15610966873169, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.948559522628784, "episode_reward": 190.24872433563974, "step": 143000}
{"episode": 144.0, "batch_reward": 0.13409650225192307, "actor_loss": -28.18130940628052, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.819267511367798, "episode_reward": 32.433336775336585, "step": 144000}
{"episode": 145.0, "batch_reward": 0.1329917858466506, "actor_loss": -28.20509150695801, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.19959592819214, "episode_reward": 156.82149630125713, "step": 145000}
{"episode": 146.0, "batch_reward": 0.13376587836444379, "actor_loss": -28.1633470993042, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.948986530303955, "episode_reward": 176.45947189829607, "step": 146000}
{"episode": 147.0, "batch_reward": 0.13393388801813125, "actor_loss": -28.172833660125733, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 21.09704566001892, "episode_reward": 36.193934466555305, "step": 147000}
{"episode": 148.0, "batch_reward": 0.1335935941338539, "actor_loss": -28.071307445526124, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.663631439208984, "episode_reward": 190.22552305668714, "step": 148000}
{"episode": 149.0, "batch_reward": 0.13415894577652215, "actor_loss": -28.044192779541017, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 22.08410930633545, "episode_reward": 175.9446169212583, "step": 149000}
{"episode": 150.0, "batch_reward": 0.13422879353165626, "actor_loss": -28.13190068817139, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "step": 150000}
