{"episode_reward": 0.0, "episode": 1.0, "duration": 14.11381983757019, "step": 1000}
{"episode_reward": 7.051849146674556, "episode": 2.0, "duration": 1.2449140548706055, "step": 2000}
{"episode_reward": 365.4711839680396, "episode": 3.0, "batch_reward": 0.17578588739887163, "critic_loss": 0.0548077074338214, "actor_loss": -29.03053954672985, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 74.68226671218872, "step": 3000}
{"episode_reward": 17.356096553271566, "episode": 4.0, "batch_reward": 0.11740362547338008, "critic_loss": 0.050065074698999526, "actor_loss": -24.097994631290437, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.502589464187622, "step": 4000}
{"episode_reward": 44.501203346777494, "episode": 5.0, "batch_reward": 0.09847055665403605, "critic_loss": 0.05679942178539932, "actor_loss": -23.249722868919374, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.684632539749146, "step": 5000}
{"episode_reward": 19.794104080433932, "episode": 6.0, "batch_reward": 0.0850797253958881, "critic_loss": 0.06214912191405892, "actor_loss": -20.978434494018554, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.51126217842102, "step": 6000}
{"episode_reward": 33.10518071812452, "episode": 7.0, "batch_reward": 0.07857015881687403, "critic_loss": 0.05135475530661643, "actor_loss": -21.297080607891083, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.32413411140442, "step": 7000}
{"episode_reward": 77.62492717828673, "episode": 8.0, "batch_reward": 0.07791922776773572, "critic_loss": 0.06188206462748349, "actor_loss": -20.373932833194733, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.031235694885254, "step": 8000}
{"episode_reward": 38.93637950746412, "episode": 9.0, "batch_reward": 0.07591955639049411, "critic_loss": 0.069947863843292, "actor_loss": -19.73421844816208, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.460417985916138, "step": 9000}
{"episode_reward": 79.56891528857834, "episode": 10.0, "batch_reward": 0.07946013149619102, "critic_loss": 0.07788506704941392, "actor_loss": -19.7634951941967, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.623071432113647, "step": 10000}
{"episode_reward": 134.3189251835837, "episode": 11.0, "batch_reward": 0.08504565023630857, "critic_loss": 0.09075704648345709, "actor_loss": -18.230119507074356, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.40100860595703, "step": 11000}
{"episode_reward": 153.7535242716609, "episode": 12.0, "batch_reward": 0.09036270878463984, "critic_loss": 0.09354333216324448, "actor_loss": -18.54212263804674, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.850041151046753, "step": 12000}
{"episode_reward": 155.5295746445324, "episode": 13.0, "batch_reward": 0.09321247059851885, "critic_loss": 0.10468259540200234, "actor_loss": -19.21708873307705, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.379366636276245, "step": 13000}
{"episode_reward": 50.87314613446146, "episode": 14.0, "batch_reward": 0.09067407525330783, "critic_loss": 0.11867544122412801, "actor_loss": -17.01620940157026, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.829569101333618, "step": 14000}
{"episode_reward": 58.47375550379322, "episode": 15.0, "batch_reward": 0.08733533819019794, "critic_loss": 0.10967509485781193, "actor_loss": -16.23269500040263, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.590989351272583, "step": 15000}
{"episode_reward": 39.274145770587175, "episode": 16.0, "batch_reward": 0.08470684196054935, "critic_loss": 0.10830941186472774, "actor_loss": -16.200653443396092, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.45017433166504, "step": 16000}
{"episode_reward": 47.252383441438425, "episode": 17.0, "batch_reward": 0.08539284654706716, "critic_loss": 0.11904788334667683, "actor_loss": -15.363438537195325, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.726846933364868, "step": 17000}
{"episode_reward": 165.0812498070239, "episode": 18.0, "batch_reward": 0.09073546563088894, "critic_loss": 0.11610631557554006, "actor_loss": -15.75305809648335, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.902924299240112, "step": 18000}
{"episode_reward": 187.25829672991284, "episode": 19.0, "batch_reward": 0.09354400207847356, "critic_loss": 0.12893702743202448, "actor_loss": -15.294454198144376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.98640203475952, "step": 19000}
{"episode_reward": 66.71987407982903, "episode": 20.0, "batch_reward": 0.09601652488857508, "critic_loss": 0.13507222963869572, "actor_loss": -14.362710103034972, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.09474468231201, "step": 20000}
{"episode_reward": 264.404626814922, "episode": 21.0, "batch_reward": 0.10328837644308805, "critic_loss": 0.1403564655892551, "actor_loss": -16.393008147120476, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.56418538093567, "step": 21000}
{"episode_reward": 232.5724751101873, "episode": 22.0, "batch_reward": 0.108309439599514, "critic_loss": 0.14363300773501397, "actor_loss": -14.493507545351981, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.869105577468872, "step": 22000}
{"episode_reward": 149.00085376018743, "episode": 23.0, "batch_reward": 0.1091966403722763, "critic_loss": 0.15373914424329996, "actor_loss": -15.095435900211335, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.403542518615723, "step": 23000}
{"episode_reward": 86.8044490357627, "episode": 24.0, "batch_reward": 0.1101807726174593, "critic_loss": 0.16350103770941496, "actor_loss": -15.1097227165699, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.746163606643677, "step": 24000}
{"episode_reward": 245.6839205324067, "episode": 25.0, "batch_reward": 0.11351450519263745, "critic_loss": 0.1717352721095085, "actor_loss": -14.79342817234993, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.381619453430176, "step": 25000}
{"episode_reward": 86.93628522245366, "episode": 26.0, "batch_reward": 0.11388541781157255, "critic_loss": 0.16234149030596018, "actor_loss": -14.851141174554824, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.299217224121094, "step": 26000}
{"episode_reward": 149.74039383833008, "episode": 27.0, "batch_reward": 0.11560742641240358, "critic_loss": 0.18303698904812335, "actor_loss": -15.032606286048889, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.596434354782104, "step": 27000}
{"episode_reward": 158.5130937723069, "episode": 28.0, "batch_reward": 0.11679089312255382, "critic_loss": 0.1753054089099169, "actor_loss": -14.555482383728027, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.695402145385742, "step": 28000}
{"episode_reward": 98.31193500928418, "episode": 29.0, "batch_reward": 0.11504330405592919, "critic_loss": 0.1864680681526661, "actor_loss": -14.383622685432433, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.474374055862427, "step": 29000}
{"episode_reward": 105.27631393769992, "episode": 30.0, "batch_reward": 0.11617229868471622, "critic_loss": 0.204555382296443, "actor_loss": -14.950017487049102, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.427711486816406, "step": 30000}
{"episode_reward": 131.43694920698198, "episode": 31.0, "batch_reward": 0.11715104246139527, "critic_loss": 0.2343901281580329, "actor_loss": -14.538104291915893, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.97753405570984, "step": 31000}
{"episode_reward": 288.34227706666604, "episode": 32.0, "batch_reward": 0.12048642279952765, "critic_loss": 0.2912162200883031, "actor_loss": -14.219698093414307, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.71541452407837, "step": 32000}
{"episode_reward": 69.01928699227483, "episode": 33.0, "batch_reward": 0.12002433911710977, "critic_loss": 0.28983196391165256, "actor_loss": -14.483875086784362, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.785813331604004, "step": 33000}
{"episode_reward": 163.1564578404097, "episode": 34.0, "batch_reward": 0.11956898407638072, "critic_loss": 0.3020434525385499, "actor_loss": -14.618416618347167, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.591607093811035, "step": 34000}
{"episode_reward": 38.72398188820536, "episode": 35.0, "batch_reward": 0.119791338942945, "critic_loss": 0.25180810667574405, "actor_loss": -14.35962495613098, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.742270708084106, "step": 35000}
{"episode_reward": 194.12363440993656, "episode": 36.0, "batch_reward": 0.12221613286435604, "critic_loss": 0.25897778641432523, "actor_loss": -14.051306747436524, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.90329623222351, "step": 36000}
{"episode_reward": 245.90627799896768, "episode": 37.0, "batch_reward": 0.1258424173295498, "critic_loss": 0.2841728312000632, "actor_loss": -15.085750586509704, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.485016345977783, "step": 37000}
{"episode_reward": 305.17809626377675, "episode": 38.0, "batch_reward": 0.12941641891002656, "critic_loss": 0.28220688363164664, "actor_loss": -15.548948893547058, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.733269453048706, "step": 38000}
{"episode_reward": 142.10943267063283, "episode": 39.0, "batch_reward": 0.13128667353838683, "critic_loss": 0.2669285756722093, "actor_loss": -15.253762533187865, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.877519130706787, "step": 39000}
{"episode_reward": 257.6753173815011, "episode": 40.0, "batch_reward": 0.13508084885030985, "critic_loss": 0.25426701447367667, "actor_loss": -15.40709913444519, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.754762411117554, "step": 40000}
{"episode_reward": 281.0226680986499, "episode": 41.0, "batch_reward": 0.13669925815612077, "critic_loss": 0.23864060676842927, "actor_loss": -16.01437230491638, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.52654790878296, "step": 41000}
{"episode_reward": 151.8056803070097, "episode": 42.0, "batch_reward": 0.13719945676624776, "critic_loss": 0.24425122670829297, "actor_loss": -15.758628176689149, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.681138038635254, "step": 42000}
{"episode_reward": 131.01817578365063, "episode": 43.0, "batch_reward": 0.13782840019464493, "critic_loss": 0.24526476131379604, "actor_loss": -15.657690145492554, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.649722814559937, "step": 43000}
{"episode_reward": 180.94424088823368, "episode": 44.0, "batch_reward": 0.13776639986783265, "critic_loss": 0.26533033484220503, "actor_loss": -14.652571157455444, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.989668369293213, "step": 44000}
{"episode_reward": 147.15149378286551, "episode": 45.0, "batch_reward": 0.13850466837733985, "critic_loss": 0.2767989769652486, "actor_loss": -15.273492332458495, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.344874620437622, "step": 45000}
{"episode_reward": 159.09845526151938, "episode": 46.0, "batch_reward": 0.1399862267151475, "critic_loss": 0.2772483284026384, "actor_loss": -16.330941928863524, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.027890920639038, "step": 46000}
{"episode_reward": 359.9060990212858, "episode": 47.0, "batch_reward": 0.14530400107800961, "critic_loss": 0.2897551905959845, "actor_loss": -16.26250630569458, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.957491397857666, "step": 47000}
{"episode_reward": 386.0526049256419, "episode": 48.0, "batch_reward": 0.15107127756625413, "critic_loss": 0.28032274624705317, "actor_loss": -17.079039253234864, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.123844861984253, "step": 48000}
{"episode_reward": 427.8008102203936, "episode": 49.0, "batch_reward": 0.15283458828926086, "critic_loss": 0.268163416557014, "actor_loss": -16.794081119537353, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.06758737564087, "step": 49000}
{"episode_reward": 82.39380781188245, "episode": 50.0, "batch_reward": 0.15230264997482298, "critic_loss": 0.26563463008403776, "actor_loss": -17.006088348388673, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.623849630355835, "step": 50000}
{"episode_reward": 147.1158404028628, "episode": 51.0, "batch_reward": 0.15255252624303103, "critic_loss": 0.2559053265154362, "actor_loss": -17.048481351852416, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.20333671569824, "step": 51000}
{"episode_reward": 161.54812956569825, "episode": 52.0, "batch_reward": 0.1539591069370508, "critic_loss": 0.24381595627218486, "actor_loss": -17.551269344329835, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.697162628173828, "step": 52000}
{"episode_reward": 263.3958047072533, "episode": 53.0, "batch_reward": 0.15658627363294364, "critic_loss": 0.2770005875378847, "actor_loss": -17.52899678039551, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.39151930809021, "step": 53000}
{"episode_reward": 413.95364935699456, "episode": 54.0, "batch_reward": 0.16217846497893335, "critic_loss": 0.25169111911207437, "actor_loss": -18.03330174446106, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.847042560577393, "step": 54000}
{"episode_reward": 459.37570425390356, "episode": 55.0, "batch_reward": 0.16587219439446926, "critic_loss": 0.23997547663748264, "actor_loss": -18.597796432495116, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.729419231414795, "step": 55000}
{"episode_reward": 130.63630792447756, "episode": 56.0, "batch_reward": 0.16485272724181413, "critic_loss": 0.2364445151537657, "actor_loss": -18.60610063743591, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.172365427017212, "step": 56000}
{"episode_reward": 177.23954863682604, "episode": 57.0, "batch_reward": 0.16764375510811805, "critic_loss": 0.26342428917437793, "actor_loss": -18.96576649093628, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.731032133102417, "step": 57000}
{"episode_reward": 416.8426526477264, "episode": 58.0, "batch_reward": 0.1707856664210558, "critic_loss": 0.2995206345692277, "actor_loss": -19.335786750793456, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.250794649124146, "step": 58000}
{"episode_reward": 413.4825386421409, "episode": 59.0, "batch_reward": 0.17576548723876476, "critic_loss": 0.2781897658184171, "actor_loss": -19.885178527832032, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.050578117370605, "step": 59000}
{"episode_reward": 455.01198147528976, "episode": 60.0, "batch_reward": 0.17992973615974187, "critic_loss": 0.3031404908299446, "actor_loss": -20.34945090293884, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.57011389732361, "step": 60000}
{"episode_reward": 433.7419625741113, "episode": 61.0, "batch_reward": 0.18459469963610173, "critic_loss": 0.31170296666771174, "actor_loss": -20.99107473564148, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.78619623184204, "step": 61000}
{"episode_reward": 498.5881924605745, "episode": 62.0, "batch_reward": 0.1905998689979315, "critic_loss": 0.2762651981115341, "actor_loss": -21.509843090057373, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.786674737930298, "step": 62000}
{"episode_reward": 489.1641135858422, "episode": 63.0, "batch_reward": 0.19437309555709362, "critic_loss": 0.26720038752257824, "actor_loss": -21.98529401397705, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.18017268180847, "step": 63000}
{"episode_reward": 426.7666366935092, "episode": 64.0, "batch_reward": 0.19785282279551028, "critic_loss": 0.27257817213982344, "actor_loss": -22.293597999572754, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.045887231826782, "step": 64000}
{"episode_reward": 457.56409237280457, "episode": 65.0, "batch_reward": 0.20185283064842224, "critic_loss": 0.2729875231534243, "actor_loss": -22.875372005462648, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.70622968673706, "step": 65000}
{"episode_reward": 317.14292896470766, "episode": 66.0, "batch_reward": 0.2044333201944828, "critic_loss": 0.2636430100053549, "actor_loss": -23.322958248138427, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.790375471115112, "step": 66000}
{"episode_reward": 405.6121844593802, "episode": 67.0, "batch_reward": 0.2058847698420286, "critic_loss": 0.28718136352300644, "actor_loss": -23.42209448623657, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.668193817138672, "step": 67000}
{"episode_reward": 183.42461645190988, "episode": 68.0, "batch_reward": 0.20672502380609512, "critic_loss": 0.26833136554807424, "actor_loss": -23.411239292144774, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.279372692108154, "step": 68000}
{"episode_reward": 416.03074527744553, "episode": 69.0, "batch_reward": 0.2057737112492323, "critic_loss": 0.2936171276271343, "actor_loss": -23.849269454956055, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.961196899414062, "step": 69000}
{"episode_reward": 82.13518635799699, "episode": 70.0, "batch_reward": 0.20728919407725335, "critic_loss": 0.30386911588162185, "actor_loss": -23.968321269989012, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.711126565933228, "step": 70000}
{"episode_reward": 416.89282546372164, "episode": 71.0, "batch_reward": 0.20904102897644042, "critic_loss": 0.3465004760697484, "actor_loss": -24.1932149848938, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.211410999298096, "step": 71000}
{"episode_reward": 137.1114449284232, "episode": 72.0, "batch_reward": 0.20976633127033711, "critic_loss": 0.3437701456099749, "actor_loss": -24.241502151489257, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.644591331481934, "step": 72000}
{"episode_reward": 468.5978723927434, "episode": 73.0, "batch_reward": 0.21392187882959843, "critic_loss": 0.33774867791682484, "actor_loss": -24.657840450286866, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.923339128494263, "step": 73000}
{"episode_reward": 440.12845913372, "episode": 74.0, "batch_reward": 0.21559125854074954, "critic_loss": 0.34239315404742954, "actor_loss": -25.058513389587404, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.221038579940796, "step": 74000}
{"episode_reward": 519.9138703267416, "episode": 75.0, "batch_reward": 0.22012730427086352, "critic_loss": 0.3399367467015982, "actor_loss": -25.58938503265381, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.821313858032227, "step": 75000}
{"episode_reward": 444.75533849310835, "episode": 76.0, "batch_reward": 0.22298275224864483, "critic_loss": 0.3199933218434453, "actor_loss": -25.71810468673706, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.30000352859497, "step": 76000}
{"episode_reward": 466.800928802288, "episode": 77.0, "batch_reward": 0.22658138465881347, "critic_loss": 0.31254544661939143, "actor_loss": -26.23474782562256, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.812161445617676, "step": 77000}
{"episode_reward": 538.1030080101312, "episode": 78.0, "batch_reward": 0.23029889000952244, "critic_loss": 0.3140689401775599, "actor_loss": -26.50312550354004, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.17106008529663, "step": 78000}
{"episode_reward": 500.02617361402906, "episode": 79.0, "batch_reward": 0.23449776831269264, "critic_loss": 0.28761492715775966, "actor_loss": -26.73722808074951, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.948094606399536, "step": 79000}
{"episode_reward": 484.14657708034684, "episode": 80.0, "batch_reward": 0.23738234765827657, "critic_loss": 0.3111234879270196, "actor_loss": -27.191153579711916, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.848006010055542, "step": 80000}
{"episode_reward": 528.1904597632956, "episode": 81.0, "batch_reward": 0.24130303794145583, "critic_loss": 0.3052525619417429, "actor_loss": -27.76622341156006, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.919904947280884, "step": 81000}
{"episode_reward": 530.0159436395747, "episode": 82.0, "batch_reward": 0.24429542201757432, "critic_loss": 0.3026195573210716, "actor_loss": -28.022585689544677, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.99593448638916, "step": 82000}
{"episode_reward": 506.5518098762485, "episode": 83.0, "batch_reward": 0.24834556950628758, "critic_loss": 0.36429153817892074, "actor_loss": -28.761801498413085, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.113085985183716, "step": 83000}
{"episode_reward": 543.330392151039, "episode": 84.0, "batch_reward": 0.25182655642926693, "critic_loss": 0.3169797861501574, "actor_loss": -29.27786404800415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.60944414138794, "step": 84000}
{"episode_reward": 510.85522646126464, "episode": 85.0, "batch_reward": 0.25377477875351906, "critic_loss": 0.2976688596904278, "actor_loss": -29.638523559570313, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.63349199295044, "step": 85000}
{"episode_reward": 434.23809018224875, "episode": 86.0, "batch_reward": 0.2569645342379808, "critic_loss": 0.28601801571249963, "actor_loss": -30.1077573928833, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.701163053512573, "step": 86000}
{"episode_reward": 545.2621204778192, "episode": 87.0, "batch_reward": 0.25955650249123574, "critic_loss": 0.2948936430439353, "actor_loss": -30.166476135253905, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.771822929382324, "step": 87000}
{"episode_reward": 577.4898380541487, "episode": 88.0, "batch_reward": 0.26069700384140015, "critic_loss": 0.3046024635285139, "actor_loss": -30.41421997833252, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.462886571884155, "step": 88000}
{"episode_reward": 141.67888052419508, "episode": 89.0, "batch_reward": 0.261335981503129, "critic_loss": 0.3351093740612269, "actor_loss": -30.381870517730714, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.886610746383667, "step": 89000}
{"episode_reward": 312.4041685411308, "episode": 90.0, "batch_reward": 0.26371271996200085, "critic_loss": 0.3282462826371193, "actor_loss": -30.585299324035645, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.529733180999756, "step": 90000}
{"episode_reward": 484.593881025724, "episode": 91.0, "batch_reward": 0.26546739363670346, "critic_loss": 0.3462757432460785, "actor_loss": -30.662315185546873, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.87095856666565, "step": 91000}
{"episode_reward": 518.8924465606672, "episode": 92.0, "batch_reward": 0.26842870147526265, "critic_loss": 0.37499061311781406, "actor_loss": -31.01620238876343, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.8706533908844, "step": 92000}
{"episode_reward": 552.5559371426298, "episode": 93.0, "batch_reward": 0.2708558784127235, "critic_loss": 0.33166475616395474, "actor_loss": -31.331414909362792, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.670822620391846, "step": 93000}
{"episode_reward": 530.8205081937039, "episode": 94.0, "batch_reward": 0.27422709327936173, "critic_loss": 0.34132788760960103, "actor_loss": -31.606251094818116, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.602678775787354, "step": 94000}
{"episode_reward": 500.2313411240112, "episode": 95.0, "batch_reward": 0.2762683749496937, "critic_loss": 0.34083701238036157, "actor_loss": -31.700604194641112, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.338854789733887, "step": 95000}
{"episode_reward": 551.1173486762075, "episode": 96.0, "batch_reward": 0.27864730648696423, "critic_loss": 0.34766087754815816, "actor_loss": -31.917813175201417, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.99109673500061, "step": 96000}
{"episode_reward": 172.58742246171366, "episode": 97.0, "batch_reward": 0.2777156202495098, "critic_loss": 0.34708407762646676, "actor_loss": -32.06003982925415, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.970158338546753, "step": 97000}
{"episode_reward": 555.1164072024645, "episode": 98.0, "batch_reward": 0.27983817891776563, "critic_loss": 0.3991316873282194, "actor_loss": -32.170400333404544, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.590356588363647, "step": 98000}
{"episode_reward": 522.6661091685762, "episode": 99.0, "batch_reward": 0.2833718021810055, "critic_loss": 0.3570046557635069, "actor_loss": -32.76799600982666, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.595617532730103, "step": 99000}
{"episode_reward": 552.1519231588475, "episode": 100.0, "batch_reward": 0.28524735011160374, "critic_loss": 0.36872873607277873, "actor_loss": -32.74031907272339, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.86257791519165, "step": 100000}
{"episode_reward": 143.36021900765962, "episode": 101.0, "batch_reward": 0.2847617026865482, "critic_loss": 0.37565931310504674, "actor_loss": -33.06721116638184, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.87283158302307, "step": 101000}
{"episode_reward": 510.7313917266053, "episode": 102.0, "batch_reward": 0.2870582477450371, "critic_loss": 0.3546587229669094, "actor_loss": -33.03893556213379, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.24584126472473, "step": 102000}
{"episode_reward": 512.4298527577565, "episode": 103.0, "batch_reward": 0.2890556552708149, "critic_loss": 0.3985379626750946, "actor_loss": -33.31988050460816, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.45495843887329, "step": 103000}
{"episode_reward": 571.1287757645899, "episode": 104.0, "batch_reward": 0.2912989559173584, "critic_loss": 0.3782471071407199, "actor_loss": -33.41216302871704, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.720522165298462, "step": 104000}
{"episode_reward": 542.8309011997865, "episode": 105.0, "batch_reward": 0.29471517069637776, "critic_loss": 0.3766539428085089, "actor_loss": -33.86276965713501, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.92915391921997, "step": 105000}
{"episode_reward": 575.4144269249282, "episode": 106.0, "batch_reward": 0.2972054613679647, "critic_loss": 0.3625178347527981, "actor_loss": -34.09199880599976, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.37828493118286, "step": 106000}
{"episode_reward": 544.2131641148659, "episode": 107.0, "batch_reward": 0.29882766906917096, "critic_loss": 0.37964543388038874, "actor_loss": -34.39928966140747, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.023038148880005, "step": 107000}
{"episode_reward": 553.9881498941886, "episode": 108.0, "batch_reward": 0.301615939706564, "critic_loss": 0.3945026164650917, "actor_loss": -34.4763939781189, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.415424823760986, "step": 108000}
{"episode_reward": 537.0901593215933, "episode": 109.0, "batch_reward": 0.3038593217879534, "critic_loss": 0.39557946291565893, "actor_loss": -34.732824256896976, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.921476364135742, "step": 109000}
{"episode_reward": 561.5922229091661, "episode": 110.0, "batch_reward": 0.30690585377812385, "critic_loss": 0.37174887269735335, "actor_loss": -34.91856706237793, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.2110493183136, "step": 110000}
{"episode_reward": 555.5020142648511, "episode": 111.0, "batch_reward": 0.30747518163919446, "critic_loss": 0.4007415928542614, "actor_loss": -35.21837160491943, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.92476153373718, "step": 111000}
{"episode_reward": 552.9731072669124, "episode": 112.0, "batch_reward": 0.3083746822476387, "critic_loss": 0.4012311187237501, "actor_loss": -35.31516711044311, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.84853219985962, "step": 112000}
{"episode_reward": 168.0003615180183, "episode": 113.0, "batch_reward": 0.3091692657917738, "critic_loss": 0.3619573108255863, "actor_loss": -35.35220380401611, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.99627113342285, "step": 113000}
{"episode_reward": 570.5350669340664, "episode": 114.0, "batch_reward": 0.3110625626593828, "critic_loss": 0.34965425987541676, "actor_loss": -35.53059313201904, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.125450372695923, "step": 114000}
{"episode_reward": 572.3158481288784, "episode": 115.0, "batch_reward": 0.31418752506375314, "critic_loss": 0.39946001138538123, "actor_loss": -35.719350284576414, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.01065492630005, "step": 115000}
{"episode_reward": 550.165657484265, "episode": 116.0, "batch_reward": 0.3151499843001366, "critic_loss": 0.34887690092623236, "actor_loss": -35.91268093490601, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.786449670791626, "step": 116000}
{"episode_reward": 546.7284258796553, "episode": 117.0, "batch_reward": 0.31978470185399055, "critic_loss": 0.3560156918168068, "actor_loss": -36.253570781707765, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.277878761291504, "step": 117000}
{"episode_reward": 567.6959890194961, "episode": 118.0, "batch_reward": 0.3204900507032871, "critic_loss": 0.33632186843454837, "actor_loss": -36.41991245269775, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.658786296844482, "step": 118000}
{"episode_reward": 559.8262557645074, "episode": 119.0, "batch_reward": 0.3218807947933674, "critic_loss": 0.4199446608945727, "actor_loss": -36.410144695281986, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.24609899520874, "step": 119000}
{"episode_reward": 548.2276465004858, "episode": 120.0, "batch_reward": 0.32374049508571623, "critic_loss": 0.3582892033979297, "actor_loss": -36.6988288269043, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.407970666885376, "step": 120000}
{"episode_reward": 572.331976835146, "episode": 121.0, "batch_reward": 0.32548727455735205, "critic_loss": 0.36521371100842953, "actor_loss": -36.83493131256103, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.254931688308716, "step": 121000}
{"episode_reward": 584.4055633013608, "episode": 122.0, "batch_reward": 0.32861743712425234, "critic_loss": 0.34901639848947524, "actor_loss": -37.006436141967775, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.51377296447754, "step": 122000}
{"episode_reward": 532.3755932872158, "episode": 123.0, "batch_reward": 0.3300452115237713, "critic_loss": 0.3839851510375738, "actor_loss": -37.088959644317626, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.80597448348999, "step": 123000}
{"episode_reward": 555.5115856535575, "episode": 124.0, "batch_reward": 0.33136528584361075, "critic_loss": 0.4163168506398797, "actor_loss": -37.276120094299316, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.892064809799194, "step": 124000}
{"episode_reward": 555.6880688599357, "episode": 125.0, "batch_reward": 0.3325375520288944, "critic_loss": 0.3931825423836708, "actor_loss": -37.29627293395996, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.753384351730347, "step": 125000}
{"episode_reward": 577.5287672065526, "episode": 126.0, "batch_reward": 0.3355849675834179, "critic_loss": 0.39142147260904314, "actor_loss": -37.5464185218811, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.999314546585083, "step": 126000}
{"episode_reward": 563.1103337937276, "episode": 127.0, "batch_reward": 0.33743721997737885, "critic_loss": 0.3726595942080021, "actor_loss": -37.68017866516113, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.017383337020874, "step": 127000}
{"episode_reward": 583.1559027421695, "episode": 128.0, "batch_reward": 0.3391936146020889, "critic_loss": 0.4079617015570402, "actor_loss": -37.956151260375975, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.997642040252686, "step": 128000}
{"episode_reward": 552.5209863234488, "episode": 129.0, "batch_reward": 0.34050407296419144, "critic_loss": 0.39625005385279655, "actor_loss": -38.00806215667725, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.599161624908447, "step": 129000}
{"episode_reward": 568.2224278438399, "episode": 130.0, "batch_reward": 0.3424496796429157, "critic_loss": 0.4389980884343386, "actor_loss": -38.169386352539064, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.78367042541504, "step": 130000}
{"episode_reward": 579.0577808539847, "episode": 131.0, "batch_reward": 0.3449575012922287, "critic_loss": 0.43141053357720377, "actor_loss": -38.44268506622314, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.65251636505127, "step": 131000}
{"episode_reward": 556.8589740224118, "episode": 132.0, "batch_reward": 0.3455689212679863, "critic_loss": 0.38923663046211004, "actor_loss": -38.375774665832516, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.850868701934814, "step": 132000}
{"episode_reward": 572.2595472494487, "episode": 133.0, "batch_reward": 0.3478533902168274, "critic_loss": 0.40626492284238336, "actor_loss": -38.64904672241211, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.082348346710205, "step": 133000}
{"episode_reward": 582.5402652741099, "episode": 134.0, "batch_reward": 0.34887496468424795, "critic_loss": 0.3632942123413086, "actor_loss": -38.651624588012695, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.25684928894043, "step": 134000}
{"episode_reward": 545.721467498462, "episode": 135.0, "batch_reward": 0.3507534616589546, "critic_loss": 0.3611079670637846, "actor_loss": -38.889360572814944, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.449600219726562, "step": 135000}
{"episode_reward": 576.4139247573876, "episode": 136.0, "batch_reward": 0.3537227004468441, "critic_loss": 0.3905721828043461, "actor_loss": -39.161939178466795, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.82271146774292, "step": 136000}
{"episode_reward": 577.1492614342278, "episode": 137.0, "batch_reward": 0.35497037595510483, "critic_loss": 0.38646141746640206, "actor_loss": -39.16771520996094, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.403391361236572, "step": 137000}
{"episode_reward": 582.3626998498097, "episode": 138.0, "batch_reward": 0.35504748892784116, "critic_loss": 0.3842731424793601, "actor_loss": -39.142120727539066, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.059239387512207, "step": 138000}
{"episode_reward": 537.5299740948691, "episode": 139.0, "batch_reward": 0.35743845760822296, "critic_loss": 0.40031765706837175, "actor_loss": -39.51956241607666, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.21247959136963, "step": 139000}
{"episode_reward": 532.7998309092562, "episode": 140.0, "batch_reward": 0.35735008007287977, "critic_loss": 0.36937849830091, "actor_loss": -39.60503923797607, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.749508380889893, "step": 140000}
{"episode_reward": 587.2441083067715, "episode": 141.0, "batch_reward": 0.36151976120471957, "critic_loss": 0.405891519382596, "actor_loss": -39.89260747528076, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.374388456344604, "step": 141000}
{"episode_reward": 569.3499567767386, "episode": 142.0, "batch_reward": 0.36116861736774447, "critic_loss": 0.41183547185361385, "actor_loss": -39.88371496582031, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.7277729511261, "step": 142000}
{"episode_reward": 529.5537687354814, "episode": 143.0, "batch_reward": 0.3623244668543339, "critic_loss": 0.3991033750548959, "actor_loss": -40.02424338531494, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.911137580871582, "step": 143000}
{"episode_reward": 594.3709168555584, "episode": 144.0, "batch_reward": 0.3650801387429237, "critic_loss": 0.4205319093465805, "actor_loss": -40.334087303161624, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.955901861190796, "step": 144000}
{"episode_reward": 592.1536817740075, "episode": 145.0, "batch_reward": 0.3654834022521973, "critic_loss": 0.41789537450671194, "actor_loss": -40.54848542022705, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.606741428375244, "step": 145000}
{"episode_reward": 565.3563412740026, "episode": 146.0, "batch_reward": 0.3667264251410961, "critic_loss": 0.4484650246053934, "actor_loss": -40.82184767913818, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.938693046569824, "step": 146000}
{"episode_reward": 394.69296111577034, "episode": 147.0, "batch_reward": 0.3662298060953617, "critic_loss": 0.4337857581377029, "actor_loss": -41.0374686126709, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.34244441986084, "step": 147000}
{"episode_reward": 581.0119605923592, "episode": 148.0, "batch_reward": 0.369833826482296, "critic_loss": 0.45858250181376936, "actor_loss": -41.31478460693359, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.591649770736694, "step": 148000}
{"episode_reward": 554.0194251761878, "episode": 149.0, "batch_reward": 0.3712402229309082, "critic_loss": 0.4384204534590244, "actor_loss": -41.6120591506958, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.15575885772705, "step": 149000}
{"episode_reward": 595.7130501432438, "episode": 150.0, "batch_reward": 0.3719407517910004, "critic_loss": 0.42030657997727394, "actor_loss": -41.793060958862306, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
