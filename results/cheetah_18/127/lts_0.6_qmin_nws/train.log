{"episode_reward": 0.0, "episode": 1.0, "duration": 20.57792854309082, "step": 1000}
{"episode_reward": 7.051849146674556, "episode": 2.0, "duration": 1.632373332977295, "step": 2000}
{"episode_reward": 365.4711839680396, "episode": 3.0, "batch_reward": 0.1757585415346458, "critic_loss": 0.05364247552103979, "actor_loss": -23.056001745417817, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 64.68420004844666, "step": 3000}
{"episode_reward": 17.237198870986607, "episode": 4.0, "batch_reward": 0.11637231088429689, "critic_loss": 0.041074979638680814, "actor_loss": -18.67203985595703, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.150646209716797, "step": 4000}
{"episode_reward": 24.22163975658491, "episode": 5.0, "batch_reward": 0.09669360509887338, "critic_loss": 0.040406759535893795, "actor_loss": -17.275829833984375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.176477432250977, "step": 5000}
{"episode_reward": 39.399670304025335, "episode": 6.0, "batch_reward": 0.08323333134129643, "critic_loss": 0.04307569972611964, "actor_loss": -18.1039398458004, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.106087923049927, "step": 6000}
{"episode_reward": 9.049699332838095, "episode": 7.0, "batch_reward": 0.07214797532930971, "critic_loss": 0.04475281312596053, "actor_loss": -16.161220603942873, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.59408736228943, "step": 7000}
{"episode_reward": 34.481392693135795, "episode": 8.0, "batch_reward": 0.07133158211037517, "critic_loss": 0.05879306371696293, "actor_loss": -17.345900542259216, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.018330335617065, "step": 8000}
{"episode_reward": 69.97777682484414, "episode": 9.0, "batch_reward": 0.06762879844382405, "critic_loss": 0.05544473416544497, "actor_loss": -17.475147949457167, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.04472517967224, "step": 9000}
{"episode_reward": 21.15847276307058, "episode": 10.0, "batch_reward": 0.0642208448126912, "critic_loss": 0.05651722943410278, "actor_loss": -17.02489068543911, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.243513822555542, "step": 10000}
{"episode_reward": 45.10446917372109, "episode": 11.0, "batch_reward": 0.06322227476164699, "critic_loss": 0.06148774471692741, "actor_loss": -16.913227571964264, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.97092270851135, "step": 11000}
{"episode_reward": 50.0847426991703, "episode": 12.0, "batch_reward": 0.06174324403330684, "critic_loss": 0.06871219191513955, "actor_loss": -17.125953496575356, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.417956590652466, "step": 12000}
{"episode_reward": 69.6317701535824, "episode": 13.0, "batch_reward": 0.06368419111147523, "critic_loss": 0.09843212058767677, "actor_loss": -16.5564037527442, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.944806814193726, "step": 13000}
{"episode_reward": 96.89759622703747, "episode": 14.0, "batch_reward": 0.06714101203531027, "critic_loss": 0.15926311703026294, "actor_loss": -16.51588352301717, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.01303482055664, "step": 14000}
{"episode_reward": 115.13489998665968, "episode": 15.0, "batch_reward": 0.07137794653326272, "critic_loss": 0.2043335887566209, "actor_loss": -18.234533820189537, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.176428079605103, "step": 15000}
{"episode_reward": 140.10427267012065, "episode": 16.0, "batch_reward": 0.07540486978366971, "critic_loss": 0.19576437656581402, "actor_loss": -17.78458795443177, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.425719499588013, "step": 16000}
{"episode_reward": 92.34227238061857, "episode": 17.0, "batch_reward": 0.07519429288059473, "critic_loss": 0.16507212182879447, "actor_loss": -17.482917619526386, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.709964275360107, "step": 17000}
{"episode_reward": 94.2630066782953, "episode": 18.0, "batch_reward": 0.0752409220971167, "critic_loss": 0.14398819368332624, "actor_loss": -17.41707139444351, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.184173345565796, "step": 18000}
{"episode_reward": 28.306437701457078, "episode": 19.0, "batch_reward": 0.07366075275093317, "critic_loss": 0.13723014555126428, "actor_loss": -17.27590098333359, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.91221284866333, "step": 19000}
{"episode_reward": 84.3217710189155, "episode": 20.0, "batch_reward": 0.07505499591678381, "critic_loss": 0.16389881213754415, "actor_loss": -18.36636363506317, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.093574047088623, "step": 20000}
{"episode_reward": 137.26886847995434, "episode": 21.0, "batch_reward": 0.08033536896854639, "critic_loss": 0.2108342571333051, "actor_loss": -16.761892824172975, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.701416969299316, "step": 21000}
{"episode_reward": 222.44424666992796, "episode": 22.0, "batch_reward": 0.08744323417544365, "critic_loss": 0.1800119115561247, "actor_loss": -18.84130552482605, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.34248995780945, "step": 22000}
{"episode_reward": 274.4833557776001, "episode": 23.0, "batch_reward": 0.09597253388538957, "critic_loss": 0.14883239533007145, "actor_loss": -18.400057625770568, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.745521545410156, "step": 23000}
{"episode_reward": 189.59438284252772, "episode": 24.0, "batch_reward": 0.09935222215950489, "critic_loss": 0.13824813689291476, "actor_loss": -18.980639884471895, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.679107427597046, "step": 24000}
{"episode_reward": 246.1362332847247, "episode": 25.0, "batch_reward": 0.10237793568521739, "critic_loss": 0.1340814973935485, "actor_loss": -19.405216465473174, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.316486597061157, "step": 25000}
{"episode_reward": 41.77936424716888, "episode": 26.0, "batch_reward": 0.10160517562925815, "critic_loss": 0.13254937548190354, "actor_loss": -18.73412605381012, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.92824625968933, "step": 26000}
{"episode_reward": 110.7637362913934, "episode": 27.0, "batch_reward": 0.10129797943681479, "critic_loss": 0.15384946601837873, "actor_loss": -17.87220809841156, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.64532160758972, "step": 27000}
{"episode_reward": 69.4669197807055, "episode": 28.0, "batch_reward": 0.10028760445863008, "critic_loss": 0.18667453184723853, "actor_loss": -18.383601353168487, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.38503932952881, "step": 28000}
{"episode_reward": 74.22348917449406, "episode": 29.0, "batch_reward": 0.10187542258203029, "critic_loss": 0.22189127042889595, "actor_loss": -17.558354864120485, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.415640115737915, "step": 29000}
{"episode_reward": 233.12377824167723, "episode": 30.0, "batch_reward": 0.10336156832426786, "critic_loss": 0.2596975724324584, "actor_loss": -17.150341535568238, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.754142999649048, "step": 30000}
{"episode_reward": 46.25457697771959, "episode": 31.0, "batch_reward": 0.10121998851001263, "critic_loss": 0.2516922169998288, "actor_loss": -17.17193340969086, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.545610666275024, "step": 31000}
{"episode_reward": 48.50072821222168, "episode": 32.0, "batch_reward": 0.10065127022564412, "critic_loss": 0.27246056763827803, "actor_loss": -17.267389852046968, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.54558777809143, "step": 32000}
{"episode_reward": 48.97516568376648, "episode": 33.0, "batch_reward": 0.09793520906567574, "critic_loss": 0.249293884716928, "actor_loss": -16.91444894361496, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.697316884994507, "step": 33000}
{"episode_reward": 30.96917327884275, "episode": 34.0, "batch_reward": 0.09606405440717936, "critic_loss": 0.320156988888979, "actor_loss": -16.458940938949585, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.05658268928528, "step": 34000}
{"episode_reward": 33.550801873535235, "episode": 35.0, "batch_reward": 0.09387052123993635, "critic_loss": 0.31119483771920203, "actor_loss": -16.61599428987503, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.944292306900024, "step": 35000}
{"episode_reward": 49.15049582848142, "episode": 36.0, "batch_reward": 0.09475488257408142, "critic_loss": 0.30560538682341576, "actor_loss": -17.313485414505006, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.917149782180786, "step": 36000}
{"episode_reward": 190.59608627601233, "episode": 37.0, "batch_reward": 0.09772696152329445, "critic_loss": 0.3442550054937601, "actor_loss": -16.736927531719207, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.123302459716797, "step": 37000}
{"episode_reward": 256.7581988569564, "episode": 38.0, "batch_reward": 0.10269450362026691, "critic_loss": 0.30303039019554856, "actor_loss": -17.2602610244751, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.12591791152954, "step": 38000}
{"episode_reward": 339.9980970234438, "episode": 39.0, "batch_reward": 0.10644472157955169, "critic_loss": 0.3256522931754589, "actor_loss": -17.458918889045716, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.207242965698242, "step": 39000}
{"episode_reward": 33.31075710780348, "episode": 40.0, "batch_reward": 0.10715962892770767, "critic_loss": 0.31267680460214614, "actor_loss": -17.718916654586792, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.139089107513428, "step": 40000}
{"episode_reward": 344.7829451277416, "episode": 41.0, "batch_reward": 0.11360202115774155, "critic_loss": 0.2945619869455695, "actor_loss": -17.508845418930054, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.74608874320984, "step": 41000}
{"episode_reward": 301.6201549963039, "episode": 42.0, "batch_reward": 0.11459558541327715, "critic_loss": 0.28819577262550594, "actor_loss": -18.051217131614685, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.353939533233643, "step": 42000}
{"episode_reward": 44.80931168666389, "episode": 43.0, "batch_reward": 0.11396712728589774, "critic_loss": 0.2676964594051242, "actor_loss": -18.256925647735596, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.303412675857544, "step": 43000}
{"episode_reward": 72.36958172259521, "episode": 44.0, "batch_reward": 0.11293982745707035, "critic_loss": 0.28931492459774016, "actor_loss": -18.90126573944092, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.145031213760376, "step": 44000}
{"episode_reward": 63.70039382458839, "episode": 45.0, "batch_reward": 0.11456898387521505, "critic_loss": 0.29319767852127554, "actor_loss": -18.201806049346924, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.846367835998535, "step": 45000}
{"episode_reward": 367.03651873783707, "episode": 46.0, "batch_reward": 0.1179609982445836, "critic_loss": 0.2792841764613986, "actor_loss": -17.839710179328918, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.49030041694641, "step": 46000}
{"episode_reward": 225.4921145783621, "episode": 47.0, "batch_reward": 0.1216259244531393, "critic_loss": 0.2863657996058464, "actor_loss": -18.45130327320099, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.909655809402466, "step": 47000}
{"episode_reward": 254.5307892356833, "episode": 48.0, "batch_reward": 0.12561684615910054, "critic_loss": 0.29198684909194705, "actor_loss": -18.75252252006531, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.70672345161438, "step": 48000}
{"episode_reward": 404.21750476723963, "episode": 49.0, "batch_reward": 0.12810865923017264, "critic_loss": 0.2858468231409788, "actor_loss": -19.626814865112305, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.073524475097656, "step": 49000}
{"episode_reward": 63.15164386550733, "episode": 50.0, "batch_reward": 0.12851834961771966, "critic_loss": 0.32454330269992354, "actor_loss": -19.235059685707093, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.638205766677856, "step": 50000}
{"episode_reward": 266.40173989660207, "episode": 51.0, "batch_reward": 0.13286708530783653, "critic_loss": 0.3094197516143322, "actor_loss": -19.494784234046936, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.36541700363159, "step": 51000}
{"episode_reward": 355.5347606055292, "episode": 52.0, "batch_reward": 0.13644879393279552, "critic_loss": 0.3039630976393819, "actor_loss": -19.24393211174011, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.1159508228302, "step": 52000}
{"episode_reward": 381.80770388767684, "episode": 53.0, "batch_reward": 0.14130325269699096, "critic_loss": 0.36978220760822295, "actor_loss": -20.275795412063598, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.423364877700806, "step": 53000}
{"episode_reward": 326.81092765326184, "episode": 54.0, "batch_reward": 0.14402803549170495, "critic_loss": 0.3606898440271616, "actor_loss": -20.947676900863648, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.85695171356201, "step": 54000}
{"episode_reward": 174.0766992724201, "episode": 55.0, "batch_reward": 0.14538139386475085, "critic_loss": 0.382939119592309, "actor_loss": -20.18781957626343, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.584269285202026, "step": 55000}
{"episode_reward": 394.8184153611321, "episode": 56.0, "batch_reward": 0.1501136299818754, "critic_loss": 0.37340573041141034, "actor_loss": -20.753200357437134, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.107373476028442, "step": 56000}
{"episode_reward": 399.0029359403848, "episode": 57.0, "batch_reward": 0.15461098746955396, "critic_loss": 0.3939457902163267, "actor_loss": -21.03245848274231, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.767512798309326, "step": 57000}
{"episode_reward": 362.8721004155855, "episode": 58.0, "batch_reward": 0.15775672083348036, "critic_loss": 0.4608257246464491, "actor_loss": -21.444146200180054, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.336413860321045, "step": 58000}
{"episode_reward": 379.12609244099036, "episode": 59.0, "batch_reward": 0.15970978565514088, "critic_loss": 0.4085483925193548, "actor_loss": -21.7560856590271, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.11115550994873, "step": 59000}
{"episode_reward": 104.28668828809109, "episode": 60.0, "batch_reward": 0.15977286837995053, "critic_loss": 0.4267362516373396, "actor_loss": -21.82566827583313, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.340718269348145, "step": 60000}
{"episode_reward": 272.96680293645665, "episode": 61.0, "batch_reward": 0.16250663594156503, "critic_loss": 0.41675079573690893, "actor_loss": -21.556999809265136, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.73200845718384, "step": 61000}
{"episode_reward": 386.7889339732963, "episode": 62.0, "batch_reward": 0.16558765617012977, "critic_loss": 0.4340087775737047, "actor_loss": -22.469031396865844, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.71906089782715, "step": 62000}
{"episode_reward": 218.88195516482017, "episode": 63.0, "batch_reward": 0.16755164709687234, "critic_loss": 0.3888933584541082, "actor_loss": -22.104170539855957, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.201664209365845, "step": 63000}
{"episode_reward": 361.6271859013923, "episode": 64.0, "batch_reward": 0.170365851059556, "critic_loss": 0.43240804024040697, "actor_loss": -22.530728267669677, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.878756761550903, "step": 64000}
{"episode_reward": 401.6706204339741, "episode": 65.0, "batch_reward": 0.17387867833673953, "critic_loss": 0.43755730730295184, "actor_loss": -22.950512786865236, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.198103666305542, "step": 65000}
{"episode_reward": 336.3676298404907, "episode": 66.0, "batch_reward": 0.17511479561030865, "critic_loss": 0.4346843537837267, "actor_loss": -22.75302200317383, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.595451831817627, "step": 66000}
{"episode_reward": 139.40461925339457, "episode": 67.0, "batch_reward": 0.17680835207551718, "critic_loss": 0.42806409500539305, "actor_loss": -23.36353931617737, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.202648162841797, "step": 67000}
{"episode_reward": 457.8863724263814, "episode": 68.0, "batch_reward": 0.17988004338741304, "critic_loss": 0.4801184193342924, "actor_loss": -24.037839506149293, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.280757904052734, "step": 68000}
{"episode_reward": 371.1032321054123, "episode": 69.0, "batch_reward": 0.18272899958491326, "critic_loss": 0.43966636392474173, "actor_loss": -23.200947406768798, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.283002614974976, "step": 69000}
{"episode_reward": 411.378828612712, "episode": 70.0, "batch_reward": 0.1859820249825716, "critic_loss": 0.46123113548755645, "actor_loss": -23.564779136657716, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.761457443237305, "step": 70000}
{"episode_reward": 408.2226947230222, "episode": 71.0, "batch_reward": 0.18789405527710915, "critic_loss": 0.4582358775138855, "actor_loss": -23.63011368560791, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.16347813606262, "step": 71000}
{"episode_reward": 107.956512545211, "episode": 72.0, "batch_reward": 0.18786498525738715, "critic_loss": 0.45550084099173543, "actor_loss": -23.848559843063356, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.072883367538452, "step": 72000}
{"episode_reward": 417.8344521846192, "episode": 73.0, "batch_reward": 0.19215140557289123, "critic_loss": 0.44852925731241705, "actor_loss": -24.57252014732361, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.341010332107544, "step": 73000}
{"episode_reward": 430.3551069593419, "episode": 74.0, "batch_reward": 0.19388890582323073, "critic_loss": 0.46874408566951753, "actor_loss": -24.6099082736969, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.241369009017944, "step": 74000}
{"episode_reward": 424.9742301506672, "episode": 75.0, "batch_reward": 0.19681474539637567, "critic_loss": 0.4508670576363802, "actor_loss": -24.812342418670653, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.93758773803711, "step": 75000}
{"episode_reward": 406.51252965293673, "episode": 76.0, "batch_reward": 0.20043070997297763, "critic_loss": 0.4203017636090517, "actor_loss": -25.09660365867615, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.428319931030273, "step": 76000}
{"episode_reward": 403.75129077393376, "episode": 77.0, "batch_reward": 0.20167863626778126, "critic_loss": 0.39955808827281, "actor_loss": -25.219301290512085, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.347337007522583, "step": 77000}
{"episode_reward": 130.78174563839892, "episode": 78.0, "batch_reward": 0.2014352557361126, "critic_loss": 0.4397298957705498, "actor_loss": -25.09171015930176, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.809061527252197, "step": 78000}
{"episode_reward": 389.2079066984103, "episode": 79.0, "batch_reward": 0.20481903082132338, "critic_loss": 0.4197242649644613, "actor_loss": -25.68729344177246, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.837772607803345, "step": 79000}
{"episode_reward": 455.80764251177317, "episode": 80.0, "batch_reward": 0.2073936869353056, "critic_loss": 0.4121412281990051, "actor_loss": -26.022588569641112, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.349260568618774, "step": 80000}
{"episode_reward": 438.08138438152906, "episode": 81.0, "batch_reward": 0.2105155982673168, "critic_loss": 0.42128301717340944, "actor_loss": -26.10003372192383, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.42729735374451, "step": 81000}
{"episode_reward": 352.95728624516977, "episode": 82.0, "batch_reward": 0.21107708728313446, "critic_loss": 0.45386585092544557, "actor_loss": -25.649839756011964, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.54239821434021, "step": 82000}
{"episode_reward": 405.6620878859744, "episode": 83.0, "batch_reward": 0.21446561618149282, "critic_loss": 0.39515796659886837, "actor_loss": -26.575830057144167, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.348766803741455, "step": 83000}
{"episode_reward": 438.12252607069877, "episode": 84.0, "batch_reward": 0.21770369854569435, "critic_loss": 0.4363726566135883, "actor_loss": -26.968570600509643, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.344865083694458, "step": 84000}
{"episode_reward": 431.16986512511755, "episode": 85.0, "batch_reward": 0.21850371889770032, "critic_loss": 0.4149490324407816, "actor_loss": -26.5394108543396, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.244389295578003, "step": 85000}
{"episode_reward": 204.81547341497085, "episode": 86.0, "batch_reward": 0.219892225548625, "critic_loss": 0.41123045244812967, "actor_loss": -26.542054639816286, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.16369652748108, "step": 86000}
{"episode_reward": 441.7031570163802, "episode": 87.0, "batch_reward": 0.22205858650803567, "critic_loss": 0.46187487652897835, "actor_loss": -27.351620109558105, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.826920747756958, "step": 87000}
{"episode_reward": 400.7825989629402, "episode": 88.0, "batch_reward": 0.22381040056049822, "critic_loss": 0.4368562857359648, "actor_loss": -26.636414413452147, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.438668966293335, "step": 88000}
{"episode_reward": 410.0274080708629, "episode": 89.0, "batch_reward": 0.22645108483731746, "critic_loss": 0.4501169278174639, "actor_loss": -26.984404609680176, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.434914588928223, "step": 89000}
{"episode_reward": 227.07104604695192, "episode": 90.0, "batch_reward": 0.22671863143146037, "critic_loss": 0.4161007856875658, "actor_loss": -27.07206409072876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.36890482902527, "step": 90000}
{"episode_reward": 401.24275157094695, "episode": 91.0, "batch_reward": 0.22844758097827433, "critic_loss": 0.438473639562726, "actor_loss": -27.213736125946046, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.99747824668884, "step": 91000}
{"episode_reward": 442.54141934305136, "episode": 92.0, "batch_reward": 0.2303272900134325, "critic_loss": 0.41055558422207833, "actor_loss": -27.91358380508423, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.966443061828613, "step": 92000}
{"episode_reward": 447.5669476225402, "episode": 93.0, "batch_reward": 0.23205853420495987, "critic_loss": 0.3820618771016598, "actor_loss": -27.569210567474364, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.376416444778442, "step": 93000}
{"episode_reward": 202.1761932717473, "episode": 94.0, "batch_reward": 0.23289703376591206, "critic_loss": 0.4052979653030634, "actor_loss": -28.167332637786867, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.981675148010254, "step": 94000}
{"episode_reward": 193.1679040589828, "episode": 95.0, "batch_reward": 0.2315884144604206, "critic_loss": 0.4659287355095148, "actor_loss": -28.461946262359618, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.663443088531494, "step": 95000}
{"episode_reward": 448.8520648350014, "episode": 96.0, "batch_reward": 0.23568337899446487, "critic_loss": 0.456929684355855, "actor_loss": -28.341742500305177, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.746272563934326, "step": 96000}
{"episode_reward": 424.97767825307886, "episode": 97.0, "batch_reward": 0.2365506297647953, "critic_loss": 0.46394041119515894, "actor_loss": -27.946868389129637, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.157793521881104, "step": 97000}
{"episode_reward": 388.7650777379907, "episode": 98.0, "batch_reward": 0.23760952751338482, "critic_loss": 0.4799437658190727, "actor_loss": -29.157428634643555, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.35290837287903, "step": 98000}
{"episode_reward": 418.8552951689533, "episode": 99.0, "batch_reward": 0.23983833974599839, "critic_loss": 0.4725539066493511, "actor_loss": -28.694010746002196, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.29610323905945, "step": 99000}
{"episode_reward": 319.29762865823056, "episode": 100.0, "batch_reward": 0.24101271104812622, "critic_loss": 0.45977316762506965, "actor_loss": -28.695546058654784, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.950283765792847, "step": 100000}
{"episode_reward": 426.7935720847128, "episode": 101.0, "batch_reward": 0.24282382161915303, "critic_loss": 0.49095487470924853, "actor_loss": -28.75318392944336, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.265196800231934, "step": 101000}
{"episode_reward": 431.18135669258663, "episode": 102.0, "batch_reward": 0.24445640505850316, "critic_loss": 0.48666358859837056, "actor_loss": -29.22465934753418, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.166407585144043, "step": 102000}
{"episode_reward": 391.5333530313939, "episode": 103.0, "batch_reward": 0.24567920529842377, "critic_loss": 0.5139424936026334, "actor_loss": -29.35926494216919, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.437976360321045, "step": 103000}
{"episode_reward": 374.1352436597161, "episode": 104.0, "batch_reward": 0.2471439088881016, "critic_loss": 0.5083696885704995, "actor_loss": -28.87217860031128, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.510496139526367, "step": 104000}
{"episode_reward": 385.2442622688821, "episode": 105.0, "batch_reward": 0.24968081386387347, "critic_loss": 0.5476035313755274, "actor_loss": -29.28233118057251, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.12057328224182, "step": 105000}
{"episode_reward": 492.1505365840448, "episode": 106.0, "batch_reward": 0.25071097165346146, "critic_loss": 0.5246652787923813, "actor_loss": -29.515565830230713, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.83254337310791, "step": 106000}
{"episode_reward": 338.9945396891423, "episode": 107.0, "batch_reward": 0.25107699136435985, "critic_loss": 0.5387649329453706, "actor_loss": -29.03117777252197, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.24774956703186, "step": 107000}
{"episode_reward": 433.51057065904916, "episode": 108.0, "batch_reward": 0.2524701499938965, "critic_loss": 0.4999753973484039, "actor_loss": -30.344467872619628, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.597485065460205, "step": 108000}
{"episode_reward": 456.7311000351002, "episode": 109.0, "batch_reward": 0.2555025027394295, "critic_loss": 0.508527116432786, "actor_loss": -29.99477721405029, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.920989990234375, "step": 109000}
{"episode_reward": 435.89733617113257, "episode": 110.0, "batch_reward": 0.2573531598299742, "critic_loss": 0.5180542407482862, "actor_loss": -30.86695015335083, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.61373257637024, "step": 110000}
{"episode_reward": 414.21042287987063, "episode": 111.0, "batch_reward": 0.25784596948325633, "critic_loss": 0.4794226763397455, "actor_loss": -30.01302205657959, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.516928911209106, "step": 111000}
{"episode_reward": 439.6628157523309, "episode": 112.0, "batch_reward": 0.25929760560393333, "critic_loss": 0.4526393719166517, "actor_loss": -30.750730094909667, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.972936153411865, "step": 112000}
{"episode_reward": 445.58119553135714, "episode": 113.0, "batch_reward": 0.2606448827236891, "critic_loss": 0.44721019886434077, "actor_loss": -30.39154902648926, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.514529943466187, "step": 113000}
{"episode_reward": 472.43006588386595, "episode": 114.0, "batch_reward": 0.26257531902194026, "critic_loss": 0.478610067114234, "actor_loss": -30.772473262786864, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.72388505935669, "step": 114000}
{"episode_reward": 426.67220001150514, "episode": 115.0, "batch_reward": 0.2646052559167147, "critic_loss": 0.4991477762460709, "actor_loss": -30.92844083786011, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.037505388259888, "step": 115000}
{"episode_reward": 452.4434394714978, "episode": 116.0, "batch_reward": 0.2666395111232996, "critic_loss": 0.484088897690177, "actor_loss": -31.09627004623413, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.335474729537964, "step": 116000}
{"episode_reward": 423.9609440806231, "episode": 117.0, "batch_reward": 0.2685664887726307, "critic_loss": 0.45795336221158506, "actor_loss": -30.89773960876465, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.520752429962158, "step": 117000}
{"episode_reward": 435.26440587500764, "episode": 118.0, "batch_reward": 0.2695549724251032, "critic_loss": 0.48290830665826795, "actor_loss": -31.077330001831054, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.384103775024414, "step": 118000}
{"episode_reward": 482.2103978476608, "episode": 119.0, "batch_reward": 0.2708497903048992, "critic_loss": 0.48348703429102896, "actor_loss": -31.14428792953491, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.043744802474976, "step": 119000}
{"episode_reward": 493.97547348027837, "episode": 120.0, "batch_reward": 0.2727466389387846, "critic_loss": 0.4840856790989637, "actor_loss": -31.288906673431395, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.376941442489624, "step": 120000}
{"episode_reward": 489.6381834502283, "episode": 121.0, "batch_reward": 0.27361937241256234, "critic_loss": 0.5133681488931179, "actor_loss": -31.508023262023926, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.73639225959778, "step": 121000}
{"episode_reward": 444.6437765424703, "episode": 122.0, "batch_reward": 0.27632509323954585, "critic_loss": 0.48262461452186106, "actor_loss": -31.94725182723999, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.370304107666016, "step": 122000}
{"episode_reward": 473.52761373864126, "episode": 123.0, "batch_reward": 0.2782273617386818, "critic_loss": 0.48333058899641035, "actor_loss": -32.01408662033081, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.162273406982422, "step": 123000}
{"episode_reward": 477.8150613770675, "episode": 124.0, "batch_reward": 0.27957931837439537, "critic_loss": 0.5304551510363817, "actor_loss": -32.61104672241211, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.099284410476685, "step": 124000}
{"episode_reward": 417.07494489318435, "episode": 125.0, "batch_reward": 0.2802941316217184, "critic_loss": 0.49361927099525926, "actor_loss": -32.1651056060791, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.67430305480957, "step": 125000}
{"episode_reward": 447.90656713222484, "episode": 126.0, "batch_reward": 0.2820252008587122, "critic_loss": 0.5033419048935175, "actor_loss": -32.547774452209474, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.156721830368042, "step": 126000}
{"episode_reward": 460.97415537359456, "episode": 127.0, "batch_reward": 0.28296024022996424, "critic_loss": 0.5034552365094423, "actor_loss": -32.666088806152345, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.735766887664795, "step": 127000}
{"episode_reward": 488.0161268849377, "episode": 128.0, "batch_reward": 0.28487271167337896, "critic_loss": 0.5442898072749376, "actor_loss": -32.73594880676269, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.899412393569946, "step": 128000}
{"episode_reward": 444.69967927937563, "episode": 129.0, "batch_reward": 0.28677478882670404, "critic_loss": 0.5098958341032267, "actor_loss": -32.75655544662476, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.458409070968628, "step": 129000}
{"episode_reward": 442.5185428687975, "episode": 130.0, "batch_reward": 0.28693093931674957, "critic_loss": 0.5092123576253652, "actor_loss": -32.8488694229126, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.020795822143555, "step": 130000}
{"episode_reward": 501.55934973497494, "episode": 131.0, "batch_reward": 0.2885621470063925, "critic_loss": 0.49667219530045986, "actor_loss": -32.56080086135864, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.51938509941101, "step": 131000}
{"episode_reward": 467.3349483505708, "episode": 132.0, "batch_reward": 0.29010462734103204, "critic_loss": 0.48238600128889086, "actor_loss": -33.22322308731079, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.704986095428467, "step": 132000}
{"episode_reward": 444.6866690317412, "episode": 133.0, "batch_reward": 0.2917317575663328, "critic_loss": 0.5291662381589413, "actor_loss": -32.849588306427, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.029890060424805, "step": 133000}
{"episode_reward": 478.0139872751796, "episode": 134.0, "batch_reward": 0.29272255052626134, "critic_loss": 0.4538563786447048, "actor_loss": -33.2214153175354, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.161717891693115, "step": 134000}
{"episode_reward": 482.127799921364, "episode": 135.0, "batch_reward": 0.2938408532142639, "critic_loss": 0.4874733844548464, "actor_loss": -33.658925354003905, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.98215913772583, "step": 135000}
{"episode_reward": 494.2334558141712, "episode": 136.0, "batch_reward": 0.2959619452953339, "critic_loss": 0.45228621074557307, "actor_loss": -33.866698219299316, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.82016134262085, "step": 136000}
{"episode_reward": 468.5629559126825, "episode": 137.0, "batch_reward": 0.2974803550988436, "critic_loss": 0.4587658898681402, "actor_loss": -33.74308071136475, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.03714108467102, "step": 137000}
{"episode_reward": 469.9567711672014, "episode": 138.0, "batch_reward": 0.29785211646556853, "critic_loss": 0.47963940572738645, "actor_loss": -33.77206217956543, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.31021499633789, "step": 138000}
{"episode_reward": 488.49781954070806, "episode": 139.0, "batch_reward": 0.3002843818515539, "critic_loss": 0.4711913390159607, "actor_loss": -33.973783447265625, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.919621467590332, "step": 139000}
{"episode_reward": 481.0778356608524, "episode": 140.0, "batch_reward": 0.3000513863861561, "critic_loss": 0.480801306694746, "actor_loss": -34.28512239074707, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.58138871192932, "step": 140000}
{"episode_reward": 336.9218512798333, "episode": 141.0, "batch_reward": 0.30221220925450326, "critic_loss": 0.48637518274784086, "actor_loss": -34.09674112701416, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.6291286945343, "step": 141000}
{"episode_reward": 200.93998939286152, "episode": 142.0, "batch_reward": 0.3006455300450325, "critic_loss": 0.46324970059096815, "actor_loss": -33.917863273620604, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.060948610305786, "step": 142000}
{"episode_reward": 426.41312549681777, "episode": 143.0, "batch_reward": 0.3014950463026762, "critic_loss": 0.5155200067013502, "actor_loss": -33.96621168899536, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.419032335281372, "step": 143000}
{"episode_reward": 436.2594598223964, "episode": 144.0, "batch_reward": 0.3016361389458179, "critic_loss": 0.5129540661424399, "actor_loss": -34.35738707351685, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.011716604232788, "step": 144000}
{"episode_reward": 176.27381963371516, "episode": 145.0, "batch_reward": 0.3013121902346611, "critic_loss": 0.4925500892698765, "actor_loss": -34.37114643096924, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.80981993675232, "step": 145000}
{"episode_reward": 474.7988962747571, "episode": 146.0, "batch_reward": 0.3019536570906639, "critic_loss": 0.5019887081235648, "actor_loss": -34.03756589889527, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.914114236831665, "step": 146000}
{"episode_reward": 510.16347366097773, "episode": 147.0, "batch_reward": 0.3029854802787304, "critic_loss": 0.5001314173489809, "actor_loss": -34.55844995117187, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.034828424453735, "step": 147000}
{"episode_reward": 494.55142124847913, "episode": 148.0, "batch_reward": 0.306032467097044, "critic_loss": 0.4967741103619337, "actor_loss": -34.78976530075073, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.020318031311035, "step": 148000}
{"episode_reward": 468.968775235571, "episode": 149.0, "batch_reward": 0.30704045939445496, "critic_loss": 0.5043308006376028, "actor_loss": -34.86526942062378, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.529951333999634, "step": 149000}
{"episode_reward": 460.82044767309014, "episode": 150.0, "batch_reward": 0.3073079552948475, "critic_loss": 0.4662164934575558, "actor_loss": -34.74971642303467, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
