{"episode_reward": 0.0, "episode": 1.0, "duration": 13.834473848342896, "step": 1000}
{"episode_reward": 7.051849146674556, "episode": 2.0, "duration": 1.2418584823608398, "step": 2000}
{"episode_reward": 365.4711839680396, "episode": 3.0, "batch_reward": 0.17590019798757792, "critic_loss": 0.049242710181340826, "actor_loss": -21.31446817978507, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 76.01770091056824, "step": 3000}
{"episode_reward": 22.097287264252973, "episode": 4.0, "batch_reward": 0.12047576996684074, "critic_loss": 0.059489989083260295, "actor_loss": -18.090630420446395, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.28096318244934, "step": 4000}
{"episode_reward": 55.08175525024237, "episode": 5.0, "batch_reward": 0.1056226744428277, "critic_loss": 0.06341269920021296, "actor_loss": -15.951676717996598, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.481934070587158, "step": 5000}
{"episode_reward": 50.69053178963845, "episode": 6.0, "batch_reward": 0.09744336165860296, "critic_loss": 0.07227503711916507, "actor_loss": -14.163402982234954, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.520588397979736, "step": 6000}
{"episode_reward": 52.17948780948833, "episode": 7.0, "batch_reward": 0.09044472606852651, "critic_loss": 0.07938602217845618, "actor_loss": -14.065887051582337, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.81772494316101, "step": 7000}
{"episode_reward": 55.77451085170486, "episode": 8.0, "batch_reward": 0.08547882577031851, "critic_loss": 0.07833506312780082, "actor_loss": -13.167502942562104, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.80242085456848, "step": 8000}
{"episode_reward": 68.42276351297451, "episode": 9.0, "batch_reward": 0.08585257027298213, "critic_loss": 0.10062205397337676, "actor_loss": -12.727319713830948, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.234504222869873, "step": 9000}
{"episode_reward": 88.86118704531894, "episode": 10.0, "batch_reward": 0.08677406496927142, "critic_loss": 0.12970260973647238, "actor_loss": -12.894221630692481, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.959732055664062, "step": 10000}
{"episode_reward": 133.54623322856887, "episode": 11.0, "batch_reward": 0.09388068057596684, "critic_loss": 0.15419028748571872, "actor_loss": -13.537683564499021, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.82214379310608, "step": 11000}
{"episode_reward": 142.73983395362637, "episode": 12.0, "batch_reward": 0.09199328983947634, "critic_loss": 0.14202720701694488, "actor_loss": -13.426991602391004, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.474088430404663, "step": 12000}
{"episode_reward": 23.42244776253959, "episode": 13.0, "batch_reward": 0.08656580090522766, "critic_loss": 0.13958849396556616, "actor_loss": -13.272141324579716, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.874876260757446, "step": 13000}
{"episode_reward": 26.343742952098864, "episode": 14.0, "batch_reward": 0.08469983875006437, "critic_loss": 0.14893008752912282, "actor_loss": -13.000570580743254, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.46099042892456, "step": 14000}
{"episode_reward": 65.85388646920168, "episode": 15.0, "batch_reward": 0.08651924254745245, "critic_loss": 0.14899420687556267, "actor_loss": -12.279384344056249, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.989219188690186, "step": 15000}
{"episode_reward": 223.43840086628006, "episode": 16.0, "batch_reward": 0.09401356332749128, "critic_loss": 0.14580850438028575, "actor_loss": -13.400417991101742, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.543251514434814, "step": 16000}
{"episode_reward": 127.39494427938382, "episode": 17.0, "batch_reward": 0.09773896263539791, "critic_loss": 0.12262822949886322, "actor_loss": -13.437036496460438, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.32351589202881, "step": 17000}
{"episode_reward": 206.25348503128143, "episode": 18.0, "batch_reward": 0.10330949411541224, "critic_loss": 0.12992043877393009, "actor_loss": -13.866732278585435, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.45594835281372, "step": 18000}
{"episode_reward": 195.83197974781461, "episode": 19.0, "batch_reward": 0.10794224613159895, "critic_loss": 0.13806534497067333, "actor_loss": -14.469401073932648, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.266050577163696, "step": 19000}
{"episode_reward": 179.63463985581697, "episode": 20.0, "batch_reward": 0.11252775948494673, "critic_loss": 0.14150072241574527, "actor_loss": -13.835205725312234, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.358438968658447, "step": 20000}
{"episode_reward": 233.61069498135507, "episode": 21.0, "batch_reward": 0.11752042096108198, "critic_loss": 0.14209293363988398, "actor_loss": -15.918208413600922, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.303800106048584, "step": 21000}
{"episode_reward": 173.1964813865615, "episode": 22.0, "batch_reward": 0.12107776382565498, "critic_loss": 0.1488964250385761, "actor_loss": -14.289024294376373, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.187663078308105, "step": 22000}
{"episode_reward": 236.51406401545103, "episode": 23.0, "batch_reward": 0.12770176876336337, "critic_loss": 0.14910170052573085, "actor_loss": -15.77507314825058, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.453339099884033, "step": 23000}
{"episode_reward": 257.0587748376984, "episode": 24.0, "batch_reward": 0.13212002608925105, "critic_loss": 0.1592552400380373, "actor_loss": -16.090950349330903, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.255011796951294, "step": 24000}
{"episode_reward": 252.7015705410083, "episode": 25.0, "batch_reward": 0.13817181190103292, "critic_loss": 0.18098948852717878, "actor_loss": -16.33596099424362, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.217562437057495, "step": 25000}
{"episode_reward": 291.2411518606548, "episode": 26.0, "batch_reward": 0.14443169564753772, "critic_loss": 0.19372420038282873, "actor_loss": -17.051620512008668, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.38169836997986, "step": 26000}
{"episode_reward": 295.8561404682045, "episode": 27.0, "batch_reward": 0.14918018322438, "critic_loss": 0.18554129046946763, "actor_loss": -17.888827533721923, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.078856468200684, "step": 27000}
{"episode_reward": 280.93107239378384, "episode": 28.0, "batch_reward": 0.15590529746562243, "critic_loss": 0.19007321871817112, "actor_loss": -17.82604053211212, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.798992395401, "step": 28000}
{"episode_reward": 285.74288290435294, "episode": 29.0, "batch_reward": 0.16007580006867647, "critic_loss": 0.18965054512023927, "actor_loss": -18.51688474559784, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.78249955177307, "step": 29000}
{"episode_reward": 373.5995366551981, "episode": 30.0, "batch_reward": 0.16764561849832535, "critic_loss": 0.19828195416927338, "actor_loss": -20.118048161506653, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.468189001083374, "step": 30000}
{"episode_reward": 307.0593040540293, "episode": 31.0, "batch_reward": 0.1722129888087511, "critic_loss": 0.20257444792985915, "actor_loss": -19.870619888305665, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.73328924179077, "step": 31000}
{"episode_reward": 352.31442332271234, "episode": 32.0, "batch_reward": 0.176333195194602, "critic_loss": 0.237956277243793, "actor_loss": -19.543478600502013, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.745486974716187, "step": 32000}
{"episode_reward": 233.6844414339672, "episode": 33.0, "batch_reward": 0.17903016358613968, "critic_loss": 0.23525433675199747, "actor_loss": -20.223260948181153, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.61353635787964, "step": 33000}
{"episode_reward": 326.6947742198942, "episode": 34.0, "batch_reward": 0.18336151519417762, "critic_loss": 0.2403389737829566, "actor_loss": -21.088062908172606, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.76191520690918, "step": 34000}
{"episode_reward": 199.67580180683157, "episode": 35.0, "batch_reward": 0.18313196079432964, "critic_loss": 0.2501876658573747, "actor_loss": -20.392938482284546, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.653616189956665, "step": 35000}
{"episode_reward": 280.32670914502125, "episode": 36.0, "batch_reward": 0.18399243995547296, "critic_loss": 0.2565140431821346, "actor_loss": -20.279670190811157, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.68295979499817, "step": 36000}
{"episode_reward": 78.86405313921257, "episode": 37.0, "batch_reward": 0.18408934634923935, "critic_loss": 0.28856857132911684, "actor_loss": -21.00007999229431, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.294683933258057, "step": 37000}
{"episode_reward": 307.960226311126, "episode": 38.0, "batch_reward": 0.18688247601687907, "critic_loss": 0.29766948291659356, "actor_loss": -21.331514921188354, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.868464708328247, "step": 38000}
{"episode_reward": 313.64322460234223, "episode": 39.0, "batch_reward": 0.1891250819116831, "critic_loss": 0.2993500294536352, "actor_loss": -21.332111019134523, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.21028184890747, "step": 39000}
{"episode_reward": 180.05873831008319, "episode": 40.0, "batch_reward": 0.18790249218046665, "critic_loss": 0.31630714297294615, "actor_loss": -21.36957291030884, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.433983325958252, "step": 40000}
{"episode_reward": 93.24940973309066, "episode": 41.0, "batch_reward": 0.1880179327428341, "critic_loss": 0.31026775054633615, "actor_loss": -22.037401245117188, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.70446968078613, "step": 41000}
{"episode_reward": 320.4447548855224, "episode": 42.0, "batch_reward": 0.19225128225982188, "critic_loss": 0.31636614800989626, "actor_loss": -21.910460721969603, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.43564462661743, "step": 42000}
{"episode_reward": 348.37136446077693, "episode": 43.0, "batch_reward": 0.19343414947390555, "critic_loss": 0.34869032645225523, "actor_loss": -21.575102272033693, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.69291877746582, "step": 43000}
{"episode_reward": 139.39823792465384, "episode": 44.0, "batch_reward": 0.1921662786155939, "critic_loss": 0.3219311570674181, "actor_loss": -20.931555410385133, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.67812180519104, "step": 44000}
{"episode_reward": 142.4730827002616, "episode": 45.0, "batch_reward": 0.1905803968757391, "critic_loss": 0.3313083266466856, "actor_loss": -21.5259718914032, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.383800506591797, "step": 45000}
{"episode_reward": 84.07392531175182, "episode": 46.0, "batch_reward": 0.18890773597359659, "critic_loss": 0.3003010343834758, "actor_loss": -22.012502059936523, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.854326963424683, "step": 46000}
{"episode_reward": 225.4388138400042, "episode": 47.0, "batch_reward": 0.18809612438082696, "critic_loss": 0.29528031378239394, "actor_loss": -21.666637657165527, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.50308346748352, "step": 47000}
{"episode_reward": 48.17604713200735, "episode": 48.0, "batch_reward": 0.18610040184855461, "critic_loss": 0.3231422010362148, "actor_loss": -21.49847059059143, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.691664695739746, "step": 48000}
{"episode_reward": 62.96706420862587, "episode": 49.0, "batch_reward": 0.1840008812993765, "critic_loss": 0.3158356635421514, "actor_loss": -20.610132232666015, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.316085815429688, "step": 49000}
{"episode_reward": 103.94029152886911, "episode": 50.0, "batch_reward": 0.18390931324660778, "critic_loss": 0.30407194957137107, "actor_loss": -20.96430265426636, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.699547290802002, "step": 50000}
{"episode_reward": 399.83097874193624, "episode": 51.0, "batch_reward": 0.18587924018502236, "critic_loss": 0.29002518923580645, "actor_loss": -21.44443084716797, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.73124122619629, "step": 51000}
{"episode_reward": 76.38951187031554, "episode": 52.0, "batch_reward": 0.18700315518677235, "critic_loss": 0.323571048527956, "actor_loss": -21.975877864837646, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.094261646270752, "step": 52000}
{"episode_reward": 428.9116892578408, "episode": 53.0, "batch_reward": 0.19122805124521255, "critic_loss": 0.3350323970913887, "actor_loss": -22.03796708869934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.51339602470398, "step": 53000}
{"episode_reward": 316.9998111364572, "episode": 54.0, "batch_reward": 0.19433653657138347, "critic_loss": 0.3406828318685293, "actor_loss": -22.024043916702272, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.403781175613403, "step": 54000}
{"episode_reward": 416.24609405377754, "episode": 55.0, "batch_reward": 0.19726728983223438, "critic_loss": 0.3223038557171822, "actor_loss": -23.027173274993896, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.379796743392944, "step": 55000}
{"episode_reward": 456.8231426708738, "episode": 56.0, "batch_reward": 0.2006409305781126, "critic_loss": 0.3516336449831724, "actor_loss": -23.36716022491455, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.535855054855347, "step": 56000}
{"episode_reward": 153.06365137817573, "episode": 57.0, "batch_reward": 0.2011106313318014, "critic_loss": 0.357240987226367, "actor_loss": -23.48333540725708, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.311267375946045, "step": 57000}
{"episode_reward": 334.87257800058785, "episode": 58.0, "batch_reward": 0.20266833272576332, "critic_loss": 0.34507621987909076, "actor_loss": -23.860537227630616, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.124797105789185, "step": 58000}
{"episode_reward": 392.3498548335124, "episode": 59.0, "batch_reward": 0.20780010183155537, "critic_loss": 0.3968251041471958, "actor_loss": -24.27102393722534, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.0486261844635, "step": 59000}
{"episode_reward": 465.52788635921064, "episode": 60.0, "batch_reward": 0.21074585916101932, "critic_loss": 0.3725106062963605, "actor_loss": -24.416945617675783, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.677099466323853, "step": 60000}
{"episode_reward": 457.97028146049985, "episode": 61.0, "batch_reward": 0.21491659684479236, "critic_loss": 0.3619813496917486, "actor_loss": -25.29641438293457, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.63541793823242, "step": 61000}
{"episode_reward": 484.0297504865242, "episode": 62.0, "batch_reward": 0.21898963618278502, "critic_loss": 0.37578275069594386, "actor_loss": -25.235640727996827, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.586824893951416, "step": 62000}
{"episode_reward": 205.42058063204357, "episode": 63.0, "batch_reward": 0.21942386125028132, "critic_loss": 0.36853129985928534, "actor_loss": -25.890478538513182, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.894163131713867, "step": 63000}
{"episode_reward": 465.7750495331938, "episode": 64.0, "batch_reward": 0.2246025704741478, "critic_loss": 0.356141114667058, "actor_loss": -26.274996711730957, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.425523042678833, "step": 64000}
{"episode_reward": 499.09190046819356, "episode": 65.0, "batch_reward": 0.22790618786215783, "critic_loss": 0.3753188682794571, "actor_loss": -26.577691463470458, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.244534254074097, "step": 65000}
{"episode_reward": 440.399143439053, "episode": 66.0, "batch_reward": 0.2316736081391573, "critic_loss": 0.3742944787442684, "actor_loss": -27.191682777404786, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.419501066207886, "step": 66000}
{"episode_reward": 472.4574526485748, "episode": 67.0, "batch_reward": 0.2349514080286026, "critic_loss": 0.3802031851559877, "actor_loss": -27.311544910430907, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.680266857147217, "step": 67000}
{"episode_reward": 459.86535933512033, "episode": 68.0, "batch_reward": 0.2378943780809641, "critic_loss": 0.36042428413033484, "actor_loss": -27.446271236419676, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.704787731170654, "step": 68000}
{"episode_reward": 474.24159220292233, "episode": 69.0, "batch_reward": 0.24125265325605869, "critic_loss": 0.39214967742562296, "actor_loss": -28.35032413864136, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.434431552886963, "step": 69000}
{"episode_reward": 445.2691559064686, "episode": 70.0, "batch_reward": 0.24472823153436185, "critic_loss": 0.37425487810373304, "actor_loss": -28.707333854675294, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.431389570236206, "step": 70000}
{"episode_reward": 483.9069950124033, "episode": 71.0, "batch_reward": 0.24764360903203486, "critic_loss": 0.40069475281238554, "actor_loss": -28.981960929870606, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.33471179008484, "step": 71000}
{"episode_reward": 338.28894509980944, "episode": 72.0, "batch_reward": 0.24904010911285876, "critic_loss": 0.3802923077493906, "actor_loss": -29.2319729385376, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.888736248016357, "step": 72000}
{"episode_reward": 455.92798649052344, "episode": 73.0, "batch_reward": 0.2519943666607142, "critic_loss": 0.40502169519662856, "actor_loss": -29.210102104187012, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.131636381149292, "step": 73000}
{"episode_reward": 496.3115108672783, "episode": 74.0, "batch_reward": 0.2548343050926924, "critic_loss": 0.3752768722474575, "actor_loss": -29.602385524749756, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.212424278259277, "step": 74000}
{"episode_reward": 494.73744118797396, "episode": 75.0, "batch_reward": 0.2582214057445526, "critic_loss": 0.37637512780725957, "actor_loss": -30.011207160949706, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.34927749633789, "step": 75000}
{"episode_reward": 472.4294565303711, "episode": 76.0, "batch_reward": 0.2615815780609846, "critic_loss": 0.3871508083194494, "actor_loss": -30.29567512512207, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.752319812774658, "step": 76000}
{"episode_reward": 401.46174048797104, "episode": 77.0, "batch_reward": 0.2620331619232893, "critic_loss": 0.39422629699110984, "actor_loss": -30.357766578674315, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.72380828857422, "step": 77000}
{"episode_reward": 331.5769503265675, "episode": 78.0, "batch_reward": 0.2640244062691927, "critic_loss": 0.41632591535151003, "actor_loss": -30.53226830291748, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.536346435546875, "step": 78000}
{"episode_reward": 469.05669806716463, "episode": 79.0, "batch_reward": 0.26669669434428217, "critic_loss": 0.4085516162514687, "actor_loss": -30.704674808502197, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.278567790985107, "step": 79000}
{"episode_reward": 469.01131975267236, "episode": 80.0, "batch_reward": 0.26907594192028045, "critic_loss": 0.44172908064723015, "actor_loss": -30.986582851409914, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.067554235458374, "step": 80000}
{"episode_reward": 471.3100807784473, "episode": 81.0, "batch_reward": 0.27248195236921313, "critic_loss": 0.4350093365162611, "actor_loss": -31.263335868835448, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.585776567459106, "step": 81000}
{"episode_reward": 463.2867152505032, "episode": 82.0, "batch_reward": 0.27330823385715486, "critic_loss": 0.47638208790123465, "actor_loss": -31.7444181098938, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.62807059288025, "step": 82000}
{"episode_reward": 249.96854912800578, "episode": 83.0, "batch_reward": 0.27412618485093115, "critic_loss": 0.4616140886098146, "actor_loss": -31.553150939941407, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.474738836288452, "step": 83000}
{"episode_reward": 439.01066977377457, "episode": 84.0, "batch_reward": 0.27589137947559356, "critic_loss": 0.4719864440858364, "actor_loss": -31.74849464035034, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.246071815490723, "step": 84000}
{"episode_reward": 491.11456893653946, "episode": 85.0, "batch_reward": 0.2784771063625813, "critic_loss": 0.4468071097582579, "actor_loss": -32.18694624710083, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.28620219230652, "step": 85000}
{"episode_reward": 542.0157907356127, "episode": 86.0, "batch_reward": 0.28122616064548495, "critic_loss": 0.44837290233373644, "actor_loss": -32.6075221748352, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.427473068237305, "step": 86000}
{"episode_reward": 192.46201311919864, "episode": 87.0, "batch_reward": 0.28070638740062714, "critic_loss": 0.42477660678327084, "actor_loss": -32.141564460754395, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.428624391555786, "step": 87000}
{"episode_reward": 217.43830612722144, "episode": 88.0, "batch_reward": 0.277964061960578, "critic_loss": 0.5230952362269163, "actor_loss": -32.313398918151854, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.55217456817627, "step": 88000}
{"episode_reward": 172.04718392327985, "episode": 89.0, "batch_reward": 0.2768445787727833, "critic_loss": 0.4644283093363047, "actor_loss": -32.29929912567139, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.363101720809937, "step": 89000}
{"episode_reward": 122.24125593143424, "episode": 90.0, "batch_reward": 0.27816970881819725, "critic_loss": 0.48845776125788687, "actor_loss": -32.2665358543396, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.746876001358032, "step": 90000}
{"episode_reward": 508.60519293155096, "episode": 91.0, "batch_reward": 0.2797302164435387, "critic_loss": 0.48845174646377565, "actor_loss": -32.46029941558838, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.062313079833984, "step": 91000}
{"episode_reward": 521.0576100132954, "episode": 92.0, "batch_reward": 0.282968519538641, "critic_loss": 0.5373095843493938, "actor_loss": -32.60060315322876, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.335463762283325, "step": 92000}
{"episode_reward": 484.54940134000833, "episode": 93.0, "batch_reward": 0.28541999113559724, "critic_loss": 0.47633812691271304, "actor_loss": -32.99886375808716, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.570664644241333, "step": 93000}
{"episode_reward": 522.1337059483004, "episode": 94.0, "batch_reward": 0.2867029127627611, "critic_loss": 0.4806799291074276, "actor_loss": -32.91336656951904, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.358760595321655, "step": 94000}
{"episode_reward": 456.2318510307429, "episode": 95.0, "batch_reward": 0.287776934504509, "critic_loss": 0.4602412488758564, "actor_loss": -32.755561740875244, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.74365735054016, "step": 95000}
{"episode_reward": 257.7214537339509, "episode": 96.0, "batch_reward": 0.2889094850420952, "critic_loss": 0.4650802347064018, "actor_loss": -33.12217608642578, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.91085648536682, "step": 96000}
{"episode_reward": 494.07299106669234, "episode": 97.0, "batch_reward": 0.2894618997424841, "critic_loss": 0.4696279254704714, "actor_loss": -33.38437775421143, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.51587462425232, "step": 97000}
{"episode_reward": 421.0477083477462, "episode": 98.0, "batch_reward": 0.2913403156399727, "critic_loss": 0.48495449152588843, "actor_loss": -33.128360340118405, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.4977605342865, "step": 98000}
{"episode_reward": 531.5207357199455, "episode": 99.0, "batch_reward": 0.2940914988964796, "critic_loss": 0.4876702163368464, "actor_loss": -33.80675877380371, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.659707069396973, "step": 99000}
{"episode_reward": 501.46385910614094, "episode": 100.0, "batch_reward": 0.29614200673997404, "critic_loss": 0.478172142624855, "actor_loss": -33.91811848449707, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.996124744415283, "step": 100000}
{"episode_reward": 520.3995304345954, "episode": 101.0, "batch_reward": 0.2980980445742607, "critic_loss": 0.4925790350288153, "actor_loss": -34.23541292572021, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.59126543998718, "step": 101000}
{"episode_reward": 486.81444398787573, "episode": 102.0, "batch_reward": 0.29991875210404395, "critic_loss": 0.47043891867995263, "actor_loss": -34.227597885131836, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.360650062561035, "step": 102000}
{"episode_reward": 537.5130853425893, "episode": 103.0, "batch_reward": 0.30067718639969826, "critic_loss": 0.5133176773786545, "actor_loss": -34.27350120925903, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.22530221939087, "step": 103000}
{"episode_reward": 104.87200448426559, "episode": 104.0, "batch_reward": 0.3017737545967102, "critic_loss": 0.4650607092678547, "actor_loss": -34.58999097442627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.37634301185608, "step": 104000}
{"episode_reward": 509.3669388073373, "episode": 105.0, "batch_reward": 0.3027240036725998, "critic_loss": 0.4969106473326683, "actor_loss": -34.59463467025757, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.46094560623169, "step": 105000}
{"episode_reward": 518.8018014292926, "episode": 106.0, "batch_reward": 0.30416285084187983, "critic_loss": 0.4973725851178169, "actor_loss": -34.6794886932373, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.379308938980103, "step": 106000}
{"episode_reward": 491.96298537749624, "episode": 107.0, "batch_reward": 0.30672190330922605, "critic_loss": 0.4616640037894249, "actor_loss": -34.99627998352051, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.867796659469604, "step": 107000}
{"episode_reward": 505.978578771178, "episode": 108.0, "batch_reward": 0.30873992578685283, "critic_loss": 0.4617681246697903, "actor_loss": -34.79953707504272, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.311171531677246, "step": 108000}
{"episode_reward": 534.2609569151983, "episode": 109.0, "batch_reward": 0.3108463597297668, "critic_loss": 0.46343922317028047, "actor_loss": -35.20796269226074, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.399572610855103, "step": 109000}
{"episode_reward": 505.16919025395725, "episode": 110.0, "batch_reward": 0.31291107442975047, "critic_loss": 0.46065273785591127, "actor_loss": -35.188504280090335, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.695968866348267, "step": 110000}
{"episode_reward": 516.3107007935183, "episode": 111.0, "batch_reward": 0.314219662040472, "critic_loss": 0.4578030331432819, "actor_loss": -35.64757655334473, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.373501777648926, "step": 111000}
{"episode_reward": 350.3662195285641, "episode": 112.0, "batch_reward": 0.3137539560496807, "critic_loss": 0.46536388832330705, "actor_loss": -35.35883080673218, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.793094873428345, "step": 112000}
{"episode_reward": 499.31469882322745, "episode": 113.0, "batch_reward": 0.3161823052465916, "critic_loss": 0.4912554637789726, "actor_loss": -35.72326211547851, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.404622793197632, "step": 113000}
{"episode_reward": 390.68003646671303, "episode": 114.0, "batch_reward": 0.31675602558255195, "critic_loss": 0.46559973557293416, "actor_loss": -35.61160744857788, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.080665826797485, "step": 114000}
{"episode_reward": 509.1405340974345, "episode": 115.0, "batch_reward": 0.3196875314116478, "critic_loss": 0.5031414219290018, "actor_loss": -36.01431224441529, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.546626806259155, "step": 115000}
{"episode_reward": 555.7190379054266, "episode": 116.0, "batch_reward": 0.32141427871584893, "critic_loss": 0.4882801852375269, "actor_loss": -36.087355655670166, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.331389904022217, "step": 116000}
{"episode_reward": 484.09092208452273, "episode": 117.0, "batch_reward": 0.32330681347846985, "critic_loss": 0.4638934904187918, "actor_loss": -36.42143231201172, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.64811420440674, "step": 117000}
{"episode_reward": 502.8410685479401, "episode": 118.0, "batch_reward": 0.32308608122169974, "critic_loss": 0.4864695276319981, "actor_loss": -36.372303497314455, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.211902379989624, "step": 118000}
{"episode_reward": 499.90708596047807, "episode": 119.0, "batch_reward": 0.32553866937756537, "critic_loss": 0.49492073364555833, "actor_loss": -36.65635624694824, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.511496782302856, "step": 119000}
{"episode_reward": 507.2767932205612, "episode": 120.0, "batch_reward": 0.3258914597928524, "critic_loss": 0.5405784120112658, "actor_loss": -36.500479652404785, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.25295901298523, "step": 120000}
{"episode_reward": 504.8622562060151, "episode": 121.0, "batch_reward": 0.3278813195824623, "critic_loss": 0.510378681614995, "actor_loss": -36.666444133758546, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.717114210128784, "step": 121000}
{"episode_reward": 535.898012090537, "episode": 122.0, "batch_reward": 0.32978633791208267, "critic_loss": 0.5487874590754509, "actor_loss": -36.81766829681396, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.53702688217163, "step": 122000}
{"episode_reward": 528.4902130022083, "episode": 123.0, "batch_reward": 0.3316987144649029, "critic_loss": 0.5026995359808206, "actor_loss": -37.090223014831544, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.702281713485718, "step": 123000}
{"episode_reward": 528.5601035504028, "episode": 124.0, "batch_reward": 0.3329224523305893, "critic_loss": 0.4835218763500452, "actor_loss": -37.01435029220581, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.976921558380127, "step": 124000}
{"episode_reward": 483.787922538612, "episode": 125.0, "batch_reward": 0.33367936858534814, "critic_loss": 0.46845643439888957, "actor_loss": -37.21958235931397, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.197968244552612, "step": 125000}
{"episode_reward": 499.2561950411904, "episode": 126.0, "batch_reward": 0.33549082455039025, "critic_loss": 0.485206063747406, "actor_loss": -37.288534690856935, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.344070196151733, "step": 126000}
{"episode_reward": 458.4729805746798, "episode": 127.0, "batch_reward": 0.3369052268564701, "critic_loss": 0.5503739133179187, "actor_loss": -37.39367698669434, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.673198699951172, "step": 127000}
{"episode_reward": 543.543593649424, "episode": 128.0, "batch_reward": 0.33762999495863916, "critic_loss": 0.4746183767616749, "actor_loss": -37.49897403717041, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.674160957336426, "step": 128000}
{"episode_reward": 522.5367540450253, "episode": 129.0, "batch_reward": 0.3397141011059284, "critic_loss": 0.43567878705263136, "actor_loss": -37.72038780212402, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.619108200073242, "step": 129000}
{"episode_reward": 515.6602018105943, "episode": 130.0, "batch_reward": 0.34017071503400803, "critic_loss": 0.42959952484071257, "actor_loss": -37.73849238204956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.449316263198853, "step": 130000}
{"episode_reward": 366.9360924645975, "episode": 131.0, "batch_reward": 0.34145436543226243, "critic_loss": 0.478821319386363, "actor_loss": -37.88326238632202, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.73540639877319, "step": 131000}
{"episode_reward": 503.19289816548456, "episode": 132.0, "batch_reward": 0.34206833922863006, "critic_loss": 0.4667888016849756, "actor_loss": -37.66904719543457, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.48019814491272, "step": 132000}
{"episode_reward": 504.7890316151606, "episode": 133.0, "batch_reward": 0.34364322847127915, "critic_loss": 0.46758942647278307, "actor_loss": -38.0966926651001, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.509167909622192, "step": 133000}
{"episode_reward": 513.4594697061286, "episode": 134.0, "batch_reward": 0.3447442794442177, "critic_loss": 0.509687304392457, "actor_loss": -38.025404956817624, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.463943481445312, "step": 134000}
{"episode_reward": 493.5144477614784, "episode": 135.0, "batch_reward": 0.3445395387709141, "critic_loss": 0.5019876206070185, "actor_loss": -37.88787326812744, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.472538232803345, "step": 135000}
{"episode_reward": 493.13550997244084, "episode": 136.0, "batch_reward": 0.3477754128575325, "critic_loss": 0.4908171913474798, "actor_loss": -38.22116690063476, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.74449324607849, "step": 136000}
{"episode_reward": 531.6054537266361, "episode": 137.0, "batch_reward": 0.3485804917216301, "critic_loss": 0.46630173003673553, "actor_loss": -38.31506916046143, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.385462045669556, "step": 137000}
{"episode_reward": 531.005459541347, "episode": 138.0, "batch_reward": 0.3498214969933033, "critic_loss": 0.5323195665180683, "actor_loss": -38.35633679962158, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.178133964538574, "step": 138000}
{"episode_reward": 511.5238181157234, "episode": 139.0, "batch_reward": 0.35085582718253133, "critic_loss": 0.48798847977817056, "actor_loss": -38.536386222839354, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.506741285324097, "step": 139000}
{"episode_reward": 540.6983590699565, "episode": 140.0, "batch_reward": 0.35109411644935606, "critic_loss": 0.45354535123705864, "actor_loss": -38.33930303192139, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.316457748413086, "step": 140000}
{"episode_reward": 519.5300133158779, "episode": 141.0, "batch_reward": 0.354294887393713, "critic_loss": 0.43888239639997484, "actor_loss": -38.80201725769043, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.6740026473999, "step": 141000}
{"episode_reward": 549.680091839026, "episode": 142.0, "batch_reward": 0.35521315956115723, "critic_loss": 0.4248220631480217, "actor_loss": -38.88936897277832, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.64552092552185, "step": 142000}
{"episode_reward": 483.34059528955726, "episode": 143.0, "batch_reward": 0.355591123521328, "critic_loss": 0.4245428612083197, "actor_loss": -39.05627780151367, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.147772550582886, "step": 143000}
{"episode_reward": 524.4461905320056, "episode": 144.0, "batch_reward": 0.3573222441971302, "critic_loss": 0.4808480477631092, "actor_loss": -38.87773323059082, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.301836013793945, "step": 144000}
{"episode_reward": 482.5155190141282, "episode": 145.0, "batch_reward": 0.35722076943516734, "critic_loss": 0.43827433095872403, "actor_loss": -38.87018286895752, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.17617917060852, "step": 145000}
{"episode_reward": 543.2847990816151, "episode": 146.0, "batch_reward": 0.3586634857356548, "critic_loss": 0.40812887996435165, "actor_loss": -39.27310583496094, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.613084316253662, "step": 146000}
{"episode_reward": 501.48291875611767, "episode": 147.0, "batch_reward": 0.3588340151011944, "critic_loss": 0.407797285400331, "actor_loss": -39.170215785980226, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.403274059295654, "step": 147000}
{"episode_reward": 494.5139670208104, "episode": 148.0, "batch_reward": 0.36082305398583414, "critic_loss": 0.4286362039074302, "actor_loss": -39.20457308197022, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.470443725585938, "step": 148000}
{"episode_reward": 513.8453341627779, "episode": 149.0, "batch_reward": 0.3624777272939682, "critic_loss": 0.42589013085514305, "actor_loss": -39.37580612945557, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.70753026008606, "step": 149000}
{"episode_reward": 545.9107976033205, "episode": 150.0, "batch_reward": 0.3637082135379314, "critic_loss": 0.390316127166152, "actor_loss": -39.38499760437012, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
