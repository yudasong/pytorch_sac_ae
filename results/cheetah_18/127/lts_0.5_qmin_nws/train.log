{"episode_reward": 0.0, "episode": 1.0, "duration": 20.427358388900757, "step": 1000}
{"episode_reward": 7.051849146674556, "episode": 2.0, "duration": 1.948909044265747, "step": 2000}
{"episode_reward": 365.4711839680396, "episode": 3.0, "batch_reward": 0.175905024657034, "critic_loss": 0.03790006947928183, "actor_loss": -19.56310700451364, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 66.12811422348022, "step": 3000}
{"episode_reward": 39.73830541030422, "episode": 4.0, "batch_reward": 0.12110427360981703, "critic_loss": 0.03200663838814944, "actor_loss": -15.661193605422973, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.76484775543213, "step": 4000}
{"episode_reward": 17.730629104851715, "episode": 5.0, "batch_reward": 0.10047839406132698, "critic_loss": 0.034230471773073076, "actor_loss": -15.119058113858104, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.215723514556885, "step": 5000}
{"episode_reward": 52.43361702299001, "episode": 6.0, "batch_reward": 0.09116959460824728, "critic_loss": 0.04761394740454852, "actor_loss": -15.937716833502055, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.600970029830933, "step": 6000}
{"episode_reward": 56.919416917355285, "episode": 7.0, "batch_reward": 0.09077287315577269, "critic_loss": 0.0773520568460226, "actor_loss": -14.67191203918308, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.356264114379883, "step": 7000}
{"episode_reward": 109.62997943997264, "episode": 8.0, "batch_reward": 0.08810456481948495, "critic_loss": 0.08447147531062364, "actor_loss": -14.419205027811229, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.453081369400024, "step": 8000}
{"episode_reward": 23.453556874655355, "episode": 9.0, "batch_reward": 0.08242167178168892, "critic_loss": 0.08477202620729804, "actor_loss": -15.051391735978424, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.037245512008667, "step": 9000}
{"episode_reward": 49.98761825869353, "episode": 10.0, "batch_reward": 0.08473638217896223, "critic_loss": 0.09804461839050055, "actor_loss": -14.795462916582823, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.341490507125854, "step": 10000}
{"episode_reward": 154.76457614941089, "episode": 11.0, "batch_reward": 0.09203710275888442, "critic_loss": 0.11933281641080976, "actor_loss": -15.064860850021244, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.788623571395874, "step": 11000}
{"episode_reward": 190.2114579749825, "episode": 12.0, "batch_reward": 0.10168911742419004, "critic_loss": 0.1471522588059306, "actor_loss": -15.78070215958357, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.184908628463745, "step": 12000}
{"episode_reward": 222.91723782330803, "episode": 13.0, "batch_reward": 0.1064205127954483, "critic_loss": 0.1718227196931839, "actor_loss": -15.694883889913559, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.84212303161621, "step": 13000}
{"episode_reward": 46.667055937996565, "episode": 14.0, "batch_reward": 0.10129450179636479, "critic_loss": 0.15588745757192374, "actor_loss": -15.144176300764084, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.53392505645752, "step": 14000}
{"episode_reward": 28.974323521433337, "episode": 15.0, "batch_reward": 0.09592135313153267, "critic_loss": 0.14209187227860093, "actor_loss": -15.209901233673095, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.280410289764404, "step": 15000}
{"episode_reward": 27.64964521335935, "episode": 16.0, "batch_reward": 0.09665940042585135, "critic_loss": 0.15246916959434748, "actor_loss": -14.693923588991165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.76399302482605, "step": 16000}
{"episode_reward": 157.76216842100158, "episode": 17.0, "batch_reward": 0.0958553738668561, "critic_loss": 0.15624210770055652, "actor_loss": -14.209824247598648, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.35665202140808, "step": 17000}
{"episode_reward": 37.64571868587973, "episode": 18.0, "batch_reward": 0.09784834030643105, "critic_loss": 0.16611648412048816, "actor_loss": -14.367504897117614, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.448039054870605, "step": 18000}
{"episode_reward": 209.57321504447145, "episode": 19.0, "batch_reward": 0.09847111945971847, "critic_loss": 0.1439487804323435, "actor_loss": -14.079188249111176, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.387212991714478, "step": 19000}
{"episode_reward": 26.856999667987793, "episode": 20.0, "batch_reward": 0.09605437652766705, "critic_loss": 0.13472978195175528, "actor_loss": -14.61410243844986, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.042750597000122, "step": 20000}
{"episode_reward": 63.16778177067282, "episode": 21.0, "batch_reward": 0.09517181722447277, "critic_loss": 0.13415945379436017, "actor_loss": -12.728991844892501, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.14191508293152, "step": 21000}
{"episode_reward": 62.52568592099533, "episode": 22.0, "batch_reward": 0.09572897181659937, "critic_loss": 0.14703479264676572, "actor_loss": -14.37158816075325, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.34100842475891, "step": 22000}
{"episode_reward": 235.52364906691366, "episode": 23.0, "batch_reward": 0.09966043558716774, "critic_loss": 0.16043856403976678, "actor_loss": -14.077452467918397, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.579320669174194, "step": 23000}
{"episode_reward": 56.806737759593595, "episode": 24.0, "batch_reward": 0.09802362988144159, "critic_loss": 0.17489460092037917, "actor_loss": -13.834291815757751, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.561642169952393, "step": 24000}
{"episode_reward": 77.89565831691529, "episode": 25.0, "batch_reward": 0.09899393658339978, "critic_loss": 0.17850945053249598, "actor_loss": -14.184639485359192, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.865524768829346, "step": 25000}
{"episode_reward": 146.6967006880235, "episode": 26.0, "batch_reward": 0.10177510041743516, "critic_loss": 0.15185676927864553, "actor_loss": -14.058784637928008, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.5932879447937, "step": 26000}
{"episode_reward": 241.27454244717418, "episode": 27.0, "batch_reward": 0.10654539564996958, "critic_loss": 0.1832124083712697, "actor_loss": -14.125586213111877, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.69685196876526, "step": 27000}
{"episode_reward": 152.9813243437034, "episode": 28.0, "batch_reward": 0.11053658667206764, "critic_loss": 0.18723340526223184, "actor_loss": -14.866918116569519, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.30156707763672, "step": 28000}
{"episode_reward": 307.1200135811776, "episode": 29.0, "batch_reward": 0.11411802464723587, "critic_loss": 0.1956636013686657, "actor_loss": -15.003509815216065, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.764375925064087, "step": 29000}
{"episode_reward": 128.12119504663715, "episode": 30.0, "batch_reward": 0.11652638802677392, "critic_loss": 0.17007916992902755, "actor_loss": -14.280142946720122, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.162111520767212, "step": 30000}
{"episode_reward": 223.6130648162632, "episode": 31.0, "batch_reward": 0.11807664766907693, "critic_loss": 0.20733021080493927, "actor_loss": -15.109319881439209, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.81347918510437, "step": 31000}
{"episode_reward": 189.36085431717953, "episode": 32.0, "batch_reward": 0.12173463380336762, "critic_loss": 0.18089713677763938, "actor_loss": -16.132014073371888, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.354145050048828, "step": 32000}
{"episode_reward": 166.5559975466634, "episode": 33.0, "batch_reward": 0.12396970081329346, "critic_loss": 0.16527202331274748, "actor_loss": -16.21393306541443, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.614680767059326, "step": 33000}
{"episode_reward": 296.2737302663145, "episode": 34.0, "batch_reward": 0.12878824877738954, "critic_loss": 0.1806929603740573, "actor_loss": -15.846710687637328, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.652909517288208, "step": 34000}
{"episode_reward": 310.72997019008085, "episode": 35.0, "batch_reward": 0.1338638778179884, "critic_loss": 0.16031317188590766, "actor_loss": -16.852938164711, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.709160327911377, "step": 35000}
{"episode_reward": 324.08504817687776, "episode": 36.0, "batch_reward": 0.13991111787408592, "critic_loss": 0.1666300935074687, "actor_loss": -17.465326899528502, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.403714418411255, "step": 36000}
{"episode_reward": 301.23103540100567, "episode": 37.0, "batch_reward": 0.1434316041395068, "critic_loss": 0.1924051620066166, "actor_loss": -17.15938992023468, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.139923572540283, "step": 37000}
{"episode_reward": 281.36617455982343, "episode": 38.0, "batch_reward": 0.14672610801458358, "critic_loss": 0.20050315155088902, "actor_loss": -17.69432948112488, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.709571361541748, "step": 38000}
{"episode_reward": 169.72346558104283, "episode": 39.0, "batch_reward": 0.14894601283967496, "critic_loss": 0.20897664562612772, "actor_loss": -17.643066158294676, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.102163791656494, "step": 39000}
{"episode_reward": 338.5814155040656, "episode": 40.0, "batch_reward": 0.1531332103088498, "critic_loss": 0.2076569856777787, "actor_loss": -18.108334443092346, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.937426328659058, "step": 40000}
{"episode_reward": 308.45981962909707, "episode": 41.0, "batch_reward": 0.15593584965914487, "critic_loss": 0.22733393517136574, "actor_loss": -18.150684122085572, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.81829571723938, "step": 41000}
{"episode_reward": 202.04133151548928, "episode": 42.0, "batch_reward": 0.15802735420316458, "critic_loss": 0.23888192472606898, "actor_loss": -18.624016348838808, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.878144025802612, "step": 42000}
{"episode_reward": 326.35814569056004, "episode": 43.0, "batch_reward": 0.16112157287448645, "critic_loss": 0.2602302729189396, "actor_loss": -19.54174425315857, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.4634051322937, "step": 43000}
{"episode_reward": 207.3777838293552, "episode": 44.0, "batch_reward": 0.16339317535609008, "critic_loss": 0.26877660454809665, "actor_loss": -20.337280647277833, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.65550971031189, "step": 44000}
{"episode_reward": 361.64893075554807, "episode": 45.0, "batch_reward": 0.16591563829034567, "critic_loss": 0.28781074552983044, "actor_loss": -19.82770924949646, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.694791793823242, "step": 45000}
{"episode_reward": 145.62870542463855, "episode": 46.0, "batch_reward": 0.16664958862960338, "critic_loss": 0.3251338745504618, "actor_loss": -19.59372137451172, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.958465576171875, "step": 46000}
{"episode_reward": 301.61541922955325, "episode": 47.0, "batch_reward": 0.16812600429356098, "critic_loss": 0.32702692703157665, "actor_loss": -20.167109035491944, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.48331379890442, "step": 47000}
{"episode_reward": 60.44280684284504, "episode": 48.0, "batch_reward": 0.16794231468439103, "critic_loss": 0.33833777624368666, "actor_loss": -20.21046803855896, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.411715507507324, "step": 48000}
{"episode_reward": 323.5509559886996, "episode": 49.0, "batch_reward": 0.1720856650918722, "critic_loss": 0.35127900265157225, "actor_loss": -21.461987188339233, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.095808506011963, "step": 49000}
{"episode_reward": 390.1065955188647, "episode": 50.0, "batch_reward": 0.17504935197532176, "critic_loss": 0.38155434419214723, "actor_loss": -21.27981859588623, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.334367275238037, "step": 50000}
{"episode_reward": 362.69170006290136, "episode": 51.0, "batch_reward": 0.17838561721146107, "critic_loss": 0.40045786878466605, "actor_loss": -21.25397966003418, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.44556665420532, "step": 51000}
{"episode_reward": 191.5803702854624, "episode": 52.0, "batch_reward": 0.18033228331804277, "critic_loss": 0.3925812629163265, "actor_loss": -21.76777932167053, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.539008617401123, "step": 52000}
{"episode_reward": 417.6133203862218, "episode": 53.0, "batch_reward": 0.18417337468266487, "critic_loss": 0.42594334280490875, "actor_loss": -22.854108531951905, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.8285493850708, "step": 53000}
{"episode_reward": 334.07848266136523, "episode": 54.0, "batch_reward": 0.1863909605294466, "critic_loss": 0.3894229973852634, "actor_loss": -23.141908201217653, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.186294317245483, "step": 54000}
{"episode_reward": 347.8195407914621, "episode": 55.0, "batch_reward": 0.1895123589783907, "critic_loss": 0.38548848368227484, "actor_loss": -22.706107860565186, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.33259129524231, "step": 55000}
{"episode_reward": 394.7437519482835, "episode": 56.0, "batch_reward": 0.19431551124155522, "critic_loss": 0.38163292668759824, "actor_loss": -23.36829787826538, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.496796369552612, "step": 56000}
{"episode_reward": 432.99683667594553, "episode": 57.0, "batch_reward": 0.1984942130893469, "critic_loss": 0.40650328186154366, "actor_loss": -23.688726242065428, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.808099031448364, "step": 57000}
{"episode_reward": 381.20776853996233, "episode": 58.0, "batch_reward": 0.2003712430894375, "critic_loss": 0.3997144769281149, "actor_loss": -24.615683372497557, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.449334621429443, "step": 58000}
{"episode_reward": 137.2205130420627, "episode": 59.0, "batch_reward": 0.20074767465889454, "critic_loss": 0.41295923592150213, "actor_loss": -24.29067087173462, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.76334857940674, "step": 59000}
{"episode_reward": 297.0847698804846, "episode": 60.0, "batch_reward": 0.20202526226639747, "critic_loss": 0.4249496174603701, "actor_loss": -24.733677862167358, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.68254852294922, "step": 60000}
{"episode_reward": 394.07217918492455, "episode": 61.0, "batch_reward": 0.20547906006872654, "critic_loss": 0.4452514320909977, "actor_loss": -24.55061336708069, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.296802043914795, "step": 61000}
{"episode_reward": 449.84388308473893, "episode": 62.0, "batch_reward": 0.20882925152778625, "critic_loss": 0.40363951402902604, "actor_loss": -25.6849490070343, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.965199947357178, "step": 62000}
{"episode_reward": 410.7931651204433, "episode": 63.0, "batch_reward": 0.21182886691391467, "critic_loss": 0.42361981406807897, "actor_loss": -25.102520523071288, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.746410846710205, "step": 63000}
{"episode_reward": 225.35732048531054, "episode": 64.0, "batch_reward": 0.2112741885483265, "critic_loss": 0.4360437695533037, "actor_loss": -25.673679244995117, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.35423231124878, "step": 64000}
{"episode_reward": 131.26483727038192, "episode": 65.0, "batch_reward": 0.21160189804434776, "critic_loss": 0.46049265821278096, "actor_loss": -25.41653694343567, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.647038221359253, "step": 65000}
{"episode_reward": 420.7616950722087, "episode": 66.0, "batch_reward": 0.2146220407038927, "critic_loss": 0.44294521287083627, "actor_loss": -25.967889434814452, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.54316473007202, "step": 66000}
{"episode_reward": 409.7336154485803, "episode": 67.0, "batch_reward": 0.2167258532345295, "critic_loss": 0.47074436512589457, "actor_loss": -26.52447710418701, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.55715584754944, "step": 67000}
{"episode_reward": 400.7593185276243, "episode": 68.0, "batch_reward": 0.21985881939530372, "critic_loss": 0.4557689214646816, "actor_loss": -27.010403663635255, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.983801126480103, "step": 68000}
{"episode_reward": 370.9489666617091, "episode": 69.0, "batch_reward": 0.2220497811436653, "critic_loss": 0.44671687033772467, "actor_loss": -26.576794975280762, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.454243421554565, "step": 69000}
{"episode_reward": 436.5128203994256, "episode": 70.0, "batch_reward": 0.224569602817297, "critic_loss": 0.44771636128425596, "actor_loss": -26.82205774307251, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.58103322982788, "step": 70000}
{"episode_reward": 206.60761768642473, "episode": 71.0, "batch_reward": 0.22521544283628464, "critic_loss": 0.4601198698580265, "actor_loss": -26.73537699508667, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.61567783355713, "step": 71000}
{"episode_reward": 411.4611099717483, "episode": 72.0, "batch_reward": 0.22758234660327434, "critic_loss": 0.4567601348906755, "actor_loss": -26.944624496459962, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.925974130630493, "step": 72000}
{"episode_reward": 168.58973274480041, "episode": 73.0, "batch_reward": 0.22744045320153236, "critic_loss": 0.48241543017327787, "actor_loss": -27.050319271087645, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.750162601470947, "step": 73000}
{"episode_reward": 447.45362257682484, "episode": 74.0, "batch_reward": 0.23018696427345275, "critic_loss": 0.5312504706829786, "actor_loss": -27.43470863342285, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.58710527420044, "step": 74000}
{"episode_reward": 344.926015781882, "episode": 75.0, "batch_reward": 0.2301715099364519, "critic_loss": 0.4882068260163069, "actor_loss": -27.407112129211427, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.45783233642578, "step": 75000}
{"episode_reward": 339.4124814958345, "episode": 76.0, "batch_reward": 0.23329619857668876, "critic_loss": 0.5104875817000866, "actor_loss": -27.534696586608888, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.329770803451538, "step": 76000}
{"episode_reward": 457.56434576636246, "episode": 77.0, "batch_reward": 0.23612893441319466, "critic_loss": 0.49858929379284384, "actor_loss": -28.13308874130249, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.90396022796631, "step": 77000}
{"episode_reward": 477.4819845948184, "episode": 78.0, "batch_reward": 0.23892427004873754, "critic_loss": 0.49650013287365435, "actor_loss": -28.149860748291015, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.637761116027832, "step": 78000}
{"episode_reward": 428.58258207613017, "episode": 79.0, "batch_reward": 0.241708861887455, "critic_loss": 0.5711350124031306, "actor_loss": -28.96027906036377, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.60458517074585, "step": 79000}
{"episode_reward": 429.8729154933627, "episode": 80.0, "batch_reward": 0.24382741509377956, "critic_loss": 0.5437180011868477, "actor_loss": -29.033118347167967, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.49619722366333, "step": 80000}
{"episode_reward": 464.3898924549046, "episode": 81.0, "batch_reward": 0.246037612631917, "critic_loss": 0.5261788226813078, "actor_loss": -29.186157634735107, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.950376749038696, "step": 81000}
{"episode_reward": 324.37608971249097, "episode": 82.0, "batch_reward": 0.2475242565870285, "critic_loss": 0.5751167367249728, "actor_loss": -29.028338150024414, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.165335416793823, "step": 82000}
{"episode_reward": 489.3675519102751, "episode": 83.0, "batch_reward": 0.2507111737728119, "critic_loss": 0.5607165635377168, "actor_loss": -29.55034164428711, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.778050661087036, "step": 83000}
{"episode_reward": 473.7640852630479, "episode": 84.0, "batch_reward": 0.2525516878664494, "critic_loss": 0.5499242285341024, "actor_loss": -29.91963972854614, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.481019496917725, "step": 84000}
{"episode_reward": 416.7275868118562, "episode": 85.0, "batch_reward": 0.2549465407580137, "critic_loss": 0.5808016985356808, "actor_loss": -29.756330673217775, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.03646159172058, "step": 85000}
{"episode_reward": 408.79624080571483, "episode": 86.0, "batch_reward": 0.257275795802474, "critic_loss": 0.5648696563392878, "actor_loss": -29.926835388183594, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.4110004901886, "step": 86000}
{"episode_reward": 457.7112977310186, "episode": 87.0, "batch_reward": 0.25999940690398216, "critic_loss": 0.5923709844052791, "actor_loss": -30.47145793914795, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.590435028076172, "step": 87000}
{"episode_reward": 434.4299231882312, "episode": 88.0, "batch_reward": 0.2597073984742165, "critic_loss": 0.5983573362380267, "actor_loss": -30.27939874649048, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.287144422531128, "step": 88000}
{"episode_reward": 142.23503934326658, "episode": 89.0, "batch_reward": 0.25974503335356713, "critic_loss": 0.554885668054223, "actor_loss": -29.824690090179445, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.88563823699951, "step": 89000}
{"episode_reward": 449.58471231389984, "episode": 90.0, "batch_reward": 0.26298885484039786, "critic_loss": 0.6381292818039656, "actor_loss": -30.163333034515382, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.291456699371338, "step": 90000}
{"episode_reward": 378.2899954723208, "episode": 91.0, "batch_reward": 0.2630657419413328, "critic_loss": 0.5877086971998214, "actor_loss": -30.022997398376464, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.62190818786621, "step": 91000}
{"episode_reward": 499.021340956951, "episode": 92.0, "batch_reward": 0.2666531622558832, "critic_loss": 0.5878918106108904, "actor_loss": -31.0197338142395, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.729613304138184, "step": 92000}
{"episode_reward": 357.6126477267065, "episode": 93.0, "batch_reward": 0.266504602894187, "critic_loss": 0.5674899675250054, "actor_loss": -30.259908321380614, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.72588801383972, "step": 93000}
{"episode_reward": 467.41860518722063, "episode": 94.0, "batch_reward": 0.26964769077301026, "critic_loss": 0.5498398651629687, "actor_loss": -31.124101058959962, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.253928899765015, "step": 94000}
{"episode_reward": 468.9077492014997, "episode": 95.0, "batch_reward": 0.27137405478954313, "critic_loss": 0.5961307921409607, "actor_loss": -31.555158473968508, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.17011046409607, "step": 95000}
{"episode_reward": 466.04384358907504, "episode": 96.0, "batch_reward": 0.2739190889596939, "critic_loss": 0.6168408139497041, "actor_loss": -31.10607323074341, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.67043685913086, "step": 96000}
{"episode_reward": 438.09068239987016, "episode": 97.0, "batch_reward": 0.2753866565823555, "critic_loss": 0.5869385797828436, "actor_loss": -31.104462490081787, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.17518448829651, "step": 97000}
{"episode_reward": 516.0168508557916, "episode": 98.0, "batch_reward": 0.2774063789844513, "critic_loss": 0.5398453823328018, "actor_loss": -31.91885629272461, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.359160661697388, "step": 98000}
{"episode_reward": 473.08272064151447, "episode": 99.0, "batch_reward": 0.28016782069206236, "critic_loss": 0.5376515531092882, "actor_loss": -32.0595396194458, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.695190906524658, "step": 99000}
{"episode_reward": 471.68656725179727, "episode": 100.0, "batch_reward": 0.2802529223412275, "critic_loss": 0.5403591251671315, "actor_loss": -31.917120002746582, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.71012854576111, "step": 100000}
{"episode_reward": 117.16189218953859, "episode": 101.0, "batch_reward": 0.28019159123301507, "critic_loss": 0.5503939422369003, "actor_loss": -31.767865482330322, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.44578504562378, "step": 101000}
{"episode_reward": 492.2587324149552, "episode": 102.0, "batch_reward": 0.28161069212853906, "critic_loss": 0.5829502206891776, "actor_loss": -32.13554871749878, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.811150789260864, "step": 102000}
{"episode_reward": 367.36782940600074, "episode": 103.0, "batch_reward": 0.2817026454657316, "critic_loss": 0.5311439046412706, "actor_loss": -32.06767665481567, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.69346857070923, "step": 103000}
{"episode_reward": 298.0543545845576, "episode": 104.0, "batch_reward": 0.2833037521094084, "critic_loss": 0.5508873757869005, "actor_loss": -31.739320014953613, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.752825260162354, "step": 104000}
{"episode_reward": 500.0370519738471, "episode": 105.0, "batch_reward": 0.2855893175303936, "critic_loss": 0.5000533982217312, "actor_loss": -32.15930522155762, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.4006826877594, "step": 105000}
{"episode_reward": 483.679379880028, "episode": 106.0, "batch_reward": 0.2873290421962738, "critic_loss": 0.5264862499088049, "actor_loss": -32.18416861343384, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.89545202255249, "step": 106000}
{"episode_reward": 474.8105732132166, "episode": 107.0, "batch_reward": 0.2885984044522047, "critic_loss": 0.45801722338795664, "actor_loss": -32.302351081848144, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.318480253219604, "step": 107000}
{"episode_reward": 472.993734350134, "episode": 108.0, "batch_reward": 0.2908980564177036, "critic_loss": 0.4960235995054245, "actor_loss": -33.0937696685791, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.013015508651733, "step": 108000}
{"episode_reward": 468.12773454609476, "episode": 109.0, "batch_reward": 0.29248485165834426, "critic_loss": 0.4814568575173616, "actor_loss": -32.79590584945679, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.165695190429688, "step": 109000}
{"episode_reward": 484.73081819073093, "episode": 110.0, "batch_reward": 0.29443061353266237, "critic_loss": 0.4700182354003191, "actor_loss": -33.160116844177246, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.770873546600342, "step": 110000}
{"episode_reward": 501.137155268759, "episode": 111.0, "batch_reward": 0.29544104082882405, "critic_loss": 0.49832952401041986, "actor_loss": -33.01671866607666, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.389660358428955, "step": 111000}
{"episode_reward": 452.7687628852917, "episode": 112.0, "batch_reward": 0.29720571148395536, "critic_loss": 0.4949720473885536, "actor_loss": -33.619876613616945, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.22175693511963, "step": 112000}
{"episode_reward": 455.2783005315926, "episode": 113.0, "batch_reward": 0.29734130093455313, "critic_loss": 0.47149445340037344, "actor_loss": -32.89110886383057, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.70158624649048, "step": 113000}
{"episode_reward": 88.51770755583415, "episode": 114.0, "batch_reward": 0.2964073797315359, "critic_loss": 0.5379636624604464, "actor_loss": -33.320062633514404, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.25624942779541, "step": 114000}
{"episode_reward": 439.30500020533196, "episode": 115.0, "batch_reward": 0.2977879829853773, "critic_loss": 0.4978635414093733, "actor_loss": -33.27214631271362, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.43997836112976, "step": 115000}
{"episode_reward": 459.12663810758755, "episode": 116.0, "batch_reward": 0.2999293910264969, "critic_loss": 0.5022492767125368, "actor_loss": -33.4374871635437, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.306389808654785, "step": 116000}
{"episode_reward": 509.8199857450091, "episode": 117.0, "batch_reward": 0.302304410636425, "critic_loss": 0.4525301580429077, "actor_loss": -33.363203769683835, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.398064613342285, "step": 117000}
{"episode_reward": 505.95828306770693, "episode": 118.0, "batch_reward": 0.3027402786761522, "critic_loss": 0.44493154798448087, "actor_loss": -33.506909732818606, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.896589040756226, "step": 118000}
{"episode_reward": 484.82126038506584, "episode": 119.0, "batch_reward": 0.30346498584747317, "critic_loss": 0.4655035062730312, "actor_loss": -33.48533557891846, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.282899856567383, "step": 119000}
{"episode_reward": 481.87427556380476, "episode": 120.0, "batch_reward": 0.30494017511606214, "critic_loss": 0.4559906426370144, "actor_loss": -33.722738941192624, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.172340154647827, "step": 120000}
{"episode_reward": 230.88743143794332, "episode": 121.0, "batch_reward": 0.3055575187653303, "critic_loss": 0.48482770717144014, "actor_loss": -33.708169288635254, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.42647624015808, "step": 121000}
{"episode_reward": 507.6324766442629, "episode": 122.0, "batch_reward": 0.3062174972295761, "critic_loss": 0.5459238841235637, "actor_loss": -34.09277356719971, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.32407855987549, "step": 122000}
{"episode_reward": 439.9192250805358, "episode": 123.0, "batch_reward": 0.30860248976945875, "critic_loss": 0.47196057032048705, "actor_loss": -34.28977687835693, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.393621683120728, "step": 123000}
{"episode_reward": 471.7670513019372, "episode": 124.0, "batch_reward": 0.3099559822976589, "critic_loss": 0.48996639482676985, "actor_loss": -34.49663469314575, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.79946255683899, "step": 124000}
{"episode_reward": 500.11421252301346, "episode": 125.0, "batch_reward": 0.31011206340789793, "critic_loss": 0.4436409242749214, "actor_loss": -34.24494002532959, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.047025442123413, "step": 125000}
{"episode_reward": 490.8583454682593, "episode": 126.0, "batch_reward": 0.3125513819754124, "critic_loss": 0.45940938583016394, "actor_loss": -34.718114933013915, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.438390493392944, "step": 126000}
{"episode_reward": 460.5191984827459, "episode": 127.0, "batch_reward": 0.3131436847448349, "critic_loss": 0.45371236631274225, "actor_loss": -34.8436307220459, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.030439376831055, "step": 127000}
{"episode_reward": 454.99513024019063, "episode": 128.0, "batch_reward": 0.31475811171531676, "critic_loss": 0.477428781658411, "actor_loss": -34.93324609375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.65718173980713, "step": 128000}
{"episode_reward": 499.32986068460474, "episode": 129.0, "batch_reward": 0.3162986683547497, "critic_loss": 0.49850832028687, "actor_loss": -34.936237815856934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.545879364013672, "step": 129000}
{"episode_reward": 481.28537021829123, "episode": 130.0, "batch_reward": 0.317223941296339, "critic_loss": 0.5478714566230773, "actor_loss": -34.91556688308716, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.34120750427246, "step": 130000}
{"episode_reward": 503.1844332401761, "episode": 131.0, "batch_reward": 0.3194453103542328, "critic_loss": 0.4969168076366186, "actor_loss": -35.11432400512695, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.547465801239014, "step": 131000}
{"episode_reward": 476.6604988422076, "episode": 132.0, "batch_reward": 0.3191687438488007, "critic_loss": 0.46993754236400126, "actor_loss": -35.066889991760256, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.697453260421753, "step": 132000}
{"episode_reward": 200.45056617005963, "episode": 133.0, "batch_reward": 0.3194419360756874, "critic_loss": 0.5213323820978403, "actor_loss": -34.787610092163085, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.4366397857666, "step": 133000}
{"episode_reward": 468.8183104981581, "episode": 134.0, "batch_reward": 0.31925663608312604, "critic_loss": 0.49440084294974807, "actor_loss": -35.09206331634522, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.66082739830017, "step": 134000}
{"episode_reward": 454.9432890871649, "episode": 135.0, "batch_reward": 0.32124298146367075, "critic_loss": 0.5545151998996735, "actor_loss": -35.52543933486938, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.404765844345093, "step": 135000}
{"episode_reward": 511.05146680419193, "episode": 136.0, "batch_reward": 0.3230280092060566, "critic_loss": 0.5548677285909652, "actor_loss": -35.67455461502075, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.608003616333008, "step": 136000}
{"episode_reward": 475.7594276958463, "episode": 137.0, "batch_reward": 0.32489920595288274, "critic_loss": 0.5682601259946823, "actor_loss": -35.63989130783081, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.20032811164856, "step": 137000}
{"episode_reward": 478.75301608449496, "episode": 138.0, "batch_reward": 0.3246658295094967, "critic_loss": 0.5030607359409333, "actor_loss": -35.69004425811767, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.107106685638428, "step": 138000}
{"episode_reward": 478.76323875541846, "episode": 139.0, "batch_reward": 0.32624063184857366, "critic_loss": 0.5583024723380804, "actor_loss": -35.5973575553894, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.9260573387146, "step": 139000}
{"episode_reward": 523.9224602763758, "episode": 140.0, "batch_reward": 0.3263932605981827, "critic_loss": 0.5218436626940965, "actor_loss": -35.810457481384276, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.638303995132446, "step": 140000}
{"episode_reward": 493.06068825987455, "episode": 141.0, "batch_reward": 0.3305272687673569, "critic_loss": 0.5494639513641596, "actor_loss": -36.058264926910404, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.478076219558716, "step": 141000}
{"episode_reward": 545.769157759907, "episode": 142.0, "batch_reward": 0.3302764758169651, "critic_loss": 0.5316022758930922, "actor_loss": -36.074825050354, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.768245935440063, "step": 142000}
{"episode_reward": 388.96480428602223, "episode": 143.0, "batch_reward": 0.3299315146505833, "critic_loss": 0.5350575360059738, "actor_loss": -36.15684358596802, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.784647226333618, "step": 143000}
{"episode_reward": 460.4068951757425, "episode": 144.0, "batch_reward": 0.3319721962213516, "critic_loss": 0.554111111432314, "actor_loss": -36.28824541091919, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.649035453796387, "step": 144000}
{"episode_reward": 500.84228000079327, "episode": 145.0, "batch_reward": 0.3326644451022148, "critic_loss": 0.5512892795503139, "actor_loss": -36.59757359313965, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.986536979675293, "step": 145000}
{"episode_reward": 465.84982752281974, "episode": 146.0, "batch_reward": 0.33233265298604964, "critic_loss": 0.5319666204303503, "actor_loss": -36.05714904403686, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.729448556900024, "step": 146000}
{"episode_reward": 506.86249830960276, "episode": 147.0, "batch_reward": 0.33374418067932127, "critic_loss": 0.47957411223649976, "actor_loss": -36.525776264190675, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.664203882217407, "step": 147000}
{"episode_reward": 535.7849022630893, "episode": 148.0, "batch_reward": 0.3366157999932766, "critic_loss": 0.49095160786807535, "actor_loss": -36.70070608520508, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.736711740493774, "step": 148000}
{"episode_reward": 502.4694497599227, "episode": 149.0, "batch_reward": 0.33726259037852285, "critic_loss": 0.5187039298415184, "actor_loss": -36.731898303985595, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.805907249450684, "step": 149000}
{"episode_reward": 476.7463435679573, "episode": 150.0, "batch_reward": 0.3388999801278114, "critic_loss": 0.5263107466250658, "actor_loss": -37.02652095413208, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
