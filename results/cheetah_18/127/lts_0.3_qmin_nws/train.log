{"episode_reward": 0.0, "episode": 1.0, "duration": 18.720144987106323, "step": 1000}
{"episode_reward": 7.051849146674556, "episode": 2.0, "duration": 1.652540922164917, "step": 2000}
{"episode_reward": 365.4711839680396, "episode": 3.0, "batch_reward": 0.17560974231518361, "critic_loss": 0.028682008878492184, "actor_loss": -11.620629836711622, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 68.24298286437988, "step": 3000}
{"episode_reward": 21.441353849967204, "episode": 4.0, "batch_reward": 0.11917466881126165, "critic_loss": 0.031081564818508923, "actor_loss": -10.310832004383206, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.160423278808594, "step": 4000}
{"episode_reward": 29.24624905384053, "episode": 5.0, "batch_reward": 0.09629918465390802, "critic_loss": 0.02604606706649065, "actor_loss": -9.39886763868481, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.977527141571045, "step": 5000}
{"episode_reward": 11.646839148005935, "episode": 6.0, "batch_reward": 0.08398176249489188, "critic_loss": 0.0362430870924145, "actor_loss": -10.339900617063046, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.074106693267822, "step": 6000}
{"episode_reward": 87.70603932196907, "episode": 7.0, "batch_reward": 0.09079297875985504, "critic_loss": 0.05800714983418584, "actor_loss": -9.833055262327195, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.08103609085083, "step": 7000}
{"episode_reward": 108.09852111846045, "episode": 8.0, "batch_reward": 0.08829301542788744, "critic_loss": 0.07563243382796646, "actor_loss": -10.487227546215058, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.00184655189514, "step": 8000}
{"episode_reward": 44.97229841794236, "episode": 9.0, "batch_reward": 0.08145624063163996, "critic_loss": 0.06360882575064898, "actor_loss": -10.418746109962463, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.997817754745483, "step": 9000}
{"episode_reward": 22.424220984326297, "episode": 10.0, "batch_reward": 0.07993477578461171, "critic_loss": 0.0648757693413645, "actor_loss": -10.525157047271728, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.12152934074402, "step": 10000}
{"episode_reward": 73.77076421767997, "episode": 11.0, "batch_reward": 0.07602101105451584, "critic_loss": 0.0724770390521735, "actor_loss": -11.429369880199433, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.8390736579895, "step": 11000}
{"episode_reward": 50.05879117137126, "episode": 12.0, "batch_reward": 0.07351654740050435, "critic_loss": 0.07421753694303333, "actor_loss": -12.282189972877502, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.922637939453125, "step": 12000}
{"episode_reward": 104.98379050068243, "episode": 13.0, "batch_reward": 0.07904264193028211, "critic_loss": 0.0966671937238425, "actor_loss": -11.876725793838501, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.085999965667725, "step": 13000}
{"episode_reward": 80.41504511362137, "episode": 14.0, "batch_reward": 0.0774445698224008, "critic_loss": 0.09216733169555665, "actor_loss": -12.434238332748413, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.872558116912842, "step": 14000}
{"episode_reward": 44.435248240203336, "episode": 15.0, "batch_reward": 0.0745777898542583, "critic_loss": 0.10920937886834145, "actor_loss": -12.041181032180786, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.735806941986084, "step": 15000}
{"episode_reward": 40.460582945075004, "episode": 16.0, "batch_reward": 0.07847947524115444, "critic_loss": 0.13511300959438086, "actor_loss": -12.322453535079957, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.93235969543457, "step": 16000}
{"episode_reward": 200.30601099671003, "episode": 17.0, "batch_reward": 0.0846819737367332, "critic_loss": 0.16110740151256323, "actor_loss": -12.544411390304566, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.416521072387695, "step": 17000}
{"episode_reward": 156.9642783433061, "episode": 18.0, "batch_reward": 0.08451006757095456, "critic_loss": 0.15555763759464025, "actor_loss": -12.503273886680603, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.039830207824707, "step": 18000}
{"episode_reward": 36.82601070162107, "episode": 19.0, "batch_reward": 0.08283429209515453, "critic_loss": 0.1816169144883752, "actor_loss": -12.405837003707886, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.902106761932373, "step": 19000}
{"episode_reward": 49.7971198057707, "episode": 20.0, "batch_reward": 0.08564139690250158, "critic_loss": 0.2158899996727705, "actor_loss": -13.205575998306275, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.58848524093628, "step": 20000}
{"episode_reward": 246.6841136945422, "episode": 21.0, "batch_reward": 0.09341666105762124, "critic_loss": 0.24579070714861154, "actor_loss": -13.892505867004395, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.72763776779175, "step": 21000}
{"episode_reward": 205.10151986558824, "episode": 22.0, "batch_reward": 0.09641452023386955, "critic_loss": 0.22647518254816532, "actor_loss": -15.189057752609253, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.660556316375732, "step": 22000}
{"episode_reward": 112.7100266206177, "episode": 23.0, "batch_reward": 0.09792735917121172, "critic_loss": 0.21985445675998927, "actor_loss": -14.665015075683593, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.080500841140747, "step": 23000}
{"episode_reward": 131.07417807509435, "episode": 24.0, "batch_reward": 0.09780921514332294, "critic_loss": 0.21836717176437379, "actor_loss": -14.765176330566407, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.22469735145569, "step": 24000}
{"episode_reward": 85.47521343419558, "episode": 25.0, "batch_reward": 0.09995426657050847, "critic_loss": 0.24068684991449119, "actor_loss": -14.612820251464843, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.114925861358643, "step": 25000}
{"episode_reward": 166.75220012000042, "episode": 26.0, "batch_reward": 0.09891358751803636, "critic_loss": 0.21558519387245179, "actor_loss": -14.49816573524475, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.73543357849121, "step": 26000}
{"episode_reward": 51.590460062088276, "episode": 27.0, "batch_reward": 0.09881642162054777, "critic_loss": 0.2318132126033306, "actor_loss": -14.576015794754028, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.76921772956848, "step": 27000}
{"episode_reward": 93.79415391912352, "episode": 28.0, "batch_reward": 0.09772035445645452, "critic_loss": 0.2484220791310072, "actor_loss": -15.052243814468383, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.206456422805786, "step": 28000}
{"episode_reward": 61.95431894937384, "episode": 29.0, "batch_reward": 0.09677252177521586, "critic_loss": 0.26897395291924475, "actor_loss": -14.48107487487793, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.140239238739014, "step": 29000}
{"episode_reward": 84.08566389335422, "episode": 30.0, "batch_reward": 0.09733479385077953, "critic_loss": 0.25659138993918895, "actor_loss": -14.21935087776184, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.025172472000122, "step": 30000}
{"episode_reward": 103.52696476321634, "episode": 31.0, "batch_reward": 0.09535680408775807, "critic_loss": 0.2594005359336734, "actor_loss": -14.254964756011963, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.59533214569092, "step": 31000}
{"episode_reward": 44.04838618323044, "episode": 32.0, "batch_reward": 0.09775066015124322, "critic_loss": 0.251414506688714, "actor_loss": -14.835400604248047, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.021737575531006, "step": 32000}
{"episode_reward": 334.63748697325235, "episode": 33.0, "batch_reward": 0.10515450511127711, "critic_loss": 0.24842396511137485, "actor_loss": -15.670874095916748, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.665267944335938, "step": 33000}
{"episode_reward": 347.3693467632015, "episode": 34.0, "batch_reward": 0.11138857117295266, "critic_loss": 0.24500214584171773, "actor_loss": -15.821226371765137, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.53385591506958, "step": 34000}
{"episode_reward": 147.41448846498574, "episode": 35.0, "batch_reward": 0.11235138204693794, "critic_loss": 0.23082124038040638, "actor_loss": -16.405650094985962, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.0424165725708, "step": 35000}
{"episode_reward": 182.67696241355074, "episode": 36.0, "batch_reward": 0.11419695408642291, "critic_loss": 0.22746047464758157, "actor_loss": -16.634613843917847, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.455261945724487, "step": 36000}
{"episode_reward": 214.1716766129157, "episode": 37.0, "batch_reward": 0.1177305596396327, "critic_loss": 0.26641290650516747, "actor_loss": -16.675615760803222, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.43314266204834, "step": 37000}
{"episode_reward": 325.6867060418687, "episode": 38.0, "batch_reward": 0.12308944865316153, "critic_loss": 0.28616809491068124, "actor_loss": -17.173354265213014, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.98324680328369, "step": 38000}
{"episode_reward": 384.64051548816155, "episode": 39.0, "batch_reward": 0.13161332097649575, "critic_loss": 0.2932745537906885, "actor_loss": -17.922940534591675, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.14856243133545, "step": 39000}
{"episode_reward": 324.0065615210409, "episode": 40.0, "batch_reward": 0.13443802608549596, "critic_loss": 0.28853590283542874, "actor_loss": -17.905871589660645, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.281927585601807, "step": 40000}
{"episode_reward": 210.06721994708496, "episode": 41.0, "batch_reward": 0.13322311813384294, "critic_loss": 0.27287354186922314, "actor_loss": -17.89579537963867, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.57559514045715, "step": 41000}
{"episode_reward": 40.259641514006894, "episode": 42.0, "batch_reward": 0.13549947772920132, "critic_loss": 0.2687870377227664, "actor_loss": -18.414797300338744, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.617926836013794, "step": 42000}
{"episode_reward": 426.42677706739335, "episode": 43.0, "batch_reward": 0.14190198802947998, "critic_loss": 0.26133615168184043, "actor_loss": -18.868522617340087, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.745065927505493, "step": 43000}
{"episode_reward": 384.6973019731965, "episode": 44.0, "batch_reward": 0.14526670092344285, "critic_loss": 0.26069547163695095, "actor_loss": -19.344458290100096, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.53695058822632, "step": 44000}
{"episode_reward": 147.85087120439394, "episode": 45.0, "batch_reward": 0.14774696965515613, "critic_loss": 0.2625464420840144, "actor_loss": -19.238224542617797, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.406309843063354, "step": 45000}
{"episode_reward": 230.8071930393647, "episode": 46.0, "batch_reward": 0.15007704745978118, "critic_loss": 0.25779753614962103, "actor_loss": -19.32182546234131, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.192739009857178, "step": 46000}
{"episode_reward": 452.7051904965115, "episode": 47.0, "batch_reward": 0.15514377330243587, "critic_loss": 0.23580954691022635, "actor_loss": -19.7758044052124, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.061821937561035, "step": 47000}
{"episode_reward": 357.74099377308437, "episode": 48.0, "batch_reward": 0.1617212027385831, "critic_loss": 0.24602749674022198, "actor_loss": -20.302223999023436, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.737080574035645, "step": 48000}
{"episode_reward": 425.9665281445364, "episode": 49.0, "batch_reward": 0.16685079634934663, "critic_loss": 0.23700766612589358, "actor_loss": -20.843752180099486, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.1259548664093, "step": 49000}
{"episode_reward": 427.2569733844183, "episode": 50.0, "batch_reward": 0.1718920770585537, "critic_loss": 0.24715557795763016, "actor_loss": -21.111842655181885, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.205020904541016, "step": 50000}
{"episode_reward": 463.50002593575766, "episode": 51.0, "batch_reward": 0.1780212460309267, "critic_loss": 0.2354625380039215, "actor_loss": -21.348880672454833, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.33175015449524, "step": 51000}
{"episode_reward": 491.41469535364143, "episode": 52.0, "batch_reward": 0.18385446824133397, "critic_loss": 0.24279908705502748, "actor_loss": -21.667792037963867, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.83422327041626, "step": 52000}
{"episode_reward": 474.6967157429468, "episode": 53.0, "batch_reward": 0.18871420001983644, "critic_loss": 0.24755315662175417, "actor_loss": -22.394468273162843, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.91884469985962, "step": 53000}
{"episode_reward": 464.1129915783081, "episode": 54.0, "batch_reward": 0.19302508556842804, "critic_loss": 0.2490905021801591, "actor_loss": -22.63233435058594, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.008492946624756, "step": 54000}
{"episode_reward": 159.44998837298886, "episode": 55.0, "batch_reward": 0.19333379875123502, "critic_loss": 0.2658696143254638, "actor_loss": -22.913303428649904, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.107566833496094, "step": 55000}
{"episode_reward": 460.62552544743465, "episode": 56.0, "batch_reward": 0.19893000531196595, "critic_loss": 0.28833364409208295, "actor_loss": -23.334704971313478, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.649232864379883, "step": 56000}
{"episode_reward": 474.7099725193396, "episode": 57.0, "batch_reward": 0.2018010036498308, "critic_loss": 0.31443676993250846, "actor_loss": -23.793525127410888, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.4281644821167, "step": 57000}
{"episode_reward": 109.54156461035086, "episode": 58.0, "batch_reward": 0.20103135295212268, "critic_loss": 0.3151342210769653, "actor_loss": -24.09664057922363, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.30730438232422, "step": 58000}
{"episode_reward": 418.8627029953273, "episode": 59.0, "batch_reward": 0.20561576749384403, "critic_loss": 0.331688660427928, "actor_loss": -24.1181014251709, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.476582527160645, "step": 59000}
{"episode_reward": 477.1446702271883, "episode": 60.0, "batch_reward": 0.21063803072273732, "critic_loss": 0.3164907948151231, "actor_loss": -24.943470691680908, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.731555938720703, "step": 60000}
{"episode_reward": 467.0464005903644, "episode": 61.0, "batch_reward": 0.2151650602668524, "critic_loss": 0.3313505914658308, "actor_loss": -25.42775656890869, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.34393906593323, "step": 61000}
{"episode_reward": 479.4284398598117, "episode": 62.0, "batch_reward": 0.2192689955383539, "critic_loss": 0.318476946040988, "actor_loss": -25.977150119781495, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.49558401107788, "step": 62000}
{"episode_reward": 436.92536062936244, "episode": 63.0, "batch_reward": 0.22244986885786056, "critic_loss": 0.3436991065442562, "actor_loss": -26.151835357666016, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.39324450492859, "step": 63000}
{"episode_reward": 348.251001220705, "episode": 64.0, "batch_reward": 0.2252241155952215, "critic_loss": 0.3556853109151125, "actor_loss": -26.7092907333374, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.8431339263916, "step": 64000}
{"episode_reward": 292.82532086713803, "episode": 65.0, "batch_reward": 0.2255063263475895, "critic_loss": 0.3657883185148239, "actor_loss": -26.79522240447998, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.632451057434082, "step": 65000}
{"episode_reward": 489.59031983842067, "episode": 66.0, "batch_reward": 0.22838909968733787, "critic_loss": 0.34327599668502806, "actor_loss": -27.12636368179321, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.548478603363037, "step": 66000}
{"episode_reward": 219.08640123733394, "episode": 67.0, "batch_reward": 0.2288806427568197, "critic_loss": 0.36133420641720293, "actor_loss": -27.417778369903566, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.3097665309906, "step": 67000}
{"episode_reward": 460.1301583665762, "episode": 68.0, "batch_reward": 0.23233737190067769, "critic_loss": 0.40509063117206096, "actor_loss": -27.5755177192688, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.827354431152344, "step": 68000}
{"episode_reward": 438.63587679581843, "episode": 69.0, "batch_reward": 0.23506130036711692, "critic_loss": 0.381475311383605, "actor_loss": -27.597771598815918, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.59234046936035, "step": 69000}
{"episode_reward": 283.7014802423709, "episode": 70.0, "batch_reward": 0.23681880822777748, "critic_loss": 0.39613158725202086, "actor_loss": -27.96872138595581, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.806361198425293, "step": 70000}
{"episode_reward": 493.4923209919951, "episode": 71.0, "batch_reward": 0.24004147124290467, "critic_loss": 0.3946031037271023, "actor_loss": -28.285508968353273, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.88920450210571, "step": 71000}
{"episode_reward": 404.3895796922852, "episode": 72.0, "batch_reward": 0.24223510473966597, "critic_loss": 0.4121932924836874, "actor_loss": -28.320434226989747, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.831753492355347, "step": 72000}
{"episode_reward": 493.9229603540411, "episode": 73.0, "batch_reward": 0.24623230290412904, "critic_loss": 0.3564456288963556, "actor_loss": -28.791596698760987, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.890449285507202, "step": 73000}
{"episode_reward": 507.6916841741756, "episode": 74.0, "batch_reward": 0.24894849841296673, "critic_loss": 0.3632546467781067, "actor_loss": -29.05726292037964, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.914551734924316, "step": 74000}
{"episode_reward": 520.3400183668052, "episode": 75.0, "batch_reward": 0.2525075327455997, "critic_loss": 0.35794110161066056, "actor_loss": -29.204648250579833, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.840851545333862, "step": 75000}
{"episode_reward": 489.4448025579893, "episode": 76.0, "batch_reward": 0.25690764060616494, "critic_loss": 0.36276264326274393, "actor_loss": -29.767463802337648, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.31077527999878, "step": 76000}
{"episode_reward": 464.4097177660608, "episode": 77.0, "batch_reward": 0.25883417622745036, "critic_loss": 0.3694023102223873, "actor_loss": -29.990151973724366, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.216039896011353, "step": 77000}
{"episode_reward": 527.5500021443672, "episode": 78.0, "batch_reward": 0.2618968650251627, "critic_loss": 0.37322845904529095, "actor_loss": -30.237269969940186, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.750263452529907, "step": 78000}
{"episode_reward": 540.9320443591757, "episode": 79.0, "batch_reward": 0.265844997048378, "critic_loss": 0.3676076287478209, "actor_loss": -30.571470420837404, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.68779969215393, "step": 79000}
{"episode_reward": 509.4737604167768, "episode": 80.0, "batch_reward": 0.26864665003120897, "critic_loss": 0.3704499458372593, "actor_loss": -30.957190456390382, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.818440198898315, "step": 80000}
{"episode_reward": 477.8125223260302, "episode": 81.0, "batch_reward": 0.2725023676902056, "critic_loss": 0.37839630065858365, "actor_loss": -31.170196907043458, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.47067046165466, "step": 81000}
{"episode_reward": 506.295142973067, "episode": 82.0, "batch_reward": 0.27441112822294234, "critic_loss": 0.3824120825827122, "actor_loss": -31.247781387329102, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.598654747009277, "step": 82000}
{"episode_reward": 493.77887883216374, "episode": 83.0, "batch_reward": 0.2770577354878187, "critic_loss": 0.3831608918905258, "actor_loss": -31.573464332580567, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.186054944992065, "step": 83000}
{"episode_reward": 447.3083080023111, "episode": 84.0, "batch_reward": 0.27909979835152626, "critic_loss": 0.41417296405136583, "actor_loss": -31.703611644744875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.737306118011475, "step": 84000}
{"episode_reward": 476.79334663103685, "episode": 85.0, "batch_reward": 0.2813407712578774, "critic_loss": 0.4511896479576826, "actor_loss": -31.98620703125, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.574933528900146, "step": 85000}
{"episode_reward": 514.6774441869106, "episode": 86.0, "batch_reward": 0.2840465258061886, "critic_loss": 0.40916013181209565, "actor_loss": -32.213774745941166, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.76250171661377, "step": 86000}
{"episode_reward": 491.77605957058597, "episode": 87.0, "batch_reward": 0.28674541868269443, "critic_loss": 0.42497626243531705, "actor_loss": -32.54674392318726, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.127678155899048, "step": 87000}
{"episode_reward": 522.3925307234693, "episode": 88.0, "batch_reward": 0.2887767287790775, "critic_loss": 0.39681467881798743, "actor_loss": -32.38689741516113, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.084064483642578, "step": 88000}
{"episode_reward": 384.15412364469256, "episode": 89.0, "batch_reward": 0.29111030931770804, "critic_loss": 0.4379214104413986, "actor_loss": -32.718874015808105, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.56002378463745, "step": 89000}
{"episode_reward": 532.4714269428208, "episode": 90.0, "batch_reward": 0.29538006637990477, "critic_loss": 0.47424824027717116, "actor_loss": -33.05110632324219, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.181087017059326, "step": 90000}
{"episode_reward": 526.2797445179599, "episode": 91.0, "batch_reward": 0.29596536557376385, "critic_loss": 0.4523080903887749, "actor_loss": -33.06219169998169, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 41.22726249694824, "step": 91000}
{"episode_reward": 560.8464972280863, "episode": 92.0, "batch_reward": 0.2991108923703432, "critic_loss": 0.39906000036001205, "actor_loss": -33.56912740707398, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.494107007980347, "step": 92000}
{"episode_reward": 544.887310004728, "episode": 93.0, "batch_reward": 0.30078926143050194, "critic_loss": 0.45601198805868626, "actor_loss": -33.60536828231812, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.38831639289856, "step": 93000}
{"episode_reward": 551.2576108070559, "episode": 94.0, "batch_reward": 0.3045411078631878, "critic_loss": 0.4173785451352596, "actor_loss": -33.84650138092041, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.853099584579468, "step": 94000}
{"episode_reward": 523.8214887454775, "episode": 95.0, "batch_reward": 0.3061148551851511, "critic_loss": 0.41829723381996153, "actor_loss": -34.20165626907349, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.953684091567993, "step": 95000}
{"episode_reward": 513.5998741904981, "episode": 96.0, "batch_reward": 0.3091344877779484, "critic_loss": 0.4147569918036461, "actor_loss": -34.30167895889282, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.869063138961792, "step": 96000}
{"episode_reward": 545.5325533501607, "episode": 97.0, "batch_reward": 0.31082296633720397, "critic_loss": 0.42051258745789527, "actor_loss": -34.587147701263426, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.505712509155273, "step": 97000}
{"episode_reward": 532.5428759758199, "episode": 98.0, "batch_reward": 0.3127446167320013, "critic_loss": 0.4253226171582937, "actor_loss": -34.86681170654297, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.247976064682007, "step": 98000}
{"episode_reward": 489.00887790221816, "episode": 99.0, "batch_reward": 0.3154078412353992, "critic_loss": 0.41659122420847416, "actor_loss": -35.071307422637936, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.52891993522644, "step": 99000}
{"episode_reward": 545.1277662177339, "episode": 100.0, "batch_reward": 0.3181831383109093, "critic_loss": 0.39745997011661527, "actor_loss": -35.34797006607056, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.421410083770752, "step": 100000}
{"episode_reward": 555.0546585527627, "episode": 101.0, "batch_reward": 0.3200842300206423, "critic_loss": 0.42793821965157985, "actor_loss": -35.34814372253418, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.28412079811096, "step": 101000}
{"episode_reward": 538.6176805766248, "episode": 102.0, "batch_reward": 0.3217162046134472, "critic_loss": 0.42386642706394195, "actor_loss": -35.733587478637695, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.096694707870483, "step": 102000}
{"episode_reward": 541.8430287184175, "episode": 103.0, "batch_reward": 0.3238574510514736, "critic_loss": 0.3899139638841152, "actor_loss": -35.88226797103882, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.577452421188354, "step": 103000}
{"episode_reward": 550.737123896006, "episode": 104.0, "batch_reward": 0.3268221665918827, "critic_loss": 0.4246443426758051, "actor_loss": -36.08742602157593, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.57118582725525, "step": 104000}
{"episode_reward": 553.6716807765972, "episode": 105.0, "batch_reward": 0.32904799056053163, "critic_loss": 0.4024722026437521, "actor_loss": -36.37814152908325, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.151781797409058, "step": 105000}
{"episode_reward": 560.7443390399585, "episode": 106.0, "batch_reward": 0.3313586778640747, "critic_loss": 0.40528742848336696, "actor_loss": -36.77242394638061, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.3470675945282, "step": 106000}
{"episode_reward": 551.4946446612036, "episode": 107.0, "batch_reward": 0.3319636117219925, "critic_loss": 0.3964796098917723, "actor_loss": -36.749414962768554, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.463196992874146, "step": 107000}
{"episode_reward": 549.4812655616039, "episode": 108.0, "batch_reward": 0.33452028355002406, "critic_loss": 0.3765604286491871, "actor_loss": -37.163773792266845, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.503546476364136, "step": 108000}
{"episode_reward": 529.5397456631999, "episode": 109.0, "batch_reward": 0.3376819822192192, "critic_loss": 0.4145236128270626, "actor_loss": -37.366954830169675, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.154144763946533, "step": 109000}
{"episode_reward": 529.7298578920575, "episode": 110.0, "batch_reward": 0.33818085777759554, "critic_loss": 0.38659775215387343, "actor_loss": -37.602725387573244, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.302388906478882, "step": 110000}
{"episode_reward": 508.2669404129624, "episode": 111.0, "batch_reward": 0.33930542743206027, "critic_loss": 0.38962136897444727, "actor_loss": -37.69295603942871, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.06464076042175, "step": 111000}
{"episode_reward": 538.1517288822739, "episode": 112.0, "batch_reward": 0.3412177259624004, "critic_loss": 0.3932772072851658, "actor_loss": -37.82221290588379, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.654173851013184, "step": 112000}
{"episode_reward": 538.5217440099013, "episode": 113.0, "batch_reward": 0.3431811764240265, "critic_loss": 0.41051853612065314, "actor_loss": -37.96748378753662, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.61789846420288, "step": 113000}
{"episode_reward": 540.6769590562943, "episode": 114.0, "batch_reward": 0.346138188123703, "critic_loss": 0.39238606943190096, "actor_loss": -38.47678895568848, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.072015047073364, "step": 114000}
{"episode_reward": 536.4085233875559, "episode": 115.0, "batch_reward": 0.3471603458225727, "critic_loss": 0.38024284718930723, "actor_loss": -38.57444254302978, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.460838794708252, "step": 115000}
{"episode_reward": 554.5174778470652, "episode": 116.0, "batch_reward": 0.34891619098186494, "critic_loss": 0.36126040782034397, "actor_loss": -38.71927131652832, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.81887674331665, "step": 116000}
{"episode_reward": 526.2413547593452, "episode": 117.0, "batch_reward": 0.35150311106443405, "critic_loss": 0.3576513063013554, "actor_loss": -38.925300323486326, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.33685302734375, "step": 117000}
{"episode_reward": 536.0772300631884, "episode": 118.0, "batch_reward": 0.3517998897731304, "critic_loss": 0.39435262958705425, "actor_loss": -38.94155640411377, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.828778505325317, "step": 118000}
{"episode_reward": 543.1445868928946, "episode": 119.0, "batch_reward": 0.3533497049510479, "critic_loss": 0.3874178319722414, "actor_loss": -38.97645559692383, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.598001718521118, "step": 119000}
{"episode_reward": 531.6195793781022, "episode": 120.0, "batch_reward": 0.354750376701355, "critic_loss": 0.392970827832818, "actor_loss": -39.19534092712402, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.019423484802246, "step": 120000}
{"episode_reward": 566.5087451198262, "episode": 121.0, "batch_reward": 0.35630301013588905, "critic_loss": 0.3836348158270121, "actor_loss": -39.38017251586914, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.11899185180664, "step": 121000}
{"episode_reward": 579.5098900399124, "episode": 122.0, "batch_reward": 0.35919388541579245, "critic_loss": 0.38669883510470393, "actor_loss": -39.63073548126221, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.33091449737549, "step": 122000}
{"episode_reward": 548.5863432628165, "episode": 123.0, "batch_reward": 0.359936492562294, "critic_loss": 0.4237518761605024, "actor_loss": -39.68571153259278, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.579169511795044, "step": 123000}
{"episode_reward": 526.6405899942912, "episode": 124.0, "batch_reward": 0.36143655800819396, "critic_loss": 0.4159505851864815, "actor_loss": -39.75684497070313, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.54022765159607, "step": 124000}
{"episode_reward": 537.3894782311905, "episode": 125.0, "batch_reward": 0.3610302122831345, "critic_loss": 0.4370674452036619, "actor_loss": -39.93800344085693, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.273184776306152, "step": 125000}
{"episode_reward": 298.0676919353967, "episode": 126.0, "batch_reward": 0.36254736429452894, "critic_loss": 0.4382499537914991, "actor_loss": -40.34982958984375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.164541482925415, "step": 126000}
{"episode_reward": 525.295308193949, "episode": 127.0, "batch_reward": 0.3634923251569271, "critic_loss": 0.44941937185823916, "actor_loss": -40.40975496673584, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.6934974193573, "step": 127000}
{"episode_reward": 490.9562797292609, "episode": 128.0, "batch_reward": 0.3645726813673973, "critic_loss": 0.4190309727191925, "actor_loss": -40.50867663574219, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.999467849731445, "step": 128000}
{"episode_reward": 547.6663371626623, "episode": 129.0, "batch_reward": 0.36463567179441453, "critic_loss": 0.4097594157755375, "actor_loss": -40.66592879486084, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.062142610549927, "step": 129000}
{"episode_reward": 191.35515917856588, "episode": 130.0, "batch_reward": 0.36261541110277173, "critic_loss": 0.3988617165982723, "actor_loss": -40.73568943023682, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.34805130958557, "step": 130000}
{"episode_reward": 10.456554040422844, "episode": 131.0, "batch_reward": 0.36021611830592154, "critic_loss": 0.4426215973496437, "actor_loss": -40.78987342071533, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.13383340835571, "step": 131000}
{"episode_reward": 8.579106705782053, "episode": 132.0, "batch_reward": 0.3573466359972954, "critic_loss": 0.42620993189513684, "actor_loss": -40.873393981933596, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.19522738456726, "step": 132000}
{"episode_reward": 10.49881548042627, "episode": 133.0, "batch_reward": 0.3548332017958164, "critic_loss": 0.4213596789091825, "actor_loss": -40.89077308654785, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.52561926841736, "step": 133000}
{"episode_reward": 9.668377252577363, "episode": 134.0, "batch_reward": 0.3511651302576065, "critic_loss": 0.39331104898452757, "actor_loss": -40.8562059173584, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.4894061088562, "step": 134000}
{"episode_reward": 9.737572131049717, "episode": 135.0, "batch_reward": 0.3495169169306755, "critic_loss": 0.36035314507782457, "actor_loss": -41.03932126617432, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.353674173355103, "step": 135000}
{"episode_reward": 8.22238201335129, "episode": 136.0, "batch_reward": 0.3474071148633957, "critic_loss": 0.3291150722205639, "actor_loss": -41.01309072113037, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.51313877105713, "step": 136000}
{"episode_reward": 7.10412974896681, "episode": 137.0, "batch_reward": 0.345474182009697, "critic_loss": 0.30506552807986737, "actor_loss": -40.88976007080078, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.811971187591553, "step": 137000}
{"episode_reward": 8.84062087622268, "episode": 138.0, "batch_reward": 0.3421412787735462, "critic_loss": 0.3031530960872769, "actor_loss": -40.61547703552246, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.8277428150177, "step": 138000}
{"episode_reward": 6.499994910117484, "episode": 139.0, "batch_reward": 0.3399871229529381, "critic_loss": 0.30113150485605, "actor_loss": -40.36860127258301, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.13322114944458, "step": 139000}
{"episode_reward": 8.102046603120527, "episode": 140.0, "batch_reward": 0.3358783780038357, "critic_loss": 0.3204349215850234, "actor_loss": -39.99121201324463, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.175939798355103, "step": 140000}
{"episode_reward": 10.604352995861646, "episode": 141.0, "batch_reward": 0.3361086473464966, "critic_loss": 0.34125564274191855, "actor_loss": -39.80267825317383, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.53685784339905, "step": 141000}
{"episode_reward": 16.80897692752459, "episode": 142.0, "batch_reward": 0.3343780398368835, "critic_loss": 0.28087940211594103, "actor_loss": -39.68908992004395, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.965768814086914, "step": 142000}
{"episode_reward": 333.6727780015623, "episode": 143.0, "batch_reward": 0.3345794573426247, "critic_loss": 0.3352848278209567, "actor_loss": -39.52262466430664, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.303035259246826, "step": 143000}
{"episode_reward": 499.34456449458196, "episode": 144.0, "batch_reward": 0.33599132278561594, "critic_loss": 0.33257323583215476, "actor_loss": -39.494084251403805, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.049116134643555, "step": 144000}
{"episode_reward": 534.0139844940326, "episode": 145.0, "batch_reward": 0.3372440456748009, "critic_loss": 0.3489605680629611, "actor_loss": -39.40641184997558, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.590156316757202, "step": 145000}
{"episode_reward": 562.901386673527, "episode": 146.0, "batch_reward": 0.3376174181997776, "critic_loss": 0.36302040817588566, "actor_loss": -39.29178354644775, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.52034640312195, "step": 146000}
{"episode_reward": 530.787163937158, "episode": 147.0, "batch_reward": 0.3391281824707985, "critic_loss": 0.3169129413440824, "actor_loss": -39.516044296264646, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.84346580505371, "step": 147000}
{"episode_reward": 539.5927053731818, "episode": 148.0, "batch_reward": 0.3422272300720215, "critic_loss": 0.37122124626487496, "actor_loss": -39.64469553375244, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.08164691925049, "step": 148000}
{"episode_reward": 550.1793598769326, "episode": 149.0, "batch_reward": 0.34334915250539777, "critic_loss": 0.3528524795472622, "actor_loss": -39.72227404022217, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.215631008148193, "step": 149000}
{"episode_reward": 527.4535492257301, "episode": 150.0, "batch_reward": 0.34352739694714546, "critic_loss": 0.3557196367532015, "actor_loss": -39.64024315643311, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
