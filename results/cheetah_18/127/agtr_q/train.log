{"episode": 1.0, "duration": 20.452637434005737, "episode_reward": 7.051849146674556, "step": 1000}
{"episode": 2.0, "duration": 1.68984055519104, "episode_reward": 365.4711839680396, "step": 2000}
{"episode": 3.0, "batch_reward": 0.17855291978573154, "actor_loss": -35.6113428914962, "actor_target_entropy": -6.0, "alpha_value": 0.01377813086574139, "duration": 56.27893400192261, "episode_reward": 58.146038484360204, "step": 3000}
{"episode": 4.0, "batch_reward": 0.13060486311465502, "actor_loss": -32.569982383728025, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.141271114349365, "episode_reward": 43.88365047080841, "step": 4000}
{"episode": 5.0, "batch_reward": 0.11190190962702036, "actor_loss": -31.61117660903931, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.861823797225952, "episode_reward": 54.38370377234927, "step": 5000}
{"episode": 6.0, "batch_reward": 0.10033726969361305, "actor_loss": -30.908156845092773, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.773338556289673, "episode_reward": 51.192223916194415, "step": 6000}
{"episode": 7.0, "batch_reward": 0.09385511979833246, "actor_loss": -30.43385224914551, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.954384326934814, "episode_reward": 58.29625298619073, "step": 7000}
{"episode": 8.0, "batch_reward": 0.08964466584846377, "actor_loss": -30.209220684051513, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.297811031341553, "episode_reward": 59.51292513242424, "step": 8000}
{"episode": 9.0, "batch_reward": 0.08606544993445277, "actor_loss": -29.99820598220825, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.499197721481323, "episode_reward": 75.89440725124338, "step": 9000}
{"episode": 10.0, "batch_reward": 0.08329716687649488, "actor_loss": -24.52107482147217, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 4077.331084728241, "episode_reward": 27.110111842415087, "step": 10000}
{"episode": 11.0, "batch_reward": 0.08038177350535988, "actor_loss": -24.308711311340332, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 34.18024516105652, "episode_reward": 77.26471674588866, "step": 11000}
{"episode": 12.0, "batch_reward": 0.08158669404685498, "actor_loss": -20.831035457611083, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 439.2148804664612, "episode_reward": 124.07003145462903, "step": 12000}
{"episode": 13.0, "batch_reward": 0.08634804468229414, "actor_loss": -21.104203205108643, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.441221475601196, "episode_reward": 110.45137990213013, "step": 13000}
{"episode": 14.0, "batch_reward": 0.08885651786625386, "actor_loss": -18.79076385498047, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 452.3947103023529, "episode_reward": 115.84061624095217, "step": 14000}
{"episode": 15.0, "batch_reward": 0.08897514872998, "actor_loss": -18.820680725097656, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.127975702285767, "episode_reward": 90.4364193899733, "step": 15000}
{"episode": 16.0, "batch_reward": 0.09332350742816925, "actor_loss": -17.09603429222107, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 443.96525716781616, "episode_reward": 270.63650025416894, "step": 16000}
{"episode": 17.0, "batch_reward": 0.10217964120209216, "actor_loss": -17.69659422683716, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.621146202087402, "episode_reward": 228.2779663034977, "step": 17000}
{"episode": 18.0, "batch_reward": 0.10721336407959461, "actor_loss": -16.305932928085326, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 437.3919532299042, "episode_reward": 75.22282375163739, "step": 18000}
{"episode": 19.0, "batch_reward": 0.10641184121370316, "actor_loss": -15.86707048034668, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.73043155670166, "episode_reward": 90.81983949481433, "step": 19000}
{"episode": 20.0, "batch_reward": 0.10916949757933617, "actor_loss": -14.938494424819947, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 440.9445300102234, "episode_reward": 289.9985105497165, "step": 20000}
{"episode": 21.0, "batch_reward": 0.11582631159573793, "actor_loss": -15.330884601593018, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 40.455026149749756, "episode_reward": 146.5370128729307, "step": 21000}
{"episode": 22.0, "batch_reward": 0.11845724531263113, "actor_loss": -14.30890879058838, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 440.55047631263733, "episode_reward": 187.27645989119407, "step": 22000}
{"episode": 23.0, "batch_reward": 0.12357118852436542, "actor_loss": -14.682163814544678, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.100146055221558, "episode_reward": 340.4236045794422, "step": 23000}
{"episode": 24.0, "batch_reward": 0.13274741265922785, "actor_loss": -15.075589080810547, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 455.0878276824951, "episode_reward": 357.6606730029935, "step": 24000}
{"episode": 25.0, "batch_reward": 0.1412862520441413, "actor_loss": -15.884865938186646, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.52407145500183, "episode_reward": 312.2021642489347, "step": 25000}
{"episode": 26.0, "batch_reward": 0.14833675003051758, "actor_loss": -16.126054256439208, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 440.269526720047, "episode_reward": 331.77510441544774, "step": 26000}
{"episode": 27.0, "batch_reward": 0.15536976352334023, "actor_loss": -16.774322515487672, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.74765706062317, "episode_reward": 313.7388641887601, "step": 27000}
{"episode": 28.0, "batch_reward": 0.1606685324832797, "actor_loss": -17.24050693130493, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 447.98233461380005, "episode_reward": 331.3191736988203, "step": 28000}
{"episode": 29.0, "batch_reward": 0.1667562534958124, "actor_loss": -17.862574604034425, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.249579668045044, "episode_reward": 338.7112897372625, "step": 29000}
{"episode": 30.0, "batch_reward": 0.17226676534116267, "actor_loss": -18.154454721450804, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 441.1791353225708, "episode_reward": 228.4924858733528, "step": 30000}
{"episode": 31.0, "batch_reward": 0.17081040009856224, "actor_loss": -18.12624617767334, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 39.98407244682312, "episode_reward": 135.51941714219345, "step": 31000}
{"episode": 32.0, "batch_reward": 0.1681767045482993, "actor_loss": -17.999038301467895, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 441.2288155555725, "episode_reward": 18.62628393819439, "step": 32000}
{"episode": 33.0, "batch_reward": 0.1666093692407012, "actor_loss": -17.938729049682618, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.99450922012329, "episode_reward": 164.62363219894792, "step": 33000}
{"episode": 34.0, "batch_reward": 0.167464962169528, "actor_loss": -18.277616985321046, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 449.4705054759979, "episode_reward": 305.23740507930137, "step": 34000}
{"episode": 35.0, "batch_reward": 0.17054087185859682, "actor_loss": -18.568660886764526, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.04642081260681, "episode_reward": 203.81157481084853, "step": 35000}
{"episode": 36.0, "batch_reward": 0.17209463660418986, "actor_loss": -18.77667188835144, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 439.90826988220215, "episode_reward": 209.9831759007712, "step": 36000}
{"episode": 37.0, "batch_reward": 0.172803681910038, "actor_loss": -18.754874349594115, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.860363960266113, "episode_reward": 240.99597235428297, "step": 37000}
{"episode": 38.0, "batch_reward": 0.17534939263761043, "actor_loss": -19.1241797580719, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 449.3522746562958, "episode_reward": 286.90713571082773, "step": 38000}
{"episode": 39.0, "batch_reward": 0.17773684751987456, "actor_loss": -19.351516435623168, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.533082485198975, "episode_reward": 269.74027091700015, "step": 39000}
{"episode": 40.0, "batch_reward": 0.18205416271090508, "actor_loss": -19.40998215484619, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 441.33321475982666, "episode_reward": 302.8743456216271, "step": 40000}
{"episode": 41.0, "batch_reward": 0.1822872811257839, "actor_loss": -19.468381572723388, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 39.66691279411316, "episode_reward": 259.5900398571807, "step": 41000}
{"episode": 42.0, "batch_reward": 0.1838015885949135, "actor_loss": -18.776303897857666, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 439.8778932094574, "episode_reward": 240.57356000905062, "step": 42000}
{"episode": 43.0, "batch_reward": 0.18687032258510589, "actor_loss": -19.110184921264647, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.015188932418823, "episode_reward": 329.9572895634018, "step": 43000}
{"episode": 44.0, "batch_reward": 0.19038815541565418, "actor_loss": -19.68235647583008, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 445.63532972335815, "episode_reward": 345.743345716712, "step": 44000}
{"episode": 45.0, "batch_reward": 0.1938093528598547, "actor_loss": -19.988252967834473, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.10886001586914, "episode_reward": 270.10618758284346, "step": 45000}
{"episode": 46.0, "batch_reward": 0.19646804539859294, "actor_loss": -19.865588287353514, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 435.7604126930237, "episode_reward": 358.3996604062248, "step": 46000}
{"episode": 47.0, "batch_reward": 0.19862135729193686, "actor_loss": -20.085129306793213, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.126314163208008, "episode_reward": 318.9044778122676, "step": 47000}
{"episode": 48.0, "batch_reward": 0.201510749489069, "actor_loss": -19.884843626022338, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 448.01469469070435, "episode_reward": 336.31286459395386, "step": 48000}
{"episode": 49.0, "batch_reward": 0.204408259421587, "actor_loss": -20.07018695449829, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.183967351913452, "episode_reward": 316.745746337788, "step": 49000}
{"episode": 50.0, "batch_reward": 0.20783689215779305, "actor_loss": -20.518911945343017, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 440.9508607387543, "episode_reward": 390.3237645950303, "step": 50000}
{"episode": 51.0, "batch_reward": 0.21060630121827126, "actor_loss": -20.697515232086182, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 34.093384742736816, "episode_reward": 385.1385050008493, "step": 51000}
{"episode": 52.0, "batch_reward": 0.21271636249125003, "actor_loss": -20.626295391082763, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 441.21229362487793, "episode_reward": 339.7840539380155, "step": 52000}
{"episode": 53.0, "batch_reward": 0.21716667731106282, "actor_loss": -21.0431015625, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.79083752632141, "episode_reward": 417.93921643900194, "step": 53000}
{"episode": 54.0, "batch_reward": 0.22063884232938288, "actor_loss": -21.324084537506103, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 437.87548899650574, "episode_reward": 428.8457976028804, "step": 54000}
{"episode": 55.0, "batch_reward": 0.2236396296620369, "actor_loss": -21.56180548095703, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.123611450195312, "episode_reward": 383.1296642852892, "step": 55000}
{"episode": 56.0, "batch_reward": 0.2240963013023138, "actor_loss": -21.064830127716064, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 423.38944125175476, "episode_reward": 196.67474745386778, "step": 56000}
{"episode": 57.0, "batch_reward": 0.22627978892624379, "actor_loss": -21.266980339050292, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.109654188156128, "episode_reward": 206.0118542895745, "step": 57000}
{"episode": 58.0, "batch_reward": 0.22607713821530342, "actor_loss": -20.915231105804445, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 426.3361132144928, "episode_reward": 418.2301745947691, "step": 58000}
{"episode": 59.0, "batch_reward": 0.2298005697131157, "actor_loss": -21.191494483947753, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.83274531364441, "episode_reward": 412.0138767651767, "step": 59000}
{"episode": 60.0, "batch_reward": 0.23319420389831066, "actor_loss": -20.77637199783325, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 428.1737172603607, "episode_reward": 422.67737352805887, "step": 60000}
{"episode": 61.0, "batch_reward": 0.23546652622520925, "actor_loss": -20.96825922012329, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.68178415298462, "episode_reward": 345.4029715060873, "step": 61000}
{"episode": 62.0, "batch_reward": 0.23660781714320184, "actor_loss": -20.060702251434325, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 430.28196382522583, "episode_reward": 337.8930094177582, "step": 62000}
{"episode": 63.0, "batch_reward": 0.23836535741388798, "actor_loss": -20.280206718444823, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.777358531951904, "episode_reward": 382.9356124226611, "step": 63000}
{"episode": 64.0, "batch_reward": 0.24216318455338479, "actor_loss": -20.48068143081665, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 429.0134618282318, "episode_reward": 410.53299963817534, "step": 64000}
{"episode": 65.0, "batch_reward": 0.24313715094327926, "actor_loss": -20.5770237159729, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.13647985458374, "episode_reward": 399.7592895057472, "step": 65000}
{"episode": 66.0, "batch_reward": 0.24573964765667916, "actor_loss": -20.356512462615967, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 426.58644700050354, "episode_reward": 343.8599265241195, "step": 66000}
{"episode": 67.0, "batch_reward": 0.24777756752073765, "actor_loss": -20.560621852874757, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.011412143707275, "episode_reward": 396.0297882292416, "step": 67000}
{"episode": 68.0, "batch_reward": 0.24996530844271184, "actor_loss": -20.74534104537964, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 429.567298412323, "episode_reward": 349.8334500243736, "step": 68000}
{"episode": 69.0, "batch_reward": 0.2513899581432342, "actor_loss": -20.842545917510986, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.178820848464966, "episode_reward": 348.2746333780694, "step": 69000}
{"episode": 70.0, "batch_reward": 0.25250174094736577, "actor_loss": -20.791270221710207, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 422.52231335639954, "episode_reward": 384.20727911941503, "step": 70000}
{"episode": 71.0, "batch_reward": 0.2541386689245701, "actor_loss": -20.87059048461914, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.29518151283264, "episode_reward": 406.179243887513, "step": 71000}
{"episode": 72.0, "batch_reward": 0.25706625275313855, "actor_loss": -20.934134384155275, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 434.46486830711365, "episode_reward": 344.49599089612514, "step": 72000}
{"episode": 73.0, "batch_reward": 0.25631001295149325, "actor_loss": -20.91807751083374, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.283787965774536, "episode_reward": 296.3894927241461, "step": 73000}
{"episode": 74.0, "batch_reward": 0.25632086500525475, "actor_loss": -20.901727828979492, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 429.8943085670471, "episode_reward": 232.179056693006, "step": 74000}
{"episode": 75.0, "batch_reward": 0.2587767359763384, "actor_loss": -21.113677921295167, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.754260063171387, "episode_reward": 352.4559298178178, "step": 75000}
{"episode": 76.0, "batch_reward": 0.2589142682850361, "actor_loss": -21.00514363479614, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 437.60312390327454, "episode_reward": 299.52230274999323, "step": 76000}
{"episode": 77.0, "batch_reward": 0.2600259258747101, "actor_loss": -21.058214054107665, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.25522780418396, "episode_reward": 320.9365682278079, "step": 77000}
{"episode": 78.0, "batch_reward": 0.26039962689578533, "actor_loss": -21.263128849029542, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 428.46100521087646, "episode_reward": 361.5055481847675, "step": 78000}
{"episode": 79.0, "batch_reward": 0.2620801229327917, "actor_loss": -21.42456778717041, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.91673970222473, "episode_reward": 363.789905462171, "step": 79000}
{"episode": 80.0, "batch_reward": 0.2630827504694462, "actor_loss": -20.843469234466554, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 434.9036238193512, "episode_reward": 361.225330543136, "step": 80000}
{"episode": 81.0, "batch_reward": 0.2629861934930086, "actor_loss": -20.903920654296876, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 32.62712502479553, "episode_reward": 216.27975829706617, "step": 81000}
{"episode": 82.0, "batch_reward": 0.26356023688614366, "actor_loss": -20.251447990417482, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 435.56380343437195, "episode_reward": 349.97558276678643, "step": 82000}
{"episode": 83.0, "batch_reward": 0.2648299417197704, "actor_loss": -20.36346049118042, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.425410747528076, "episode_reward": 340.8821181244901, "step": 83000}
{"episode": 84.0, "batch_reward": 0.2657087555080652, "actor_loss": -20.96161408996582, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 439.2198393344879, "episode_reward": 333.62095668295126, "step": 84000}
{"episode": 85.0, "batch_reward": 0.26700764600932597, "actor_loss": -21.055161582946777, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.00703525543213, "episode_reward": 381.1080615683552, "step": 85000}
{"episode": 86.0, "batch_reward": 0.2674878004640341, "actor_loss": -20.506785449981688, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 452.41597175598145, "episode_reward": 382.4268460659855, "step": 86000}
{"episode": 87.0, "batch_reward": 0.2690718461573124, "actor_loss": -20.634081104278565, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.995097398757935, "episode_reward": 365.0626731204844, "step": 87000}
{"episode": 88.0, "batch_reward": 0.2711549967974424, "actor_loss": -20.777147315979004, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 442.1490647792816, "episode_reward": 371.69327551327234, "step": 88000}
{"episode": 89.0, "batch_reward": 0.27120248188078405, "actor_loss": -20.92409870147705, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.42883324623108, "episode_reward": 383.8586434807991, "step": 89000}
{"episode": 90.0, "batch_reward": 0.2726080964356661, "actor_loss": -20.725918502807616, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 448.8787376880646, "episode_reward": 338.23931335712473, "step": 90000}
{"episode": 91.0, "batch_reward": 0.27342460842430594, "actor_loss": -20.765095981597902, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 33.96807241439819, "episode_reward": 295.98217531007174, "step": 91000}
{"episode": 92.0, "batch_reward": 0.27383373022079466, "actor_loss": -20.47179682922363, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 431.97802805900574, "episode_reward": 274.4988199077821, "step": 92000}
{"episode": 93.0, "batch_reward": 0.27316578233242034, "actor_loss": -20.416254791259767, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.527501583099365, "episode_reward": 257.5169828140712, "step": 93000}
{"episode": 94.0, "batch_reward": 0.2732976779192686, "actor_loss": -20.614415370941163, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 445.0841295719147, "episode_reward": 310.2034567427213, "step": 94000}
{"episode": 95.0, "batch_reward": 0.2724050728827715, "actor_loss": -20.610711296081544, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.03027653694153, "episode_reward": 256.82685771674574, "step": 95000}
{"episode": 96.0, "batch_reward": 0.27351657435297966, "actor_loss": -19.680762851715087, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 443.7876937389374, "episode_reward": 311.0284272845694, "step": 96000}
{"episode": 97.0, "batch_reward": 0.2747551607191563, "actor_loss": -19.781258377075197, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.46836495399475, "episode_reward": 309.57363278763415, "step": 97000}
{"episode": 98.0, "batch_reward": 0.27408743964135646, "actor_loss": -19.373291465759277, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 442.58588790893555, "episode_reward": 344.32920343500575, "step": 98000}
{"episode": 99.0, "batch_reward": 0.2746831636279821, "actor_loss": -19.443606781005858, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.41954493522644, "episode_reward": 353.76370740631876, "step": 99000}
{"episode": 100.0, "batch_reward": 0.27630058194696905, "actor_loss": -19.21030534362793, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 437.332670211792, "episode_reward": 346.96425377752047, "step": 100000}
{"episode": 101.0, "batch_reward": 0.276914079606533, "actor_loss": -19.325089603424072, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 34.10159373283386, "episode_reward": 376.2642268954377, "step": 101000}
{"episode": 102.0, "batch_reward": 0.2773796011209488, "actor_loss": -18.934308406829835, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 448.57804584503174, "episode_reward": 377.58806161324424, "step": 102000}
{"episode": 103.0, "batch_reward": 0.2786633629798889, "actor_loss": -19.17343201446533, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.164352655410767, "episode_reward": 351.92076532426984, "step": 103000}
{"episode": 104.0, "batch_reward": 0.2784394993335009, "actor_loss": -19.404425651550294, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 440.3752589225769, "episode_reward": 234.95016034211108, "step": 104000}
{"episode": 105.0, "batch_reward": 0.27932853481173514, "actor_loss": -19.429706893920898, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.438616275787354, "episode_reward": 348.00114972624186, "step": 105000}
{"episode": 106.0, "batch_reward": 0.27941344180703165, "actor_loss": -19.508986209869384, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 444.6623682975769, "episode_reward": 394.27971438688775, "step": 106000}
{"episode": 107.0, "batch_reward": 0.28082228760421274, "actor_loss": -19.654551605224608, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.659351587295532, "episode_reward": 402.7886176612914, "step": 107000}
{"episode": 108.0, "batch_reward": 0.2818877509087324, "actor_loss": -19.81452982330322, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 447.96703243255615, "episode_reward": 378.26851212431313, "step": 108000}
{"episode": 109.0, "batch_reward": 0.2830495980530977, "actor_loss": -19.91982608795166, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.397596836090088, "episode_reward": 409.4029113738273, "step": 109000}
{"episode": 110.0, "batch_reward": 0.28412604542076586, "actor_loss": -19.934326362609863, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 441.5972526073456, "episode_reward": 360.8238088020795, "step": 110000}
{"episode": 111.0, "batch_reward": 0.28500965055823324, "actor_loss": -19.91506873321533, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 33.125930070877075, "episode_reward": 355.34184363750916, "step": 111000}
{"episode": 112.0, "batch_reward": 0.28552432841062547, "actor_loss": -20.440216800689697, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 452.4028830528259, "episode_reward": 407.0182814567154, "step": 112000}
{"episode": 113.0, "batch_reward": 0.2867218742519617, "actor_loss": -20.63107580566406, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.76591658592224, "episode_reward": 373.76087846100256, "step": 113000}
{"episode": 114.0, "batch_reward": 0.28726859733462334, "actor_loss": -20.190087776184082, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 448.3679270744324, "episode_reward": 365.0817574335546, "step": 114000}
{"episode": 115.0, "batch_reward": 0.2876058022081852, "actor_loss": -20.23584404373169, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.340128660202026, "episode_reward": 348.06952863877535, "step": 115000}
{"episode": 116.0, "batch_reward": 0.28824774965643885, "actor_loss": -19.88156913757324, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 439.65505957603455, "episode_reward": 375.1794351187098, "step": 116000}
{"episode": 117.0, "batch_reward": 0.28739995466172696, "actor_loss": -19.789769443511965, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 20.606479167938232, "episode_reward": 31.094032730871742, "step": 117000}
{"episode": 118.0, "batch_reward": 0.285777482137084, "actor_loss": -19.452077102661132, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 447.4930157661438, "episode_reward": 285.3914865245496, "step": 118000}
{"episode": 119.0, "batch_reward": 0.28691695593297484, "actor_loss": -19.499737014770506, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.71399450302124, "episode_reward": 392.12511302831706, "step": 119000}
{"episode": 120.0, "batch_reward": 0.2870474736839533, "actor_loss": -20.40528861618042, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 447.4842371940613, "episode_reward": 203.84433073813315, "step": 120000}
{"episode": 121.0, "batch_reward": 0.286926272392273, "actor_loss": -20.39488004684448, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 38.68070077896118, "episode_reward": 405.47052923810134, "step": 121000}
{"episode": 122.0, "batch_reward": 0.288501464471221, "actor_loss": -19.72959698867798, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 446.85055327415466, "episode_reward": 431.93647959478255, "step": 122000}
{"episode": 123.0, "batch_reward": 0.2884914279729128, "actor_loss": -19.81518444824219, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.218717336654663, "episode_reward": 438.3005640888015, "step": 123000}
{"episode": 124.0, "batch_reward": 0.29161638411879537, "actor_loss": -19.721933673858643, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 450.6958885192871, "episode_reward": 422.28511312409057, "step": 124000}
{"episode": 125.0, "batch_reward": 0.2913407433331013, "actor_loss": -19.760918296813966, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.57043170928955, "episode_reward": 305.90558761918214, "step": 125000}
{"episode": 126.0, "batch_reward": 0.2912635634839535, "actor_loss": -19.644366600036623, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 440.64089012145996, "episode_reward": 405.5231593809618, "step": 126000}
{"episode": 127.0, "batch_reward": 0.29300358064472676, "actor_loss": -19.821798416137696, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.56231117248535, "episode_reward": 409.52250927668246, "step": 127000}
{"episode": 128.0, "batch_reward": 0.2939857606738806, "actor_loss": -19.867562881469727, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 452.09425044059753, "episode_reward": 399.43096643378544, "step": 128000}
{"episode": 129.0, "batch_reward": 0.29440628123283386, "actor_loss": -19.8669626121521, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.10967445373535, "episode_reward": 415.45927300513927, "step": 129000}
{"episode": 130.0, "batch_reward": 0.2944025303274393, "actor_loss": -20.55532444381714, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 438.69938254356384, "episode_reward": 387.0097217000318, "step": 130000}
{"episode": 131.0, "batch_reward": 0.29566575625538827, "actor_loss": -20.602255210876464, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 34.21121430397034, "episode_reward": 393.60183614004006, "step": 131000}
{"episode": 132.0, "batch_reward": 0.29674424839019775, "actor_loss": -20.581743251800535, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 441.7671492099762, "episode_reward": 355.21295506144827, "step": 132000}
{"episode": 133.0, "batch_reward": 0.29746356898546217, "actor_loss": -20.75586022567749, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.06109881401062, "episode_reward": 359.0323224051305, "step": 133000}
{"episode": 134.0, "batch_reward": 0.29766373896598813, "actor_loss": -20.99137763977051, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 444.7629210948944, "episode_reward": 274.80001315242845, "step": 134000}
{"episode": 135.0, "batch_reward": 0.2961639449596405, "actor_loss": -20.843978073120116, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.411627054214478, "episode_reward": 329.90981915413835, "step": 135000}
{"episode": 136.0, "batch_reward": 0.29820663753151894, "actor_loss": -20.761997608184814, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 443.11585116386414, "episode_reward": 396.2528414395767, "step": 136000}
{"episode": 137.0, "batch_reward": 0.299089443475008, "actor_loss": -20.855910976409913, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.284435272216797, "episode_reward": 383.24889888651825, "step": 137000}
{"episode": 138.0, "batch_reward": 0.2993571571409702, "actor_loss": -20.60996092605591, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 453.2904098033905, "episode_reward": 389.50219997113106, "step": 138000}
{"episode": 139.0, "batch_reward": 0.2988035401105881, "actor_loss": -20.57264556503296, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.714993715286255, "episode_reward": 195.1700186916981, "step": 139000}
{"episode": 140.0, "batch_reward": 0.29965918058156965, "actor_loss": -20.619681106567384, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 442.1166913509369, "episode_reward": 383.1587381123062, "step": 140000}
{"episode": 141.0, "batch_reward": 0.29876287230849263, "actor_loss": -20.592673168182372, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 37.90247392654419, "episode_reward": 407.1306168910125, "step": 141000}
{"episode": 142.0, "batch_reward": 0.2993707757592201, "actor_loss": -20.94951012802124, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 424.5317575931549, "episode_reward": 298.598730498893, "step": 142000}
{"episode": 143.0, "batch_reward": 0.2992989718914032, "actor_loss": -21.01582223892212, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.809829235076904, "episode_reward": 67.7644445423382, "step": 143000}
{"episode": 144.0, "batch_reward": 0.2968893488943577, "actor_loss": -20.93575802230835, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 427.9735162258148, "episode_reward": 36.80378378401926, "step": 144000}
{"episode": 145.0, "batch_reward": 0.29621969901025297, "actor_loss": -20.89308151245117, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.119086503982544, "episode_reward": 282.5664780706262, "step": 145000}
{"episode": 146.0, "batch_reward": 0.296192085146904, "actor_loss": -21.111584892272948, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 423.7692348957062, "episode_reward": 125.63815823225241, "step": 146000}
{"episode": 147.0, "batch_reward": 0.29482440192997456, "actor_loss": -21.04468481063843, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.193243980407715, "episode_reward": 61.6187820077568, "step": 147000}
{"episode": 148.0, "batch_reward": 0.29406516733765603, "actor_loss": -20.994758670806885, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 433.46125292778015, "episode_reward": 365.37289480048577, "step": 148000}
{"episode": 149.0, "batch_reward": 0.294103698939085, "actor_loss": -20.99548444747925, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.11325216293335, "episode_reward": 351.92167757726213, "step": 149000}
{"episode": 150.0, "batch_reward": 0.29368115746974943, "actor_loss": -21.06387292098999, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "step": 150000}
