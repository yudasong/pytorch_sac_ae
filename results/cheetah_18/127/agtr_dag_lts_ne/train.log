{"episode": 1.0, "duration": 18.503092527389526, "episode_reward": 7.051849146674556, "step": 1000}
{"episode": 2.0, "duration": 1.5302293300628662, "episode_reward": 365.4711839680396, "step": 2000}
{"episode": 3.0, "batch_reward": 0.1909955693368476, "critic_loss": 0.6673674510345335, "actor_loss": -41.37718895083668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 73.94625616073608, "episode_reward": 302.9962026308635, "step": 3000}
{"episode": 4.0, "batch_reward": 0.24219859141111375, "critic_loss": 0.7940302078127861, "actor_loss": -46.197616355895995, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.114856004714966, "episode_reward": 401.7811358527059, "step": 4000}
{"episode": 5.0, "batch_reward": 0.2834602809101343, "critic_loss": 0.9985348867177963, "actor_loss": -48.78175183868408, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.879085302352905, "episode_reward": 473.35504832944014, "step": 5000}
{"episode": 6.0, "batch_reward": 0.3201673928797245, "critic_loss": 1.3707201011776924, "actor_loss": -51.66385305786133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.458160161972046, "episode_reward": 468.26316142744037, "step": 6000}
{"episode": 7.0, "batch_reward": 0.3478131273090839, "critic_loss": 1.5815889027118684, "actor_loss": -52.807714126586916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.77136492729187, "episode_reward": 521.318814943465, "step": 7000}
{"episode": 8.0, "batch_reward": 0.36884457695484163, "critic_loss": 1.537188776552677, "actor_loss": -53.94103720092773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.336032152175903, "episode_reward": 494.7110282147057, "step": 8000}
{"episode": 9.0, "batch_reward": 0.3835773996412754, "critic_loss": 1.2681976128220558, "actor_loss": -54.99301971435547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.509679079055786, "episode_reward": 451.4630017787317, "step": 9000}
{"episode": 10.0, "batch_reward": 0.38991389283537864, "critic_loss": 1.0308768639564514, "actor_loss": -53.04647976684571, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 3946.3055992126465, "episode_reward": 454.96912010790317, "step": 10000}
{"episode": 11.0, "batch_reward": 0.3917491146624088, "critic_loss": 0.8721713317632676, "actor_loss": -52.646334671020504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.01833653450012, "episode_reward": 396.5317034563577, "step": 11000}
{"episode": 12.0, "batch_reward": 0.4000380669236183, "critic_loss": 0.808230684787035, "actor_loss": -50.635833656311036, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 441.16546392440796, "episode_reward": 495.0805059446163, "step": 12000}
{"episode": 13.0, "batch_reward": 0.39718956795334814, "critic_loss": 0.7349136854708195, "actor_loss": -49.53861795043945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.452993869781494, "episode_reward": 174.78160840229023, "step": 13000}
{"episode": 14.0, "batch_reward": 0.38818784040212634, "critic_loss": 0.6049355926215648, "actor_loss": -45.51497650909424, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 439.8066973686218, "episode_reward": 517.1653435704773, "step": 14000}
{"episode": 15.0, "batch_reward": 0.3948643006980419, "critic_loss": 0.598440346032381, "actor_loss": -45.85706248474121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.91658306121826, "episode_reward": 386.8249785085557, "step": 15000}
{"episode": 16.0, "batch_reward": 0.3945933150649071, "critic_loss": 0.6022977930605411, "actor_loss": -44.70673030853271, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 440.0174767971039, "episode_reward": 440.3006888336406, "step": 16000}
{"episode": 17.0, "batch_reward": 0.3979436328113079, "critic_loss": 0.557857957571745, "actor_loss": -44.52057053375244, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.489134311676025, "episode_reward": 454.5359917707376, "step": 17000}
{"episode": 18.0, "batch_reward": 0.4019161926805973, "critic_loss": 0.5050361074507237, "actor_loss": -44.07500535583496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 434.43403005599976, "episode_reward": 467.8676642758777, "step": 18000}
{"episode": 19.0, "batch_reward": 0.4055052421689033, "critic_loss": 0.5070060324072838, "actor_loss": -43.862230583190915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.446266651153564, "episode_reward": 489.7569519835554, "step": 19000}
{"episode": 20.0, "batch_reward": 0.40931521251797676, "critic_loss": 0.5103697067201137, "actor_loss": -42.96329328918457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 436.90987753868103, "episode_reward": 488.0129223627655, "step": 20000}
{"episode": 21.0, "batch_reward": 0.41413806411623955, "critic_loss": 0.5173014620840549, "actor_loss": -42.92593154144287, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.84722280502319, "episode_reward": 472.6026495165746, "step": 21000}
{"episode": 22.0, "batch_reward": 0.4175336560308933, "critic_loss": 0.48712205854058266, "actor_loss": -42.405352836608884, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 435.93280506134033, "episode_reward": 512.637222249048, "step": 22000}
{"episode": 23.0, "batch_reward": 0.4216845289468765, "critic_loss": 0.5003032194375991, "actor_loss": -42.41086567687988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.3310546875, "episode_reward": 485.33384417155173, "step": 23000}
{"episode": 24.0, "batch_reward": 0.42534407836198806, "critic_loss": 0.4742911734431982, "actor_loss": -42.535949157714846, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 435.80323791503906, "episode_reward": 542.2444837408256, "step": 24000}
{"episode": 25.0, "batch_reward": 0.4280074589550495, "critic_loss": 0.4664959043562412, "actor_loss": -42.464037483215336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.258869171142578, "episode_reward": 488.57389786605773, "step": 25000}
{"episode": 26.0, "batch_reward": 0.43081811732053754, "critic_loss": 0.4855502621680498, "actor_loss": -42.44448994064331, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 436.924280166626, "episode_reward": 474.5836551369748, "step": 26000}
{"episode": 27.0, "batch_reward": 0.4329290705025196, "critic_loss": 0.45918632119894026, "actor_loss": -42.30962663269043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.996069192886353, "episode_reward": 500.53803051786036, "step": 27000}
{"episode": 28.0, "batch_reward": 0.4342912583053112, "critic_loss": 0.4299537397325039, "actor_loss": -42.098485984802245, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 437.2734251022339, "episode_reward": 523.8684396229993, "step": 28000}
{"episode": 29.0, "batch_reward": 0.4389181206226349, "critic_loss": 0.44774963521957395, "actor_loss": -41.54674449920654, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.171392917633057, "episode_reward": 496.57215170506737, "step": 29000}
{"episode": 30.0, "batch_reward": 0.44024778416752813, "critic_loss": 0.44793725322186945, "actor_loss": -41.919145584106445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 436.1444227695465, "episode_reward": 484.5087377735149, "step": 30000}
{"episode": 31.0, "batch_reward": 0.4411095013022423, "critic_loss": 0.4574424152523279, "actor_loss": -41.48331285858154, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.242920875549316, "episode_reward": 484.3562477704649, "step": 31000}
{"episode": 32.0, "batch_reward": 0.4427841899394989, "critic_loss": 0.45089348389208317, "actor_loss": -41.12790826034546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 434.3228268623352, "episode_reward": 477.3574238355775, "step": 32000}
{"episode": 33.0, "batch_reward": 0.4430090257227421, "critic_loss": 0.4538736302405596, "actor_loss": -41.2320097732544, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.448933601379395, "episode_reward": 445.73651277561027, "step": 33000}
{"episode": 34.0, "batch_reward": 0.44359206315875055, "critic_loss": 0.4429489421993494, "actor_loss": -40.62267325592041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 434.46113538742065, "episode_reward": 457.69224743928015, "step": 34000}
{"episode": 35.0, "batch_reward": 0.4449443941116333, "critic_loss": 0.44385041131079195, "actor_loss": -41.13495350265503, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.50979208946228, "episode_reward": 488.63753468239355, "step": 35000}
{"episode": 36.0, "batch_reward": 0.44537428990006445, "critic_loss": 0.4388809331655502, "actor_loss": -40.90317419433594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 434.62348198890686, "episode_reward": 476.11600659063026, "step": 36000}
{"episode": 37.0, "batch_reward": 0.4459431307911873, "critic_loss": 0.4247099696844816, "actor_loss": -40.224976608276364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.492175340652466, "episode_reward": 456.8548782665082, "step": 37000}
{"episode": 38.0, "batch_reward": 0.4460614939332008, "critic_loss": 0.41320144644379614, "actor_loss": -40.90409016418457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 433.97413396835327, "episode_reward": 513.8952075457564, "step": 38000}
{"episode": 39.0, "batch_reward": 0.449372061252594, "critic_loss": 0.3833614256680012, "actor_loss": -40.67734442138672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.494757175445557, "episode_reward": 479.17242656458006, "step": 39000}
{"episode": 40.0, "batch_reward": 0.4493843552172184, "critic_loss": 0.3885888864248991, "actor_loss": -41.371670066833495, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 434.3862166404724, "episode_reward": 495.71292444581036, "step": 40000}
{"episode": 41.0, "batch_reward": 0.4503938929140568, "critic_loss": 0.36137213283777236, "actor_loss": -40.50835221862793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.74422574043274, "episode_reward": 491.89957066496504, "step": 41000}
{"episode": 42.0, "batch_reward": 0.4513661777973175, "critic_loss": 0.3713016581237316, "actor_loss": -40.81279741668701, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 423.93054127693176, "episode_reward": 484.3841834135669, "step": 42000}
{"episode": 43.0, "batch_reward": 0.4525167905688286, "critic_loss": 0.34289903669059274, "actor_loss": -40.45413322448731, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.999874114990234, "episode_reward": 475.0254277258335, "step": 43000}
{"episode": 44.0, "batch_reward": 0.45337983685731886, "critic_loss": 0.31927894954383373, "actor_loss": -40.98865993499756, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 433.7232828140259, "episode_reward": 466.826094616738, "step": 44000}
{"episode": 45.0, "batch_reward": 0.45327565318346025, "critic_loss": 0.3214793040603399, "actor_loss": -40.71777238464355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.206342458724976, "episode_reward": 472.85734961660063, "step": 45000}
{"episode": 46.0, "batch_reward": 0.453677333176136, "critic_loss": 0.30525652316212654, "actor_loss": -40.99058045196533, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 432.6031002998352, "episode_reward": 475.8576179789253, "step": 46000}
{"episode": 47.0, "batch_reward": 0.45365977865457535, "critic_loss": 0.3010751187950373, "actor_loss": -40.465031517028805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.97784948348999, "episode_reward": 451.19795201101346, "step": 47000}
{"episode": 48.0, "batch_reward": 0.45316880017518996, "critic_loss": 0.28257825717329976, "actor_loss": -40.80806932830811, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 433.87528443336487, "episode_reward": 453.1879159043415, "step": 48000}
{"episode": 49.0, "batch_reward": 0.4523286209702492, "critic_loss": 0.27917460426688195, "actor_loss": -40.619991325378415, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.3553626537323, "episode_reward": 456.318284900711, "step": 49000}
{"episode": 50.0, "batch_reward": 0.45370721715688705, "critic_loss": 0.258339827761054, "actor_loss": -40.77209234619141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 433.2071168422699, "episode_reward": 485.76735342562256, "step": 50000}
{"episode": 51.0, "batch_reward": 0.4542542796432972, "critic_loss": 0.2489285158663988, "actor_loss": -40.95879613494873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.84456014633179, "episode_reward": 486.04582137293204, "step": 51000}
{"episode": 52.0, "batch_reward": 0.45494917207956315, "critic_loss": 0.25192490696907044, "actor_loss": -40.595550514221195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 433.11916613578796, "episode_reward": 492.25579922276, "step": 52000}
{"episode": 53.0, "batch_reward": 0.45618237954378127, "critic_loss": 0.253718449011445, "actor_loss": -40.47923621368408, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.333651065826416, "episode_reward": 470.2087023688945, "step": 53000}
{"episode": 54.0, "batch_reward": 0.45576560306549074, "critic_loss": 0.2529565685093403, "actor_loss": -40.85425392913818, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 432.8984384536743, "episode_reward": 460.09859143524085, "step": 54000}
{"episode": 55.0, "batch_reward": 0.45576875904202463, "critic_loss": 0.24927153976261615, "actor_loss": -40.788271995544434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.505865812301636, "episode_reward": 454.63946801913823, "step": 55000}
{"episode": 56.0, "batch_reward": 0.4563156631588936, "critic_loss": 0.23074907479435205, "actor_loss": -41.22570150756836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 433.467431306839, "episode_reward": 475.91952378524576, "step": 56000}
{"episode": 57.0, "batch_reward": 0.456845111310482, "critic_loss": 0.2294766934812069, "actor_loss": -41.24554997253418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.535864114761353, "episode_reward": 500.33416978615634, "step": 57000}
{"episode": 58.0, "batch_reward": 0.4572422670722008, "critic_loss": 0.2254360651448369, "actor_loss": -40.914882957458495, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 432.01520895957947, "episode_reward": 471.8297999337309, "step": 58000}
{"episode": 59.0, "batch_reward": 0.4578454051017761, "critic_loss": 0.22763604944199323, "actor_loss": -40.60837954711914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.247694969177246, "episode_reward": 475.1885752581434, "step": 59000}
{"episode": 60.0, "batch_reward": 0.457965601503849, "critic_loss": 0.22545076641440392, "actor_loss": -40.81972927856445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 432.8497304916382, "episode_reward": 469.2604285216984, "step": 60000}
{"episode": 61.0, "batch_reward": 0.4575260851979256, "critic_loss": 0.22173437539488078, "actor_loss": -40.68741366577149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.8908588886261, "episode_reward": 433.25293707766286, "step": 61000}
{"episode": 62.0, "batch_reward": 0.45691318181157115, "critic_loss": 0.21481769897788763, "actor_loss": -40.61646484375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 431.97840213775635, "episode_reward": 475.1451145724946, "step": 62000}
{"episode": 63.0, "batch_reward": 0.457865179002285, "critic_loss": 0.21585680171847343, "actor_loss": -40.78728618621826, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.475056409835815, "episode_reward": 454.3957594823073, "step": 63000}
{"episode": 64.0, "batch_reward": 0.4574385051727295, "critic_loss": 0.21366559084504844, "actor_loss": -40.83076937866211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 433.5831546783447, "episode_reward": 456.1684907970705, "step": 64000}
{"episode": 65.0, "batch_reward": 0.4578315676152706, "critic_loss": 0.23419021556526423, "actor_loss": -40.72339097595215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.147602558135986, "episode_reward": 443.927991423413, "step": 65000}
{"episode": 66.0, "batch_reward": 0.457437354773283, "critic_loss": 0.2546331451758742, "actor_loss": -40.535097221374514, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 432.3171138763428, "episode_reward": 432.44909713414637, "step": 66000}
{"episode": 67.0, "batch_reward": 0.4559604329764843, "critic_loss": 0.3063914862945676, "actor_loss": -40.47016596221924, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.027745723724365, "episode_reward": 418.28388561984286, "step": 67000}
{"episode": 68.0, "batch_reward": 0.4527650994062424, "critic_loss": 0.32172532837092876, "actor_loss": -40.41611956787109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 431.694299697876, "episode_reward": 8.288505013894351, "step": 68000}
{"episode": 69.0, "batch_reward": 0.4462573167979717, "critic_loss": 0.3125191556513309, "actor_loss": -39.692979553222656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.916667699813843, "episode_reward": 4.722914777334743, "step": 69000}
{"episode": 70.0, "batch_reward": 0.4399836091697216, "critic_loss": 0.27377150413393975, "actor_loss": -39.72619760894776, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 431.29138112068176, "episode_reward": 8.92825625773684, "step": 70000}
{"episode": 71.0, "batch_reward": 0.4337117149531841, "critic_loss": 0.24991602256149054, "actor_loss": -39.71845302581787, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.86123490333557, "episode_reward": 3.5259108444981413, "step": 71000}
{"episode": 72.0, "batch_reward": 0.4311873141229153, "critic_loss": 0.233550286360085, "actor_loss": -39.48341763687134, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 431.54117798805237, "episode_reward": 418.110606820837, "step": 72000}
{"episode": 73.0, "batch_reward": 0.42998214572668075, "critic_loss": 0.22208526284247637, "actor_loss": -39.649241989135746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.12974715232849, "episode_reward": 315.0314197202502, "step": 73000}
{"episode": 74.0, "batch_reward": 0.4278197357058525, "critic_loss": 0.20663823556154967, "actor_loss": -39.20053174209595, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 430.36890029907227, "episode_reward": 316.2733191433674, "step": 74000}
{"episode": 75.0, "batch_reward": 0.42459592714905736, "critic_loss": 0.20078824716061353, "actor_loss": -38.889236259460446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.58200979232788, "episode_reward": 65.56363815906317, "step": 75000}
{"episode": 76.0, "batch_reward": 0.421834275752306, "critic_loss": 0.18611161148548125, "actor_loss": -39.4378297958374, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 430.5899477005005, "episode_reward": 299.9498367677962, "step": 76000}
{"episode": 77.0, "batch_reward": 0.4190356278717518, "critic_loss": 0.19540841725468636, "actor_loss": -38.87171407318115, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.59557271003723, "episode_reward": 160.78542357004162, "step": 77000}
{"episode": 78.0, "batch_reward": 0.4175071552991867, "critic_loss": 0.1891406487748027, "actor_loss": -38.964886116027834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 431.8990271091461, "episode_reward": 467.5074919858193, "step": 78000}
{"episode": 79.0, "batch_reward": 0.4187463698089123, "critic_loss": 0.19649289888888596, "actor_loss": -38.910716297149655, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.460171222686768, "episode_reward": 448.2184425141336, "step": 79000}
{"episode": 80.0, "batch_reward": 0.41939132726192474, "critic_loss": 0.21607665357738734, "actor_loss": -38.65215860748291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 431.59605598449707, "episode_reward": 428.44256412871226, "step": 80000}
{"episode": 81.0, "batch_reward": 0.41926818922162057, "critic_loss": 0.21509462518244982, "actor_loss": -38.77549124526978, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.90854215621948, "episode_reward": 452.9053509158501, "step": 81000}
{"episode": 82.0, "batch_reward": 0.4199828477501869, "critic_loss": 0.21122885177284478, "actor_loss": -39.36291641616821, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 431.26772594451904, "episode_reward": 472.12907768730275, "step": 82000}
{"episode": 83.0, "batch_reward": 0.4203085765838623, "critic_loss": 0.21339072079211474, "actor_loss": -39.12915960311889, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.13156771659851, "episode_reward": 463.97160327311263, "step": 83000}
{"episode": 84.0, "batch_reward": 0.4216540048122406, "critic_loss": 0.20455836340039968, "actor_loss": -39.320305168151855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 431.1653025150299, "episode_reward": 474.2653644149027, "step": 84000}
{"episode": 85.0, "batch_reward": 0.4210843549668789, "critic_loss": 0.20466763347387315, "actor_loss": -38.990328147888185, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.347694158554077, "episode_reward": 451.19970997238147, "step": 85000}
{"episode": 86.0, "batch_reward": 0.42186792874336243, "critic_loss": 0.20679677135497332, "actor_loss": -39.2637036743164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 430.8727219104767, "episode_reward": 455.6574322400964, "step": 86000}
{"episode": 87.0, "batch_reward": 0.421903443723917, "critic_loss": 0.21072657722979785, "actor_loss": -39.547096977233885, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.539917945861816, "episode_reward": 483.67800435156227, "step": 87000}
{"episode": 88.0, "batch_reward": 0.4235370032787323, "critic_loss": 0.20598310475051404, "actor_loss": -40.02513687896729, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 433.2342438697815, "episode_reward": 457.5212036771526, "step": 88000}
{"episode": 89.0, "batch_reward": 0.4225897558033466, "critic_loss": 0.21457983611524106, "actor_loss": -39.652449043273926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.0427303314209, "episode_reward": 434.7578665649682, "step": 89000}
{"episode": 90.0, "batch_reward": 0.42301173824071886, "critic_loss": 0.20395400088280438, "actor_loss": -40.032482543945314, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 430.27712845802307, "episode_reward": 475.9712240458843, "step": 90000}
{"episode": 91.0, "batch_reward": 0.42409360948204994, "critic_loss": 0.19536063403636217, "actor_loss": -40.28638083648681, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.82090759277344, "episode_reward": 487.2873753486625, "step": 91000}
{"episode": 92.0, "batch_reward": 0.42385679346323013, "critic_loss": 0.19667237596213819, "actor_loss": -39.75308660125732, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 423.8936541080475, "episode_reward": 451.9063449386503, "step": 92000}
{"episode": 93.0, "batch_reward": 0.42481394428014757, "critic_loss": 0.19367820819467307, "actor_loss": -39.89982430267334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.419234037399292, "episode_reward": 445.08580264872967, "step": 93000}
{"episode": 94.0, "batch_reward": 0.42480042907595633, "critic_loss": 0.19649798784404993, "actor_loss": -39.97723034667969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 430.08859729766846, "episode_reward": 445.5847738960497, "step": 94000}
{"episode": 95.0, "batch_reward": 0.425875169724226, "critic_loss": 0.18104380829632283, "actor_loss": -40.05398365020752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.426445722579956, "episode_reward": 457.1003272750377, "step": 95000}
{"episode": 96.0, "batch_reward": 0.42552461290359495, "critic_loss": 0.17809767284989356, "actor_loss": -40.2427610244751, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 430.3796305656433, "episode_reward": 470.6373745233825, "step": 96000}
{"episode": 97.0, "batch_reward": 0.42640376633405686, "critic_loss": 0.1738472827896476, "actor_loss": -40.35315145111084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.268445014953613, "episode_reward": 487.4445104762623, "step": 97000}
{"episode": 98.0, "batch_reward": 0.4269084986150265, "critic_loss": 0.18100173365324734, "actor_loss": -39.81328551483154, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 431.3681266307831, "episode_reward": 453.5745660723563, "step": 98000}
{"episode": 99.0, "batch_reward": 0.4274711530804634, "critic_loss": 0.17369752535223962, "actor_loss": -40.291933448791504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.984362602233887, "episode_reward": 462.1817990166542, "step": 99000}
{"episode": 100.0, "batch_reward": 0.42755163776874544, "critic_loss": 0.17046481928229332, "actor_loss": -40.41604718780518, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 430.62295746803284, "episode_reward": 456.43854139582646, "step": 100000}
{"episode": 101.0, "batch_reward": 0.42707504898309706, "critic_loss": 0.17355400228500367, "actor_loss": -40.41630018615723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.606215715408325, "episode_reward": 458.8276320488149, "step": 101000}
{"episode": 102.0, "batch_reward": 0.42802983057498933, "critic_loss": 0.16730650663375854, "actor_loss": -40.40546047973633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 430.157338142395, "episode_reward": 465.38400073628793, "step": 102000}
{"episode": 103.0, "batch_reward": 0.42804582992196083, "critic_loss": 0.16853112408518792, "actor_loss": -40.713095420837405, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.11630868911743, "episode_reward": 459.8362366863288, "step": 103000}
{"episode": 104.0, "batch_reward": 0.42901759734749795, "critic_loss": 0.16435934016108514, "actor_loss": -40.55871347808838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 431.232901096344, "episode_reward": 465.14097740471954, "step": 104000}
{"episode": 105.0, "batch_reward": 0.4294207679331303, "critic_loss": 0.16626798734813927, "actor_loss": -40.910595664978025, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.205637216567993, "episode_reward": 480.969669870657, "step": 105000}
{"episode": 106.0, "batch_reward": 0.42960272133350375, "critic_loss": 0.16850470601022244, "actor_loss": -41.11529965209961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 429.8907685279846, "episode_reward": 454.39481012335415, "step": 106000}
{"episode": 107.0, "batch_reward": 0.4299101732671261, "critic_loss": 0.15364747861772776, "actor_loss": -41.23325713348389, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.26350426673889, "episode_reward": 468.8138850549958, "step": 107000}
{"episode": 108.0, "batch_reward": 0.4302870193123817, "critic_loss": 0.1604870377033949, "actor_loss": -41.252943748474124, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 429.89458560943604, "episode_reward": 453.7953604257617, "step": 108000}
{"episode": 109.0, "batch_reward": 0.43062181627750395, "critic_loss": 0.15502528318017722, "actor_loss": -41.44318958282471, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.822893857955933, "episode_reward": 473.33467337505584, "step": 109000}
{"episode": 110.0, "batch_reward": 0.4306408085823059, "critic_loss": 0.15484296841174364, "actor_loss": -41.53038069915772, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 431.5499596595764, "episode_reward": 484.1569638473953, "step": 110000}
{"episode": 111.0, "batch_reward": 0.4314348988831043, "critic_loss": 0.1539616555571556, "actor_loss": -41.35528955841065, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.32593369483948, "episode_reward": 489.36036634447, "step": 111000}
{"episode": 112.0, "batch_reward": 0.4324678388237953, "critic_loss": 0.15572668950259685, "actor_loss": -41.195890975952146, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 430.2092089653015, "episode_reward": 463.2726237817308, "step": 112000}
{"episode": 113.0, "batch_reward": 0.43232720598578456, "critic_loss": 0.15213042906671762, "actor_loss": -41.5948825302124, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.91723656654358, "episode_reward": 473.68785186855007, "step": 113000}
{"episode": 114.0, "batch_reward": 0.43231467160582543, "critic_loss": 0.15247384767979383, "actor_loss": -41.493888145446775, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 428.82791900634766, "episode_reward": 463.5901154611704, "step": 114000}
{"episode": 115.0, "batch_reward": 0.43224731174111364, "critic_loss": 0.1496873961687088, "actor_loss": -41.40419223022461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.302953720092773, "episode_reward": 482.8584413994313, "step": 115000}
{"episode": 116.0, "batch_reward": 0.43355281233787535, "critic_loss": 0.1547886401042342, "actor_loss": -41.46316058349609, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 428.3156716823578, "episode_reward": 496.7624945603079, "step": 116000}
{"episode": 117.0, "batch_reward": 0.43376612511277196, "critic_loss": 0.1523969315364957, "actor_loss": -41.651435470581056, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.104716777801514, "episode_reward": 489.84835211674863, "step": 117000}
{"episode": 118.0, "batch_reward": 0.4337503160238266, "critic_loss": 0.15326069454848767, "actor_loss": -41.098623153686525, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 427.327294588089, "episode_reward": 468.77211705341335, "step": 118000}
{"episode": 119.0, "batch_reward": 0.4346994969248772, "critic_loss": 0.1417023049518466, "actor_loss": -41.104245094299316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.944366693496704, "episode_reward": 486.4859285308009, "step": 119000}
{"episode": 120.0, "batch_reward": 0.4345273210704327, "critic_loss": 0.14484814797341825, "actor_loss": -41.2324529800415, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 428.3080816268921, "episode_reward": 466.9169956496711, "step": 120000}
{"episode": 121.0, "batch_reward": 0.43567466831207274, "critic_loss": 0.15054344233870506, "actor_loss": -41.39763175201416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.851266860961914, "episode_reward": 464.7627463674671, "step": 121000}
{"episode": 122.0, "batch_reward": 0.4354462396800518, "critic_loss": 0.15489038770645858, "actor_loss": -41.451778160095216, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 428.0217125415802, "episode_reward": 468.5184993553207, "step": 122000}
{"episode": 123.0, "batch_reward": 0.43559539794921875, "critic_loss": 0.15445074384287, "actor_loss": -41.271561302185056, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.89171862602234, "episode_reward": 447.08448984743904, "step": 123000}
{"episode": 124.0, "batch_reward": 0.43566586208343505, "critic_loss": 0.14666235533356667, "actor_loss": -41.1718006362915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 426.54507303237915, "episode_reward": 475.811223351398, "step": 124000}
{"episode": 125.0, "batch_reward": 0.4358564949929714, "critic_loss": 0.15001979803666474, "actor_loss": -40.99293919372558, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.930399656295776, "episode_reward": 453.7788492821959, "step": 125000}
{"episode": 126.0, "batch_reward": 0.4360785141289234, "critic_loss": 0.14172152838110924, "actor_loss": -41.23296001434326, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 427.2119495868683, "episode_reward": 477.4902502338776, "step": 126000}
{"episode": 127.0, "batch_reward": 0.4367558613717556, "critic_loss": 0.15015937827527523, "actor_loss": -41.30722789764404, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.999310731887817, "episode_reward": 464.77954301277464, "step": 127000}
{"episode": 128.0, "batch_reward": 0.436861795514822, "critic_loss": 0.14758729414641858, "actor_loss": -41.280039779663085, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 427.6909878253937, "episode_reward": 473.2738780103145, "step": 128000}
{"episode": 129.0, "batch_reward": 0.4373038949370384, "critic_loss": 0.15126173355430364, "actor_loss": -41.182882591247555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.93394947052002, "episode_reward": 471.4501525746797, "step": 129000}
{"episode": 130.0, "batch_reward": 0.43722222352027895, "critic_loss": 0.1459058235436678, "actor_loss": -41.56862773132324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 425.1157970428467, "episode_reward": 471.48667241735217, "step": 130000}
{"episode": 131.0, "batch_reward": 0.4369470399916172, "critic_loss": 0.14537749204039574, "actor_loss": -41.316446334838865, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.50467824935913, "episode_reward": 478.41758111278733, "step": 131000}
{"episode": 132.0, "batch_reward": 0.4379788148701191, "critic_loss": 0.1436292743012309, "actor_loss": -41.51808414459229, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 424.35604882240295, "episode_reward": 491.4835477170588, "step": 132000}
{"episode": 133.0, "batch_reward": 0.438763039290905, "critic_loss": 0.14996485847234725, "actor_loss": -41.54823289489746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.88579297065735, "episode_reward": 468.8312418287568, "step": 133000}
{"episode": 134.0, "batch_reward": 0.4391661758720875, "critic_loss": 0.13827853985130786, "actor_loss": -41.235181983947754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 424.63513112068176, "episode_reward": 504.86803841049874, "step": 134000}
{"episode": 135.0, "batch_reward": 0.4393468150496483, "critic_loss": 0.14669527898728849, "actor_loss": -41.29530180358887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.9616379737854, "episode_reward": 476.86458939902656, "step": 135000}
{"episode": 136.0, "batch_reward": 0.43979193860292437, "critic_loss": 0.13549671716988088, "actor_loss": -41.57498405456543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 425.491747379303, "episode_reward": 472.01565063874864, "step": 136000}
{"episode": 137.0, "batch_reward": 0.4396096078455448, "critic_loss": 0.13797149956971408, "actor_loss": -41.45843499755859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.937407970428467, "episode_reward": 468.37842762471485, "step": 137000}
{"episode": 138.0, "batch_reward": 0.4397699089050293, "critic_loss": 0.13237529634684325, "actor_loss": -40.93032944488525, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 425.3362617492676, "episode_reward": 468.0873952165226, "step": 138000}
{"episode": 139.0, "batch_reward": 0.44057023572921755, "critic_loss": 0.13757429185509681, "actor_loss": -41.36072720336914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.701478481292725, "episode_reward": 465.5703196836802, "step": 139000}
{"episode": 140.0, "batch_reward": 0.43996673887968063, "critic_loss": 0.14533963771909475, "actor_loss": -41.54980263519287, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 425.59439492225647, "episode_reward": 469.29300255836876, "step": 140000}
{"episode": 141.0, "batch_reward": 0.4403864929974079, "critic_loss": 0.14526159622520207, "actor_loss": -41.36561296081543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.36683201789856, "episode_reward": 477.82790159993175, "step": 141000}
{"episode": 142.0, "batch_reward": 0.4408106808662415, "critic_loss": 0.14238623167574405, "actor_loss": -41.756275665283205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 416.66010904312134, "episode_reward": 480.55582351872835, "step": 142000}
{"episode": 143.0, "batch_reward": 0.4409323781430721, "critic_loss": 0.13473393588513136, "actor_loss": -41.73115660095215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.915624618530273, "episode_reward": 469.87705145898906, "step": 143000}
{"episode": 144.0, "batch_reward": 0.44060265451669695, "critic_loss": 0.1341986474841833, "actor_loss": -41.30461129760742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 425.5359241962433, "episode_reward": 446.27204366147123, "step": 144000}
{"episode": 145.0, "batch_reward": 0.44139951390028, "critic_loss": 0.13489173866063356, "actor_loss": -41.2932391204834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.058132886886597, "episode_reward": 444.6446837292501, "step": 145000}
{"episode": 146.0, "batch_reward": 0.44149824291467665, "critic_loss": 0.13229189538955688, "actor_loss": -41.79894958496094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 425.72835659980774, "episode_reward": 461.12135907797125, "step": 146000}
{"episode": 147.0, "batch_reward": 0.4416730905175209, "critic_loss": 0.1278695859462023, "actor_loss": -41.553188972473144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.93470287322998, "episode_reward": 481.6920530552036, "step": 147000}
{"episode": 148.0, "batch_reward": 0.44150664973258974, "critic_loss": 0.13476273611187936, "actor_loss": -42.07332973480224, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 424.3325719833374, "episode_reward": 459.80251386766884, "step": 148000}
{"episode": 149.0, "batch_reward": 0.4418098258078098, "critic_loss": 0.13755966994166374, "actor_loss": -41.74073123931885, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.391268014907837, "episode_reward": 436.34009054560977, "step": 149000}
{"episode": 150.0, "batch_reward": 0.44169413289427756, "critic_loss": 0.12907565052807332, "actor_loss": -41.40977131652832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
