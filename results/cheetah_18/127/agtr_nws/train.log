{"episode": 1.0, "duration": 19.017558574676514, "episode_reward": 7.051849146674556, "step": 1000}
{"episode": 2.0, "duration": 1.6882548332214355, "episode_reward": 365.4711839680396, "step": 2000}
{"episode": 3.0, "batch_reward": 0.17903759601554223, "actor_loss": -37.760552859105985, "actor_target_entropy": -6.0, "alpha_value": 0.01377813086574139, "duration": 63.67200946807861, "episode_reward": 72.31702900727065, "step": 3000}
{"episode": 4.0, "batch_reward": 0.1316066363528371, "actor_loss": -30.439239269256593, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.742269039154053, "episode_reward": 15.764417292662964, "step": 4000}
{"episode": 5.0, "batch_reward": 0.10321505144611001, "actor_loss": -30.218906192779542, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.661184072494507, "episode_reward": 4.1241909710929034, "step": 5000}
{"episode": 6.0, "batch_reward": 0.08438591377809644, "actor_loss": -29.938568943023682, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.073030948638916, "episode_reward": 5.062974513973715, "step": 6000}
{"episode": 7.0, "batch_reward": 0.0734228705726564, "actor_loss": -29.531497325897217, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.63181495666504, "episode_reward": 22.30228871643176, "step": 7000}
{"episode": 8.0, "batch_reward": 0.06645619523525238, "actor_loss": -29.187026371002197, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.162151098251343, "episode_reward": 4.543671070524026, "step": 8000}
{"episode": 9.0, "batch_reward": 0.06162187713757157, "actor_loss": -29.07855858230591, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.8314106464386, "episode_reward": 62.28534699244156, "step": 9000}
{"episode": 10.0, "batch_reward": 0.061678000524640085, "actor_loss": -25.686315982818602, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 3862.387368440628, "episode_reward": 50.68775753144661, "step": 10000}
{"episode": 11.0, "batch_reward": 0.06163432817161083, "actor_loss": -25.682553775787355, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 34.552780628204346, "episode_reward": 57.04594382134296, "step": 11000}
{"episode": 12.0, "batch_reward": 0.06108569250628352, "actor_loss": -24.162856624603272, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 419.12838077545166, "episode_reward": 93.19355621186818, "step": 12000}
{"episode": 13.0, "batch_reward": 0.06251636588573456, "actor_loss": -23.911541442871094, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.801294565200806, "episode_reward": 31.5457376821961, "step": 13000}
{"episode": 14.0, "batch_reward": 0.06220032360963523, "actor_loss": -23.13424767303467, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 428.97369742393494, "episode_reward": 91.599823803745, "step": 14000}
{"episode": 15.0, "batch_reward": 0.06430951483547688, "actor_loss": -23.159008838653566, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.815993547439575, "episode_reward": 78.88094931271796, "step": 15000}
{"episode": 16.0, "batch_reward": 0.06365675070509315, "actor_loss": -22.39152158355713, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 418.9881319999695, "episode_reward": 40.936535541989315, "step": 16000}
{"episode": 17.0, "batch_reward": 0.06437821490690113, "actor_loss": -22.0078048248291, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.044942378997803, "episode_reward": 112.96772698223866, "step": 17000}
{"episode": 18.0, "batch_reward": 0.06690299579128622, "actor_loss": -21.789114391326905, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 424.1901009082794, "episode_reward": 108.28682966511802, "step": 18000}
{"episode": 19.0, "batch_reward": 0.06929244384169579, "actor_loss": -21.971053020477296, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.265709161758423, "episode_reward": 123.39386114937844, "step": 19000}
{"episode": 20.0, "batch_reward": 0.07308590196073056, "actor_loss": -21.319211116790772, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 414.8721649646759, "episode_reward": 137.28378744505216, "step": 20000}
{"episode": 21.0, "batch_reward": 0.07612643873691559, "actor_loss": -21.285165046691894, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 32.25919580459595, "episode_reward": 151.85712188165255, "step": 21000}
{"episode": 22.0, "batch_reward": 0.07711989641562104, "actor_loss": -20.00510327911377, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 416.64842462539673, "episode_reward": 25.544206363680427, "step": 22000}
{"episode": 23.0, "batch_reward": 0.07855661898106336, "actor_loss": -19.80690367126465, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.70238709449768, "episode_reward": 199.27848912041003, "step": 23000}
{"episode": 24.0, "batch_reward": 0.08291274064406752, "actor_loss": -19.155121044158935, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 418.24613523483276, "episode_reward": 186.0287095396843, "step": 24000}
{"episode": 25.0, "batch_reward": 0.08757643748819828, "actor_loss": -19.506423358917235, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 15.825489044189453, "episode_reward": 207.69101546999173, "step": 25000}
{"episode": 26.0, "batch_reward": 0.09234841200709343, "actor_loss": -18.819986089706422, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 424.0746097564697, "episode_reward": 215.27777378603548, "step": 26000}
{"episode": 27.0, "batch_reward": 0.09732235885411501, "actor_loss": -19.257182830810546, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.024910926818848, "episode_reward": 217.29207216707627, "step": 27000}
{"episode": 28.0, "batch_reward": 0.10243202339112759, "actor_loss": -18.716239459991456, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 420.15269589424133, "episode_reward": 286.2734097444904, "step": 28000}
{"episode": 29.0, "batch_reward": 0.10872259259968996, "actor_loss": -19.232637371063234, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.211323738098145, "episode_reward": 257.85191318151146, "step": 29000}
{"episode": 30.0, "batch_reward": 0.11563979893177748, "actor_loss": -18.879239891052247, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 416.570184469223, "episode_reward": 338.4497347021087, "step": 30000}
{"episode": 31.0, "batch_reward": 0.12199394378811121, "actor_loss": -19.42675671386719, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.555859327316284, "episode_reward": 313.59118203617805, "step": 31000}
{"episode": 32.0, "batch_reward": 0.12637010500580073, "actor_loss": -18.99737614822388, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 422.1927990913391, "episode_reward": 228.71351091891884, "step": 32000}
{"episode": 33.0, "batch_reward": 0.13014470127224922, "actor_loss": -19.239708269119262, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.863494634628296, "episode_reward": 235.57842377070202, "step": 33000}
{"episode": 34.0, "batch_reward": 0.13358531754463912, "actor_loss": -18.337098207473755, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 421.4542508125305, "episode_reward": 256.72518514557885, "step": 34000}
{"episode": 35.0, "batch_reward": 0.1373394269347191, "actor_loss": -18.715889249801634, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.84477734565735, "episode_reward": 251.66735078866776, "step": 35000}
{"episode": 36.0, "batch_reward": 0.14078615673631428, "actor_loss": -17.714000453948973, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 422.25583052635193, "episode_reward": 319.4593623451224, "step": 36000}
{"episode": 37.0, "batch_reward": 0.1465264053121209, "actor_loss": -18.159531579971315, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.72427535057068, "episode_reward": 285.9419722056424, "step": 37000}
{"episode": 38.0, "batch_reward": 0.14887104865908624, "actor_loss": -17.456490327835084, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 420.2889859676361, "episode_reward": 253.5665936567751, "step": 38000}
{"episode": 39.0, "batch_reward": 0.15275914452970027, "actor_loss": -17.68376707649231, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.952561616897583, "episode_reward": 272.8219174318784, "step": 39000}
{"episode": 40.0, "batch_reward": 0.1553519262224436, "actor_loss": -17.14760199546814, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 423.2703540325165, "episode_reward": 296.4514421652308, "step": 40000}
{"episode": 41.0, "batch_reward": 0.15575033342838288, "actor_loss": -17.08690838623047, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 34.19684338569641, "episode_reward": 54.04292333527066, "step": 41000}
{"episode": 42.0, "batch_reward": 0.1540850799307227, "actor_loss": -16.058929651260375, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 411.2393035888672, "episode_reward": 98.55123324070463, "step": 42000}
{"episode": 43.0, "batch_reward": 0.15463686969131232, "actor_loss": -15.960567646026611, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.00082802772522, "episode_reward": 301.1553414219805, "step": 43000}
{"episode": 44.0, "batch_reward": 0.15657091761380434, "actor_loss": -15.807619447708129, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 421.79861879348755, "episode_reward": 98.37131580915857, "step": 44000}
{"episode": 45.0, "batch_reward": 0.1557441586330533, "actor_loss": -15.688252969741821, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.0435152053833, "episode_reward": 201.55424480467437, "step": 45000}
{"episode": 46.0, "batch_reward": 0.15747629292309284, "actor_loss": -15.726444101333618, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 416.27660393714905, "episode_reward": 216.84148684317012, "step": 46000}
{"episode": 47.0, "batch_reward": 0.1578702032491565, "actor_loss": -15.93346409034729, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.817286491394043, "episode_reward": 249.37786916197751, "step": 47000}
{"episode": 48.0, "batch_reward": 0.16032484225928784, "actor_loss": -15.829464014053345, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 420.7664887905121, "episode_reward": 250.60886190333173, "step": 48000}
{"episode": 49.0, "batch_reward": 0.1625742710828781, "actor_loss": -15.965231103897095, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.673909187316895, "episode_reward": 245.20964086033447, "step": 49000}
{"episode": 50.0, "batch_reward": 0.16404733876138924, "actor_loss": -15.64944638633728, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 420.08103251457214, "episode_reward": 102.48381471792145, "step": 50000}
{"episode": 51.0, "batch_reward": 0.16338696993142365, "actor_loss": -15.480256349563598, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.494354248046875, "episode_reward": 259.98599793612766, "step": 51000}
{"episode": 52.0, "batch_reward": 0.16498918307572602, "actor_loss": -15.950223699569703, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 419.0676290988922, "episode_reward": 264.2966269140305, "step": 52000}
{"episode": 53.0, "batch_reward": 0.1665161804333329, "actor_loss": -15.998489515304566, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.432562112808228, "episode_reward": 103.7553642254294, "step": 53000}
{"episode": 54.0, "batch_reward": 0.16497991015017033, "actor_loss": -16.318033716201782, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 415.41881108283997, "episode_reward": 248.09935365581094, "step": 54000}
{"episode": 55.0, "batch_reward": 0.16740950137376787, "actor_loss": -16.567028959274293, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.856672048568726, "episode_reward": 298.3450173210137, "step": 55000}
{"episode": 56.0, "batch_reward": 0.16950354239344598, "actor_loss": -16.660035009384156, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 425.49544048309326, "episode_reward": 304.53204892255354, "step": 56000}
{"episode": 57.0, "batch_reward": 0.1724199568629265, "actor_loss": -16.863346096038818, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.674278497695923, "episode_reward": 265.60118599017204, "step": 57000}
{"episode": 58.0, "batch_reward": 0.17384485305845737, "actor_loss": -17.435369081497193, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 419.497261762619, "episode_reward": 290.2188608686466, "step": 58000}
{"episode": 59.0, "batch_reward": 0.1749648521989584, "actor_loss": -17.545494678497313, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.205824851989746, "episode_reward": 178.4047011981455, "step": 59000}
{"episode": 60.0, "batch_reward": 0.17618110734224318, "actor_loss": -18.14381146812439, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 424.06782937049866, "episode_reward": 310.42705239040066, "step": 60000}
{"episode": 61.0, "batch_reward": 0.17808367800712585, "actor_loss": -18.336478303909303, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 33.397186040878296, "episode_reward": 369.1269645261709, "step": 61000}
{"episode": 62.0, "batch_reward": 0.18082209937274457, "actor_loss": -18.768469594955445, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 420.00619888305664, "episode_reward": 365.71348972234756, "step": 62000}
{"episode": 63.0, "batch_reward": 0.18214590564370156, "actor_loss": -18.734565132141114, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.801130294799805, "episode_reward": 87.7292974017456, "step": 63000}
{"episode": 64.0, "batch_reward": 0.1816382845491171, "actor_loss": -19.28898659133911, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 424.22069811820984, "episode_reward": 103.39748115500443, "step": 64000}
{"episode": 65.0, "batch_reward": 0.18158907625079154, "actor_loss": -19.373168743133544, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.7631778717041, "episode_reward": 337.38993854930095, "step": 65000}
{"episode": 66.0, "batch_reward": 0.18325142028927804, "actor_loss": -19.619268070220947, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 415.7224533557892, "episode_reward": 327.40984944571414, "step": 66000}
{"episode": 67.0, "batch_reward": 0.18570623603463174, "actor_loss": -19.808583408355712, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.445769786834717, "episode_reward": 194.01857989527508, "step": 67000}
{"episode": 68.0, "batch_reward": 0.18618669407069682, "actor_loss": -19.654137424468995, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 420.60272097587585, "episode_reward": 341.97909628319985, "step": 68000}
{"episode": 69.0, "batch_reward": 0.18846562941372394, "actor_loss": -19.907308883666992, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.9684419631958, "episode_reward": 347.2828912730931, "step": 69000}
{"episode": 70.0, "batch_reward": 0.19031674249470235, "actor_loss": -19.460718017578124, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 421.2638809680939, "episode_reward": 300.46726651975274, "step": 70000}
{"episode": 71.0, "batch_reward": 0.19165131518244743, "actor_loss": -19.6433694896698, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 36.195125579833984, "episode_reward": 297.14498159281135, "step": 71000}
{"episode": 72.0, "batch_reward": 0.1941782878637314, "actor_loss": -19.227190645217895, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 421.8680896759033, "episode_reward": 277.0330534774075, "step": 72000}
{"episode": 73.0, "batch_reward": 0.19383376587927342, "actor_loss": -19.28047001647949, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.58248496055603, "episode_reward": 298.2984577303227, "step": 73000}
{"episode": 74.0, "batch_reward": 0.1960238090157509, "actor_loss": -18.855932508468626, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 420.2778980731964, "episode_reward": 334.5322864112326, "step": 74000}
{"episode": 75.0, "batch_reward": 0.19900394032895566, "actor_loss": -19.026887199401855, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.631757259368896, "episode_reward": 315.82039728497244, "step": 75000}
{"episode": 76.0, "batch_reward": 0.19866303795576096, "actor_loss": -19.063549213409424, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 419.7430317401886, "episode_reward": 244.38435596350254, "step": 76000}
{"episode": 77.0, "batch_reward": 0.2009888618439436, "actor_loss": -19.228681549072267, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 15.80757212638855, "episode_reward": 346.0180994782575, "step": 77000}
{"episode": 78.0, "batch_reward": 0.2017487757354975, "actor_loss": -18.832169290542602, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 424.4819531440735, "episode_reward": 299.27983435379184, "step": 78000}
{"episode": 79.0, "batch_reward": 0.20321044431626797, "actor_loss": -18.900904930114745, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.057549476623535, "episode_reward": 329.11988128408416, "step": 79000}
{"episode": 80.0, "batch_reward": 0.20415321630239486, "actor_loss": -18.767821643829347, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 419.7034537792206, "episode_reward": 161.57994963032766, "step": 80000}
{"episode": 81.0, "batch_reward": 0.20439568904042243, "actor_loss": -18.841374582290648, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.977588176727295, "episode_reward": 378.8308259997015, "step": 81000}
{"episode": 82.0, "batch_reward": 0.2069441640228033, "actor_loss": -18.4890688457489, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 422.8733513355255, "episode_reward": 374.6828293830668, "step": 82000}
{"episode": 83.0, "batch_reward": 0.20853136824071408, "actor_loss": -18.740888357162476, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.924345016479492, "episode_reward": 346.758619819619, "step": 83000}
{"episode": 84.0, "batch_reward": 0.21001694810390473, "actor_loss": -19.088130603790283, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 420.8928520679474, "episode_reward": 334.90422526357355, "step": 84000}
{"episode": 85.0, "batch_reward": 0.21196400906145574, "actor_loss": -19.20147626686096, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.426275491714478, "episode_reward": 346.43320431450576, "step": 85000}
{"episode": 86.0, "batch_reward": 0.21349312710762025, "actor_loss": -19.079294311523437, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 422.6595571041107, "episode_reward": 359.4542401567283, "step": 86000}
{"episode": 87.0, "batch_reward": 0.2156337429136038, "actor_loss": -19.25147310447693, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.816309452056885, "episode_reward": 367.2734630704829, "step": 87000}
{"episode": 88.0, "batch_reward": 0.21713015846908093, "actor_loss": -19.251057434082032, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 418.6470649242401, "episode_reward": 334.32242568422845, "step": 88000}
{"episode": 89.0, "batch_reward": 0.21794570298492907, "actor_loss": -19.41880130958557, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.397591829299927, "episode_reward": 289.61920894567317, "step": 89000}
{"episode": 90.0, "batch_reward": 0.21874354228377343, "actor_loss": -18.894300550460816, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 421.70344066619873, "episode_reward": 319.50334565350124, "step": 90000}
{"episode": 91.0, "batch_reward": 0.21978058290481567, "actor_loss": -18.89339602279663, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.3485951423645, "episode_reward": 267.1799203298044, "step": 91000}
{"episode": 92.0, "batch_reward": 0.22072610048949717, "actor_loss": -18.680856693267824, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 406.3689980506897, "episode_reward": 324.4591625140674, "step": 92000}
{"episode": 93.0, "batch_reward": 0.22155404560267924, "actor_loss": -18.717858476638796, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.537639617919922, "episode_reward": 334.8720025627468, "step": 93000}
{"episode": 94.0, "batch_reward": 0.22297776213288306, "actor_loss": -19.198590728759765, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 424.5514175891876, "episode_reward": 300.2616163258806, "step": 94000}
{"episode": 95.0, "batch_reward": 0.22355986760556698, "actor_loss": -19.248160387039185, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.945533514022827, "episode_reward": 344.9268995943567, "step": 95000}
{"episode": 96.0, "batch_reward": 0.22501746915280818, "actor_loss": -18.46631729888916, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 417.8702480792999, "episode_reward": 359.5641342341219, "step": 96000}
{"episode": 97.0, "batch_reward": 0.22741621538996695, "actor_loss": -18.682815814971924, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.435891151428223, "episode_reward": 344.7654427024267, "step": 97000}
{"episode": 98.0, "batch_reward": 0.22734307898581027, "actor_loss": -18.66365295410156, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 422.70431208610535, "episode_reward": 276.8226053982609, "step": 98000}
{"episode": 99.0, "batch_reward": 0.22826227444410324, "actor_loss": -18.773954999923706, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.485127687454224, "episode_reward": 334.87859409621444, "step": 99000}
{"episode": 100.0, "batch_reward": 0.22990487636625767, "actor_loss": -18.936338430404664, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 421.52903175354004, "episode_reward": 350.64508580465133, "step": 100000}
{"episode": 101.0, "batch_reward": 0.2304710743576288, "actor_loss": -18.928641864776612, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 33.59067106246948, "episode_reward": 282.4007471862072, "step": 101000}
{"episode": 102.0, "batch_reward": 0.23078362095355986, "actor_loss": -19.195373788833617, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 422.3083941936493, "episode_reward": 190.43128429324483, "step": 102000}
{"episode": 103.0, "batch_reward": 0.23034965619444847, "actor_loss": -19.135474548339843, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.067318439483643, "episode_reward": 339.004471486378, "step": 103000}
{"episode": 104.0, "batch_reward": 0.23137573419511318, "actor_loss": -19.815499240875244, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 421.46423602104187, "episode_reward": 346.75276138495843, "step": 104000}
{"episode": 105.0, "batch_reward": 0.2328642438352108, "actor_loss": -19.851439456939698, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.963005781173706, "episode_reward": 363.80434731196493, "step": 105000}
{"episode": 106.0, "batch_reward": 0.23337600542604922, "actor_loss": -20.089026138305663, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 420.335156917572, "episode_reward": 412.5171713866044, "step": 106000}
{"episode": 107.0, "batch_reward": 0.2357609888613224, "actor_loss": -20.311569717407227, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.96416997909546, "episode_reward": 393.23605310694285, "step": 107000}
{"episode": 108.0, "batch_reward": 0.23821287904679775, "actor_loss": -20.87414672088623, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 422.7744526863098, "episode_reward": 460.3094648181917, "step": 108000}
{"episode": 109.0, "batch_reward": 0.23955854141712188, "actor_loss": -21.07955393600464, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.75121831893921, "episode_reward": 454.8018483026615, "step": 109000}
{"episode": 110.0, "batch_reward": 0.24156417487561702, "actor_loss": -21.25261277770996, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 423.7042324542999, "episode_reward": 237.7576670088555, "step": 110000}
{"episode": 111.0, "batch_reward": 0.24067885527014732, "actor_loss": -21.17001435470581, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 34.078532457351685, "episode_reward": 198.95025468210966, "step": 111000}
{"episode": 112.0, "batch_reward": 0.2404881583750248, "actor_loss": -21.809148452758787, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 421.74187207221985, "episode_reward": 260.4994724353162, "step": 112000}
{"episode": 113.0, "batch_reward": 0.23919365733861922, "actor_loss": -21.669019557952883, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.008151292800903, "episode_reward": 238.79392765465025, "step": 113000}
{"episode": 114.0, "batch_reward": 0.2408262843489647, "actor_loss": -21.698309776306154, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 423.60083842277527, "episode_reward": 304.38516720599756, "step": 114000}
{"episode": 115.0, "batch_reward": 0.24203108128905296, "actor_loss": -21.876789695739745, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.459327459335327, "episode_reward": 372.70155209254744, "step": 115000}
{"episode": 116.0, "batch_reward": 0.24252105888724326, "actor_loss": -22.39837277984619, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 415.69983077049255, "episode_reward": 380.50859475079847, "step": 116000}
{"episode": 117.0, "batch_reward": 0.24313974359631538, "actor_loss": -22.395836341857912, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.516143321990967, "episode_reward": 342.9996064626713, "step": 117000}
{"episode": 118.0, "batch_reward": 0.24424470815062524, "actor_loss": -22.857224910736083, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 423.9555871486664, "episode_reward": 350.9597963998691, "step": 118000}
{"episode": 119.0, "batch_reward": 0.24547456151247024, "actor_loss": -22.86333934020996, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.003765106201172, "episode_reward": 354.7903556789148, "step": 119000}
{"episode": 120.0, "batch_reward": 0.24619484110176562, "actor_loss": -23.78282692718506, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 421.00859904289246, "episode_reward": 336.62529658385205, "step": 120000}
{"episode": 121.0, "batch_reward": 0.2472938268482685, "actor_loss": -23.84541310119629, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 34.468236207962036, "episode_reward": 353.8985814752677, "step": 121000}
{"episode": 122.0, "batch_reward": 0.24895201694965363, "actor_loss": -24.22392593383789, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 417.4983570575714, "episode_reward": 341.7370892509976, "step": 122000}
{"episode": 123.0, "batch_reward": 0.24792906790971755, "actor_loss": -24.21324571609497, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.41546368598938, "episode_reward": 171.21003573065252, "step": 123000}
{"episode": 124.0, "batch_reward": 0.24855550788342953, "actor_loss": -24.39912282562256, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 425.06904220581055, "episode_reward": 214.3528151595458, "step": 124000}
{"episode": 125.0, "batch_reward": 0.24776863585412504, "actor_loss": -24.281415714263915, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.04394006729126, "episode_reward": 84.16881861540358, "step": 125000}
{"episode": 126.0, "batch_reward": 0.24560931211709977, "actor_loss": -24.10361849975586, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 413.0092945098877, "episode_reward": 74.47724984632319, "step": 126000}
{"episode": 127.0, "batch_reward": 0.24456014475226404, "actor_loss": -24.139001960754396, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 17.05665421485901, "episode_reward": 123.54567093907549, "step": 127000}
{"episode": 128.0, "batch_reward": 0.24392984941601753, "actor_loss": -23.5886240234375, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 422.9379813671112, "episode_reward": 382.1669477790805, "step": 128000}
{"episode": 129.0, "batch_reward": 0.24425829342007638, "actor_loss": -23.69002758026123, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.30907964706421, "episode_reward": 42.486253704146336, "step": 129000}
{"episode": 130.0, "batch_reward": 0.24226909771561622, "actor_loss": -23.98307904434204, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 419.07319688796997, "episode_reward": 329.82731347977887, "step": 130000}
{"episode": 131.0, "batch_reward": 0.24433110722899437, "actor_loss": -24.061320854187013, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 31.852282524108887, "episode_reward": 370.11919060508893, "step": 131000}
{"episode": 132.0, "batch_reward": 0.24572242972254754, "actor_loss": -24.3499136428833, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 424.56255197525024, "episode_reward": 359.2035496702951, "step": 132000}
{"episode": 133.0, "batch_reward": 0.24683824060857296, "actor_loss": -24.34420611190796, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.48624873161316, "episode_reward": 316.7955144818817, "step": 133000}
{"episode": 134.0, "batch_reward": 0.24765858002007007, "actor_loss": -24.316536331176756, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 416.2082908153534, "episode_reward": 302.98556219836655, "step": 134000}
{"episode": 135.0, "batch_reward": 0.24635402500629425, "actor_loss": -24.09578311920166, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.346765518188477, "episode_reward": 91.31612011664505, "step": 135000}
{"episode": 136.0, "batch_reward": 0.24500086802244186, "actor_loss": -24.315765968322754, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 426.2192180156708, "episode_reward": 97.331381775028, "step": 136000}
{"episode": 137.0, "batch_reward": 0.24493375031650066, "actor_loss": -24.310120208740233, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.809637308120728, "episode_reward": 273.6136922950413, "step": 137000}
{"episode": 138.0, "batch_reward": 0.24502176125347613, "actor_loss": -23.809632495880127, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 418.01336669921875, "episode_reward": 358.1993603857671, "step": 138000}
{"episode": 139.0, "batch_reward": 0.24533551107347012, "actor_loss": -23.81649293899536, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 15.886968851089478, "episode_reward": 127.45472924067653, "step": 139000}
{"episode": 140.0, "batch_reward": 0.2446261329650879, "actor_loss": -23.868512325286865, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 425.1306257247925, "episode_reward": 358.2470264452594, "step": 140000}
{"episode": 141.0, "batch_reward": 0.24445654180645943, "actor_loss": -23.930284240722656, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 35.55323624610901, "episode_reward": 43.00289292195213, "step": 141000}
{"episode": 142.0, "batch_reward": 0.24403233954310416, "actor_loss": -23.903731884002685, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 408.2606258392334, "episode_reward": 341.53033297994216, "step": 142000}
{"episode": 143.0, "batch_reward": 0.2460146459043026, "actor_loss": -24.02277543258667, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 19.031801462173462, "episode_reward": 294.6386239433671, "step": 143000}
{"episode": 144.0, "batch_reward": 0.24554582865536212, "actor_loss": -23.753196044921875, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 424.21974778175354, "episode_reward": 245.16924915154218, "step": 144000}
{"episode": 145.0, "batch_reward": 0.24542429879307748, "actor_loss": -23.72574761581421, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.935667991638184, "episode_reward": 252.05050596124823, "step": 145000}
{"episode": 146.0, "batch_reward": 0.24561900955438615, "actor_loss": -23.456591667175292, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 415.68310594558716, "episode_reward": 330.7714998357338, "step": 146000}
{"episode": 147.0, "batch_reward": 0.24552559493482112, "actor_loss": -23.373349842071534, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 18.63229465484619, "episode_reward": 376.7465684391927, "step": 147000}
{"episode": 148.0, "batch_reward": 0.2482239374369383, "actor_loss": -22.993419799804688, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 418.6470308303833, "episode_reward": 397.286642168052, "step": 148000}
{"episode": 149.0, "batch_reward": 0.24797169755399226, "actor_loss": -22.877476387023925, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "duration": 16.910789012908936, "episode_reward": 431.21138858418914, "step": 149000}
{"episode": 150.0, "batch_reward": 0.24912452039122582, "actor_loss": -22.143783508300782, "actor_target_entropy": -6.0, "alpha_value": 0.013778130865741629, "step": 150000}
