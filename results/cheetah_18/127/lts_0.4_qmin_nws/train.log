{"episode_reward": 0.0, "episode": 1.0, "duration": 19.33250617980957, "step": 1000}
{"episode_reward": 7.051849146674556, "episode": 2.0, "duration": 1.6067144870758057, "step": 2000}
{"episode_reward": 365.4711839680396, "episode": 3.0, "batch_reward": 0.1762773230269417, "critic_loss": 0.034018572944391264, "actor_loss": -15.50971273482567, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 66.45696139335632, "step": 3000}
{"episode_reward": 25.42115774646894, "episode": 4.0, "batch_reward": 0.11789203710108996, "critic_loss": 0.03180945758894086, "actor_loss": -12.43066977314651, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.32779884338379, "step": 4000}
{"episode_reward": 31.972087992056906, "episode": 5.0, "batch_reward": 0.10116720467060804, "critic_loss": 0.035993103075772526, "actor_loss": -12.33765124181658, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.021064281463623, "step": 5000}
{"episode_reward": 50.03647083158997, "episode": 6.0, "batch_reward": 0.09574644079059362, "critic_loss": 0.051664751064032316, "actor_loss": -13.206047597680241, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.72286868095398, "step": 6000}
{"episode_reward": 91.03405619489072, "episode": 7.0, "batch_reward": 0.0955894679427147, "critic_loss": 0.056132795553654434, "actor_loss": -11.869906210288406, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.1992928981781, "step": 7000}
{"episode_reward": 76.81190578908321, "episode": 8.0, "batch_reward": 0.09577616342157126, "critic_loss": 0.0934612112864852, "actor_loss": -12.232154317051172, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.058008193969727, "step": 8000}
{"episode_reward": 97.51926086859407, "episode": 9.0, "batch_reward": 0.09652805165201425, "critic_loss": 0.10200054568052291, "actor_loss": -12.657433186292648, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.589775562286377, "step": 9000}
{"episode_reward": 140.70010471664318, "episode": 10.0, "batch_reward": 0.09891071669757366, "critic_loss": 0.10573780192807317, "actor_loss": -12.477042476654052, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.131142139434814, "step": 10000}
{"episode_reward": 70.8006715240858, "episode": 11.0, "batch_reward": 0.10127385105192661, "critic_loss": 0.13341480012983084, "actor_loss": -12.807770439386367, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.06980657577515, "step": 11000}
{"episode_reward": 156.54863644187864, "episode": 12.0, "batch_reward": 0.1006306880041957, "critic_loss": 0.12333822038397194, "actor_loss": -12.641069915533066, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.039612531661987, "step": 12000}
{"episode_reward": 59.68041499926957, "episode": 13.0, "batch_reward": 0.09918147647380829, "critic_loss": 0.13007839094102383, "actor_loss": -11.724429840564728, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.977545499801636, "step": 13000}
{"episode_reward": 79.98214507701006, "episode": 14.0, "batch_reward": 0.09494147696346045, "critic_loss": 0.13194819501042365, "actor_loss": -11.97317669248581, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.266443252563477, "step": 14000}
{"episode_reward": 29.26129273348198, "episode": 15.0, "batch_reward": 0.09699882988259197, "critic_loss": 0.1625970991551876, "actor_loss": -12.510636961460113, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.596810817718506, "step": 15000}
{"episode_reward": 206.4042824196201, "episode": 16.0, "batch_reward": 0.10402840173989535, "critic_loss": 0.1762620129957795, "actor_loss": -12.270808933258056, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.12055730819702, "step": 16000}
{"episode_reward": 170.8693725752233, "episode": 17.0, "batch_reward": 0.10319168401509524, "critic_loss": 0.17651950647309422, "actor_loss": -12.428680979251862, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.893101692199707, "step": 17000}
{"episode_reward": 54.08848378869562, "episode": 18.0, "batch_reward": 0.10311668731272221, "critic_loss": 0.18571338581293823, "actor_loss": -12.531248707294464, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.12427067756653, "step": 18000}
{"episode_reward": 202.62004131937175, "episode": 19.0, "batch_reward": 0.10739147486537695, "critic_loss": 0.173819839194417, "actor_loss": -12.797497773647308, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.886205196380615, "step": 19000}
{"episode_reward": 93.60429483317013, "episode": 20.0, "batch_reward": 0.10680082242190837, "critic_loss": 0.1468062390834093, "actor_loss": -13.008776672840119, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.361047744750977, "step": 20000}
{"episode_reward": 156.05423996976512, "episode": 21.0, "batch_reward": 0.10694749841839075, "critic_loss": 0.16240943970531224, "actor_loss": -12.536052402973175, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.256386041641235, "step": 21000}
{"episode_reward": 48.33950366943119, "episode": 22.0, "batch_reward": 0.10863968612253666, "critic_loss": 0.1550572738572955, "actor_loss": -14.38913372707367, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.919740915298462, "step": 22000}
{"episode_reward": 256.0173273535907, "episode": 23.0, "batch_reward": 0.11491490828245879, "critic_loss": 0.15524837467074395, "actor_loss": -14.00656137084961, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.978779315948486, "step": 23000}
{"episode_reward": 127.95768231732887, "episode": 24.0, "batch_reward": 0.11422333471477032, "critic_loss": 0.15308528524637222, "actor_loss": -13.786927952766419, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.439424514770508, "step": 24000}
{"episode_reward": 120.4000575351404, "episode": 25.0, "batch_reward": 0.11776133435219527, "critic_loss": 0.14595509663969278, "actor_loss": -13.945063550949097, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.886001348495483, "step": 25000}
{"episode_reward": 341.9011608467774, "episode": 26.0, "batch_reward": 0.12245397067815066, "critic_loss": 0.16454975359141827, "actor_loss": -13.737826651573181, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.14570164680481, "step": 26000}
{"episode_reward": 62.13153767201688, "episode": 27.0, "batch_reward": 0.12001365505903959, "critic_loss": 0.1544253355935216, "actor_loss": -13.156872509002685, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.557708501815796, "step": 27000}
{"episode_reward": 68.36438936436873, "episode": 28.0, "batch_reward": 0.1209829621911049, "critic_loss": 0.157650115609169, "actor_loss": -14.16475514316559, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.810991764068604, "step": 28000}
{"episode_reward": 153.03700007054272, "episode": 29.0, "batch_reward": 0.12206709647923708, "critic_loss": 0.1767642822563648, "actor_loss": -14.041652344703675, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.233396291732788, "step": 29000}
{"episode_reward": 303.8952283186381, "episode": 30.0, "batch_reward": 0.12749898635596038, "critic_loss": 0.17659433552622794, "actor_loss": -13.807310236930848, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.360445976257324, "step": 30000}
{"episode_reward": 121.59907647348481, "episode": 31.0, "batch_reward": 0.12874990040063858, "critic_loss": 0.18807695664465426, "actor_loss": -14.737748717308044, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.21669244766235, "step": 31000}
{"episode_reward": 261.23438504675033, "episode": 32.0, "batch_reward": 0.13099224342405796, "critic_loss": 0.19473583463579416, "actor_loss": -15.032944716453553, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.08347249031067, "step": 32000}
{"episode_reward": 91.73213345105789, "episode": 33.0, "batch_reward": 0.12778210043162108, "critic_loss": 0.20807580910623075, "actor_loss": -15.066507444381713, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.383609533309937, "step": 33000}
{"episode_reward": 43.328934690449884, "episode": 34.0, "batch_reward": 0.130045051202178, "critic_loss": 0.2198131347373128, "actor_loss": -14.459485246658325, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.37108087539673, "step": 34000}
{"episode_reward": 348.15819303132395, "episode": 35.0, "batch_reward": 0.13463491034507752, "critic_loss": 0.24663893024623393, "actor_loss": -15.630393245697022, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.342217683792114, "step": 35000}
{"episode_reward": 284.7919885322629, "episode": 36.0, "batch_reward": 0.13708937592059373, "critic_loss": 0.2558395920321345, "actor_loss": -16.062979073524474, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.88280987739563, "step": 36000}
{"episode_reward": 120.89245842193289, "episode": 37.0, "batch_reward": 0.13855270531773567, "critic_loss": 0.28561007433384655, "actor_loss": -15.764958143234253, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.402709245681763, "step": 37000}
{"episode_reward": 226.3739406180281, "episode": 38.0, "batch_reward": 0.14151439438015223, "critic_loss": 0.31435983504354953, "actor_loss": -16.31227294921875, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.515341758728027, "step": 38000}
{"episode_reward": 258.7758230683392, "episode": 39.0, "batch_reward": 0.14475757852196694, "critic_loss": 0.36126626855134963, "actor_loss": -16.59163709640503, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.79504704475403, "step": 39000}
{"episode_reward": 350.0766515441856, "episode": 40.0, "batch_reward": 0.14900035049021243, "critic_loss": 0.358641170360148, "actor_loss": -16.740124897003174, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.404239416122437, "step": 40000}
{"episode_reward": 154.42235560987447, "episode": 41.0, "batch_reward": 0.14683552980422973, "critic_loss": 0.4018261670619249, "actor_loss": -15.864211555480956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 42.35233163833618, "step": 41000}
{"episode_reward": 69.39341070098287, "episode": 42.0, "batch_reward": 0.14929227090626956, "critic_loss": 0.3438222681879997, "actor_loss": -17.01988821029663, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.730693817138672, "step": 42000}
{"episode_reward": 399.2677850653429, "episode": 43.0, "batch_reward": 0.15343134997040034, "critic_loss": 0.3499954089522362, "actor_loss": -17.59184240722656, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.191617965698242, "step": 43000}
{"episode_reward": 176.10628335218078, "episode": 44.0, "batch_reward": 0.15529488126933574, "critic_loss": 0.33093929185718296, "actor_loss": -18.269117389678954, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.533893585205078, "step": 44000}
{"episode_reward": 360.53719942376813, "episode": 45.0, "batch_reward": 0.15857230311632156, "critic_loss": 0.3039577088057995, "actor_loss": -18.572037286758423, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.719467639923096, "step": 45000}
{"episode_reward": 356.4037383125486, "episode": 46.0, "batch_reward": 0.16401669046282769, "critic_loss": 0.297477903097868, "actor_loss": -18.338615472793578, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.739420175552368, "step": 46000}
{"episode_reward": 462.72384229295915, "episode": 47.0, "batch_reward": 0.1709959657639265, "critic_loss": 0.31338145802170037, "actor_loss": -19.200261262893676, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.27729344367981, "step": 47000}
{"episode_reward": 396.7540410502343, "episode": 48.0, "batch_reward": 0.17425059995055198, "critic_loss": 0.3117210204750299, "actor_loss": -19.867717794418336, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.522729635238647, "step": 48000}
{"episode_reward": 159.8276881434114, "episode": 49.0, "batch_reward": 0.17511099645495415, "critic_loss": 0.3529685431495309, "actor_loss": -20.089302265167237, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.787198305130005, "step": 49000}
{"episode_reward": 308.1370797237467, "episode": 50.0, "batch_reward": 0.1771355314925313, "critic_loss": 0.3603685949295759, "actor_loss": -19.740573167800903, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.520513772964478, "step": 50000}
{"episode_reward": 373.6371682792582, "episode": 51.0, "batch_reward": 0.18111705775558948, "critic_loss": 0.37167789290845393, "actor_loss": -19.976357173919677, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.024744749069214, "step": 51000}
{"episode_reward": 345.2320376275356, "episode": 52.0, "batch_reward": 0.18270764148235322, "critic_loss": 0.41252607184648515, "actor_loss": -20.146049695968628, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.83024001121521, "step": 52000}
{"episode_reward": 118.97057730709062, "episode": 53.0, "batch_reward": 0.1839791821539402, "critic_loss": 0.43742750011384485, "actor_loss": -20.985672971725464, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.481002807617188, "step": 53000}
{"episode_reward": 424.06383706986253, "episode": 54.0, "batch_reward": 0.1893615116775036, "critic_loss": 0.40969885659217836, "actor_loss": -21.257895069122313, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.76202940940857, "step": 54000}
{"episode_reward": 452.94410784226227, "episode": 55.0, "batch_reward": 0.19281411704421042, "critic_loss": 0.3904994366466999, "actor_loss": -21.646170095443726, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.198609113693237, "step": 55000}
{"episode_reward": 436.52499008092457, "episode": 56.0, "batch_reward": 0.19842963021993637, "critic_loss": 0.3672719847857952, "actor_loss": -22.001140298843385, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.76211977005005, "step": 56000}
{"episode_reward": 420.47827042645105, "episode": 57.0, "batch_reward": 0.2016588139384985, "critic_loss": 0.3807622058540583, "actor_loss": -22.457037508010863, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.456885814666748, "step": 57000}
{"episode_reward": 446.8496193954802, "episode": 58.0, "batch_reward": 0.20559556137025356, "critic_loss": 0.38105952011048794, "actor_loss": -23.195542339324952, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.208104133605957, "step": 58000}
{"episode_reward": 452.49622775803095, "episode": 59.0, "batch_reward": 0.20983069917559624, "critic_loss": 0.4164733286648989, "actor_loss": -23.43440272140503, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.640169858932495, "step": 59000}
{"episode_reward": 373.45947666423854, "episode": 60.0, "batch_reward": 0.2101757972240448, "critic_loss": 0.43788722360134125, "actor_loss": -23.622383195877074, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.765917539596558, "step": 60000}
{"episode_reward": 123.64089899968943, "episode": 61.0, "batch_reward": 0.2088990314155817, "critic_loss": 0.4367904426008463, "actor_loss": -23.226805137634276, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.666502952575684, "step": 61000}
{"episode_reward": 102.92906046710172, "episode": 62.0, "batch_reward": 0.20964241372048856, "critic_loss": 0.43426256872713564, "actor_loss": -23.666483299255372, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.087092876434326, "step": 62000}
{"episode_reward": 379.5935447131825, "episode": 63.0, "batch_reward": 0.21091056033968925, "critic_loss": 0.4645249714553356, "actor_loss": -23.400784734725953, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.166653633117676, "step": 63000}
{"episode_reward": 133.3413955195167, "episode": 64.0, "batch_reward": 0.21056659246981144, "critic_loss": 0.45568586829304697, "actor_loss": -23.796788387298584, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.134655952453613, "step": 64000}
{"episode_reward": 497.83400661683885, "episode": 65.0, "batch_reward": 0.21547466456890108, "critic_loss": 0.46929346583783627, "actor_loss": -23.99469941711426, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.968686819076538, "step": 65000}
{"episode_reward": 475.76930414264484, "episode": 66.0, "batch_reward": 0.21989004610478877, "critic_loss": 0.4419178389757872, "actor_loss": -24.76775693130493, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.144635915756226, "step": 66000}
{"episode_reward": 457.8894905826879, "episode": 67.0, "batch_reward": 0.224076066121459, "critic_loss": 0.45040324434638024, "actor_loss": -25.70466506576538, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.563942432403564, "step": 67000}
{"episode_reward": 462.6871986735106, "episode": 68.0, "batch_reward": 0.22684174171090127, "critic_loss": 0.41378867310285566, "actor_loss": -25.795537910461427, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.101054191589355, "step": 68000}
{"episode_reward": 498.3059063009878, "episode": 69.0, "batch_reward": 0.23033728349208832, "critic_loss": 0.44084784707427027, "actor_loss": -25.713226642608642, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.98762035369873, "step": 69000}
{"episode_reward": 496.16327381067066, "episode": 70.0, "batch_reward": 0.2346904903203249, "critic_loss": 0.43003682363033296, "actor_loss": -26.50260740661621, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.585368871688843, "step": 70000}
{"episode_reward": 448.0612017491874, "episode": 71.0, "batch_reward": 0.23700893135368825, "critic_loss": 0.41983228336274625, "actor_loss": -26.548607223510743, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.778319120407104, "step": 71000}
{"episode_reward": 492.71408770412, "episode": 72.0, "batch_reward": 0.24043024925887585, "critic_loss": 0.4396803833991289, "actor_loss": -26.846577964782714, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.686434507369995, "step": 72000}
{"episode_reward": 449.6711123114806, "episode": 73.0, "batch_reward": 0.24445122954249382, "critic_loss": 0.4232685060203075, "actor_loss": -27.40426359176636, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.392006635665894, "step": 73000}
{"episode_reward": 482.39333725030133, "episode": 74.0, "batch_reward": 0.24656123492121695, "critic_loss": 0.42829387356340887, "actor_loss": -27.69760751724243, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.501001358032227, "step": 74000}
{"episode_reward": 284.6892233061526, "episode": 75.0, "batch_reward": 0.24779680201411247, "critic_loss": 0.44505987618863585, "actor_loss": -27.799159271240235, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.305543422698975, "step": 75000}
{"episode_reward": 491.65968723378523, "episode": 76.0, "batch_reward": 0.25073495984077454, "critic_loss": 0.4334446788281202, "actor_loss": -28.033617198944093, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.51570439338684, "step": 76000}
{"episode_reward": 429.1499606796972, "episode": 77.0, "batch_reward": 0.2537064926624298, "critic_loss": 0.46076560600101946, "actor_loss": -28.622949794769287, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.21698760986328, "step": 77000}
{"episode_reward": 533.6011800105548, "episode": 78.0, "batch_reward": 0.25683364045619966, "critic_loss": 0.4453501381725073, "actor_loss": -28.82386809539795, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.08417296409607, "step": 78000}
{"episode_reward": 515.2568637930024, "episode": 79.0, "batch_reward": 0.26050827914476393, "critic_loss": 0.43684661196172236, "actor_loss": -29.32247495651245, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.459510803222656, "step": 79000}
{"episode_reward": 500.63485639070336, "episode": 80.0, "batch_reward": 0.26232412649691106, "critic_loss": 0.4184126769155264, "actor_loss": -29.68491905593872, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.49636220932007, "step": 80000}
{"episode_reward": 497.17515654350893, "episode": 81.0, "batch_reward": 0.2666766997426748, "critic_loss": 0.3990547551214695, "actor_loss": -30.12209485626221, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 43.4133403301239, "step": 81000}
{"episode_reward": 447.5648217304891, "episode": 82.0, "batch_reward": 0.26842491249740125, "critic_loss": 0.4130822084397078, "actor_loss": -30.12004667663574, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.525629997253418, "step": 82000}
{"episode_reward": 521.929852815921, "episode": 83.0, "batch_reward": 0.2718218326419592, "critic_loss": 0.4110030603855848, "actor_loss": -30.593521118164062, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.311458110809326, "step": 83000}
{"episode_reward": 389.51161158446746, "episode": 84.0, "batch_reward": 0.2728198860138655, "critic_loss": 0.4442283125966787, "actor_loss": -30.793063785552977, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.407920122146606, "step": 84000}
{"episode_reward": 483.23943585867056, "episode": 85.0, "batch_reward": 0.27479860082268714, "critic_loss": 0.4447541972398758, "actor_loss": -30.841015735626222, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.550432205200195, "step": 85000}
{"episode_reward": 449.69665878030395, "episode": 86.0, "batch_reward": 0.27782074196636675, "critic_loss": 0.4454880518168211, "actor_loss": -31.238329681396486, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.556021213531494, "step": 86000}
{"episode_reward": 507.5404507758115, "episode": 87.0, "batch_reward": 0.28056968802213667, "critic_loss": 0.4542611757516861, "actor_loss": -31.586148433685302, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.94526481628418, "step": 87000}
{"episode_reward": 422.4836396574115, "episode": 88.0, "batch_reward": 0.28164546194672585, "critic_loss": 0.4519713421463966, "actor_loss": -31.513759563446044, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.810807943344116, "step": 88000}
{"episode_reward": 476.77034912791186, "episode": 89.0, "batch_reward": 0.28419276610016825, "critic_loss": 0.4716861775070429, "actor_loss": -31.602004302978514, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.593355894088745, "step": 89000}
{"episode_reward": 531.9715522608767, "episode": 90.0, "batch_reward": 0.2880664579123259, "critic_loss": 0.4672968295365572, "actor_loss": -31.871723167419432, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.330170154571533, "step": 90000}
{"episode_reward": 513.285632728561, "episode": 91.0, "batch_reward": 0.2892603050917387, "critic_loss": 0.4536375147998333, "actor_loss": -32.02988599395752, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.979129791259766, "step": 91000}
{"episode_reward": 535.7566691343353, "episode": 92.0, "batch_reward": 0.2925761764496565, "critic_loss": 0.4715617587715387, "actor_loss": -32.68867537689209, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.688233852386475, "step": 92000}
{"episode_reward": 513.1068822479418, "episode": 93.0, "batch_reward": 0.29366956682503226, "critic_loss": 0.4481686050891876, "actor_loss": -32.62661864852905, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.4428448677063, "step": 93000}
{"episode_reward": 531.2917155261704, "episode": 94.0, "batch_reward": 0.29723920841515067, "critic_loss": 0.46473406831920144, "actor_loss": -33.047636459350585, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.148534059524536, "step": 94000}
{"episode_reward": 487.51114041872717, "episode": 95.0, "batch_reward": 0.29885353830456735, "critic_loss": 0.4167120344489813, "actor_loss": -33.44724656677246, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.378251314163208, "step": 95000}
{"episode_reward": 485.3210375421345, "episode": 96.0, "batch_reward": 0.30209427903592584, "critic_loss": 0.4305849944204092, "actor_loss": -33.43880117416382, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.889209985733032, "step": 96000}
{"episode_reward": 496.1641848805957, "episode": 97.0, "batch_reward": 0.30320667707920074, "critic_loss": 0.443818627178669, "actor_loss": -33.6765537109375, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.10769748687744, "step": 97000}
{"episode_reward": 524.4766754289233, "episode": 98.0, "batch_reward": 0.30477609238028525, "critic_loss": 0.46108864729106425, "actor_loss": -34.081317310333255, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.79948091506958, "step": 98000}
{"episode_reward": 498.9638463811299, "episode": 99.0, "batch_reward": 0.3066063824146986, "critic_loss": 0.3880144669860601, "actor_loss": -34.05376059341431, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.837507247924805, "step": 99000}
{"episode_reward": 480.8311840650039, "episode": 100.0, "batch_reward": 0.3091603502631187, "critic_loss": 0.3891980364620686, "actor_loss": -34.426554412841796, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.588038444519043, "step": 100000}
{"episode_reward": 533.9720959233857, "episode": 101.0, "batch_reward": 0.31060977560281755, "critic_loss": 0.40945951713621614, "actor_loss": -34.2953444480896, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.31765389442444, "step": 101000}
{"episode_reward": 520.095999317997, "episode": 102.0, "batch_reward": 0.31303565615415574, "critic_loss": 0.41584329845011236, "actor_loss": -34.59177196502686, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.028679609298706, "step": 102000}
{"episode_reward": 485.0914861922905, "episode": 103.0, "batch_reward": 0.3148947847634554, "critic_loss": 0.4182784937247634, "actor_loss": -34.70321645736694, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.63121461868286, "step": 103000}
{"episode_reward": 490.133291993657, "episode": 104.0, "batch_reward": 0.3170870334804058, "critic_loss": 0.40613155131042006, "actor_loss": -34.69782818603515, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.39942717552185, "step": 104000}
{"episode_reward": 522.1771887850892, "episode": 105.0, "batch_reward": 0.31902974724769595, "critic_loss": 0.4176296728551388, "actor_loss": -35.08474178314209, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.202093601226807, "step": 105000}
{"episode_reward": 498.8753432161168, "episode": 106.0, "batch_reward": 0.3204913042336702, "critic_loss": 0.3990335166156292, "actor_loss": -35.24244216156006, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.211562156677246, "step": 106000}
{"episode_reward": 504.8364774038922, "episode": 107.0, "batch_reward": 0.3221024615764618, "critic_loss": 0.4028434338122606, "actor_loss": -35.19958135604858, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.986944675445557, "step": 107000}
{"episode_reward": 532.2962604937998, "episode": 108.0, "batch_reward": 0.3237063343524933, "critic_loss": 0.4190750291645527, "actor_loss": -35.63837385559082, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.42472505569458, "step": 108000}
{"episode_reward": 529.6252521073119, "episode": 109.0, "batch_reward": 0.32677947118878364, "critic_loss": 0.38396932278573515, "actor_loss": -35.730111782073976, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.149107217788696, "step": 109000}
{"episode_reward": 519.6590707394314, "episode": 110.0, "batch_reward": 0.3277513792216778, "critic_loss": 0.44020382715761663, "actor_loss": -36.03236881256103, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.06972026824951, "step": 110000}
{"episode_reward": 525.512796952593, "episode": 111.0, "batch_reward": 0.3294532917141914, "critic_loss": 0.4136723991036415, "actor_loss": -36.09198690032959, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.36376094818115, "step": 111000}
{"episode_reward": 507.520897821197, "episode": 112.0, "batch_reward": 0.33128540498018266, "critic_loss": 0.41881745161116124, "actor_loss": -36.28635202789307, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.711760997772217, "step": 112000}
{"episode_reward": 519.7807654330286, "episode": 113.0, "batch_reward": 0.33301934283971785, "critic_loss": 0.39730888976156714, "actor_loss": -36.13368270874023, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.801392793655396, "step": 113000}
{"episode_reward": 537.057987807756, "episode": 114.0, "batch_reward": 0.33459667932987214, "critic_loss": 0.3951753416955471, "actor_loss": -36.71235264205933, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.602948904037476, "step": 114000}
{"episode_reward": 491.9833849208135, "episode": 115.0, "batch_reward": 0.3366671161353588, "critic_loss": 0.42177370454370977, "actor_loss": -36.692957706451416, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.450946807861328, "step": 115000}
{"episode_reward": 520.9682194492766, "episode": 116.0, "batch_reward": 0.3373545788526535, "critic_loss": 0.3976018692627549, "actor_loss": -36.796825145721435, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.977759838104248, "step": 116000}
{"episode_reward": 533.4108006691189, "episode": 117.0, "batch_reward": 0.34012934628129005, "critic_loss": 0.39682286176085474, "actor_loss": -36.81061113739014, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.50791573524475, "step": 117000}
{"episode_reward": 533.2050859037545, "episode": 118.0, "batch_reward": 0.34108752927184105, "critic_loss": 0.4276220280900598, "actor_loss": -37.08229046630859, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.77080273628235, "step": 118000}
{"episode_reward": 506.76973898759866, "episode": 119.0, "batch_reward": 0.34291214534640313, "critic_loss": 0.39798949636518954, "actor_loss": -37.146199058532716, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.543920040130615, "step": 119000}
{"episode_reward": 487.69393405081826, "episode": 120.0, "batch_reward": 0.34271077618002893, "critic_loss": 0.43366210274398326, "actor_loss": -37.20780350112915, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.33156418800354, "step": 120000}
{"episode_reward": 538.9881277642072, "episode": 121.0, "batch_reward": 0.3452667756676674, "critic_loss": 0.4574976290911436, "actor_loss": -37.42948917770386, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 40.68658137321472, "step": 121000}
{"episode_reward": 529.770547471403, "episode": 122.0, "batch_reward": 0.3468664021193981, "critic_loss": 0.4230361781865358, "actor_loss": -37.84137982559204, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.758228540420532, "step": 122000}
{"episode_reward": 524.315511330282, "episode": 123.0, "batch_reward": 0.3486245770454407, "critic_loss": 0.44743974301218986, "actor_loss": -37.9126183013916, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.542603254318237, "step": 123000}
{"episode_reward": 530.6123441918429, "episode": 124.0, "batch_reward": 0.3475195682644844, "critic_loss": 0.5455668419748545, "actor_loss": -37.976878173828126, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.032039880752563, "step": 124000}
{"episode_reward": 10.63313368882499, "episode": 125.0, "batch_reward": 0.3443823641240597, "critic_loss": 0.7169376933276653, "actor_loss": -38.01701178741455, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.753517150878906, "step": 125000}
{"episode_reward": 9.550979494019314, "episode": 126.0, "batch_reward": 0.3421253739893436, "critic_loss": 0.7940759107768536, "actor_loss": -38.29268312072754, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.189987182617188, "step": 126000}
{"episode_reward": 12.202022614892055, "episode": 127.0, "batch_reward": 0.3398444083929062, "critic_loss": 0.7511054466366768, "actor_loss": -38.41757029724121, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.074167728424072, "step": 127000}
{"episode_reward": 11.945481146972647, "episode": 128.0, "batch_reward": 0.3380067384243011, "critic_loss": 0.7593085612952709, "actor_loss": -38.48245142364502, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.364001274108887, "step": 128000}
{"episode_reward": 98.16313937200297, "episode": 129.0, "batch_reward": 0.33625429338216783, "critic_loss": 0.6912786796391011, "actor_loss": -38.443079864501954, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.42851972579956, "step": 129000}
{"episode_reward": 72.78125276234883, "episode": 130.0, "batch_reward": 0.33225716453790666, "critic_loss": 0.6317614583075046, "actor_loss": -38.19851736450195, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.036595821380615, "step": 130000}
{"episode_reward": 22.350610329473664, "episode": 131.0, "batch_reward": 0.3319811100065708, "critic_loss": 0.5313437395095825, "actor_loss": -38.260140525817874, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 39.73413133621216, "step": 131000}
{"episode_reward": 30.979386106445766, "episode": 132.0, "batch_reward": 0.32980731213092807, "critic_loss": 0.5251216862946749, "actor_loss": -38.166236755371095, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.60752558708191, "step": 132000}
{"episode_reward": 87.1962971859909, "episode": 133.0, "batch_reward": 0.32709173077344894, "critic_loss": 0.4998847082108259, "actor_loss": -37.76705536651611, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.447669744491577, "step": 133000}
{"episode_reward": 51.6800814054472, "episode": 134.0, "batch_reward": 0.3242226321697235, "critic_loss": 0.42498011825978754, "actor_loss": -37.787976818084715, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.540980339050293, "step": 134000}
{"episode_reward": 44.02764413649053, "episode": 135.0, "batch_reward": 0.32230646786093714, "critic_loss": 0.4590898471027613, "actor_loss": -37.73475908660889, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.71151065826416, "step": 135000}
{"episode_reward": 244.1420999700592, "episode": 136.0, "batch_reward": 0.3217670223414898, "critic_loss": 0.44019824278354647, "actor_loss": -37.58931805038452, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.29960870742798, "step": 136000}
{"episode_reward": 209.11380328746446, "episode": 137.0, "batch_reward": 0.3241428364813328, "critic_loss": 0.42401813143491746, "actor_loss": -37.62618460083008, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.456939220428467, "step": 137000}
{"episode_reward": 506.90258527285863, "episode": 138.0, "batch_reward": 0.32327140298485757, "critic_loss": 0.483700179040432, "actor_loss": -37.2932551612854, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.536051273345947, "step": 138000}
{"episode_reward": 455.81265352182345, "episode": 139.0, "batch_reward": 0.32530335083603856, "critic_loss": 0.4961278710961342, "actor_loss": -37.42944621276855, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.80181860923767, "step": 139000}
{"episode_reward": 536.9322847809116, "episode": 140.0, "batch_reward": 0.3255810440182686, "critic_loss": 0.46007835638523104, "actor_loss": -37.329446880340576, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.24368166923523, "step": 140000}
{"episode_reward": 472.0126704145963, "episode": 141.0, "batch_reward": 0.3287103134691715, "critic_loss": 0.5042743807286024, "actor_loss": -37.52203500366211, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.24341106414795, "step": 141000}
{"episode_reward": 511.44008164158026, "episode": 142.0, "batch_reward": 0.328961963146925, "critic_loss": 0.4839550144076347, "actor_loss": -37.417883167266844, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 25.007097244262695, "step": 142000}
{"episode_reward": 502.65836839950146, "episode": 143.0, "batch_reward": 0.32988197648525236, "critic_loss": 0.4844956832677126, "actor_loss": -37.52778670501709, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.266249179840088, "step": 143000}
{"episode_reward": 478.44332664254335, "episode": 144.0, "batch_reward": 0.3310710305571556, "critic_loss": 0.47900634534657, "actor_loss": -37.59869969558716, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.50607681274414, "step": 144000}
{"episode_reward": 514.6827361815186, "episode": 145.0, "batch_reward": 0.3330937058031559, "critic_loss": 0.47332405285537243, "actor_loss": -37.73900400543213, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.605664253234863, "step": 145000}
{"episode_reward": 537.9670343631377, "episode": 146.0, "batch_reward": 0.3325286791920662, "critic_loss": 0.4525683438777924, "actor_loss": -37.601095001220706, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 23.532800912857056, "step": 146000}
{"episode_reward": 452.6992292527174, "episode": 147.0, "batch_reward": 0.3339270759522915, "critic_loss": 0.4767196111083031, "actor_loss": -37.840921592712405, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.922491312026978, "step": 147000}
{"episode_reward": 532.0549398696072, "episode": 148.0, "batch_reward": 0.3361532288789749, "critic_loss": 0.46764757731556894, "actor_loss": -37.99416661071778, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.606919288635254, "step": 148000}
{"episode_reward": 511.6638386790558, "episode": 149.0, "batch_reward": 0.33594879668951033, "critic_loss": 0.4629768676757812, "actor_loss": -38.01859358978272, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 24.379894256591797, "step": 149000}
{"episode_reward": 235.25730339543554, "episode": 150.0, "batch_reward": 0.33649497240781784, "critic_loss": 0.4681616586744785, "actor_loss": -38.10297340393066, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
