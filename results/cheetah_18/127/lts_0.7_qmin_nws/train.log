{"episode_reward": 0.0, "episode": 1.0, "duration": 18.357831716537476, "step": 1000}
{"episode_reward": 7.051849146674556, "episode": 2.0, "duration": 1.582932710647583, "step": 2000}
{"episode_reward": 365.4711839680396, "episode": 3.0, "batch_reward": 0.176224849248636, "critic_loss": 0.056190222144007644, "actor_loss": -26.57149767172055, "actor_target_entropy": -6.0, "alpha_value": 0.010000000000000443, "duration": 62.057236194610596, "step": 3000}
{"episode_reward": 22.02527030210382, "episode": 4.0, "batch_reward": 0.11487366994470358, "critic_loss": 0.03678611339814961, "actor_loss": -20.001045134067535, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.19881772994995, "step": 4000}
{"episode_reward": 6.940957683547319, "episode": 5.0, "batch_reward": 0.09160895474627614, "critic_loss": 0.036391183584928516, "actor_loss": -19.23542020702362, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.714300632476807, "step": 5000}
{"episode_reward": 21.454247765589244, "episode": 6.0, "batch_reward": 0.08302751528471708, "critic_loss": 0.05458478615060448, "actor_loss": -19.830498973846435, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.223629236221313, "step": 6000}
{"episode_reward": 73.8929942075137, "episode": 7.0, "batch_reward": 0.0799371301010251, "critic_loss": 0.08211768803745509, "actor_loss": -18.121970273017883, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.625115633010864, "step": 7000}
{"episode_reward": 29.221718630945713, "episode": 8.0, "batch_reward": 0.07958788144215942, "critic_loss": 0.08707350532338023, "actor_loss": -17.116105013847353, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.04477071762085, "step": 8000}
{"episode_reward": 104.02897580641836, "episode": 9.0, "batch_reward": 0.08064963675662876, "critic_loss": 0.0947340930402279, "actor_loss": -16.625289974689483, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.47525429725647, "step": 9000}
{"episode_reward": 91.59934608309857, "episode": 10.0, "batch_reward": 0.08378332302346826, "critic_loss": 0.10973737911880016, "actor_loss": -17.622570998191833, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.166878700256348, "step": 10000}
{"episode_reward": 149.78674864068722, "episode": 11.0, "batch_reward": 0.08756123233214021, "critic_loss": 0.12446532381698489, "actor_loss": -16.965271075725557, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.90783977508545, "step": 11000}
{"episode_reward": 71.0713517851553, "episode": 12.0, "batch_reward": 0.08665075980499387, "critic_loss": 0.12401555300876498, "actor_loss": -16.949928991556167, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.19954800605774, "step": 12000}
{"episode_reward": 81.7596777908886, "episode": 13.0, "batch_reward": 0.08772397228330374, "critic_loss": 0.1284809337966144, "actor_loss": -16.92100948190689, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.27489972114563, "step": 13000}
{"episode_reward": 102.29205664991956, "episode": 14.0, "batch_reward": 0.08812279469892383, "critic_loss": 0.1617896402031183, "actor_loss": -16.582020104050635, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.901002168655396, "step": 14000}
{"episode_reward": 75.6328652142743, "episode": 15.0, "batch_reward": 0.08795255153253674, "critic_loss": 0.20360904347896575, "actor_loss": -16.877104556649922, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.70377779006958, "step": 15000}
{"episode_reward": 122.27368610939544, "episode": 16.0, "batch_reward": 0.09089675765484571, "critic_loss": 0.19438879311829804, "actor_loss": -17.719063681691885, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.24783182144165, "step": 16000}
{"episode_reward": 157.56863261041593, "episode": 17.0, "batch_reward": 0.09371826285123826, "critic_loss": 0.19734237316250802, "actor_loss": -16.858039589464664, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.739219665527344, "step": 17000}
{"episode_reward": 110.22668890895406, "episode": 18.0, "batch_reward": 0.09531483231112362, "critic_loss": 0.20666274999082088, "actor_loss": -17.418895588770507, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.96495747566223, "step": 18000}
{"episode_reward": 168.67232097907072, "episode": 19.0, "batch_reward": 0.09679495228081941, "critic_loss": 0.2065922490283847, "actor_loss": -17.419161141686143, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.462220907211304, "step": 19000}
{"episode_reward": 34.90263121997565, "episode": 20.0, "batch_reward": 0.09686206979304553, "critic_loss": 0.2046630808338523, "actor_loss": -18.36854955922067, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.2460355758667, "step": 20000}
{"episode_reward": 157.54272528886082, "episode": 21.0, "batch_reward": 0.09872311690449714, "critic_loss": 0.2222183903232217, "actor_loss": -16.91385747218132, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.831913471221924, "step": 21000}
{"episode_reward": 88.55439214445505, "episode": 22.0, "batch_reward": 0.09742637646198272, "critic_loss": 0.21266168655455112, "actor_loss": -17.545725222036243, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.26737380027771, "step": 22000}
{"episode_reward": 55.53578095499399, "episode": 23.0, "batch_reward": 0.09874734795093536, "critic_loss": 0.20221297588944434, "actor_loss": -16.878445159733296, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.477739810943604, "step": 23000}
{"episode_reward": 252.7050365701882, "episode": 24.0, "batch_reward": 0.10501942931860685, "critic_loss": 0.21002465250343083, "actor_loss": -18.1312016531229, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.918250560760498, "step": 24000}
{"episode_reward": 246.4522691254205, "episode": 25.0, "batch_reward": 0.1123665504977107, "critic_loss": 0.19197173251211644, "actor_loss": -19.237247306466102, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.903369665145874, "step": 25000}
{"episode_reward": 290.06228063457104, "episode": 26.0, "batch_reward": 0.11810688806325197, "critic_loss": 0.17744801721721887, "actor_loss": -18.87077859187126, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.23914122581482, "step": 26000}
{"episode_reward": 239.1133120353109, "episode": 27.0, "batch_reward": 0.12266128625720739, "critic_loss": 0.17583892565965653, "actor_loss": -19.288210204601288, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.538285970687866, "step": 27000}
{"episode_reward": 239.99419211676263, "episode": 28.0, "batch_reward": 0.12673643392324446, "critic_loss": 0.16782765160501004, "actor_loss": -19.53043751335144, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.06631898880005, "step": 28000}
{"episode_reward": 226.31466603211896, "episode": 29.0, "batch_reward": 0.13033170219510792, "critic_loss": 0.15236398234963416, "actor_loss": -20.186006657123567, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.52468752861023, "step": 29000}
{"episode_reward": 271.89126824853304, "episode": 30.0, "batch_reward": 0.13643807372450828, "critic_loss": 0.15308463667333125, "actor_loss": -20.27451971578598, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.187811851501465, "step": 30000}
{"episode_reward": 291.55306719753344, "episode": 31.0, "batch_reward": 0.14146190667897462, "critic_loss": 0.1525439558327198, "actor_loss": -20.687082290649414, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.872437477111816, "step": 31000}
{"episode_reward": 285.4878464393421, "episode": 32.0, "batch_reward": 0.14700792317092418, "critic_loss": 0.16269437443464996, "actor_loss": -21.219315537452697, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.1688494682312, "step": 32000}
{"episode_reward": 348.9784968449279, "episode": 33.0, "batch_reward": 0.15206353724747895, "critic_loss": 0.1640341706946492, "actor_loss": -22.047295411586763, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.25178098678589, "step": 33000}
{"episode_reward": 276.78928745614166, "episode": 34.0, "batch_reward": 0.15603367508202792, "critic_loss": 0.17551010812073947, "actor_loss": -22.30050347328186, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.846227645874023, "step": 34000}
{"episode_reward": 272.7851862587229, "episode": 35.0, "batch_reward": 0.15939143974334002, "critic_loss": 0.18800363007932902, "actor_loss": -22.83678440093994, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.67754554748535, "step": 35000}
{"episode_reward": 331.6156016031527, "episode": 36.0, "batch_reward": 0.1639003147110343, "critic_loss": 0.2074324139356613, "actor_loss": -23.892356202125548, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.23042321205139, "step": 36000}
{"episode_reward": 329.02825221364964, "episode": 37.0, "batch_reward": 0.16853116245567798, "critic_loss": 0.24501409243047237, "actor_loss": -23.157246974945068, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.263796091079712, "step": 37000}
{"episode_reward": 365.1981100705044, "episode": 38.0, "batch_reward": 0.17414644479751587, "critic_loss": 0.26878208929300307, "actor_loss": -23.328533199310304, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.620721340179443, "step": 38000}
{"episode_reward": 330.36258020932127, "episode": 39.0, "batch_reward": 0.1779761015921831, "critic_loss": 0.2550649259835482, "actor_loss": -24.299473375320435, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.027042865753174, "step": 39000}
{"episode_reward": 255.24194905964808, "episode": 40.0, "batch_reward": 0.1799306041151285, "critic_loss": 0.237717987164855, "actor_loss": -24.645138414382934, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.248291730880737, "step": 40000}
{"episode_reward": 299.28331564005987, "episode": 41.0, "batch_reward": 0.18233102391660214, "critic_loss": 0.23274344950914383, "actor_loss": -24.572534046173097, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.83186173439026, "step": 41000}
{"episode_reward": 324.1700793615676, "episode": 42.0, "batch_reward": 0.18726904104650022, "critic_loss": 0.24065752426534892, "actor_loss": -25.064194286346435, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.718883514404297, "step": 42000}
{"episode_reward": 253.66429938579338, "episode": 43.0, "batch_reward": 0.1881512692272663, "critic_loss": 0.23961448527127505, "actor_loss": -25.351834045410158, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.23242449760437, "step": 43000}
{"episode_reward": 357.78182057887085, "episode": 44.0, "batch_reward": 0.18934217210114002, "critic_loss": 0.2632031518816948, "actor_loss": -26.773814819335936, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.100002765655518, "step": 44000}
{"episode_reward": 83.7312081534909, "episode": 45.0, "batch_reward": 0.1895106284469366, "critic_loss": 0.25269525092095135, "actor_loss": -25.995037172317506, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.98478651046753, "step": 45000}
{"episode_reward": 361.1835762398263, "episode": 46.0, "batch_reward": 0.19283646486699582, "critic_loss": 0.25994678685069084, "actor_loss": -25.390502559661865, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.784363746643066, "step": 46000}
{"episode_reward": 370.63787462482077, "episode": 47.0, "batch_reward": 0.19633774384856223, "critic_loss": 0.2646772471368313, "actor_loss": -26.234575904846192, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.2325656414032, "step": 47000}
{"episode_reward": 339.9984807091462, "episode": 48.0, "batch_reward": 0.20027746638655664, "critic_loss": 0.2588767110332847, "actor_loss": -26.435328128814696, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.34599781036377, "step": 48000}
{"episode_reward": 285.2015297490627, "episode": 49.0, "batch_reward": 0.2022903556227684, "critic_loss": 0.289105653449893, "actor_loss": -27.55695061683655, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.694157123565674, "step": 49000}
{"episode_reward": 353.30712080854136, "episode": 50.0, "batch_reward": 0.20436496068537235, "critic_loss": 0.28889613756537436, "actor_loss": -27.161349018096924, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.364089965820312, "step": 50000}
{"episode_reward": 346.2543692548815, "episode": 51.0, "batch_reward": 0.20822466059029102, "critic_loss": 0.2724042244404554, "actor_loss": -27.15964955329895, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.558505058288574, "step": 51000}
{"episode_reward": 359.41680163430976, "episode": 52.0, "batch_reward": 0.2114499354660511, "critic_loss": 0.2834026377797127, "actor_loss": -27.514902559280394, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.962885856628418, "step": 52000}
{"episode_reward": 355.0002724839173, "episode": 53.0, "batch_reward": 0.21279027554392815, "critic_loss": 0.2834540668129921, "actor_loss": -28.1761109790802, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.584872007369995, "step": 53000}
{"episode_reward": 341.1322262647342, "episode": 54.0, "batch_reward": 0.21616048587858677, "critic_loss": 0.2981190923601389, "actor_loss": -28.858903162002562, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.271764755249023, "step": 54000}
{"episode_reward": 340.62032607477033, "episode": 55.0, "batch_reward": 0.2178002124428749, "critic_loss": 0.28186172007769345, "actor_loss": -28.580584535598756, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.062520503997803, "step": 55000}
{"episode_reward": 375.64736421742765, "episode": 56.0, "batch_reward": 0.22179814103245735, "critic_loss": 0.2709195436835289, "actor_loss": -28.67835046005249, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.936123847961426, "step": 56000}
{"episode_reward": 370.1970456626785, "episode": 57.0, "batch_reward": 0.22391231079399584, "critic_loss": 0.27172098533809186, "actor_loss": -28.75804123878479, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.558070421218872, "step": 57000}
{"episode_reward": 386.1832416149986, "episode": 58.0, "batch_reward": 0.2262192762196064, "critic_loss": 0.2897639555633068, "actor_loss": -29.142374893188478, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.224470376968384, "step": 58000}
{"episode_reward": 371.1779805528929, "episode": 59.0, "batch_reward": 0.22979338784515857, "critic_loss": 0.28969593182206155, "actor_loss": -29.18115418815613, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.050121545791626, "step": 59000}
{"episode_reward": 381.3041702532141, "episode": 60.0, "batch_reward": 0.2320439994931221, "critic_loss": 0.2781685532033443, "actor_loss": -29.697316665649414, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.135889291763306, "step": 60000}
{"episode_reward": 397.38381386023934, "episode": 61.0, "batch_reward": 0.234193164229393, "critic_loss": 0.28410524348914623, "actor_loss": -29.692717292785645, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.703011989593506, "step": 61000}
{"episode_reward": 367.43451807808884, "episode": 62.0, "batch_reward": 0.23691828237473964, "critic_loss": 0.2826791534125805, "actor_loss": -30.112188152313234, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.206827640533447, "step": 62000}
{"episode_reward": 369.9012003068887, "episode": 63.0, "batch_reward": 0.23939656303822995, "critic_loss": 0.26939238998293874, "actor_loss": -30.4165034866333, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.50897240638733, "step": 63000}
{"episode_reward": 402.7808606099617, "episode": 64.0, "batch_reward": 0.24140677343308925, "critic_loss": 0.2701127863526344, "actor_loss": -30.586951278686524, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.233799695968628, "step": 64000}
{"episode_reward": 352.0403639336662, "episode": 65.0, "batch_reward": 0.24317217636108399, "critic_loss": 0.2767089357227087, "actor_loss": -30.382916107177735, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.25303053855896, "step": 65000}
{"episode_reward": 407.95887454918875, "episode": 66.0, "batch_reward": 0.24580574832856655, "critic_loss": 0.2585917329415679, "actor_loss": -30.78609730529785, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.095523834228516, "step": 66000}
{"episode_reward": 434.3224313791735, "episode": 67.0, "batch_reward": 0.24837608635425568, "critic_loss": 0.26768816535174844, "actor_loss": -31.412000633239746, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.814292430877686, "step": 67000}
{"episode_reward": 365.88006387969864, "episode": 68.0, "batch_reward": 0.2502373443543911, "critic_loss": 0.2888727762848139, "actor_loss": -32.237901741027834, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.52218246459961, "step": 68000}
{"episode_reward": 353.7099211326864, "episode": 69.0, "batch_reward": 0.25240360225737096, "critic_loss": 0.2698235892727971, "actor_loss": -31.11447467803955, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.89666771888733, "step": 69000}
{"episode_reward": 450.87345707657977, "episode": 70.0, "batch_reward": 0.25491643863916397, "critic_loss": 0.2596000889390707, "actor_loss": -31.704408721923826, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.689378261566162, "step": 70000}
{"episode_reward": 413.6346849585385, "episode": 71.0, "batch_reward": 0.2574457219541073, "critic_loss": 0.26208873884379863, "actor_loss": -31.432939392089843, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.73389792442322, "step": 71000}
{"episode_reward": 429.8088444939517, "episode": 72.0, "batch_reward": 0.25950079450011254, "critic_loss": 0.26802592813968656, "actor_loss": -31.9768385848999, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.84581422805786, "step": 72000}
{"episode_reward": 425.5715474979738, "episode": 73.0, "batch_reward": 0.2615671655684709, "critic_loss": 0.2612156472355127, "actor_loss": -32.28871687698364, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.253931760787964, "step": 73000}
{"episode_reward": 390.4768799703463, "episode": 74.0, "batch_reward": 0.26370074197649956, "critic_loss": 0.2912049868553877, "actor_loss": -32.16316122436523, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.310731649398804, "step": 74000}
{"episode_reward": 421.40205136153924, "episode": 75.0, "batch_reward": 0.2651937924474478, "critic_loss": 0.2686121170818806, "actor_loss": -32.55853574371338, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.603164672851562, "step": 75000}
{"episode_reward": 413.5203331694724, "episode": 76.0, "batch_reward": 0.26791360637545586, "critic_loss": 0.26232765609025954, "actor_loss": -32.69711220550537, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.185152530670166, "step": 76000}
{"episode_reward": 437.83661640354774, "episode": 77.0, "batch_reward": 0.27051996944844725, "critic_loss": 0.28936360314488413, "actor_loss": -32.965252208709714, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.476922750473022, "step": 77000}
{"episode_reward": 437.8793986080647, "episode": 78.0, "batch_reward": 0.27165519100427626, "critic_loss": 0.26995008482784033, "actor_loss": -33.35862322235108, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.246549367904663, "step": 78000}
{"episode_reward": 437.12107671027206, "episode": 79.0, "batch_reward": 0.2744356377273798, "critic_loss": 0.2767155819609761, "actor_loss": -33.76817315292358, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.23939085006714, "step": 79000}
{"episode_reward": 419.0121768444757, "episode": 80.0, "batch_reward": 0.27582674063742163, "critic_loss": 0.2767686506062746, "actor_loss": -33.79627590560913, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.771997213363647, "step": 80000}
{"episode_reward": 413.0857679444181, "episode": 81.0, "batch_reward": 0.2780555679649115, "critic_loss": 0.28101212556660177, "actor_loss": -33.56141644287109, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.7068030834198, "step": 81000}
{"episode_reward": 405.02198964059636, "episode": 82.0, "batch_reward": 0.2785822288244963, "critic_loss": 0.28028866889327764, "actor_loss": -33.560993225097654, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.548733472824097, "step": 82000}
{"episode_reward": 411.8028662592007, "episode": 83.0, "batch_reward": 0.28136426202952863, "critic_loss": 0.3049480526000261, "actor_loss": -33.98747031402588, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.37295627593994, "step": 83000}
{"episode_reward": 393.81581338746, "episode": 84.0, "batch_reward": 0.28200450782477854, "critic_loss": 0.3090277833044529, "actor_loss": -34.48070930480957, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.238645315170288, "step": 84000}
{"episode_reward": 414.7648600135637, "episode": 85.0, "batch_reward": 0.28340395206213, "critic_loss": 0.3058805876374245, "actor_loss": -34.458749004364016, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.258586645126343, "step": 85000}
{"episode_reward": 429.2472395326858, "episode": 86.0, "batch_reward": 0.2856604519933462, "critic_loss": 0.29495031157135965, "actor_loss": -33.92430439758301, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.286943435668945, "step": 86000}
{"episode_reward": 432.6221016164758, "episode": 87.0, "batch_reward": 0.2872796842455864, "critic_loss": 0.32619396038353443, "actor_loss": -35.1455292930603, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.702319145202637, "step": 87000}
{"episode_reward": 407.25459846511296, "episode": 88.0, "batch_reward": 0.28830566816031933, "critic_loss": 0.32603719940781595, "actor_loss": -34.26577363204956, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.22481656074524, "step": 88000}
{"episode_reward": 408.0379310902329, "episode": 89.0, "batch_reward": 0.2890995062589645, "critic_loss": 0.34492088462412357, "actor_loss": -34.409840305328366, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.954792022705078, "step": 89000}
{"episode_reward": 145.89307226762918, "episode": 90.0, "batch_reward": 0.288526997551322, "critic_loss": 0.35362978065013884, "actor_loss": -34.30675565719604, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.042386293411255, "step": 90000}
{"episode_reward": 425.7617917127376, "episode": 91.0, "batch_reward": 0.2901427529156208, "critic_loss": 0.32999496152997015, "actor_loss": -34.37307224273682, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.73557209968567, "step": 91000}
{"episode_reward": 414.5807639327763, "episode": 92.0, "batch_reward": 0.29127072820067407, "critic_loss": 0.32013309709727766, "actor_loss": -34.94091182327271, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.286531925201416, "step": 92000}
{"episode_reward": 428.5601272693823, "episode": 93.0, "batch_reward": 0.291672177657485, "critic_loss": 0.31180134546756744, "actor_loss": -34.46404135131836, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.49939489364624, "step": 93000}
{"episode_reward": 137.9143464609965, "episode": 94.0, "batch_reward": 0.28999203285574915, "critic_loss": 0.3472550898939371, "actor_loss": -34.64280377578736, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.309191942214966, "step": 94000}
{"episode_reward": 117.9664784210656, "episode": 95.0, "batch_reward": 0.2874859872162342, "critic_loss": 0.3576309099197388, "actor_loss": -34.6520128364563, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.22850465774536, "step": 95000}
{"episode_reward": 46.24772969128924, "episode": 96.0, "batch_reward": 0.28728441597521304, "critic_loss": 0.3771158393770456, "actor_loss": -34.39922647476196, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.936832904815674, "step": 96000}
{"episode_reward": 428.6985730228222, "episode": 97.0, "batch_reward": 0.2869374911040068, "critic_loss": 0.347142315864563, "actor_loss": -33.85086685943604, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.55841636657715, "step": 97000}
{"episode_reward": 247.12983323320813, "episode": 98.0, "batch_reward": 0.28763226898014543, "critic_loss": 0.37731994383037093, "actor_loss": -34.952324619293215, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.23608660697937, "step": 98000}
{"episode_reward": 413.7450581067615, "episode": 99.0, "batch_reward": 0.28893725675344467, "critic_loss": 0.3997763160765171, "actor_loss": -34.128339683532715, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.229858875274658, "step": 99000}
{"episode_reward": 405.6891429511703, "episode": 100.0, "batch_reward": 0.2906678536236286, "critic_loss": 0.4130965928733349, "actor_loss": -34.28451435470581, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.665924549102783, "step": 100000}
{"episode_reward": 418.12307991682, "episode": 101.0, "batch_reward": 0.29118562395870684, "critic_loss": 0.369023876324296, "actor_loss": -34.30437918090821, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 36.75416088104248, "step": 101000}
{"episode_reward": 406.55410604234, "episode": 102.0, "batch_reward": 0.29226337191462515, "critic_loss": 0.3666783684790134, "actor_loss": -34.91430995559693, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.840776205062866, "step": 102000}
{"episode_reward": 398.235530867172, "episode": 103.0, "batch_reward": 0.29270698088407515, "critic_loss": 0.38479636478424073, "actor_loss": -34.50064573669434, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.00055503845215, "step": 103000}
{"episode_reward": 291.6783990377677, "episode": 104.0, "batch_reward": 0.29328875786066055, "critic_loss": 0.3527512705177069, "actor_loss": -34.37988740158081, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.329941987991333, "step": 104000}
{"episode_reward": 383.39072632503724, "episode": 105.0, "batch_reward": 0.29464550882577895, "critic_loss": 0.3542426685243845, "actor_loss": -34.757854125976564, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.254308462142944, "step": 105000}
{"episode_reward": 409.89531667203335, "episode": 106.0, "batch_reward": 0.29513998319208623, "critic_loss": 0.3773503300845623, "actor_loss": -34.729902599334714, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.643934965133667, "step": 106000}
{"episode_reward": 390.117019943603, "episode": 107.0, "batch_reward": 0.2962003504484892, "critic_loss": 0.3957258224338293, "actor_loss": -34.34014892959595, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.37934112548828, "step": 107000}
{"episode_reward": 455.75736149337774, "episode": 108.0, "batch_reward": 0.2975679824352264, "critic_loss": 0.38105531546473503, "actor_loss": -35.34974161148071, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.223402738571167, "step": 108000}
{"episode_reward": 419.1888790748449, "episode": 109.0, "batch_reward": 0.29861228507757187, "critic_loss": 0.3563877014517784, "actor_loss": -35.045584117889405, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.261841773986816, "step": 109000}
{"episode_reward": 413.2960845636648, "episode": 110.0, "batch_reward": 0.300443540841341, "critic_loss": 0.34958413292467594, "actor_loss": -35.67126273727417, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.20955753326416, "step": 110000}
{"episode_reward": 397.4635047906473, "episode": 111.0, "batch_reward": 0.3007065361887217, "critic_loss": 0.34563225631415845, "actor_loss": -34.99603380203247, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.00238561630249, "step": 111000}
{"episode_reward": 417.96742668856535, "episode": 112.0, "batch_reward": 0.3017685851752758, "critic_loss": 0.3578050054460764, "actor_loss": -35.77011440658569, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.780715703964233, "step": 112000}
{"episode_reward": 429.5881456128685, "episode": 113.0, "batch_reward": 0.30243461388349535, "critic_loss": 0.3667478132992983, "actor_loss": -35.36667765808105, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.19320559501648, "step": 113000}
{"episode_reward": 219.22428979684855, "episode": 114.0, "batch_reward": 0.30259216532111166, "critic_loss": 0.3629207591712475, "actor_loss": -35.613941104888916, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.593268871307373, "step": 114000}
{"episode_reward": 418.5566048445578, "episode": 115.0, "batch_reward": 0.30375724548101424, "critic_loss": 0.34373938411474225, "actor_loss": -35.53805447769165, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.23580265045166, "step": 115000}
{"episode_reward": 440.18410056257255, "episode": 116.0, "batch_reward": 0.3044606084227562, "critic_loss": 0.3212322838827968, "actor_loss": -35.8409227180481, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.240863800048828, "step": 116000}
{"episode_reward": 404.0869968469635, "episode": 117.0, "batch_reward": 0.30610461711883546, "critic_loss": 0.325149676784873, "actor_loss": -35.57543547439575, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.03387188911438, "step": 117000}
{"episode_reward": 430.49182452149455, "episode": 118.0, "batch_reward": 0.306705003336072, "critic_loss": 0.307890354141593, "actor_loss": -35.53634476089478, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.617671251296997, "step": 118000}
{"episode_reward": 452.5488104572046, "episode": 119.0, "batch_reward": 0.3075500051677227, "critic_loss": 0.3545834816247225, "actor_loss": -35.844663681030276, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.281699180603027, "step": 119000}
{"episode_reward": 398.02265807585775, "episode": 120.0, "batch_reward": 0.308105153799057, "critic_loss": 0.34447912815213205, "actor_loss": -35.64186855697632, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.92470908164978, "step": 120000}
{"episode_reward": 363.4204837130595, "episode": 121.0, "batch_reward": 0.30850553515553475, "critic_loss": 0.3732860777527094, "actor_loss": -35.778672485351564, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 37.77696132659912, "step": 121000}
{"episode_reward": 320.1112196013261, "episode": 122.0, "batch_reward": 0.3092497518658638, "critic_loss": 0.35853576508164403, "actor_loss": -36.2616512298584, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.260474920272827, "step": 122000}
{"episode_reward": 426.3075179394034, "episode": 123.0, "batch_reward": 0.3101078927218914, "critic_loss": 0.33179886351525784, "actor_loss": -36.281886711120606, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.409143686294556, "step": 123000}
{"episode_reward": 413.52707105192786, "episode": 124.0, "batch_reward": 0.31137735037505626, "critic_loss": 0.3594781684726477, "actor_loss": -36.48269300842285, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.774895906448364, "step": 124000}
{"episode_reward": 404.0955537712164, "episode": 125.0, "batch_reward": 0.3112515332698822, "critic_loss": 0.40054152949154376, "actor_loss": -36.17468634414673, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.352541208267212, "step": 125000}
{"episode_reward": 439.18385684178935, "episode": 126.0, "batch_reward": 0.31312082332372665, "critic_loss": 0.3446406708061695, "actor_loss": -36.66193238067627, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.246185302734375, "step": 126000}
{"episode_reward": 381.5784736716412, "episode": 127.0, "batch_reward": 0.3131006836593151, "critic_loss": 0.368870378896594, "actor_loss": -36.63452923965454, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.509048223495483, "step": 127000}
{"episode_reward": 412.91717173032356, "episode": 128.0, "batch_reward": 0.3137859587073326, "critic_loss": 0.38842848837375643, "actor_loss": -36.576882499694825, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.725465059280396, "step": 128000}
{"episode_reward": 406.7902913126633, "episode": 129.0, "batch_reward": 0.3154993665218353, "critic_loss": 0.37474359561502935, "actor_loss": -36.608461544036864, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.216339349746704, "step": 129000}
{"episode_reward": 407.95030276708064, "episode": 130.0, "batch_reward": 0.31507626032829283, "critic_loss": 0.42242301024496554, "actor_loss": -36.876564441680905, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.267472505569458, "step": 130000}
{"episode_reward": 445.76149988222056, "episode": 131.0, "batch_reward": 0.31624239787459374, "critic_loss": 0.38474573568999765, "actor_loss": -36.2209107055664, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.96052384376526, "step": 131000}
{"episode_reward": 362.434142188889, "episode": 132.0, "batch_reward": 0.31572167149186137, "critic_loss": 0.40396933613717556, "actor_loss": -36.97443648147583, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.24934482574463, "step": 132000}
{"episode_reward": 411.91134239871104, "episode": 133.0, "batch_reward": 0.3175374754667282, "critic_loss": 0.3737029823958874, "actor_loss": -36.62376183319092, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.236560821533203, "step": 133000}
{"episode_reward": 410.772607406109, "episode": 134.0, "batch_reward": 0.3175899693071842, "critic_loss": 0.3601174294650555, "actor_loss": -36.969972747802736, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.291221380233765, "step": 134000}
{"episode_reward": 396.8738978086812, "episode": 135.0, "batch_reward": 0.3184406093657017, "critic_loss": 0.4080941773056984, "actor_loss": -37.21210234832763, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.82505512237549, "step": 135000}
{"episode_reward": 418.1208837294738, "episode": 136.0, "batch_reward": 0.3195434609949589, "critic_loss": 0.4329460959881544, "actor_loss": -36.97452030181885, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.254513263702393, "step": 136000}
{"episode_reward": 196.73423402636678, "episode": 137.0, "batch_reward": 0.3195540353357792, "critic_loss": 0.4017633550018072, "actor_loss": -37.035055095672604, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.751457452774048, "step": 137000}
{"episode_reward": 395.6701284726758, "episode": 138.0, "batch_reward": 0.31863946759700773, "critic_loss": 0.39957743214070796, "actor_loss": -36.887361248016354, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.824843645095825, "step": 138000}
{"episode_reward": 416.7116598919984, "episode": 139.0, "batch_reward": 0.31952129626274106, "critic_loss": 0.42174191522598264, "actor_loss": -36.77447695541382, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.27004384994507, "step": 139000}
{"episode_reward": 353.71087380022954, "episode": 140.0, "batch_reward": 0.3192009885907173, "critic_loss": 0.43045607559382915, "actor_loss": -37.33465993881226, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.2973792552948, "step": 140000}
{"episode_reward": 411.08302234021767, "episode": 141.0, "batch_reward": 0.32184796744585037, "critic_loss": 0.3731883469969034, "actor_loss": -37.24669269943237, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 38.974671602249146, "step": 141000}
{"episode_reward": 440.9293670618707, "episode": 142.0, "batch_reward": 0.3217685584127903, "critic_loss": 0.4167318236976862, "actor_loss": -37.23605405426025, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.199232816696167, "step": 142000}
{"episode_reward": 354.6690393670939, "episode": 143.0, "batch_reward": 0.32097618079185486, "critic_loss": 0.4141902552545071, "actor_loss": -37.298374000549316, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.235071182250977, "step": 143000}
{"episode_reward": 113.86710830184984, "episode": 144.0, "batch_reward": 0.3205405029058456, "critic_loss": 0.41135696799308064, "actor_loss": -37.588567306518556, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.918542623519897, "step": 144000}
{"episode_reward": 383.5305176607543, "episode": 145.0, "batch_reward": 0.3207597283124924, "critic_loss": 0.39744098982214926, "actor_loss": -37.24458247375488, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 21.31104063987732, "step": 145000}
{"episode_reward": 391.3742828337827, "episode": 146.0, "batch_reward": 0.321131543636322, "critic_loss": 0.4231213522180915, "actor_loss": -36.658813999176026, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.233876943588257, "step": 146000}
{"episode_reward": 437.96619866414477, "episode": 147.0, "batch_reward": 0.32089058101177215, "critic_loss": 0.45521458351612093, "actor_loss": -37.138501266479494, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.380802154541016, "step": 147000}
{"episode_reward": 434.7707007871401, "episode": 148.0, "batch_reward": 0.32335926142334936, "critic_loss": 0.3958662350475788, "actor_loss": -37.552052196502686, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 22.10588574409485, "step": 148000}
{"episode_reward": 411.7571620424307, "episode": 149.0, "batch_reward": 0.3239815662801266, "critic_loss": 0.47951443341374395, "actor_loss": -37.58188874816894, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "duration": 20.335830211639404, "step": 149000}
{"episode_reward": 387.20087863092874, "episode": 150.0, "batch_reward": 0.3238495839238167, "critic_loss": 0.4976508411616087, "actor_loss": -37.44975035476685, "actor_target_entropy": -6.0, "alpha_value": 0.009999999999999875, "step": 150000}
