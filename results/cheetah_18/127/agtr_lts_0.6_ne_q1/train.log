{"episode_reward": 0.0, "episode": 1.0, "duration": 24.339224338531494, "step": 1000}
{"episode_reward": 7.051849146674556, "episode": 2.0, "duration": 2.312875986099243, "step": 2000}
{"episode_reward": 365.4711839680396, "episode": 3.0, "batch_reward": 0.18050923503043453, "critic_loss": 0.5215946170251423, "actor_loss": -36.062033707831276, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 88.68355011940002, "step": 3000}
{"episode_reward": 93.2868532894711, "episode": 4.0, "batch_reward": 0.1602588528096676, "critic_loss": 0.6308322944939136, "actor_loss": -33.68603532409668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.367276668548584, "step": 4000}
{"episode_reward": 208.30903175568994, "episode": 5.0, "batch_reward": 0.16696181555837392, "critic_loss": 0.7061511998474598, "actor_loss": -33.13029085159302, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.571351528167725, "step": 5000}
{"episode_reward": 162.1745309870792, "episode": 6.0, "batch_reward": 0.17357897505164147, "critic_loss": 0.7078312667608261, "actor_loss": -32.655572101593016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.755131483078003, "step": 6000}
{"episode_reward": 235.47645405112257, "episode": 7.0, "batch_reward": 0.18390595671534538, "critic_loss": 0.8334826087057591, "actor_loss": -32.13989967727661, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.30195450782776, "step": 7000}
{"episode_reward": 229.01033222536552, "episode": 8.0, "batch_reward": 0.19240489007532596, "critic_loss": 0.8448627089560032, "actor_loss": -32.55389744186402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.028481245040894, "step": 8000}
{"episode_reward": 254.66927702266386, "episode": 9.0, "batch_reward": 0.19771955710649491, "critic_loss": 0.8544201010763646, "actor_loss": -32.32833582687378, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.365269660949707, "step": 9000}
{"episode_reward": 228.43397897009774, "episode": 10.0, "batch_reward": 0.20456883081793786, "critic_loss": 0.8977390376627445, "actor_loss": -32.00883814239502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.981850385665894, "step": 10000}
{"episode_reward": 326.274225796296, "episode": 11.0, "batch_reward": 0.217874429166317, "critic_loss": 0.9866301380991935, "actor_loss": -32.53450234222412, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 55.25926899909973, "step": 11000}
{"episode_reward": 358.4001837953711, "episode": 12.0, "batch_reward": 0.22365253667533397, "critic_loss": 0.9844763766527176, "actor_loss": -32.37404431533813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.56431770324707, "step": 12000}
{"episode_reward": 140.31066640488254, "episode": 13.0, "batch_reward": 0.22461949986219407, "critic_loss": 0.9267971848249436, "actor_loss": -31.60072678756714, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.762287139892578, "step": 13000}
{"episode_reward": 423.1838650517787, "episode": 14.0, "batch_reward": 0.23970377771556378, "critic_loss": 0.8645624848604202, "actor_loss": -32.20885424041748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.098410606384277, "step": 14000}
{"episode_reward": 411.93979622442555, "episode": 15.0, "batch_reward": 0.24955110636353492, "critic_loss": 0.7638292615711689, "actor_loss": -33.07893898391723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.779201984405518, "step": 15000}
{"episode_reward": 395.5820099070573, "episode": 16.0, "batch_reward": 0.2607249488681555, "critic_loss": 0.6708502500653267, "actor_loss": -33.353240657806396, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.046284675598145, "step": 16000}
{"episode_reward": 436.10832648361696, "episode": 17.0, "batch_reward": 0.27067028304934504, "critic_loss": 0.622336975812912, "actor_loss": -33.58472090530395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.328142881393433, "step": 17000}
{"episode_reward": 336.541272171316, "episode": 18.0, "batch_reward": 0.2741603390276432, "critic_loss": 0.5692124310731888, "actor_loss": -33.57727513504028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.481725692749023, "step": 18000}
{"episode_reward": 422.3203109617986, "episode": 19.0, "batch_reward": 0.28298945766687394, "critic_loss": 0.5304069604575634, "actor_loss": -34.016815391540526, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.604742765426636, "step": 19000}
{"episode_reward": 417.95266289962547, "episode": 20.0, "batch_reward": 0.28968932226300237, "critic_loss": 0.5173093173801899, "actor_loss": -34.71565296554565, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.944162130355835, "step": 20000}
{"episode_reward": 416.13092021472403, "episode": 21.0, "batch_reward": 0.29589743733406065, "critic_loss": 0.5260288608968258, "actor_loss": -34.04389052581787, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 56.01551365852356, "step": 21000}
{"episode_reward": 375.6982885689018, "episode": 22.0, "batch_reward": 0.30005071467161176, "critic_loss": 0.5024708431363106, "actor_loss": -35.055028705596925, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.906464338302612, "step": 22000}
{"episode_reward": 422.26624413748755, "episode": 23.0, "batch_reward": 0.30489722061157226, "critic_loss": 0.5003480753004551, "actor_loss": -34.798406772613525, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.859094619750977, "step": 23000}
{"episode_reward": 380.98315468107756, "episode": 24.0, "batch_reward": 0.30677789396047594, "critic_loss": 0.4938972477912903, "actor_loss": -35.13834046936035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.701743602752686, "step": 24000}
{"episode_reward": 380.9783798006337, "episode": 25.0, "batch_reward": 0.3120141723155975, "critic_loss": 0.5080040167570115, "actor_loss": -35.577633792877194, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.005160570144653, "step": 25000}
{"episode_reward": 418.9047650933047, "episode": 26.0, "batch_reward": 0.31536759704351425, "critic_loss": 0.5467728425264359, "actor_loss": -35.55771649169922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.35917901992798, "step": 26000}
{"episode_reward": 400.2353601738562, "episode": 27.0, "batch_reward": 0.3181134576797485, "critic_loss": 0.5776187042593957, "actor_loss": -35.31781470489502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.594281673431396, "step": 27000}
{"episode_reward": 394.5046399245416, "episode": 28.0, "batch_reward": 0.32195284473896024, "critic_loss": 0.6013872104287148, "actor_loss": -36.1364490814209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.21556520462036, "step": 28000}
{"episode_reward": 414.8148234905993, "episode": 29.0, "batch_reward": 0.3232835103869438, "critic_loss": 0.6282957425415516, "actor_loss": -35.686981616973874, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.511778116226196, "step": 29000}
{"episode_reward": 378.2360161392334, "episode": 30.0, "batch_reward": 0.32698749053478243, "critic_loss": 0.6475784098505973, "actor_loss": -35.709901927947996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.583306789398193, "step": 30000}
{"episode_reward": 412.8511750434195, "episode": 31.0, "batch_reward": 0.32970342454314233, "critic_loss": 0.7037444975376129, "actor_loss": -36.06398155212403, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 56.345043659210205, "step": 31000}
{"episode_reward": 433.65096965824847, "episode": 32.0, "batch_reward": 0.3342292366325855, "critic_loss": 0.7156092230379582, "actor_loss": -36.606843830108645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.293091535568237, "step": 32000}
{"episode_reward": 471.9087067592394, "episode": 33.0, "batch_reward": 0.33709977212548253, "critic_loss": 0.7423032310605049, "actor_loss": -36.75251522064209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.69362711906433, "step": 33000}
{"episode_reward": 407.9917664423304, "episode": 34.0, "batch_reward": 0.3396186304986477, "critic_loss": 0.7856816885769368, "actor_loss": -36.76527761459351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.741166353225708, "step": 34000}
{"episode_reward": 454.866443310363, "episode": 35.0, "batch_reward": 0.34375745862722396, "critic_loss": 0.8147751565575599, "actor_loss": -37.23768916320801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.017300844192505, "step": 35000}
{"episode_reward": 505.62953323845664, "episode": 36.0, "batch_reward": 0.3479253444969654, "critic_loss": 0.9041673176884651, "actor_loss": -38.040047367095944, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.61489224433899, "step": 36000}
{"episode_reward": 489.60993495089247, "episode": 37.0, "batch_reward": 0.35168209648132326, "critic_loss": 0.903896683216095, "actor_loss": -37.55483032608032, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.112807512283325, "step": 37000}
{"episode_reward": 442.59792011932956, "episode": 38.0, "batch_reward": 0.35472142627835274, "critic_loss": 0.9373127682805061, "actor_loss": -37.71404051208496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.611039400100708, "step": 38000}
{"episode_reward": 466.46242213991616, "episode": 39.0, "batch_reward": 0.35703386121988295, "critic_loss": 0.9977060543000698, "actor_loss": -37.814157009124756, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.61464238166809, "step": 39000}
{"episode_reward": 418.81447032640415, "episode": 40.0, "batch_reward": 0.3591433076262474, "critic_loss": 0.9634451641440391, "actor_loss": -38.21537375640869, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.844640254974365, "step": 40000}
{"episode_reward": 475.6887263378777, "episode": 41.0, "batch_reward": 0.36109035059809685, "critic_loss": 0.8871926199197769, "actor_loss": -37.68871049880981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 57.55921673774719, "step": 41000}
{"episode_reward": 469.65468146626455, "episode": 42.0, "batch_reward": 0.3651932273209095, "critic_loss": 0.8960479461848736, "actor_loss": -38.39039524078369, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.016061544418335, "step": 42000}
{"episode_reward": 479.3994581139085, "episode": 43.0, "batch_reward": 0.3667878413796425, "critic_loss": 0.904624113202095, "actor_loss": -38.94087767791748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.743528604507446, "step": 43000}
{"episode_reward": 483.69525301427876, "episode": 44.0, "batch_reward": 0.3694841586053371, "critic_loss": 0.8468165951669216, "actor_loss": -39.695706821441654, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.432159185409546, "step": 44000}
{"episode_reward": 496.81887614844976, "episode": 45.0, "batch_reward": 0.37341996002197264, "critic_loss": 0.8586315675377846, "actor_loss": -39.57074713897705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.768754720687866, "step": 45000}
{"episode_reward": 544.7780549942192, "episode": 46.0, "batch_reward": 0.3759660190343857, "critic_loss": 0.8718189188241958, "actor_loss": -39.04368981552124, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.63253378868103, "step": 46000}
{"episode_reward": 532.317604575033, "episode": 47.0, "batch_reward": 0.37939795875549315, "critic_loss": 0.9572791269123554, "actor_loss": -39.61070080184937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.482572317123413, "step": 47000}
{"episode_reward": 472.4879100290141, "episode": 48.0, "batch_reward": 0.3820875669121742, "critic_loss": 0.9007315628230572, "actor_loss": -39.80375979995728, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.880133628845215, "step": 48000}
{"episode_reward": 520.9721486423858, "episode": 49.0, "batch_reward": 0.38469329380989076, "critic_loss": 0.872120495647192, "actor_loss": -40.726326683044434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.942424058914185, "step": 49000}
{"episode_reward": 488.4436761744354, "episode": 50.0, "batch_reward": 0.38233099642395973, "critic_loss": 0.9794011988639831, "actor_loss": -40.20923788833618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.060842514038086, "step": 50000}
{"episode_reward": 65.61120070207404, "episode": 51.0, "batch_reward": 0.38109532091021536, "critic_loss": 0.9306286145150662, "actor_loss": -39.95615041732788, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 57.75118041038513, "step": 51000}
{"episode_reward": 539.3235382614864, "episode": 52.0, "batch_reward": 0.38352206668257716, "critic_loss": 0.8305460913479328, "actor_loss": -39.58036739730835, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.681718349456787, "step": 52000}
{"episode_reward": 474.83321775701796, "episode": 53.0, "batch_reward": 0.38531341552734377, "critic_loss": 0.8456647420823574, "actor_loss": -40.35411513137817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.855870485305786, "step": 53000}
{"episode_reward": 547.46169559071, "episode": 54.0, "batch_reward": 0.388605009585619, "critic_loss": 0.8128325531482696, "actor_loss": -41.02368650817871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.6984121799469, "step": 54000}
{"episode_reward": 523.195748588836, "episode": 55.0, "batch_reward": 0.389512943983078, "critic_loss": 0.8574170716702938, "actor_loss": -40.43178414535522, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.77303123474121, "step": 55000}
{"episode_reward": 479.18271587529654, "episode": 56.0, "batch_reward": 0.3926932763159275, "critic_loss": 0.852203692495823, "actor_loss": -40.86781665802002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.573401927947998, "step": 56000}
{"episode_reward": 482.9919120044791, "episode": 57.0, "batch_reward": 0.39482270044088363, "critic_loss": 0.8551756572127343, "actor_loss": -40.95457454299927, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.740158081054688, "step": 57000}
{"episode_reward": 499.59738797332034, "episode": 58.0, "batch_reward": 0.3949333099722862, "critic_loss": 0.7927958661317825, "actor_loss": -41.1438857383728, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.215495109558105, "step": 58000}
{"episode_reward": 535.4044169478742, "episode": 59.0, "batch_reward": 0.3988429295420647, "critic_loss": 0.7858913697898388, "actor_loss": -41.542443866729734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.558430671691895, "step": 59000}
{"episode_reward": 540.5363702134399, "episode": 60.0, "batch_reward": 0.40059821420907976, "critic_loss": 0.7458791503310204, "actor_loss": -41.85486695480347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.46942973136902, "step": 60000}
{"episode_reward": 514.5132558244791, "episode": 61.0, "batch_reward": 0.40249439936876297, "critic_loss": 0.7643733491301536, "actor_loss": -41.59742502975464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 58.227829694747925, "step": 61000}
{"episode_reward": 499.37692430713554, "episode": 62.0, "batch_reward": 0.4043939348757267, "critic_loss": 0.7582608723640442, "actor_loss": -42.29099629211426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.099627017974854, "step": 62000}
{"episode_reward": 499.264679044606, "episode": 63.0, "batch_reward": 0.4052046701014042, "critic_loss": 0.7838484826087951, "actor_loss": -41.93224301147461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.702070951461792, "step": 63000}
{"episode_reward": 496.96748585564484, "episode": 64.0, "batch_reward": 0.40704251393675805, "critic_loss": 0.7911227870285511, "actor_loss": -42.30753475189209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.693271160125732, "step": 64000}
{"episode_reward": 483.20508386148714, "episode": 65.0, "batch_reward": 0.40824852952361107, "critic_loss": 0.7605601962506771, "actor_loss": -42.41448254394531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.28286600112915, "step": 65000}
{"episode_reward": 458.0961609055944, "episode": 66.0, "batch_reward": 0.4087617816925049, "critic_loss": 0.7823613643944264, "actor_loss": -42.461545845031736, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.46726655960083, "step": 66000}
{"episode_reward": 526.3066443028673, "episode": 67.0, "batch_reward": 0.4109003944396973, "critic_loss": 0.792015023946762, "actor_loss": -42.96496413421631, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.712825536727905, "step": 67000}
{"episode_reward": 495.397950246658, "episode": 68.0, "batch_reward": 0.4113781797885895, "critic_loss": 0.787314780831337, "actor_loss": -43.38366845703125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.000919818878174, "step": 68000}
{"episode_reward": 483.1369524289276, "episode": 69.0, "batch_reward": 0.4123055422902107, "critic_loss": 0.7721137197315693, "actor_loss": -42.70016470336914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.857020378112793, "step": 69000}
{"episode_reward": 575.7787027132844, "episode": 70.0, "batch_reward": 0.41593666476011276, "critic_loss": 0.8130108433663845, "actor_loss": -43.01489744567871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.324352979660034, "step": 70000}
{"episode_reward": 567.198630672187, "episode": 71.0, "batch_reward": 0.41757661959528924, "critic_loss": 0.8326292192339897, "actor_loss": -43.040367347717286, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 58.7196888923645, "step": 71000}
{"episode_reward": 560.1182378095647, "episode": 72.0, "batch_reward": 0.4187884361445904, "critic_loss": 0.8415314104855061, "actor_loss": -43.37554405212402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.66092586517334, "step": 72000}
{"episode_reward": 445.8666399314781, "episode": 73.0, "batch_reward": 0.420394289880991, "critic_loss": 0.8027126370072365, "actor_loss": -43.74638380432129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.90325164794922, "step": 73000}
{"episode_reward": 533.181099575867, "episode": 74.0, "batch_reward": 0.42180063578486443, "critic_loss": 0.8060699211359024, "actor_loss": -43.77036000823975, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.479899406433105, "step": 74000}
{"episode_reward": 552.3993509234136, "episode": 75.0, "batch_reward": 0.4222670932114124, "critic_loss": 0.8330599264502525, "actor_loss": -43.89589733886719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.555532932281494, "step": 75000}
{"episode_reward": 508.2739151482788, "episode": 76.0, "batch_reward": 0.42426260954141615, "critic_loss": 0.8114786166250706, "actor_loss": -44.02056248474121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.524622678756714, "step": 76000}
{"episode_reward": 543.2647943519175, "episode": 77.0, "batch_reward": 0.42609291777014735, "critic_loss": 0.8128093594014645, "actor_loss": -44.35620233917236, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.620484352111816, "step": 77000}
{"episode_reward": 581.7080050041423, "episode": 78.0, "batch_reward": 0.42837471470236776, "critic_loss": 0.8254734353423119, "actor_loss": -44.477470161437985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.14068913459778, "step": 78000}
{"episode_reward": 596.1612210531573, "episode": 79.0, "batch_reward": 0.43036696130037305, "critic_loss": 0.8588692570626736, "actor_loss": -44.8782650604248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.989937782287598, "step": 79000}
{"episode_reward": 545.5103135094574, "episode": 80.0, "batch_reward": 0.4311211251318455, "critic_loss": 0.8107768557965755, "actor_loss": -45.11184467315674, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.79411292076111, "step": 80000}
{"episode_reward": 577.0872637296904, "episode": 81.0, "batch_reward": 0.43450815173983576, "critic_loss": 0.8316215383410454, "actor_loss": -45.22178909301758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 59.081634283065796, "step": 81000}
{"episode_reward": 508.28927196316573, "episode": 82.0, "batch_reward": 0.434365607380867, "critic_loss": 0.7529923922717571, "actor_loss": -44.92610576629639, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.89770245552063, "step": 82000}
{"episode_reward": 564.4095923713264, "episode": 83.0, "batch_reward": 0.43666005444526673, "critic_loss": 0.797757324963808, "actor_loss": -45.49489329528809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.2609920501709, "step": 83000}
{"episode_reward": 540.6129439973132, "episode": 84.0, "batch_reward": 0.437390176653862, "critic_loss": 0.7897726042270661, "actor_loss": -45.765611991882324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.646495580673218, "step": 84000}
{"episode_reward": 544.3159628701243, "episode": 85.0, "batch_reward": 0.43822787538170815, "critic_loss": 0.7943424995541573, "actor_loss": -45.60229013061524, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.366432189941406, "step": 85000}
{"episode_reward": 546.8481908431093, "episode": 86.0, "batch_reward": 0.43991218253970144, "critic_loss": 0.7628211974203587, "actor_loss": -45.67155550384521, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.879719734191895, "step": 86000}
{"episode_reward": 555.8746878237682, "episode": 87.0, "batch_reward": 0.4408106437623501, "critic_loss": 0.7708907356560231, "actor_loss": -46.27420726776123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.11137080192566, "step": 87000}
{"episode_reward": 588.5747168865912, "episode": 88.0, "batch_reward": 0.4425025081038475, "critic_loss": 0.7919202724099159, "actor_loss": -45.85238948822021, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.368030548095703, "step": 88000}
{"episode_reward": 549.8124753977258, "episode": 89.0, "batch_reward": 0.4442046625614166, "critic_loss": 0.7748575175702572, "actor_loss": -45.89549298095703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.089917421340942, "step": 89000}
{"episode_reward": 523.7785374706963, "episode": 90.0, "batch_reward": 0.44571304848790166, "critic_loss": 0.7878148795068264, "actor_loss": -46.14888157653809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.668134927749634, "step": 90000}
{"episode_reward": 566.8027968465983, "episode": 91.0, "batch_reward": 0.44695578202605246, "critic_loss": 0.7388179098665715, "actor_loss": -46.32455519104004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 58.61476683616638, "step": 91000}
{"episode_reward": 559.0933690164961, "episode": 92.0, "batch_reward": 0.44742930194735525, "critic_loss": 0.7863726199865341, "actor_loss": -46.68428381347656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.2744038105011, "step": 92000}
{"episode_reward": 547.9656794058304, "episode": 93.0, "batch_reward": 0.4488416275978088, "critic_loss": 0.7757408986985683, "actor_loss": -46.54597526550293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.461875677108765, "step": 93000}
{"episode_reward": 554.0520415331127, "episode": 94.0, "batch_reward": 0.4490995413661003, "critic_loss": 0.8008854543864727, "actor_loss": -46.947836486816406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.3699848651886, "step": 94000}
{"episode_reward": 269.3043752038181, "episode": 95.0, "batch_reward": 0.4471923000216484, "critic_loss": 0.8082023333907128, "actor_loss": -47.028123497009275, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.626188278198242, "step": 95000}
{"episode_reward": 520.9665786749073, "episode": 96.0, "batch_reward": 0.44911159896850583, "critic_loss": 0.8036081850528717, "actor_loss": -46.81196807861328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.971471309661865, "step": 96000}
{"episode_reward": 542.6848209009996, "episode": 97.0, "batch_reward": 0.44935888263583185, "critic_loss": 0.7639924343526363, "actor_loss": -46.7068645401001, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.122272491455078, "step": 97000}
{"episode_reward": 598.1536311144645, "episode": 98.0, "batch_reward": 0.4507220025956631, "critic_loss": 0.7927355008721352, "actor_loss": -47.43704582214355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.417388200759888, "step": 98000}
{"episode_reward": 540.6111591989791, "episode": 99.0, "batch_reward": 0.45182805639505386, "critic_loss": 0.789894831508398, "actor_loss": -47.13262729644775, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.668421983718872, "step": 99000}
{"episode_reward": 528.0903981937456, "episode": 100.0, "batch_reward": 0.4531807675361633, "critic_loss": 0.7602110377550125, "actor_loss": -47.27287316131592, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.549588680267334, "step": 100000}
{"episode_reward": 544.6891614628438, "episode": 101.0, "batch_reward": 0.4529073744416237, "critic_loss": 0.7317859462201596, "actor_loss": -47.21160511779785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 58.723713397979736, "step": 101000}
{"episode_reward": 560.7095502256955, "episode": 102.0, "batch_reward": 0.45491388234496116, "critic_loss": 0.7442161189317703, "actor_loss": -47.60397383117676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.010374069213867, "step": 102000}
{"episode_reward": 494.6270394356027, "episode": 103.0, "batch_reward": 0.45487849190831187, "critic_loss": 0.7503138163685799, "actor_loss": -47.674843147277834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.924567222595215, "step": 103000}
{"episode_reward": 515.988091819969, "episode": 104.0, "batch_reward": 0.45577761310338977, "critic_loss": 0.7531768819391728, "actor_loss": -47.37972387695312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.856914043426514, "step": 104000}
{"episode_reward": 545.7650455589485, "episode": 105.0, "batch_reward": 0.45686518052220343, "critic_loss": 0.7307447983622551, "actor_loss": -47.54532699584961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.808136224746704, "step": 105000}
{"episode_reward": 502.54838693327395, "episode": 106.0, "batch_reward": 0.4565558825135231, "critic_loss": 0.7238249806165695, "actor_loss": -47.63861908721924, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.495856046676636, "step": 106000}
{"episode_reward": 568.5363505763517, "episode": 107.0, "batch_reward": 0.4573919136822224, "critic_loss": 0.6609315848648548, "actor_loss": -47.58732221221924, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.415019035339355, "step": 107000}
{"episode_reward": 545.9039850454236, "episode": 108.0, "batch_reward": 0.4585247083008289, "critic_loss": 0.7113151322305202, "actor_loss": -48.30462400817871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.223296642303467, "step": 108000}
{"episode_reward": 530.6773272018763, "episode": 109.0, "batch_reward": 0.45989113023877143, "critic_loss": 0.7175044754743576, "actor_loss": -48.02467889404297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.506305694580078, "step": 109000}
{"episode_reward": 549.0443528509659, "episode": 110.0, "batch_reward": 0.46010561591386795, "critic_loss": 0.7223241753578186, "actor_loss": -48.49369387054443, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.647218704223633, "step": 110000}
{"episode_reward": 556.7617425978424, "episode": 111.0, "batch_reward": 0.46127552759647367, "critic_loss": 0.7149467644393444, "actor_loss": -48.07130725097656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 58.51907253265381, "step": 111000}
{"episode_reward": 556.2176024008096, "episode": 112.0, "batch_reward": 0.46187713557481763, "critic_loss": 0.7108244539201259, "actor_loss": -48.49085034179687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.77094554901123, "step": 112000}
{"episode_reward": 574.671210195878, "episode": 113.0, "batch_reward": 0.4632717832326889, "critic_loss": 0.677212276339531, "actor_loss": -48.32909046173096, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.63540816307068, "step": 113000}
{"episode_reward": 595.4838084426291, "episode": 114.0, "batch_reward": 0.4640398896932602, "critic_loss": 0.7122907681167125, "actor_loss": -48.620661766052244, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.207640171051025, "step": 114000}
{"episode_reward": 550.1194930756787, "episode": 115.0, "batch_reward": 0.46559269580245016, "critic_loss": 0.7004664510190487, "actor_loss": -48.72460800933838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.103989362716675, "step": 115000}
{"episode_reward": 555.500884158689, "episode": 116.0, "batch_reward": 0.4657894951403141, "critic_loss": 0.7054144667387009, "actor_loss": -48.759705406188964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.736313819885254, "step": 116000}
{"episode_reward": 575.3111331783485, "episode": 117.0, "batch_reward": 0.4676294177174568, "critic_loss": 0.7103114619851112, "actor_loss": -48.76642222595215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.12613344192505, "step": 117000}
{"episode_reward": 566.3317910953459, "episode": 118.0, "batch_reward": 0.4671036697924137, "critic_loss": 0.7019818908572197, "actor_loss": -48.853117660522464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.725261211395264, "step": 118000}
{"episode_reward": 556.5531739236864, "episode": 119.0, "batch_reward": 0.46859391796588895, "critic_loss": 0.6883980219364166, "actor_loss": -48.94868402099609, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.842545747756958, "step": 119000}
{"episode_reward": 557.8305582193292, "episode": 120.0, "batch_reward": 0.46890907660126685, "critic_loss": 0.7119524812698365, "actor_loss": -49.000721572875975, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.589130640029907, "step": 120000}
{"episode_reward": 583.483253579286, "episode": 121.0, "batch_reward": 0.46981750416755674, "critic_loss": 0.7024611066579819, "actor_loss": -49.15354624176025, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 59.259477853775024, "step": 121000}
{"episode_reward": 561.7826827779166, "episode": 122.0, "batch_reward": 0.4706268065869808, "critic_loss": 0.7378102768063545, "actor_loss": -49.304846237182616, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.80842685699463, "step": 122000}
{"episode_reward": 578.8642718710616, "episode": 123.0, "batch_reward": 0.47155131927132604, "critic_loss": 0.7657449525594712, "actor_loss": -49.41996096038818, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.698078870773315, "step": 123000}
{"episode_reward": 566.9415931229851, "episode": 124.0, "batch_reward": 0.4719794036746025, "critic_loss": 0.6969373636245727, "actor_loss": -49.60071688079834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.234405517578125, "step": 124000}
{"episode_reward": 519.5561119901702, "episode": 125.0, "batch_reward": 0.4722456295490265, "critic_loss": 0.7614743510484695, "actor_loss": -49.46386667633057, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.439162254333496, "step": 125000}
{"episode_reward": 539.8301665586272, "episode": 126.0, "batch_reward": 0.473029683470726, "critic_loss": 0.766067973613739, "actor_loss": -49.64196874237061, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.815874338150024, "step": 126000}
{"episode_reward": 526.0637958943693, "episode": 127.0, "batch_reward": 0.47372721910476684, "critic_loss": 0.7175687254071236, "actor_loss": -49.7008790435791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.737239360809326, "step": 127000}
{"episode_reward": 582.204676569422, "episode": 128.0, "batch_reward": 0.47443553814291956, "critic_loss": 0.7418276299834251, "actor_loss": -49.70691720581055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.251529455184937, "step": 128000}
{"episode_reward": 550.5975060875028, "episode": 129.0, "batch_reward": 0.4750768032073975, "critic_loss": 0.7138544403612613, "actor_loss": -49.632874984741214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.767017126083374, "step": 129000}
{"episode_reward": 524.1215348757077, "episode": 130.0, "batch_reward": 0.475658989071846, "critic_loss": 0.7206941031813622, "actor_loss": -49.83512052154541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.52787446975708, "step": 130000}
{"episode_reward": 538.5334574009522, "episode": 131.0, "batch_reward": 0.4766397781968117, "critic_loss": 0.6893559632897377, "actor_loss": -49.59328675079346, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 59.06184697151184, "step": 131000}
{"episode_reward": 552.0521698558698, "episode": 132.0, "batch_reward": 0.4767349365949631, "critic_loss": 0.7273514263629913, "actor_loss": -49.89025405883789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.290071725845337, "step": 132000}
{"episode_reward": 542.9700723217928, "episode": 133.0, "batch_reward": 0.4777348019778728, "critic_loss": 0.6966540486812591, "actor_loss": -49.88382006835938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.771570920944214, "step": 133000}
{"episode_reward": 552.1386325605556, "episode": 134.0, "batch_reward": 0.4774316921234131, "critic_loss": 0.7297839395999909, "actor_loss": -49.911912063598635, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.60754370689392, "step": 134000}
{"episode_reward": 566.0287063304758, "episode": 135.0, "batch_reward": 0.4780890737771988, "critic_loss": 0.713225198239088, "actor_loss": -50.12918187713623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.81783390045166, "step": 135000}
{"episode_reward": 539.5284327591341, "episode": 136.0, "batch_reward": 0.4789882743954659, "critic_loss": 0.7305913891196251, "actor_loss": -50.19759927368164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.496716737747192, "step": 136000}
{"episode_reward": 578.9447040091342, "episode": 137.0, "batch_reward": 0.48020747977495193, "critic_loss": 0.7133163220584392, "actor_loss": -50.24690070343018, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.583418607711792, "step": 137000}
{"episode_reward": 582.1413110180808, "episode": 138.0, "batch_reward": 0.48011941266059877, "critic_loss": 0.7314288020730019, "actor_loss": -50.280328521728514, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.932093381881714, "step": 138000}
{"episode_reward": 563.1336672566817, "episode": 139.0, "batch_reward": 0.4810358301401138, "critic_loss": 0.7419796171784401, "actor_loss": -50.312264572143555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.424999475479126, "step": 139000}
{"episode_reward": 538.4158491299619, "episode": 140.0, "batch_reward": 0.48079309695959094, "critic_loss": 0.7380963735282421, "actor_loss": -50.469305084228516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.907572269439697, "step": 140000}
{"episode_reward": 543.6480271673029, "episode": 141.0, "batch_reward": 0.48299310192465783, "critic_loss": 0.7614635355770588, "actor_loss": -50.46467148590088, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 58.81288719177246, "step": 141000}
{"episode_reward": 561.7300217681603, "episode": 142.0, "batch_reward": 0.4825165821015835, "critic_loss": 0.7826524579823018, "actor_loss": -50.48427803039551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.78944683074951, "step": 142000}
{"episode_reward": 514.7479537092355, "episode": 143.0, "batch_reward": 0.4823694105446339, "critic_loss": 0.7522007432579995, "actor_loss": -50.45605583953857, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.4318528175354, "step": 143000}
{"episode_reward": 534.8203133679095, "episode": 144.0, "batch_reward": 0.4832950910925865, "critic_loss": 0.803077961474657, "actor_loss": -50.6956442565918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.729159355163574, "step": 144000}
{"episode_reward": 578.9798913283154, "episode": 145.0, "batch_reward": 0.48325888857245447, "critic_loss": 0.765988695859909, "actor_loss": -50.76059519195557, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.559743642807007, "step": 145000}
{"episode_reward": 540.3322079961895, "episode": 146.0, "batch_reward": 0.48336335182189943, "critic_loss": 0.7570573411583901, "actor_loss": -50.51034141540527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.358204126358032, "step": 146000}
{"episode_reward": 543.2760357574846, "episode": 147.0, "batch_reward": 0.4838191642463207, "critic_loss": 0.7554416506588459, "actor_loss": -50.73810699462891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.836940050125122, "step": 147000}
{"episode_reward": 543.9840618812696, "episode": 148.0, "batch_reward": 0.48521500796079636, "critic_loss": 0.7518946859240532, "actor_loss": -50.88481143951416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.706139087677002, "step": 148000}
{"episode_reward": 506.98171813322324, "episode": 149.0, "batch_reward": 0.48505789175629616, "critic_loss": 0.7587129099965095, "actor_loss": -50.89316056060791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.551413536071777, "step": 149000}
{"episode_reward": 561.7227793272093, "episode": 150.0, "batch_reward": 0.48522869098186494, "critic_loss": 0.7815927795767784, "actor_loss": -50.84475594329834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
