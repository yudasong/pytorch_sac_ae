{"episode_reward": 0.0, "episode": 1.0, "duration": 21.388490438461304, "step": 1000}
{"episode_reward": 28.177075776326152, "episode": 2.0, "duration": 1.835256576538086, "step": 2000}
{"episode_reward": 69.84046218736019, "episode": 3.0, "batch_reward": 0.04956528223819954, "critic_loss": 0.15771892612906208, "actor_loss": -77.06833108914952, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499180007, "duration": 62.287240743637085, "step": 3000}
{"episode_reward": 55.453857256473555, "episode": 4.0, "batch_reward": 0.05290170464664698, "critic_loss": 0.13482298658415676, "actor_loss": -72.68023448181152, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.713496685028076, "step": 4000}
{"episode_reward": 39.60439806301276, "episode": 5.0, "batch_reward": 0.04595053695142269, "critic_loss": 0.13308270778134465, "actor_loss": -69.09702226257325, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.498611211776733, "step": 5000}
{"episode_reward": 19.163718472218054, "episode": 6.0, "batch_reward": 0.04302346691675484, "critic_loss": 0.11426780803874136, "actor_loss": -68.03340496063232, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.328517198562622, "step": 6000}
{"episode_reward": 54.84384531557612, "episode": 7.0, "batch_reward": 0.050834658440202476, "critic_loss": 0.16032266714423896, "actor_loss": -68.01500648498535, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.279673099517822, "step": 7000}
{"episode_reward": 160.76379239468326, "episode": 8.0, "batch_reward": 0.061610755294561385, "critic_loss": 0.15220218231528998, "actor_loss": -67.05278686523438, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.45991086959839, "step": 8000}
{"episode_reward": 62.02277927116473, "episode": 9.0, "batch_reward": 0.07407867610454559, "critic_loss": 0.1419652270451188, "actor_loss": -66.30983294677735, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.173275232315063, "step": 9000}
{"episode_reward": 297.1944071792394, "episode": 10.0, "batch_reward": 0.08316042539104819, "critic_loss": 0.12662042570114135, "actor_loss": -64.51815940093994, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.308603763580322, "step": 10000}
{"episode_reward": 15.633750136618394, "episode": 11.0, "batch_reward": 0.0772942715883255, "critic_loss": 0.10370977977290749, "actor_loss": -63.72106968688965, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.83510875701904, "step": 11000}
{"episode_reward": 16.616012044606364, "episode": 12.0, "batch_reward": 0.08728920291364194, "critic_loss": 0.12036759724095464, "actor_loss": -61.85805419921875, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.558186531066895, "step": 12000}
{"episode_reward": 396.9419313573771, "episode": 13.0, "batch_reward": 0.10224211836233735, "critic_loss": 0.12143722188472748, "actor_loss": -61.107338943481444, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.455207109451294, "step": 13000}
{"episode_reward": 98.78634180907964, "episode": 14.0, "batch_reward": 0.09901287346333265, "critic_loss": 0.10749862784892321, "actor_loss": -59.373570014953614, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.636555433273315, "step": 14000}
{"episode_reward": 57.12391180358052, "episode": 15.0, "batch_reward": 0.1059397715702653, "critic_loss": 0.12386593575030565, "actor_loss": -61.27477944946289, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.63358211517334, "step": 15000}
{"episode_reward": 374.57706186414805, "episode": 16.0, "batch_reward": 0.12205698900669813, "critic_loss": 0.14521542331203818, "actor_loss": -60.85005842590332, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.27258825302124, "step": 16000}
{"episode_reward": 286.39684966177117, "episode": 17.0, "batch_reward": 0.1313459584414959, "critic_loss": 0.160783802844584, "actor_loss": -58.97038565063477, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.631996631622314, "step": 17000}
{"episode_reward": 200.6341594484653, "episode": 18.0, "batch_reward": 0.13216635647416114, "critic_loss": 0.18033271628618242, "actor_loss": -57.738458236694335, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.12834358215332, "step": 18000}
{"episode_reward": 107.32686787535744, "episode": 19.0, "batch_reward": 0.13637785006314515, "critic_loss": 0.2178766144812107, "actor_loss": -58.27455073547363, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.26836633682251, "step": 19000}
{"episode_reward": 336.10790646234517, "episode": 20.0, "batch_reward": 0.13933028706908226, "critic_loss": 0.22615763287991286, "actor_loss": -58.48784200286865, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.808508157730103, "step": 20000}
{"episode_reward": 81.36589876114932, "episode": 21.0, "batch_reward": 0.14152831143885852, "critic_loss": 0.2492934944406152, "actor_loss": -58.84782158660889, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.02724885940552, "step": 21000}
{"episode_reward": 308.48823715282595, "episode": 22.0, "batch_reward": 0.14727233792841435, "critic_loss": 0.28540595909953115, "actor_loss": -57.136992729187014, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.45087766647339, "step": 22000}
{"episode_reward": 191.24811058147412, "episode": 23.0, "batch_reward": 0.1537651117965579, "critic_loss": 0.3197250844836235, "actor_loss": -56.35477448272705, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.668855905532837, "step": 23000}
{"episode_reward": 339.51472364481583, "episode": 24.0, "batch_reward": 0.16241805701702833, "critic_loss": 0.3393578956276178, "actor_loss": -57.80781065368652, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.21085238456726, "step": 24000}
{"episode_reward": 446.9186388404895, "episode": 25.0, "batch_reward": 0.16583733795583247, "critic_loss": 0.3383766717463732, "actor_loss": -55.565546829223635, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.28243374824524, "step": 25000}
{"episode_reward": 15.229961555398225, "episode": 26.0, "batch_reward": 0.16037566302716733, "critic_loss": 0.31942830331623556, "actor_loss": -54.64104926300049, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.071080446243286, "step": 26000}
{"episode_reward": 63.01641108112171, "episode": 27.0, "batch_reward": 0.16073315885663034, "critic_loss": 0.36970919160544874, "actor_loss": -54.22690509796143, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.53309392929077, "step": 27000}
{"episode_reward": 219.9664484866203, "episode": 28.0, "batch_reward": 0.16046933292597532, "critic_loss": 0.5739741135537625, "actor_loss": -53.87606655883789, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.302725315093994, "step": 28000}
{"episode_reward": 75.76301165617873, "episode": 29.0, "batch_reward": 0.15983299723267555, "critic_loss": 1.1469380365610122, "actor_loss": -57.42047890472412, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.54255509376526, "step": 29000}
{"episode_reward": 162.8484582935651, "episode": 30.0, "batch_reward": 0.1600502781420946, "critic_loss": 0.9251352201402188, "actor_loss": -58.223519355773924, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.758209228515625, "step": 30000}
{"episode_reward": 253.2237391941532, "episode": 31.0, "batch_reward": 0.1586031483411789, "critic_loss": 0.7670816142857074, "actor_loss": -59.48588910675049, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.337515354156494, "step": 31000}
{"episode_reward": 14.574828544062047, "episode": 32.0, "batch_reward": 0.16094266141206026, "critic_loss": 0.7184999295771122, "actor_loss": -59.517594078063965, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.095532178878784, "step": 32000}
{"episode_reward": 422.68903932836906, "episode": 33.0, "batch_reward": 0.17096880182623864, "critic_loss": 0.6789581589996815, "actor_loss": -59.21790929412842, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.62313437461853, "step": 33000}
{"episode_reward": 527.3075625204275, "episode": 34.0, "batch_reward": 0.1785222206786275, "critic_loss": 0.6324836930334568, "actor_loss": -56.835432357788086, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.661790370941162, "step": 34000}
{"episode_reward": 277.1367904627761, "episode": 35.0, "batch_reward": 0.18327410408854486, "critic_loss": 0.593397620856762, "actor_loss": -59.08730797576904, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.426790475845337, "step": 35000}
{"episode_reward": 279.67464562150855, "episode": 36.0, "batch_reward": 0.1787718521207571, "critic_loss": 0.5612892586588859, "actor_loss": -57.323825004577635, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.707017421722412, "step": 36000}
{"episode_reward": 15.25836828009026, "episode": 37.0, "batch_reward": 0.174528450332582, "critic_loss": 0.5218847366273404, "actor_loss": -56.94334964752197, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.858803510665894, "step": 37000}
{"episode_reward": 15.702071433607586, "episode": 38.0, "batch_reward": 0.16976266033947468, "critic_loss": 0.5154571000039577, "actor_loss": -57.9821833114624, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.28316307067871, "step": 38000}
{"episode_reward": 16.477543619692145, "episode": 39.0, "batch_reward": 0.17103458756953477, "critic_loss": 0.5465044042468071, "actor_loss": -59.1530685043335, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.400792837142944, "step": 39000}
{"episode_reward": 212.4560843998294, "episode": 40.0, "batch_reward": 0.172799580745399, "critic_loss": 0.5443496694266796, "actor_loss": -58.55124262237549, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.284106016159058, "step": 40000}
{"episode_reward": 530.3801127625836, "episode": 41.0, "batch_reward": 0.18402011191099882, "critic_loss": 0.579475408911705, "actor_loss": -58.25221544647217, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.157612800598145, "step": 41000}
{"episode_reward": 568.2459012319454, "episode": 42.0, "batch_reward": 0.18603028401732444, "critic_loss": 0.5588272904455662, "actor_loss": -57.07873644256592, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.309174299240112, "step": 42000}
{"episode_reward": 15.191377640103008, "episode": 43.0, "batch_reward": 0.18783941657841205, "critic_loss": 0.573091517046094, "actor_loss": -57.226399505615234, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.737853288650513, "step": 43000}
{"episode_reward": 571.0708075475103, "episode": 44.0, "batch_reward": 0.19619949442148207, "critic_loss": 0.6329032696336507, "actor_loss": -56.84699674987793, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.502940893173218, "step": 44000}
{"episode_reward": 589.7792796214835, "episode": 45.0, "batch_reward": 0.19970609982311727, "critic_loss": 0.6352623986303806, "actor_loss": -58.18326948547363, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.699525833129883, "step": 45000}
{"episode_reward": 17.551512980459087, "episode": 46.0, "batch_reward": 0.19469078984856605, "critic_loss": 0.6434542005658149, "actor_loss": -57.658876083374025, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.470351696014404, "step": 46000}
{"episode_reward": 24.59547676566433, "episode": 47.0, "batch_reward": 0.19242658112943173, "critic_loss": 0.6386015020310879, "actor_loss": -56.6216340713501, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.39772391319275, "step": 47000}
{"episode_reward": 54.39016398665966, "episode": 48.0, "batch_reward": 0.1941211856305599, "critic_loss": 0.6615676083862781, "actor_loss": -55.78306507110596, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.895105361938477, "step": 48000}
{"episode_reward": 525.7145269083834, "episode": 49.0, "batch_reward": 0.2024424768090248, "critic_loss": 0.6977471854686738, "actor_loss": -56.63015281677246, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.75339388847351, "step": 49000}
{"episode_reward": 662.5207577364354, "episode": 50.0, "batch_reward": 0.21306030914187432, "critic_loss": 0.7619913928508758, "actor_loss": -57.118403663635256, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.582326650619507, "step": 50000}
{"episode_reward": 625.9082615778701, "episode": 51.0, "batch_reward": 0.2195684698522091, "critic_loss": 0.7872147136032581, "actor_loss": -55.46730288696289, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.21945095062256, "step": 51000}
{"episode_reward": 587.1111075121634, "episode": 52.0, "batch_reward": 0.2211780024319887, "critic_loss": 0.803283680319786, "actor_loss": -57.77823878097534, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.47485375404358, "step": 52000}
{"episode_reward": 15.717837992786867, "episode": 53.0, "batch_reward": 0.22305886705219746, "critic_loss": 0.780137946754694, "actor_loss": -56.866954372406006, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.436372756958008, "step": 53000}
{"episode_reward": 591.3939192787419, "episode": 54.0, "batch_reward": 0.2280212813615799, "critic_loss": 0.8027617702484131, "actor_loss": -57.14308473587036, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.711589097976685, "step": 54000}
{"episode_reward": 299.9354814714179, "episode": 55.0, "batch_reward": 0.22618846057355405, "critic_loss": 0.7948884139955044, "actor_loss": -55.692857425689695, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.659197092056274, "step": 55000}
{"episode_reward": 41.74029701843073, "episode": 56.0, "batch_reward": 0.2289542549997568, "critic_loss": 0.8301091855764389, "actor_loss": -57.764119930267334, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.319451570510864, "step": 56000}
{"episode_reward": 736.9689355271806, "episode": 57.0, "batch_reward": 0.2328067432940006, "critic_loss": 0.8506217764317989, "actor_loss": -58.11451332092285, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.363025665283203, "step": 57000}
{"episode_reward": 48.215213686863784, "episode": 58.0, "batch_reward": 0.230522401958704, "critic_loss": 0.7925244275331497, "actor_loss": -55.62034358978271, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.710253477096558, "step": 58000}
{"episode_reward": 64.47564378504865, "episode": 59.0, "batch_reward": 0.22635001215338707, "critic_loss": 0.7991061117053032, "actor_loss": -56.29734447860718, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.072997093200684, "step": 59000}
{"episode_reward": 63.07769967599827, "episode": 60.0, "batch_reward": 0.22738394206762313, "critic_loss": 0.7807698798775673, "actor_loss": -59.51075019073486, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.23955273628235, "step": 60000}
{"episode_reward": 554.2756932760348, "episode": 61.0, "batch_reward": 0.22930171301960944, "critic_loss": 0.7822002600431442, "actor_loss": -56.236151012420656, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.94334316253662, "step": 61000}
{"episode_reward": 18.681119868064947, "episode": 62.0, "batch_reward": 0.22477229130268098, "critic_loss": 0.784041785299778, "actor_loss": -55.52530638504028, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.4343683719635, "step": 62000}
{"episode_reward": 64.29724288769053, "episode": 63.0, "batch_reward": 0.22179821749031545, "critic_loss": 0.7980382161736488, "actor_loss": -57.13965001678467, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.28285503387451, "step": 63000}
{"episode_reward": 72.25975222119126, "episode": 64.0, "batch_reward": 0.22643336847424508, "critic_loss": 0.8349247686862945, "actor_loss": -56.534322856903074, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.433368682861328, "step": 64000}
{"episode_reward": 812.0205819988903, "episode": 65.0, "batch_reward": 0.23115049621462821, "critic_loss": 0.8283241069614887, "actor_loss": -57.12120788574219, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.211955308914185, "step": 65000}
{"episode_reward": 98.84096692357207, "episode": 66.0, "batch_reward": 0.23208058522641659, "critic_loss": 0.8796719837784767, "actor_loss": -57.38733604049683, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.262054204940796, "step": 66000}
{"episode_reward": 739.5390397572173, "episode": 67.0, "batch_reward": 0.23920417413115502, "critic_loss": 0.9001144003868103, "actor_loss": -59.247553504943845, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.098025798797607, "step": 67000}
{"episode_reward": 694.0965578887989, "episode": 68.0, "batch_reward": 0.24195178401470185, "critic_loss": 0.915594087600708, "actor_loss": -55.68977187347412, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.526723384857178, "step": 68000}
{"episode_reward": 60.39356918615409, "episode": 69.0, "batch_reward": 0.24545353335142137, "critic_loss": 0.9181079016625882, "actor_loss": -57.76274395751953, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.27179980278015, "step": 69000}
{"episode_reward": 879.2007674254407, "episode": 70.0, "batch_reward": 0.2542031321376562, "critic_loss": 0.9269373306632042, "actor_loss": -58.47125782394409, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.761582136154175, "step": 70000}
{"episode_reward": 789.2994851053131, "episode": 71.0, "batch_reward": 0.2568247001618147, "critic_loss": 0.947858701378107, "actor_loss": -56.4530916557312, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.68480849266052, "step": 71000}
{"episode_reward": 72.41973606239195, "episode": 72.0, "batch_reward": 0.25448570722341535, "critic_loss": 0.9229762156605721, "actor_loss": -57.1277854385376, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.322739601135254, "step": 72000}
{"episode_reward": 73.96999628026661, "episode": 73.0, "batch_reward": 0.25456988348066806, "critic_loss": 0.8807372234761714, "actor_loss": -57.21067585754395, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.447150707244873, "step": 73000}
{"episode_reward": 473.49610233646996, "episode": 74.0, "batch_reward": 0.25919349563121796, "critic_loss": 0.8961926335394382, "actor_loss": -58.51161450958252, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.246477603912354, "step": 74000}
{"episode_reward": 801.5763504375445, "episode": 75.0, "batch_reward": 0.26287545454502104, "critic_loss": 0.8944615682065487, "actor_loss": -58.22454195022583, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.292879819869995, "step": 75000}
{"episode_reward": 62.448205797169976, "episode": 76.0, "batch_reward": 0.26168332958221435, "critic_loss": 0.8702310127913951, "actor_loss": -57.82285470962525, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.949594974517822, "step": 76000}
{"episode_reward": 645.2369281202152, "episode": 77.0, "batch_reward": 0.263440942928195, "critic_loss": 0.8915566012859345, "actor_loss": -57.993990234375, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.609044313430786, "step": 77000}
{"episode_reward": 67.02649076287463, "episode": 78.0, "batch_reward": 0.26653610344231127, "critic_loss": 0.8679948530197144, "actor_loss": -59.27721273040771, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.57032561302185, "step": 78000}
{"episode_reward": 794.9265749950471, "episode": 79.0, "batch_reward": 0.26939082442224027, "critic_loss": 0.872860054641962, "actor_loss": -56.81851906967163, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.32991647720337, "step": 79000}
{"episode_reward": 84.26888805577434, "episode": 80.0, "batch_reward": 0.2653367237448692, "critic_loss": 0.8482776567935943, "actor_loss": -57.048784648895264, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.41647171974182, "step": 80000}
{"episode_reward": 65.8145224428483, "episode": 81.0, "batch_reward": 0.2678384961485863, "critic_loss": 0.8495143566727639, "actor_loss": -58.16344426727295, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.6032612323761, "step": 81000}
{"episode_reward": 835.3249978562136, "episode": 82.0, "batch_reward": 0.2706600399464369, "critic_loss": 0.8076651971638202, "actor_loss": -60.01985453033447, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.667847394943237, "step": 82000}
{"episode_reward": 51.248576313057434, "episode": 83.0, "batch_reward": 0.2727549111247063, "critic_loss": 0.8565488833189011, "actor_loss": -58.55574132537842, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.633337259292603, "step": 83000}
{"episode_reward": 811.1113046881676, "episode": 84.0, "batch_reward": 0.2772243544757366, "critic_loss": 0.882299899071455, "actor_loss": -58.79169424057007, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.76609992980957, "step": 84000}
{"episode_reward": 752.9940582540085, "episode": 85.0, "batch_reward": 0.2777339693009853, "critic_loss": 0.8938391567468643, "actor_loss": -59.659195266723636, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.259158849716187, "step": 85000}
{"episode_reward": 16.2570021786347, "episode": 86.0, "batch_reward": 0.27728786209225653, "critic_loss": 0.9563701852560044, "actor_loss": -58.06636293411255, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.0821213722229, "step": 86000}
{"episode_reward": 71.82707197373493, "episode": 87.0, "batch_reward": 0.27749268229305746, "critic_loss": 0.909598935753107, "actor_loss": -58.305513942718505, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.352107763290405, "step": 87000}
{"episode_reward": 722.5112532855885, "episode": 88.0, "batch_reward": 0.28252775529026986, "critic_loss": 0.9476742849647999, "actor_loss": -57.15864907836914, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.305129766464233, "step": 88000}
{"episode_reward": 783.6062073509016, "episode": 89.0, "batch_reward": 0.2891218853443861, "critic_loss": 1.0099967826604843, "actor_loss": -58.49126231002808, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.78365683555603, "step": 89000}
{"episode_reward": 794.4354822672825, "episode": 90.0, "batch_reward": 0.29037190940976143, "critic_loss": 0.995480027616024, "actor_loss": -59.80479008483887, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.522289514541626, "step": 90000}
{"episode_reward": 69.2628163303786, "episode": 91.0, "batch_reward": 0.2926402710676193, "critic_loss": 1.0472499976158143, "actor_loss": -58.91315841293335, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.22024750709534, "step": 91000}
{"episode_reward": 639.0620176978935, "episode": 92.0, "batch_reward": 0.292293969348073, "critic_loss": 1.063088558703661, "actor_loss": -58.5573839225769, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.385395765304565, "step": 92000}
{"episode_reward": 72.50169975403662, "episode": 93.0, "batch_reward": 0.29178423538804055, "critic_loss": 1.0190251576006413, "actor_loss": -58.42314058303833, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.368910312652588, "step": 93000}
{"episode_reward": 862.2819043222418, "episode": 94.0, "batch_reward": 0.29958572481572626, "critic_loss": 1.0635469252169132, "actor_loss": -58.12643685150147, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.323845624923706, "step": 94000}
{"episode_reward": 873.252035298431, "episode": 95.0, "batch_reward": 0.30174235098063945, "critic_loss": 1.0495994591712952, "actor_loss": -60.53119408416748, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.75653386116028, "step": 95000}
{"episode_reward": 66.88643821576774, "episode": 96.0, "batch_reward": 0.29954501773416997, "critic_loss": 1.0067853304743766, "actor_loss": -59.31047124862671, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.59217929840088, "step": 96000}
{"episode_reward": 76.33609304069775, "episode": 97.0, "batch_reward": 0.29985963310301306, "critic_loss": 0.9813182833492756, "actor_loss": -59.82840557479859, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.80676817893982, "step": 97000}
{"episode_reward": 818.6101860130078, "episode": 98.0, "batch_reward": 0.30642769640684125, "critic_loss": 0.9846843311190605, "actor_loss": -59.52346851348877, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.244536876678467, "step": 98000}
{"episode_reward": 801.5348065199674, "episode": 99.0, "batch_reward": 0.3101916972845793, "critic_loss": 0.9977395710349083, "actor_loss": -59.746455303192135, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.35261559486389, "step": 99000}
{"episode_reward": 861.5855200379327, "episode": 100.0, "batch_reward": 0.3170731276422739, "critic_loss": 1.036082714319229, "actor_loss": -59.2921646118164, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.329395532608032, "step": 100000}
{"episode_reward": 832.834515840245, "episode": 101.0, "batch_reward": 0.322252505466342, "critic_loss": 1.0036446102261543, "actor_loss": -61.19836722183228, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.754740953445435, "step": 101000}
{"episode_reward": 875.642099594657, "episode": 102.0, "batch_reward": 0.32796497324109075, "critic_loss": 1.0155268702507019, "actor_loss": -60.83121868133545, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.427229404449463, "step": 102000}
{"episode_reward": 922.2861544115606, "episode": 103.0, "batch_reward": 0.32988272435963156, "critic_loss": 1.02460591045022, "actor_loss": -61.065648498535154, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.291139125823975, "step": 103000}
{"episode_reward": 64.8215845038573, "episode": 104.0, "batch_reward": 0.3277236636579037, "critic_loss": 1.00112369915843, "actor_loss": -60.57400423431397, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.488211154937744, "step": 104000}
{"episode_reward": 63.300219475444045, "episode": 105.0, "batch_reward": 0.32919430136680605, "critic_loss": 0.98387069272995, "actor_loss": -60.87831808853149, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.6086266040802, "step": 105000}
{"episode_reward": 837.6142029444065, "episode": 106.0, "batch_reward": 0.33255858044326303, "critic_loss": 1.003356965750456, "actor_loss": -60.00300291824341, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.9885094165802, "step": 106000}
{"episode_reward": 830.6555119060283, "episode": 107.0, "batch_reward": 0.334924755141139, "critic_loss": 1.0390003697276116, "actor_loss": -61.21863735961914, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.286359071731567, "step": 107000}
{"episode_reward": 71.85711844629225, "episode": 108.0, "batch_reward": 0.3328859729766846, "critic_loss": 1.0285540764033794, "actor_loss": -61.295969497680666, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.505005598068237, "step": 108000}
{"episode_reward": 74.19716817757968, "episode": 109.0, "batch_reward": 0.33436181274056437, "critic_loss": 1.0695700292289256, "actor_loss": -61.577690872192385, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.296459436416626, "step": 109000}
{"episode_reward": 834.1788081198812, "episode": 110.0, "batch_reward": 0.33792943075299264, "critic_loss": 1.0771141704022884, "actor_loss": -62.59933055114746, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.25791621208191, "step": 110000}
{"episode_reward": 851.0311006997762, "episode": 111.0, "batch_reward": 0.34307757434248926, "critic_loss": 1.2559423629641533, "actor_loss": -63.53911661529541, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.05454707145691, "step": 111000}
{"episode_reward": 887.4655260912685, "episode": 112.0, "batch_reward": 0.34740540581941604, "critic_loss": 1.315964835524559, "actor_loss": -63.37086483764649, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.406025171279907, "step": 112000}
{"episode_reward": 821.9251726486242, "episode": 113.0, "batch_reward": 0.3475360618829727, "critic_loss": 1.2635531102120876, "actor_loss": -63.73372368621826, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.27519726753235, "step": 113000}
{"episode_reward": 14.09075831079615, "episode": 114.0, "batch_reward": 0.34947605995833875, "critic_loss": 1.178089625775814, "actor_loss": -66.16129267883301, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.47574019432068, "step": 114000}
{"episode_reward": 916.9903331631766, "episode": 115.0, "batch_reward": 0.35222671979665754, "critic_loss": 1.1405487632155418, "actor_loss": -65.55929608154297, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.64185118675232, "step": 115000}
{"episode_reward": 853.1253301351636, "episode": 116.0, "batch_reward": 0.3556705486178398, "critic_loss": 1.0708557992875576, "actor_loss": -66.38743327331542, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.905537128448486, "step": 116000}
{"episode_reward": 88.37561605019589, "episode": 117.0, "batch_reward": 0.3569394207894802, "critic_loss": 1.0890239208638668, "actor_loss": -65.15563330078125, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.312539100646973, "step": 117000}
{"episode_reward": 857.7469898798521, "episode": 118.0, "batch_reward": 0.36023926600813866, "critic_loss": 1.076848173558712, "actor_loss": -66.33800679779053, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.59303879737854, "step": 118000}
{"episode_reward": 922.970070680691, "episode": 119.0, "batch_reward": 0.36247309610247613, "critic_loss": 1.0657844907641412, "actor_loss": -66.42194018554687, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.784212350845337, "step": 119000}
{"episode_reward": 137.6945706395935, "episode": 120.0, "batch_reward": 0.3615070611536503, "critic_loss": 1.0620569018423558, "actor_loss": -65.22465413665772, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.29465079307556, "step": 120000}
{"episode_reward": 904.2984515348819, "episode": 121.0, "batch_reward": 0.36693025594949724, "critic_loss": 1.0761657901406287, "actor_loss": -66.13126219177246, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.647021532058716, "step": 121000}
{"episode_reward": 885.4816003927033, "episode": 122.0, "batch_reward": 0.37129155856370927, "critic_loss": 1.0772332996726035, "actor_loss": -66.9213678665161, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.27581286430359, "step": 122000}
{"episode_reward": 825.9302734676621, "episode": 123.0, "batch_reward": 0.37132366648316384, "critic_loss": 1.102426690518856, "actor_loss": -65.75078728485107, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.568397521972656, "step": 123000}
{"episode_reward": 105.74003537863796, "episode": 124.0, "batch_reward": 0.3739671037197113, "critic_loss": 1.091691138535738, "actor_loss": -67.29322313690186, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.642966270446777, "step": 124000}
{"episode_reward": 894.324133137823, "episode": 125.0, "batch_reward": 0.3774201468229294, "critic_loss": 1.0872635942697526, "actor_loss": -66.06443872833252, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.175636053085327, "step": 125000}
{"episode_reward": 921.2223111037081, "episode": 126.0, "batch_reward": 0.3825908860862255, "critic_loss": 1.0569464020729065, "actor_loss": -68.09179412841797, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.29237389564514, "step": 126000}
{"episode_reward": 888.4324237270196, "episode": 127.0, "batch_reward": 0.3870888722240925, "critic_loss": 1.0284935884773732, "actor_loss": -68.31938515472412, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.385595083236694, "step": 127000}
{"episode_reward": 887.1062359343988, "episode": 128.0, "batch_reward": 0.38534540954232216, "critic_loss": 1.015489358961582, "actor_loss": -67.9340492324829, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.206693410873413, "step": 128000}
{"episode_reward": 20.42711865294128, "episode": 129.0, "batch_reward": 0.38454422134161, "critic_loss": 0.96637049472332, "actor_loss": -68.20547384643555, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.63303804397583, "step": 129000}
{"episode_reward": 929.290579431915, "episode": 130.0, "batch_reward": 0.38946067696809766, "critic_loss": 0.9663997376263141, "actor_loss": -68.44372550964356, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.437373638153076, "step": 130000}
{"episode_reward": 896.6072051833894, "episode": 131.0, "batch_reward": 0.39587843176722526, "critic_loss": 1.000128248512745, "actor_loss": -68.7392407913208, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.72725820541382, "step": 131000}
{"episode_reward": 837.1566117928003, "episode": 132.0, "batch_reward": 0.3967404521405697, "critic_loss": 0.9368434181213379, "actor_loss": -68.04778211975098, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.281932830810547, "step": 132000}
{"episode_reward": 16.750241979612625, "episode": 133.0, "batch_reward": 0.39224469995498656, "critic_loss": 0.9171702899038792, "actor_loss": -68.20668482208252, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.946157693862915, "step": 133000}
{"episode_reward": 17.424731370158927, "episode": 134.0, "batch_reward": 0.38880618822574614, "critic_loss": 0.9533774613440037, "actor_loss": -68.74234215545654, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.956870317459106, "step": 134000}
{"episode_reward": 67.4462480559475, "episode": 135.0, "batch_reward": 0.3894692075848579, "critic_loss": 0.9472461728453636, "actor_loss": -67.8617035369873, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.371849298477173, "step": 135000}
{"episode_reward": 942.4409430734421, "episode": 136.0, "batch_reward": 0.39511346569657324, "critic_loss": 0.8913821669220925, "actor_loss": -68.72059883117676, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.242688179016113, "step": 136000}
{"episode_reward": 896.7893881213364, "episode": 137.0, "batch_reward": 0.3959682804644108, "critic_loss": 0.9078070475161075, "actor_loss": -67.55933409881592, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.588186264038086, "step": 137000}
{"episode_reward": 904.631039495112, "episode": 138.0, "batch_reward": 0.3981676551401615, "critic_loss": 0.8571173242628575, "actor_loss": -66.77517037200927, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.63095998764038, "step": 138000}
{"episode_reward": 65.96879681178828, "episode": 139.0, "batch_reward": 0.39678945764899254, "critic_loss": 0.8860178135931492, "actor_loss": -66.95935125732422, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.309425592422485, "step": 139000}
{"episode_reward": 66.027825512985, "episode": 140.0, "batch_reward": 0.3919032315015793, "critic_loss": 0.8605832059681415, "actor_loss": -66.24852415466309, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.66274642944336, "step": 140000}
{"episode_reward": 64.92102331886504, "episode": 141.0, "batch_reward": 0.3906092309355736, "critic_loss": 0.874805678665638, "actor_loss": -65.49111631011962, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.923428535461426, "step": 141000}
{"episode_reward": 64.50858416776585, "episode": 142.0, "batch_reward": 0.38951616087555885, "critic_loss": 0.8839424033463001, "actor_loss": -67.14050764465333, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.02126383781433, "step": 142000}
{"episode_reward": 911.8919175617411, "episode": 143.0, "batch_reward": 0.3923388304412365, "critic_loss": 0.915285859644413, "actor_loss": -66.28396535491943, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.53707242012024, "step": 143000}
{"episode_reward": 74.21826741412991, "episode": 144.0, "batch_reward": 0.3935697209537029, "critic_loss": 0.8994903231561184, "actor_loss": -66.49910111236572, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.31595015525818, "step": 144000}
{"episode_reward": 852.6711428294992, "episode": 145.0, "batch_reward": 0.39670600393414496, "critic_loss": 0.8645536475777627, "actor_loss": -66.22984482574464, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.87457823753357, "step": 145000}
{"episode_reward": 877.3310541960534, "episode": 146.0, "batch_reward": 0.39695223066210744, "critic_loss": 0.8658125185668468, "actor_loss": -67.31790940093994, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.646023273468018, "step": 146000}
{"episode_reward": 35.247425797604556, "episode": 147.0, "batch_reward": 0.39716271445155144, "critic_loss": 0.8478775633871556, "actor_loss": -66.7822511291504, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.858840942382812, "step": 147000}
{"episode_reward": 74.50527487393485, "episode": 148.0, "batch_reward": 0.3948689212501049, "critic_loss": 0.8419467906653881, "actor_loss": -66.52398239898682, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.272814989089966, "step": 148000}
{"episode_reward": 938.8360676431611, "episode": 149.0, "batch_reward": 0.4002164459824562, "critic_loss": 0.7919283917844295, "actor_loss": -66.85693678283691, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.682040452957153, "step": 149000}
{"episode_reward": 917.5812472515532, "episode": 150.0, "batch_reward": 0.40365240776538847, "critic_loss": 0.8255448240339756, "actor_loss": -67.27917149353027, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "step": 150000}
