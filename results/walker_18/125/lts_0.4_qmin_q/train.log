{"episode_reward": 0.0, "episode": 1.0, "duration": 22.430961847305298, "step": 1000}
{"episode_reward": 28.177075776326152, "episode": 2.0, "duration": 1.9319803714752197, "step": 2000}
{"episode_reward": 69.84046218736019, "episode": 3.0, "batch_reward": 0.049921950237796324, "critic_loss": 0.155619573298992, "actor_loss": -76.86314612514929, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499180007, "duration": 64.77214503288269, "step": 3000}
{"episode_reward": 60.02655989733604, "episode": 4.0, "batch_reward": 0.05572630911320448, "critic_loss": 0.14989444803074004, "actor_loss": -73.14234741210937, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.400272369384766, "step": 4000}
{"episode_reward": 74.75028689021106, "episode": 5.0, "batch_reward": 0.06314431463181973, "critic_loss": 0.1527298279106617, "actor_loss": -71.49083706665039, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.848891735076904, "step": 5000}
{"episode_reward": 93.95089177479792, "episode": 6.0, "batch_reward": 0.07041785446181893, "critic_loss": 0.14983295810595154, "actor_loss": -70.82071495819092, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.272669792175293, "step": 6000}
{"episode_reward": 135.86931824128973, "episode": 7.0, "batch_reward": 0.08219687987491489, "critic_loss": 0.15693581259995698, "actor_loss": -69.58795011138916, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.266324043273926, "step": 7000}
{"episode_reward": 116.195065947763, "episode": 8.0, "batch_reward": 0.0788324274122715, "critic_loss": 0.1555074280947447, "actor_loss": -67.47652397918701, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.88396167755127, "step": 8000}
{"episode_reward": 18.993567725968802, "episode": 9.0, "batch_reward": 0.0809066568352282, "critic_loss": 0.27743527477234603, "actor_loss": -67.37914018249512, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.65325140953064, "step": 9000}
{"episode_reward": 136.90414377576937, "episode": 10.0, "batch_reward": 0.07856975475698709, "critic_loss": 0.232503024764359, "actor_loss": -65.44234909820557, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.25887703895569, "step": 10000}
{"episode_reward": 24.23067057230882, "episode": 11.0, "batch_reward": 0.07326392548531294, "critic_loss": 0.17033683378994466, "actor_loss": -64.03201519012451, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.32451272010803, "step": 11000}
{"episode_reward": 15.694215099656128, "episode": 12.0, "batch_reward": 0.07049952041357756, "critic_loss": 0.1678239122852683, "actor_loss": -62.74510486602783, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.023730993270874, "step": 12000}
{"episode_reward": 53.43282981722877, "episode": 13.0, "batch_reward": 0.07240218506753444, "critic_loss": 0.20411503088474273, "actor_loss": -61.64774011230469, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.40633201599121, "step": 13000}
{"episode_reward": 155.02535918656116, "episode": 14.0, "batch_reward": 0.07753077474236489, "critic_loss": 0.23055953811854124, "actor_loss": -59.43528588867188, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.89746356010437, "step": 14000}
{"episode_reward": 126.93098119256044, "episode": 15.0, "batch_reward": 0.08065149256587029, "critic_loss": 0.26655822949111463, "actor_loss": -60.74528867340088, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.644535541534424, "step": 15000}
{"episode_reward": 103.51920589354151, "episode": 16.0, "batch_reward": 0.08222579707205295, "critic_loss": 0.2927692853957415, "actor_loss": -60.377923896789554, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.96566605567932, "step": 16000}
{"episode_reward": 105.67846162336814, "episode": 17.0, "batch_reward": 0.0875653783492744, "critic_loss": 0.395975922241807, "actor_loss": -58.432119079589846, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.900065660476685, "step": 17000}
{"episode_reward": 237.26420138290274, "episode": 18.0, "batch_reward": 0.09178234350681305, "critic_loss": 0.4293389891535044, "actor_loss": -57.71619454956055, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.87681746482849, "step": 18000}
{"episode_reward": 56.3441759598859, "episode": 19.0, "batch_reward": 0.09397658370435238, "critic_loss": 0.5163211331218481, "actor_loss": -58.05041526031494, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.012772798538208, "step": 19000}
{"episode_reward": 210.567419312302, "episode": 20.0, "batch_reward": 0.09364365517348051, "critic_loss": 0.7277052515745163, "actor_loss": -57.979122573852536, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.893877744674683, "step": 20000}
{"episode_reward": 14.981697067924525, "episode": 21.0, "batch_reward": 0.0901017444320023, "critic_loss": 0.7614879272580147, "actor_loss": -57.73460025787354, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.68438220024109, "step": 21000}
{"episode_reward": 22.771961338522445, "episode": 22.0, "batch_reward": 0.08719449784234166, "critic_loss": 0.7301691064536572, "actor_loss": -57.46011320495605, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.241002559661865, "step": 22000}
{"episode_reward": 42.629955630673415, "episode": 23.0, "batch_reward": 0.08640978598594666, "critic_loss": 0.7701681773066521, "actor_loss": -57.07817748260498, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.961945295333862, "step": 23000}
{"episode_reward": 65.0070828222494, "episode": 24.0, "batch_reward": 0.0867232333905995, "critic_loss": 0.7897656991183758, "actor_loss": -59.4536989440918, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.880146503448486, "step": 24000}
{"episode_reward": 101.38838571632901, "episode": 25.0, "batch_reward": 0.08959794010594488, "critic_loss": 0.9087084649801255, "actor_loss": -59.165848640441894, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.166763305664062, "step": 25000}
{"episode_reward": 193.80169435060225, "episode": 26.0, "batch_reward": 0.08973023698851466, "critic_loss": 0.7675352338552475, "actor_loss": -60.43066027832031, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.970284938812256, "step": 26000}
{"episode_reward": 60.84962196335597, "episode": 27.0, "batch_reward": 0.09017277710139751, "critic_loss": 0.7488151032328606, "actor_loss": -61.14642189788818, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.91279911994934, "step": 27000}
{"episode_reward": 89.26417712682897, "episode": 28.0, "batch_reward": 0.08866456819698215, "critic_loss": 0.7522079774141311, "actor_loss": -61.14121204376221, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.944727182388306, "step": 28000}
{"episode_reward": 58.456215531038154, "episode": 29.0, "batch_reward": 0.08740215614065527, "critic_loss": 0.7886160388290883, "actor_loss": -62.0747329788208, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.063395023345947, "step": 29000}
{"episode_reward": 42.99336567520776, "episode": 30.0, "batch_reward": 0.08535814375802875, "critic_loss": 0.7850459585487842, "actor_loss": -61.62668391418457, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.421851634979248, "step": 30000}
{"episode_reward": 25.321114561903148, "episode": 31.0, "batch_reward": 0.08476531801372766, "critic_loss": 0.6849523407518864, "actor_loss": -61.59312277984619, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.550862073898315, "step": 31000}
{"episode_reward": 76.39583316237645, "episode": 32.0, "batch_reward": 0.08327817256003618, "critic_loss": 0.6761342360973358, "actor_loss": -62.36317916107178, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.25474500656128, "step": 32000}
{"episode_reward": 84.24453229028212, "episode": 33.0, "batch_reward": 0.0834537413455546, "critic_loss": 0.7611029804646969, "actor_loss": -61.87155820465088, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.187577486038208, "step": 33000}
{"episode_reward": 26.34710494321058, "episode": 34.0, "batch_reward": 0.0822308438718319, "critic_loss": 0.7780513543188572, "actor_loss": -59.96594873809814, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.23024296760559, "step": 34000}
{"episode_reward": 25.447786053374614, "episode": 35.0, "batch_reward": 0.08005321890115738, "critic_loss": 0.7624287952184677, "actor_loss": -62.71614597320556, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.667325496673584, "step": 35000}
{"episode_reward": 23.641723765822427, "episode": 36.0, "batch_reward": 0.07886144460365176, "critic_loss": 0.7392222597002983, "actor_loss": -62.352571632385256, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.87107753753662, "step": 36000}
{"episode_reward": 35.494768592867004, "episode": 37.0, "batch_reward": 0.07817665718123316, "critic_loss": 0.742849794536829, "actor_loss": -61.67086603546142, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.275492906570435, "step": 37000}
{"episode_reward": 68.90574795515154, "episode": 38.0, "batch_reward": 0.07748167281597852, "critic_loss": 0.9150229032337666, "actor_loss": -61.60176969146728, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.990081787109375, "step": 38000}
{"episode_reward": 67.09782198596538, "episode": 39.0, "batch_reward": 0.07703553331643342, "critic_loss": 1.3076848701238633, "actor_loss": -62.84002603149414, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.868722438812256, "step": 39000}
{"episode_reward": 30.52906563242871, "episode": 40.0, "batch_reward": 0.07539284403249621, "critic_loss": 1.996610948562622, "actor_loss": -61.56994394683838, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.025208234786987, "step": 40000}
{"episode_reward": 29.129953266184696, "episode": 41.0, "batch_reward": 0.07457941912859678, "critic_loss": 2.698882637619972, "actor_loss": -62.085835472106936, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.844858169555664, "step": 41000}
{"episode_reward": 23.32913198792343, "episode": 42.0, "batch_reward": 0.07432992175593972, "critic_loss": 2.8439112212061883, "actor_loss": -62.329256355285644, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.42672371864319, "step": 42000}
{"episode_reward": 104.87194740338653, "episode": 43.0, "batch_reward": 0.07445508888363839, "critic_loss": 2.9797530442476274, "actor_loss": -62.74842651367187, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.26726245880127, "step": 43000}
{"episode_reward": 35.219664281173394, "episode": 44.0, "batch_reward": 0.07332623361051083, "critic_loss": 2.823212493598461, "actor_loss": -62.92277809906006, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.183234930038452, "step": 44000}
{"episode_reward": 35.94603595323537, "episode": 45.0, "batch_reward": 0.07310079946368933, "critic_loss": 2.7932842947244643, "actor_loss": -64.39797588348388, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.264013528823853, "step": 45000}
{"episode_reward": 46.173174839355795, "episode": 46.0, "batch_reward": 0.072739781614393, "critic_loss": 2.717480379700661, "actor_loss": -64.62218395996094, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.373093843460083, "step": 46000}
{"episode_reward": 44.26010069812126, "episode": 47.0, "batch_reward": 0.07184765255078673, "critic_loss": 2.261912924170494, "actor_loss": -64.64273176574707, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.075836420059204, "step": 47000}
{"episode_reward": 98.21403266892237, "episode": 48.0, "batch_reward": 0.07194996426999568, "critic_loss": 2.1818336363434794, "actor_loss": -64.83996200561523, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.165502071380615, "step": 48000}
{"episode_reward": 17.227965336885028, "episode": 49.0, "batch_reward": 0.07107232908532024, "critic_loss": 1.9580396369099617, "actor_loss": -65.87555655670165, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.272430658340454, "step": 49000}
{"episode_reward": 92.33232745146749, "episode": 50.0, "batch_reward": 0.07260230438783764, "critic_loss": 1.8031381836533547, "actor_loss": -66.20042735290528, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.43234944343567, "step": 50000}
{"episode_reward": 121.26959260278952, "episode": 51.0, "batch_reward": 0.07339942671358585, "critic_loss": 1.6903907086849213, "actor_loss": -65.30164405059814, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.5847647190094, "step": 51000}
{"episode_reward": 150.7551364901546, "episode": 52.0, "batch_reward": 0.0747574797309935, "critic_loss": 1.6102176914215087, "actor_loss": -66.10931155395508, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.139465808868408, "step": 52000}
{"episode_reward": 88.42805240540335, "episode": 53.0, "batch_reward": 0.0763142820559442, "critic_loss": 1.5907009134292602, "actor_loss": -65.3883645401001, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.981367111206055, "step": 53000}
{"episode_reward": 281.1961287150399, "episode": 54.0, "batch_reward": 0.07996750438585877, "critic_loss": 1.63431731569767, "actor_loss": -64.83280290985107, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.558355569839478, "step": 54000}
{"episode_reward": 282.02541098988064, "episode": 55.0, "batch_reward": 0.08280933114513755, "critic_loss": 2.247924921512604, "actor_loss": -63.79021502685547, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.248619079589844, "step": 55000}
{"episode_reward": 250.5429434578589, "episode": 56.0, "batch_reward": 0.08643562917783856, "critic_loss": 2.194295407295227, "actor_loss": -65.30736903381347, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.270831823349, "step": 56000}
{"episode_reward": 264.57268679630823, "episode": 57.0, "batch_reward": 0.0899612834341824, "critic_loss": 2.140946663916111, "actor_loss": -65.71762890625, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.251561641693115, "step": 57000}
{"episode_reward": 298.3811421018246, "episode": 58.0, "batch_reward": 0.09423536649346352, "critic_loss": 1.9867578262090684, "actor_loss": -64.64494150543213, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.241914987564087, "step": 58000}
{"episode_reward": 342.3814970749948, "episode": 59.0, "batch_reward": 0.09558326129987836, "critic_loss": 1.9421674771308899, "actor_loss": -65.55314293670655, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.459450244903564, "step": 59000}
{"episode_reward": 14.660482522025543, "episode": 60.0, "batch_reward": 0.09688700473308563, "critic_loss": 2.047054739296436, "actor_loss": -66.27961849212646, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.074387073516846, "step": 60000}
{"episode_reward": 311.0731495418428, "episode": 61.0, "batch_reward": 0.10072440028190613, "critic_loss": 2.1005529069900515, "actor_loss": -66.43584687042237, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.96925950050354, "step": 61000}
{"episode_reward": 347.0970985712626, "episode": 62.0, "batch_reward": 0.10246616779267788, "critic_loss": 2.574883513867855, "actor_loss": -67.51198789978028, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.881322383880615, "step": 62000}
{"episode_reward": 10.782380334037859, "episode": 63.0, "batch_reward": 0.10084795636683702, "critic_loss": 2.6046455670595168, "actor_loss": -69.35727748870849, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.83209204673767, "step": 63000}
{"episode_reward": 27.935903459343532, "episode": 64.0, "batch_reward": 0.10006398636847734, "critic_loss": 2.7766582653522494, "actor_loss": -70.86613237762451, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.920597553253174, "step": 64000}
{"episode_reward": 69.32357546667433, "episode": 65.0, "batch_reward": 0.099412851087749, "critic_loss": 2.942824786543846, "actor_loss": -72.36760189819336, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.915576219558716, "step": 65000}
{"episode_reward": 52.39350740449833, "episode": 66.0, "batch_reward": 0.09843871319293976, "critic_loss": 2.8093714978694915, "actor_loss": -73.30023913574219, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.52063298225403, "step": 66000}
{"episode_reward": 26.945221521041077, "episode": 67.0, "batch_reward": 0.09761347841471434, "critic_loss": 2.535818584561348, "actor_loss": -73.91452886962891, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.205228328704834, "step": 67000}
{"episode_reward": 114.64033955290878, "episode": 68.0, "batch_reward": 0.09809904766827822, "critic_loss": 2.2750706718564033, "actor_loss": -73.6752816619873, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.058982610702515, "step": 68000}
{"episode_reward": 137.5596479559307, "episode": 69.0, "batch_reward": 0.0992794292345643, "critic_loss": 1.937412142455578, "actor_loss": -74.39566467285157, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.95847773551941, "step": 69000}
{"episode_reward": 132.21625876983018, "episode": 70.0, "batch_reward": 0.09878510594367981, "critic_loss": 1.5661345350146294, "actor_loss": -74.51506883239746, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.295485019683838, "step": 70000}
{"episode_reward": 93.12715402789345, "episode": 71.0, "batch_reward": 0.09884111319854856, "critic_loss": 1.1152867688834667, "actor_loss": -73.68959271240234, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.347662925720215, "step": 71000}
{"episode_reward": 52.378444620987366, "episode": 72.0, "batch_reward": 0.09806197909265757, "critic_loss": 0.8059564438164234, "actor_loss": -72.95226319885253, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.259357690811157, "step": 72000}
{"episode_reward": 73.6063207201129, "episode": 73.0, "batch_reward": 0.09727308028936386, "critic_loss": 0.6404464857876301, "actor_loss": -72.03750148010253, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.324726104736328, "step": 73000}
{"episode_reward": 50.49823432527816, "episode": 74.0, "batch_reward": 0.09570384326949716, "critic_loss": 0.5446906140744686, "actor_loss": -71.12588536071777, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.5104718208313, "step": 74000}
{"episode_reward": 36.462302521677486, "episode": 75.0, "batch_reward": 0.09732213432341814, "critic_loss": 0.4871896852254868, "actor_loss": -69.73644242095948, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.994701623916626, "step": 75000}
{"episode_reward": 76.10359767693589, "episode": 76.0, "batch_reward": 0.09624446345120669, "critic_loss": 0.4341071052402258, "actor_loss": -68.33219646453857, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.279382705688477, "step": 76000}
{"episode_reward": 240.61291385811265, "episode": 77.0, "batch_reward": 0.09934571420401335, "critic_loss": 0.3959969766885042, "actor_loss": -67.11415372467042, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.531389713287354, "step": 77000}
{"episode_reward": 249.2841001393238, "episode": 78.0, "batch_reward": 0.1001894955933094, "critic_loss": 0.35088867096602916, "actor_loss": -66.02991909790039, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.898175954818726, "step": 78000}
{"episode_reward": 297.13955215526556, "episode": 79.0, "batch_reward": 0.10164488680660724, "critic_loss": 0.3224375587850809, "actor_loss": -64.02836555480957, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.072241067886353, "step": 79000}
{"episode_reward": 83.71306930231147, "episode": 80.0, "batch_reward": 0.10397186731547117, "critic_loss": 0.2964170946329832, "actor_loss": -62.78612229919434, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.95385479927063, "step": 80000}
{"episode_reward": 405.3151770505212, "episode": 81.0, "batch_reward": 0.10922201146930456, "critic_loss": 0.2976271207332611, "actor_loss": -62.493297950744626, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.38570857048035, "step": 81000}
{"episode_reward": 429.0372831764686, "episode": 82.0, "batch_reward": 0.11012024039775133, "critic_loss": 0.28991832067817447, "actor_loss": -61.445183296203616, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.29764223098755, "step": 82000}
{"episode_reward": 73.44496090118477, "episode": 83.0, "batch_reward": 0.11146778054535389, "critic_loss": 0.2983978349938989, "actor_loss": -60.326025955200194, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.761313676834106, "step": 83000}
{"episode_reward": 428.5656560265477, "episode": 84.0, "batch_reward": 0.11583601000905037, "critic_loss": 0.2978903950452805, "actor_loss": -59.9785308227539, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.88384509086609, "step": 84000}
{"episode_reward": 461.35526909310124, "episode": 85.0, "batch_reward": 0.11934108144044876, "critic_loss": 0.28218589875102046, "actor_loss": -59.19923683166504, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.82400345802307, "step": 85000}
{"episode_reward": 429.27603197730616, "episode": 86.0, "batch_reward": 0.12325905603170395, "critic_loss": 0.2678589951172471, "actor_loss": -57.923466651916506, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.272789478302002, "step": 86000}
{"episode_reward": 478.90550908692904, "episode": 87.0, "batch_reward": 0.127003237105906, "critic_loss": 0.2941543294787407, "actor_loss": -56.294732955932616, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.17341113090515, "step": 87000}
{"episode_reward": 428.47554146553176, "episode": 88.0, "batch_reward": 0.12979862152785063, "critic_loss": 0.34469951936602594, "actor_loss": -55.204636962890625, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.194782972335815, "step": 88000}
{"episode_reward": 200.99099760764145, "episode": 89.0, "batch_reward": 0.13111016949266197, "critic_loss": 0.37402875800430774, "actor_loss": -55.473454406738284, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.31694483757019, "step": 89000}
{"episode_reward": 474.60693435893785, "episode": 90.0, "batch_reward": 0.13359293566644193, "critic_loss": 0.4234439685493708, "actor_loss": -55.47227333831787, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.014076948165894, "step": 90000}
{"episode_reward": 69.45470477524, "episode": 91.0, "batch_reward": 0.1350292800888419, "critic_loss": 0.4585625034570694, "actor_loss": -54.08304249572754, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.26224946975708, "step": 91000}
{"episode_reward": 483.2459038288601, "episode": 92.0, "batch_reward": 0.13549386011064052, "critic_loss": 0.48422721818089487, "actor_loss": -54.72374378967285, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.581516981124878, "step": 92000}
{"episode_reward": 67.52786206906244, "episode": 93.0, "batch_reward": 0.1374406361207366, "critic_loss": 0.5474759400188923, "actor_loss": -53.2850432510376, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.91920757293701, "step": 93000}
{"episode_reward": 428.4946110880769, "episode": 94.0, "batch_reward": 0.13921391082555057, "critic_loss": 0.5848617892563343, "actor_loss": -53.571163940429685, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.106146574020386, "step": 94000}
{"episode_reward": 88.10351464487674, "episode": 95.0, "batch_reward": 0.13955610074847938, "critic_loss": 0.6185799917876721, "actor_loss": -54.31704575347901, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.282344818115234, "step": 95000}
{"episode_reward": 155.69252736357782, "episode": 96.0, "batch_reward": 0.1377530875504017, "critic_loss": 0.6589220364689827, "actor_loss": -52.97130452728271, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.886969327926636, "step": 96000}
{"episode_reward": 81.95927421226118, "episode": 97.0, "batch_reward": 0.1393277837857604, "critic_loss": 0.6849345952868462, "actor_loss": -53.51905220794678, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.977855443954468, "step": 97000}
{"episode_reward": 515.0541548313403, "episode": 98.0, "batch_reward": 0.1431535323187709, "critic_loss": 0.7383282898664475, "actor_loss": -52.88480899047852, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.060285568237305, "step": 98000}
{"episode_reward": 522.6308650939527, "episode": 99.0, "batch_reward": 0.1487499044984579, "critic_loss": 0.7794812597632408, "actor_loss": -52.774754875183106, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.881101608276367, "step": 99000}
{"episode_reward": 551.3570777076117, "episode": 100.0, "batch_reward": 0.1507846913561225, "critic_loss": 0.7155538202226162, "actor_loss": -52.09098974609375, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.752145767211914, "step": 100000}
{"episode_reward": 239.87864968953335, "episode": 101.0, "batch_reward": 0.15277122876793145, "critic_loss": 0.7818511348664761, "actor_loss": -53.88929524993897, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.99761986732483, "step": 101000}
{"episode_reward": 457.64720783585665, "episode": 102.0, "batch_reward": 0.1549900069385767, "critic_loss": 0.8620112037062645, "actor_loss": -53.401724311828616, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.408133029937744, "step": 102000}
{"episode_reward": 582.190948985706, "episode": 103.0, "batch_reward": 0.16010395019501447, "critic_loss": 0.846731143027544, "actor_loss": -53.31563975524902, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.432087898254395, "step": 103000}
{"episode_reward": 571.4631697497192, "episode": 104.0, "batch_reward": 0.16342585206776858, "critic_loss": 0.8496824626922608, "actor_loss": -53.49089161682129, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.422341108322144, "step": 104000}
{"episode_reward": 444.8637743257882, "episode": 105.0, "batch_reward": 0.16741978321224452, "critic_loss": 0.8715184250771999, "actor_loss": -52.027497222900394, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.887866258621216, "step": 105000}
{"episode_reward": 565.3100931916659, "episode": 106.0, "batch_reward": 0.16886541457474233, "critic_loss": 0.8828106251060963, "actor_loss": -52.153946250915524, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.837039709091187, "step": 106000}
{"episode_reward": 387.83953936500143, "episode": 107.0, "batch_reward": 0.1735688799470663, "critic_loss": 0.8793082517087459, "actor_loss": -54.98069352722168, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.153245449066162, "step": 107000}
{"episode_reward": 588.510670404931, "episode": 108.0, "batch_reward": 0.17498384956270457, "critic_loss": 0.771764281630516, "actor_loss": -56.096269317626955, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.058495044708252, "step": 108000}
{"episode_reward": 14.688418011622689, "episode": 109.0, "batch_reward": 0.17391169992089273, "critic_loss": 0.7455104477405549, "actor_loss": -55.47996055603027, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.104063749313354, "step": 109000}
{"episode_reward": 359.52778564215026, "episode": 110.0, "batch_reward": 0.17870694898813963, "critic_loss": 0.7026960777342319, "actor_loss": -56.29525060272217, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.30621600151062, "step": 110000}
{"episode_reward": 686.6030306788956, "episode": 111.0, "batch_reward": 0.18196511401981116, "critic_loss": 0.6835126429796219, "actor_loss": -55.653480590820315, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.30544066429138, "step": 111000}
{"episode_reward": 663.1152376479865, "episode": 112.0, "batch_reward": 0.18458431265503167, "critic_loss": 0.6758057677447796, "actor_loss": -55.40092610168457, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.97907543182373, "step": 112000}
{"episode_reward": 334.1917866583423, "episode": 113.0, "batch_reward": 0.1878124839514494, "critic_loss": 0.7149419510662556, "actor_loss": -55.895752868652345, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.146542072296143, "step": 113000}
{"episode_reward": 643.093163913442, "episode": 114.0, "batch_reward": 0.19075227235257625, "critic_loss": 0.679826670140028, "actor_loss": -57.59332492828369, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.8750102519989, "step": 114000}
{"episode_reward": 735.7490779047421, "episode": 115.0, "batch_reward": 0.19659434068202972, "critic_loss": 0.6701127845644951, "actor_loss": -56.42992568206787, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.131184577941895, "step": 115000}
{"episode_reward": 649.7015903758422, "episode": 116.0, "batch_reward": 0.19783829335868358, "critic_loss": 0.6406741821169853, "actor_loss": -57.316478340148926, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.311789751052856, "step": 116000}
{"episode_reward": 129.74998296510708, "episode": 117.0, "batch_reward": 0.19905567503720523, "critic_loss": 0.6258936310559511, "actor_loss": -56.2003747177124, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.6672580242157, "step": 117000}
{"episode_reward": 578.2198482935692, "episode": 118.0, "batch_reward": 0.20370718328654766, "critic_loss": 0.6163571939468384, "actor_loss": -57.61327276611328, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.892515897750854, "step": 118000}
{"episode_reward": 674.2192551394594, "episode": 119.0, "batch_reward": 0.20518163338303566, "critic_loss": 0.6225810603797436, "actor_loss": -55.70989270019531, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.8676278591156, "step": 119000}
{"episode_reward": 109.67281810112084, "episode": 120.0, "batch_reward": 0.2049174694865942, "critic_loss": 0.6405269184559583, "actor_loss": -54.37548340606689, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.85678195953369, "step": 120000}
{"episode_reward": 510.625324134043, "episode": 121.0, "batch_reward": 0.20947369408607483, "critic_loss": 0.6883660876750946, "actor_loss": -55.115395233154295, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.08076333999634, "step": 121000}
{"episode_reward": 749.1448910699702, "episode": 122.0, "batch_reward": 0.21291100451350212, "critic_loss": 0.7215657601058483, "actor_loss": -55.57898638916016, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.21581768989563, "step": 122000}
{"episode_reward": 656.0046718053343, "episode": 123.0, "batch_reward": 0.2182993156015873, "critic_loss": 0.7514294638931751, "actor_loss": -54.65884043121338, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.985061407089233, "step": 123000}
{"episode_reward": 710.6432883174685, "episode": 124.0, "batch_reward": 0.22074357482790946, "critic_loss": 0.744759235471487, "actor_loss": -55.84416062927246, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.15772247314453, "step": 124000}
{"episode_reward": 639.170052676839, "episode": 125.0, "batch_reward": 0.22319288776814938, "critic_loss": 0.7684694424569607, "actor_loss": -54.9644119720459, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.307637453079224, "step": 125000}
{"episode_reward": 765.1838595194739, "episode": 126.0, "batch_reward": 0.22815915662050248, "critic_loss": 0.7745036780536175, "actor_loss": -56.49832214355469, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.339518070220947, "step": 126000}
{"episode_reward": 732.4959261084014, "episode": 127.0, "batch_reward": 0.2319654742181301, "critic_loss": 0.7843368001282215, "actor_loss": -56.30549546051025, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.895001888275146, "step": 127000}
{"episode_reward": 338.472631732684, "episode": 128.0, "batch_reward": 0.22992412808537482, "critic_loss": 0.809076260715723, "actor_loss": -56.748457527160646, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.10088014602661, "step": 128000}
{"episode_reward": 15.485632965220844, "episode": 129.0, "batch_reward": 0.2326474538743496, "critic_loss": 0.7900743669867516, "actor_loss": -57.26159506988525, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.03274941444397, "step": 129000}
{"episode_reward": 847.9887073178534, "episode": 130.0, "batch_reward": 0.23593227027356625, "critic_loss": 0.8351133929491044, "actor_loss": -55.69409925079346, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.879640102386475, "step": 130000}
{"episode_reward": 800.1655004097568, "episode": 131.0, "batch_reward": 0.24088056525588036, "critic_loss": 0.8229814965426921, "actor_loss": -56.476207984924315, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.596893072128296, "step": 131000}
{"episode_reward": 761.2018360705753, "episode": 132.0, "batch_reward": 0.24228359362483023, "critic_loss": 0.8367558339834213, "actor_loss": -56.19832601165771, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.242175102233887, "step": 132000}
{"episode_reward": 17.50237233522712, "episode": 133.0, "batch_reward": 0.24149412663280964, "critic_loss": 0.8655796557068824, "actor_loss": -57.75202661132813, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.872494220733643, "step": 133000}
{"episode_reward": 785.1737414120438, "episode": 134.0, "batch_reward": 0.2464726422727108, "critic_loss": 0.8781927401125431, "actor_loss": -58.625874908447265, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.105304479599, "step": 134000}
{"episode_reward": 746.3270433973437, "episode": 135.0, "batch_reward": 0.25080158600211144, "critic_loss": 0.9173560092747212, "actor_loss": -56.83065771484375, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.124530792236328, "step": 135000}
{"episode_reward": 855.9828026273699, "episode": 136.0, "batch_reward": 0.2565230620354414, "critic_loss": 0.9368819791972637, "actor_loss": -57.37563730621338, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.29215407371521, "step": 136000}
{"episode_reward": 909.2318301135203, "episode": 137.0, "batch_reward": 0.25744918774068354, "critic_loss": 0.9145322244167328, "actor_loss": -56.951643280029295, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.918570041656494, "step": 137000}
{"episode_reward": 117.63412418792434, "episode": 138.0, "batch_reward": 0.2589488625526428, "critic_loss": 0.9067426706850529, "actor_loss": -56.39877020263672, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.752660751342773, "step": 138000}
{"episode_reward": 837.6844988496948, "episode": 139.0, "batch_reward": 0.26089939594268796, "critic_loss": 0.9578564357757569, "actor_loss": -57.1348388671875, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.242542266845703, "step": 139000}
{"episode_reward": 120.50870947709869, "episode": 140.0, "batch_reward": 0.2618912016153336, "critic_loss": 0.9455927925705909, "actor_loss": -57.154430702209474, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.837552547454834, "step": 140000}
{"episode_reward": 848.1140807149445, "episode": 141.0, "batch_reward": 0.2659043945968151, "critic_loss": 0.963466221421957, "actor_loss": -57.26090859222412, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.833295583724976, "step": 141000}
{"episode_reward": 787.6001131380497, "episode": 142.0, "batch_reward": 0.26929444980621337, "critic_loss": 0.943580847889185, "actor_loss": -58.15989134979248, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.90852665901184, "step": 142000}
{"episode_reward": 842.1069096999254, "episode": 143.0, "batch_reward": 0.27228981935977936, "critic_loss": 0.9545542671382428, "actor_loss": -58.229178482055666, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.611298084259033, "step": 143000}
{"episode_reward": 354.3560095572919, "episode": 144.0, "batch_reward": 0.2754654462337494, "critic_loss": 0.9835706058740615, "actor_loss": -58.26269033050537, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.25383162498474, "step": 144000}
{"episode_reward": 824.578146869609, "episode": 145.0, "batch_reward": 0.2802072269171476, "critic_loss": 1.0006737164855004, "actor_loss": -59.218933837890624, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.04395842552185, "step": 145000}
{"episode_reward": 862.2415169764412, "episode": 146.0, "batch_reward": 0.28153527280688284, "critic_loss": 1.0432083058357238, "actor_loss": -60.783253677368165, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.983804941177368, "step": 146000}
{"episode_reward": 862.7739422892544, "episode": 147.0, "batch_reward": 0.2851778828203678, "critic_loss": 1.0300209937989713, "actor_loss": -60.33768768310547, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.290360927581787, "step": 147000}
{"episode_reward": 826.2275908791106, "episode": 148.0, "batch_reward": 0.29017849987745287, "critic_loss": 1.0422535173892975, "actor_loss": -60.455321716308596, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.331322193145752, "step": 148000}
{"episode_reward": 911.0397374983672, "episode": 149.0, "batch_reward": 0.2946240922808647, "critic_loss": 1.0820152019262315, "actor_loss": -61.15254652404785, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.08092713356018, "step": 149000}
{"episode_reward": 844.0404960916578, "episode": 150.0, "batch_reward": 0.2997991414070129, "critic_loss": 1.0978712581396104, "actor_loss": -61.87462589263916, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "step": 150000}
