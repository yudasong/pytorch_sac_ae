{"episode_reward": 0.0, "episode": 1.0, "duration": 21.585940837860107, "step": 1000}
{"episode_reward": 28.177075776326152, "episode": 2.0, "duration": 1.949244499206543, "step": 2000}
{"episode_reward": 69.84046218736019, "episode": 3.0, "batch_reward": 0.05133585728116137, "critic_loss": 0.01189102736165003, "actor_loss": -65.81734788593124, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499180007, "duration": 63.257609128952026, "step": 3000}
{"episode_reward": 56.16532977014009, "episode": 4.0, "batch_reward": 0.04978227721527219, "critic_loss": 0.007709118686849251, "actor_loss": -64.65345063424111, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.646223068237305, "step": 4000}
{"episode_reward": 25.625496367366885, "episode": 5.0, "batch_reward": 0.044901135087013246, "critic_loss": 0.010305536363506689, "actor_loss": -60.12489197540283, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.75178599357605, "step": 5000}
{"episode_reward": 30.542902857107002, "episode": 6.0, "batch_reward": 0.0421664300262928, "critic_loss": 0.012369694909779355, "actor_loss": -61.33739854300022, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.027612686157227, "step": 6000}
{"episode_reward": 44.2765370231421, "episode": 7.0, "batch_reward": 0.04362765420414507, "critic_loss": 0.013834913624450565, "actor_loss": -62.413609146356585, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.836812496185303, "step": 7000}
{"episode_reward": 46.65314455635655, "episode": 8.0, "batch_reward": 0.04315260771661997, "critic_loss": 0.012034364990424365, "actor_loss": -61.333203742980956, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.539186716079712, "step": 8000}
{"episode_reward": 37.92471731900601, "episode": 9.0, "batch_reward": 0.04177423699758947, "critic_loss": 0.01254617894347757, "actor_loss": -61.681722831487654, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.13776683807373, "step": 9000}
{"episode_reward": 31.061931645973157, "episode": 10.0, "batch_reward": 0.04140144290961325, "critic_loss": 0.010387016566004605, "actor_loss": -62.232475086212155, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.60926580429077, "step": 10000}
{"episode_reward": 43.9874732874355, "episode": 11.0, "batch_reward": 0.041662432873621584, "critic_loss": 0.013312620286829769, "actor_loss": -62.12961306333542, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.783567667007446, "step": 11000}
{"episode_reward": 40.1004078023795, "episode": 12.0, "batch_reward": 0.04107480618357658, "critic_loss": 0.012066428881604224, "actor_loss": -60.61645659732819, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.149462938308716, "step": 12000}
{"episode_reward": 40.35177019646707, "episode": 13.0, "batch_reward": 0.041508490789681676, "critic_loss": 0.01255926129873842, "actor_loss": -61.790557150363924, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.538370609283447, "step": 13000}
{"episode_reward": 46.61645084887784, "episode": 14.0, "batch_reward": 0.04347008372470736, "critic_loss": 0.019192405584733934, "actor_loss": -59.39364486217499, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.97990345954895, "step": 14000}
{"episode_reward": 68.60486639043276, "episode": 15.0, "batch_reward": 0.04445721735060215, "critic_loss": 0.018487820875365286, "actor_loss": -66.59516014766693, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.732298612594604, "step": 15000}
{"episode_reward": 58.79203289733457, "episode": 16.0, "batch_reward": 0.045175757750868795, "critic_loss": 0.019748344795778392, "actor_loss": -62.36045971870422, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.20317244529724, "step": 16000}
{"episode_reward": 64.90493056778726, "episode": 17.0, "batch_reward": 0.04714633299782872, "critic_loss": 0.035559962041676045, "actor_loss": -64.21860245776176, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.463736057281494, "step": 17000}
{"episode_reward": 77.28875806021341, "episode": 18.0, "batch_reward": 0.04813806263357401, "critic_loss": 0.05166352043300867, "actor_loss": -62.726005397319796, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.474555015563965, "step": 18000}
{"episode_reward": 57.43892984396084, "episode": 19.0, "batch_reward": 0.04907136175781488, "critic_loss": 0.053461477095261216, "actor_loss": -60.54952596759796, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.292972564697266, "step": 19000}
{"episode_reward": 65.30538455111056, "episode": 20.0, "batch_reward": 0.049095909465104344, "critic_loss": 0.0820985840074718, "actor_loss": -63.90197653889656, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.81778907775879, "step": 20000}
{"episode_reward": 60.2154333454052, "episode": 21.0, "batch_reward": 0.05015590493381023, "critic_loss": 0.17747542912699282, "actor_loss": -64.06854832269251, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.3479950428009, "step": 21000}
{"episode_reward": 61.4392197007549, "episode": 22.0, "batch_reward": 0.050454685289412736, "critic_loss": 0.6461827655471861, "actor_loss": -64.04944051560014, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.723565101623535, "step": 22000}
{"episode_reward": 59.36144048999568, "episode": 23.0, "batch_reward": 0.050622009593993426, "critic_loss": 1.760207412518561, "actor_loss": -66.7616421295628, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.796201705932617, "step": 23000}
{"episode_reward": 57.92103269532032, "episode": 24.0, "batch_reward": 0.05116231633722782, "critic_loss": 2.704903007104993, "actor_loss": -65.22265257889032, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.46151828765869, "step": 24000}
{"episode_reward": 63.19641411903286, "episode": 25.0, "batch_reward": 0.05160955821350217, "critic_loss": 6.158905441373586, "actor_loss": -64.68678935647011, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.840279817581177, "step": 25000}
{"episode_reward": 60.08127320264095, "episode": 26.0, "batch_reward": 0.05236762350052595, "critic_loss": 16.393038267612457, "actor_loss": -68.57922852802277, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.989989519119263, "step": 26000}
{"episode_reward": 73.22179884771134, "episode": 27.0, "batch_reward": 0.053459606677293776, "critic_loss": 36.25879710197449, "actor_loss": -69.60197250938415, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.127732038497925, "step": 27000}
{"episode_reward": 81.45364321544571, "episode": 28.0, "batch_reward": 0.054125004000961784, "critic_loss": 84.07446459960937, "actor_loss": -73.60931684494018, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.643685579299927, "step": 28000}
{"episode_reward": 58.88338629755448, "episode": 29.0, "batch_reward": 0.053927891712635755, "critic_loss": 166.79524992752076, "actor_loss": -82.31278762054443, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.444891452789307, "step": 29000}
{"episode_reward": 101.51840433879943, "episode": 30.0, "batch_reward": 0.05731263333559036, "critic_loss": 418.61577972412107, "actor_loss": -101.15216603088379, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.657787084579468, "step": 30000}
{"episode_reward": 168.03480000462622, "episode": 31.0, "batch_reward": 0.06072227845340967, "critic_loss": 518.9955573425293, "actor_loss": -124.57895909118652, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.23673725128174, "step": 31000}
{"episode_reward": 172.56632606931674, "episode": 32.0, "batch_reward": 0.06459949418157339, "critic_loss": 487.9739931335449, "actor_loss": -148.33723182678222, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.928388595581055, "step": 32000}
{"episode_reward": 159.65617611562118, "episode": 33.0, "batch_reward": 0.06590211790427565, "critic_loss": 468.9233246154785, "actor_loss": -151.23777278137206, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.156132221221924, "step": 33000}
{"episode_reward": 64.01715059554455, "episode": 34.0, "batch_reward": 0.06599769205227494, "critic_loss": 432.56113996887206, "actor_loss": -172.05666723632814, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.045745849609375, "step": 34000}
{"episode_reward": 65.06696254430229, "episode": 35.0, "batch_reward": 0.06613827288150788, "critic_loss": 384.11960890197753, "actor_loss": -155.13506204223634, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.744705200195312, "step": 35000}
{"episode_reward": 99.90296669261836, "episode": 36.0, "batch_reward": 0.0667509052157402, "critic_loss": 300.3915414428711, "actor_loss": -179.06030154418946, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.465137720108032, "step": 36000}
{"episode_reward": 62.9303983118014, "episode": 37.0, "batch_reward": 0.06672646574303508, "critic_loss": 234.7755155029297, "actor_loss": -157.00566369628908, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.707730531692505, "step": 37000}
{"episode_reward": 57.49727769480037, "episode": 38.0, "batch_reward": 0.06770858940854668, "critic_loss": 210.9985529937744, "actor_loss": -156.84482968139648, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.532567739486694, "step": 38000}
{"episode_reward": 153.03483880434842, "episode": 39.0, "batch_reward": 0.07017429445683956, "critic_loss": 184.77926091003417, "actor_loss": -157.00580055236816, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.63037943840027, "step": 39000}
{"episode_reward": 204.26184604044838, "episode": 40.0, "batch_reward": 0.07207033411040902, "critic_loss": 174.603410987854, "actor_loss": -157.59130696105956, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.8980233669281, "step": 40000}
{"episode_reward": 58.59922765258961, "episode": 41.0, "batch_reward": 0.0717692330032587, "critic_loss": 140.14879861068727, "actor_loss": -159.37509674072265, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.344805002212524, "step": 41000}
{"episode_reward": 83.60179164406884, "episode": 42.0, "batch_reward": 0.07295311974361539, "critic_loss": 109.63643334960938, "actor_loss": -175.00728269958495, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.601293563842773, "step": 42000}
{"episode_reward": 107.2031640712041, "episode": 43.0, "batch_reward": 0.07355787773802877, "critic_loss": 92.80539122390748, "actor_loss": -167.6778678894043, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.404139757156372, "step": 43000}
{"episode_reward": 102.60833563201206, "episode": 44.0, "batch_reward": 0.07447879394143819, "critic_loss": 76.48160206985473, "actor_loss": -166.4628595123291, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.470526695251465, "step": 44000}
{"episode_reward": 110.15728679832701, "episode": 45.0, "batch_reward": 0.07504837430268527, "critic_loss": 64.91708720970153, "actor_loss": -161.1204699707031, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.889920473098755, "step": 45000}
{"episode_reward": 125.58863597566607, "episode": 46.0, "batch_reward": 0.07644581047818065, "critic_loss": 55.2968533115387, "actor_loss": -158.7497198791504, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.009535789489746, "step": 46000}
{"episode_reward": 148.90562226016925, "episode": 47.0, "batch_reward": 0.07836863141134381, "critic_loss": 46.934816482543944, "actor_loss": -147.40854600524904, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.645334005355835, "step": 47000}
{"episode_reward": 161.32053453389858, "episode": 48.0, "batch_reward": 0.0792585489489138, "critic_loss": 40.530549926757814, "actor_loss": -148.57839973449708, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.90865468978882, "step": 48000}
{"episode_reward": 135.2492015084541, "episode": 49.0, "batch_reward": 0.08156638554111123, "critic_loss": 34.89419182395935, "actor_loss": -135.73361822509764, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.53335452079773, "step": 49000}
{"episode_reward": 135.8249765291654, "episode": 50.0, "batch_reward": 0.08349009058624506, "critic_loss": 29.7368618183136, "actor_loss": -141.61827479553222, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.991401195526123, "step": 50000}
{"episode_reward": 187.21397454749984, "episode": 51.0, "batch_reward": 0.08362877428531647, "critic_loss": 27.05921155166626, "actor_loss": -136.26548921203613, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.49233388900757, "step": 51000}
{"episode_reward": 93.32274726305832, "episode": 52.0, "batch_reward": 0.08325849140807987, "critic_loss": 23.549853512763978, "actor_loss": -134.52256144714354, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.491506099700928, "step": 52000}
{"episode_reward": 33.40560232578946, "episode": 53.0, "batch_reward": 0.08243241506069898, "critic_loss": 20.5958014755249, "actor_loss": -128.27695724487305, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.298776149749756, "step": 53000}
{"episode_reward": 28.02002369896985, "episode": 54.0, "batch_reward": 0.08105594342574478, "critic_loss": 18.610122672080994, "actor_loss": -127.6025951538086, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.92556405067444, "step": 54000}
{"episode_reward": 24.81363100014158, "episode": 55.0, "batch_reward": 0.07999564742296934, "critic_loss": 16.092721662521363, "actor_loss": -116.89040521240234, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.718085050582886, "step": 55000}
{"episode_reward": 41.47319276432, "episode": 56.0, "batch_reward": 0.0803599429577589, "critic_loss": 13.802550369739533, "actor_loss": -116.55774784851074, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.44767928123474, "step": 56000}
{"episode_reward": 135.29157152125325, "episode": 57.0, "batch_reward": 0.0811151748932898, "critic_loss": 12.286236447811127, "actor_loss": -119.48833360290527, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.186086177825928, "step": 57000}
{"episode_reward": 56.58037689124813, "episode": 58.0, "batch_reward": 0.08009248418360948, "critic_loss": 10.229979347229003, "actor_loss": -114.83270077514648, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.630160808563232, "step": 58000}
{"episode_reward": 64.3765865166215, "episode": 59.0, "batch_reward": 0.0798952647075057, "critic_loss": 9.248845562458039, "actor_loss": -113.97254920959473, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.457768440246582, "step": 59000}
{"episode_reward": 62.010884425797066, "episode": 60.0, "batch_reward": 0.07947529351711273, "critic_loss": 8.650418422460556, "actor_loss": -110.41297271728516, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.71164298057556, "step": 60000}
{"episode_reward": 45.7993063389363, "episode": 61.0, "batch_reward": 0.07925255050882697, "critic_loss": 8.839469135046006, "actor_loss": -109.48932382202149, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.11980319023132, "step": 61000}
{"episode_reward": 59.84012470922692, "episode": 62.0, "batch_reward": 0.07853498403355479, "critic_loss": 7.630404006481171, "actor_loss": -102.11651690673828, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.85641837120056, "step": 62000}
{"episode_reward": 68.91509040310234, "episode": 63.0, "batch_reward": 0.07861995454877616, "critic_loss": 6.413392956256867, "actor_loss": -102.83989408874511, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.321757316589355, "step": 63000}
{"episode_reward": 60.909832949067756, "episode": 64.0, "batch_reward": 0.07845724323019386, "critic_loss": 6.00838929271698, "actor_loss": -100.33647326660156, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.834707498550415, "step": 64000}
{"episode_reward": 62.34008369609922, "episode": 65.0, "batch_reward": 0.07814023911952972, "critic_loss": 5.643315277099609, "actor_loss": -99.52166705322266, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.842260360717773, "step": 65000}
{"episode_reward": 64.58144015133712, "episode": 66.0, "batch_reward": 0.07920192841812969, "critic_loss": 5.499148690462112, "actor_loss": -96.9753257598877, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.86373805999756, "step": 66000}
{"episode_reward": 242.59524350346123, "episode": 67.0, "batch_reward": 0.08114126121625304, "critic_loss": 5.036125286102295, "actor_loss": -94.26981823730469, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.276503086090088, "step": 67000}
{"episode_reward": 157.54425898453408, "episode": 68.0, "batch_reward": 0.08155788430571556, "critic_loss": 4.861769755959511, "actor_loss": -93.53425915527343, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.558118104934692, "step": 68000}
{"episode_reward": 79.11562284722996, "episode": 69.0, "batch_reward": 0.0825833815895021, "critic_loss": 3.9362206491231917, "actor_loss": -91.35837852478028, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.578081846237183, "step": 69000}
{"episode_reward": 236.0611913576151, "episode": 70.0, "batch_reward": 0.08404132831841707, "critic_loss": 3.8853208928108214, "actor_loss": -89.45125938415528, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.101247787475586, "step": 70000}
{"episode_reward": 64.56420973654211, "episode": 71.0, "batch_reward": 0.08371478326991201, "critic_loss": 3.3374230608940123, "actor_loss": -87.68454803466797, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.596494913101196, "step": 71000}
{"episode_reward": 215.27038908299716, "episode": 72.0, "batch_reward": 0.08573141391947865, "critic_loss": 3.2669421067237856, "actor_loss": -86.35052391052245, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.43350338935852, "step": 72000}
{"episode_reward": 71.55571936610771, "episode": 73.0, "batch_reward": 0.08695192497596145, "critic_loss": 2.6713234971761706, "actor_loss": -85.53932211303712, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.629428386688232, "step": 73000}
{"episode_reward": 290.91541588225, "episode": 74.0, "batch_reward": 0.08921696884185076, "critic_loss": 2.52441494679451, "actor_loss": -84.09271212768554, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.462658166885376, "step": 74000}
{"episode_reward": 190.97944572027887, "episode": 75.0, "batch_reward": 0.08895373146235942, "critic_loss": 2.209779032468796, "actor_loss": -83.56091110229492, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.72025179862976, "step": 75000}
{"episode_reward": 32.23429830300963, "episode": 76.0, "batch_reward": 0.09033419805765151, "critic_loss": 1.9256968708634377, "actor_loss": -82.41347872924804, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.953838348388672, "step": 76000}
{"episode_reward": 351.59599960982615, "episode": 77.0, "batch_reward": 0.09267816331237555, "critic_loss": 1.8284609505534173, "actor_loss": -81.67986241149903, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.681864738464355, "step": 77000}
{"episode_reward": 70.93621686777344, "episode": 78.0, "batch_reward": 0.09167089293152093, "critic_loss": 1.6324858964681626, "actor_loss": -80.76978843688966, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.930626153945923, "step": 78000}
{"episode_reward": 70.86469396098124, "episode": 79.0, "batch_reward": 0.09190686263889074, "critic_loss": 1.5740161314010621, "actor_loss": -80.0300945892334, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.394153594970703, "step": 79000}
{"episode_reward": 66.44333064244334, "episode": 80.0, "batch_reward": 0.09131479788571596, "critic_loss": 1.5213896371126174, "actor_loss": -79.41094631958008, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.80642032623291, "step": 80000}
{"episode_reward": 62.16094378266834, "episode": 81.0, "batch_reward": 0.09107333964109421, "critic_loss": 1.208967082887888, "actor_loss": -78.42893505859375, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.76912713050842, "step": 81000}
{"episode_reward": 63.310134835893464, "episode": 82.0, "batch_reward": 0.09100863683968782, "critic_loss": 1.072893042564392, "actor_loss": -78.19486741638184, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.61602210998535, "step": 82000}
{"episode_reward": 63.88268773843879, "episode": 83.0, "batch_reward": 0.09161139842122794, "critic_loss": 1.007966314703226, "actor_loss": -76.82262551879883, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.948237419128418, "step": 83000}
{"episode_reward": 327.7651530563871, "episode": 84.0, "batch_reward": 0.09559186450392008, "critic_loss": 0.8874139049947262, "actor_loss": -77.34852533721924, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.917834043502808, "step": 84000}
{"episode_reward": 440.42427891930976, "episode": 85.0, "batch_reward": 0.09900924380868674, "critic_loss": 0.8138076708316803, "actor_loss": -75.91672528839112, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.46834421157837, "step": 85000}
{"episode_reward": 373.52722647149113, "episode": 86.0, "batch_reward": 0.10082652301341295, "critic_loss": 0.7044436828494072, "actor_loss": -75.3935223083496, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.642221450805664, "step": 86000}
{"episode_reward": 71.4757144343881, "episode": 87.0, "batch_reward": 0.10086820612847805, "critic_loss": 0.6120057742893695, "actor_loss": -74.68296224212646, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.716501474380493, "step": 87000}
{"episode_reward": 314.6371657116861, "episode": 88.0, "batch_reward": 0.10288692440837621, "critic_loss": 0.6191909601986408, "actor_loss": -73.46199147796631, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.410354137420654, "step": 88000}
{"episode_reward": 134.50347683289647, "episode": 89.0, "batch_reward": 0.10508046858012676, "critic_loss": 0.6072063362300396, "actor_loss": -73.99317986297608, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.95416760444641, "step": 89000}
{"episode_reward": 413.80561415038596, "episode": 90.0, "batch_reward": 0.10649180574715138, "critic_loss": 0.5411737503111362, "actor_loss": -74.03393099212647, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.5073983669281, "step": 90000}
{"episode_reward": 71.62322946194217, "episode": 91.0, "batch_reward": 0.10808483150601388, "critic_loss": 0.5229017179459333, "actor_loss": -73.13842578125, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.0500168800354, "step": 91000}
{"episode_reward": 441.20622127345877, "episode": 92.0, "batch_reward": 0.1092513636648655, "critic_loss": 0.4833635007441044, "actor_loss": -72.63941337585449, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.456599235534668, "step": 92000}
{"episode_reward": 66.17720831364038, "episode": 93.0, "batch_reward": 0.11001443968713284, "critic_loss": 0.4935358004122973, "actor_loss": -71.63573726654053, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.350260257720947, "step": 93000}
{"episode_reward": 368.84463896721206, "episode": 94.0, "batch_reward": 0.11239712499827147, "critic_loss": 0.4815374945998192, "actor_loss": -72.04320483398438, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.85172963142395, "step": 94000}
{"episode_reward": 68.75813735548091, "episode": 95.0, "batch_reward": 0.11155314610153437, "critic_loss": 0.43767880426347255, "actor_loss": -72.11752012634277, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.882318258285522, "step": 95000}
{"episode_reward": 73.69671834327127, "episode": 96.0, "batch_reward": 0.11130913698673248, "critic_loss": 0.43213923750817773, "actor_loss": -72.1690569152832, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.340928077697754, "step": 96000}
{"episode_reward": 74.53147811385932, "episode": 97.0, "batch_reward": 0.10973000273108482, "critic_loss": 0.4759186001420021, "actor_loss": -72.49124599838257, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.515939712524414, "step": 97000}
{"episode_reward": 98.75641733042093, "episode": 98.0, "batch_reward": 0.11248149923235178, "critic_loss": 0.4610428020954132, "actor_loss": -71.57880483627319, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.886160135269165, "step": 98000}
{"episode_reward": 498.6891500073603, "episode": 99.0, "batch_reward": 0.11642808490991592, "critic_loss": 0.4546210500895977, "actor_loss": -70.08533139038086, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.72339677810669, "step": 99000}
{"episode_reward": 437.7314679481202, "episode": 100.0, "batch_reward": 0.11925964473187924, "critic_loss": 0.47447762385010717, "actor_loss": -70.79838612747193, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.24407982826233, "step": 100000}
{"episode_reward": 419.8001707178181, "episode": 101.0, "batch_reward": 0.12234205853939056, "critic_loss": 0.49223057202994824, "actor_loss": -70.7443182220459, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.45634889602661, "step": 101000}
{"episode_reward": 255.3441014239732, "episode": 102.0, "batch_reward": 0.12127339049428701, "critic_loss": 0.47207107657194136, "actor_loss": -69.62023714447021, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.521469354629517, "step": 102000}
{"episode_reward": 85.82232525389307, "episode": 103.0, "batch_reward": 0.12134518475085497, "critic_loss": 0.5087388136833906, "actor_loss": -70.81608325958251, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.497092247009277, "step": 103000}
{"episode_reward": 67.3022185176342, "episode": 104.0, "batch_reward": 0.12268464498221875, "critic_loss": 0.5032016422003508, "actor_loss": -70.8124232788086, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.443378686904907, "step": 104000}
{"episode_reward": 420.96702201552176, "episode": 105.0, "batch_reward": 0.12538870964944362, "critic_loss": 0.48957513697445393, "actor_loss": -70.46476081466675, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.728102445602417, "step": 105000}
{"episode_reward": 232.26786181963303, "episode": 106.0, "batch_reward": 0.12598798045516013, "critic_loss": 0.5148540858924389, "actor_loss": -69.67344567871093, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.429197072982788, "step": 106000}
{"episode_reward": 399.8821409113501, "episode": 107.0, "batch_reward": 0.12845128767192363, "critic_loss": 0.48847919566929343, "actor_loss": -70.46325086593627, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.931766271591187, "step": 107000}
{"episode_reward": 254.874600013557, "episode": 108.0, "batch_reward": 0.12867954284697772, "critic_loss": 0.5067722606658935, "actor_loss": -69.46763666534424, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.934626579284668, "step": 108000}
{"episode_reward": 89.28401657058927, "episode": 109.0, "batch_reward": 0.12791693797707557, "critic_loss": 0.49473866732418537, "actor_loss": -71.78645837020873, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.77572798728943, "step": 109000}
{"episode_reward": 59.3192801216717, "episode": 110.0, "batch_reward": 0.1277360764890909, "critic_loss": 0.474963146135211, "actor_loss": -70.53362384796142, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.148216247558594, "step": 110000}
{"episode_reward": 94.85278027281538, "episode": 111.0, "batch_reward": 0.1283876067325473, "critic_loss": 0.4821313147097826, "actor_loss": -70.22339860153198, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.71638298034668, "step": 111000}
{"episode_reward": 109.68874575726593, "episode": 112.0, "batch_reward": 0.12869547568261624, "critic_loss": 0.46409413674473765, "actor_loss": -67.96907110214234, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.150373458862305, "step": 112000}
{"episode_reward": 452.7476578596594, "episode": 113.0, "batch_reward": 0.12969689191877842, "critic_loss": 0.5506517844945192, "actor_loss": -69.53485778045655, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.881057024002075, "step": 113000}
{"episode_reward": 81.91910017112326, "episode": 114.0, "batch_reward": 0.13230078317970037, "critic_loss": 0.5553584951907397, "actor_loss": -70.6700544013977, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.29316735267639, "step": 114000}
{"episode_reward": 481.60336206007594, "episode": 115.0, "batch_reward": 0.1346098814830184, "critic_loss": 0.5583944899737835, "actor_loss": -69.03231233406066, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.859567165374756, "step": 115000}
{"episode_reward": 514.6922107686961, "episode": 116.0, "batch_reward": 0.136502379283309, "critic_loss": 0.566001906812191, "actor_loss": -68.87935634231567, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.93733310699463, "step": 116000}
{"episode_reward": 86.29656321000655, "episode": 117.0, "batch_reward": 0.13880652361363172, "critic_loss": 0.5954764251112938, "actor_loss": -68.1788854598999, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.454122066497803, "step": 117000}
{"episode_reward": 336.13128834861766, "episode": 118.0, "batch_reward": 0.14058012783527374, "critic_loss": 0.6126572592556476, "actor_loss": -69.25899090194702, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.247633934020996, "step": 118000}
{"episode_reward": 559.667467456525, "episode": 119.0, "batch_reward": 0.1419956518933177, "critic_loss": 0.6723422480225563, "actor_loss": -69.48789596748352, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.101229906082153, "step": 119000}
{"episode_reward": 78.8450794484025, "episode": 120.0, "batch_reward": 0.14227338483929633, "critic_loss": 0.6757270825207233, "actor_loss": -68.76840006256103, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.19992446899414, "step": 120000}
{"episode_reward": 514.4025515011954, "episode": 121.0, "batch_reward": 0.14563974764943122, "critic_loss": 0.7320960133373737, "actor_loss": -67.3468700351715, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.16415858268738, "step": 121000}
{"episode_reward": 629.3053229690208, "episode": 122.0, "batch_reward": 0.14825901988893747, "critic_loss": 0.7056365797817707, "actor_loss": -68.15226259613037, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.529492378234863, "step": 122000}
{"episode_reward": 189.50346575501405, "episode": 123.0, "batch_reward": 0.14862514626234768, "critic_loss": 0.6989137243032455, "actor_loss": -66.12413022613525, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.938445568084717, "step": 123000}
{"episode_reward": 89.14353645924002, "episode": 124.0, "batch_reward": 0.15015452900528908, "critic_loss": 0.6754579153954983, "actor_loss": -67.74126852035522, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.0627019405365, "step": 124000}
{"episode_reward": 514.350576302821, "episode": 125.0, "batch_reward": 0.1522523951306939, "critic_loss": 0.7254085194766522, "actor_loss": -67.25643480491638, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.972284078598022, "step": 125000}
{"episode_reward": 612.0156041674225, "episode": 126.0, "batch_reward": 0.1557597607076168, "critic_loss": 0.7538751062750816, "actor_loss": -66.03584999656677, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.70455288887024, "step": 126000}
{"episode_reward": 503.875384048847, "episode": 127.0, "batch_reward": 0.1563941890001297, "critic_loss": 0.7770793473124504, "actor_loss": -68.62259159469605, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.119126796722412, "step": 127000}
{"episode_reward": 335.1322838141966, "episode": 128.0, "batch_reward": 0.15703481222689153, "critic_loss": 0.7874589042961597, "actor_loss": -70.39546168518066, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.044816493988037, "step": 128000}
{"episode_reward": 98.70895115237904, "episode": 129.0, "batch_reward": 0.159691819421947, "critic_loss": 0.7825193371474742, "actor_loss": -68.92200214385986, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.84807300567627, "step": 129000}
{"episode_reward": 563.5599121352495, "episode": 130.0, "batch_reward": 0.16297345981001854, "critic_loss": 0.8165165618062019, "actor_loss": -68.68341142845154, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.45903968811035, "step": 130000}
{"episode_reward": 588.0158531651958, "episode": 131.0, "batch_reward": 0.16581576772779227, "critic_loss": 0.8265198980867863, "actor_loss": -70.11118131637573, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.31145405769348, "step": 131000}
{"episode_reward": 445.0401305652764, "episode": 132.0, "batch_reward": 0.16783403818309306, "critic_loss": 0.8880754152536392, "actor_loss": -69.81122518157959, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.520066022872925, "step": 132000}
{"episode_reward": 286.18525933337463, "episode": 133.0, "batch_reward": 0.16712925209105015, "critic_loss": 0.8893279405534268, "actor_loss": -69.00194503974915, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.927266836166382, "step": 133000}
{"episode_reward": 74.36232540557059, "episode": 134.0, "batch_reward": 0.16554234318435193, "critic_loss": 0.9173694783449173, "actor_loss": -69.75392842483521, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.801440954208374, "step": 134000}
{"episode_reward": 39.763481790013344, "episode": 135.0, "batch_reward": 0.1671799805611372, "critic_loss": 0.9162283391058444, "actor_loss": -69.27059452056885, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.617326736450195, "step": 135000}
{"episode_reward": 581.8938769913841, "episode": 136.0, "batch_reward": 0.17154847011715174, "critic_loss": 0.9242944875061512, "actor_loss": -71.3300447216034, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.922948360443115, "step": 136000}
{"episode_reward": 605.4572410517109, "episode": 137.0, "batch_reward": 0.17383052423596382, "critic_loss": 0.9311881266534329, "actor_loss": -69.70913597106933, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.64163565635681, "step": 137000}
{"episode_reward": 622.1062372348908, "episode": 138.0, "batch_reward": 0.17565956002473831, "critic_loss": 0.9766015447080135, "actor_loss": -66.43558264160156, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.108848333358765, "step": 138000}
{"episode_reward": 240.11471039947045, "episode": 139.0, "batch_reward": 0.17638780785351993, "critic_loss": 0.9612139022052288, "actor_loss": -67.47972085380555, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.83085799217224, "step": 139000}
{"episode_reward": 85.77913198985212, "episode": 140.0, "batch_reward": 0.17384452249854804, "critic_loss": 0.9607025420963764, "actor_loss": -66.21299366760253, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.54712414741516, "step": 140000}
{"episode_reward": 100.42184305650207, "episode": 141.0, "batch_reward": 0.17458356668800115, "critic_loss": 0.9933737886250019, "actor_loss": -67.31713695144653, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.00334811210632, "step": 141000}
{"episode_reward": 88.31157964717256, "episode": 142.0, "batch_reward": 0.17494280173629523, "critic_loss": 1.012774821072817, "actor_loss": -67.85258857727051, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.546793937683105, "step": 142000}
{"episode_reward": 473.2971911249153, "episode": 143.0, "batch_reward": 0.17851920272409916, "critic_loss": 1.014049225270748, "actor_loss": -69.02021950340271, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.945462703704834, "step": 143000}
{"episode_reward": 638.5403376716956, "episode": 144.0, "batch_reward": 0.18121742227673532, "critic_loss": 1.0228975889384746, "actor_loss": -68.67150585174561, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.07373070716858, "step": 144000}
{"episode_reward": 603.0162313822312, "episode": 145.0, "batch_reward": 0.18294409919530152, "critic_loss": 1.1680609868168832, "actor_loss": -68.16163021659851, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.216033220291138, "step": 145000}
{"episode_reward": 508.43159006954994, "episode": 146.0, "batch_reward": 0.18365935802459718, "critic_loss": 1.2895234140157699, "actor_loss": -67.76738726425171, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.705002784729004, "step": 146000}
{"episode_reward": 17.26348321001469, "episode": 147.0, "batch_reward": 0.1845016696304083, "critic_loss": 1.4250671586990356, "actor_loss": -70.07878108978271, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.460402727127075, "step": 147000}
{"episode_reward": 556.6069773043855, "episode": 148.0, "batch_reward": 0.1869112101495266, "critic_loss": 1.4291349053680897, "actor_loss": -68.60397086143493, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.97999405860901, "step": 148000}
{"episode_reward": 612.436530067661, "episode": 149.0, "batch_reward": 0.19073466210067272, "critic_loss": 1.3845622516274452, "actor_loss": -69.70339251899719, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.663520097732544, "step": 149000}
{"episode_reward": 545.2328462770124, "episode": 150.0, "batch_reward": 0.1935890655964613, "critic_loss": 1.2578822246193886, "actor_loss": -68.2366613960266, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "step": 150000}
