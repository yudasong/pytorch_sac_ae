{"episode_reward": 0.0, "episode": 1.0, "duration": 22.057791233062744, "step": 1000}
{"episode_reward": 28.177075776326152, "episode": 2.0, "duration": 1.8616273403167725, "step": 2000}
{"episode_reward": 69.84046218736019, "episode": 3.0, "batch_reward": 0.04844066712951891, "critic_loss": 0.13619125395995868, "actor_loss": -76.3212883938976, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499180007, "duration": 64.00172448158264, "step": 3000}
{"episode_reward": 34.77443244579385, "episode": 4.0, "batch_reward": 0.0409521145708859, "critic_loss": 0.13403425022214652, "actor_loss": -70.22424322509765, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.5749831199646, "step": 4000}
{"episode_reward": 16.994675363142015, "episode": 5.0, "batch_reward": 0.038200578724965455, "critic_loss": 0.12941197672858834, "actor_loss": -68.00457286071777, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.239179849624634, "step": 5000}
{"episode_reward": 37.225348442677785, "episode": 6.0, "batch_reward": 0.03978628578782081, "critic_loss": 0.12969973708316684, "actor_loss": -67.06732235717773, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.85508108139038, "step": 6000}
{"episode_reward": 61.80319905245811, "episode": 7.0, "batch_reward": 0.048787211254239085, "critic_loss": 0.20414787525683642, "actor_loss": -67.03337236022949, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.897945642471313, "step": 7000}
{"episode_reward": 99.75715732709803, "episode": 8.0, "batch_reward": 0.0494008709192276, "critic_loss": 0.18674240879714488, "actor_loss": -66.53751537322998, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.71039342880249, "step": 8000}
{"episode_reward": 42.238874643901156, "episode": 9.0, "batch_reward": 0.049332189176231625, "critic_loss": 0.15098711032047868, "actor_loss": -66.3676234664917, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.872891187667847, "step": 9000}
{"episode_reward": 56.2862747338012, "episode": 10.0, "batch_reward": 0.048324834425002336, "critic_loss": 0.14416778337955474, "actor_loss": -65.10335092163086, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.035813093185425, "step": 10000}
{"episode_reward": 23.25473290675742, "episode": 11.0, "batch_reward": 0.04576263210549951, "critic_loss": 0.13521927289292215, "actor_loss": -64.63881435394288, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.09629797935486, "step": 11000}
{"episode_reward": 21.932461926998364, "episode": 12.0, "batch_reward": 0.04324731319583953, "critic_loss": 0.1180726057291031, "actor_loss": -62.951741790771486, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.590796947479248, "step": 12000}
{"episode_reward": 10.835693635298743, "episode": 13.0, "batch_reward": 0.040733954662457106, "critic_loss": 0.11565874592214823, "actor_loss": -62.107889472961425, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.4542293548584, "step": 13000}
{"episode_reward": 19.089977481233056, "episode": 14.0, "batch_reward": 0.039191762283444405, "critic_loss": 0.11775215908512474, "actor_loss": -60.856577209472654, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.145060300827026, "step": 14000}
{"episode_reward": 14.268590149230915, "episode": 15.0, "batch_reward": 0.04378209519386291, "critic_loss": 0.14331957228854297, "actor_loss": -59.981028114318846, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.7135169506073, "step": 15000}
{"episode_reward": 135.1733818921294, "episode": 16.0, "batch_reward": 0.047272732129320504, "critic_loss": 0.16706604116410018, "actor_loss": -59.5125542755127, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.49823784828186, "step": 16000}
{"episode_reward": 84.70057916063075, "episode": 17.0, "batch_reward": 0.04751798735558987, "critic_loss": 0.1327283546254039, "actor_loss": -58.335149093627926, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.21729016304016, "step": 17000}
{"episode_reward": 40.174951514430674, "episode": 18.0, "batch_reward": 0.04660504349693656, "critic_loss": 0.16536838939785958, "actor_loss": -57.76789392852783, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.658066511154175, "step": 18000}
{"episode_reward": 23.84232424571854, "episode": 19.0, "batch_reward": 0.04579180128872395, "critic_loss": 0.17845624868571758, "actor_loss": -58.971599327087404, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.447474718093872, "step": 19000}
{"episode_reward": 52.17926955852732, "episode": 20.0, "batch_reward": 0.04697558918595314, "critic_loss": 0.16433618034422398, "actor_loss": -58.31707872009277, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.505531311035156, "step": 20000}
{"episode_reward": 73.43487350667641, "episode": 21.0, "batch_reward": 0.04633372624404728, "critic_loss": 0.13869842125475407, "actor_loss": -58.19046349334717, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.11340880393982, "step": 21000}
{"episode_reward": 21.103055481630587, "episode": 22.0, "batch_reward": 0.04741833723708987, "critic_loss": 0.12141738917306065, "actor_loss": -57.02595639038086, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.970511198043823, "step": 22000}
{"episode_reward": 88.1074327209072, "episode": 23.0, "batch_reward": 0.047263165524229406, "critic_loss": 0.11333666501566768, "actor_loss": -55.23423534393311, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.90863800048828, "step": 23000}
{"episode_reward": 23.108721157381964, "episode": 24.0, "batch_reward": 0.046497734799981115, "critic_loss": 0.11000520299002528, "actor_loss": -54.373380966186524, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.00829029083252, "step": 24000}
{"episode_reward": 24.1303138094789, "episode": 25.0, "batch_reward": 0.045343241408467294, "critic_loss": 0.08723452957719564, "actor_loss": -53.72516714477539, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.804879188537598, "step": 25000}
{"episode_reward": 23.511836409254148, "episode": 26.0, "batch_reward": 0.04446665770560503, "critic_loss": 0.07665990284085274, "actor_loss": -52.44031895446777, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.787002325057983, "step": 26000}
{"episode_reward": 13.739608581753155, "episode": 27.0, "batch_reward": 0.04378510817699134, "critic_loss": 0.06984022112190723, "actor_loss": -51.362809844970705, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.55710506439209, "step": 27000}
{"episode_reward": 22.79072035915434, "episode": 28.0, "batch_reward": 0.04249808583036065, "critic_loss": 0.07301152108982205, "actor_loss": -50.54403514862061, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.44934844970703, "step": 28000}
{"episode_reward": 15.496076731873444, "episode": 29.0, "batch_reward": 0.041582104234024884, "critic_loss": 0.06613665358163416, "actor_loss": -49.78641095733643, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.610802173614502, "step": 29000}
{"episode_reward": 16.712703886903366, "episode": 30.0, "batch_reward": 0.041636011010035875, "critic_loss": 0.06545819535665214, "actor_loss": -48.94479488372803, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.213597774505615, "step": 30000}
{"episode_reward": 50.00824317947356, "episode": 31.0, "batch_reward": 0.04138299538753927, "critic_loss": 0.06643106509372591, "actor_loss": -47.81601515197754, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.34089922904968, "step": 31000}
{"episode_reward": 15.509450426506548, "episode": 32.0, "batch_reward": 0.04211643843352795, "critic_loss": 0.08187872939184308, "actor_loss": -46.92676402282715, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.467785358428955, "step": 32000}
{"episode_reward": 109.7184977351458, "episode": 33.0, "batch_reward": 0.04234474322758615, "critic_loss": 0.07934462955594063, "actor_loss": -46.099559951782226, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.469635725021362, "step": 33000}
{"episode_reward": 22.4062472697426, "episode": 34.0, "batch_reward": 0.043093682624399665, "critic_loss": 0.07998302729427814, "actor_loss": -44.03862703704834, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.08188557624817, "step": 34000}
{"episode_reward": 90.6014627858323, "episode": 35.0, "batch_reward": 0.04559175902605057, "critic_loss": 0.07729057233594358, "actor_loss": -44.55463380432129, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.933935403823853, "step": 35000}
{"episode_reward": 185.34687942494196, "episode": 36.0, "batch_reward": 0.04756554875150323, "critic_loss": 0.07773595682531595, "actor_loss": -44.47119797515869, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.76486611366272, "step": 36000}
{"episode_reward": 15.543961348996199, "episode": 37.0, "batch_reward": 0.047100118538364766, "critic_loss": 0.07530648498050868, "actor_loss": -42.85801845550537, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.59449863433838, "step": 37000}
{"episode_reward": 51.25177705129582, "episode": 38.0, "batch_reward": 0.046909087862819436, "critic_loss": 0.05898039419949055, "actor_loss": -42.31631707763672, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.885892868041992, "step": 38000}
{"episode_reward": 54.20125541882104, "episode": 39.0, "batch_reward": 0.047647441372275355, "critic_loss": 0.06194566232897341, "actor_loss": -42.936062591552734, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.939817428588867, "step": 39000}
{"episode_reward": 73.8213481723786, "episode": 40.0, "batch_reward": 0.05052976867556572, "critic_loss": 0.059551916221156714, "actor_loss": -41.78989679718018, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.492761850357056, "step": 40000}
{"episode_reward": 236.40954584746126, "episode": 41.0, "batch_reward": 0.055021090075373646, "critic_loss": 0.0662361207511276, "actor_loss": -41.2852078590393, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.72669196128845, "step": 41000}
{"episode_reward": 145.27471631876824, "episode": 42.0, "batch_reward": 0.05495398654788732, "critic_loss": 0.06948926698789, "actor_loss": -38.73545877456665, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.494410276412964, "step": 42000}
{"episode_reward": 67.28143193336236, "episode": 43.0, "batch_reward": 0.0587083871550858, "critic_loss": 0.08864123601838947, "actor_loss": -38.85610592651367, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.613368272781372, "step": 43000}
{"episode_reward": 367.58691728972957, "episode": 44.0, "batch_reward": 0.06451411819830537, "critic_loss": 0.10176919417083263, "actor_loss": -38.367065284729, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.85915970802307, "step": 44000}
{"episode_reward": 317.3872124926896, "episode": 45.0, "batch_reward": 0.06891449754312634, "critic_loss": 0.11680429881811141, "actor_loss": -38.972075366973876, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.79010033607483, "step": 45000}
{"episode_reward": 101.41100670142045, "episode": 46.0, "batch_reward": 0.06746577915176749, "critic_loss": 0.12035231718048453, "actor_loss": -38.80951510238648, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.781439065933228, "step": 46000}
{"episode_reward": 15.764376340891266, "episode": 47.0, "batch_reward": 0.0676537564098835, "critic_loss": 0.11839995142817497, "actor_loss": -36.96809517288208, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.96061897277832, "step": 47000}
{"episode_reward": 74.17388195738155, "episode": 48.0, "batch_reward": 0.06814252831041813, "critic_loss": 0.12694842200353743, "actor_loss": -35.45447300338745, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.136128664016724, "step": 48000}
{"episode_reward": 82.69811318187857, "episode": 49.0, "batch_reward": 0.07149445272609592, "critic_loss": 0.14010839180275797, "actor_loss": -36.73101327133179, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.440343379974365, "step": 49000}
{"episode_reward": 409.76320491867807, "episode": 50.0, "batch_reward": 0.07962634154036641, "critic_loss": 0.15915427858382464, "actor_loss": -36.200491443634036, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.226335048675537, "step": 50000}
{"episode_reward": 432.5837464834654, "episode": 51.0, "batch_reward": 0.08490091449767351, "critic_loss": 0.14757294235378504, "actor_loss": -35.00929122161865, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.1762797832489, "step": 51000}
{"episode_reward": 413.1402178929943, "episode": 52.0, "batch_reward": 0.08789362420886755, "critic_loss": 0.13887905990704894, "actor_loss": -37.25646926498413, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.563488245010376, "step": 52000}
{"episode_reward": 64.01258507230526, "episode": 53.0, "batch_reward": 0.09138797736912965, "critic_loss": 0.1481574868634343, "actor_loss": -36.26323710250855, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.176212072372437, "step": 53000}
{"episode_reward": 405.7466857402784, "episode": 54.0, "batch_reward": 0.09732865114882588, "critic_loss": 0.16626841466873885, "actor_loss": -34.211060817718504, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.60391855239868, "step": 54000}
{"episode_reward": 483.37651917247246, "episode": 55.0, "batch_reward": 0.10138496284559369, "critic_loss": 0.17554992712289094, "actor_loss": -34.4103461227417, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.447307109832764, "step": 55000}
{"episode_reward": 72.7595588666909, "episode": 56.0, "batch_reward": 0.1046983260512352, "critic_loss": 0.17281089525297283, "actor_loss": -34.49714984893799, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.087209701538086, "step": 56000}
{"episode_reward": 487.87674536918576, "episode": 57.0, "batch_reward": 0.10806264777481556, "critic_loss": 0.1921989165917039, "actor_loss": -36.341240985870364, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.638811349868774, "step": 57000}
{"episode_reward": 82.31810998925107, "episode": 58.0, "batch_reward": 0.10829767993837595, "critic_loss": 0.2015344995483756, "actor_loss": -33.67739839553833, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.474518060684204, "step": 58000}
{"episode_reward": 98.05633937575645, "episode": 59.0, "batch_reward": 0.1097258293479681, "critic_loss": 0.2165450790449977, "actor_loss": -36.50122911834717, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.462233543395996, "step": 59000}
{"episode_reward": 502.05013301987736, "episode": 60.0, "batch_reward": 0.11786470326781273, "critic_loss": 0.22757419608533383, "actor_loss": -37.09627848434448, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.497877836227417, "step": 60000}
{"episode_reward": 543.2576416120037, "episode": 61.0, "batch_reward": 0.12108237149566412, "critic_loss": 0.23291262831538917, "actor_loss": -34.83133963394165, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.46949362754822, "step": 61000}
{"episode_reward": 106.16959888847364, "episode": 62.0, "batch_reward": 0.12159859742224216, "critic_loss": 0.24257990971207619, "actor_loss": -34.43391271209717, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.000272035598755, "step": 62000}
{"episode_reward": 131.81648380012118, "episode": 63.0, "batch_reward": 0.12003334508836269, "critic_loss": 0.2587346432879567, "actor_loss": -36.66882137298584, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.956378698349, "step": 63000}
{"episode_reward": 23.468406205753855, "episode": 64.0, "batch_reward": 0.1194873813316226, "critic_loss": 0.2732194775566459, "actor_loss": -35.84491259002686, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.462228536605835, "step": 64000}
{"episode_reward": 91.13373912012875, "episode": 65.0, "batch_reward": 0.11766255392879248, "critic_loss": 0.26061420944333075, "actor_loss": -35.8690305557251, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.740787982940674, "step": 65000}
{"episode_reward": 42.8792612547869, "episode": 66.0, "batch_reward": 0.12089865786582231, "critic_loss": 0.2490525470301509, "actor_loss": -36.90287166595459, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.71316885948181, "step": 66000}
{"episode_reward": 497.32356489026245, "episode": 67.0, "batch_reward": 0.12782762207090856, "critic_loss": 0.2670296004042029, "actor_loss": -37.522739524841306, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.504993200302124, "step": 67000}
{"episode_reward": 523.9212905476361, "episode": 68.0, "batch_reward": 0.12927560989558698, "critic_loss": 0.25633988393098117, "actor_loss": -36.442737701416014, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.262462377548218, "step": 68000}
{"episode_reward": 67.37038502422038, "episode": 69.0, "batch_reward": 0.1308705664947629, "critic_loss": 0.25424638805538413, "actor_loss": -36.97616352462769, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.866533756256104, "step": 69000}
{"episode_reward": 533.2156145407955, "episode": 70.0, "batch_reward": 0.13737375371903182, "critic_loss": 0.2539508250132203, "actor_loss": -37.455730926513674, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.51572895050049, "step": 70000}
{"episode_reward": 555.6579163462837, "episode": 71.0, "batch_reward": 0.1407001442760229, "critic_loss": 0.2586982682943344, "actor_loss": -37.038889381408694, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.06083917617798, "step": 71000}
{"episode_reward": 96.03116025302106, "episode": 72.0, "batch_reward": 0.142794776879251, "critic_loss": 0.2720789489597082, "actor_loss": -37.727934120178226, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.827311038970947, "step": 72000}
{"episode_reward": 535.7666938167351, "episode": 73.0, "batch_reward": 0.14860986310243607, "critic_loss": 0.2557215694114566, "actor_loss": -37.882626586914064, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.655850887298584, "step": 73000}
{"episode_reward": 577.5904755710998, "episode": 74.0, "batch_reward": 0.1538653910011053, "critic_loss": 0.25741013188660145, "actor_loss": -38.212707077026366, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.925862550735474, "step": 74000}
{"episode_reward": 566.1302860622363, "episode": 75.0, "batch_reward": 0.16009346648305656, "critic_loss": 0.2606578848287463, "actor_loss": -37.67613692855835, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.755544900894165, "step": 75000}
{"episode_reward": 576.076486543788, "episode": 76.0, "batch_reward": 0.1636488806679845, "critic_loss": 0.26148418701440096, "actor_loss": -37.126393077850345, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.47023057937622, "step": 76000}
{"episode_reward": 531.4078698598506, "episode": 77.0, "batch_reward": 0.1668938318863511, "critic_loss": 0.26994300992786885, "actor_loss": -38.552743766784666, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.317403316497803, "step": 77000}
{"episode_reward": 16.914640365884775, "episode": 78.0, "batch_reward": 0.16825710836052896, "critic_loss": 0.2817182110995054, "actor_loss": -38.92502918243408, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.567749738693237, "step": 78000}
{"episode_reward": 383.12189431309577, "episode": 79.0, "batch_reward": 0.16712882185727357, "critic_loss": 0.2917350492924452, "actor_loss": -37.991477241516115, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.501550912857056, "step": 79000}
{"episode_reward": 18.17128215073396, "episode": 80.0, "batch_reward": 0.16603139688819646, "critic_loss": 0.30452060598134995, "actor_loss": -37.33618621444702, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.68831706047058, "step": 80000}
{"episode_reward": 26.92702672593546, "episode": 81.0, "batch_reward": 0.1673873532935977, "critic_loss": 0.32667342737317084, "actor_loss": -39.29102522659302, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.91193461418152, "step": 81000}
{"episode_reward": 598.2227590654462, "episode": 82.0, "batch_reward": 0.16987563610821962, "critic_loss": 0.3488134992271662, "actor_loss": -37.98667226791382, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.493024349212646, "step": 82000}
{"episode_reward": 90.8042383639545, "episode": 83.0, "batch_reward": 0.17134307789057493, "critic_loss": 0.3676195143535733, "actor_loss": -38.817290458679196, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.646481037139893, "step": 83000}
{"episode_reward": 540.9200725301068, "episode": 84.0, "batch_reward": 0.1755902009829879, "critic_loss": 0.36820239320397374, "actor_loss": -39.44644089126587, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.607364654541016, "step": 84000}
{"episode_reward": 581.4057879550364, "episode": 85.0, "batch_reward": 0.18030944324284792, "critic_loss": 0.37532966051995753, "actor_loss": -38.637143249511716, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.457004070281982, "step": 85000}
{"episode_reward": 565.823540134076, "episode": 86.0, "batch_reward": 0.18516528497636317, "critic_loss": 0.37336184456944466, "actor_loss": -39.098677501678466, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.208714723587036, "step": 86000}
{"episode_reward": 611.8773941141941, "episode": 87.0, "batch_reward": 0.18911945796757937, "critic_loss": 0.38864487297832967, "actor_loss": -38.786786003112795, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.91884136199951, "step": 87000}
{"episode_reward": 648.2250954803695, "episode": 88.0, "batch_reward": 0.19480337724089622, "critic_loss": 0.4008852878510952, "actor_loss": -39.25546923828125, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.63288688659668, "step": 88000}
{"episode_reward": 700.505938261129, "episode": 89.0, "batch_reward": 0.20154621307551862, "critic_loss": 0.4004203531593084, "actor_loss": -40.18134811401367, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.461955547332764, "step": 89000}
{"episode_reward": 641.4523741588498, "episode": 90.0, "batch_reward": 0.20494306651502847, "critic_loss": 0.39706375604867933, "actor_loss": -41.06497040557861, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.70406746864319, "step": 90000}
{"episode_reward": 474.0265671704038, "episode": 91.0, "batch_reward": 0.2092307679206133, "critic_loss": 0.3839194152057171, "actor_loss": -40.52275410079956, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.170777797698975, "step": 91000}
{"episode_reward": 649.0197330834255, "episode": 92.0, "batch_reward": 0.2091664609760046, "critic_loss": 0.3847660721987486, "actor_loss": -41.10063425827026, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.237847328186035, "step": 92000}
{"episode_reward": 66.14964289001057, "episode": 93.0, "batch_reward": 0.21133974973857403, "critic_loss": 0.4197531037181616, "actor_loss": -40.28203232574463, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.884581804275513, "step": 93000}
{"episode_reward": 673.1769720131501, "episode": 94.0, "batch_reward": 0.21337744880467654, "critic_loss": 0.4315483828485012, "actor_loss": -41.53166924285889, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.638479948043823, "step": 94000}
{"episode_reward": 81.3456568145593, "episode": 95.0, "batch_reward": 0.21165341512858868, "critic_loss": 0.41595910939574243, "actor_loss": -42.81602920150757, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.462416172027588, "step": 95000}
{"episode_reward": 64.5567228296316, "episode": 96.0, "batch_reward": 0.21074245443940162, "critic_loss": 0.42703687623143194, "actor_loss": -42.106703659057615, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.800485372543335, "step": 96000}
{"episode_reward": 67.69450644192614, "episode": 97.0, "batch_reward": 0.21180280168354512, "critic_loss": 0.4426816848069429, "actor_loss": -42.41239362716675, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.60589075088501, "step": 97000}
{"episode_reward": 656.6418893504082, "episode": 98.0, "batch_reward": 0.21692942748963834, "critic_loss": 0.45699934197962283, "actor_loss": -42.9814822807312, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.489482402801514, "step": 98000}
{"episode_reward": 347.5359967045073, "episode": 99.0, "batch_reward": 0.218740358710289, "critic_loss": 0.48270042787492273, "actor_loss": -42.86799839401245, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.05363368988037, "step": 99000}
{"episode_reward": 720.9017358092638, "episode": 100.0, "batch_reward": 0.2248402600735426, "critic_loss": 0.5178695638030767, "actor_loss": -43.41319500350952, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.79080629348755, "step": 100000}
{"episode_reward": 687.0935758737992, "episode": 101.0, "batch_reward": 0.22748999513685703, "critic_loss": 0.5494173967838287, "actor_loss": -44.43638921737671, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.366029500961304, "step": 101000}
{"episode_reward": 724.2730462634402, "episode": 102.0, "batch_reward": 0.2321993110626936, "critic_loss": 0.5974203636944294, "actor_loss": -45.44400120544434, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.589755058288574, "step": 102000}
{"episode_reward": 761.2750451537131, "episode": 103.0, "batch_reward": 0.23432031358778477, "critic_loss": 0.6062795214056969, "actor_loss": -45.84215845489502, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.31367802619934, "step": 103000}
{"episode_reward": 22.229873161559563, "episode": 104.0, "batch_reward": 0.23837996678054332, "critic_loss": 0.5874975824058056, "actor_loss": -45.55467435455322, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.48090362548828, "step": 104000}
{"episode_reward": 710.9643997265281, "episode": 105.0, "batch_reward": 0.2418112278133631, "critic_loss": 0.5799290927350521, "actor_loss": -45.863574935913086, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.41024136543274, "step": 105000}
{"episode_reward": 683.696812191121, "episode": 106.0, "batch_reward": 0.24400595785677434, "critic_loss": 0.5565353997051716, "actor_loss": -45.66348366546631, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.774765968322754, "step": 106000}
{"episode_reward": 680.763675630229, "episode": 107.0, "batch_reward": 0.24825027523934842, "critic_loss": 0.5811873731464148, "actor_loss": -47.16989588928222, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.53252935409546, "step": 107000}
{"episode_reward": 697.6576188842224, "episode": 108.0, "batch_reward": 0.2506120087057352, "critic_loss": 0.5724299081563949, "actor_loss": -48.760736236572264, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.56676983833313, "step": 108000}
{"episode_reward": 106.61513633608628, "episode": 109.0, "batch_reward": 0.2512327126562595, "critic_loss": 0.5824954845905304, "actor_loss": -48.72060411071777, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.0220787525177, "step": 109000}
{"episode_reward": 80.13614170409868, "episode": 110.0, "batch_reward": 0.25136106254160406, "critic_loss": 0.5647590108811855, "actor_loss": -48.78448139190674, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.447622776031494, "step": 110000}
{"episode_reward": 727.9909285489855, "episode": 111.0, "batch_reward": 0.25488877822458744, "critic_loss": 0.5536138499528169, "actor_loss": -49.87021525573731, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.981581926345825, "step": 111000}
{"episode_reward": 689.6214006366741, "episode": 112.0, "batch_reward": 0.25900503249466417, "critic_loss": 0.5422598159015178, "actor_loss": -49.0642762298584, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.68162703514099, "step": 112000}
{"episode_reward": 808.1486247152076, "episode": 113.0, "batch_reward": 0.2610434636622667, "critic_loss": 0.5617095117270946, "actor_loss": -49.03270902252197, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.51609992980957, "step": 113000}
{"episode_reward": 88.39719010613351, "episode": 114.0, "batch_reward": 0.2623904416114092, "critic_loss": 0.52771193651855, "actor_loss": -49.61349778747559, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.946866750717163, "step": 114000}
{"episode_reward": 782.0462307551048, "episode": 115.0, "batch_reward": 0.2666245538443327, "critic_loss": 0.5600240341126919, "actor_loss": -49.67226205444336, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.824557065963745, "step": 115000}
{"episode_reward": 727.5703150642794, "episode": 116.0, "batch_reward": 0.26894343954324723, "critic_loss": 0.5730707635134459, "actor_loss": -49.99674322509765, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.509960174560547, "step": 116000}
{"episode_reward": 120.93251465969959, "episode": 117.0, "batch_reward": 0.2716389629244804, "critic_loss": 0.5761939035952092, "actor_loss": -50.193244041442874, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.779632568359375, "step": 117000}
{"episode_reward": 765.5370402508346, "episode": 118.0, "batch_reward": 0.2741567803323269, "critic_loss": 0.5863265645503998, "actor_loss": -49.99293553924561, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.98702836036682, "step": 118000}
{"episode_reward": 780.9987148785991, "episode": 119.0, "batch_reward": 0.27619295789301396, "critic_loss": 0.5986958218812942, "actor_loss": -49.950636459350584, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.518758296966553, "step": 119000}
{"episode_reward": 129.258227343155, "episode": 120.0, "batch_reward": 0.2764781875312328, "critic_loss": 0.5936574795544147, "actor_loss": -49.356322967529294, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.941630125045776, "step": 120000}
{"episode_reward": 685.4824079104034, "episode": 121.0, "batch_reward": 0.2818958507925272, "critic_loss": 0.6271362842917443, "actor_loss": -50.62770167541504, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.64032554626465, "step": 121000}
{"episode_reward": 753.9215003102579, "episode": 122.0, "batch_reward": 0.2856326577812433, "critic_loss": 0.6173498971164226, "actor_loss": -50.81780564117432, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.794111490249634, "step": 122000}
{"episode_reward": 776.4081543474783, "episode": 123.0, "batch_reward": 0.2859100348204374, "critic_loss": 0.6292577636986971, "actor_loss": -50.73175106811524, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.172075748443604, "step": 123000}
{"episode_reward": 95.8232853312355, "episode": 124.0, "batch_reward": 0.2869626909792423, "critic_loss": 0.6283330214619637, "actor_loss": -51.011565750122074, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.022059679031372, "step": 124000}
{"episode_reward": 772.7366184465533, "episode": 125.0, "batch_reward": 0.2920757708996534, "critic_loss": 0.6284166920781136, "actor_loss": -51.57537770080567, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.473355770111084, "step": 125000}
{"episode_reward": 790.400103220591, "episode": 126.0, "batch_reward": 0.2948362814337015, "critic_loss": 0.6452173604667186, "actor_loss": -52.2691392288208, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.926783084869385, "step": 126000}
{"episode_reward": 882.7575601652076, "episode": 127.0, "batch_reward": 0.2989277481883764, "critic_loss": 0.6508245140016079, "actor_loss": -52.80948119354248, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.909468173980713, "step": 127000}
{"episode_reward": 802.4364273622135, "episode": 128.0, "batch_reward": 0.30191124947369097, "critic_loss": 0.663702166095376, "actor_loss": -52.98487328338623, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.48928189277649, "step": 128000}
{"episode_reward": 607.0175196408583, "episode": 129.0, "batch_reward": 0.3051786718964577, "critic_loss": 0.6650655618607998, "actor_loss": -54.2420179977417, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.811384916305542, "step": 129000}
{"episode_reward": 774.6538092381163, "episode": 130.0, "batch_reward": 0.308105997890234, "critic_loss": 0.675308430582285, "actor_loss": -53.66222339630127, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.96665072441101, "step": 130000}
{"episode_reward": 788.4194626307269, "episode": 131.0, "batch_reward": 0.31332256737351416, "critic_loss": 0.7019757938086987, "actor_loss": -53.91907772064209, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.72008919715881, "step": 131000}
{"episode_reward": 850.1772379960302, "episode": 132.0, "batch_reward": 0.31744887767732144, "critic_loss": 0.7331014907062053, "actor_loss": -53.632396377563474, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.98830270767212, "step": 132000}
{"episode_reward": 824.2974905470527, "episode": 133.0, "batch_reward": 0.3204269435554743, "critic_loss": 0.7346754094362259, "actor_loss": -54.73303192138672, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.63621187210083, "step": 133000}
{"episode_reward": 805.7734148948801, "episode": 134.0, "batch_reward": 0.3232554365247488, "critic_loss": 0.7768497332334519, "actor_loss": -54.8138201675415, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.697652578353882, "step": 134000}
{"episode_reward": 666.1036430379862, "episode": 135.0, "batch_reward": 0.32646548908948897, "critic_loss": 0.7547396976947784, "actor_loss": -54.25654839324951, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.929097652435303, "step": 135000}
{"episode_reward": 863.3185895451537, "episode": 136.0, "batch_reward": 0.3319958966374397, "critic_loss": 0.7820839948058128, "actor_loss": -56.01387505340576, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.943776607513428, "step": 136000}
{"episode_reward": 878.9484998483891, "episode": 137.0, "batch_reward": 0.33570518258214, "critic_loss": 0.7933131482601166, "actor_loss": -54.6799557723999, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.490795850753784, "step": 137000}
{"episode_reward": 845.0776117007814, "episode": 138.0, "batch_reward": 0.3380190076828003, "critic_loss": 0.8108797280788421, "actor_loss": -54.987586196899414, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.54911756515503, "step": 138000}
{"episode_reward": 803.1423900238983, "episode": 139.0, "batch_reward": 0.3426166473329067, "critic_loss": 0.8404635510742664, "actor_loss": -56.451598289489745, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.68108105659485, "step": 139000}
{"episode_reward": 825.5907813609143, "episode": 140.0, "batch_reward": 0.344500396117568, "critic_loss": 0.8968085337877274, "actor_loss": -56.69062515258789, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.558932542800903, "step": 140000}
{"episode_reward": 787.0863510605874, "episode": 141.0, "batch_reward": 0.3453770482242107, "critic_loss": 0.8950594726204872, "actor_loss": -56.746275115966796, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.00513195991516, "step": 141000}
{"episode_reward": 14.399954627810267, "episode": 142.0, "batch_reward": 0.34429194551706316, "critic_loss": 0.9368642104566097, "actor_loss": -56.22231829071045, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.469961643218994, "step": 142000}
{"episode_reward": 895.4448784777657, "episode": 143.0, "batch_reward": 0.3500848445892334, "critic_loss": 1.0636021193861962, "actor_loss": -58.244224479675296, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.16267156600952, "step": 143000}
{"episode_reward": 800.8010574945044, "episode": 144.0, "batch_reward": 0.35312940368056295, "critic_loss": 1.1822379839420318, "actor_loss": -58.881433921813965, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.352583169937134, "step": 144000}
{"episode_reward": 849.5869895889812, "episode": 145.0, "batch_reward": 0.3587166335582733, "critic_loss": 1.366994885623455, "actor_loss": -59.43990658569336, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.165070295333862, "step": 145000}
{"episode_reward": 901.5640969272032, "episode": 146.0, "batch_reward": 0.3604438954293728, "critic_loss": 1.432979254603386, "actor_loss": -60.88271128845215, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.45423460006714, "step": 146000}
{"episode_reward": 831.6075018802846, "episode": 147.0, "batch_reward": 0.3613885096013546, "critic_loss": 1.4279422575831413, "actor_loss": -62.257082061767576, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.90727686882019, "step": 147000}
{"episode_reward": 34.48525639458175, "episode": 148.0, "batch_reward": 0.36108550024032593, "critic_loss": 1.3902635177373885, "actor_loss": -63.776794425964354, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.880773305892944, "step": 148000}
{"episode_reward": 874.2955388559492, "episode": 149.0, "batch_reward": 0.36553363358974456, "critic_loss": 1.3647817698121072, "actor_loss": -64.35062827301026, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.745014667510986, "step": 149000}
{"episode_reward": 850.96059718804, "episode": 150.0, "batch_reward": 0.37088232845067975, "critic_loss": 1.267143901705742, "actor_loss": -65.84935652923583, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "step": 150000}
