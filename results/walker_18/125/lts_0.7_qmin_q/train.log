{"episode_reward": 0.0, "episode": 1.0, "duration": 23.128523349761963, "step": 1000}
{"episode_reward": 28.177075776326152, "episode": 2.0, "duration": 1.9868981838226318, "step": 2000}
{"episode_reward": 69.84046218736019, "episode": 3.0, "batch_reward": 0.04890516515983944, "critic_loss": 0.17396833261561298, "actor_loss": -77.86508631467724, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499180007, "duration": 63.81616926193237, "step": 3000}
{"episode_reward": 36.57514278087218, "episode": 4.0, "batch_reward": 0.0450817422196269, "critic_loss": 0.14630242904275656, "actor_loss": -73.27484800720215, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.712209224700928, "step": 4000}
{"episode_reward": 30.7056275266715, "episode": 5.0, "batch_reward": 0.041676599198952315, "critic_loss": 0.1222143639922142, "actor_loss": -70.54432299804688, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.183555126190186, "step": 5000}
{"episode_reward": 31.432399343714952, "episode": 6.0, "batch_reward": 0.05327793804742396, "critic_loss": 0.14995083695277572, "actor_loss": -69.89480897521973, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.45513415336609, "step": 6000}
{"episode_reward": 136.98099546047357, "episode": 7.0, "batch_reward": 0.05758371738344431, "critic_loss": 0.1092449571788311, "actor_loss": -69.96350259399414, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.00855588912964, "step": 7000}
{"episode_reward": 52.677771974537116, "episode": 8.0, "batch_reward": 0.05289820221066475, "critic_loss": 0.10790248310565949, "actor_loss": -67.78017307281495, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.38189196586609, "step": 8000}
{"episode_reward": 16.93677570617616, "episode": 9.0, "batch_reward": 0.06023126396536827, "critic_loss": 0.18602784429863095, "actor_loss": -66.84457530975342, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.16774034500122, "step": 9000}
{"episode_reward": 178.66609437030087, "episode": 10.0, "batch_reward": 0.06250867689028382, "critic_loss": 0.13768175365403296, "actor_loss": -66.20792011260987, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.496472597122192, "step": 10000}
{"episode_reward": 24.941311691995523, "episode": 11.0, "batch_reward": 0.06166442038491368, "critic_loss": 0.1426432638540864, "actor_loss": -66.24566292572021, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.21876049041748, "step": 11000}
{"episode_reward": 68.80850835415555, "episode": 12.0, "batch_reward": 0.0642168727144599, "critic_loss": 0.13679959197342395, "actor_loss": -65.13553324890137, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.25793194770813, "step": 12000}
{"episode_reward": 103.8987268823969, "episode": 13.0, "batch_reward": 0.07058715311065317, "critic_loss": 0.14474100682139396, "actor_loss": -65.24376400756836, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.34866189956665, "step": 13000}
{"episode_reward": 165.6631006644739, "episode": 14.0, "batch_reward": 0.07069329810515046, "critic_loss": 0.14496075962483884, "actor_loss": -63.57011656188965, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.45030188560486, "step": 14000}
{"episode_reward": 15.293979405442352, "episode": 15.0, "batch_reward": 0.07502066281810403, "critic_loss": 0.14294260589405894, "actor_loss": -66.24816310119628, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.124447107315063, "step": 15000}
{"episode_reward": 221.37839350273183, "episode": 16.0, "batch_reward": 0.07995507486537098, "critic_loss": 0.1555417594909668, "actor_loss": -64.58063312530517, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.793049097061157, "step": 16000}
{"episode_reward": 120.56298670151853, "episode": 17.0, "batch_reward": 0.08757593064010143, "critic_loss": 0.18020260011404754, "actor_loss": -63.091050186157226, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.400146961212158, "step": 17000}
{"episode_reward": 293.0775441915132, "episode": 18.0, "batch_reward": 0.10124662852287293, "critic_loss": 0.1850070389509201, "actor_loss": -63.418244789123534, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.39166283607483, "step": 18000}
{"episode_reward": 262.9661626904359, "episode": 19.0, "batch_reward": 0.10311862187087537, "critic_loss": 0.18052816599607469, "actor_loss": -62.59705025100708, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.14340043067932, "step": 19000}
{"episode_reward": 48.93091018606132, "episode": 20.0, "batch_reward": 0.0996710964217782, "critic_loss": 0.1672948560267687, "actor_loss": -63.306397727966306, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.153483390808105, "step": 20000}
{"episode_reward": 77.58375643661059, "episode": 21.0, "batch_reward": 0.09873496897146106, "critic_loss": 0.1531224114149809, "actor_loss": -63.54730701828003, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.82559275627136, "step": 21000}
{"episode_reward": 65.0848780479697, "episode": 22.0, "batch_reward": 0.10379828925430774, "critic_loss": 0.15507278426736593, "actor_loss": -62.43633262252808, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.207515239715576, "step": 22000}
{"episode_reward": 369.59627191063834, "episode": 23.0, "batch_reward": 0.11595950281620025, "critic_loss": 0.18332137093693018, "actor_loss": -63.4779641494751, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.129125356674194, "step": 23000}
{"episode_reward": 382.7477896449041, "episode": 24.0, "batch_reward": 0.12715843299031257, "critic_loss": 0.20570803887397052, "actor_loss": -63.36832125091553, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.69402766227722, "step": 24000}
{"episode_reward": 376.94690186391273, "episode": 25.0, "batch_reward": 0.1299608937576413, "critic_loss": 0.2140060810148716, "actor_loss": -61.16781178665161, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.164775848388672, "step": 25000}
{"episode_reward": 17.039596936844642, "episode": 26.0, "batch_reward": 0.12635095269232988, "critic_loss": 0.20153435587137938, "actor_loss": -61.66155942535401, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.220757484436035, "step": 26000}
{"episode_reward": 62.37547074096257, "episode": 27.0, "batch_reward": 0.1257113807797432, "critic_loss": 0.21157457815110683, "actor_loss": -61.932801887512205, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.55276131629944, "step": 27000}
{"episode_reward": 91.16339882454908, "episode": 28.0, "batch_reward": 0.12439524636417627, "critic_loss": 0.20309739559143783, "actor_loss": -60.492831943511966, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.127335786819458, "step": 28000}
{"episode_reward": 78.19762021359048, "episode": 29.0, "batch_reward": 0.12090583752840757, "critic_loss": 0.1883758641704917, "actor_loss": -61.816323440551756, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.1593337059021, "step": 29000}
{"episode_reward": 62.654051652620176, "episode": 30.0, "batch_reward": 0.12250421320647001, "critic_loss": 0.19349398796260356, "actor_loss": -60.208695568084714, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.067704439163208, "step": 30000}
{"episode_reward": 150.63722179098917, "episode": 31.0, "batch_reward": 0.11991794445365668, "critic_loss": 0.18756141754984856, "actor_loss": -61.35707026672363, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.865153312683105, "step": 31000}
{"episode_reward": 23.474797095556163, "episode": 32.0, "batch_reward": 0.12233252084255218, "critic_loss": 0.19993325820565225, "actor_loss": -59.58473286819458, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.761094570159912, "step": 32000}
{"episode_reward": 381.58372878082037, "episode": 33.0, "batch_reward": 0.12800401427596808, "critic_loss": 0.2074281389862299, "actor_loss": -61.82548807144165, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.218799114227295, "step": 33000}
{"episode_reward": 268.7840162197081, "episode": 34.0, "batch_reward": 0.13504406172782182, "critic_loss": 0.2026181992813945, "actor_loss": -59.20982458114624, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.175507068634033, "step": 34000}
{"episode_reward": 358.4859075093393, "episode": 35.0, "batch_reward": 0.14060734866559504, "critic_loss": 0.20930297645926477, "actor_loss": -61.25692488479614, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.39275288581848, "step": 35000}
{"episode_reward": 340.5738659470882, "episode": 36.0, "batch_reward": 0.14096668145805596, "critic_loss": 0.2110873189419508, "actor_loss": -57.93649715042114, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.324208974838257, "step": 36000}
{"episode_reward": 14.726900433184984, "episode": 37.0, "batch_reward": 0.1387407593354583, "critic_loss": 0.22329748882353306, "actor_loss": -59.58109159088135, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.387300968170166, "step": 37000}
{"episode_reward": 75.27203924044726, "episode": 38.0, "batch_reward": 0.1369383749589324, "critic_loss": 0.2352393713966012, "actor_loss": -60.466135147094725, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.252867460250854, "step": 38000}
{"episode_reward": 76.39438710691648, "episode": 39.0, "batch_reward": 0.1388164734914899, "critic_loss": 0.2522561110556126, "actor_loss": -60.79199503898621, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.24059796333313, "step": 39000}
{"episode_reward": 330.71612116534715, "episode": 40.0, "batch_reward": 0.1425981178060174, "critic_loss": 0.2481653906106949, "actor_loss": -61.23016849517822, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.45967674255371, "step": 40000}
{"episode_reward": 343.61128121654, "episode": 41.0, "batch_reward": 0.1489087822139263, "critic_loss": 0.25000251449644567, "actor_loss": -60.589627588272094, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.46801781654358, "step": 41000}
{"episode_reward": 380.72089022498864, "episode": 42.0, "batch_reward": 0.15184900093823672, "critic_loss": 0.25517503184080126, "actor_loss": -58.80584990310669, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.600764513015747, "step": 42000}
{"episode_reward": 78.9715092135894, "episode": 43.0, "batch_reward": 0.15294060749560595, "critic_loss": 0.24916027765721083, "actor_loss": -59.14021899795532, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.17434048652649, "step": 43000}
{"episode_reward": 352.9348684355409, "episode": 44.0, "batch_reward": 0.1565796264782548, "critic_loss": 0.26406656740605833, "actor_loss": -58.46797871780395, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.27489185333252, "step": 44000}
{"episode_reward": 340.2365139526237, "episode": 45.0, "batch_reward": 0.15882543398439883, "critic_loss": 0.2713864027559757, "actor_loss": -60.17939207649231, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.04531502723694, "step": 45000}
{"episode_reward": 106.2513139592548, "episode": 46.0, "batch_reward": 0.1572693171352148, "critic_loss": 0.2746807403564453, "actor_loss": -58.93201061820984, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.47286868095398, "step": 46000}
{"episode_reward": 99.69659191384429, "episode": 47.0, "batch_reward": 0.1560907156765461, "critic_loss": 0.2626921857893467, "actor_loss": -60.30015626907348, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.13283920288086, "step": 47000}
{"episode_reward": 87.9760546608648, "episode": 48.0, "batch_reward": 0.15727150208503007, "critic_loss": 0.26594332019984723, "actor_loss": -57.06580836868286, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.654197216033936, "step": 48000}
{"episode_reward": 344.1730144203168, "episode": 49.0, "batch_reward": 0.1631000937372446, "critic_loss": 0.27389636598527434, "actor_loss": -60.65358114814758, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.139737606048584, "step": 49000}
{"episode_reward": 415.85303143283096, "episode": 50.0, "batch_reward": 0.167354061499238, "critic_loss": 0.2831588069200516, "actor_loss": -60.526186153411864, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.117613315582275, "step": 50000}
{"episode_reward": 290.2057671132475, "episode": 51.0, "batch_reward": 0.16851614379882812, "critic_loss": 0.29007567539811135, "actor_loss": -60.32607207298279, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.201215744018555, "step": 51000}
{"episode_reward": 407.5967352221886, "episode": 52.0, "batch_reward": 0.17154576981812716, "critic_loss": 0.30262907503545283, "actor_loss": -60.77795093536377, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.51232099533081, "step": 52000}
{"episode_reward": 95.5660492661775, "episode": 53.0, "batch_reward": 0.17239855636656284, "critic_loss": 0.29912981851398945, "actor_loss": -60.089973920822146, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.167112827301025, "step": 53000}
{"episode_reward": 427.00840292138224, "episode": 54.0, "batch_reward": 0.1774565446972847, "critic_loss": 0.2975613799840212, "actor_loss": -60.91401629257202, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.330662965774536, "step": 54000}
{"episode_reward": 416.78886020061833, "episode": 55.0, "batch_reward": 0.17874207781255244, "critic_loss": 0.2955329522639513, "actor_loss": -61.098037693023684, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.91854429244995, "step": 55000}
{"episode_reward": 78.43369136391098, "episode": 56.0, "batch_reward": 0.18066441063582897, "critic_loss": 0.29784326725453136, "actor_loss": -61.42836157798767, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.49315619468689, "step": 56000}
{"episode_reward": 426.28040362871053, "episode": 57.0, "batch_reward": 0.18323122665286065, "critic_loss": 0.31283892887830733, "actor_loss": -60.729179470062256, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.126730918884277, "step": 57000}
{"episode_reward": 105.34407374329496, "episode": 58.0, "batch_reward": 0.18080235657095908, "critic_loss": 0.29839303205907347, "actor_loss": -59.43409019088745, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.748132705688477, "step": 58000}
{"episode_reward": 73.78301504753813, "episode": 59.0, "batch_reward": 0.1811032037883997, "critic_loss": 0.305455554485321, "actor_loss": -59.03054226875305, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.28731346130371, "step": 59000}
{"episode_reward": 422.93216720004017, "episode": 60.0, "batch_reward": 0.183184712857008, "critic_loss": 0.3135126126110554, "actor_loss": -60.7872296333313, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.487311840057373, "step": 60000}
{"episode_reward": 80.21527862746862, "episode": 61.0, "batch_reward": 0.18010060726106167, "critic_loss": 0.29725744703412055, "actor_loss": -59.601589130401614, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.705743074417114, "step": 61000}
{"episode_reward": 56.295486299293735, "episode": 62.0, "batch_reward": 0.17902936169505118, "critic_loss": 0.3021890552118421, "actor_loss": -60.83140406608582, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.456035614013672, "step": 62000}
{"episode_reward": 85.32247830734619, "episode": 63.0, "batch_reward": 0.17751474083960056, "critic_loss": 0.30723378022015096, "actor_loss": -59.11723956298828, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.15806531906128, "step": 63000}
{"episode_reward": 124.16461545264767, "episode": 64.0, "batch_reward": 0.1801026523336768, "critic_loss": 0.30807870395481585, "actor_loss": -60.28510171508789, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.783326387405396, "step": 64000}
{"episode_reward": 504.65330990734986, "episode": 65.0, "batch_reward": 0.18395679488778113, "critic_loss": 0.33436173367500305, "actor_loss": -60.13837333679199, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.841200828552246, "step": 65000}
{"episode_reward": 445.6623542723084, "episode": 66.0, "batch_reward": 0.18895282720029355, "critic_loss": 0.3376490163952112, "actor_loss": -60.455924213409425, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.009164810180664, "step": 66000}
{"episode_reward": 462.7142741909096, "episode": 67.0, "batch_reward": 0.1924894553720951, "critic_loss": 0.32733581970632075, "actor_loss": -61.177481470108035, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.159281969070435, "step": 67000}
{"episode_reward": 414.68328008047985, "episode": 68.0, "batch_reward": 0.19476797619462013, "critic_loss": 0.33435864017903805, "actor_loss": -58.463261539459225, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.15006971359253, "step": 68000}
{"episode_reward": 388.6432795265471, "episode": 69.0, "batch_reward": 0.19719452813267707, "critic_loss": 0.35040101109445093, "actor_loss": -58.58811011695862, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.135775804519653, "step": 69000}
{"episode_reward": 463.01920819708977, "episode": 70.0, "batch_reward": 0.2026286339610815, "critic_loss": 0.365771842032671, "actor_loss": -61.32704733848572, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.164114952087402, "step": 70000}
{"episode_reward": 460.45306409938365, "episode": 71.0, "batch_reward": 0.20532255558669568, "critic_loss": 0.43446112525463104, "actor_loss": -60.71348261070251, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.882020235061646, "step": 71000}
{"episode_reward": 461.3138739817994, "episode": 72.0, "batch_reward": 0.20897540892660618, "critic_loss": 0.7610425949394702, "actor_loss": -60.10875248527527, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.140784978866577, "step": 72000}
{"episode_reward": 418.1006584193084, "episode": 73.0, "batch_reward": 0.21200085067749022, "critic_loss": 1.415037771254778, "actor_loss": -60.930783199310305, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.36968445777893, "step": 73000}
{"episode_reward": 444.878257508536, "episode": 74.0, "batch_reward": 0.21585618321597577, "critic_loss": 1.3386864347457885, "actor_loss": -62.418404722213744, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.22628092765808, "step": 74000}
{"episode_reward": 493.46691727046823, "episode": 75.0, "batch_reward": 0.2191535651832819, "critic_loss": 1.2874376276731492, "actor_loss": -62.45538579368591, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.13728618621826, "step": 75000}
{"episode_reward": 480.34411424902316, "episode": 76.0, "batch_reward": 0.22182082353532315, "critic_loss": 1.230921975195408, "actor_loss": -63.69843749237061, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.077513933181763, "step": 76000}
{"episode_reward": 507.79458107035975, "episode": 77.0, "batch_reward": 0.22649040932953357, "critic_loss": 1.19960061866045, "actor_loss": -61.9291533203125, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.127943992614746, "step": 77000}
{"episode_reward": 456.0318778279199, "episode": 78.0, "batch_reward": 0.23025308933854102, "critic_loss": 1.1443305361568927, "actor_loss": -63.20130443572998, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.095998764038086, "step": 78000}
{"episode_reward": 475.04212711909065, "episode": 79.0, "batch_reward": 0.2295419827401638, "critic_loss": 1.1762774294018745, "actor_loss": -60.954155124664304, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.164769172668457, "step": 79000}
{"episode_reward": 16.125739396335902, "episode": 80.0, "batch_reward": 0.23043434169888496, "critic_loss": 1.1164613530039786, "actor_loss": -62.78634502792358, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.490158796310425, "step": 80000}
{"episode_reward": 498.94488397364745, "episode": 81.0, "batch_reward": 0.2326178074926138, "critic_loss": 1.0769086768627167, "actor_loss": -63.37355337905884, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 43.1498339176178, "step": 81000}
{"episode_reward": 267.6296988787516, "episode": 82.0, "batch_reward": 0.23322453810274602, "critic_loss": 1.0643147658109664, "actor_loss": -65.57683546447754, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.147095680236816, "step": 82000}
{"episode_reward": 447.1725143593404, "episode": 83.0, "batch_reward": 0.23615751335024834, "critic_loss": 1.0185818687677384, "actor_loss": -62.21666513061523, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.150600910186768, "step": 83000}
{"episode_reward": 506.01034383909575, "episode": 84.0, "batch_reward": 0.23992740462720394, "critic_loss": 1.0490977176725864, "actor_loss": -65.02899282073975, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.928983211517334, "step": 84000}
{"episode_reward": 486.9917051615528, "episode": 85.0, "batch_reward": 0.23939340832829475, "critic_loss": 1.0125992854833603, "actor_loss": -64.43549517440796, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.168728351593018, "step": 85000}
{"episode_reward": 20.026693051015414, "episode": 86.0, "batch_reward": 0.23893250355124473, "critic_loss": 0.99845099401474, "actor_loss": -63.52022085952759, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.635398626327515, "step": 86000}
{"episode_reward": 268.20962106967016, "episode": 87.0, "batch_reward": 0.24008944749832153, "critic_loss": 1.0121406252086163, "actor_loss": -63.369262950897216, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.749775409698486, "step": 87000}
{"episode_reward": 501.9101157154871, "episode": 88.0, "batch_reward": 0.2417021204829216, "critic_loss": 0.9938233325183392, "actor_loss": -62.182987194061276, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.123874187469482, "step": 88000}
{"episode_reward": 439.42944239308076, "episode": 89.0, "batch_reward": 0.2462568605840206, "critic_loss": 0.9078560302257538, "actor_loss": -64.77520026016235, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.154913187026978, "step": 89000}
{"episode_reward": 472.5237607403901, "episode": 90.0, "batch_reward": 0.24677456989884378, "critic_loss": 0.9895333738327027, "actor_loss": -65.93089877700805, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.099174976348877, "step": 90000}
{"episode_reward": 438.4029178014897, "episode": 91.0, "batch_reward": 0.25005791284143924, "critic_loss": 0.8950949919521809, "actor_loss": -63.86873399734497, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.65418553352356, "step": 91000}
{"episode_reward": 519.267401157567, "episode": 92.0, "batch_reward": 0.25180514897406103, "critic_loss": 0.8847281554937363, "actor_loss": -62.973528465270995, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.609090328216553, "step": 92000}
{"episode_reward": 461.85368236681745, "episode": 93.0, "batch_reward": 0.25476001101732254, "critic_loss": 0.9329295683205128, "actor_loss": -63.04432875442505, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.045926094055176, "step": 93000}
{"episode_reward": 530.0329507392598, "episode": 94.0, "batch_reward": 0.25452851776778695, "critic_loss": 0.9153249231278896, "actor_loss": -63.09994540405273, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.300477981567383, "step": 94000}
{"episode_reward": 52.87575086282869, "episode": 95.0, "batch_reward": 0.25492888583242895, "critic_loss": 0.8970683023035526, "actor_loss": -65.31021516036988, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.184964895248413, "step": 95000}
{"episode_reward": 305.7757238120574, "episode": 96.0, "batch_reward": 0.25695170406997203, "critic_loss": 0.9445035460293293, "actor_loss": -65.21791873550416, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.14624309539795, "step": 96000}
{"episode_reward": 468.7664268547696, "episode": 97.0, "batch_reward": 0.2583432662934065, "critic_loss": 0.9148301225602626, "actor_loss": -65.76356775283813, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.50856328010559, "step": 97000}
{"episode_reward": 527.0915587396695, "episode": 98.0, "batch_reward": 0.2618997796922922, "critic_loss": 0.881029830545187, "actor_loss": -62.96166377639771, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.031540393829346, "step": 98000}
{"episode_reward": 531.0330061455874, "episode": 99.0, "batch_reward": 0.26397308804094793, "critic_loss": 0.8573600188195706, "actor_loss": -63.144944889068604, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.397350788116455, "step": 99000}
{"episode_reward": 352.75586018499496, "episode": 100.0, "batch_reward": 0.26548886820673945, "critic_loss": 0.8315636087059974, "actor_loss": -63.70031909561157, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.097224712371826, "step": 100000}
{"episode_reward": 464.24755328151616, "episode": 101.0, "batch_reward": 0.26680867885053156, "critic_loss": 0.7982458145022392, "actor_loss": -64.51556799316407, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.404770851135254, "step": 101000}
{"episode_reward": 575.3221007959535, "episode": 102.0, "batch_reward": 0.2690768964290619, "critic_loss": 0.7885721590220928, "actor_loss": -64.02452640533447, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.54796075820923, "step": 102000}
{"episode_reward": 459.66337362202717, "episode": 103.0, "batch_reward": 0.2712255049794912, "critic_loss": 0.836130724310875, "actor_loss": -63.868294883728026, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.87167739868164, "step": 103000}
{"episode_reward": 542.4385241210414, "episode": 104.0, "batch_reward": 0.2725871715694666, "critic_loss": 0.8736655348241329, "actor_loss": -63.874154155731205, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.137805938720703, "step": 104000}
{"episode_reward": 222.98260012523218, "episode": 105.0, "batch_reward": 0.27415991482138635, "critic_loss": 0.927658551722765, "actor_loss": -63.968810512542724, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.068937063217163, "step": 105000}
{"episode_reward": 531.1740774274847, "episode": 106.0, "batch_reward": 0.27675718311965464, "critic_loss": 0.9628039018511773, "actor_loss": -62.64697824859619, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.030163288116455, "step": 106000}
{"episode_reward": 573.714743567671, "episode": 107.0, "batch_reward": 0.2778893374353647, "critic_loss": 0.975788273781538, "actor_loss": -63.85513610839844, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.024224519729614, "step": 107000}
{"episode_reward": 528.4643212154743, "episode": 108.0, "batch_reward": 0.28347209802269935, "critic_loss": 1.0592148598730564, "actor_loss": -63.85216299819946, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.161155939102173, "step": 108000}
{"episode_reward": 545.9107394774787, "episode": 109.0, "batch_reward": 0.28459952042996883, "critic_loss": 1.2223924335241318, "actor_loss": -65.4138653755188, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.236144304275513, "step": 109000}
{"episode_reward": 541.1333541111372, "episode": 110.0, "batch_reward": 0.2867906833291054, "critic_loss": 1.231791894108057, "actor_loss": -64.10057007980346, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.224762678146362, "step": 110000}
{"episode_reward": 583.7264031091645, "episode": 111.0, "batch_reward": 0.2895851349979639, "critic_loss": 1.4880982379317285, "actor_loss": -66.22450543212891, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.810606956481934, "step": 111000}
{"episode_reward": 577.8296503928078, "episode": 112.0, "batch_reward": 0.2916920806020498, "critic_loss": 3.2174946265220643, "actor_loss": -64.90602021408081, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.95078730583191, "step": 112000}
{"episode_reward": 621.7276755163674, "episode": 113.0, "batch_reward": 0.29166922506690024, "critic_loss": 3.872748411178589, "actor_loss": -66.3082342453003, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.233816862106323, "step": 113000}
{"episode_reward": 18.860325279340255, "episode": 114.0, "batch_reward": 0.2936488031744957, "critic_loss": 3.511356302857399, "actor_loss": -68.0621643486023, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.14305019378662, "step": 114000}
{"episode_reward": 605.0419258612745, "episode": 115.0, "batch_reward": 0.29548926213383675, "critic_loss": 3.0181382685899734, "actor_loss": -67.63629543304444, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.29370403289795, "step": 115000}
{"episode_reward": 608.8010874118496, "episode": 116.0, "batch_reward": 0.2994098843485117, "critic_loss": 2.913164741873741, "actor_loss": -67.9802137184143, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.926599979400635, "step": 116000}
{"episode_reward": 608.0227229375321, "episode": 117.0, "batch_reward": 0.3017956857383251, "critic_loss": 2.6040051884651185, "actor_loss": -67.69430579376221, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.514965772628784, "step": 117000}
{"episode_reward": 629.4808701654273, "episode": 118.0, "batch_reward": 0.30319499200582506, "critic_loss": 2.4932650166749952, "actor_loss": -68.39951460647583, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.09699034690857, "step": 118000}
{"episode_reward": 586.6364067361212, "episode": 119.0, "batch_reward": 0.3070415266156197, "critic_loss": 2.400597420334816, "actor_loss": -68.84773616790771, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.45964217185974, "step": 119000}
{"episode_reward": 594.7073182542101, "episode": 120.0, "batch_reward": 0.3077159152030945, "critic_loss": 2.399450919687748, "actor_loss": -67.2431796951294, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.993954181671143, "step": 120000}
{"episode_reward": 630.8046671401863, "episode": 121.0, "batch_reward": 0.31056687495112417, "critic_loss": 2.18916234177351, "actor_loss": -67.73558121490478, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.806671142578125, "step": 121000}
{"episode_reward": 195.55209928876, "episode": 122.0, "batch_reward": 0.30977075585722924, "critic_loss": 2.0923949056267737, "actor_loss": -67.55231768035888, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.489695072174072, "step": 122000}
{"episode_reward": 612.8154701825523, "episode": 123.0, "batch_reward": 0.30989311899244787, "critic_loss": 1.998371887087822, "actor_loss": -65.24307934570312, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.319703817367554, "step": 123000}
{"episode_reward": 15.431861829186927, "episode": 124.0, "batch_reward": 0.3104506133645773, "critic_loss": 1.9505877686738968, "actor_loss": -67.57956829833985, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.34941864013672, "step": 124000}
{"episode_reward": 430.5202633758205, "episode": 125.0, "batch_reward": 0.31009626799821854, "critic_loss": 1.8989636957645417, "actor_loss": -67.71756297302247, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.192744255065918, "step": 125000}
{"episode_reward": 199.1950348918144, "episode": 126.0, "batch_reward": 0.3098519680649042, "critic_loss": 1.8667342951893806, "actor_loss": -67.70908296966553, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.458508253097534, "step": 126000}
{"episode_reward": 549.2866816546588, "episode": 127.0, "batch_reward": 0.31044910071790216, "critic_loss": 1.8721969454884528, "actor_loss": -67.61392538452148, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.654467821121216, "step": 127000}
{"episode_reward": 148.554926120608, "episode": 128.0, "batch_reward": 0.3084374870657921, "critic_loss": 2.1987823556661605, "actor_loss": -69.03507266235351, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.969040632247925, "step": 128000}
{"episode_reward": 18.442981503927722, "episode": 129.0, "batch_reward": 0.3090616478025913, "critic_loss": 2.0681572747826578, "actor_loss": -69.06705110168457, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.6945698261261, "step": 129000}
{"episode_reward": 686.9248817359263, "episode": 130.0, "batch_reward": 0.31116877688467504, "critic_loss": 2.36690238314867, "actor_loss": -67.89210683441162, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.87906265258789, "step": 130000}
{"episode_reward": 338.77140242874214, "episode": 131.0, "batch_reward": 0.31211651316285133, "critic_loss": 2.4586163946390154, "actor_loss": -69.81085587310791, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.50726675987244, "step": 131000}
{"episode_reward": 269.99575427623967, "episode": 132.0, "batch_reward": 0.31167836874723437, "critic_loss": 2.6180350872278213, "actor_loss": -68.35334373474122, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.01099920272827, "step": 132000}
{"episode_reward": 328.65584354904587, "episode": 133.0, "batch_reward": 0.3093299447745085, "critic_loss": 2.576898931145668, "actor_loss": -68.60373370361329, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.653183698654175, "step": 133000}
{"episode_reward": 19.32480797470201, "episode": 134.0, "batch_reward": 0.3075501141399145, "critic_loss": 2.672031155705452, "actor_loss": -68.86597911071777, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.08601999282837, "step": 134000}
{"episode_reward": 72.74328371368173, "episode": 135.0, "batch_reward": 0.30703320002555845, "critic_loss": 3.088215738892555, "actor_loss": -69.21222380065917, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.906880855560303, "step": 135000}
{"episode_reward": 615.026857656044, "episode": 136.0, "batch_reward": 0.3099579699039459, "critic_loss": 3.205685599684715, "actor_loss": -70.81462359619141, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.564759731292725, "step": 136000}
{"episode_reward": 641.2460304554584, "episode": 137.0, "batch_reward": 0.3111332466900349, "critic_loss": 3.379367060422897, "actor_loss": -69.16687108612061, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.97366452217102, "step": 137000}
{"episode_reward": 633.4732755054715, "episode": 138.0, "batch_reward": 0.3134736665636301, "critic_loss": 3.0932598625421526, "actor_loss": -69.18277336120606, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.504454374313354, "step": 138000}
{"episode_reward": 15.736587038803806, "episode": 139.0, "batch_reward": 0.3109131791144609, "critic_loss": 2.6886008117198945, "actor_loss": -69.85265734100342, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.89816164970398, "step": 139000}
{"episode_reward": 59.96879128354654, "episode": 140.0, "batch_reward": 0.3073196620047092, "critic_loss": 2.395720441877842, "actor_loss": -69.91679849243164, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.196791410446167, "step": 140000}
{"episode_reward": 14.881757985196316, "episode": 141.0, "batch_reward": 0.30657048751413823, "critic_loss": 2.2988424898982047, "actor_loss": -69.61716821289062, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.036707162857056, "step": 141000}
{"episode_reward": 57.70117211779199, "episode": 142.0, "batch_reward": 0.3056803228259087, "critic_loss": 2.1284035965204238, "actor_loss": -70.66217036437989, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.417511701583862, "step": 142000}
{"episode_reward": 726.0602097669193, "episode": 143.0, "batch_reward": 0.30565817654132843, "critic_loss": 2.061583720445633, "actor_loss": -70.70033660125732, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.226616621017456, "step": 143000}
{"episode_reward": 51.88786076912731, "episode": 144.0, "batch_reward": 0.30594302904605863, "critic_loss": 1.976145560324192, "actor_loss": -71.13226148986817, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.168988943099976, "step": 144000}
{"episode_reward": 75.08123949266785, "episode": 145.0, "batch_reward": 0.3071883061826229, "critic_loss": 1.7670643669962882, "actor_loss": -70.63156052398682, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.1019389629364, "step": 145000}
{"episode_reward": 658.7039859317148, "episode": 146.0, "batch_reward": 0.30629995638132096, "critic_loss": 1.696704034268856, "actor_loss": -70.31672551727294, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.21541452407837, "step": 146000}
{"episode_reward": 63.85780962759963, "episode": 147.0, "batch_reward": 0.3070499811023474, "critic_loss": 1.6123321346640587, "actor_loss": -70.95798455810547, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.05681824684143, "step": 147000}
{"episode_reward": 631.1770601234446, "episode": 148.0, "batch_reward": 0.30950914983451366, "critic_loss": 1.5003474134802819, "actor_loss": -69.76819862365723, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.57495093345642, "step": 148000}
{"episode_reward": 664.3466836723567, "episode": 149.0, "batch_reward": 0.31255126804113387, "critic_loss": 1.4830215398073197, "actor_loss": -70.34494982910157, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.652417182922363, "step": 149000}
{"episode_reward": 605.4623334700153, "episode": 150.0, "batch_reward": 0.31449630837142467, "critic_loss": 1.429136414527893, "actor_loss": -70.27164278411865, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "step": 150000}
