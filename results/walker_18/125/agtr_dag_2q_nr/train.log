{"episode": 1.0, "duration": 21.85823941230774, "episode_reward": 28.177075776326152, "step": 1000}
{"episode": 2.0, "duration": 1.9440279006958008, "episode_reward": 69.84046218736019, "step": 2000}
{"episode": 3.0, "batch_reward": 0.06880801462976087, "critic_loss": 0.37832777173310844, "actor_loss": -79.81706725353716, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499180007, "duration": 86.50456476211548, "episode_reward": 387.44428914918063, "step": 3000}
{"episode": 4.0, "batch_reward": 0.1989732259809971, "critic_loss": 0.6703087766766548, "actor_loss": -81.03195491027832, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.561187028884888, "episode_reward": 376.3138104985013, "step": 4000}
{"episode": 5.0, "batch_reward": 0.24906281389296056, "critic_loss": 0.6598108393847942, "actor_loss": -82.03985052490235, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.48864197731018, "episode_reward": 435.51150818530334, "step": 5000}
{"episode": 6.0, "batch_reward": 0.2761592956185341, "critic_loss": 0.9199958719909191, "actor_loss": -82.54755532836914, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.687663316726685, "episode_reward": 433.0628071518154, "step": 6000}
{"episode": 7.0, "batch_reward": 0.2991214308440685, "critic_loss": 0.9453571848273278, "actor_loss": -82.52057136535645, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.946091890335083, "episode_reward": 419.1167359954892, "step": 7000}
{"episode": 8.0, "batch_reward": 0.2922154058814049, "critic_loss": 0.8223412362635135, "actor_loss": -82.2103053894043, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.129541397094727, "episode_reward": 69.44337944597999, "step": 8000}
{"episode": 9.0, "batch_reward": 0.29202685053646565, "critic_loss": 0.8525571754574776, "actor_loss": -82.1447908782959, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 30.19464135169983, "episode_reward": 521.8222343944798, "step": 9000}
{"episode": 10.0, "batch_reward": 0.29054168112576007, "critic_loss": 1.1149543237090112, "actor_loss": -73.14596760559083, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 4990.672165393829, "episode_reward": 34.422012540943655, "step": 10000}
{"episode": 11.0, "batch_reward": 0.2648870883285999, "critic_loss": 0.8210076566338539, "actor_loss": -72.35870472717285, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 50.96782445907593, "episode_reward": 23.381112594392103, "step": 11000}
{"episode": 12.0, "batch_reward": 0.2578511380106211, "critic_loss": 0.862155924975872, "actor_loss": -67.78127144622803, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 610.9002060890198, "episode_reward": 226.3400637394257, "step": 12000}
{"episode": 13.0, "batch_reward": 0.2605956081748009, "critic_loss": 0.9241415391266345, "actor_loss": -68.11220695495605, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.662127256393433, "episode_reward": 494.8110233215811, "step": 13000}
{"episode": 14.0, "batch_reward": 0.26224645859003065, "critic_loss": 0.8990188180804253, "actor_loss": -65.57098774719238, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 580.6031556129456, "episode_reward": 41.46816287562076, "step": 14000}
{"episode": 15.0, "batch_reward": 0.2516766727119684, "critic_loss": 0.919481394469738, "actor_loss": -64.38451579284668, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.602075576782227, "episode_reward": 137.56363969180245, "step": 15000}
{"episode": 16.0, "batch_reward": 0.2534744876176119, "critic_loss": 0.943035567164421, "actor_loss": -63.57426307678222, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 590.0759727954865, "episode_reward": 428.6461985518121, "step": 16000}
{"episode": 17.0, "batch_reward": 0.266723191305995, "critic_loss": 1.0892920539677142, "actor_loss": -63.95858925628662, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.787633657455444, "episode_reward": 550.5087087646687, "step": 17000}
{"episode": 18.0, "batch_reward": 0.2728184264749289, "critic_loss": 1.3440933160185813, "actor_loss": -64.26951211547852, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 553.2988119125366, "episode_reward": 121.97368668862484, "step": 18000}
{"episode": 19.0, "batch_reward": 0.2739464824348688, "critic_loss": 1.4567227717041968, "actor_loss": -64.45495289611816, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 31.037925720214844, "episode_reward": 403.68804411893456, "step": 19000}
{"episode": 20.0, "batch_reward": 0.26639157965779303, "critic_loss": 1.5342530294060708, "actor_loss": -60.93302221679688, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 572.7037003040314, "episode_reward": 20.586804591682917, "step": 20000}
{"episode": 21.0, "batch_reward": 0.2637878280878067, "critic_loss": 1.541852842748165, "actor_loss": -60.38481758880615, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 50.05502247810364, "episode_reward": 413.5746742336053, "step": 21000}
{"episode": 22.0, "batch_reward": 0.2707078117877245, "critic_loss": 1.5482639078497886, "actor_loss": -59.91736735534668, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 561.7040929794312, "episode_reward": 364.7117336725853, "step": 22000}
{"episode": 23.0, "batch_reward": 0.2691346730440855, "critic_loss": 1.3364964114427567, "actor_loss": -59.77958102416992, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 31.68814206123352, "episode_reward": 23.309377327052527, "step": 23000}
{"episode": 24.0, "batch_reward": 0.26616156643629074, "critic_loss": 1.3840299292802811, "actor_loss": -58.81298404693604, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 571.0560791492462, "episode_reward": 365.9290662555475, "step": 24000}
{"episode": 25.0, "batch_reward": 0.2620344071686268, "critic_loss": 1.3011153947114944, "actor_loss": -58.52253493499756, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.516322135925293, "episode_reward": 23.502317155519464, "step": 25000}
{"episode": 26.0, "batch_reward": 0.2584898653626442, "critic_loss": 1.3909257547855378, "actor_loss": -56.321879737854005, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 576.1052277088165, "episode_reward": 442.7430186556585, "step": 26000}
{"episode": 27.0, "batch_reward": 0.2683539370447397, "critic_loss": 1.483968874335289, "actor_loss": -56.70517214202881, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.571959972381592, "episode_reward": 645.8073231780448, "step": 27000}
{"episode": 28.0, "batch_reward": 0.2780046125203371, "critic_loss": 1.378036093711853, "actor_loss": -54.81861637878418, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 562.4376575946808, "episode_reward": 467.4770055274357, "step": 28000}
{"episode": 29.0, "batch_reward": 0.28318538950383665, "critic_loss": 1.3078812925219536, "actor_loss": -55.04412406158447, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.278107404708862, "episode_reward": 434.18946293253754, "step": 29000}
{"episode": 30.0, "batch_reward": 0.2934487157016993, "critic_loss": 1.2944359144568442, "actor_loss": -56.172010986328125, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 575.9869742393494, "episode_reward": 501.52587795673026, "step": 30000}
{"episode": 31.0, "batch_reward": 0.3007406989485025, "critic_loss": 1.2665419874191284, "actor_loss": -56.27473091888428, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 57.06017565727234, "episode_reward": 608.582363017639, "step": 31000}
{"episode": 32.0, "batch_reward": 0.31147300386428833, "critic_loss": 1.2335241855978967, "actor_loss": -56.43459309387207, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 567.13139128685, "episode_reward": 654.1264584008633, "step": 32000}
{"episode": 33.0, "batch_reward": 0.3236694302111864, "critic_loss": 1.2750206922888756, "actor_loss": -56.682420806884764, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 30.230315923690796, "episode_reward": 772.9351532501299, "step": 33000}
{"episode": 34.0, "batch_reward": 0.33494903495907785, "critic_loss": 1.2850325825214386, "actor_loss": -56.26617368316651, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 559.9599990844727, "episode_reward": 605.8244134253108, "step": 34000}
{"episode": 35.0, "batch_reward": 0.3437267543077469, "critic_loss": 1.345673034310341, "actor_loss": -56.182943397521974, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.453654289245605, "episode_reward": 657.4910278056395, "step": 35000}
{"episode": 36.0, "batch_reward": 0.34430294516682625, "critic_loss": 1.4612734635472298, "actor_loss": -56.59463688659668, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 570.2190191745758, "episode_reward": 15.133327245875053, "step": 36000}
{"episode": 37.0, "batch_reward": 0.3368122845441103, "critic_loss": 1.4022259105443955, "actor_loss": -55.82339365386963, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.259153604507446, "episode_reward": 86.3034960997816, "step": 37000}
{"episode": 38.0, "batch_reward": 0.3363185192793608, "critic_loss": 1.5107727862000466, "actor_loss": -55.631740844726565, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 569.576479434967, "episode_reward": 646.5727416143292, "step": 38000}
{"episode": 39.0, "batch_reward": 0.3468993296474218, "critic_loss": 1.57176746571064, "actor_loss": -55.69156649017334, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.928133726119995, "episode_reward": 702.8967495506985, "step": 39000}
{"episode": 40.0, "batch_reward": 0.3546214103996754, "critic_loss": 1.6596889751553536, "actor_loss": -55.528181632995604, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 554.1438910961151, "episode_reward": 756.1152352560836, "step": 40000}
{"episode": 41.0, "batch_reward": 0.36373886474967004, "critic_loss": 1.8268512458205224, "actor_loss": -55.906923538208005, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 52.58864498138428, "episode_reward": 705.6253748593231, "step": 41000}
{"episode": 42.0, "batch_reward": 0.37006115421652797, "critic_loss": 2.0671826628446577, "actor_loss": -55.033288917541505, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 544.227546453476, "episode_reward": 566.1248305784683, "step": 42000}
{"episode": 43.0, "batch_reward": 0.37715030217170714, "critic_loss": 2.0712766531705857, "actor_loss": -55.34929389190674, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 30.0080509185791, "episode_reward": 695.3725691261905, "step": 43000}
{"episode": 44.0, "batch_reward": 0.3865583243668079, "critic_loss": 2.245623694419861, "actor_loss": -55.17789990997314, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 571.6717591285706, "episode_reward": 750.3315238753972, "step": 44000}
{"episode": 45.0, "batch_reward": 0.39300173833966257, "critic_loss": 2.3831749117970467, "actor_loss": -55.53819477844238, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.99282217025757, "episode_reward": 784.0930574045268, "step": 45000}
{"episode": 46.0, "batch_reward": 0.39750110983848574, "critic_loss": 2.3759671849012376, "actor_loss": -55.84353556060791, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 586.9466643333435, "episode_reward": 604.920689202434, "step": 46000}
{"episode": 47.0, "batch_reward": 0.3970719953477383, "critic_loss": 2.3226186047792434, "actor_loss": -55.7667339630127, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.587177753448486, "episode_reward": 74.31603148401926, "step": 47000}
{"episode": 48.0, "batch_reward": 0.39996714371442793, "critic_loss": 2.3568413947820663, "actor_loss": -56.382755241394044, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 553.832677602768, "episode_reward": 824.3166084079219, "step": 48000}
{"episode": 49.0, "batch_reward": 0.4071640495955944, "critic_loss": 2.3745537922382356, "actor_loss": -56.805944129943846, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.171313285827637, "episode_reward": 733.7210650887262, "step": 49000}
{"episode": 50.0, "batch_reward": 0.41363055831193923, "critic_loss": 2.3773520011901854, "actor_loss": -56.87674755859375, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 552.2389180660248, "episode_reward": 772.2583739810094, "step": 50000}
{"episode": 51.0, "batch_reward": 0.42095917478203776, "critic_loss": 2.366333945333958, "actor_loss": -57.21892467498779, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 50.0885009765625, "episode_reward": 824.6973351666669, "step": 51000}
{"episode": 52.0, "batch_reward": 0.4234882773458958, "critic_loss": 2.2614853739738465, "actor_loss": -56.95457480621338, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 551.0662820339203, "episode_reward": 114.65265742906988, "step": 52000}
{"episode": 53.0, "batch_reward": 0.4234802951514721, "critic_loss": 2.2294240958690645, "actor_loss": -57.129739112854004, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.5730242729187, "episode_reward": 842.3462863711361, "step": 53000}
{"episode": 54.0, "batch_reward": 0.42956198689341546, "critic_loss": 2.2211048384308816, "actor_loss": -57.992734397888185, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 565.0553588867188, "episode_reward": 729.2570381457937, "step": 54000}
{"episode": 55.0, "batch_reward": 0.43788627928495405, "critic_loss": 2.1211984122991563, "actor_loss": -58.47065087890625, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.408605813980103, "episode_reward": 866.0241336279214, "step": 55000}
{"episode": 56.0, "batch_reward": 0.4461264990568161, "critic_loss": 2.0380509306192396, "actor_loss": -58.1891329498291, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 579.5873968601227, "episode_reward": 877.0720163369778, "step": 56000}
{"episode": 57.0, "batch_reward": 0.44539049619436266, "critic_loss": 2.005236225605011, "actor_loss": -58.11838084411621, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 29.050107955932617, "episode_reward": 78.51672519354103, "step": 57000}
{"episode": 58.0, "batch_reward": 0.4399930312037468, "critic_loss": 1.9454419900774955, "actor_loss": -58.330193977355954, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 590.1216156482697, "episode_reward": 79.3994042140705, "step": 58000}
{"episode": 59.0, "batch_reward": 0.43374311551451683, "critic_loss": 1.9451506698727608, "actor_loss": -57.81476465606689, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.1864333152771, "episode_reward": 18.138397003156435, "step": 59000}
{"episode": 60.0, "batch_reward": 0.431538764744997, "critic_loss": 1.9111691777706146, "actor_loss": -57.39887258148193, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 560.4361119270325, "episode_reward": 788.6573560182774, "step": 60000}
{"episode": 61.0, "batch_reward": 0.43898062539100646, "critic_loss": 1.9224358081817627, "actor_loss": -57.81818772888184, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 52.89842200279236, "episode_reward": 806.2589621104731, "step": 61000}
{"episode": 62.0, "batch_reward": 0.4364867654442787, "critic_loss": 1.8666602602005005, "actor_loss": -58.03892602539062, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 564.2483413219452, "episode_reward": 75.7408914314805, "step": 62000}
{"episode": 63.0, "batch_reward": 0.4385368749797344, "critic_loss": 1.9341743841767312, "actor_loss": -58.146362869262695, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 34.08018708229065, "episode_reward": 800.0167292421326, "step": 63000}
{"episode": 64.0, "batch_reward": 0.43644566714763644, "critic_loss": 1.872178709745407, "actor_loss": -58.54095774078369, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 561.214426279068, "episode_reward": 24.948736385134076, "step": 64000}
{"episode": 65.0, "batch_reward": 0.4374497615695, "critic_loss": 1.950057671189308, "actor_loss": -58.84699789428711, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 30.8881573677063, "episode_reward": 551.8668064744509, "step": 65000}
{"episode": 66.0, "batch_reward": 0.4391811316311359, "critic_loss": 1.9664908080697059, "actor_loss": -58.633576347351074, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 565.9461710453033, "episode_reward": 831.410541851072, "step": 66000}
{"episode": 67.0, "batch_reward": 0.44622772708535197, "critic_loss": 1.8766515185236932, "actor_loss": -59.03935900878906, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.25261425971985, "episode_reward": 891.2119997649551, "step": 67000}
{"episode": 68.0, "batch_reward": 0.4528203642964363, "critic_loss": 1.995011131644249, "actor_loss": -59.50728817749023, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 562.6592020988464, "episode_reward": 803.3552268798024, "step": 68000}
{"episode": 69.0, "batch_reward": 0.4578404241204262, "critic_loss": 2.0081363441348077, "actor_loss": -60.04279811096191, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.381489038467407, "episode_reward": 910.4395603666497, "step": 69000}
{"episode": 70.0, "batch_reward": 0.4648115849196911, "critic_loss": 1.9549056940674783, "actor_loss": -60.35733603668213, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 557.6761014461517, "episode_reward": 808.7137772517141, "step": 70000}
{"episode": 71.0, "batch_reward": 0.4686262739300728, "critic_loss": 1.9389246872067452, "actor_loss": -60.94489588165283, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 50.05314779281616, "episode_reward": 780.6975958760022, "step": 71000}
{"episode": 72.0, "batch_reward": 0.4721761366426945, "critic_loss": 1.8455230059623717, "actor_loss": -61.206022300720214, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 563.8740620613098, "episode_reward": 689.2428926301186, "step": 72000}
{"episode": 73.0, "batch_reward": 0.4781871673464775, "critic_loss": 1.774755407691002, "actor_loss": -61.70598397064209, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.098326683044434, "episode_reward": 858.5182869667701, "step": 73000}
{"episode": 74.0, "batch_reward": 0.48263764280080795, "critic_loss": 1.7282025112509727, "actor_loss": -61.81913887023926, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 575.2435119152069, "episode_reward": 883.3413971199757, "step": 74000}
{"episode": 75.0, "batch_reward": 0.48565594291687014, "critic_loss": 1.7152243371009828, "actor_loss": -62.40582968139648, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.210201025009155, "episode_reward": 736.2579877577646, "step": 75000}
{"episode": 76.0, "batch_reward": 0.48957783880829814, "critic_loss": 1.6725410069823266, "actor_loss": -62.15701111602783, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 576.1721167564392, "episode_reward": 757.3734857769625, "step": 76000}
{"episode": 77.0, "batch_reward": 0.4888766381442547, "critic_loss": 1.6596046140193939, "actor_loss": -62.550003662109376, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.736762523651123, "episode_reward": 631.7692945275271, "step": 77000}
{"episode": 78.0, "batch_reward": 0.49602583318948745, "critic_loss": 1.6372629162669181, "actor_loss": -63.62090567016602, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 562.5160119533539, "episode_reward": 823.5807926290814, "step": 78000}
{"episode": 79.0, "batch_reward": 0.5005848338007927, "critic_loss": 1.5847032574415207, "actor_loss": -63.84950643157959, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.61803936958313, "episode_reward": 833.6008806661672, "step": 79000}
{"episode": 80.0, "batch_reward": 0.5013728570938111, "critic_loss": 1.5883809307813643, "actor_loss": -64.57950727081298, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 588.5656318664551, "episode_reward": 610.1204877603709, "step": 80000}
{"episode": 81.0, "batch_reward": 0.5064492730796337, "critic_loss": 1.5717448049187661, "actor_loss": -64.76986307525635, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 50.10466384887695, "episode_reward": 816.3172015067547, "step": 81000}
{"episode": 82.0, "batch_reward": 0.5090416427850724, "critic_loss": 1.5946813739538193, "actor_loss": -64.89911341094971, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 551.2836401462555, "episode_reward": 823.4107609767625, "step": 82000}
{"episode": 83.0, "batch_reward": 0.5122331391572952, "critic_loss": 1.5398436523675918, "actor_loss": -65.30388801574708, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.646122217178345, "episode_reward": 852.1501593670495, "step": 83000}
{"episode": 84.0, "batch_reward": 0.5162697072029114, "critic_loss": 1.4993769396543504, "actor_loss": -65.89745449829101, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 555.6881551742554, "episode_reward": 862.3370427454057, "step": 84000}
{"episode": 85.0, "batch_reward": 0.5213576571643352, "critic_loss": 1.5730284894704818, "actor_loss": -66.2049225769043, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.65442395210266, "episode_reward": 818.9810936293046, "step": 85000}
{"episode": 86.0, "batch_reward": 0.5249034541845322, "critic_loss": 1.5439157353639603, "actor_loss": -67.03163004302978, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 564.0093896389008, "episode_reward": 828.9963148359041, "step": 86000}
{"episode": 87.0, "batch_reward": 0.5292688242197037, "critic_loss": 1.5143952472805977, "actor_loss": -67.37059417724609, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.471577405929565, "episode_reward": 870.9750410232409, "step": 87000}
{"episode": 88.0, "batch_reward": 0.5309999237060546, "critic_loss": 1.550311811029911, "actor_loss": -67.59778134918213, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 575.1736741065979, "episode_reward": 779.0451611062726, "step": 88000}
{"episode": 89.0, "batch_reward": 0.535603518307209, "critic_loss": 1.5480521218776704, "actor_loss": -68.18962503051758, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.549007892608643, "episode_reward": 907.1539056118353, "step": 89000}
{"episode": 90.0, "batch_reward": 0.5400710346400738, "critic_loss": 1.6219710644483567, "actor_loss": -68.80694050598144, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 559.9568474292755, "episode_reward": 859.6013182943778, "step": 90000}
{"episode": 91.0, "batch_reward": 0.5426035400629043, "critic_loss": 1.7233865854740142, "actor_loss": -69.41144941711426, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 51.07453942298889, "episode_reward": 883.3778324908048, "step": 91000}
{"episode": 92.0, "batch_reward": 0.545228547424078, "critic_loss": 2.0156638336181643, "actor_loss": -70.21112226104736, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 551.2844636440277, "episode_reward": 878.5217343600041, "step": 92000}
{"episode": 93.0, "batch_reward": 0.5495428083837033, "critic_loss": 2.2441180629730226, "actor_loss": -71.20438496398926, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.26802897453308, "episode_reward": 833.2281732702722, "step": 93000}
{"episode": 94.0, "batch_reward": 0.5512032466828823, "critic_loss": 2.5567530895471573, "actor_loss": -72.19803717041016, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 544.9253392219543, "episode_reward": 899.2356753428588, "step": 94000}
{"episode": 95.0, "batch_reward": 0.5544618100225925, "critic_loss": 2.8703885278105736, "actor_loss": -72.82670745849609, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.4988911151886, "episode_reward": 442.3371632822178, "step": 95000}
{"episode": 96.0, "batch_reward": 0.5533035860359669, "critic_loss": 3.2034344381093978, "actor_loss": -72.9886310119629, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 565.3629245758057, "episode_reward": 831.4160886053689, "step": 96000}
{"episode": 97.0, "batch_reward": 0.5575803995728493, "critic_loss": 3.9869870345592497, "actor_loss": -73.46779225158691, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.57814621925354, "episode_reward": 469.9243940593349, "step": 97000}
{"episode": 98.0, "batch_reward": 0.554277395516634, "critic_loss": 7.028832752943039, "actor_loss": -74.89748928833008, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 567.5897600650787, "episode_reward": 73.26091602404493, "step": 98000}
{"episode": 99.0, "batch_reward": 0.5497199604213238, "critic_loss": 12.158060981512069, "actor_loss": -79.66408572387695, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 30.06610131263733, "episode_reward": 70.17595569747567, "step": 99000}
{"episode": 100.0, "batch_reward": 0.542891147941351, "critic_loss": 18.64194298839569, "actor_loss": -87.23491748046875, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 564.740879535675, "episode_reward": 67.22963328763181, "step": 100000}
{"episode": 101.0, "batch_reward": 0.538930032223463, "critic_loss": 24.625450595855714, "actor_loss": -97.16472831726074, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 52.13905954360962, "episode_reward": 72.61874008492087, "step": 101000}
{"episode": 102.0, "batch_reward": 0.5338013980984688, "critic_loss": 33.42618923091889, "actor_loss": -107.0003664855957, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 568.2862441539764, "episode_reward": 88.76027856043777, "step": 102000}
{"episode": 103.0, "batch_reward": 0.5273813171684743, "critic_loss": 42.23500444793701, "actor_loss": -115.49921684265136, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 30.705304861068726, "episode_reward": 150.1787711395594, "step": 103000}
{"episode": 104.0, "batch_reward": 0.5253269076347351, "critic_loss": 48.55898090171814, "actor_loss": -124.75806176757813, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 572.5844080448151, "episode_reward": 85.25988070835008, "step": 104000}
{"episode": 105.0, "batch_reward": 0.5223167244791984, "critic_loss": 66.15576265525817, "actor_loss": -134.2083445739746, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 31.35701608657837, "episode_reward": 102.63696010350212, "step": 105000}
{"episode": 106.0, "batch_reward": 0.5174789498746395, "critic_loss": 86.88120286560059, "actor_loss": -150.50187057495117, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 568.4778771400452, "episode_reward": 40.58950500473964, "step": 106000}
{"episode": 107.0, "batch_reward": 0.5133239862322807, "critic_loss": 78.49955136108399, "actor_loss": -171.2152733154297, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.65372610092163, "episode_reward": 27.88385604359348, "step": 107000}
{"episode": 108.0, "batch_reward": 0.5097729523479938, "critic_loss": 68.76384131622315, "actor_loss": -182.31109603881836, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 557.4504759311676, "episode_reward": 122.4178354488297, "step": 108000}
{"episode": 109.0, "batch_reward": 0.5042516594827176, "critic_loss": 63.77780996894836, "actor_loss": -188.47963287353517, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 31.597822904586792, "episode_reward": 190.46115537456976, "step": 109000}
{"episode": 110.0, "batch_reward": 0.5025553950965405, "critic_loss": 54.96802123641968, "actor_loss": -192.41766876220703, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 567.0127274990082, "episode_reward": 284.0598399634741, "step": 110000}
{"episode": 111.0, "batch_reward": 0.5019994747042656, "critic_loss": 48.96183867263794, "actor_loss": -193.22225894165038, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 49.79103326797485, "episode_reward": 498.3715185919349, "step": 111000}
{"episode": 112.0, "batch_reward": 0.504520004928112, "critic_loss": 42.79086973190308, "actor_loss": -193.43669262695312, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 557.7553679943085, "episode_reward": 733.179736151564, "step": 112000}
{"episode": 113.0, "batch_reward": 0.5021303404569626, "critic_loss": 38.85783862113953, "actor_loss": -193.06368212890624, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.330347776412964, "episode_reward": 208.74931906272354, "step": 113000}
{"episode": 114.0, "batch_reward": 0.5025973010063172, "critic_loss": 33.45806709575653, "actor_loss": -192.4708049621582, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 556.9683487415314, "episode_reward": 690.8462867384809, "step": 114000}
{"episode": 115.0, "batch_reward": 0.5046086841225624, "critic_loss": 30.55794302940369, "actor_loss": -192.07462579345705, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.677372455596924, "episode_reward": 675.3587575809188, "step": 115000}
{"episode": 116.0, "batch_reward": 0.5064942952096462, "critic_loss": 25.43393514919281, "actor_loss": -192.53820559692383, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 581.4431121349335, "episode_reward": 204.99707864361, "step": 116000}
{"episode": 117.0, "batch_reward": 0.4994386268556118, "critic_loss": 20.9150122089386, "actor_loss": -191.4104126586914, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.34591031074524, "episode_reward": 358.91154586248985, "step": 117000}
{"episode": 118.0, "batch_reward": 0.50050776091218, "critic_loss": 17.757942771434784, "actor_loss": -190.54484603881835, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 558.7688002586365, "episode_reward": 282.3351351155509, "step": 118000}
{"episode": 119.0, "batch_reward": 0.49940409025549887, "critic_loss": 16.519521053314207, "actor_loss": -189.87632470703124, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 29.00892734527588, "episode_reward": 156.84171091709757, "step": 119000}
{"episode": 120.0, "batch_reward": 0.494952318996191, "critic_loss": 14.31979729795456, "actor_loss": -189.34228833007813, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 572.5645213127136, "episode_reward": 42.753049976221654, "step": 120000}
{"episode": 121.0, "batch_reward": 0.4919850835204124, "critic_loss": 12.429016262054443, "actor_loss": -188.50286254882812, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 50.02761387825012, "episode_reward": 216.0507422439774, "step": 121000}
{"episode": 122.0, "batch_reward": 0.49045881190896035, "critic_loss": 10.992230570316314, "actor_loss": -187.26598791503906, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 544.3550934791565, "episode_reward": 323.2449799242746, "step": 122000}
{"episode": 123.0, "batch_reward": 0.4870566864013672, "critic_loss": 9.433658576965332, "actor_loss": -185.1943182067871, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.22908854484558, "episode_reward": 29.89805031194544, "step": 123000}
{"episode": 124.0, "batch_reward": 0.48682874646782875, "critic_loss": 8.654354479074478, "actor_loss": -182.9310574951172, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 542.525351524353, "episode_reward": 518.3799675410618, "step": 124000}
{"episode": 125.0, "batch_reward": 0.4857610043287277, "critic_loss": 8.183649291992188, "actor_loss": -181.22739669799805, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.248493671417236, "episode_reward": 492.7337238038099, "step": 125000}
{"episode": 126.0, "batch_reward": 0.48535758510231974, "critic_loss": 7.705107613563538, "actor_loss": -179.30857611083985, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 546.543877363205, "episode_reward": 128.3978487441558, "step": 126000}
{"episode": 127.0, "batch_reward": 0.4837312735915184, "critic_loss": 6.876494050979614, "actor_loss": -177.00751043701172, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.150289297103882, "episode_reward": 666.9198717108092, "step": 127000}
{"episode": 128.0, "batch_reward": 0.4830344445705414, "critic_loss": 6.018989233255386, "actor_loss": -173.58943362426757, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 536.2970719337463, "episode_reward": 31.44952835204082, "step": 128000}
{"episode": 129.0, "batch_reward": 0.48360572707653043, "critic_loss": 5.31386760520935, "actor_loss": -170.62764868164064, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.29002618789673, "episode_reward": 891.8832520596999, "step": 129000}
{"episode": 130.0, "batch_reward": 0.48450891456007955, "critic_loss": 4.794714429140091, "actor_loss": -167.63496588134765, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 535.1485524177551, "episode_reward": 894.1169790759884, "step": 130000}
{"episode": 131.0, "batch_reward": 0.49014497476816177, "critic_loss": 4.228568263530732, "actor_loss": -164.79110440063477, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 49.73736333847046, "episode_reward": 911.7793715235326, "step": 131000}
{"episode": 132.0, "batch_reward": 0.4906589432656765, "critic_loss": 3.974098433613777, "actor_loss": -162.14720443725585, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 530.4636507034302, "episode_reward": 889.8018990175383, "step": 132000}
{"episode": 133.0, "batch_reward": 0.4916728149652481, "critic_loss": 3.4898232979774475, "actor_loss": -159.51652166748048, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.186681747436523, "episode_reward": 552.6456979611887, "step": 133000}
{"episode": 134.0, "batch_reward": 0.4949169096946716, "critic_loss": 3.166741730809212, "actor_loss": -156.80306677246094, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 555.0412917137146, "episode_reward": 62.59674522631978, "step": 134000}
{"episode": 135.0, "batch_reward": 0.4926941052377224, "critic_loss": 2.885071208357811, "actor_loss": -154.27564730834962, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.73747420310974, "episode_reward": 939.5037491943295, "step": 135000}
{"episode": 136.0, "batch_reward": 0.496485031247139, "critic_loss": 2.678157992243767, "actor_loss": -151.4616946105957, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 560.6974058151245, "episode_reward": 921.9833343003584, "step": 136000}
{"episode": 137.0, "batch_reward": 0.49658275172114374, "critic_loss": 2.5823002071380614, "actor_loss": -148.84605529785156, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 29.377537488937378, "episode_reward": 948.8240683054651, "step": 137000}
{"episode": 138.0, "batch_reward": 0.5000274739265442, "critic_loss": 2.3912471798658372, "actor_loss": -146.27761981201172, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 541.4728860855103, "episode_reward": 138.50860935451158, "step": 138000}
{"episode": 139.0, "batch_reward": 0.495158680588007, "critic_loss": 2.1231782423853875, "actor_loss": -143.78730560302733, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.0564181804657, "episode_reward": 82.47711987767325, "step": 139000}
{"episode": 140.0, "batch_reward": 0.49176830518245696, "critic_loss": 1.9909528132081031, "actor_loss": -141.2682278137207, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 539.5153062343597, "episode_reward": 86.35955449079978, "step": 140000}
{"episode": 141.0, "batch_reward": 0.4889667899012566, "critic_loss": 1.8367593826651574, "actor_loss": -138.64573150634766, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 49.79555535316467, "episode_reward": 59.546715905130156, "step": 141000}
{"episode": 142.0, "batch_reward": 0.4912712688446045, "critic_loss": 1.690552946329117, "actor_loss": -136.2149301147461, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 521.2582824230194, "episode_reward": 952.7414825231215, "step": 142000}
{"episode": 143.0, "batch_reward": 0.4906619255244732, "critic_loss": 1.7075614315867425, "actor_loss": -133.86084246826172, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.255637168884277, "episode_reward": 78.42904929655435, "step": 143000}
{"episode": 144.0, "batch_reward": 0.4872789863348007, "critic_loss": 1.5682733879685402, "actor_loss": -131.47648822021483, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 537.924919128418, "episode_reward": 119.9547803852018, "step": 144000}
{"episode": 145.0, "batch_reward": 0.48766014334559443, "critic_loss": 1.4782377215027809, "actor_loss": -129.2437430419922, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 29.38448214530945, "episode_reward": 945.6564466333806, "step": 145000}
{"episode": 146.0, "batch_reward": 0.48930537545681, "critic_loss": 1.4519133177399635, "actor_loss": -127.15946751403808, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 540.1352789402008, "episode_reward": 83.19314161953918, "step": 146000}
{"episode": 147.0, "batch_reward": 0.4857759362757206, "critic_loss": 1.3533936160802842, "actor_loss": -125.01080310058593, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.666363954544067, "episode_reward": 517.9468129282193, "step": 147000}
{"episode": 148.0, "batch_reward": 0.48917517784237863, "critic_loss": 1.2494558943510055, "actor_loss": -123.11923764038086, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 550.194363117218, "episode_reward": 921.0049694842345, "step": 148000}
{"episode": 149.0, "batch_reward": 0.49079222801327704, "critic_loss": 1.2526054564118385, "actor_loss": -121.1576558380127, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 28.757182836532593, "episode_reward": 882.2430503366386, "step": 149000}
{"episode": 150.0, "batch_reward": 0.49424826288223267, "critic_loss": 1.2079396993517875, "actor_loss": -119.49576066589356, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "step": 150000}
