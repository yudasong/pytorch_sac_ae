{"episode": 1.0, "duration": 26.45429754257202, "episode_reward": 28.177075776326152, "step": 1000}
{"episode": 2.0, "duration": 2.006385087966919, "episode_reward": 69.84046218736019, "step": 2000}
{"episode": 3.0, "batch_reward": 0.06947855540700618, "actor_loss": -80.12650460880153, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499180007, "duration": 53.69877362251282, "episode_reward": 360.05586965266224, "step": 3000}
{"episode": 4.0, "batch_reward": 0.14676417352259158, "actor_loss": -80.54421499633789, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.722238302230835, "episode_reward": 84.70890205113064, "step": 4000}
{"episode": 5.0, "batch_reward": 0.16271579895913602, "actor_loss": -79.98414997863769, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.451736450195312, "episode_reward": 387.1250129301943, "step": 5000}
{"episode": 6.0, "batch_reward": 0.20001055952906607, "actor_loss": -80.69965489196777, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.68995952606201, "episode_reward": 254.5331539888018, "step": 6000}
{"episode": 7.0, "batch_reward": 0.2118222359865904, "actor_loss": -80.54748835754394, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.21755576133728, "episode_reward": 424.58994000917, "step": 7000}
{"episode": 8.0, "batch_reward": 0.215794911891222, "actor_loss": -79.97460414123535, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.66506290435791, "episode_reward": 17.017726639224605, "step": 8000}
{"episode": 9.0, "batch_reward": 0.2111107265353203, "actor_loss": -79.42576452636719, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.297887086868286, "episode_reward": 335.4338240208651, "step": 9000}
{"episode": 10.0, "batch_reward": 0.21093700256943704, "actor_loss": -74.89540055847168, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 4135.079209804535, "episode_reward": 73.46082461261717, "step": 10000}
{"episode": 11.0, "batch_reward": 0.19476443859934806, "actor_loss": -74.94723989868164, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.21739888191223, "episode_reward": 22.411191783197328, "step": 11000}
{"episode": 12.0, "batch_reward": 0.18065186807513237, "actor_loss": -69.0640545501709, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 453.71994256973267, "episode_reward": 27.894180005935908, "step": 12000}
{"episode": 13.0, "batch_reward": 0.17147748883068561, "actor_loss": -69.02018157958985, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.791365146636963, "episode_reward": 89.05918641950406, "step": 13000}
{"episode": 14.0, "batch_reward": 0.16607406641542913, "actor_loss": -64.11254733276367, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 435.6438190937042, "episode_reward": 77.29082273809027, "step": 14000}
{"episode": 15.0, "batch_reward": 0.1656711888089776, "actor_loss": -64.23457877349854, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.089351415634155, "episode_reward": 259.10564884137676, "step": 15000}
{"episode": 16.0, "batch_reward": 0.17205458351224662, "actor_loss": -62.16790460968018, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 448.9074203968048, "episode_reward": 196.0583735000294, "step": 16000}
{"episode": 17.0, "batch_reward": 0.16651219967007638, "actor_loss": -61.90650640106201, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.285643339157104, "episode_reward": 76.26688280137296, "step": 17000}
{"episode": 18.0, "batch_reward": 0.16653747243434192, "actor_loss": -59.60031886291504, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 448.04212641716003, "episode_reward": 303.58683958059487, "step": 18000}
{"episode": 19.0, "batch_reward": 0.17866710982471704, "actor_loss": -60.55811945343017, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.27399778366089, "episode_reward": 406.4615982714162, "step": 19000}
{"episode": 20.0, "batch_reward": 0.17909413541853428, "actor_loss": -57.21415626525879, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 454.90590143203735, "episode_reward": 23.444819718910768, "step": 20000}
{"episode": 21.0, "batch_reward": 0.17168783450126648, "actor_loss": -56.85854071044922, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.850542306900024, "episode_reward": 28.88838471902344, "step": 21000}
{"episode": 22.0, "batch_reward": 0.1758369771167636, "actor_loss": -54.47257209777832, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 439.13464283943176, "episode_reward": 498.10709904768663, "step": 22000}
{"episode": 23.0, "batch_reward": 0.1897311874553561, "actor_loss": -55.59228540802002, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.905898809432983, "episode_reward": 480.81711632639184, "step": 23000}
{"episode": 24.0, "batch_reward": 0.19762487088143826, "actor_loss": -55.52268241119385, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 425.0373010635376, "episode_reward": 151.32939670328065, "step": 24000}
{"episode": 25.0, "batch_reward": 0.19230295411497356, "actor_loss": -55.03353240966797, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.91003656387329, "episode_reward": 88.80895969383153, "step": 25000}
{"episode": 26.0, "batch_reward": 0.1957264302149415, "actor_loss": -52.90590335083008, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 426.9181957244873, "episode_reward": 453.8172884044038, "step": 26000}
{"episode": 27.0, "batch_reward": 0.20545142570137978, "actor_loss": -53.82740761566162, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.82730722427368, "episode_reward": 427.49738622912093, "step": 27000}
{"episode": 28.0, "batch_reward": 0.21162793800234794, "actor_loss": -53.635803581237795, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 426.2366986274719, "episode_reward": 237.9828397923938, "step": 28000}
{"episode": 29.0, "batch_reward": 0.2109245060235262, "actor_loss": -53.62669119262695, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.418424367904663, "episode_reward": 315.8457291251143, "step": 29000}
{"episode": 30.0, "batch_reward": 0.21826192624866964, "actor_loss": -54.695143043518065, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 458.67950415611267, "episode_reward": 466.8133739201217, "step": 30000}
{"episode": 31.0, "batch_reward": 0.22127734883129596, "actor_loss": -55.16072389221191, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 39.78622508049011, "episode_reward": 161.74979634834432, "step": 31000}
{"episode": 32.0, "batch_reward": 0.22349093009531498, "actor_loss": -54.395920135498045, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 455.9283037185669, "episode_reward": 332.0786422703587, "step": 32000}
{"episode": 33.0, "batch_reward": 0.22683605001866816, "actor_loss": -54.954412673950195, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.235347032546997, "episode_reward": 472.4573406389576, "step": 33000}
{"episode": 34.0, "batch_reward": 0.2345413134843111, "actor_loss": -55.37099584960937, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 451.2955105304718, "episode_reward": 532.5951378372813, "step": 34000}
{"episode": 35.0, "batch_reward": 0.24148952229321002, "actor_loss": -56.09219493865967, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.785245895385742, "episode_reward": 378.54669797668276, "step": 35000}
{"episode": 36.0, "batch_reward": 0.24679240345954895, "actor_loss": -58.87080834197998, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 452.51454758644104, "episode_reward": 502.5320019575388, "step": 36000}
{"episode": 37.0, "batch_reward": 0.2545537681430578, "actor_loss": -59.321116790771484, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.0190486907959, "episode_reward": 489.4870203846815, "step": 37000}
{"episode": 38.0, "batch_reward": 0.26040425488352775, "actor_loss": -60.857270912170414, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 460.59334111213684, "episode_reward": 432.36205512091163, "step": 38000}
{"episode": 39.0, "batch_reward": 0.2672065741121769, "actor_loss": -61.505420600891114, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.520426750183105, "episode_reward": 536.634421018225, "step": 39000}
{"episode": 40.0, "batch_reward": 0.2722324891090393, "actor_loss": -61.33083402252197, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 451.02396035194397, "episode_reward": 524.278894429027, "step": 40000}
{"episode": 41.0, "batch_reward": 0.27883198648691176, "actor_loss": -61.87980632781982, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.09691524505615, "episode_reward": 594.5070441128489, "step": 41000}
{"episode": 42.0, "batch_reward": 0.28141400480270384, "actor_loss": -61.133935768127444, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 444.96566128730774, "episode_reward": 67.25945453237254, "step": 42000}
{"episode": 43.0, "batch_reward": 0.28069611531496047, "actor_loss": -60.96647312164307, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.010607719421387, "episode_reward": 418.98857981164537, "step": 43000}
{"episode": 44.0, "batch_reward": 0.2839670640081167, "actor_loss": -59.50155647277832, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 468.25400471687317, "episode_reward": 427.50419658627436, "step": 44000}
{"episode": 45.0, "batch_reward": 0.28270420840382576, "actor_loss": -59.332347541809085, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.263128519058228, "episode_reward": 78.38012300966852, "step": 45000}
{"episode": 46.0, "batch_reward": 0.2793369188308716, "actor_loss": -57.31486399078369, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 450.27718114852905, "episode_reward": 72.4469981151329, "step": 46000}
{"episode": 47.0, "batch_reward": 0.2744111707210541, "actor_loss": -57.15477197265625, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.490882396697998, "episode_reward": 76.10941221411139, "step": 47000}
{"episode": 48.0, "batch_reward": 0.2744916943758726, "actor_loss": -52.75057320404053, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 449.50501132011414, "episode_reward": 515.8446607667285, "step": 48000}
{"episode": 49.0, "batch_reward": 0.2750848312228918, "actor_loss": -52.96957682037353, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.439409732818604, "episode_reward": 251.9323285686004, "step": 49000}
{"episode": 50.0, "batch_reward": 0.27840151445567607, "actor_loss": -48.00677889251709, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 450.050977230072, "episode_reward": 417.8927741991316, "step": 50000}
{"episode": 51.0, "batch_reward": 0.2805035942494869, "actor_loss": -48.4302409286499, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 37.49523210525513, "episode_reward": 421.8744743645765, "step": 51000}
{"episode": 52.0, "batch_reward": 0.28028016930818556, "actor_loss": -42.11334600830078, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 449.40803599357605, "episode_reward": 206.3296088553218, "step": 52000}
{"episode": 53.0, "batch_reward": 0.2811370653361082, "actor_loss": -41.73376557159424, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.26495909690857, "episode_reward": 301.5881335731083, "step": 53000}
{"episode": 54.0, "batch_reward": 0.28241627241671086, "actor_loss": -33.677529724121094, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 455.96482944488525, "episode_reward": 415.95399451954864, "step": 54000}
{"episode": 55.0, "batch_reward": 0.2804479533433914, "actor_loss": -33.91980703353882, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.414491415023804, "episode_reward": 22.90119458899697, "step": 55000}
{"episode": 56.0, "batch_reward": 0.2792048525959253, "actor_loss": -18.420995923519136, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 452.6124200820923, "episode_reward": 365.20052762913184, "step": 56000}
{"episode": 57.0, "batch_reward": 0.2794776850789785, "actor_loss": -19.146257120609285, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.366780996322632, "episode_reward": 33.36118563631566, "step": 57000}
{"episode": 58.0, "batch_reward": 0.2749445229768753, "actor_loss": 9.261744967997075, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 457.2665023803711, "episode_reward": 28.295988256826206, "step": 58000}
{"episode": 59.0, "batch_reward": 0.26855372841656205, "actor_loss": 9.82850931763649, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.372142553329468, "episode_reward": 13.935207183480914, "step": 59000}
{"episode": 60.0, "batch_reward": 0.2672153491675854, "actor_loss": 37.66802615737915, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 452.79255199432373, "episode_reward": 193.8952834367556, "step": 60000}
{"episode": 61.0, "batch_reward": 0.2642014367431402, "actor_loss": 37.871200191497806, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.619560956954956, "episode_reward": 23.569916802378664, "step": 61000}
{"episode": 62.0, "batch_reward": 0.2601525263488293, "actor_loss": 69.55255262756347, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 458.28745698928833, "episode_reward": 24.19546307486669, "step": 62000}
{"episode": 63.0, "batch_reward": 0.25745370200276374, "actor_loss": 69.95085092163086, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.939640998840332, "episode_reward": 187.79812182397268, "step": 63000}
{"episode": 64.0, "batch_reward": 0.25597224934399126, "actor_loss": 64.62991647338868, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 450.21112608909607, "episode_reward": 186.54563232224942, "step": 64000}
{"episode": 65.0, "batch_reward": 0.2542928615957499, "actor_loss": 64.45345583343506, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.04827046394348, "episode_reward": 79.48349004810684, "step": 65000}
{"episode": 66.0, "batch_reward": 0.2532143886387348, "actor_loss": 55.24065872192383, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 462.0441687107086, "episode_reward": 224.3455656205045, "step": 66000}
{"episode": 67.0, "batch_reward": 0.25273063661158085, "actor_loss": 56.05061520385742, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.743401765823364, "episode_reward": 261.51516054408387, "step": 67000}
{"episode": 68.0, "batch_reward": 0.251841058447957, "actor_loss": 49.59971375274658, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 462.3982231616974, "episode_reward": 15.20714866483552, "step": 68000}
{"episode": 69.0, "batch_reward": 0.25024230578541756, "actor_loss": 49.839005187988285, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.79282283782959, "episode_reward": 352.0639966861784, "step": 69000}
{"episode": 70.0, "batch_reward": 0.24883395393192767, "actor_loss": 44.88268524932862, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 455.0959463119507, "episode_reward": 44.65868635089531, "step": 70000}
{"episode": 71.0, "batch_reward": 0.24635681867599488, "actor_loss": 44.69422408676147, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.20534157752991, "episode_reward": 15.453322138997523, "step": 71000}
{"episode": 72.0, "batch_reward": 0.24215055893361567, "actor_loss": 35.22656408691406, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 451.1286482810974, "episode_reward": 18.36013795925349, "step": 72000}
{"episode": 73.0, "batch_reward": 0.2406816408187151, "actor_loss": 35.645640773773195, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.186694860458374, "episode_reward": 150.63600932711077, "step": 73000}
{"episode": 74.0, "batch_reward": 0.24144069573283194, "actor_loss": 19.1165417470932, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 452.13372015953064, "episode_reward": 165.41204295754912, "step": 74000}
{"episode": 75.0, "batch_reward": 0.2386189669072628, "actor_loss": 19.01731463623047, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.827094078063965, "episode_reward": 18.79343065792635, "step": 75000}
{"episode": 76.0, "batch_reward": 0.2357250569611788, "actor_loss": 14.16749839782715, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 458.2640132904053, "episode_reward": 75.3439893886865, "step": 76000}
{"episode": 77.0, "batch_reward": 0.2332334793806076, "actor_loss": 14.457077881336213, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.54948401451111, "episode_reward": 23.420586216138638, "step": 77000}
{"episode": 78.0, "batch_reward": 0.23163202053308488, "actor_loss": 6.562702644348144, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 454.4031298160553, "episode_reward": 25.385929548656296, "step": 78000}
{"episode": 79.0, "batch_reward": 0.22844328670203687, "actor_loss": 7.17390924423933, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.391425371170044, "episode_reward": 25.427229718189025, "step": 79000}
{"episode": 80.0, "batch_reward": 0.22611418759822846, "actor_loss": -4.217183671653271, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 449.06158566474915, "episode_reward": 76.35700221558997, "step": 80000}
{"episode": 81.0, "batch_reward": 0.22418341782689094, "actor_loss": -4.0201572904586795, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.53401565551758, "episode_reward": 104.31429699485851, "step": 81000}
{"episode": 82.0, "batch_reward": 0.22170949466526507, "actor_loss": -14.59468400478363, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 456.577290058136, "episode_reward": 21.412997423587345, "step": 82000}
{"episode": 83.0, "batch_reward": 0.22101680256426334, "actor_loss": -14.213177589416503, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.366970539093018, "episode_reward": 149.90612498887694, "step": 83000}
{"episode": 84.0, "batch_reward": 0.21918073551356793, "actor_loss": -21.20215718460083, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 455.44610834121704, "episode_reward": 102.59682892739715, "step": 84000}
{"episode": 85.0, "batch_reward": 0.21746573297679425, "actor_loss": -20.8308710269928, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.753873109817505, "episode_reward": 41.95324093943664, "step": 85000}
{"episode": 86.0, "batch_reward": 0.21462903629243374, "actor_loss": -23.331125652313233, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 456.62707471847534, "episode_reward": 53.70028732415523, "step": 86000}
{"episode": 87.0, "batch_reward": 0.2159232085198164, "actor_loss": -23.38543452835083, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.171051025390625, "episode_reward": 320.5409100786711, "step": 87000}
{"episode": 88.0, "batch_reward": 0.2156941957473755, "actor_loss": -26.726384227752686, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 462.29955792427063, "episode_reward": 288.29682659396343, "step": 88000}
{"episode": 89.0, "batch_reward": 0.21799390089511872, "actor_loss": -26.835958312988282, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.157270908355713, "episode_reward": 475.8542783460688, "step": 89000}
{"episode": 90.0, "batch_reward": 0.21940304942429065, "actor_loss": -31.762103954315187, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 459.3410005569458, "episode_reward": 82.1447096125973, "step": 90000}
{"episode": 91.0, "batch_reward": 0.21910104876756667, "actor_loss": -31.77157641983032, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.17968797683716, "episode_reward": 141.39197162227265, "step": 91000}
{"episode": 92.0, "batch_reward": 0.21666420371830464, "actor_loss": -36.6598987197876, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 453.4588689804077, "episode_reward": 81.2209379812646, "step": 92000}
{"episode": 93.0, "batch_reward": 0.21689231918752194, "actor_loss": -36.80212363052368, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.683927536010742, "episode_reward": 373.12078961916234, "step": 93000}
{"episode": 94.0, "batch_reward": 0.21830127672851085, "actor_loss": -39.43315193939209, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 458.91176295280457, "episode_reward": 306.6788073044971, "step": 94000}
{"episode": 95.0, "batch_reward": 0.21837809263169766, "actor_loss": -39.643001098632816, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.309199333190918, "episode_reward": 323.3993151655664, "step": 95000}
{"episode": 96.0, "batch_reward": 0.22024299605190753, "actor_loss": -42.449906547546384, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 453.52123069763184, "episode_reward": 474.22839524374905, "step": 96000}
{"episode": 97.0, "batch_reward": 0.22017642790079117, "actor_loss": -42.381196014404296, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.531494617462158, "episode_reward": 79.60777640088739, "step": 97000}
{"episode": 98.0, "batch_reward": 0.22105191893875598, "actor_loss": -43.634796981811526, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 460.2080309391022, "episode_reward": 323.9507840493912, "step": 98000}
{"episode": 99.0, "batch_reward": 0.22195917987823485, "actor_loss": -43.89522784423828, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.582930088043213, "episode_reward": 153.47818156377673, "step": 99000}
{"episode": 100.0, "batch_reward": 0.22126357506215572, "actor_loss": -45.318278968811036, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 459.75252175331116, "episode_reward": 511.22133717812375, "step": 100000}
{"episode": 101.0, "batch_reward": 0.22549275422096252, "actor_loss": -45.754696426391604, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.52614212036133, "episode_reward": 486.18180436628353, "step": 101000}
{"episode": 102.0, "batch_reward": 0.2251282920986414, "actor_loss": -48.13447483062744, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 452.61551308631897, "episode_reward": 23.15042739514597, "step": 102000}
{"episode": 103.0, "batch_reward": 0.22252055935561657, "actor_loss": -47.76829937744141, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.07665205001831, "episode_reward": 88.1536057991944, "step": 103000}
{"episode": 104.0, "batch_reward": 0.22202428612112998, "actor_loss": -50.52714710998535, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 453.80353140830994, "episode_reward": 86.81372725181353, "step": 104000}
{"episode": 105.0, "batch_reward": 0.22342236940562726, "actor_loss": -50.74781631469727, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.654577255249023, "episode_reward": 610.3629224930888, "step": 105000}
{"episode": 106.0, "batch_reward": 0.22438192619383335, "actor_loss": -53.91880791473389, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 460.3939573764801, "episode_reward": 113.84929259203196, "step": 106000}
{"episode": 107.0, "batch_reward": 0.2226218510121107, "actor_loss": -53.67934365081787, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.705095767974854, "episode_reward": 17.885808540067615, "step": 107000}
{"episode": 108.0, "batch_reward": 0.2226901226490736, "actor_loss": -52.89003889465332, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 456.7421374320984, "episode_reward": 584.7151294540396, "step": 108000}
{"episode": 109.0, "batch_reward": 0.2266668109148741, "actor_loss": -53.183684394836426, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.85734462738037, "episode_reward": 498.6203601715353, "step": 109000}
{"episode": 110.0, "batch_reward": 0.22954233039915561, "actor_loss": -53.34358317565918, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 454.22687792778015, "episode_reward": 527.6064671339306, "step": 110000}
{"episode": 111.0, "batch_reward": 0.23168315534293651, "actor_loss": -53.6040902633667, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.62470531463623, "episode_reward": 587.6860478477724, "step": 111000}
{"episode": 112.0, "batch_reward": 0.2341463558524847, "actor_loss": -54.3821474609375, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 458.81757164001465, "episode_reward": 509.19783929535794, "step": 112000}
{"episode": 113.0, "batch_reward": 0.23478160326182843, "actor_loss": -54.38755453491211, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.98682713508606, "episode_reward": 15.626063512862485, "step": 113000}
{"episode": 114.0, "batch_reward": 0.23707881128787994, "actor_loss": -55.95930800628662, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 451.75052070617676, "episode_reward": 483.77423441655145, "step": 114000}
{"episode": 115.0, "batch_reward": 0.23750953625142573, "actor_loss": -55.99976073455811, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.716256380081177, "episode_reward": 550.836427601834, "step": 115000}
{"episode": 116.0, "batch_reward": 0.23995431479811669, "actor_loss": -56.84702320861816, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 457.4988582134247, "episode_reward": 392.9229403176037, "step": 116000}
{"episode": 117.0, "batch_reward": 0.24022430191934108, "actor_loss": -56.977179901123044, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.897851705551147, "episode_reward": 474.4235214962177, "step": 117000}
{"episode": 118.0, "batch_reward": 0.24354341381788253, "actor_loss": -57.04409745788574, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 456.40575313568115, "episode_reward": 537.1405758320245, "step": 118000}
{"episode": 119.0, "batch_reward": 0.2477979533970356, "actor_loss": -57.32553996276855, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.48743176460266, "episode_reward": 670.522840689527, "step": 119000}
{"episode": 120.0, "batch_reward": 0.25069863098859785, "actor_loss": -58.22422019195557, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 455.0188817977905, "episode_reward": 613.2848666755322, "step": 120000}
{"episode": 121.0, "batch_reward": 0.25317177169024946, "actor_loss": -58.34958920288086, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.81018090248108, "episode_reward": 652.7099549978369, "step": 121000}
{"episode": 122.0, "batch_reward": 0.2562552454024553, "actor_loss": -59.99641054534912, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 458.79729318618774, "episode_reward": 604.6249385922341, "step": 122000}
{"episode": 123.0, "batch_reward": 0.25872397734224795, "actor_loss": -60.202974281311036, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.664993286132812, "episode_reward": 440.15364399488146, "step": 123000}
{"episode": 124.0, "batch_reward": 0.260894085675478, "actor_loss": -59.58453522491455, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 460.82677149772644, "episode_reward": 606.3938187497941, "step": 124000}
{"episode": 125.0, "batch_reward": 0.2635656155049801, "actor_loss": -59.84062356567383, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.50932502746582, "episode_reward": 640.2865539917572, "step": 125000}
{"episode": 126.0, "batch_reward": 0.266809435158968, "actor_loss": -60.86636508178711, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 461.1811158657074, "episode_reward": 599.9728424055827, "step": 126000}
{"episode": 127.0, "batch_reward": 0.26896138064563274, "actor_loss": -61.02390444946289, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.514604330062866, "episode_reward": 285.9481446496182, "step": 127000}
{"episode": 128.0, "batch_reward": 0.26851584112644195, "actor_loss": -61.503927734375, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 454.85229897499084, "episode_reward": 257.69985865937736, "step": 128000}
{"episode": 129.0, "batch_reward": 0.2691930653899908, "actor_loss": -61.76304588317871, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.563650369644165, "episode_reward": 377.38714438922835, "step": 129000}
{"episode": 130.0, "batch_reward": 0.2699416494369507, "actor_loss": -61.15637908935547, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 467.0002875328064, "episode_reward": 218.31026643783883, "step": 130000}
{"episode": 131.0, "batch_reward": 0.27114113336801526, "actor_loss": -61.236596534729, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 43.120450258255005, "episode_reward": 393.16924112085866, "step": 131000}
{"episode": 132.0, "batch_reward": 0.2708424961566925, "actor_loss": -61.868780555725095, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 462.84882712364197, "episode_reward": 178.674047769863, "step": 132000}
{"episode": 133.0, "batch_reward": 0.2678564502447843, "actor_loss": -61.906439247131345, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.039867877960205, "episode_reward": 199.0504167337275, "step": 133000}
{"episode": 134.0, "batch_reward": 0.2670118993371725, "actor_loss": -62.7950200881958, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 463.301878452301, "episode_reward": 416.1609317377594, "step": 134000}
{"episode": 135.0, "batch_reward": 0.2730776873230934, "actor_loss": -63.04325370025635, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.345222234725952, "episode_reward": 527.8577723468001, "step": 135000}
{"episode": 136.0, "batch_reward": 0.271926711961627, "actor_loss": -61.16495086669922, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 462.65844988822937, "episode_reward": 547.6465892330946, "step": 136000}
{"episode": 137.0, "batch_reward": 0.2733515352755785, "actor_loss": -61.3478002243042, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.479287147521973, "episode_reward": 468.24229961275154, "step": 137000}
{"episode": 138.0, "batch_reward": 0.2749474001824856, "actor_loss": -62.48464839935303, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 454.499719619751, "episode_reward": 514.7218170255959, "step": 138000}
{"episode": 139.0, "batch_reward": 0.2771507920324802, "actor_loss": -62.65040819549561, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.558644771575928, "episode_reward": 486.64690325823517, "step": 139000}
{"episode": 140.0, "batch_reward": 0.2767318099141121, "actor_loss": -63.305098403930664, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 459.4295918941498, "episode_reward": 305.27330271743284, "step": 140000}
{"episode": 141.0, "batch_reward": 0.279633123382926, "actor_loss": -63.46497551727295, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 39.35689854621887, "episode_reward": 451.3535245620747, "step": 141000}
{"episode": 142.0, "batch_reward": 0.28027996718883513, "actor_loss": -63.77176805877686, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 436.62726497650146, "episode_reward": 447.42409148447354, "step": 142000}
{"episode": 143.0, "batch_reward": 0.28162533827126024, "actor_loss": -63.86845079040528, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.164745807647705, "episode_reward": 429.4153513570369, "step": 143000}
{"episode": 144.0, "batch_reward": 0.28072212013602255, "actor_loss": -63.714701736450195, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 429.09195351600647, "episode_reward": 14.167586638649789, "step": 144000}
{"episode": 145.0, "batch_reward": 0.2816986274570227, "actor_loss": -63.85875505065918, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.010308504104614, "episode_reward": 671.5046311200848, "step": 145000}
{"episode": 146.0, "batch_reward": 0.28354470278322697, "actor_loss": -63.30720259857178, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 434.8150067329407, "episode_reward": 13.050624319330964, "step": 146000}
{"episode": 147.0, "batch_reward": 0.2800402564257383, "actor_loss": -63.074778549194335, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.93337082862854, "episode_reward": 544.8519075634878, "step": 147000}
{"episode": 148.0, "batch_reward": 0.28451984605193137, "actor_loss": -61.90450199890137, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 429.1355924606323, "episode_reward": 633.4065152141345, "step": 148000}
{"episode": 149.0, "batch_reward": 0.28510519668459894, "actor_loss": -61.8592759552002, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.943849563598633, "episode_reward": 571.1065332590885, "step": 149000}
{"episode": 150.0, "batch_reward": 0.28782066445052623, "actor_loss": -61.1288546295166, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "step": 150000}
