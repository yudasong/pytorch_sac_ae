{"episode": 1.0, "duration": 20.489216089248657, "episode_reward": 28.177075776326152, "step": 1000}
{"episode": 2.0, "duration": 1.7996046543121338, "episode_reward": 69.84046218736019, "step": 2000}
{"episode": 3.0, "batch_reward": 0.06736967047454716, "critic_loss": 0.46825457348420885, "actor_loss": -80.0461362676174, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499180007, "duration": 79.9622073173523, "episode_reward": 332.83820901519886, "step": 3000}
{"episode": 4.0, "batch_reward": 0.16295787356048821, "critic_loss": 0.5648411459773779, "actor_loss": -81.76722843933105, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.860719442367554, "episode_reward": 266.2932833084398, "step": 4000}
{"episode": 5.0, "batch_reward": 0.20326985847949983, "critic_loss": 0.6987053256332875, "actor_loss": -82.67574598693848, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.927591800689697, "episode_reward": 410.9854685698061, "step": 5000}
{"episode": 6.0, "batch_reward": 0.23578863607347011, "critic_loss": 0.8335131587684155, "actor_loss": -82.95583494567872, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.789778470993042, "episode_reward": 273.422544100758, "step": 6000}
{"episode": 7.0, "batch_reward": 0.24326048044860363, "critic_loss": 0.9251778689324855, "actor_loss": -82.37442300415039, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.597208976745605, "episode_reward": 401.28836278972665, "step": 7000}
{"episode": 8.0, "batch_reward": 0.24284325306117535, "critic_loss": 1.16829871737957, "actor_loss": -82.44364324951172, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.602428436279297, "episode_reward": 73.62753769377274, "step": 8000}
{"episode": 9.0, "batch_reward": 0.24146754707396031, "critic_loss": 1.2441758428812026, "actor_loss": -82.37287602233887, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.607672452926636, "episode_reward": 405.8823709917231, "step": 9000}
{"episode": 10.0, "batch_reward": 0.25202264012396336, "critic_loss": 3.106324356675148, "actor_loss": -70.3368062286377, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 4368.749981641769, "episode_reward": 197.35910193746867, "step": 10000}
{"episode": 11.0, "batch_reward": 0.23536647053062915, "critic_loss": 1.8918968971967698, "actor_loss": -69.64215669250488, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 43.66196942329407, "episode_reward": 20.25763683653796, "step": 11000}
{"episode": 12.0, "batch_reward": 0.22066783152520655, "critic_loss": 2.098612054467201, "actor_loss": -61.067410552978515, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 484.4011244773865, "episode_reward": 84.92459438764874, "step": 12000}
{"episode": 13.0, "batch_reward": 0.21423680873215198, "critic_loss": 2.5174646680355073, "actor_loss": -60.79614326477051, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.805600881576538, "episode_reward": 192.58754031133884, "step": 13000}
{"episode": 14.0, "batch_reward": 0.20898348745703696, "critic_loss": 2.455392579674721, "actor_loss": -57.76735725402832, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 511.53074622154236, "episode_reward": 141.0277384150226, "step": 14000}
{"episode": 15.0, "batch_reward": 0.2161480141878128, "critic_loss": 2.365387795329094, "actor_loss": -58.49955284118652, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 23.39603543281555, "episode_reward": 499.2266061640657, "step": 15000}
{"episode": 16.0, "batch_reward": 0.2339424397200346, "critic_loss": 2.6134804767370223, "actor_loss": -58.91494445800781, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 515.6099796295166, "episode_reward": 409.70171751780794, "step": 16000}
{"episode": 17.0, "batch_reward": 0.23811822824180126, "critic_loss": 2.4376199171543123, "actor_loss": -59.22001453399658, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.709503889083862, "episode_reward": 196.92288799816296, "step": 17000}
{"episode": 18.0, "batch_reward": 0.24303754855692386, "critic_loss": 2.3991654806137084, "actor_loss": -58.163073066711426, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 474.08926796913147, "episode_reward": 520.7264766794625, "step": 18000}
{"episode": 19.0, "batch_reward": 0.2612220062017441, "critic_loss": 2.566967656373978, "actor_loss": -59.46283332824707, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.992331981658936, "episode_reward": 601.737449763485, "step": 19000}
{"episode": 20.0, "batch_reward": 0.265271743863821, "critic_loss": 2.395362581372261, "actor_loss": -59.44654472351074, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 466.9097957611084, "episode_reward": 123.0806151983822, "step": 20000}
{"episode": 21.0, "batch_reward": 0.26538573050498965, "critic_loss": 2.4630242785215377, "actor_loss": -59.638870727539064, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 39.64198088645935, "episode_reward": 491.36688223597776, "step": 21000}
{"episode": 22.0, "batch_reward": 0.27841943824291226, "critic_loss": 2.7952803844213485, "actor_loss": -60.53384550476074, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 477.5632572174072, "episode_reward": 562.481870608648, "step": 22000}
{"episode": 23.0, "batch_reward": 0.2988573747575283, "critic_loss": 2.965559122800827, "actor_loss": -61.52563619995117, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.647429943084717, "episode_reward": 675.9306572385282, "step": 23000}
{"episode": 24.0, "batch_reward": 0.3113540941774845, "critic_loss": 2.5127212224602697, "actor_loss": -62.83253283691406, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 466.1079351902008, "episode_reward": 589.9932650409427, "step": 24000}
{"episode": 25.0, "batch_reward": 0.31786301265656947, "critic_loss": 1.764902359545231, "actor_loss": -63.31647473907471, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.802931785583496, "episode_reward": 551.8599403850935, "step": 25000}
{"episode": 26.0, "batch_reward": 0.3283814722746611, "critic_loss": 1.3342093277573586, "actor_loss": -62.60945696258545, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 497.93145275115967, "episode_reward": 529.0062218563806, "step": 26000}
{"episode": 27.0, "batch_reward": 0.3374121223092079, "critic_loss": 1.237412107527256, "actor_loss": -63.14133923339844, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 23.618672609329224, "episode_reward": 596.7773548759119, "step": 27000}
{"episode": 28.0, "batch_reward": 0.33828004050254823, "critic_loss": 1.1823789798617363, "actor_loss": -63.7005696105957, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 458.27938055992126, "episode_reward": 72.09530092050531, "step": 28000}
{"episode": 29.0, "batch_reward": 0.33647242417931555, "critic_loss": 1.199135440826416, "actor_loss": -63.9195901184082, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.341301918029785, "episode_reward": 610.8318370050671, "step": 29000}
{"episode": 30.0, "batch_reward": 0.3480749095082283, "critic_loss": 1.30875726044178, "actor_loss": -62.97267760467529, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 445.18593168258667, "episode_reward": 687.3958509711922, "step": 30000}
{"episode": 31.0, "batch_reward": 0.35084257543087005, "critic_loss": 1.4178123458623886, "actor_loss": -63.066260078430176, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 39.55647301673889, "episode_reward": 319.96583460544736, "step": 31000}
{"episode": 32.0, "batch_reward": 0.3577613350749016, "critic_loss": 1.4743600876927376, "actor_loss": -61.29763751220703, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 497.72450160980225, "episode_reward": 719.1519835518905, "step": 32000}
{"episode": 33.0, "batch_reward": 0.36876750165224076, "critic_loss": 1.5569997674822806, "actor_loss": -62.00728680419922, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.522515773773193, "episode_reward": 655.5018506471915, "step": 33000}
{"episode": 34.0, "batch_reward": 0.3758233726024628, "critic_loss": 1.5353068810105324, "actor_loss": -60.88435789489746, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 448.1420667171478, "episode_reward": 593.5935077328827, "step": 34000}
{"episode": 35.0, "batch_reward": 0.38326359081268313, "critic_loss": 1.4676121411323548, "actor_loss": -61.36114666748047, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.34011197090149, "episode_reward": 608.3890761070388, "step": 35000}
{"episode": 36.0, "batch_reward": 0.3868508275151253, "critic_loss": 1.4398060376048087, "actor_loss": -59.55130059814453, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 498.96954894065857, "episode_reward": 384.1395266003208, "step": 36000}
{"episode": 37.0, "batch_reward": 0.3893321154713631, "critic_loss": 1.3817617314457893, "actor_loss": -59.522432929992675, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.182584524154663, "episode_reward": 649.0476618045102, "step": 37000}
{"episode": 38.0, "batch_reward": 0.39470940065383914, "critic_loss": 1.3454196968078613, "actor_loss": -58.477148178100585, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 473.89472484588623, "episode_reward": 542.6362432063901, "step": 38000}
{"episode": 39.0, "batch_reward": 0.40049543488025663, "critic_loss": 1.3438190449476242, "actor_loss": -58.86668200683594, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.824889659881592, "episode_reward": 576.1002888451816, "step": 39000}
{"episode": 40.0, "batch_reward": 0.40444565162062646, "critic_loss": 1.3414545345902442, "actor_loss": -59.28609117889404, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 469.55285716056824, "episode_reward": 659.5644141186756, "step": 40000}
{"episode": 41.0, "batch_reward": 0.406976305782795, "critic_loss": 1.420890483856201, "actor_loss": -59.54625600433349, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 44.36267828941345, "episode_reward": 217.1461605579797, "step": 41000}
{"episode": 42.0, "batch_reward": 0.39901756480336187, "critic_loss": 1.406717496752739, "actor_loss": -60.42236157226562, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 490.20001769065857, "episode_reward": 81.78811208003896, "step": 42000}
{"episode": 43.0, "batch_reward": 0.39779110679030416, "critic_loss": 1.5124352126717568, "actor_loss": -60.33089006042481, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.355489253997803, "episode_reward": 698.9862959326178, "step": 43000}
{"episode": 44.0, "batch_reward": 0.40700013893842696, "critic_loss": 1.5565868899822235, "actor_loss": -61.288276870727536, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 432.38259744644165, "episode_reward": 736.6562446032484, "step": 44000}
{"episode": 45.0, "batch_reward": 0.4057195603251457, "critic_loss": 1.5310184524655341, "actor_loss": -61.09224841308594, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.58461332321167, "episode_reward": 12.582292291647358, "step": 45000}
{"episode": 46.0, "batch_reward": 0.3973699052631855, "critic_loss": 1.5512320908904076, "actor_loss": -60.14609185791016, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 487.3188416957855, "episode_reward": 93.56577532939134, "step": 46000}
{"episode": 47.0, "batch_reward": 0.3912666115164757, "critic_loss": 1.4657391480207442, "actor_loss": -60.14796795654297, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.7347469329834, "episode_reward": 110.06143862460878, "step": 47000}
{"episode": 48.0, "batch_reward": 0.3899655887782574, "critic_loss": 1.4520268146395683, "actor_loss": -58.86600979614258, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 504.1554388999939, "episode_reward": 672.4638267266001, "step": 48000}
{"episode": 49.0, "batch_reward": 0.3977815904915333, "critic_loss": 1.4424057192802429, "actor_loss": -59.49733264160156, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.333874464035034, "episode_reward": 680.6792232691973, "step": 49000}
{"episode": 50.0, "batch_reward": 0.4030127618908882, "critic_loss": 1.5702173951268197, "actor_loss": -58.814695877075195, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 468.47055649757385, "episode_reward": 636.163359775479, "step": 50000}
{"episode": 51.0, "batch_reward": 0.4072221550643444, "critic_loss": 1.6493256204724311, "actor_loss": -59.16107782745361, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 39.37494158744812, "episode_reward": 716.031973525182, "step": 51000}
{"episode": 52.0, "batch_reward": 0.4066380401849747, "critic_loss": 1.6628943222761154, "actor_loss": -59.68066806793213, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 486.1422073841095, "episode_reward": 124.32643827455625, "step": 52000}
{"episode": 53.0, "batch_reward": 0.40857572633028033, "critic_loss": 1.7459057906866073, "actor_loss": -59.83679611206055, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.13274359703064, "episode_reward": 618.8569267409588, "step": 53000}
{"episode": 54.0, "batch_reward": 0.4121628870368004, "critic_loss": 1.8570622870922089, "actor_loss": -60.13007820892334, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 488.6242821216583, "episode_reward": 677.1033887384333, "step": 54000}
{"episode": 55.0, "batch_reward": 0.41156022098660466, "critic_loss": 2.0433017809391023, "actor_loss": -60.08487212371826, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.633800745010376, "episode_reward": 83.20173990238507, "step": 55000}
{"episode": 56.0, "batch_reward": 0.4078401128649712, "critic_loss": 2.314947260558605, "actor_loss": -61.5470189743042, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 501.14696764945984, "episode_reward": 385.35465905930164, "step": 56000}
{"episode": 57.0, "batch_reward": 0.4065230986177921, "critic_loss": 2.2521124653816225, "actor_loss": -61.57444544219971, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.2812659740448, "episode_reward": 94.72396766963932, "step": 57000}
{"episode": 58.0, "batch_reward": 0.40005649065971377, "critic_loss": 2.3516948436498644, "actor_loss": -59.39664882659912, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 458.52474308013916, "episode_reward": 92.44623115528415, "step": 58000}
{"episode": 59.0, "batch_reward": 0.39599173375964164, "critic_loss": 2.374154405593872, "actor_loss": -59.21388132476807, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 24.288556575775146, "episode_reward": 106.3037697438556, "step": 59000}
{"episode": 60.0, "batch_reward": 0.3941754987239838, "critic_loss": 2.343947968006134, "actor_loss": -64.05373336791992, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 508.22288703918457, "episode_reward": 735.0074965858987, "step": 60000}
{"episode": 61.0, "batch_reward": 0.3964129672944546, "critic_loss": 2.4645496975183487, "actor_loss": -64.28398780059814, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 39.77116942405701, "episode_reward": 76.43057952260739, "step": 61000}
{"episode": 62.0, "batch_reward": 0.3941481564640999, "critic_loss": 2.4309857647418975, "actor_loss": -66.58557367706298, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 487.16404128074646, "episode_reward": 628.6902575661923, "step": 62000}
{"episode": 63.0, "batch_reward": 0.4011745656132698, "critic_loss": 2.372718097925186, "actor_loss": -66.86652198028564, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 24.2457537651062, "episode_reward": 723.9834232524798, "step": 63000}
{"episode": 64.0, "batch_reward": 0.40359388867020607, "critic_loss": 2.295891239285469, "actor_loss": -62.48323524475098, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 485.7228298187256, "episode_reward": 685.7527129786982, "step": 64000}
{"episode": 65.0, "batch_reward": 0.40300620877742765, "critic_loss": 2.3154411383867264, "actor_loss": -62.63178563690185, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.52157473564148, "episode_reward": 65.19006729746985, "step": 65000}
{"episode": 66.0, "batch_reward": 0.4023860178589821, "critic_loss": 2.328663279771805, "actor_loss": -57.508442916870116, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 489.9735040664673, "episode_reward": 676.7996032624055, "step": 66000}
{"episode": 67.0, "batch_reward": 0.40837515851855277, "critic_loss": 2.3888066205978395, "actor_loss": -57.85829328155518, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.697937488555908, "episode_reward": 756.1190846227065, "step": 67000}
{"episode": 68.0, "batch_reward": 0.40901475861668585, "critic_loss": 2.4233162536621093, "actor_loss": -49.19938074493408, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 492.6166760921478, "episode_reward": 29.430282863649744, "step": 68000}
{"episode": 69.0, "batch_reward": 0.406111759185791, "critic_loss": 2.411802912116051, "actor_loss": -48.98201700592041, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.592055082321167, "episode_reward": 651.7176240889519, "step": 69000}
{"episode": 70.0, "batch_reward": 0.4109687567949295, "critic_loss": 2.431947503209114, "actor_loss": -53.689884658813476, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 456.29274916648865, "episode_reward": 614.805353898643, "step": 70000}
{"episode": 71.0, "batch_reward": 0.40767341178655625, "critic_loss": 2.4547370970249176, "actor_loss": -53.640030685424804, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 39.97149395942688, "episode_reward": 15.070941418398004, "step": 71000}
{"episode": 72.0, "batch_reward": 0.40912592911720275, "critic_loss": 2.6081256083250044, "actor_loss": -49.51240574645996, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 440.9423248767853, "episode_reward": 673.351138697649, "step": 72000}
{"episode": 73.0, "batch_reward": 0.4115832783281803, "critic_loss": 2.731135328412056, "actor_loss": -49.67279769134522, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.236845016479492, "episode_reward": 545.1433439885104, "step": 73000}
{"episode": 74.0, "batch_reward": 0.41256378272175787, "critic_loss": 3.0851661913394928, "actor_loss": -37.028209358215335, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 431.02825927734375, "episode_reward": 666.0188784227619, "step": 74000}
{"episode": 75.0, "batch_reward": 0.4134564820230007, "critic_loss": 3.1196635793447496, "actor_loss": -37.21656666183472, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.447679042816162, "episode_reward": 63.696917042239214, "step": 75000}
{"episode": 76.0, "batch_reward": 0.4115361268818378, "critic_loss": 3.3767371439933775, "actor_loss": -29.484924907684327, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 459.26614022254944, "episode_reward": 547.5754298168949, "step": 76000}
{"episode": 77.0, "batch_reward": 0.41116734346747397, "critic_loss": 3.688544682979584, "actor_loss": -29.46586191558838, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 23.247472047805786, "episode_reward": 36.920987057289686, "step": 77000}
{"episode": 78.0, "batch_reward": 0.4050827603340149, "critic_loss": 4.3916002831459044, "actor_loss": -28.592208726882934, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 440.5474503040314, "episode_reward": 15.977073233570852, "step": 78000}
{"episode": 79.0, "batch_reward": 0.4011002690196037, "critic_loss": 4.812216924905777, "actor_loss": -28.244209356307984, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.3727970123291, "episode_reward": 16.123119159107365, "step": 79000}
{"episode": 80.0, "batch_reward": 0.3952623056769371, "critic_loss": 5.420701610565185, "actor_loss": -14.886950764179229, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 442.22564363479614, "episode_reward": 78.27983365543942, "step": 80000}
{"episode": 81.0, "batch_reward": 0.3948292653262615, "critic_loss": 5.4924268441200255, "actor_loss": -14.470946281433106, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.02111792564392, "episode_reward": 630.7150430099922, "step": 81000}
{"episode": 82.0, "batch_reward": 0.39391077691316606, "critic_loss": 6.508611919879914, "actor_loss": -17.19457759463787, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 484.85323190689087, "episode_reward": 43.841849970380316, "step": 82000}
{"episode": 83.0, "batch_reward": 0.3927875430285931, "critic_loss": 7.226127491474152, "actor_loss": -17.348287336349486, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.838892698287964, "episode_reward": 689.4894788621876, "step": 83000}
{"episode": 84.0, "batch_reward": 0.39662984424829484, "critic_loss": 7.52756993842125, "actor_loss": -31.036996822357178, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 455.042338848114, "episode_reward": 693.6625350668407, "step": 84000}
{"episode": 85.0, "batch_reward": 0.40195570430159566, "critic_loss": 8.25935315656662, "actor_loss": -31.373248111724852, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.627857446670532, "episode_reward": 660.331410568387, "step": 85000}
{"episode": 86.0, "batch_reward": 0.40381244775652886, "critic_loss": 10.018583614349366, "actor_loss": -41.56748504638672, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 480.781033039093, "episode_reward": 703.5739621447565, "step": 86000}
{"episode": 87.0, "batch_reward": 0.4075439088344574, "critic_loss": 12.375609498500824, "actor_loss": -41.78323260498047, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.31243085861206, "episode_reward": 660.6352973347424, "step": 87000}
{"episode": 88.0, "batch_reward": 0.41088568639755246, "critic_loss": 12.392054224967957, "actor_loss": -47.32121141052246, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 483.5487906932831, "episode_reward": 697.5085884831227, "step": 88000}
{"episode": 89.0, "batch_reward": 0.4133902981877327, "critic_loss": 12.657268996715546, "actor_loss": -47.5717555770874, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.354179620742798, "episode_reward": 720.6942809554481, "step": 89000}
{"episode": 90.0, "batch_reward": 0.4162444535195827, "critic_loss": 12.659598815917969, "actor_loss": -51.18607864379883, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 461.93140983581543, "episode_reward": 527.8596370194308, "step": 90000}
{"episode": 91.0, "batch_reward": 0.4171530175507069, "critic_loss": 11.273980230808258, "actor_loss": -51.303444427490234, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.006232261657715, "episode_reward": 801.3982253478838, "step": 91000}
{"episode": 92.0, "batch_reward": 0.41851014745235443, "critic_loss": 11.302503548145294, "actor_loss": -52.169148361206055, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 412.216849565506, "episode_reward": 12.794147766366775, "step": 92000}
{"episode": 93.0, "batch_reward": 0.4177960749566555, "critic_loss": 10.299826894283294, "actor_loss": -52.22585452270508, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.614722728729248, "episode_reward": 753.7211181844774, "step": 93000}
{"episode": 94.0, "batch_reward": 0.42170108130574224, "critic_loss": 10.729216800689697, "actor_loss": -52.76927653503418, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 437.67364597320557, "episode_reward": 700.1955733890275, "step": 94000}
{"episode": 95.0, "batch_reward": 0.42208507713675497, "critic_loss": 11.445765965938568, "actor_loss": -52.674963722229, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.364766836166382, "episode_reward": 528.977061346274, "step": 95000}
{"episode": 96.0, "batch_reward": 0.42372105729579923, "critic_loss": 11.071143684864044, "actor_loss": -53.431694923400876, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 477.02206563949585, "episode_reward": 692.9411027302805, "step": 96000}
{"episode": 97.0, "batch_reward": 0.4301345318257809, "critic_loss": 11.836399935722351, "actor_loss": -53.81504878997803, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.148252964019775, "episode_reward": 725.3156447386077, "step": 97000}
{"episode": 98.0, "batch_reward": 0.4326161891222, "critic_loss": 13.58691047668457, "actor_loss": -56.382618278503415, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 458.20284700393677, "episode_reward": 701.3848828020142, "step": 98000}
{"episode": 99.0, "batch_reward": 0.4344066591858864, "critic_loss": 14.545147790908814, "actor_loss": -56.679590538024904, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.752625942230225, "episode_reward": 792.6622215460062, "step": 99000}
{"episode": 100.0, "batch_reward": 0.4364016455709934, "critic_loss": 19.323652015686037, "actor_loss": -57.04896043395996, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 461.32171726226807, "episode_reward": 725.0941372613245, "step": 100000}
{"episode": 101.0, "batch_reward": 0.44004920208454135, "critic_loss": 22.210557262897492, "actor_loss": -57.19567848205566, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.4639151096344, "episode_reward": 741.0739517607283, "step": 101000}
{"episode": 102.0, "batch_reward": 0.4425584650039673, "critic_loss": 20.371871853351593, "actor_loss": -58.338226936340334, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 486.67853593826294, "episode_reward": 801.8921274738101, "step": 102000}
{"episode": 103.0, "batch_reward": 0.44509238001704216, "critic_loss": 20.55356021261215, "actor_loss": -58.507638206481936, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.355019569396973, "episode_reward": 652.4433471595197, "step": 103000}
{"episode": 104.0, "batch_reward": 0.4483322419524193, "critic_loss": 19.483795082092286, "actor_loss": -60.35728759765625, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 457.7811324596405, "episode_reward": 668.8021539357262, "step": 104000}
{"episode": 105.0, "batch_reward": 0.45126663503050807, "critic_loss": 18.420304513454436, "actor_loss": -60.52645394134522, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.95400905609131, "episode_reward": 796.2745990149169, "step": 105000}
{"episode": 106.0, "batch_reward": 0.45491851383447646, "critic_loss": 16.11307712173462, "actor_loss": -59.812867210388184, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 507.4393756389618, "episode_reward": 730.788890035948, "step": 106000}
{"episode": 107.0, "batch_reward": 0.4578073472082615, "critic_loss": 14.929617792606354, "actor_loss": -60.222150077819826, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.326074361801147, "episode_reward": 723.2794320187825, "step": 107000}
{"episode": 108.0, "batch_reward": 0.45722197166085243, "critic_loss": 15.440068286418915, "actor_loss": -60.86487133026123, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 513.8023955821991, "episode_reward": 17.68824904569454, "step": 108000}
{"episode": 109.0, "batch_reward": 0.45303719303011897, "critic_loss": 13.861394421100616, "actor_loss": -60.30071022033692, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.347626209259033, "episode_reward": 15.313245144471457, "step": 109000}
{"episode": 110.0, "batch_reward": 0.45065474262833594, "critic_loss": 13.436579806804657, "actor_loss": -59.43518790435791, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 445.6610817909241, "episode_reward": 234.53719431190396, "step": 110000}
{"episode": 111.0, "batch_reward": 0.45028803756833075, "critic_loss": 12.35092411851883, "actor_loss": -59.329431678771975, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 45.39216613769531, "episode_reward": 787.0729701741058, "step": 111000}
{"episode": 112.0, "batch_reward": 0.4527750627398491, "critic_loss": 13.907057227611542, "actor_loss": -60.346138282775875, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 525.9357702732086, "episode_reward": 747.6878734826164, "step": 112000}
{"episode": 113.0, "batch_reward": 0.45548399376869203, "critic_loss": 13.508834385871888, "actor_loss": -60.33930221557617, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 24.81369638442993, "episode_reward": 747.5558393996434, "step": 113000}
{"episode": 114.0, "batch_reward": 0.45812341904640197, "critic_loss": 16.33791500043869, "actor_loss": -62.30846319580078, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 462.26339769363403, "episode_reward": 705.195531217462, "step": 114000}
{"episode": 115.0, "batch_reward": 0.46067353448271753, "critic_loss": 17.392188645839692, "actor_loss": -62.360894660949704, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.62851333618164, "episode_reward": 750.3873880659517, "step": 115000}
{"episode": 116.0, "batch_reward": 0.4605948258638382, "critic_loss": 20.45298104286194, "actor_loss": -61.94829013824463, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 490.2709062099457, "episode_reward": 742.5520495720596, "step": 116000}
{"episode": 117.0, "batch_reward": 0.46311232283711434, "critic_loss": 22.47721288394928, "actor_loss": -62.19585446929931, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.591923475265503, "episode_reward": 686.6785501557052, "step": 117000}
{"episode": 118.0, "batch_reward": 0.46444207218289374, "critic_loss": 20.59441360759735, "actor_loss": -63.493424919128415, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 463.80106592178345, "episode_reward": 739.2964006482658, "step": 118000}
{"episode": 119.0, "batch_reward": 0.4691062404513359, "critic_loss": 20.17000749206543, "actor_loss": -63.83965521240234, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 23.0422146320343, "episode_reward": 572.4336038844523, "step": 119000}
{"episode": 120.0, "batch_reward": 0.47054628509283064, "critic_loss": 19.786598363876344, "actor_loss": -62.97009450531006, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 447.1758484840393, "episode_reward": 833.5760481649662, "step": 120000}
{"episode": 121.0, "batch_reward": 0.4714251678586006, "critic_loss": 21.025663828849794, "actor_loss": -63.05020201873779, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.24199891090393, "episode_reward": 767.2159135493174, "step": 121000}
{"episode": 122.0, "batch_reward": 0.4764433828890324, "critic_loss": 21.668660786628724, "actor_loss": -63.3480294342041, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 486.9707429409027, "episode_reward": 676.519021478836, "step": 122000}
{"episode": 123.0, "batch_reward": 0.4774142142534256, "critic_loss": 22.784091276168823, "actor_loss": -63.53803440093994, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.539108276367188, "episode_reward": 634.9436431297811, "step": 123000}
{"episode": 124.0, "batch_reward": 0.47841598314046857, "critic_loss": 23.228351088047027, "actor_loss": -63.782247596740724, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 461.9303328990936, "episode_reward": 827.3928949330805, "step": 124000}
{"episode": 125.0, "batch_reward": 0.481632251560688, "critic_loss": 24.318117066383362, "actor_loss": -63.86562113952637, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.060174226760864, "episode_reward": 809.1198655394904, "step": 125000}
{"episode": 126.0, "batch_reward": 0.48329696121811866, "critic_loss": 25.801802911758422, "actor_loss": -63.75395858001709, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 468.25478649139404, "episode_reward": 720.1738274285583, "step": 126000}
{"episode": 127.0, "batch_reward": 0.48599225184321404, "critic_loss": 26.0177484331131, "actor_loss": -63.82895115661621, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.529186248779297, "episode_reward": 700.5088302011762, "step": 127000}
{"episode": 128.0, "batch_reward": 0.4853849876523018, "critic_loss": 26.232556649208068, "actor_loss": -63.99560404205322, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 433.69003534317017, "episode_reward": 298.46198787912357, "step": 128000}
{"episode": 129.0, "batch_reward": 0.4850596961081028, "critic_loss": 28.25298438644409, "actor_loss": -63.999187461853026, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.791475772857666, "episode_reward": 801.300725425141, "step": 129000}
{"episode": 130.0, "batch_reward": 0.48931683734059334, "critic_loss": 27.79179056930542, "actor_loss": -61.71243901824951, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 482.659916639328, "episode_reward": 877.5140441202474, "step": 130000}
{"episode": 131.0, "batch_reward": 0.4915753788053989, "critic_loss": 25.61919812488556, "actor_loss": -61.932623023986814, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 45.40865159034729, "episode_reward": 779.0235035387722, "step": 131000}
{"episode": 132.0, "batch_reward": 0.49350112053751943, "critic_loss": 24.522292397499083, "actor_loss": -62.7125673904419, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 463.28246665000916, "episode_reward": 882.075409775142, "step": 132000}
{"episode": 133.0, "batch_reward": 0.49710923647880556, "critic_loss": 21.96393475341797, "actor_loss": -62.883121940612796, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.229772567749023, "episode_reward": 782.0585490230516, "step": 133000}
{"episode": 134.0, "batch_reward": 0.4984591405689716, "critic_loss": 21.298596374511717, "actor_loss": -62.24233587646484, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 532.1671679019928, "episode_reward": 614.9247188066329, "step": 134000}
{"episode": 135.0, "batch_reward": 0.49826762342453, "critic_loss": 19.89249797153473, "actor_loss": -62.13898143005371, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.208154439926147, "episode_reward": 744.2226746024588, "step": 135000}
{"episode": 136.0, "batch_reward": 0.5032284369170665, "critic_loss": 19.328531566143035, "actor_loss": -63.050947540283204, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 482.42564153671265, "episode_reward": 795.3376514525498, "step": 136000}
{"episode": 137.0, "batch_reward": 0.503845180273056, "critic_loss": 21.748994899749757, "actor_loss": -63.04132246398926, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.361206769943237, "episode_reward": 688.4790632623237, "step": 137000}
{"episode": 138.0, "batch_reward": 0.5035122063159942, "critic_loss": 22.347413368225098, "actor_loss": -62.77575856781006, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 533.6964490413666, "episode_reward": 684.7010595826898, "step": 138000}
{"episode": 139.0, "batch_reward": 0.507306919157505, "critic_loss": 21.259749952316284, "actor_loss": -62.997710563659666, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.964096069335938, "episode_reward": 863.114169339308, "step": 139000}
{"episode": 140.0, "batch_reward": 0.5092887942194939, "critic_loss": 19.52221435213089, "actor_loss": -62.484629806518555, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 495.82154178619385, "episode_reward": 826.6297524778674, "step": 140000}
{"episode": 141.0, "batch_reward": 0.5085658082664013, "critic_loss": 20.410935112953187, "actor_loss": -62.42234873199463, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 45.07891058921814, "episode_reward": 131.88858416000207, "step": 141000}
{"episode": 142.0, "batch_reward": 0.5086665337383747, "critic_loss": 20.343944483280183, "actor_loss": -62.99153870391846, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 481.71576714515686, "episode_reward": 819.7224875503764, "step": 142000}
{"episode": 143.0, "batch_reward": 0.5103614628911018, "critic_loss": 19.723914355278016, "actor_loss": -62.96313843536377, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.940490245819092, "episode_reward": 458.8717925618047, "step": 143000}
{"episode": 144.0, "batch_reward": 0.5071247469186783, "critic_loss": 19.1332322306633, "actor_loss": -62.89922470855713, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 517.340048789978, "episode_reward": 368.45817717715215, "step": 144000}
{"episode": 145.0, "batch_reward": 0.5078493245244026, "critic_loss": 19.699725696086883, "actor_loss": -62.988469383239746, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.737410068511963, "episode_reward": 829.2145137509611, "step": 145000}
{"episode": 146.0, "batch_reward": 0.511104006767273, "critic_loss": 18.73950717496872, "actor_loss": -65.1604446258545, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 531.9840877056122, "episode_reward": 842.2624825689683, "step": 146000}
{"episode": 147.0, "batch_reward": 0.5140502764284611, "critic_loss": 16.903929575920106, "actor_loss": -65.27308032989502, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.243857860565186, "episode_reward": 695.0397351275565, "step": 147000}
{"episode": 148.0, "batch_reward": 0.5133918865025043, "critic_loss": 15.949709623813629, "actor_loss": -64.33439071655273, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 470.35112619400024, "episode_reward": 725.0287656470675, "step": 148000}
{"episode": 149.0, "batch_reward": 0.5143757770359516, "critic_loss": 16.428583033561708, "actor_loss": -64.47284403991699, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.953511953353882, "episode_reward": 788.0968935487249, "step": 149000}
{"episode": 150.0, "batch_reward": 0.5199614835977554, "critic_loss": 15.632316535949707, "actor_loss": -66.66952393341064, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "step": 150000}
