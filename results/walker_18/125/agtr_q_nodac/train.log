{"episode": 1.0, "duration": 18.55320405960083, "episode_reward": 28.177075776326152, "step": 1000}
{"episode": 2.0, "duration": 1.6927180290222168, "episode_reward": 69.84046218736019, "step": 2000}
{"episode": 3.0, "batch_reward": 0.047940039715942996, "actor_loss": -79.58554735676009, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499180007, "duration": 59.61286377906799, "episode_reward": 23.09729948686163, "step": 3000}
{"episode": 4.0, "batch_reward": 0.04884319942072034, "actor_loss": -76.37033807373047, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.610735654830933, "episode_reward": 82.52761006839715, "step": 4000}
{"episode": 5.0, "batch_reward": 0.05771825589239597, "actor_loss": -76.85195503234863, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.24114727973938, "episode_reward": 89.23107684512114, "step": 5000}
{"episode": 6.0, "batch_reward": 0.060274470295757054, "actor_loss": -77.51463471984863, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.57821750640869, "episode_reward": 70.63880629222542, "step": 6000}
{"episode": 7.0, "batch_reward": 0.07541920342668891, "actor_loss": -78.18261337280273, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.636089324951172, "episode_reward": 284.99113148136416, "step": 7000}
{"episode": 8.0, "batch_reward": 0.09198821271955968, "actor_loss": -78.91166809082031, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.564250707626343, "episode_reward": 85.45376552421966, "step": 8000}
{"episode": 9.0, "batch_reward": 0.10052077310532331, "actor_loss": -79.20858573913574, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.1547908782959, "episode_reward": 190.8097458997016, "step": 9000}
{"episode": 10.0, "batch_reward": 0.10137873461097478, "actor_loss": -79.00649752807617, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.645315647125244, "episode_reward": 79.21504322980496, "step": 10000}
{"episode": 11.0, "batch_reward": 0.09678707134723663, "actor_loss": -78.43415225219726, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 44.83881688117981, "episode_reward": 46.45890873811273, "step": 11000}
{"episode": 12.0, "batch_reward": 0.09481739321351051, "actor_loss": -78.00717053222657, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.41472887992859, "episode_reward": 78.48249985975876, "step": 12000}
{"episode": 13.0, "batch_reward": 0.09266494092345237, "actor_loss": -77.66719566345215, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.144296169281006, "episode_reward": 69.66036832304324, "step": 13000}
{"episode": 14.0, "batch_reward": 0.09668826614320278, "actor_loss": -77.88169718933105, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.517273426055908, "episode_reward": 241.5859351445491, "step": 14000}
{"episode": 15.0, "batch_reward": 0.10971726920455695, "actor_loss": -78.25151152038575, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.45388388633728, "episode_reward": 324.9984700166622, "step": 15000}
{"episode": 16.0, "batch_reward": 0.12271848201751709, "actor_loss": -78.58035939025879, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.356801748275757, "episode_reward": 317.4134781558572, "step": 16000}
{"episode": 17.0, "batch_reward": 0.1359219731837511, "actor_loss": -78.85854695129395, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.7702739238739, "episode_reward": 313.317684418729, "step": 17000}
{"episode": 18.0, "batch_reward": 0.14700302128493786, "actor_loss": -79.14782568359375, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.448121547698975, "episode_reward": 349.45555178897234, "step": 18000}
{"episode": 19.0, "batch_reward": 0.1514720637500286, "actor_loss": -79.06853735351562, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.264559507369995, "episode_reward": 70.058406856435, "step": 19000}
{"episode": 20.0, "batch_reward": 0.14599208038300276, "actor_loss": -78.63421215820313, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.599839687347412, "episode_reward": 129.57170904814052, "step": 20000}
{"episode": 21.0, "batch_reward": 0.1502314144000411, "actor_loss": -78.66346542358399, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 44.98494052886963, "episode_reward": 280.9605143806987, "step": 21000}
{"episode": 22.0, "batch_reward": 0.15817528909444808, "actor_loss": -78.91116719055175, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.96234917640686, "episode_reward": 329.5471317543524, "step": 22000}
{"episode": 23.0, "batch_reward": 0.16679420951753854, "actor_loss": -79.15616165161133, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.59906554222107, "episode_reward": 366.54916534655644, "step": 23000}
{"episode": 24.0, "batch_reward": 0.17416369304805995, "actor_loss": -79.34298934936524, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.697612047195435, "episode_reward": 347.4877888289698, "step": 24000}
{"episode": 25.0, "batch_reward": 0.1768993530869484, "actor_loss": -79.41019950866699, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.079192399978638, "episode_reward": 259.3219713700714, "step": 25000}
{"episode": 26.0, "batch_reward": 0.179494920194149, "actor_loss": -79.45199087524414, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.418619871139526, "episode_reward": 92.33789994459126, "step": 26000}
{"episode": 27.0, "batch_reward": 0.17893567615002393, "actor_loss": -79.5006190032959, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.64550805091858, "episode_reward": 166.62620097463002, "step": 27000}
{"episode": 28.0, "batch_reward": 0.17832122686505317, "actor_loss": -79.41116854858399, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.16130805015564, "episode_reward": 143.76977114447232, "step": 28000}
{"episode": 29.0, "batch_reward": 0.1767874008715153, "actor_loss": -79.32076022338867, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.17455291748047, "episode_reward": 153.3694233419582, "step": 29000}
{"episode": 30.0, "batch_reward": 0.17828421626985072, "actor_loss": -79.30563851928711, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.656800031661987, "episode_reward": 346.25470969674336, "step": 30000}
{"episode": 31.0, "batch_reward": 0.18044855870306492, "actor_loss": -79.39182289123535, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 44.540910720825195, "episode_reward": 149.78431097692777, "step": 31000}
{"episode": 32.0, "batch_reward": 0.1822972095012665, "actor_loss": -79.47101425170898, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.532848596572876, "episode_reward": 318.5932780865169, "step": 32000}
{"episode": 33.0, "batch_reward": 0.18645947827398776, "actor_loss": -79.5934709777832, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.223047018051147, "episode_reward": 336.44259942079077, "step": 33000}
{"episode": 34.0, "batch_reward": 0.19125975799560546, "actor_loss": -79.77573696899414, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.84392738342285, "episode_reward": 404.37114162960665, "step": 34000}
{"episode": 35.0, "batch_reward": 0.1948005512803793, "actor_loss": -79.85093936157226, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.40081262588501, "episode_reward": 134.95994540783866, "step": 35000}
{"episode": 36.0, "batch_reward": 0.19443208530545233, "actor_loss": -79.85190950012208, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.146709203720093, "episode_reward": 217.835973777551, "step": 36000}
{"episode": 37.0, "batch_reward": 0.1936374258995056, "actor_loss": -79.79192971801758, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.014107704162598, "episode_reward": 105.44550741070428, "step": 37000}
{"episode": 38.0, "batch_reward": 0.19151878724992275, "actor_loss": -79.64698013305664, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.477978467941284, "episode_reward": 267.78763797220444, "step": 38000}
{"episode": 39.0, "batch_reward": 0.19569350065290927, "actor_loss": -79.84781883239746, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.455079317092896, "episode_reward": 333.2387163867212, "step": 39000}
{"episode": 40.0, "batch_reward": 0.20016944275796414, "actor_loss": -79.8878201904297, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.202100038528442, "episode_reward": 399.73456940159616, "step": 40000}
{"episode": 41.0, "batch_reward": 0.20390999352931977, "actor_loss": -80.01171545410156, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 44.697617053985596, "episode_reward": 364.02462331942587, "step": 41000}
{"episode": 42.0, "batch_reward": 0.2074627393335104, "actor_loss": -80.08925369262695, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.290247917175293, "episode_reward": 337.9756469916129, "step": 42000}
{"episode": 43.0, "batch_reward": 0.21167343141138553, "actor_loss": -80.16833741760254, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.569852828979492, "episode_reward": 422.91699977967403, "step": 43000}
{"episode": 44.0, "batch_reward": 0.21549016895890236, "actor_loss": -80.29006257629395, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.022829055786133, "episode_reward": 227.10479903143477, "step": 44000}
{"episode": 45.0, "batch_reward": 0.21638386894762515, "actor_loss": -80.34401103210449, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.267913818359375, "episode_reward": 365.56121724670174, "step": 45000}
{"episode": 46.0, "batch_reward": 0.21662429647147655, "actor_loss": -80.29603788757325, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.573994159698486, "episode_reward": 64.82266694327437, "step": 46000}
{"episode": 47.0, "batch_reward": 0.21670474998652936, "actor_loss": -80.34665762329101, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.382152318954468, "episode_reward": 376.6316282314548, "step": 47000}
{"episode": 48.0, "batch_reward": 0.21676983618736267, "actor_loss": -80.35381239318848, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.51864719390869, "episode_reward": 102.20452492742459, "step": 48000}
{"episode": 49.0, "batch_reward": 0.21816453090310098, "actor_loss": -80.36321685791016, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.387856006622314, "episode_reward": 355.2893331333311, "step": 49000}
{"episode": 50.0, "batch_reward": 0.21991215959191324, "actor_loss": -80.42374772644042, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.336634159088135, "episode_reward": 363.8336193417553, "step": 50000}
{"episode": 51.0, "batch_reward": 0.22153603784739972, "actor_loss": -80.47391381835938, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 44.88905143737793, "episode_reward": 192.89464279934927, "step": 51000}
{"episode": 52.0, "batch_reward": 0.2199247134178877, "actor_loss": -80.42402027893067, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.156723737716675, "episode_reward": 54.7434079064608, "step": 52000}
{"episode": 53.0, "batch_reward": 0.21824375207722188, "actor_loss": -80.42754855346679, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.384713649749756, "episode_reward": 324.27396703043325, "step": 53000}
{"episode": 54.0, "batch_reward": 0.22133644719421863, "actor_loss": -80.43770478820801, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 23.911492586135864, "episode_reward": 349.2229394092474, "step": 54000}
{"episode": 55.0, "batch_reward": 0.22244872760772705, "actor_loss": -80.48915466308594, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.78554058074951, "episode_reward": 174.8254219287058, "step": 55000}
{"episode": 56.0, "batch_reward": 0.22254052226245402, "actor_loss": -80.48447871398926, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.999678134918213, "episode_reward": 345.8840230362989, "step": 56000}
{"episode": 57.0, "batch_reward": 0.22593334360420703, "actor_loss": -80.55109117126464, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.007327795028687, "episode_reward": 329.1842749883236, "step": 57000}
{"episode": 58.0, "batch_reward": 0.22616730655729772, "actor_loss": -80.5795774230957, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.415334463119507, "episode_reward": 397.46324276996546, "step": 58000}
{"episode": 59.0, "batch_reward": 0.22788288044929506, "actor_loss": -80.57909671020508, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.25755786895752, "episode_reward": 137.4622183090352, "step": 59000}
{"episode": 60.0, "batch_reward": 0.22798461598157882, "actor_loss": -80.61448249816894, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.180394411087036, "episode_reward": 387.1268878513449, "step": 60000}
{"episode": 61.0, "batch_reward": 0.22855799943208693, "actor_loss": -80.58367370605468, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 45.109639406204224, "episode_reward": 72.38312378917614, "step": 61000}
{"episode": 62.0, "batch_reward": 0.22842229455709456, "actor_loss": -80.60771783447265, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.428624868392944, "episode_reward": 365.465731825598, "step": 62000}
{"episode": 63.0, "batch_reward": 0.23055615796148776, "actor_loss": -80.61732456970215, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.700865507125854, "episode_reward": 357.7620900855804, "step": 63000}
{"episode": 64.0, "batch_reward": 0.23263238084316254, "actor_loss": -80.70944219970703, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.782346487045288, "episode_reward": 231.74213246035453, "step": 64000}
{"episode": 65.0, "batch_reward": 0.23104990164935588, "actor_loss": -80.6623660583496, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.943740367889404, "episode_reward": 100.20132629620225, "step": 65000}
{"episode": 66.0, "batch_reward": 0.22974898739159108, "actor_loss": -80.65863412475586, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.70721983909607, "episode_reward": 347.5437253041507, "step": 66000}
{"episode": 67.0, "batch_reward": 0.23203834702074527, "actor_loss": -80.72729290771484, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.313470602035522, "episode_reward": 368.4302393988635, "step": 67000}
{"episode": 68.0, "batch_reward": 0.23388751116394996, "actor_loss": -80.70499705505371, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.606573581695557, "episode_reward": 217.7654123136844, "step": 68000}
{"episode": 69.0, "batch_reward": 0.23381180363893508, "actor_loss": -80.7613708190918, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.20109748840332, "episode_reward": 390.50602386234976, "step": 69000}
{"episode": 70.0, "batch_reward": 0.23653778168559075, "actor_loss": -80.83997734069824, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.28741765022278, "episode_reward": 359.83617886561984, "step": 70000}
{"episode": 71.0, "batch_reward": 0.23580029724538326, "actor_loss": -80.87667166137695, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 45.872456073760986, "episode_reward": 182.67423703339028, "step": 71000}
{"episode": 72.0, "batch_reward": 0.2352021182179451, "actor_loss": -81.02383892822266, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.063643217086792, "episode_reward": 36.36110038175313, "step": 72000}
{"episode": 73.0, "batch_reward": 0.23502724029123784, "actor_loss": -81.01286277770996, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.38400888442993, "episode_reward": 286.6723613682164, "step": 73000}
{"episode": 74.0, "batch_reward": 0.23343898448348047, "actor_loss": -81.02499937438965, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.153037548065186, "episode_reward": 91.3126300425115, "step": 74000}
{"episode": 75.0, "batch_reward": 0.23346594263613224, "actor_loss": -80.99027378845214, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.033782243728638, "episode_reward": 374.0548257288791, "step": 75000}
{"episode": 76.0, "batch_reward": 0.2348395307958126, "actor_loss": -81.01710832214356, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.179954767227173, "episode_reward": 265.8211807902842, "step": 76000}
{"episode": 77.0, "batch_reward": 0.23595609225332737, "actor_loss": -81.0475733795166, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.980910301208496, "episode_reward": 264.753070089753, "step": 77000}
{"episode": 78.0, "batch_reward": 0.23358023676276207, "actor_loss": -81.04572891235351, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.654107809066772, "episode_reward": 58.9096895989307, "step": 78000}
{"episode": 79.0, "batch_reward": 0.2330449950695038, "actor_loss": -80.96822227478027, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.27770185470581, "episode_reward": 284.46507178425315, "step": 79000}
{"episode": 80.0, "batch_reward": 0.2316378784328699, "actor_loss": -80.92585060119629, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.15159583091736, "episode_reward": 64.41575382556962, "step": 80000}
{"episode": 81.0, "batch_reward": 0.23288648822903632, "actor_loss": -80.94638269042969, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 45.09111571311951, "episode_reward": 403.56465202165856, "step": 81000}
{"episode": 82.0, "batch_reward": 0.23127264547348023, "actor_loss": -80.88935920715332, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.7640483379364, "episode_reward": 23.262666417302793, "step": 82000}
{"episode": 83.0, "batch_reward": 0.23244411735236645, "actor_loss": -80.85599450683594, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.511852025985718, "episode_reward": 381.54527442027097, "step": 83000}
{"episode": 84.0, "batch_reward": 0.2328161591142416, "actor_loss": -80.83726373291016, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.81792187690735, "episode_reward": 257.87688306802823, "step": 84000}
{"episode": 85.0, "batch_reward": 0.2322025732398033, "actor_loss": -80.83149745178223, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.72452211380005, "episode_reward": 92.26108582327333, "step": 85000}
{"episode": 86.0, "batch_reward": 0.229130119279027, "actor_loss": -80.75182864379883, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.518444538116455, "episode_reward": 19.184460909350832, "step": 86000}
{"episode": 87.0, "batch_reward": 0.22863265612721442, "actor_loss": -80.65190716552735, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.323192596435547, "episode_reward": 202.1290015589944, "step": 87000}
{"episode": 88.0, "batch_reward": 0.22696617130935193, "actor_loss": -80.62292840576171, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.34078025817871, "episode_reward": 111.13948333648024, "step": 88000}
{"episode": 89.0, "batch_reward": 0.226827849522233, "actor_loss": -80.59401626586914, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.51112151145935, "episode_reward": 286.10027452336755, "step": 89000}
{"episode": 90.0, "batch_reward": 0.2267283681333065, "actor_loss": -80.51599629211425, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.655069589614868, "episode_reward": 16.698830031038217, "step": 90000}
{"episode": 91.0, "batch_reward": 0.22613228061795235, "actor_loss": -80.45815902709961, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 44.867058515548706, "episode_reward": 299.4093559769742, "step": 91000}
{"episode": 92.0, "batch_reward": 0.22603853112459182, "actor_loss": -80.54241886901856, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.0981285572052, "episode_reward": 85.32364241101764, "step": 92000}
{"episode": 93.0, "batch_reward": 0.2267573434561491, "actor_loss": -80.61145545959472, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.376729488372803, "episode_reward": 409.0985580305079, "step": 93000}
{"episode": 94.0, "batch_reward": 0.22686231434345244, "actor_loss": -80.54732748413086, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.663118600845337, "episode_reward": 223.9856080313777, "step": 94000}
{"episode": 95.0, "batch_reward": 0.22583186726272106, "actor_loss": -80.54001597595214, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.82166051864624, "episode_reward": 228.70271097420917, "step": 95000}
{"episode": 96.0, "batch_reward": 0.22570120126008988, "actor_loss": -80.50422537231445, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.271567821502686, "episode_reward": 15.744216896981388, "step": 96000}
{"episode": 97.0, "batch_reward": 0.2256431107968092, "actor_loss": -80.43671186828614, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.16456627845764, "episode_reward": 334.08614934245975, "step": 97000}
{"episode": 98.0, "batch_reward": 0.22709800846874714, "actor_loss": -80.45716082763671, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.399630784988403, "episode_reward": 384.5917014327376, "step": 98000}
{"episode": 99.0, "batch_reward": 0.22881990149617196, "actor_loss": -80.4763390197754, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.43185019493103, "episode_reward": 410.41322122926744, "step": 99000}
{"episode": 100.0, "batch_reward": 0.22985342697799205, "actor_loss": -80.53429402160644, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.532604694366455, "episode_reward": 298.5036044324998, "step": 100000}
{"episode": 101.0, "batch_reward": 0.2308385041207075, "actor_loss": -80.56377572631835, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 44.84390091896057, "episode_reward": 235.60044205778138, "step": 101000}
{"episode": 102.0, "batch_reward": 0.23025223696231842, "actor_loss": -80.59526844787598, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.257163286209106, "episode_reward": 422.46375067588434, "step": 102000}
{"episode": 103.0, "batch_reward": 0.23064101612567903, "actor_loss": -80.57882417297364, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.72309970855713, "episode_reward": 65.78540844443745, "step": 103000}
{"episode": 104.0, "batch_reward": 0.23067382457852365, "actor_loss": -80.57609226989746, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.5206081867218, "episode_reward": 360.6023670727494, "step": 104000}
{"episode": 105.0, "batch_reward": 0.23086407770216466, "actor_loss": -80.64707940673829, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.617279529571533, "episode_reward": 240.11803618414035, "step": 105000}
{"episode": 106.0, "batch_reward": 0.23192845053970815, "actor_loss": -80.71241915893555, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.100189447402954, "episode_reward": 362.3043848779219, "step": 106000}
{"episode": 107.0, "batch_reward": 0.2333054993748665, "actor_loss": -80.70409388732911, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.362550497055054, "episode_reward": 178.36206455846, "step": 107000}
{"episode": 108.0, "batch_reward": 0.23271007315814496, "actor_loss": -80.73095080566407, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.411425352096558, "episode_reward": 352.88737543581436, "step": 108000}
{"episode": 109.0, "batch_reward": 0.23398091423511505, "actor_loss": -80.81238339233398, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.305270433425903, "episode_reward": 244.61568536613953, "step": 109000}
{"episode": 110.0, "batch_reward": 0.23316875602304935, "actor_loss": -80.81822076416016, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.23159885406494, "episode_reward": 219.60657370284895, "step": 110000}
{"episode": 111.0, "batch_reward": 0.23427326902747153, "actor_loss": -80.83344090270997, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 45.06037712097168, "episode_reward": 419.5910862835134, "step": 111000}
{"episode": 112.0, "batch_reward": 0.2341707636117935, "actor_loss": -80.86038026428223, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.35202956199646, "episode_reward": 75.48826479188423, "step": 112000}
{"episode": 113.0, "batch_reward": 0.23300083868205548, "actor_loss": -80.80903010559082, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.74135708808899, "episode_reward": 24.223164758928142, "step": 113000}
{"episode": 114.0, "batch_reward": 0.2331520276516676, "actor_loss": -80.76865974426269, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.489757299423218, "episode_reward": 419.2405447610404, "step": 114000}
{"episode": 115.0, "batch_reward": 0.23433392326533795, "actor_loss": -80.82482914733886, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.58653712272644, "episode_reward": 316.5149105085002, "step": 115000}
{"episode": 116.0, "batch_reward": 0.23372719460725785, "actor_loss": -80.81212406921387, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.14829421043396, "episode_reward": 230.79568705175788, "step": 116000}
{"episode": 117.0, "batch_reward": 0.23473719967901707, "actor_loss": -80.86198820495605, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.54346251487732, "episode_reward": 207.9797492287453, "step": 117000}
{"episode": 118.0, "batch_reward": 0.2334664302021265, "actor_loss": -80.88630220031739, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.37889862060547, "episode_reward": 141.01174437003266, "step": 118000}
{"episode": 119.0, "batch_reward": 0.23403901445865632, "actor_loss": -80.94820509338379, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.6065456867218, "episode_reward": 359.85357433040156, "step": 119000}
{"episode": 120.0, "batch_reward": 0.2346865040063858, "actor_loss": -80.93515907287598, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.275243520736694, "episode_reward": 169.99290660478562, "step": 120000}
{"episode": 121.0, "batch_reward": 0.23427563020586967, "actor_loss": -80.88462559509277, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 45.065306425094604, "episode_reward": 404.0374723885654, "step": 121000}
{"episode": 122.0, "batch_reward": 0.2357724699527025, "actor_loss": -80.97520797729493, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.344465970993042, "episode_reward": 149.41105950097693, "step": 122000}
{"episode": 123.0, "batch_reward": 0.23362322589755058, "actor_loss": -80.92821655273437, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.18883442878723, "episode_reward": 165.95255101033146, "step": 123000}
{"episode": 124.0, "batch_reward": 0.2336646771878004, "actor_loss": -80.90848463439941, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.0387601852417, "episode_reward": 334.7701065834596, "step": 124000}
{"episode": 125.0, "batch_reward": 0.2349937283694744, "actor_loss": -80.92465725708009, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.91044330596924, "episode_reward": 419.95527565811415, "step": 125000}
{"episode": 126.0, "batch_reward": 0.23679828968644143, "actor_loss": -80.95353480529785, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.127485036849976, "episode_reward": 376.9575407923566, "step": 126000}
{"episode": 127.0, "batch_reward": 0.23730626280605793, "actor_loss": -81.05163702392578, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.39980721473694, "episode_reward": 278.52421659043415, "step": 127000}
{"episode": 128.0, "batch_reward": 0.23769589181244374, "actor_loss": -81.052683303833, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.248281002044678, "episode_reward": 137.44576907469002, "step": 128000}
{"episode": 129.0, "batch_reward": 0.23600581154227257, "actor_loss": -80.99475871276856, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.31076979637146, "episode_reward": 240.56337120080852, "step": 129000}
{"episode": 130.0, "batch_reward": 0.23726947520673275, "actor_loss": -81.04722431945801, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.08089327812195, "episode_reward": 471.4781189140649, "step": 130000}
{"episode": 131.0, "batch_reward": 0.23888806043565272, "actor_loss": -81.0297191772461, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 45.12527847290039, "episode_reward": 341.93286622444407, "step": 131000}
{"episode": 132.0, "batch_reward": 0.23864930494129658, "actor_loss": -81.05305691528321, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.82131338119507, "episode_reward": 70.74066786904594, "step": 132000}
{"episode": 133.0, "batch_reward": 0.23784646598994733, "actor_loss": -81.04003276062012, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.1639666557312, "episode_reward": 219.4507184881031, "step": 133000}
{"episode": 134.0, "batch_reward": 0.2372408875077963, "actor_loss": -80.99003384399414, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.65356993675232, "episode_reward": 204.90115891684553, "step": 134000}
{"episode": 135.0, "batch_reward": 0.23772243262827397, "actor_loss": -81.03753569030762, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.755200386047363, "episode_reward": 125.94479613767092, "step": 135000}
{"episode": 136.0, "batch_reward": 0.2384481353163719, "actor_loss": -81.03795973205567, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.437562942504883, "episode_reward": 466.5649980616172, "step": 136000}
{"episode": 137.0, "batch_reward": 0.2392512222379446, "actor_loss": -81.13188090515136, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.073315382003784, "episode_reward": 273.78896221665167, "step": 137000}
{"episode": 138.0, "batch_reward": 0.23817001128196716, "actor_loss": -81.08237414550781, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.222087383270264, "episode_reward": 179.76273478512388, "step": 138000}
{"episode": 139.0, "batch_reward": 0.23800374801456928, "actor_loss": -81.15288650512696, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.5285964012146, "episode_reward": 66.45839464229493, "step": 139000}
{"episode": 140.0, "batch_reward": 0.23648523442447186, "actor_loss": -81.07817829895019, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.57560634613037, "episode_reward": 38.27381188642486, "step": 140000}
{"episode": 141.0, "batch_reward": 0.23507076941430569, "actor_loss": -81.0147526397705, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 44.97881317138672, "episode_reward": 67.88804118237472, "step": 141000}
{"episode": 142.0, "batch_reward": 0.2343683118224144, "actor_loss": -81.01741508483887, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.011412620544434, "episode_reward": 513.299660774754, "step": 142000}
{"episode": 143.0, "batch_reward": 0.23472651398181915, "actor_loss": -81.04520162963867, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.090950965881348, "episode_reward": 77.23814964984706, "step": 143000}
{"episode": 144.0, "batch_reward": 0.2345608189254999, "actor_loss": -81.0169454498291, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.78471302986145, "episode_reward": 82.54262931207515, "step": 144000}
{"episode": 145.0, "batch_reward": 0.2339157621562481, "actor_loss": -81.0050071105957, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.401308059692383, "episode_reward": 161.78592749849585, "step": 145000}
{"episode": 146.0, "batch_reward": 0.23435557800531387, "actor_loss": -81.06267547607422, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.119608402252197, "episode_reward": 66.49320384789648, "step": 146000}
{"episode": 147.0, "batch_reward": 0.23279941925406455, "actor_loss": -81.06340788269043, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.559183597564697, "episode_reward": 68.63452814001565, "step": 147000}
{"episode": 148.0, "batch_reward": 0.23179097539186477, "actor_loss": -81.00250637817383, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.64003276824951, "episode_reward": 430.989794497246, "step": 148000}
{"episode": 149.0, "batch_reward": 0.23335223186016082, "actor_loss": -81.09872692871093, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.23766779899597, "episode_reward": 334.14111130581273, "step": 149000}
{"episode": 150.0, "batch_reward": 0.2347692812383175, "actor_loss": -81.07082472229004, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "step": 150000}
