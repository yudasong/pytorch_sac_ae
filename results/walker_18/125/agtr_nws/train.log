{"episode": 1.0, "duration": 24.100353717803955, "episode_reward": 28.177075776326152, "step": 1000}
{"episode": 2.0, "duration": 2.4416558742523193, "episode_reward": 69.84046218736019, "step": 2000}
{"episode": 3.0, "batch_reward": 0.04921538714678457, "actor_loss": -80.99949572199867, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499180007, "duration": 64.64614725112915, "episode_reward": 47.458394225332405, "step": 3000}
{"episode": 4.0, "batch_reward": 0.04953904223442078, "actor_loss": -78.7054761505127, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.773231506347656, "episode_reward": 44.12562687556773, "step": 4000}
{"episode": 5.0, "batch_reward": 0.04501763521879911, "actor_loss": -78.01306384277343, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.17697048187256, "episode_reward": 13.956017662708799, "step": 5000}
{"episode": 6.0, "batch_reward": 0.03948741076700389, "actor_loss": -75.75209329223632, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.478579998016357, "episode_reward": 25.87250608699241, "step": 6000}
{"episode": 7.0, "batch_reward": 0.035921829471364616, "actor_loss": -73.43620726013184, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.13110852241516, "episode_reward": 5.716265296428977, "step": 7000}
{"episode": 8.0, "batch_reward": 0.03452784918434918, "actor_loss": -72.18051826477051, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.34097146987915, "episode_reward": 46.549339380086494, "step": 8000}
{"episode": 9.0, "batch_reward": 0.033632583752274514, "actor_loss": -71.1629256439209, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.62471628189087, "episode_reward": 13.254719159231083, "step": 9000}
{"episode": 10.0, "batch_reward": 0.03347112387418747, "actor_loss": -66.04150973510743, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 4062.7377758026123, "episode_reward": 35.831241245980074, "step": 10000}
{"episode": 11.0, "batch_reward": 0.03235251620411873, "actor_loss": -65.90860482025147, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.34799861907959, "episode_reward": 15.296455558945876, "step": 11000}
{"episode": 12.0, "batch_reward": 0.03161819352582097, "actor_loss": -63.866048500061034, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 450.3956162929535, "episode_reward": 45.41678479534068, "step": 12000}
{"episode": 13.0, "batch_reward": 0.033964589478448035, "actor_loss": -64.80505776977539, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.365604400634766, "episode_reward": 68.92817312108244, "step": 13000}
{"episode": 14.0, "batch_reward": 0.03476463727094233, "actor_loss": -63.72386528778076, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 440.0468578338623, "episode_reward": 14.880437591700867, "step": 14000}
{"episode": 15.0, "batch_reward": 0.03588228339701891, "actor_loss": -64.30856317901612, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.8760666847229, "episode_reward": 71.81500062467649, "step": 15000}
{"episode": 16.0, "batch_reward": 0.0360524367634207, "actor_loss": -63.18108779144287, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 444.5005156993866, "episode_reward": 17.642782182295388, "step": 16000}
{"episode": 17.0, "batch_reward": 0.035633774897083643, "actor_loss": -63.523376640319825, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.441669464111328, "episode_reward": 46.67435440630677, "step": 17000}
{"episode": 18.0, "batch_reward": 0.036390668466687204, "actor_loss": -60.536797607421875, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 441.1612317562103, "episode_reward": 61.156799907700766, "step": 18000}
{"episode": 19.0, "batch_reward": 0.03833300859667361, "actor_loss": -61.17639970397949, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.31709384918213, "episode_reward": 70.6551667218017, "step": 19000}
{"episode": 20.0, "batch_reward": 0.03844563631154597, "actor_loss": -60.05334495544434, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 433.1326141357422, "episode_reward": 14.915796470258769, "step": 20000}
{"episode": 21.0, "batch_reward": 0.03733601177856326, "actor_loss": -59.55225857543945, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 38.698659896850586, "episode_reward": 14.192017915481726, "step": 21000}
{"episode": 22.0, "batch_reward": 0.03698362037725746, "actor_loss": -59.38493651580811, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 444.44525933265686, "episode_reward": 42.583996437633104, "step": 22000}
{"episode": 23.0, "batch_reward": 0.037658509436994794, "actor_loss": -59.959475242614744, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.27845048904419, "episode_reward": 46.87171079244468, "step": 23000}
{"episode": 24.0, "batch_reward": 0.03880628009513021, "actor_loss": -61.03435452270508, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 437.54351711273193, "episode_reward": 87.18695234291313, "step": 24000}
{"episode": 25.0, "batch_reward": 0.03896437543258071, "actor_loss": -60.87183866119385, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.75392436981201, "episode_reward": 14.60891740760444, "step": 25000}
{"episode": 26.0, "batch_reward": 0.038261927779763935, "actor_loss": -60.26371036529541, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 443.2856240272522, "episode_reward": 17.047964644316515, "step": 26000}
{"episode": 27.0, "batch_reward": 0.03883907595090568, "actor_loss": -59.68496126556396, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.977527379989624, "episode_reward": 78.0730170745132, "step": 27000}
{"episode": 28.0, "batch_reward": 0.038895965207368134, "actor_loss": -60.13455596160889, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 439.1297461986542, "episode_reward": 14.686570239185093, "step": 28000}
{"episode": 29.0, "batch_reward": 0.037387714372947814, "actor_loss": -60.02305849456787, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.517141103744507, "episode_reward": 14.2640769271958, "step": 29000}
{"episode": 30.0, "batch_reward": 0.03785130307823419, "actor_loss": -60.23976178741455, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 445.2598159313202, "episode_reward": 52.31761201542381, "step": 30000}
{"episode": 31.0, "batch_reward": 0.03768893594481051, "actor_loss": -60.623305877685546, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 38.23585796356201, "episode_reward": 26.96998247828272, "step": 31000}
{"episode": 32.0, "batch_reward": 0.0379178956206888, "actor_loss": -59.88088011169434, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 445.5644881725311, "episode_reward": 50.0865288329937, "step": 32000}
{"episode": 33.0, "batch_reward": 0.037908654019236564, "actor_loss": -60.159613693237304, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.659414529800415, "episode_reward": 43.429810876752676, "step": 33000}
{"episode": 34.0, "batch_reward": 0.03873972386680544, "actor_loss": -59.82357054901123, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 443.8666732311249, "episode_reward": 62.39719657459311, "step": 34000}
{"episode": 35.0, "batch_reward": 0.039288215454667805, "actor_loss": -60.08375437164307, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.819451570510864, "episode_reward": 57.77750086735404, "step": 35000}
{"episode": 36.0, "batch_reward": 0.039479796934872864, "actor_loss": -59.64348220825195, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 446.00573325157166, "episode_reward": 25.18879051006944, "step": 36000}
{"episode": 37.0, "batch_reward": 0.03903514842502773, "actor_loss": -60.016592086791995, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.416776180267334, "episode_reward": 24.728090921506855, "step": 37000}
{"episode": 38.0, "batch_reward": 0.03828799278102815, "actor_loss": -60.08302830505371, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 442.8560519218445, "episode_reward": 20.77333818229259, "step": 38000}
{"episode": 39.0, "batch_reward": 0.038436500875279306, "actor_loss": -60.00908833312988, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.410651683807373, "episode_reward": 63.412414016840536, "step": 39000}
{"episode": 40.0, "batch_reward": 0.03924777607433498, "actor_loss": -59.60212902832031, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 444.50687074661255, "episode_reward": 66.73707577936194, "step": 40000}
{"episode": 41.0, "batch_reward": 0.039726114153862, "actor_loss": -59.8402967300415, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 39.26146149635315, "episode_reward": 56.15238484296103, "step": 41000}
{"episode": 42.0, "batch_reward": 0.03986528736539185, "actor_loss": -59.84279270935058, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 433.77386951446533, "episode_reward": 25.384065645764988, "step": 42000}
{"episode": 43.0, "batch_reward": 0.040229907669126985, "actor_loss": -60.03328139495849, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.34092402458191, "episode_reward": 75.19590251781013, "step": 43000}
{"episode": 44.0, "batch_reward": 0.04075989465415478, "actor_loss": -61.502610427856446, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 438.14348816871643, "episode_reward": 71.66367245140268, "step": 44000}
{"episode": 45.0, "batch_reward": 0.04109785529598594, "actor_loss": -61.70957964324951, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.42250108718872, "episode_reward": 26.031261024920134, "step": 45000}
{"episode": 46.0, "batch_reward": 0.040562478132545945, "actor_loss": -62.116672157287596, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 443.1842095851898, "episode_reward": 25.560181526080424, "step": 46000}
{"episode": 47.0, "batch_reward": 0.040276777224615215, "actor_loss": -62.46664791870117, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.948880910873413, "episode_reward": 25.588648559775237, "step": 47000}
{"episode": 48.0, "batch_reward": 0.04068506650440395, "actor_loss": -62.49521076965332, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 441.66763138771057, "episode_reward": 70.07821913895228, "step": 48000}
{"episode": 49.0, "batch_reward": 0.040744829351082444, "actor_loss": -62.58829759216309, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.36789083480835, "episode_reward": 61.08734851163751, "step": 49000}
{"episode": 50.0, "batch_reward": 0.04142657576315105, "actor_loss": -61.20915369415283, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 444.503942489624, "episode_reward": 60.74344472958826, "step": 50000}
{"episode": 51.0, "batch_reward": 0.04208983053453266, "actor_loss": -61.31683413696289, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 38.36958599090576, "episode_reward": 80.62426257294378, "step": 51000}
{"episode": 52.0, "batch_reward": 0.042274710047990084, "actor_loss": -61.7840965423584, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 436.4455075263977, "episode_reward": 25.491521351067988, "step": 52000}
{"episode": 53.0, "batch_reward": 0.042208588803187015, "actor_loss": -61.9596273727417, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.019397497177124, "episode_reward": 79.45597152114055, "step": 53000}
{"episode": 54.0, "batch_reward": 0.04294855804368854, "actor_loss": -61.779721313476564, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 447.70181107521057, "episode_reward": 78.73782489029577, "step": 54000}
{"episode": 55.0, "batch_reward": 0.04319599541276693, "actor_loss": -61.726668617248535, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.584035396575928, "episode_reward": 16.099099244648585, "step": 55000}
{"episode": 56.0, "batch_reward": 0.04318900244124234, "actor_loss": -59.86644242095947, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 441.6431589126587, "episode_reward": 84.72788106757996, "step": 56000}
{"episode": 57.0, "batch_reward": 0.043442166324704885, "actor_loss": -59.90414639282226, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.57538914680481, "episode_reward": 26.37079776190708, "step": 57000}
{"episode": 58.0, "batch_reward": 0.043172354828566316, "actor_loss": -60.268053146362305, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 443.5092468261719, "episode_reward": 18.511214941854952, "step": 58000}
{"episode": 59.0, "batch_reward": 0.042790695428848266, "actor_loss": -60.238444305419925, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.14159059524536, "episode_reward": 26.4026010488622, "step": 59000}
{"episode": 60.0, "batch_reward": 0.04303642097488046, "actor_loss": -61.17338011932373, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 445.82655334472656, "episode_reward": 77.49816381673871, "step": 60000}
{"episode": 61.0, "batch_reward": 0.043242076177150014, "actor_loss": -61.21400276184082, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 38.656176805496216, "episode_reward": 25.451409278648306, "step": 61000}
{"episode": 62.0, "batch_reward": 0.04271425747685134, "actor_loss": -62.99536538696289, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 438.8126788139343, "episode_reward": 24.99553272655016, "step": 62000}
{"episode": 63.0, "batch_reward": 0.0426101459544152, "actor_loss": -63.199335258483885, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.647220611572266, "episode_reward": 25.73585132665609, "step": 63000}
{"episode": 64.0, "batch_reward": 0.0429248897396028, "actor_loss": -63.821642402648926, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 443.3314311504364, "episode_reward": 97.23342942958188, "step": 64000}
{"episode": 65.0, "batch_reward": 0.0429869766626507, "actor_loss": -64.02649075317383, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.799165725708008, "episode_reward": 25.834465734460483, "step": 65000}
{"episode": 66.0, "batch_reward": 0.04307174867205322, "actor_loss": -64.0042472076416, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 443.65681409835815, "episode_reward": 79.9175995193745, "step": 66000}
{"episode": 67.0, "batch_reward": 0.043546786380931735, "actor_loss": -64.14380683135987, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.910959005355835, "episode_reward": 69.40970368729809, "step": 67000}
{"episode": 68.0, "batch_reward": 0.043720667872577904, "actor_loss": -63.14682799530029, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 444.89185070991516, "episode_reward": 17.67545343121287, "step": 68000}
{"episode": 69.0, "batch_reward": 0.0436923621930182, "actor_loss": -62.91697346496582, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.171785593032837, "episode_reward": 79.22707591652203, "step": 69000}
{"episode": 70.0, "batch_reward": 0.04423975941538811, "actor_loss": -64.77825382232666, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 443.92864084243774, "episode_reward": 65.16522101312886, "step": 70000}
{"episode": 71.0, "batch_reward": 0.0439405674263835, "actor_loss": -64.95622919464111, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 39.0224084854126, "episode_reward": 25.8227472071686, "step": 71000}
{"episode": 72.0, "batch_reward": 0.0439318719394505, "actor_loss": -64.81271534729004, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 440.5168011188507, "episode_reward": 26.04461733152332, "step": 72000}
{"episode": 73.0, "batch_reward": 0.04407264966517687, "actor_loss": -64.98481658935548, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.16596531867981, "episode_reward": 87.88429031602723, "step": 73000}
{"episode": 74.0, "batch_reward": 0.04456059680506587, "actor_loss": -64.29683089447022, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 443.87462639808655, "episode_reward": 86.40928825155731, "step": 74000}
{"episode": 75.0, "batch_reward": 0.044944087030366064, "actor_loss": -64.47104177093506, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.49562692642212, "episode_reward": 25.801253068932873, "step": 75000}
{"episode": 76.0, "batch_reward": 0.045021103959530594, "actor_loss": -65.18034594726562, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 440.97295665740967, "episode_reward": 74.93784714350456, "step": 76000}
{"episode": 77.0, "batch_reward": 0.04519311787933111, "actor_loss": -65.43306446838379, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.403136253356934, "episode_reward": 25.904584735535206, "step": 77000}
{"episode": 78.0, "batch_reward": 0.044614703349769115, "actor_loss": -66.02736015319825, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 443.9694170951843, "episode_reward": 25.918663819962518, "step": 78000}
{"episode": 79.0, "batch_reward": 0.044287405489012596, "actor_loss": -65.92716096496582, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.381781816482544, "episode_reward": 15.526766974544248, "step": 79000}
{"episode": 80.0, "batch_reward": 0.04416553999856115, "actor_loss": -65.77125830078126, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 446.4378983974457, "episode_reward": 25.464644653897427, "step": 80000}
{"episode": 81.0, "batch_reward": 0.044428379584103825, "actor_loss": -65.92434498596191, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 38.07606053352356, "episode_reward": 75.91918585115647, "step": 81000}
{"episode": 82.0, "batch_reward": 0.04430047905445099, "actor_loss": -64.6894111328125, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 441.1962184906006, "episode_reward": 27.206672876979287, "step": 82000}
{"episode": 83.0, "batch_reward": 0.04447032010182738, "actor_loss": -64.72153463745117, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.657036066055298, "episode_reward": 52.320682339314764, "step": 83000}
{"episode": 84.0, "batch_reward": 0.04423830508999527, "actor_loss": -65.45408442687989, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 446.3010230064392, "episode_reward": 64.227702171816, "step": 84000}
{"episode": 85.0, "batch_reward": 0.04479039668291807, "actor_loss": -65.60448313140868, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.78604245185852, "episode_reward": 52.96574155554587, "step": 85000}
{"episode": 86.0, "batch_reward": 0.044256358455866576, "actor_loss": -64.6337452468872, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 439.447069644928, "episode_reward": 26.181906069626017, "step": 86000}
{"episode": 87.0, "batch_reward": 0.04455684452876449, "actor_loss": -64.7234660949707, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.57734227180481, "episode_reward": 72.1853804806661, "step": 87000}
{"episode": 88.0, "batch_reward": 0.044514161136001346, "actor_loss": -65.5478708190918, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 446.1502470970154, "episode_reward": 57.84821044637191, "step": 88000}
{"episode": 89.0, "batch_reward": 0.04500195187702775, "actor_loss": -65.58016269683839, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.420336484909058, "episode_reward": 61.747256974027245, "step": 89000}
{"episode": 90.0, "batch_reward": 0.04512484243139624, "actor_loss": -64.71531189727783, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 446.57696080207825, "episode_reward": 26.34503102092617, "step": 90000}
{"episode": 91.0, "batch_reward": 0.04526989383995533, "actor_loss": -64.77531651306153, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 38.38906002044678, "episode_reward": 66.28913374771112, "step": 91000}
{"episode": 92.0, "batch_reward": 0.0452848725579679, "actor_loss": -65.80615169525146, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 434.21105003356934, "episode_reward": 26.41291304410799, "step": 92000}
{"episode": 93.0, "batch_reward": 0.04506627239659428, "actor_loss": -65.83844765472412, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.619327068328857, "episode_reward": 70.35012494065289, "step": 93000}
{"episode": 94.0, "batch_reward": 0.04534211422875523, "actor_loss": -67.10788536071777, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 446.6088025569916, "episode_reward": 25.218638636011175, "step": 94000}
{"episode": 95.0, "batch_reward": 0.04511246088147163, "actor_loss": -67.17447013854981, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.596061944961548, "episode_reward": 26.08932369864096, "step": 95000}
{"episode": 96.0, "batch_reward": 0.044709562169387936, "actor_loss": -65.98193962097167, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 439.86518478393555, "episode_reward": 25.987193217836488, "step": 96000}
{"episode": 97.0, "batch_reward": 0.04458657716959715, "actor_loss": -66.19456450653077, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.776611328125, "episode_reward": 62.776914469044385, "step": 97000}
{"episode": 98.0, "batch_reward": 0.044993046227842566, "actor_loss": -66.62627753448486, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 441.59773111343384, "episode_reward": 59.585049949133634, "step": 98000}
{"episode": 99.0, "batch_reward": 0.044973390378057955, "actor_loss": -66.65584963989258, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.920238733291626, "episode_reward": 69.13808919645788, "step": 99000}
{"episode": 100.0, "batch_reward": 0.04532334074378014, "actor_loss": -66.78279733276368, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 444.3515305519104, "episode_reward": 63.225731032888746, "step": 100000}
{"episode": 101.0, "batch_reward": 0.045603638384491205, "actor_loss": -66.83903868103027, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 38.0545711517334, "episode_reward": 74.07597179280401, "step": 101000}
{"episode": 102.0, "batch_reward": 0.045867928847670554, "actor_loss": -65.72619343566895, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 440.4839599132538, "episode_reward": 67.09296349287301, "step": 102000}
{"episode": 103.0, "batch_reward": 0.04580948995798826, "actor_loss": -65.60509445953369, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.526808261871338, "episode_reward": 25.729872500494483, "step": 103000}
{"episode": 104.0, "batch_reward": 0.045755593702197075, "actor_loss": -66.5257625656128, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 445.9227702617645, "episode_reward": 63.31215814914434, "step": 104000}
{"episode": 105.0, "batch_reward": 0.04567229472845793, "actor_loss": -66.60443949890137, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.30565905570984, "episode_reward": 65.49210669439499, "step": 105000}
{"episode": 106.0, "batch_reward": 0.04651617833971977, "actor_loss": -67.3692251739502, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 443.32587718963623, "episode_reward": 74.85215912073109, "step": 106000}
{"episode": 107.0, "batch_reward": 0.04623198070749641, "actor_loss": -67.51760801696777, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.582302570343018, "episode_reward": 73.1780897376352, "step": 107000}
{"episode": 108.0, "batch_reward": 0.04637425617873669, "actor_loss": -66.39803311920166, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 444.5731747150421, "episode_reward": 14.399021820051413, "step": 108000}
{"episode": 109.0, "batch_reward": 0.04612417810037732, "actor_loss": -66.26457344818115, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.601959943771362, "episode_reward": 34.723597885943754, "step": 109000}
{"episode": 110.0, "batch_reward": 0.04635613811388612, "actor_loss": -65.27651150512695, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 442.16611671447754, "episode_reward": 82.91994348872926, "step": 110000}
{"episode": 111.0, "batch_reward": 0.046803733590990305, "actor_loss": -65.35560753631592, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 38.38196587562561, "episode_reward": 74.72837252015776, "step": 111000}
{"episode": 112.0, "batch_reward": 0.0468273173160851, "actor_loss": -64.63261273956299, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 443.2272927761078, "episode_reward": 69.82283673624667, "step": 112000}
{"episode": 113.0, "batch_reward": 0.04699930536001921, "actor_loss": -64.70039599609375, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.601709604263306, "episode_reward": 26.661805804153534, "step": 113000}
{"episode": 114.0, "batch_reward": 0.046908438049256804, "actor_loss": -65.29256823730469, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 447.15866112709045, "episode_reward": 50.17373249953005, "step": 114000}
{"episode": 115.0, "batch_reward": 0.046655345790088176, "actor_loss": -65.35413764953613, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.832319021224976, "episode_reward": 43.47286830864221, "step": 115000}
{"episode": 116.0, "batch_reward": 0.04644356209412217, "actor_loss": -67.42277987670899, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 442.7140939235687, "episode_reward": 25.990665865617512, "step": 116000}
{"episode": 117.0, "batch_reward": 0.046780554361641406, "actor_loss": -67.59098208618164, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.73369574546814, "episode_reward": 75.53334651192009, "step": 117000}
{"episode": 118.0, "batch_reward": 0.04661356474086642, "actor_loss": -66.16773657989502, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 437.54025387763977, "episode_reward": 63.68786302555603, "step": 118000}
{"episode": 119.0, "batch_reward": 0.04698389225453138, "actor_loss": -66.2918125, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.273893356323242, "episode_reward": 26.19257129572214, "step": 119000}
{"episode": 120.0, "batch_reward": 0.04683208478987217, "actor_loss": -68.03313973999023, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 444.4133069515228, "episode_reward": 36.08625478259589, "step": 120000}
{"episode": 121.0, "batch_reward": 0.04701806683838367, "actor_loss": -68.16982356262207, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 38.06285095214844, "episode_reward": 71.76615396800989, "step": 121000}
{"episode": 122.0, "batch_reward": 0.04708490398898721, "actor_loss": -67.3479681854248, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 440.38044929504395, "episode_reward": 73.50615429798988, "step": 122000}
{"episode": 123.0, "batch_reward": 0.0469356468450278, "actor_loss": -67.4061999130249, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.152095794677734, "episode_reward": 25.499858344202032, "step": 123000}
{"episode": 124.0, "batch_reward": 0.04690279893949628, "actor_loss": -65.09102987670899, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 442.4750542640686, "episode_reward": 88.59891909635039, "step": 124000}
{"episode": 125.0, "batch_reward": 0.04768116917833686, "actor_loss": -65.17235836029053, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.41538429260254, "episode_reward": 97.12148567617227, "step": 125000}
{"episode": 126.0, "batch_reward": 0.048050098106265066, "actor_loss": -64.51005765533448, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 440.9318697452545, "episode_reward": 84.24996660399316, "step": 126000}
{"episode": 127.0, "batch_reward": 0.0481720161549747, "actor_loss": -64.5915068359375, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.540935277938843, "episode_reward": 69.03048003364528, "step": 127000}
{"episode": 128.0, "batch_reward": 0.04829742974415421, "actor_loss": -67.72538865661622, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 444.4101848602295, "episode_reward": 25.67683363480987, "step": 128000}
{"episode": 129.0, "batch_reward": 0.04789174583926797, "actor_loss": -67.80431031799317, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.979312419891357, "episode_reward": 18.108132877048043, "step": 129000}
{"episode": 130.0, "batch_reward": 0.04812016618251801, "actor_loss": -66.47779390716553, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 440.42408657073975, "episode_reward": 82.17313535628672, "step": 130000}
{"episode": 131.0, "batch_reward": 0.048097439840435983, "actor_loss": -66.42667630004883, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.81795930862427, "episode_reward": 80.23737218774073, "step": 131000}
{"episode": 132.0, "batch_reward": 0.048229155384004116, "actor_loss": -65.92418072509766, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 440.2033293247223, "episode_reward": 17.68361531317349, "step": 132000}
{"episode": 133.0, "batch_reward": 0.04793502077832818, "actor_loss": -65.86378031158448, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.599114418029785, "episode_reward": 25.261462334375025, "step": 133000}
{"episode": 134.0, "batch_reward": 0.047778743274509906, "actor_loss": -66.42247942352294, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 445.1511597633362, "episode_reward": 26.076176862605035, "step": 134000}
{"episode": 135.0, "batch_reward": 0.04789456092193723, "actor_loss": -66.58746132659913, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.07331681251526, "episode_reward": 82.91805878695315, "step": 135000}
{"episode": 136.0, "batch_reward": 0.04795283439010382, "actor_loss": -65.38927516937255, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 443.6070547103882, "episode_reward": 84.05861195220128, "step": 136000}
{"episode": 137.0, "batch_reward": 0.04823876571655274, "actor_loss": -65.44624388885498, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.59648060798645, "episode_reward": 88.69495232546059, "step": 137000}
{"episode": 138.0, "batch_reward": 0.04834283154457807, "actor_loss": -65.51553147125244, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 442.70095205307007, "episode_reward": 25.214789183805152, "step": 138000}
{"episode": 139.0, "batch_reward": 0.04821951011940837, "actor_loss": -65.53480588531494, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.995704889297485, "episode_reward": 16.27601064887612, "step": 139000}
{"episode": 140.0, "batch_reward": 0.0476630441993475, "actor_loss": -64.50528767395019, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 441.61564087867737, "episode_reward": 26.043834852401574, "step": 140000}
{"episode": 141.0, "batch_reward": 0.04803688220307231, "actor_loss": -64.55698818206787, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 39.423768758773804, "episode_reward": 25.275252808600566, "step": 141000}
{"episode": 142.0, "batch_reward": 0.04791258723288774, "actor_loss": -62.666924308776856, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 434.0931324958801, "episode_reward": 18.64909414602429, "step": 142000}
{"episode": 143.0, "batch_reward": 0.04759723966568708, "actor_loss": -62.7429821472168, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.582465887069702, "episode_reward": 26.129581054980747, "step": 143000}
{"episode": 144.0, "batch_reward": 0.04734018268808723, "actor_loss": -59.52875247955322, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 445.29763078689575, "episode_reward": 26.719790088796657, "step": 144000}
{"episode": 145.0, "batch_reward": 0.047385768208652736, "actor_loss": -59.75817784118652, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.177576780319214, "episode_reward": 63.846535881907826, "step": 145000}
{"episode": 146.0, "batch_reward": 0.04749520226940512, "actor_loss": -59.01542580413818, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 441.2738621234894, "episode_reward": 20.848107049955917, "step": 146000}
{"episode": 147.0, "batch_reward": 0.0470569305382669, "actor_loss": -59.00965484619141, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.789780139923096, "episode_reward": 25.95282676265953, "step": 147000}
{"episode": 148.0, "batch_reward": 0.04731011277809739, "actor_loss": -60.163771797180175, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 446.4937472343445, "episode_reward": 72.2855321816847, "step": 148000}
{"episode": 149.0, "batch_reward": 0.04686316154897213, "actor_loss": -60.18224336242676, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.05626130104065, "episode_reward": 72.07632196236877, "step": 149000}
{"episode": 150.0, "batch_reward": 0.04755402678996325, "actor_loss": -59.762907821655276, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "step": 150000}
