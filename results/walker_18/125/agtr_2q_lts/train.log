{"episode_reward": 0.0, "episode": 1.0, "duration": 18.069555044174194, "step": 1000}
{"episode_reward": 28.177075776326152, "episode": 2.0, "duration": 1.6264879703521729, "step": 2000}
{"episode_reward": 69.84046218736019, "episode": 3.0, "batch_reward": 0.06028391272276789, "critic_loss": 0.12511260269651336, "actor_loss": -77.6210837453878, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499180007, "duration": 85.70118522644043, "step": 3000}
{"episode_reward": 139.93623681617134, "episode": 4.0, "batch_reward": 0.12806773097068072, "critic_loss": 0.2397200644761324, "actor_loss": -73.71236233520507, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.4423348903656, "step": 4000}
{"episode_reward": 455.1211146945315, "episode": 5.0, "batch_reward": 0.20794533464312553, "critic_loss": 0.32852228882908824, "actor_loss": -74.8376149597168, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.855655193328857, "step": 5000}
{"episode_reward": 463.41543636934307, "episode": 6.0, "batch_reward": 0.24876749646663665, "critic_loss": 0.4151980890929699, "actor_loss": -74.43407791137696, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.892720937728882, "step": 6000}
{"episode_reward": 436.9245897994709, "episode": 7.0, "batch_reward": 0.2787911633998156, "critic_loss": 0.46240728560090066, "actor_loss": -73.56951672363282, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.715704917907715, "step": 7000}
{"episode_reward": 481.33026296951755, "episode": 8.0, "batch_reward": 0.28263385021686555, "critic_loss": 0.4371483406126499, "actor_loss": -72.94821188354493, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.665024042129517, "step": 8000}
{"episode_reward": 77.73161611614744, "episode": 9.0, "batch_reward": 0.28469306108355524, "critic_loss": 0.5775881958305835, "actor_loss": -72.71089847564697, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.775578260421753, "step": 9000}
{"episode_reward": 528.7592682383198, "episode": 10.0, "batch_reward": 0.2852446726411581, "critic_loss": 0.6020846814811229, "actor_loss": -72.32798082733154, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.63868284225464, "step": 10000}
{"episode_reward": 76.38329923800498, "episode": 11.0, "batch_reward": 0.2658476404547691, "critic_loss": 0.5974336649477482, "actor_loss": -70.44955854797364, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 44.14231896400452, "step": 11000}
{"episode_reward": 84.01195097853179, "episode": 12.0, "batch_reward": 0.25495361614227297, "critic_loss": 0.7135404506921769, "actor_loss": -70.51850489807128, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.752148389816284, "step": 12000}
{"episode_reward": 152.39831038352835, "episode": 13.0, "batch_reward": 0.2511006652265787, "critic_loss": 0.9190247476994992, "actor_loss": -70.27857033538818, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.174104690551758, "step": 13000}
{"episode_reward": 219.93673982459956, "episode": 14.0, "batch_reward": 0.24052613328397274, "critic_loss": 0.8377310999333859, "actor_loss": -70.07530121612548, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.68759298324585, "step": 14000}
{"episode_reward": 90.3284536035795, "episode": 15.0, "batch_reward": 0.23372062486410142, "critic_loss": 0.9692471253275872, "actor_loss": -67.24261493682862, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.78712558746338, "step": 15000}
{"episode_reward": 86.1359766230652, "episode": 16.0, "batch_reward": 0.2373448623418808, "critic_loss": 1.0859347086548805, "actor_loss": -66.91331921386718, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.699312925338745, "step": 16000}
{"episode_reward": 477.59487369070786, "episode": 17.0, "batch_reward": 0.2367114362716675, "critic_loss": 1.0988267903327942, "actor_loss": -68.00647370910644, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.708477020263672, "step": 17000}
{"episode_reward": 64.14075552926813, "episode": 18.0, "batch_reward": 0.23138964031636716, "critic_loss": 0.964695402443409, "actor_loss": -68.21477531433105, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.689316749572754, "step": 18000}
{"episode_reward": 156.8759588409874, "episode": 19.0, "batch_reward": 0.22611847342550753, "critic_loss": 0.9128669258654117, "actor_loss": -67.32321315002442, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.288875579833984, "step": 19000}
{"episode_reward": 150.6524210282184, "episode": 20.0, "batch_reward": 0.21979619060456754, "critic_loss": 0.7987730139493943, "actor_loss": -66.87977420806885, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.290113925933838, "step": 20000}
{"episode_reward": 62.57255270314486, "episode": 21.0, "batch_reward": 0.21567824092507362, "critic_loss": 0.880206107199192, "actor_loss": -66.12932287597656, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 43.86148810386658, "step": 21000}
{"episode_reward": 141.8094110354752, "episode": 22.0, "batch_reward": 0.2189282680004835, "critic_loss": 0.8958543496727943, "actor_loss": -66.76801152038574, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.103036642074585, "step": 22000}
{"episode_reward": 546.1699090829319, "episode": 23.0, "batch_reward": 0.2311421116143465, "critic_loss": 0.8730018113255501, "actor_loss": -67.22002407836914, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.332075595855713, "step": 23000}
{"episode_reward": 359.90929450269425, "episode": 24.0, "batch_reward": 0.23870984196662903, "critic_loss": 0.9120680209696292, "actor_loss": -66.21421925354004, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.373246908187866, "step": 24000}
{"episode_reward": 458.73259485952957, "episode": 25.0, "batch_reward": 0.23955796100199223, "critic_loss": 0.8835339537262916, "actor_loss": -66.97474639129639, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.671692371368408, "step": 25000}
{"episode_reward": 106.29449548940036, "episode": 26.0, "batch_reward": 0.23264028066396714, "critic_loss": 1.041795323073864, "actor_loss": -66.74418621826172, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.531652450561523, "step": 26000}
{"episode_reward": 61.35090725166416, "episode": 27.0, "batch_reward": 0.23085362270474433, "critic_loss": 0.9978961857557297, "actor_loss": -66.32198210906982, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.617570161819458, "step": 27000}
{"episode_reward": 139.35330279486334, "episode": 28.0, "batch_reward": 0.23029595975577832, "critic_loss": 1.346233195900917, "actor_loss": -66.50534107208252, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.337384700775146, "step": 28000}
{"episode_reward": 534.7951164523909, "episode": 29.0, "batch_reward": 0.23360913909971714, "critic_loss": 1.3143940640091896, "actor_loss": -65.41976337432861, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.887190341949463, "step": 29000}
{"episode_reward": 58.63982015085756, "episode": 30.0, "batch_reward": 0.23433457918465136, "critic_loss": 1.354535356938839, "actor_loss": -65.42962870025634, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.60028076171875, "step": 30000}
{"episode_reward": 284.0033801208083, "episode": 31.0, "batch_reward": 0.23076256465911865, "critic_loss": 1.4746705396771431, "actor_loss": -64.99343019104003, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 43.84144711494446, "step": 31000}
{"episode_reward": 64.49702617610984, "episode": 32.0, "batch_reward": 0.23480800075829028, "critic_loss": 1.7800104825496674, "actor_loss": -65.94989962005616, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.796640634536743, "step": 32000}
{"episode_reward": 687.2735899387613, "episode": 33.0, "batch_reward": 0.2498397464454174, "critic_loss": 1.7914573352336884, "actor_loss": -67.67371319580079, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.379171133041382, "step": 33000}
{"episode_reward": 744.6849961699286, "episode": 34.0, "batch_reward": 0.2641616582274437, "critic_loss": 1.8852674466371537, "actor_loss": -70.60336309051513, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.84382724761963, "step": 34000}
{"episode_reward": 775.4730101683272, "episode": 35.0, "batch_reward": 0.27910198813676834, "critic_loss": 2.1558364978432656, "actor_loss": -70.28364447784423, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.114984273910522, "step": 35000}
{"episode_reward": 743.968306427716, "episode": 36.0, "batch_reward": 0.2822289059758186, "critic_loss": 2.865100011229515, "actor_loss": -72.46763994598389, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.42644190788269, "step": 36000}
{"episode_reward": 76.93111330370955, "episode": 37.0, "batch_reward": 0.28537818360328676, "critic_loss": 3.640460964679718, "actor_loss": -73.71604518127441, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.548902988433838, "step": 37000}
{"episode_reward": 620.2863853307824, "episode": 38.0, "batch_reward": 0.2915487843602896, "critic_loss": 3.9228699845075607, "actor_loss": -74.10293231201172, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.785120248794556, "step": 38000}
{"episode_reward": 240.25605139723916, "episode": 39.0, "batch_reward": 0.2868140755146742, "critic_loss": 3.9839736198186873, "actor_loss": -74.44608320617675, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.570266008377075, "step": 39000}
{"episode_reward": 161.70819991409786, "episode": 40.0, "batch_reward": 0.282680924475193, "critic_loss": 3.5992089940309526, "actor_loss": -75.47223254394531, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.83401918411255, "step": 40000}
{"episode_reward": 128.36332940398117, "episode": 41.0, "batch_reward": 0.27844925694167616, "critic_loss": 3.392504683494568, "actor_loss": -76.00546566772461, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 43.693662881851196, "step": 41000}
{"episode_reward": 128.51394591025604, "episode": 42.0, "batch_reward": 0.27471865732967854, "critic_loss": 3.3960382351875307, "actor_loss": -76.41079981994629, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.863504886627197, "step": 42000}
{"episode_reward": 95.03466561779022, "episode": 43.0, "batch_reward": 0.2717330138385296, "critic_loss": 3.288923168182373, "actor_loss": -76.27051728820801, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.734283208847046, "step": 43000}
{"episode_reward": 138.98374436233394, "episode": 44.0, "batch_reward": 0.2691627572178841, "critic_loss": 3.587496438860893, "actor_loss": -76.44539784240723, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.60396432876587, "step": 44000}
{"episode_reward": 206.51613530119613, "episode": 45.0, "batch_reward": 0.2688079632818699, "critic_loss": 4.765555041432381, "actor_loss": -76.7363077697754, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.95359969139099, "step": 45000}
{"episode_reward": 489.76966596754164, "episode": 46.0, "batch_reward": 0.27686683109402654, "critic_loss": 5.094961633920669, "actor_loss": -79.29797607421875, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.32912516593933, "step": 46000}
{"episode_reward": 764.3154297935166, "episode": 47.0, "batch_reward": 0.28414784170687196, "critic_loss": 5.077300597906112, "actor_loss": -82.38858433532715, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.566672563552856, "step": 47000}
{"episode_reward": 429.5044276069677, "episode": 48.0, "batch_reward": 0.2923841350376606, "critic_loss": 4.624604471921921, "actor_loss": -84.72278086853028, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.079573154449463, "step": 48000}
{"episode_reward": 809.8106935976357, "episode": 49.0, "batch_reward": 0.3035876024663448, "critic_loss": 3.818792379140854, "actor_loss": -86.09105462646484, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.058873176574707, "step": 49000}
{"episode_reward": 769.4358654200998, "episode": 50.0, "batch_reward": 0.3137943940907717, "critic_loss": 3.187510077238083, "actor_loss": -86.48987200927735, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.02586030960083, "step": 50000}
{"episode_reward": 777.4118440066135, "episode": 51.0, "batch_reward": 0.320647248595953, "critic_loss": 2.737752400636673, "actor_loss": -86.34901173400878, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 43.945502519607544, "step": 51000}
{"episode_reward": 488.4615469322744, "episode": 52.0, "batch_reward": 0.31729210138320924, "critic_loss": 2.631750029563904, "actor_loss": -86.2766533203125, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.652201414108276, "step": 52000}
{"episode_reward": 16.15300040911299, "episode": 53.0, "batch_reward": 0.316173631682992, "critic_loss": 2.741580894231796, "actor_loss": -85.70438818359375, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.9515700340271, "step": 53000}
{"episode_reward": 309.18715425273643, "episode": 54.0, "batch_reward": 0.31329847837984565, "critic_loss": 3.031068175077438, "actor_loss": -85.56038696289062, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.054776906967163, "step": 54000}
{"episode_reward": 204.49504451330128, "episode": 55.0, "batch_reward": 0.3105618337094784, "critic_loss": 3.3238493731021883, "actor_loss": -84.86502249145508, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.679078340530396, "step": 55000}
{"episode_reward": 133.2352992340549, "episode": 56.0, "batch_reward": 0.30663404053449633, "critic_loss": 3.603453507900238, "actor_loss": -84.9946175994873, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.1248517036438, "step": 56000}
{"episode_reward": 166.86898172520586, "episode": 57.0, "batch_reward": 0.3057156058549881, "critic_loss": 3.6293801345825196, "actor_loss": -84.76918183898925, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.877523183822632, "step": 57000}
{"episode_reward": 103.75044638469754, "episode": 58.0, "batch_reward": 0.30213058841228485, "critic_loss": 3.6809207565784456, "actor_loss": -84.2790301361084, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.9823215007782, "step": 58000}
{"episode_reward": 141.92375623141652, "episode": 59.0, "batch_reward": 0.29799189141392707, "critic_loss": 3.9329645581245423, "actor_loss": -84.01577348327636, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.90721368789673, "step": 59000}
{"episode_reward": 87.61999021484147, "episode": 60.0, "batch_reward": 0.29780770315229893, "critic_loss": 3.777181019306183, "actor_loss": -83.39141748046875, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.944791078567505, "step": 60000}
{"episode_reward": 223.0777169605376, "episode": 61.0, "batch_reward": 0.2944519647657871, "critic_loss": 3.8282496752738955, "actor_loss": -83.04184350585938, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 43.61605715751648, "step": 61000}
{"episode_reward": 129.99049042939538, "episode": 62.0, "batch_reward": 0.2901814920306206, "critic_loss": 3.713919712781906, "actor_loss": -82.68809684753418, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.08993887901306, "step": 62000}
{"episode_reward": 109.42807187428375, "episode": 63.0, "batch_reward": 0.28814826357364653, "critic_loss": 3.8018268620967866, "actor_loss": -82.5806902923584, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.562010526657104, "step": 63000}
{"episode_reward": 124.75056387371737, "episode": 64.0, "batch_reward": 0.286983388453722, "critic_loss": 4.218757254838944, "actor_loss": -83.02659197998047, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.250550985336304, "step": 64000}
{"episode_reward": 126.90218417262525, "episode": 65.0, "batch_reward": 0.28294521774351594, "critic_loss": 4.907891060113907, "actor_loss": -83.85860984802247, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.90194296836853, "step": 65000}
{"episode_reward": 86.48316145904414, "episode": 66.0, "batch_reward": 0.2796452161371708, "critic_loss": 5.383463990449905, "actor_loss": -84.97476936340333, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.958988904953003, "step": 66000}
{"episode_reward": 79.80331003280409, "episode": 67.0, "batch_reward": 0.27857320447266104, "critic_loss": 5.449072060823441, "actor_loss": -86.28416806030273, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.563942909240723, "step": 67000}
{"episode_reward": 79.48264755356644, "episode": 68.0, "batch_reward": 0.2744769978374243, "critic_loss": 5.248685333251953, "actor_loss": -86.63602359008789, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.919854402542114, "step": 68000}
{"episode_reward": 101.12616756993084, "episode": 69.0, "batch_reward": 0.2728678710013628, "critic_loss": 5.136482797622681, "actor_loss": -87.83314649963378, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.79414129257202, "step": 69000}
{"episode_reward": 76.45329334329625, "episode": 70.0, "batch_reward": 0.2668106163740158, "critic_loss": 5.098145560979843, "actor_loss": -88.4261993560791, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.8553364276886, "step": 70000}
{"episode_reward": 83.86559830870483, "episode": 71.0, "batch_reward": 0.267116066634655, "critic_loss": 4.860675943613052, "actor_loss": -88.41401501464844, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 43.73278737068176, "step": 71000}
{"episode_reward": 127.75960509205021, "episode": 72.0, "batch_reward": 0.26483011518418786, "critic_loss": 4.744252971172333, "actor_loss": -88.46820553588867, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.05106210708618, "step": 72000}
{"episode_reward": 141.31546173418175, "episode": 73.0, "batch_reward": 0.26385380409657955, "critic_loss": 4.6672573325634, "actor_loss": -88.50953480529785, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.704538345336914, "step": 73000}
{"episode_reward": 376.2677426481149, "episode": 74.0, "batch_reward": 0.26759514087438585, "critic_loss": 4.439132647514343, "actor_loss": -89.12847688293456, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.156614065170288, "step": 74000}
{"episode_reward": 411.9301501946185, "episode": 75.0, "batch_reward": 0.26930807195603845, "critic_loss": 4.028269728422165, "actor_loss": -89.28398780822754, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.737459421157837, "step": 75000}
{"episode_reward": 771.8211374686769, "episode": 76.0, "batch_reward": 0.2766095393002033, "critic_loss": 3.588583859682083, "actor_loss": -89.64990061950684, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.727655172348022, "step": 76000}
{"episode_reward": 806.2984105588158, "episode": 77.0, "batch_reward": 0.28216491208970546, "critic_loss": 3.2956380219459533, "actor_loss": -90.19176434326172, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.463175773620605, "step": 77000}
{"episode_reward": 685.1012233711728, "episode": 78.0, "batch_reward": 0.284622060239315, "critic_loss": 2.9355021061897277, "actor_loss": -90.92131427001954, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.45303726196289, "step": 78000}
{"episode_reward": 369.6142943299211, "episode": 79.0, "batch_reward": 0.2887654404938221, "critic_loss": 2.5748024022579195, "actor_loss": -90.39327490234375, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.859792709350586, "step": 79000}
{"episode_reward": 588.9575079464063, "episode": 80.0, "batch_reward": 0.2927409913390875, "critic_loss": 2.242951826810837, "actor_loss": -90.44776335144043, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.001296281814575, "step": 80000}
{"episode_reward": 641.0761934923125, "episode": 81.0, "batch_reward": 0.2994256975948811, "critic_loss": 1.9716371273994446, "actor_loss": -90.62902572631836, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 43.413081884384155, "step": 81000}
{"episode_reward": 874.5447859084009, "episode": 82.0, "batch_reward": 0.30281874917447565, "critic_loss": 1.7583756448030472, "actor_loss": -90.6882085571289, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.888907432556152, "step": 82000}
{"episode_reward": 559.0221606125091, "episode": 83.0, "batch_reward": 0.31145118762552737, "critic_loss": 1.5207900531888008, "actor_loss": -89.89164938354492, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.83053421974182, "step": 83000}
{"episode_reward": 908.4806875375602, "episode": 84.0, "batch_reward": 0.3167050165235996, "critic_loss": 1.341809242963791, "actor_loss": -89.31249365234375, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.920488595962524, "step": 84000}
{"episode_reward": 892.1441015687087, "episode": 85.0, "batch_reward": 0.31783429203927516, "critic_loss": 1.3504741395115851, "actor_loss": -88.70603376770019, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.663578033447266, "step": 85000}
{"episode_reward": 404.9377781638121, "episode": 86.0, "batch_reward": 0.3198743272125721, "critic_loss": 1.2674903998374938, "actor_loss": -87.73628443908692, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.247749090194702, "step": 86000}
{"episode_reward": 85.54901066660906, "episode": 87.0, "batch_reward": 0.3196340513676405, "critic_loss": 1.1872357347011566, "actor_loss": -86.96304292297363, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.656920671463013, "step": 87000}
{"episode_reward": 807.2351782748023, "episode": 88.0, "batch_reward": 0.3282914252430201, "critic_loss": 1.144685206890106, "actor_loss": -86.31857447814942, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.74995517730713, "step": 88000}
{"episode_reward": 909.5367709934775, "episode": 89.0, "batch_reward": 0.3332183597385883, "critic_loss": 1.1033496874868869, "actor_loss": -85.63565591430664, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.283260107040405, "step": 89000}
{"episode_reward": 845.3171146026426, "episode": 90.0, "batch_reward": 0.33851210090517997, "critic_loss": 1.0305549344420433, "actor_loss": -85.04479107666016, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.855357885360718, "step": 90000}
{"episode_reward": 879.9107444057724, "episode": 91.0, "batch_reward": 0.34434443229436873, "critic_loss": 1.0033472178578378, "actor_loss": -84.25910409545898, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 44.139681816101074, "step": 91000}
{"episode_reward": 912.834940116774, "episode": 92.0, "batch_reward": 0.34768119728565217, "critic_loss": 1.040177050471306, "actor_loss": -83.68185482788085, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.790924072265625, "step": 92000}
{"episode_reward": 85.16617175672228, "episode": 93.0, "batch_reward": 0.3478896799981594, "critic_loss": 1.000606944233179, "actor_loss": -82.82075169372558, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.606696128845215, "step": 93000}
{"episode_reward": 933.20433466639, "episode": 94.0, "batch_reward": 0.35021003940701484, "critic_loss": 1.0098843663930892, "actor_loss": -82.25711012268066, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.521663904190063, "step": 94000}
{"episode_reward": 88.40958858021553, "episode": 95.0, "batch_reward": 0.34983330783247946, "critic_loss": 0.967051785081625, "actor_loss": -81.19720233154297, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.89897346496582, "step": 95000}
{"episode_reward": 848.5805092725177, "episode": 96.0, "batch_reward": 0.35371912986040116, "critic_loss": 0.9983756422698498, "actor_loss": -80.85936447143554, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.046557188034058, "step": 96000}
{"episode_reward": 90.40924451593808, "episode": 97.0, "batch_reward": 0.353229078233242, "critic_loss": 1.0073826212584973, "actor_loss": -80.26702326965332, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.8067889213562, "step": 97000}
{"episode_reward": 847.7637344153015, "episode": 98.0, "batch_reward": 0.3609951163083315, "critic_loss": 1.0250882350206376, "actor_loss": -80.0427645111084, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.45289444923401, "step": 98000}
{"episode_reward": 882.8094145305023, "episode": 99.0, "batch_reward": 0.3637041328549385, "critic_loss": 1.1297700462937355, "actor_loss": -79.69158442687988, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.70763897895813, "step": 99000}
{"episode_reward": 858.0985134792774, "episode": 100.0, "batch_reward": 0.37138606896996496, "critic_loss": 1.3138321342468262, "actor_loss": -79.75697378540039, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.652706146240234, "step": 100000}
{"episode_reward": 858.2294629072227, "episode": 101.0, "batch_reward": 0.3738697845339775, "critic_loss": 1.4757246173620224, "actor_loss": -79.35846319580078, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 44.23271059989929, "step": 101000}
{"episode_reward": 911.2842188115864, "episode": 102.0, "batch_reward": 0.3805087692439556, "critic_loss": 1.470806422650814, "actor_loss": -79.81078515625, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.058350324630737, "step": 102000}
{"episode_reward": 903.2834450177238, "episode": 103.0, "batch_reward": 0.3831986806988716, "critic_loss": 1.3296272045969963, "actor_loss": -79.87414875793458, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.5076425075531, "step": 103000}
{"episode_reward": 839.5264976678089, "episode": 104.0, "batch_reward": 0.38770934972167015, "critic_loss": 1.247908263027668, "actor_loss": -80.2104730682373, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.035603761672974, "step": 104000}
{"episode_reward": 888.244216548391, "episode": 105.0, "batch_reward": 0.39546632489562034, "critic_loss": 1.1255873742699622, "actor_loss": -80.35158554077148, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.1567440032959, "step": 105000}
{"episode_reward": 874.006781972122, "episode": 106.0, "batch_reward": 0.3969079570174217, "critic_loss": 1.0868814980387689, "actor_loss": -80.59491952514648, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.74494242668152, "step": 106000}
{"episode_reward": 881.8443033522666, "episode": 107.0, "batch_reward": 0.40240874764323237, "critic_loss": 1.0261745909750462, "actor_loss": -80.29999763488769, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.160802602767944, "step": 107000}
{"episode_reward": 902.3399726777445, "episode": 108.0, "batch_reward": 0.4064131470322609, "critic_loss": 1.0147883374392985, "actor_loss": -80.05172186279297, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.646045207977295, "step": 108000}
{"episode_reward": 862.2221628933888, "episode": 109.0, "batch_reward": 0.4127159337699413, "critic_loss": 1.0706662794351578, "actor_loss": -79.98614305114747, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.434773921966553, "step": 109000}
{"episode_reward": 898.4171925631847, "episode": 110.0, "batch_reward": 0.4173636502623558, "critic_loss": 1.0339658924639226, "actor_loss": -79.6864150390625, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.63333511352539, "step": 110000}
{"episode_reward": 877.5756257168351, "episode": 111.0, "batch_reward": 0.4209004161953926, "critic_loss": 1.0421234579980374, "actor_loss": -79.40800228881837, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 44.183470726013184, "step": 111000}
{"episode_reward": 888.8154755601199, "episode": 112.0, "batch_reward": 0.42544632744789124, "critic_loss": 1.0040848066210746, "actor_loss": -79.77893898010254, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.77766513824463, "step": 112000}
{"episode_reward": 926.9658060473328, "episode": 113.0, "batch_reward": 0.43033117774128915, "critic_loss": 0.9974464664459228, "actor_loss": -79.885568069458, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.824357509613037, "step": 113000}
{"episode_reward": 872.8722891835836, "episode": 114.0, "batch_reward": 0.43333822572231295, "critic_loss": 1.0186143577992917, "actor_loss": -79.2465389251709, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.80634117126465, "step": 114000}
{"episode_reward": 937.9908901032862, "episode": 115.0, "batch_reward": 0.43726958668231963, "critic_loss": 1.0517431347668171, "actor_loss": -79.80056410217286, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.136484384536743, "step": 115000}
{"episode_reward": 877.015702487395, "episode": 116.0, "batch_reward": 0.44280727311968804, "critic_loss": 1.0656560100913048, "actor_loss": -79.79791600036621, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.16818642616272, "step": 116000}
{"episode_reward": 867.8747665990877, "episode": 117.0, "batch_reward": 0.44622481989860535, "critic_loss": 1.0604179244041443, "actor_loss": -80.53118334960938, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.966895818710327, "step": 117000}
{"episode_reward": 854.2917729148429, "episode": 118.0, "batch_reward": 0.4485770839750767, "critic_loss": 1.0427346378564835, "actor_loss": -80.26345614624023, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.026836156845093, "step": 118000}
{"episode_reward": 858.770933407712, "episode": 119.0, "batch_reward": 0.453152554243803, "critic_loss": 1.0230274966955184, "actor_loss": -80.53644262695312, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.66697907447815, "step": 119000}
{"episode_reward": 891.2715060907932, "episode": 120.0, "batch_reward": 0.4550368491113186, "critic_loss": 1.0653289021849632, "actor_loss": -81.15574012756348, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.041701316833496, "step": 120000}
{"episode_reward": 876.235525988967, "episode": 121.0, "batch_reward": 0.45888687899708747, "critic_loss": 1.1312524896860123, "actor_loss": -81.29021028137207, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 43.78385519981384, "step": 121000}
{"episode_reward": 879.1187096928908, "episode": 122.0, "batch_reward": 0.46197800904512404, "critic_loss": 1.2057296105325221, "actor_loss": -81.36617440795898, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.858269929885864, "step": 122000}
{"episode_reward": 827.4766265837267, "episode": 123.0, "batch_reward": 0.46701425677537917, "critic_loss": 1.3181429417729378, "actor_loss": -82.14724816894531, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.646509408950806, "step": 123000}
{"episode_reward": 882.3182759991338, "episode": 124.0, "batch_reward": 0.4692398032844067, "critic_loss": 1.418515500664711, "actor_loss": -82.2905051727295, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.91111993789673, "step": 124000}
{"episode_reward": 861.7463954783215, "episode": 125.0, "batch_reward": 0.4708226495683193, "critic_loss": 1.4901726596355438, "actor_loss": -83.03217652893066, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.199034929275513, "step": 125000}
{"episode_reward": 861.0150670795888, "episode": 126.0, "batch_reward": 0.4754712454676628, "critic_loss": 1.430438164651394, "actor_loss": -83.03281387329102, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.671834230422974, "step": 126000}
{"episode_reward": 909.1713303738428, "episode": 127.0, "batch_reward": 0.47856312441825866, "critic_loss": 1.4916178851723672, "actor_loss": -83.40625482177734, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.954500436782837, "step": 127000}
{"episode_reward": 859.6535977740608, "episode": 128.0, "batch_reward": 0.4803866918087006, "critic_loss": 1.5321248989105225, "actor_loss": -83.76160180664063, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.093031644821167, "step": 128000}
{"episode_reward": 888.8699550665226, "episode": 129.0, "batch_reward": 0.4838998998999596, "critic_loss": 1.4880591441988944, "actor_loss": -84.31479911804199, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.223507165908813, "step": 129000}
{"episode_reward": 920.9573937869014, "episode": 130.0, "batch_reward": 0.4901520116329193, "critic_loss": 1.5409018302559851, "actor_loss": -84.74403770446777, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.719728231430054, "step": 130000}
{"episode_reward": 835.8997505739231, "episode": 131.0, "batch_reward": 0.49207946756482124, "critic_loss": 1.5827194413542747, "actor_loss": -84.92343069458008, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 43.533835887908936, "step": 131000}
{"episode_reward": 922.9227024659344, "episode": 132.0, "batch_reward": 0.4928768732249737, "critic_loss": 1.6696283029913903, "actor_loss": -85.28475369262695, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.781662702560425, "step": 132000}
{"episode_reward": 866.1648640898472, "episode": 133.0, "batch_reward": 0.4959508832395077, "critic_loss": 1.7142840422987937, "actor_loss": -85.50107308959961, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.73946452140808, "step": 133000}
{"episode_reward": 922.2006601917774, "episode": 134.0, "batch_reward": 0.49624512207508087, "critic_loss": 1.6523619258999824, "actor_loss": -85.58061029052735, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.68345308303833, "step": 134000}
{"episode_reward": 618.376079178917, "episode": 135.0, "batch_reward": 0.5004676295220852, "critic_loss": 1.7201771209836005, "actor_loss": -86.01719836425781, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.513676166534424, "step": 135000}
{"episode_reward": 958.7826210657624, "episode": 136.0, "batch_reward": 0.5072827631831169, "critic_loss": 1.6791357464790344, "actor_loss": -86.3529578704834, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.195741653442383, "step": 136000}
{"episode_reward": 952.9908464554383, "episode": 137.0, "batch_reward": 0.5050272960066795, "critic_loss": 1.8482814855575562, "actor_loss": -86.60221505737304, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.680442810058594, "step": 137000}
{"episode_reward": 652.4642978693263, "episode": 138.0, "batch_reward": 0.5102988669872284, "critic_loss": 2.2586619601249693, "actor_loss": -86.8697024383545, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.494439363479614, "step": 138000}
{"episode_reward": 933.1653367422601, "episode": 139.0, "batch_reward": 0.5114729921519756, "critic_loss": 2.6707701317667962, "actor_loss": -87.4938002166748, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.894050121307373, "step": 139000}
{"episode_reward": 573.2857261392032, "episode": 140.0, "batch_reward": 0.5082509352862835, "critic_loss": 4.515807359099388, "actor_loss": -87.98385241699219, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.811073303222656, "step": 140000}
{"episode_reward": 90.41231966142763, "episode": 141.0, "batch_reward": 0.50504179880023, "critic_loss": 7.861952080607415, "actor_loss": -89.52388421630859, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 43.71684384346008, "step": 141000}
{"episode_reward": 156.3009024861473, "episode": 142.0, "batch_reward": 0.5007207773029804, "critic_loss": 12.406595904111862, "actor_loss": -94.45897103881836, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.762003660202026, "step": 142000}
{"episode_reward": 60.02612351531798, "episode": 143.0, "batch_reward": 0.5001747896671295, "critic_loss": 18.701270668029785, "actor_loss": -99.77145924377442, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.79816484451294, "step": 143000}
{"episode_reward": 90.32516040089324, "episode": 144.0, "batch_reward": 0.4974822902083397, "critic_loss": 23.309887431144713, "actor_loss": -107.07877770996093, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.03235149383545, "step": 144000}
{"episode_reward": 98.8501716914808, "episode": 145.0, "batch_reward": 0.4962366248965263, "critic_loss": 27.459816111564635, "actor_loss": -112.0135340423584, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.417479515075684, "step": 145000}
{"episode_reward": 71.80941840876523, "episode": 146.0, "batch_reward": 0.49231783413887026, "critic_loss": 29.194401607513427, "actor_loss": -119.25451095581055, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 27.070192098617554, "step": 146000}
{"episode_reward": 72.12025190530856, "episode": 147.0, "batch_reward": 0.48959349662065504, "critic_loss": 31.072282159805297, "actor_loss": -122.60321479797364, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 25.17378520965576, "step": 147000}
{"episode_reward": 75.53672764065517, "episode": 148.0, "batch_reward": 0.4856285558640957, "critic_loss": 28.193427670478822, "actor_loss": -125.739021484375, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.57988715171814, "step": 148000}
{"episode_reward": 78.07245710985126, "episode": 149.0, "batch_reward": 0.48585240650177003, "critic_loss": 27.041212921142577, "actor_loss": -129.13096865844727, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 26.558377742767334, "step": 149000}
{"episode_reward": 132.78262023096815, "episode": 150.0, "batch_reward": 0.4843698956668377, "critic_loss": 26.969091546058653, "actor_loss": -131.7206098022461, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "step": 150000}
