{"episode_reward": 0.0, "episode": 1.0, "duration": 22.151259422302246, "step": 1000}
{"episode_reward": 28.177075776326152, "episode": 2.0, "duration": 1.8980579376220703, "step": 2000}
{"episode_reward": 69.84046218736019, "episode": 3.0, "batch_reward": 0.0500923161068512, "critic_loss": 0.18782112169818269, "actor_loss": -78.43973617889539, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499180007, "duration": 63.69408559799194, "step": 3000}
{"episode_reward": 52.422166232462224, "episode": 4.0, "batch_reward": 0.06991170841827989, "critic_loss": 0.28480063274502754, "actor_loss": -75.01426948547363, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.954503774642944, "step": 4000}
{"episode_reward": 150.38601640136156, "episode": 5.0, "batch_reward": 0.08091595720127225, "critic_loss": 0.20164435981214046, "actor_loss": -73.55525937652588, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.90034055709839, "step": 5000}
{"episode_reward": 95.7026630427775, "episode": 6.0, "batch_reward": 0.07985974245518446, "critic_loss": 0.17583040221780538, "actor_loss": -73.45091271972656, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.792138814926147, "step": 6000}
{"episode_reward": 73.5299640099108, "episode": 7.0, "batch_reward": 0.07649336083233356, "critic_loss": 0.21014512815326453, "actor_loss": -73.70305059814453, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.10365056991577, "step": 7000}
{"episode_reward": 43.22825366052512, "episode": 8.0, "batch_reward": 0.07276600714772939, "critic_loss": 0.18101089556515218, "actor_loss": -73.36005369567872, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.103788137435913, "step": 8000}
{"episode_reward": 65.36539590549124, "episode": 9.0, "batch_reward": 0.07787411930039526, "critic_loss": 0.18561856039613486, "actor_loss": -73.23885245513917, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.103337049484253, "step": 9000}
{"episode_reward": 135.26151662563845, "episode": 10.0, "batch_reward": 0.07844299986958504, "critic_loss": 0.1293648223169148, "actor_loss": -73.08680614471436, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.795363187789917, "step": 10000}
{"episode_reward": 73.7129764175495, "episode": 11.0, "batch_reward": 0.07871079836040736, "critic_loss": 0.11734793777391314, "actor_loss": -72.78975461578369, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.671528339385986, "step": 11000}
{"episode_reward": 77.75046904911675, "episode": 12.0, "batch_reward": 0.08752357116341591, "critic_loss": 0.15433462188765407, "actor_loss": -71.81310140228271, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.52301836013794, "step": 12000}
{"episode_reward": 265.24426822040743, "episode": 13.0, "batch_reward": 0.10239776065945626, "critic_loss": 0.15318358240649105, "actor_loss": -72.11762403869629, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.936090230941772, "step": 13000}
{"episode_reward": 319.98076995586507, "episode": 14.0, "batch_reward": 0.11032391398400068, "critic_loss": 0.13896106646582485, "actor_loss": -71.00617247009278, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.072415828704834, "step": 14000}
{"episode_reward": 76.34044636506135, "episode": 15.0, "batch_reward": 0.1168058036789298, "critic_loss": 0.14356163044273854, "actor_loss": -74.68497715759277, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.029026985168457, "step": 15000}
{"episode_reward": 337.65398038750413, "episode": 16.0, "batch_reward": 0.1276351935118437, "critic_loss": 0.15088415364176036, "actor_loss": -72.183250289917, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.069498538970947, "step": 16000}
{"episode_reward": 163.23127125770614, "episode": 17.0, "batch_reward": 0.13199379853904247, "critic_loss": 0.1556700468659401, "actor_loss": -72.5751848449707, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.4526789188385, "step": 17000}
{"episode_reward": 279.15164197307314, "episode": 18.0, "batch_reward": 0.1417008843794465, "critic_loss": 0.17171044660359622, "actor_loss": -71.64920680236817, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.970176219940186, "step": 18000}
{"episode_reward": 349.22622982333786, "episode": 19.0, "batch_reward": 0.15488862831890582, "critic_loss": 0.1956554769799113, "actor_loss": -70.28159505462646, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.243619203567505, "step": 19000}
{"episode_reward": 415.29997204497556, "episode": 20.0, "batch_reward": 0.1592608582302928, "critic_loss": 0.2054212497472763, "actor_loss": -71.93055488204956, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.147571802139282, "step": 20000}
{"episode_reward": 74.75955120274095, "episode": 21.0, "batch_reward": 0.15487116999179124, "critic_loss": 0.20238225892931222, "actor_loss": -71.37428579711914, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.58334231376648, "step": 21000}
{"episode_reward": 23.634800171645267, "episode": 22.0, "batch_reward": 0.15687124040722847, "critic_loss": 0.2310657507032156, "actor_loss": -70.78924101257324, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.23484754562378, "step": 22000}
{"episode_reward": 385.64083884844365, "episode": 23.0, "batch_reward": 0.1662332683429122, "critic_loss": 0.2491587382555008, "actor_loss": -72.36640335083008, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.091468334197998, "step": 23000}
{"episode_reward": 386.76804519132486, "episode": 24.0, "batch_reward": 0.16891958861052989, "critic_loss": 0.2468926748111844, "actor_loss": -70.8592238960266, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.853073120117188, "step": 24000}
{"episode_reward": 16.790219235429287, "episode": 25.0, "batch_reward": 0.1630725383684039, "critic_loss": 0.2551683458313346, "actor_loss": -69.513446975708, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.690526247024536, "step": 25000}
{"episode_reward": 96.85551087639759, "episode": 26.0, "batch_reward": 0.16001643201708793, "critic_loss": 0.24938378793001176, "actor_loss": -71.0642604675293, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.27924346923828, "step": 26000}
{"episode_reward": 89.52897041971411, "episode": 27.0, "batch_reward": 0.16585171957314016, "critic_loss": 0.27044942082464696, "actor_loss": -69.49006010055543, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.88366675376892, "step": 27000}
{"episode_reward": 462.1145048505909, "episode": 28.0, "batch_reward": 0.17331846498697995, "critic_loss": 0.310003030449152, "actor_loss": -68.80904028320313, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.982945442199707, "step": 28000}
{"episode_reward": 335.0844964293324, "episode": 29.0, "batch_reward": 0.17337585701048375, "critic_loss": 0.3162523872703314, "actor_loss": -69.62055865097047, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.718883991241455, "step": 29000}
{"episode_reward": 15.988911290880212, "episode": 30.0, "batch_reward": 0.1700041573047638, "critic_loss": 0.3134173423498869, "actor_loss": -68.14223432922363, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.98171067237854, "step": 30000}
{"episode_reward": 69.57949360624231, "episode": 31.0, "batch_reward": 0.16680749215185642, "critic_loss": 0.30052756698429584, "actor_loss": -67.84966609573364, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.64805626869202, "step": 31000}
{"episode_reward": 75.1003130834627, "episode": 32.0, "batch_reward": 0.16868001593649387, "critic_loss": 0.32170368449389936, "actor_loss": -66.62105979919434, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.074288845062256, "step": 32000}
{"episode_reward": 434.9515539296084, "episode": 33.0, "batch_reward": 0.17500495524704457, "critic_loss": 0.37741819739341737, "actor_loss": -68.60597917556763, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.295634269714355, "step": 33000}
{"episode_reward": 387.15848012041977, "episode": 34.0, "batch_reward": 0.17966966535151005, "critic_loss": 0.3975608511567116, "actor_loss": -66.53445935058593, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.832728147506714, "step": 34000}
{"episode_reward": 127.96960904385939, "episode": 35.0, "batch_reward": 0.18130292429775, "critic_loss": 0.42583064071834087, "actor_loss": -69.2772458076477, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.526103019714355, "step": 35000}
{"episode_reward": 437.4862407053378, "episode": 36.0, "batch_reward": 0.1813496155589819, "critic_loss": 0.4298955983966589, "actor_loss": -65.83563762664795, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.766943216323853, "step": 36000}
{"episode_reward": 15.414754524111146, "episode": 37.0, "batch_reward": 0.1799777628555894, "critic_loss": 0.4430346530377865, "actor_loss": -68.50741264343262, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.020848989486694, "step": 37000}
{"episode_reward": 91.20521000948062, "episode": 38.0, "batch_reward": 0.1778046456873417, "critic_loss": 0.4187411413937807, "actor_loss": -68.06641036224366, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.32242488861084, "step": 38000}
{"episode_reward": 106.66394289893185, "episode": 39.0, "batch_reward": 0.17917600920051335, "critic_loss": 0.42522835187613967, "actor_loss": -68.06107388687134, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.106229782104492, "step": 39000}
{"episode_reward": 469.783619282984, "episode": 40.0, "batch_reward": 0.18637409552931786, "critic_loss": 0.43211612150073053, "actor_loss": -68.62698370933532, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.115460872650146, "step": 40000}
{"episode_reward": 361.6397608697475, "episode": 41.0, "batch_reward": 0.18791411335766314, "critic_loss": 0.42564475528895857, "actor_loss": -68.94406950378418, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.73716640472412, "step": 41000}
{"episode_reward": 94.0398293149322, "episode": 42.0, "batch_reward": 0.18486730347573757, "critic_loss": 0.41268364995718004, "actor_loss": -66.54173762130738, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.95155096054077, "step": 42000}
{"episode_reward": 72.56764144734645, "episode": 43.0, "batch_reward": 0.18672708322107792, "critic_loss": 0.42698529310524463, "actor_loss": -67.15983467674255, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.21672797203064, "step": 43000}
{"episode_reward": 461.6470049008604, "episode": 44.0, "batch_reward": 0.19110782574117183, "critic_loss": 0.4457020267993212, "actor_loss": -66.93981062507629, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.943702459335327, "step": 44000}
{"episode_reward": 188.8143014426714, "episode": 45.0, "batch_reward": 0.18821182859688998, "critic_loss": 0.43604368014633654, "actor_loss": -67.03123954963684, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.529685735702515, "step": 45000}
{"episode_reward": 16.12043825882421, "episode": 46.0, "batch_reward": 0.1834239703565836, "critic_loss": 0.4415829361826181, "actor_loss": -66.42937161254883, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.68168592453003, "step": 46000}
{"episode_reward": 62.89927396219639, "episode": 47.0, "batch_reward": 0.18198731060326098, "critic_loss": 0.41700805799663065, "actor_loss": -67.67884774971009, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.985112190246582, "step": 47000}
{"episode_reward": 70.7090999354062, "episode": 48.0, "batch_reward": 0.1828816675543785, "critic_loss": 0.44444160936772825, "actor_loss": -66.77889100074768, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.085726022720337, "step": 48000}
{"episode_reward": 374.6617621711813, "episode": 49.0, "batch_reward": 0.1870838330835104, "critic_loss": 0.46194681003689764, "actor_loss": -68.67953612136841, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.9731125831604, "step": 49000}
{"episode_reward": 290.37874946072986, "episode": 50.0, "batch_reward": 0.19098933924734593, "critic_loss": 0.4818068025559187, "actor_loss": -66.83490237617492, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.39140558242798, "step": 50000}
{"episode_reward": 468.1925701377951, "episode": 51.0, "batch_reward": 0.19499886812269687, "critic_loss": 0.48661021618545053, "actor_loss": -67.24064626693726, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.7960045337677, "step": 51000}
{"episode_reward": 346.5321659042759, "episode": 52.0, "batch_reward": 0.19459890101850033, "critic_loss": 0.5163223964124918, "actor_loss": -66.79893267059326, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.85438561439514, "step": 52000}
{"episode_reward": 70.54488622478031, "episode": 53.0, "batch_reward": 0.19665208369493484, "critic_loss": 0.4846027921885252, "actor_loss": -67.5325383644104, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.197731733322144, "step": 53000}
{"episode_reward": 500.55152216622685, "episode": 54.0, "batch_reward": 0.20141669382154942, "critic_loss": 0.5038730905801058, "actor_loss": -66.79429340934753, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.21059775352478, "step": 54000}
{"episode_reward": 462.3258168077166, "episode": 55.0, "batch_reward": 0.20278347977995873, "critic_loss": 0.4837781633883715, "actor_loss": -69.20734506797791, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.109599828720093, "step": 55000}
{"episode_reward": 66.89214034763636, "episode": 56.0, "batch_reward": 0.20318230192363262, "critic_loss": 0.4806073254495859, "actor_loss": -68.410188205719, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.451613187789917, "step": 56000}
{"episode_reward": 477.0299734159835, "episode": 57.0, "batch_reward": 0.206264910787344, "critic_loss": 0.4859414990991354, "actor_loss": -66.57664629936218, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.94885516166687, "step": 57000}
{"episode_reward": 73.97283873911698, "episode": 58.0, "batch_reward": 0.2039773919582367, "critic_loss": 0.46200525015592575, "actor_loss": -67.1359261341095, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.602654218673706, "step": 58000}
{"episode_reward": 69.09987245077467, "episode": 59.0, "batch_reward": 0.20396111412346363, "critic_loss": 0.4791424375027418, "actor_loss": -66.32280782699586, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.957974672317505, "step": 59000}
{"episode_reward": 462.48722918803526, "episode": 60.0, "batch_reward": 0.2087279304265976, "critic_loss": 0.4708098902702332, "actor_loss": -66.99346196174622, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.96276545524597, "step": 60000}
{"episode_reward": 484.66688712235134, "episode": 61.0, "batch_reward": 0.2097741646617651, "critic_loss": 0.4837064639627934, "actor_loss": -66.11903707313537, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.30326819419861, "step": 61000}
{"episode_reward": 62.35271923739338, "episode": 62.0, "batch_reward": 0.20861792013049127, "critic_loss": 0.46801097558438776, "actor_loss": -68.61525423812866, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.58564257621765, "step": 62000}
{"episode_reward": 67.97439483179704, "episode": 63.0, "batch_reward": 0.2038534279316664, "critic_loss": 0.4595607270300388, "actor_loss": -66.96108622932434, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.988666772842407, "step": 63000}
{"episode_reward": 76.8322882870294, "episode": 64.0, "batch_reward": 0.2052911868840456, "critic_loss": 0.4769223757982254, "actor_loss": -67.24631583213807, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.510669946670532, "step": 64000}
{"episode_reward": 337.4955523410556, "episode": 65.0, "batch_reward": 0.20526674437522888, "critic_loss": 0.4983426342010498, "actor_loss": -66.22645607566834, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.77975106239319, "step": 65000}
{"episode_reward": 17.75113363857507, "episode": 66.0, "batch_reward": 0.20360919798910618, "critic_loss": 0.5173079723268748, "actor_loss": -66.551669506073, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.091933012008667, "step": 66000}
{"episode_reward": 213.03899395450392, "episode": 67.0, "batch_reward": 0.20566036693751813, "critic_loss": 0.5439995668828488, "actor_loss": -67.0660070438385, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.294806957244873, "step": 67000}
{"episode_reward": 494.6305233469054, "episode": 68.0, "batch_reward": 0.20765709851682185, "critic_loss": 0.5335502182394266, "actor_loss": -66.15107397651673, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.331985235214233, "step": 68000}
{"episode_reward": 44.43496738628947, "episode": 69.0, "batch_reward": 0.2072805095911026, "critic_loss": 0.532124048113823, "actor_loss": -66.56280063247681, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.025699377059937, "step": 69000}
{"episode_reward": 535.3929168010491, "episode": 70.0, "batch_reward": 0.21229042240977286, "critic_loss": 0.5575792944729329, "actor_loss": -67.19346708869934, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.90971612930298, "step": 70000}
{"episode_reward": 362.3891484672112, "episode": 71.0, "batch_reward": 0.21121812428534031, "critic_loss": 0.5479700846672058, "actor_loss": -67.72843115615845, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.31130027770996, "step": 71000}
{"episode_reward": 74.98087533927873, "episode": 72.0, "batch_reward": 0.20944677416980267, "critic_loss": 0.5469180585443973, "actor_loss": -67.76338415145874, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.96265959739685, "step": 72000}
{"episode_reward": 71.27600264656338, "episode": 73.0, "batch_reward": 0.2104940791875124, "critic_loss": 0.5705256690084934, "actor_loss": -66.81820741653442, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.9153151512146, "step": 73000}
{"episode_reward": 286.97111730032134, "episode": 74.0, "batch_reward": 0.21053689227998257, "critic_loss": 0.5940283264517784, "actor_loss": -68.0441380558014, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.03116464614868, "step": 74000}
{"episode_reward": 445.7352243800929, "episode": 75.0, "batch_reward": 0.21175460740923882, "critic_loss": 0.6100452276170254, "actor_loss": -66.59203924560546, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.24495005607605, "step": 75000}
{"episode_reward": 71.33804665293896, "episode": 76.0, "batch_reward": 0.21198223850131034, "critic_loss": 0.6287585538476705, "actor_loss": -67.35034555053711, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.92721939086914, "step": 76000}
{"episode_reward": 265.1446709342513, "episode": 77.0, "batch_reward": 0.2107130984812975, "critic_loss": 0.5964619691073895, "actor_loss": -65.81077509880066, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.353657722473145, "step": 77000}
{"episode_reward": 47.566616619407725, "episode": 78.0, "batch_reward": 0.2077896347939968, "critic_loss": 0.5909610599279403, "actor_loss": -67.39730884933472, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.842870950698853, "step": 78000}
{"episode_reward": 76.59407074173673, "episode": 79.0, "batch_reward": 0.2069470701366663, "critic_loss": 0.6122687398195267, "actor_loss": -63.718856004714965, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.16607928276062, "step": 79000}
{"episode_reward": 14.965735388391513, "episode": 80.0, "batch_reward": 0.2042313940823078, "critic_loss": 0.6028986798524857, "actor_loss": -65.73283073997497, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.87437129020691, "step": 80000}
{"episode_reward": 74.4802761136653, "episode": 81.0, "batch_reward": 0.20474858705699445, "critic_loss": 0.6062872159779071, "actor_loss": -65.40951257324218, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.74601411819458, "step": 81000}
{"episode_reward": 546.9663762326746, "episode": 82.0, "batch_reward": 0.20715677380561828, "critic_loss": 0.6206343900263309, "actor_loss": -68.37122666358948, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.001026153564453, "step": 82000}
{"episode_reward": 70.20841011943081, "episode": 83.0, "batch_reward": 0.21031119811534882, "critic_loss": 0.6258539468646049, "actor_loss": -65.50573356628418, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.08661699295044, "step": 83000}
{"episode_reward": 535.837464510371, "episode": 84.0, "batch_reward": 0.21129875054955483, "critic_loss": 0.6763883690536022, "actor_loss": -69.58326677131653, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.075700283050537, "step": 84000}
{"episode_reward": 291.75167746998505, "episode": 85.0, "batch_reward": 0.21236261208355428, "critic_loss": 0.6991391206383705, "actor_loss": -67.06412712669372, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.971179723739624, "step": 85000}
{"episode_reward": 417.14017246943746, "episode": 86.0, "batch_reward": 0.21606207048892975, "critic_loss": 0.7440668235421181, "actor_loss": -67.04197233390808, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.78830885887146, "step": 86000}
{"episode_reward": 406.29896103008736, "episode": 87.0, "batch_reward": 0.2142311076372862, "critic_loss": 0.7529295834302903, "actor_loss": -66.61874193000793, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.007012128829956, "step": 87000}
{"episode_reward": 98.28726930829787, "episode": 88.0, "batch_reward": 0.2149100527316332, "critic_loss": 0.7423054894506931, "actor_loss": -65.32011190414428, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.76498007774353, "step": 88000}
{"episode_reward": 438.1535604861986, "episode": 89.0, "batch_reward": 0.2188611930012703, "critic_loss": 0.76601959438622, "actor_loss": -67.27638288497924, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.707683324813843, "step": 89000}
{"episode_reward": 499.29267531297415, "episode": 90.0, "batch_reward": 0.21953136417269706, "critic_loss": 0.7969590146839619, "actor_loss": -68.10330364227295, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.007227659225464, "step": 90000}
{"episode_reward": 77.217963524171, "episode": 91.0, "batch_reward": 0.22116947789490224, "critic_loss": 0.8011373131573201, "actor_loss": -67.26128540229797, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.92617630958557, "step": 91000}
{"episode_reward": 489.4823828926705, "episode": 92.0, "batch_reward": 0.22032883930206298, "critic_loss": 0.7921341921985149, "actor_loss": -66.84213451194763, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.857641458511353, "step": 92000}
{"episode_reward": 79.14580723455735, "episode": 93.0, "batch_reward": 0.22103460563719274, "critic_loss": 0.8034209107756615, "actor_loss": -65.9600913181305, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.125729084014893, "step": 93000}
{"episode_reward": 523.4517162526395, "episode": 94.0, "batch_reward": 0.22164812777936457, "critic_loss": 0.7660034519731999, "actor_loss": -67.23459617805482, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.721585750579834, "step": 94000}
{"episode_reward": 85.25757403624577, "episode": 95.0, "batch_reward": 0.21981684485077857, "critic_loss": 0.7753387685418129, "actor_loss": -67.64831265830993, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.382975578308105, "step": 95000}
{"episode_reward": 84.43979399342372, "episode": 96.0, "batch_reward": 0.2217142552137375, "critic_loss": 0.7523032605946064, "actor_loss": -68.08492511367798, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.950283527374268, "step": 96000}
{"episode_reward": 511.426908158162, "episode": 97.0, "batch_reward": 0.2232594178020954, "critic_loss": 0.7837339894771576, "actor_loss": -69.07589447784424, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.29033637046814, "step": 97000}
{"episode_reward": 452.08273285897445, "episode": 98.0, "batch_reward": 0.22816478797793388, "critic_loss": 0.7542954482734203, "actor_loss": -68.17638644981385, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.74794864654541, "step": 98000}
{"episode_reward": 492.3063593379882, "episode": 99.0, "batch_reward": 0.2299526462852955, "critic_loss": 0.7222294735610485, "actor_loss": -66.44620270729065, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.1752347946167, "step": 99000}
{"episode_reward": 541.7574354278281, "episode": 100.0, "batch_reward": 0.233274379119277, "critic_loss": 0.7340253400504589, "actor_loss": -67.81771889305115, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.288337469100952, "step": 100000}
{"episode_reward": 486.357680857075, "episode": 101.0, "batch_reward": 0.235960184186697, "critic_loss": 0.7311619788706303, "actor_loss": -67.99902775192261, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.37743663787842, "step": 101000}
{"episode_reward": 610.724955778265, "episode": 102.0, "batch_reward": 0.23769429568946362, "critic_loss": 0.8162762705087662, "actor_loss": -67.0112940673828, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.97170376777649, "step": 102000}
{"episode_reward": 399.06356951530626, "episode": 103.0, "batch_reward": 0.2389249807149172, "critic_loss": 0.829056751549244, "actor_loss": -68.6500279788971, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.86771273612976, "step": 103000}
{"episode_reward": 100.00209698791737, "episode": 104.0, "batch_reward": 0.23961614048480986, "critic_loss": 0.8225672889351845, "actor_loss": -68.76034731483459, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.632548093795776, "step": 104000}
{"episode_reward": 647.6594400533553, "episode": 105.0, "batch_reward": 0.24522836120426655, "critic_loss": 0.835375796943903, "actor_loss": -68.7032066078186, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.998843669891357, "step": 105000}
{"episode_reward": 586.1405368851339, "episode": 106.0, "batch_reward": 0.24611652049422264, "critic_loss": 0.8483100795745849, "actor_loss": -68.09816910362244, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.054217100143433, "step": 106000}
{"episode_reward": 587.5298657696628, "episode": 107.0, "batch_reward": 0.2469592984765768, "critic_loss": 0.8536652956306935, "actor_loss": -69.2175830898285, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.98876166343689, "step": 107000}
{"episode_reward": 92.4286792729673, "episode": 108.0, "batch_reward": 0.24677340087294578, "critic_loss": 0.8531633376479149, "actor_loss": -68.10736318206787, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.551501035690308, "step": 108000}
{"episode_reward": 15.042573097553166, "episode": 109.0, "batch_reward": 0.24748286168277264, "critic_loss": 0.8766829997599125, "actor_loss": -70.83922867774963, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.233561754226685, "step": 109000}
{"episode_reward": 517.1208016502765, "episode": 110.0, "batch_reward": 0.24892828397452832, "critic_loss": 0.9054626459479332, "actor_loss": -69.65227526855469, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.858677625656128, "step": 110000}
{"episode_reward": 548.3669098318064, "episode": 111.0, "batch_reward": 0.251505041539669, "critic_loss": 0.9377648470401764, "actor_loss": -69.59978178787232, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.67056393623352, "step": 111000}
{"episode_reward": 618.9776881936675, "episode": 112.0, "batch_reward": 0.25518628817796707, "critic_loss": 0.9423435754179954, "actor_loss": -67.5179829826355, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.218289613723755, "step": 112000}
{"episode_reward": 614.4223204271586, "episode": 113.0, "batch_reward": 0.255413823261857, "critic_loss": 0.8831265526115895, "actor_loss": -69.22604964637756, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.989251852035522, "step": 113000}
{"episode_reward": 16.006355570189136, "episode": 114.0, "batch_reward": 0.2567054659128189, "critic_loss": 0.8771543770134449, "actor_loss": -70.44576099777221, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.172492504119873, "step": 114000}
{"episode_reward": 597.0049389908469, "episode": 115.0, "batch_reward": 0.25660333585739137, "critic_loss": 0.8814088853299618, "actor_loss": -68.97203530883789, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.110769033432007, "step": 115000}
{"episode_reward": 177.5604215067764, "episode": 116.0, "batch_reward": 0.2559386748224497, "critic_loss": 0.916898746073246, "actor_loss": -68.73767698478699, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.96025514602661, "step": 116000}
{"episode_reward": 94.63007856367224, "episode": 117.0, "batch_reward": 0.2576013753414154, "critic_loss": 0.8856876835227012, "actor_loss": -68.13877476119995, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.735884189605713, "step": 117000}
{"episode_reward": 658.8951693075979, "episode": 118.0, "batch_reward": 0.26073184560239315, "critic_loss": 0.8758701446950435, "actor_loss": -69.36058197402954, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.17644190788269, "step": 118000}
{"episode_reward": 590.0159166477478, "episode": 119.0, "batch_reward": 0.263746151521802, "critic_loss": 0.9071012406051159, "actor_loss": -69.79492466545105, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.00624108314514, "step": 119000}
{"episode_reward": 615.5567175072915, "episode": 120.0, "batch_reward": 0.26610654056072236, "critic_loss": 0.9232052571177483, "actor_loss": -69.28200834465027, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.976094961166382, "step": 120000}
{"episode_reward": 655.7379990952877, "episode": 121.0, "batch_reward": 0.26957629892230034, "critic_loss": 0.8999354400038719, "actor_loss": -68.0975007019043, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.505921840667725, "step": 121000}
{"episode_reward": 611.1785865853826, "episode": 122.0, "batch_reward": 0.27030395744740965, "critic_loss": 0.9428866268396378, "actor_loss": -68.91295727920532, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.590805768966675, "step": 122000}
{"episode_reward": 646.0216474488122, "episode": 123.0, "batch_reward": 0.2734173860102892, "critic_loss": 0.9684625222384929, "actor_loss": -67.06742310523987, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.179765939712524, "step": 123000}
{"episode_reward": 660.8135294411525, "episode": 124.0, "batch_reward": 0.27829217779636384, "critic_loss": 0.9739572874307633, "actor_loss": -68.8180880355835, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.074745655059814, "step": 124000}
{"episode_reward": 682.6184401635632, "episode": 125.0, "batch_reward": 0.2811723393201828, "critic_loss": 0.9804943027794362, "actor_loss": -68.52555094528198, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.97942590713501, "step": 125000}
{"episode_reward": 635.3032220703105, "episode": 126.0, "batch_reward": 0.2855059996843338, "critic_loss": 1.0058069580495357, "actor_loss": -67.57977469444275, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.934221506118774, "step": 126000}
{"episode_reward": 643.749828302097, "episode": 127.0, "batch_reward": 0.28892853309214117, "critic_loss": 1.0413927111625672, "actor_loss": -70.10246169281005, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.643072366714478, "step": 127000}
{"episode_reward": 704.2751699376149, "episode": 128.0, "batch_reward": 0.2868998636752367, "critic_loss": 1.0402521425783635, "actor_loss": -71.67989865112305, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.06359076499939, "step": 128000}
{"episode_reward": 100.44471761369007, "episode": 129.0, "batch_reward": 0.2878346173912287, "critic_loss": 1.0876508424282074, "actor_loss": -70.43252488136291, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.050681591033936, "step": 129000}
{"episode_reward": 631.3035110660065, "episode": 130.0, "batch_reward": 0.29248076665401457, "critic_loss": 1.1456936331987382, "actor_loss": -70.30440853881836, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.859801769256592, "step": 130000}
{"episode_reward": 711.7651127287763, "episode": 131.0, "batch_reward": 0.29653931242227555, "critic_loss": 1.1696880360245705, "actor_loss": -71.75038996124267, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.66297507286072, "step": 131000}
{"episode_reward": 718.9143621442366, "episode": 132.0, "batch_reward": 0.2959460230767727, "critic_loss": 1.1901804914474488, "actor_loss": -71.47175140762329, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.22942066192627, "step": 132000}
{"episode_reward": 94.44620411709592, "episode": 133.0, "batch_reward": 0.2946886391788721, "critic_loss": 1.1841949738860131, "actor_loss": -70.72145093536378, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.10417604446411, "step": 133000}
{"episode_reward": 58.357301447210894, "episode": 134.0, "batch_reward": 0.29210212440788746, "critic_loss": 1.2274599357843399, "actor_loss": -71.42565314865112, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.52001190185547, "step": 134000}
{"episode_reward": 96.8972625762068, "episode": 135.0, "batch_reward": 0.2930674084573984, "critic_loss": 1.2043658200502396, "actor_loss": -70.9631509513855, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.99780249595642, "step": 135000}
{"episode_reward": 695.0584174651896, "episode": 136.0, "batch_reward": 0.29740091870725155, "critic_loss": 1.2838088445663451, "actor_loss": -72.90126982116699, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.55498242378235, "step": 136000}
{"episode_reward": 745.6531637733624, "episode": 137.0, "batch_reward": 0.2989215797334909, "critic_loss": 1.3058181356191636, "actor_loss": -71.57476541900635, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.938288688659668, "step": 137000}
{"episode_reward": 763.3439185427692, "episode": 138.0, "batch_reward": 0.3034095599800348, "critic_loss": 1.3726169630289078, "actor_loss": -68.8054376449585, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.02398920059204, "step": 138000}
{"episode_reward": 691.1885813218304, "episode": 139.0, "batch_reward": 0.30692957843840124, "critic_loss": 1.4227573701143266, "actor_loss": -69.87857077026368, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.95471978187561, "step": 139000}
{"episode_reward": 703.4819434385687, "episode": 140.0, "batch_reward": 0.3050320775806904, "critic_loss": 1.4449659650325775, "actor_loss": -68.78141842651367, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.62587022781372, "step": 140000}
{"episode_reward": 14.642299395284079, "episode": 141.0, "batch_reward": 0.3045909065753222, "critic_loss": 1.4429171009063722, "actor_loss": -69.75283100891113, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.05012631416321, "step": 141000}
{"episode_reward": 100.49466546569778, "episode": 142.0, "batch_reward": 0.3051221441626549, "critic_loss": 1.457404856801033, "actor_loss": -70.26474405288697, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.001042127609253, "step": 142000}
{"episode_reward": 814.6624067888315, "episode": 143.0, "batch_reward": 0.30566270151734354, "critic_loss": 1.516055334687233, "actor_loss": -71.33887954330444, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.023327827453613, "step": 143000}
{"episode_reward": 98.79427110563515, "episode": 144.0, "batch_reward": 0.30602315911650657, "critic_loss": 1.561473404943943, "actor_loss": -70.9424803237915, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.18800115585327, "step": 144000}
{"episode_reward": 44.55619916576007, "episode": 145.0, "batch_reward": 0.3065482514500618, "critic_loss": 1.536628681898117, "actor_loss": -70.4446092338562, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.97418212890625, "step": 145000}
{"episode_reward": 777.0749751917207, "episode": 146.0, "batch_reward": 0.3062551915794611, "critic_loss": 1.5740676382780074, "actor_loss": -70.17506639480591, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.467561721801758, "step": 146000}
{"episode_reward": 99.12067329650684, "episode": 147.0, "batch_reward": 0.30920920546352865, "critic_loss": 1.5732717528939246, "actor_loss": -72.02568988037109, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.747167587280273, "step": 147000}
{"episode_reward": 764.5802664177071, "episode": 148.0, "batch_reward": 0.30987462046742437, "critic_loss": 1.572104064643383, "actor_loss": -70.58736804199219, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.06815457344055, "step": 148000}
{"episode_reward": 808.8328046958804, "episode": 149.0, "batch_reward": 0.31391843129694463, "critic_loss": 1.5330570102334022, "actor_loss": -71.5742958831787, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.292324542999268, "step": 149000}
{"episode_reward": 724.0602414517905, "episode": 150.0, "batch_reward": 0.31777013519406316, "critic_loss": 1.5615713289380073, "actor_loss": -70.11043086624146, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "step": 150000}
