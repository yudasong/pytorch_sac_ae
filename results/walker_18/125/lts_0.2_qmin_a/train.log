{"episode_reward": 0.0, "episode": 1.0, "duration": 21.514156579971313, "step": 1000}
{"episode_reward": 28.177075776326152, "episode": 2.0, "duration": 1.8606860637664795, "step": 2000}
{"episode_reward": 69.84046218736019, "episode": 3.0, "batch_reward": 0.04710183875953885, "critic_loss": 0.009601298020133642, "actor_loss": -14.741831720058693, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499180007, "duration": 61.153348207473755, "step": 3000}
{"episode_reward": 19.158227927592357, "episode": 4.0, "batch_reward": 0.04242813544347882, "critic_loss": 0.007545900736469775, "actor_loss": -17.623554162120445, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.41206121444702, "step": 4000}
{"episode_reward": 59.15734734473542, "episode": 5.0, "batch_reward": 0.04265629435703158, "critic_loss": 0.008925708515569567, "actor_loss": -15.873259782131761, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.468350410461426, "step": 5000}
{"episode_reward": 21.505580650511803, "episode": 6.0, "batch_reward": 0.03810352324135601, "critic_loss": 0.017796025041956456, "actor_loss": -15.330916248507798, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.475523710250854, "step": 6000}
{"episode_reward": 22.715737003770016, "episode": 7.0, "batch_reward": 0.03935949207283557, "critic_loss": 0.029603254658170045, "actor_loss": -16.542747766733168, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.450586795806885, "step": 7000}
{"episode_reward": 42.85273369333565, "episode": 8.0, "batch_reward": 0.04019786861725152, "critic_loss": 0.03388669313304126, "actor_loss": -14.93553791809082, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.456453323364258, "step": 8000}
{"episode_reward": 65.8832418600683, "episode": 9.0, "batch_reward": 0.04044335152767599, "critic_loss": 0.040249896800145506, "actor_loss": -16.881492259502412, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.463807582855225, "step": 9000}
{"episode_reward": 22.61165530532276, "episode": 10.0, "batch_reward": 0.040610686775296924, "critic_loss": 0.049455339111387726, "actor_loss": -16.194321507930756, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.4617760181427, "step": 10000}
{"episode_reward": 63.33869207832226, "episode": 11.0, "batch_reward": 0.042968642350286246, "critic_loss": 0.056747793279588225, "actor_loss": -20.082395567893983, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.636271238327026, "step": 11000}
{"episode_reward": 65.7637088166342, "episode": 12.0, "batch_reward": 0.04307440000027418, "critic_loss": 0.06974177318252624, "actor_loss": -18.068014331817626, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.442554235458374, "step": 12000}
{"episode_reward": 21.004672213953747, "episode": 13.0, "batch_reward": 0.04430061028338969, "critic_loss": 0.07139504570513963, "actor_loss": -18.729469462871553, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.453036546707153, "step": 13000}
{"episode_reward": 92.90368845003734, "episode": 14.0, "batch_reward": 0.04802247905358672, "critic_loss": 0.0997738643027842, "actor_loss": -18.235756415367128, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.466074466705322, "step": 14000}
{"episode_reward": 96.3627466978733, "episode": 15.0, "batch_reward": 0.05262130765244365, "critic_loss": 0.1171681349426508, "actor_loss": -18.837739381313323, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.424553871154785, "step": 15000}
{"episode_reward": 112.78427656779817, "episode": 16.0, "batch_reward": 0.058746063109487295, "critic_loss": 0.15269396401941776, "actor_loss": -19.701082005500794, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.444616079330444, "step": 16000}
{"episode_reward": 193.5238627771309, "episode": 17.0, "batch_reward": 0.06459321808069944, "critic_loss": 0.1833658600859344, "actor_loss": -18.636084838867188, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.466357469558716, "step": 17000}
{"episode_reward": 119.38471437986276, "episode": 18.0, "batch_reward": 0.06442771629244089, "critic_loss": 0.1831163308545947, "actor_loss": -19.037706729888917, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.461700439453125, "step": 18000}
{"episode_reward": 25.040612422270886, "episode": 19.0, "batch_reward": 0.07073087739944459, "critic_loss": 0.21735075935721399, "actor_loss": -23.590977874755858, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.452465534210205, "step": 19000}
{"episode_reward": 323.09536303807374, "episode": 20.0, "batch_reward": 0.07628073584288358, "critic_loss": 0.2086298060938716, "actor_loss": -23.403072473526002, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.484049558639526, "step": 20000}
{"episode_reward": 65.271073251736, "episode": 21.0, "batch_reward": 0.07612547598406673, "critic_loss": 0.2198793953061104, "actor_loss": -25.237730422973634, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.55862379074097, "step": 21000}
{"episode_reward": 63.40651931247094, "episode": 22.0, "batch_reward": 0.08174409767240286, "critic_loss": 0.23676056779921054, "actor_loss": -24.680218473434447, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.44973587989807, "step": 22000}
{"episode_reward": 327.6470935802498, "episode": 23.0, "batch_reward": 0.09124583826214075, "critic_loss": 0.3283101137056947, "actor_loss": -23.1851990776062, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.4657084941864, "step": 23000}
{"episode_reward": 279.85105328926477, "episode": 24.0, "batch_reward": 0.10105110748112202, "critic_loss": 0.34755997693538665, "actor_loss": -24.356117025375365, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.469623565673828, "step": 24000}
{"episode_reward": 366.24170128832304, "episode": 25.0, "batch_reward": 0.112791295170784, "critic_loss": 0.3428463803678751, "actor_loss": -26.40468836784363, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.447517156600952, "step": 25000}
{"episode_reward": 396.0974761131015, "episode": 26.0, "batch_reward": 0.11849308069050311, "critic_loss": 0.3335812465250492, "actor_loss": -26.917779878616333, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.462624311447144, "step": 26000}
{"episode_reward": 163.2255036852575, "episode": 27.0, "batch_reward": 0.12493478432297707, "critic_loss": 0.3462551660686731, "actor_loss": -27.846291301727295, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.443896770477295, "step": 27000}
{"episode_reward": 393.4149314849777, "episode": 28.0, "batch_reward": 0.12914886359870434, "critic_loss": 0.3123386441171169, "actor_loss": -28.88893584060669, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.45406436920166, "step": 28000}
{"episode_reward": 34.32991634014481, "episode": 29.0, "batch_reward": 0.12476367118954658, "critic_loss": 0.2886581434458494, "actor_loss": -30.032221759796144, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.443654537200928, "step": 29000}
{"episode_reward": 35.10519135505103, "episode": 30.0, "batch_reward": 0.12352271152287722, "critic_loss": 0.2919985286593437, "actor_loss": -31.419497566223143, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.43529510498047, "step": 30000}
{"episode_reward": 92.94006556962044, "episode": 31.0, "batch_reward": 0.12272434058040381, "critic_loss": 0.27750765216350554, "actor_loss": -32.288763835906984, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.57439088821411, "step": 31000}
{"episode_reward": 69.46625423606567, "episode": 32.0, "batch_reward": 0.12194076052308082, "critic_loss": 0.28457331357896326, "actor_loss": -33.32933713912964, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.440732955932617, "step": 32000}
{"episode_reward": 114.0850078638171, "episode": 33.0, "batch_reward": 0.12066519795358181, "critic_loss": 0.28400182113051414, "actor_loss": -34.09110185241699, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.466092824935913, "step": 33000}
{"episode_reward": 73.31089857651841, "episode": 34.0, "batch_reward": 0.11942168571799994, "critic_loss": 0.2834418393149972, "actor_loss": -32.41033605957031, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.47432851791382, "step": 34000}
{"episode_reward": 78.7360450114215, "episode": 35.0, "batch_reward": 0.11998501452058553, "critic_loss": 0.2947142235785723, "actor_loss": -34.397543087005616, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.456583976745605, "step": 35000}
{"episode_reward": 170.1766544643849, "episode": 36.0, "batch_reward": 0.11825232648104429, "critic_loss": 0.3438824410140514, "actor_loss": -35.7225337600708, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.48380470275879, "step": 36000}
{"episode_reward": 15.264967135830696, "episode": 37.0, "batch_reward": 0.11480096288025379, "critic_loss": 0.3359351019561291, "actor_loss": -34.87599219894409, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.501988410949707, "step": 37000}
{"episode_reward": 18.467654214539706, "episode": 38.0, "batch_reward": 0.11334205152839422, "critic_loss": 0.30085292490571736, "actor_loss": -35.716471858978274, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.44260287284851, "step": 38000}
{"episode_reward": 21.432567081913245, "episode": 39.0, "batch_reward": 0.11779442081600427, "critic_loss": 0.31433293294906617, "actor_loss": -37.919202919006345, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.44246768951416, "step": 39000}
{"episode_reward": 551.6118833314995, "episode": 40.0, "batch_reward": 0.12344723633676767, "critic_loss": 0.32406284676492214, "actor_loss": -37.78168228912354, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.476895809173584, "step": 40000}
{"episode_reward": 103.48755932374957, "episode": 41.0, "batch_reward": 0.12393936992436648, "critic_loss": 0.39193542847037316, "actor_loss": -38.38788802337646, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.55478811264038, "step": 41000}
{"episode_reward": 201.8844210405036, "episode": 42.0, "batch_reward": 0.12328645216673613, "critic_loss": 0.36053074307739735, "actor_loss": -37.08756307220459, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.477399826049805, "step": 42000}
{"episode_reward": 64.92938881788227, "episode": 43.0, "batch_reward": 0.12741326326131822, "critic_loss": 0.3924893689751625, "actor_loss": -38.92672138595581, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.41296696662903, "step": 43000}
{"episode_reward": 520.098165046491, "episode": 44.0, "batch_reward": 0.13710490015149115, "critic_loss": 0.3844177094101906, "actor_loss": -39.81635288619995, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.454347848892212, "step": 44000}
{"episode_reward": 560.4048030986031, "episode": 45.0, "batch_reward": 0.14042520248889923, "critic_loss": 0.33857024110853673, "actor_loss": -41.34847305297851, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.474578142166138, "step": 45000}
{"episode_reward": 15.7814814963638, "episode": 46.0, "batch_reward": 0.13837001018226147, "critic_loss": 0.31510528925061226, "actor_loss": -41.9650482711792, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.451096773147583, "step": 46000}
{"episode_reward": 14.18569053144, "episode": 47.0, "batch_reward": 0.1359137877970934, "critic_loss": 0.30463807433843615, "actor_loss": -40.65464256286621, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.46160364151001, "step": 47000}
{"episode_reward": 20.520724473190825, "episode": 48.0, "batch_reward": 0.13496430283784866, "critic_loss": 0.30922467695176603, "actor_loss": -39.523456005096435, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.446796655654907, "step": 48000}
{"episode_reward": 119.07544251054168, "episode": 49.0, "batch_reward": 0.1381275039613247, "critic_loss": 0.35484843339025973, "actor_loss": -41.03779528427124, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.43325424194336, "step": 49000}
{"episode_reward": 571.3113400673656, "episode": 50.0, "batch_reward": 0.14266341173648833, "critic_loss": 0.36129359069466593, "actor_loss": -40.73968966293335, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.50749135017395, "step": 50000}
{"episode_reward": 101.54139007636343, "episode": 51.0, "batch_reward": 0.14623412907868624, "critic_loss": 0.3721977147310972, "actor_loss": -39.80524309158325, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.53713631629944, "step": 51000}
{"episode_reward": 580.4335629412923, "episode": 52.0, "batch_reward": 0.14948736975342036, "critic_loss": 0.3879285458475351, "actor_loss": -42.10635897827149, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.451733827590942, "step": 52000}
{"episode_reward": 17.23515714458294, "episode": 53.0, "batch_reward": 0.15185760018229486, "critic_loss": 0.43112337769567965, "actor_loss": -41.4058569984436, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.434657096862793, "step": 53000}
{"episode_reward": 478.9611394994363, "episode": 54.0, "batch_reward": 0.15816488106548787, "critic_loss": 0.4409097983539104, "actor_loss": -39.80592068862915, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.448187112808228, "step": 54000}
{"episode_reward": 574.2552230716516, "episode": 55.0, "batch_reward": 0.16438295812159776, "critic_loss": 0.4887467848062515, "actor_loss": -40.18173844909668, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.444694757461548, "step": 55000}
{"episode_reward": 478.8270630149868, "episode": 56.0, "batch_reward": 0.17086240092664956, "critic_loss": 0.5252052676975727, "actor_loss": -40.61263428115845, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.416284799575806, "step": 56000}
{"episode_reward": 639.1312146320047, "episode": 57.0, "batch_reward": 0.17743533580750226, "critic_loss": 0.5695509431511163, "actor_loss": -42.57783742904663, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.46091341972351, "step": 57000}
{"episode_reward": 408.53556661436704, "episode": 58.0, "batch_reward": 0.18048946680873632, "critic_loss": 0.6006804789304734, "actor_loss": -40.56705226898193, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.446209192276, "step": 58000}
{"episode_reward": 72.33108095938621, "episode": 59.0, "batch_reward": 0.17922633385658265, "critic_loss": 0.6034650329202413, "actor_loss": -43.08662859344482, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.448100566864014, "step": 59000}
{"episode_reward": 172.88792588436564, "episode": 60.0, "batch_reward": 0.1814270407035947, "critic_loss": 0.6700553784668446, "actor_loss": -43.542620220184325, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.44555377960205, "step": 60000}
{"episode_reward": 562.5186799841595, "episode": 61.0, "batch_reward": 0.18336617288738488, "critic_loss": 0.7528354392051697, "actor_loss": -41.71213498306275, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.59191870689392, "step": 61000}
{"episode_reward": 95.94932222676765, "episode": 62.0, "batch_reward": 0.1859583186134696, "critic_loss": 0.788955761551857, "actor_loss": -41.77427112197876, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.450434923171997, "step": 62000}
{"episode_reward": 517.9247032796532, "episode": 63.0, "batch_reward": 0.19108205152302982, "critic_loss": 0.8366980893611908, "actor_loss": -44.23999332046509, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.434357166290283, "step": 63000}
{"episode_reward": 639.194048610579, "episode": 64.0, "batch_reward": 0.1992431652545929, "critic_loss": 0.8665806092321873, "actor_loss": -44.27480856323242, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.45562744140625, "step": 64000}
{"episode_reward": 697.7690504175198, "episode": 65.0, "batch_reward": 0.20576155978441238, "critic_loss": 0.9118344224691391, "actor_loss": -45.04389884185791, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.490576028823853, "step": 65000}
{"episode_reward": 669.7831108367287, "episode": 66.0, "batch_reward": 0.21396036787331105, "critic_loss": 0.8931620537936688, "actor_loss": -46.40712458801269, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.437206983566284, "step": 66000}
{"episode_reward": 752.5105252295801, "episode": 67.0, "batch_reward": 0.22113433158397675, "critic_loss": 0.8900174078941345, "actor_loss": -47.3231534576416, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.43612504005432, "step": 67000}
{"episode_reward": 497.51640920100425, "episode": 68.0, "batch_reward": 0.22699966733157634, "critic_loss": 0.9107540356218815, "actor_loss": -46.7129839553833, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.463549375534058, "step": 68000}
{"episode_reward": 730.6700482881835, "episode": 69.0, "batch_reward": 0.23140127401053906, "critic_loss": 0.9787809470295906, "actor_loss": -47.586967628479, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.41315793991089, "step": 69000}
{"episode_reward": 507.74462450144966, "episode": 70.0, "batch_reward": 0.23765215311944485, "critic_loss": 1.013584121376276, "actor_loss": -48.342720581054685, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.491615533828735, "step": 70000}
{"episode_reward": 783.8035845577408, "episode": 71.0, "batch_reward": 0.24450467444956303, "critic_loss": 1.0196274303495885, "actor_loss": -48.593405052185055, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.52736020088196, "step": 71000}
{"episode_reward": 778.4502720050057, "episode": 72.0, "batch_reward": 0.24916752962768077, "critic_loss": 1.047562983840704, "actor_loss": -49.56901183319092, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.430606842041016, "step": 72000}
{"episode_reward": 19.00642332234128, "episode": 73.0, "batch_reward": 0.24851689423620701, "critic_loss": 1.0233402843773365, "actor_loss": -49.82288463592529, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.459962844848633, "step": 73000}
{"episode_reward": 813.6942053785442, "episode": 74.0, "batch_reward": 0.2572553060799837, "critic_loss": 1.0894883075356483, "actor_loss": -50.793598693847656, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.44650912284851, "step": 74000}
{"episode_reward": 703.1887634316113, "episode": 75.0, "batch_reward": 0.2649812892228365, "critic_loss": 1.147784585595131, "actor_loss": -51.11502490234375, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.455265283584595, "step": 75000}
{"episode_reward": 731.4277921462581, "episode": 76.0, "batch_reward": 0.2692129993140697, "critic_loss": 1.1530272495746612, "actor_loss": -51.47817069244385, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.4806809425354, "step": 76000}
{"episode_reward": 838.3769579324155, "episode": 77.0, "batch_reward": 0.27796663729846477, "critic_loss": 1.1970309476852417, "actor_loss": -53.48847604370117, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.442694187164307, "step": 77000}
{"episode_reward": 818.9345570783747, "episode": 78.0, "batch_reward": 0.28584703788161275, "critic_loss": 1.2249383997917176, "actor_loss": -54.77334046173096, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.439947843551636, "step": 78000}
{"episode_reward": 826.6486743531475, "episode": 79.0, "batch_reward": 0.29042823696136477, "critic_loss": 1.1647523655891419, "actor_loss": -55.03700841522217, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.455899000167847, "step": 79000}
{"episode_reward": 840.4861396088074, "episode": 80.0, "batch_reward": 0.2996777673214674, "critic_loss": 1.127961544752121, "actor_loss": -55.810160514831544, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.435905694961548, "step": 80000}
{"episode_reward": 872.643820367945, "episode": 81.0, "batch_reward": 0.3072414279580116, "critic_loss": 1.1304647156000138, "actor_loss": -57.78338481140137, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.53720211982727, "step": 81000}
{"episode_reward": 837.8226976541197, "episode": 82.0, "batch_reward": 0.3121395483613014, "critic_loss": 1.145459868311882, "actor_loss": -57.57723844909668, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.441240787506104, "step": 82000}
{"episode_reward": 715.5038114639385, "episode": 83.0, "batch_reward": 0.3181992861926556, "critic_loss": 1.1532211229205132, "actor_loss": -58.8236810760498, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.477450132369995, "step": 83000}
{"episode_reward": 870.2324051543428, "episode": 84.0, "batch_reward": 0.325387659445405, "critic_loss": 1.1203067694306375, "actor_loss": -59.82163494873047, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.444881916046143, "step": 84000}
{"episode_reward": 908.1616839989196, "episode": 85.0, "batch_reward": 0.3303790451437235, "critic_loss": 1.1039904018640518, "actor_loss": -60.02900801086426, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.40355086326599, "step": 85000}
{"episode_reward": 818.7214646126973, "episode": 86.0, "batch_reward": 0.3372129163891077, "critic_loss": 1.157292078256607, "actor_loss": -60.887467514038086, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.43238592147827, "step": 86000}
{"episode_reward": 900.5677738321177, "episode": 87.0, "batch_reward": 0.34258953224122524, "critic_loss": 1.1904937179088593, "actor_loss": -61.53301235198975, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.45893621444702, "step": 87000}
{"episode_reward": 834.348279835884, "episode": 88.0, "batch_reward": 0.34364633430540564, "critic_loss": 1.2676649532318116, "actor_loss": -62.50758502197266, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.457621335983276, "step": 88000}
{"episode_reward": 10.371718466162504, "episode": 89.0, "batch_reward": 0.34426115682721137, "critic_loss": 1.3099532753825187, "actor_loss": -63.627826164245604, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.47718858718872, "step": 89000}
{"episode_reward": 919.6349550539406, "episode": 90.0, "batch_reward": 0.34805985653400423, "critic_loss": 1.3651632949113846, "actor_loss": -64.92642806243896, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.465773582458496, "step": 90000}
{"episode_reward": 13.426908157575394, "episode": 91.0, "batch_reward": 0.3425189689397812, "critic_loss": 1.384706229686737, "actor_loss": -65.45716963195801, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.53976893424988, "step": 91000}
{"episode_reward": 11.952450392818657, "episode": 92.0, "batch_reward": 0.34169266757369043, "critic_loss": 1.3590865424275398, "actor_loss": -66.75995937347412, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.449053287506104, "step": 92000}
{"episode_reward": 719.5176660199868, "episode": 93.0, "batch_reward": 0.3418282598555088, "critic_loss": 1.3002168595194816, "actor_loss": -67.18472940826416, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.47672390937805, "step": 93000}
{"episode_reward": 17.622379191777735, "episode": 94.0, "batch_reward": 0.3398050176948309, "critic_loss": 1.2606831945180892, "actor_loss": -68.2370666885376, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.485217571258545, "step": 94000}
{"episode_reward": 9.928426927456877, "episode": 95.0, "batch_reward": 0.3367139083892107, "critic_loss": 1.2140343705415726, "actor_loss": -69.14584355163574, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.44105076789856, "step": 95000}
{"episode_reward": 15.515903925202318, "episode": 96.0, "batch_reward": 0.33207837285101416, "critic_loss": 1.1080299132466316, "actor_loss": -69.17300284576416, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.46446681022644, "step": 96000}
{"episode_reward": 15.4041755842696, "episode": 97.0, "batch_reward": 0.32685086120665074, "critic_loss": 1.018146323055029, "actor_loss": -69.2804404220581, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.481091737747192, "step": 97000}
{"episode_reward": 15.139040982769457, "episode": 98.0, "batch_reward": 0.3256065495610237, "critic_loss": 0.9388946057856082, "actor_loss": -69.41475491333007, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.476455688476562, "step": 98000}
{"episode_reward": 13.670847142026442, "episode": 99.0, "batch_reward": 0.3244972779303789, "critic_loss": 0.8627709486782551, "actor_loss": -69.24070639038086, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.49405026435852, "step": 99000}
{"episode_reward": 14.285932578017757, "episode": 100.0, "batch_reward": 0.32066841001808644, "critic_loss": 0.8120216828286648, "actor_loss": -68.90857450866699, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.46799063682556, "step": 100000}
{"episode_reward": 17.769603394939264, "episode": 101.0, "batch_reward": 0.31924232694506643, "critic_loss": 0.8063564352095127, "actor_loss": -68.57969284820557, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.522860050201416, "step": 101000}
{"episode_reward": 861.8643836802897, "episode": 102.0, "batch_reward": 0.3250096390247345, "critic_loss": 0.880164599776268, "actor_loss": -68.40515472412109, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.43105435371399, "step": 102000}
{"episode_reward": 753.5281381774803, "episode": 103.0, "batch_reward": 0.3305997715592384, "critic_loss": 0.935561499774456, "actor_loss": -68.15421282958984, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.440760374069214, "step": 103000}
{"episode_reward": 909.5534256726839, "episode": 104.0, "batch_reward": 0.3367756171673536, "critic_loss": 0.9660692812502384, "actor_loss": -67.82301455688477, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.44217085838318, "step": 104000}
{"episode_reward": 876.2555208619259, "episode": 105.0, "batch_reward": 0.3419958499968052, "critic_loss": 0.9641809628009796, "actor_loss": -67.68013401031494, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.435706615447998, "step": 105000}
{"episode_reward": 915.5538777293635, "episode": 106.0, "batch_reward": 0.3451870397925377, "critic_loss": 1.0178962794244288, "actor_loss": -67.51516760253907, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.428728342056274, "step": 106000}
{"episode_reward": 870.5467354605474, "episode": 107.0, "batch_reward": 0.3506578480452299, "critic_loss": 1.0545122970938683, "actor_loss": -68.0679389038086, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.488447904586792, "step": 107000}
{"episode_reward": 937.1518525139729, "episode": 108.0, "batch_reward": 0.35860368821024896, "critic_loss": 1.0169027784466744, "actor_loss": -68.93751879882812, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.432639598846436, "step": 108000}
{"episode_reward": 939.6691957091795, "episode": 109.0, "batch_reward": 0.36311240524053573, "critic_loss": 1.1161744381189347, "actor_loss": -69.0391441192627, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.482577800750732, "step": 109000}
{"episode_reward": 934.0374569581811, "episode": 110.0, "batch_reward": 0.36754974064230916, "critic_loss": 1.1044876026213168, "actor_loss": -69.20567646789551, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.459668159484863, "step": 110000}
{"episode_reward": 879.3661956490997, "episode": 111.0, "batch_reward": 0.3726935161352158, "critic_loss": 1.1283727281689644, "actor_loss": -69.85348841094971, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.55970048904419, "step": 111000}
{"episode_reward": 906.8902709342236, "episode": 112.0, "batch_reward": 0.37724848064780236, "critic_loss": 1.1059284746050835, "actor_loss": -69.5544602355957, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.443987131118774, "step": 112000}
{"episode_reward": 907.0332513949721, "episode": 113.0, "batch_reward": 0.38151666781306265, "critic_loss": 1.0942988781630993, "actor_loss": -69.61291343688964, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.427374362945557, "step": 113000}
{"episode_reward": 841.9216329545959, "episode": 114.0, "batch_reward": 0.3866706451624632, "critic_loss": 1.083403947621584, "actor_loss": -70.1632805557251, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.4460506439209, "step": 114000}
{"episode_reward": 945.424460478791, "episode": 115.0, "batch_reward": 0.39199449807405473, "critic_loss": 1.0673855775296688, "actor_loss": -70.26277172851563, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.436387538909912, "step": 115000}
{"episode_reward": 898.8754874617852, "episode": 116.0, "batch_reward": 0.3974580573737621, "critic_loss": 1.0505179184377194, "actor_loss": -70.61584938049316, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.42450475692749, "step": 116000}
{"episode_reward": 907.4661750083927, "episode": 117.0, "batch_reward": 0.4018270995020866, "critic_loss": 1.0443456295132636, "actor_loss": -71.04852913665772, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.465831995010376, "step": 117000}
{"episode_reward": 915.9109508182856, "episode": 118.0, "batch_reward": 0.40324251797795296, "critic_loss": 1.0430086953938007, "actor_loss": -71.09511671447754, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.460798501968384, "step": 118000}
{"episode_reward": 904.9120438733158, "episode": 119.0, "batch_reward": 0.4079387302696705, "critic_loss": 0.9762388000190259, "actor_loss": -71.39727894592285, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.451154470443726, "step": 119000}
{"episode_reward": 531.5121343140405, "episode": 120.0, "batch_reward": 0.4099806835055351, "critic_loss": 1.019624151289463, "actor_loss": -71.35239462280273, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.4752995967865, "step": 120000}
{"episode_reward": 936.0594111273866, "episode": 121.0, "batch_reward": 0.4142564914226532, "critic_loss": 1.0018594284951687, "actor_loss": -72.15360847473144, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.51811909675598, "step": 121000}
{"episode_reward": 908.9489151602396, "episode": 122.0, "batch_reward": 0.4177357025146484, "critic_loss": 1.00282818749547, "actor_loss": -72.47706268310547, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.470537424087524, "step": 122000}
{"episode_reward": 900.3124760265375, "episode": 123.0, "batch_reward": 0.4236571908593178, "critic_loss": 1.028985997647047, "actor_loss": -72.51780293273926, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.462655544281006, "step": 123000}
{"episode_reward": 808.7296861329779, "episode": 124.0, "batch_reward": 0.4258261202871799, "critic_loss": 1.0420136699676514, "actor_loss": -72.85510307312012, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.422574281692505, "step": 124000}
{"episode_reward": 915.2580980221512, "episode": 125.0, "batch_reward": 0.4290334948003292, "critic_loss": 1.0457128410339356, "actor_loss": -73.00902046203613, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.469870805740356, "step": 125000}
{"episode_reward": 912.792613978249, "episode": 126.0, "batch_reward": 0.4345599409043789, "critic_loss": 1.053582454264164, "actor_loss": -73.53120455932617, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.460115432739258, "step": 126000}
{"episode_reward": 930.8497893402925, "episode": 127.0, "batch_reward": 0.4384719234108925, "critic_loss": 1.0485380420684813, "actor_loss": -73.89326741027833, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.435555458068848, "step": 127000}
{"episode_reward": 952.9885537941857, "episode": 128.0, "batch_reward": 0.4388969826996326, "critic_loss": 1.0694730967581272, "actor_loss": -74.08343257141114, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.47475242614746, "step": 128000}
{"episode_reward": 860.3805019791314, "episode": 129.0, "batch_reward": 0.4432113179862499, "critic_loss": 1.050351071834564, "actor_loss": -74.52880256652833, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.46484136581421, "step": 129000}
{"episode_reward": 920.3495897684887, "episode": 130.0, "batch_reward": 0.44816748389601707, "critic_loss": 1.050556980997324, "actor_loss": -74.50623176574707, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.46376132965088, "step": 130000}
{"episode_reward": 947.486134160813, "episode": 131.0, "batch_reward": 0.45338818359375, "critic_loss": 1.0227854570448398, "actor_loss": -74.69589691162109, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.51327109336853, "step": 131000}
{"episode_reward": 952.3286659223538, "episode": 132.0, "batch_reward": 0.45656097057461736, "critic_loss": 0.9942171639204025, "actor_loss": -74.93087741088867, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.467187881469727, "step": 132000}
{"episode_reward": 861.1119940234424, "episode": 133.0, "batch_reward": 0.45794391256570816, "critic_loss": 1.0192027578651905, "actor_loss": -75.34981311035156, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.44090175628662, "step": 133000}
{"episode_reward": 923.6975879434656, "episode": 134.0, "batch_reward": 0.46087090745568277, "critic_loss": 0.9843686111867428, "actor_loss": -75.62255766296387, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.452640295028687, "step": 134000}
{"episode_reward": 872.7289469184094, "episode": 135.0, "batch_reward": 0.46439418134093285, "critic_loss": 0.965529151827097, "actor_loss": -75.68413684082032, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.49175786972046, "step": 135000}
{"episode_reward": 945.2081612198381, "episode": 136.0, "batch_reward": 0.46892319098114965, "critic_loss": 0.9539276553690433, "actor_loss": -76.36011740112305, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.448906898498535, "step": 136000}
{"episode_reward": 953.723896253558, "episode": 137.0, "batch_reward": 0.47199763980507853, "critic_loss": 0.9768066536188126, "actor_loss": -76.10044612121582, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.446588277816772, "step": 137000}
{"episode_reward": 946.0592168934863, "episode": 138.0, "batch_reward": 0.47522327598929404, "critic_loss": 0.897290536403656, "actor_loss": -76.54319639587402, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.44917917251587, "step": 138000}
{"episode_reward": 931.5384060857884, "episode": 139.0, "batch_reward": 0.4789820199608803, "critic_loss": 0.9276172726750374, "actor_loss": -77.05739680480957, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.424142122268677, "step": 139000}
{"episode_reward": 798.6529781801403, "episode": 140.0, "batch_reward": 0.4805140445828438, "critic_loss": 0.8999459412097931, "actor_loss": -77.23520477294922, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.493144989013672, "step": 140000}
{"episode_reward": 943.516911141975, "episode": 141.0, "batch_reward": 0.4845139611661434, "critic_loss": 0.919483966588974, "actor_loss": -77.49925212097168, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.51554298400879, "step": 141000}
{"episode_reward": 905.385140918216, "episode": 142.0, "batch_reward": 0.48430885580182076, "critic_loss": 0.8508020060360432, "actor_loss": -77.23136111450195, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.461244583129883, "step": 142000}
{"episode_reward": 925.2236369777766, "episode": 143.0, "batch_reward": 0.49003378361463545, "critic_loss": 0.8358525421619415, "actor_loss": -77.9817043762207, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.47092604637146, "step": 143000}
{"episode_reward": 911.2184953338634, "episode": 144.0, "batch_reward": 0.49359890779852866, "critic_loss": 0.8402322490811348, "actor_loss": -78.12130334472656, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.437629461288452, "step": 144000}
{"episode_reward": 911.3891877352426, "episode": 145.0, "batch_reward": 0.4979896127283573, "critic_loss": 0.8506300468146801, "actor_loss": -78.10097994995117, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.84798836708069, "step": 145000}
{"episode_reward": 907.2312821582524, "episode": 146.0, "batch_reward": 0.49738162937760355, "critic_loss": 0.8666932378411293, "actor_loss": -78.37775956726074, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.524962663650513, "step": 146000}
{"episode_reward": 888.9630916609054, "episode": 147.0, "batch_reward": 0.5005225018560886, "critic_loss": 0.9082299356460571, "actor_loss": -78.56106091308594, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.397107124328613, "step": 147000}
{"episode_reward": 888.6389219303414, "episode": 148.0, "batch_reward": 0.5043572771549225, "critic_loss": 0.8638399397730827, "actor_loss": -78.77104972839355, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.407684564590454, "step": 148000}
{"episode_reward": 942.0618416591128, "episode": 149.0, "batch_reward": 0.5077989110052585, "critic_loss": 0.8368272504806519, "actor_loss": -78.72436077880859, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.826321363449097, "step": 149000}
{"episode_reward": 936.5670126397489, "episode": 150.0, "batch_reward": 0.5127299757003784, "critic_loss": 0.8503887310922146, "actor_loss": -79.0818420715332, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "step": 150000}
