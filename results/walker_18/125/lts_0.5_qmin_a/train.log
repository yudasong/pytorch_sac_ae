{"episode_reward": 0.0, "episode": 1.0, "duration": 21.35257315635681, "step": 1000}
{"episode_reward": 28.177075776326152, "episode": 2.0, "duration": 1.8588283061981201, "step": 2000}
{"episode_reward": 69.84046218736019, "episode": 3.0, "batch_reward": 0.04672249898726879, "critic_loss": 0.010239091688733614, "actor_loss": -40.45759208876343, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499180007, "duration": 60.57595205307007, "step": 3000}
{"episode_reward": 10.348843487115703, "episode": 4.0, "batch_reward": 0.03279080068692565, "critic_loss": 0.002888717211142648, "actor_loss": -41.320240586280825, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.28461742401123, "step": 4000}
{"episode_reward": 10.112918666494735, "episode": 5.0, "batch_reward": 0.028249286422505973, "critic_loss": 0.0025527477611904034, "actor_loss": -35.88792572510243, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.286690711975098, "step": 5000}
{"episode_reward": 12.995673676503321, "episode": 6.0, "batch_reward": 0.03102939946576953, "critic_loss": 0.006615293643786572, "actor_loss": -37.83854896020889, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.258678674697876, "step": 6000}
{"episode_reward": 59.34333552670197, "episode": 7.0, "batch_reward": 0.033234618285670876, "critic_loss": 0.008761529491399415, "actor_loss": -40.31263788282871, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.248339891433716, "step": 7000}
{"episode_reward": 49.31386319331982, "episode": 8.0, "batch_reward": 0.03314241570048034, "critic_loss": 0.022211936973268166, "actor_loss": -39.72577760839462, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.22773814201355, "step": 8000}
{"episode_reward": 15.589002954941305, "episode": 9.0, "batch_reward": 0.033144549733027814, "critic_loss": 0.011668762331362813, "actor_loss": -39.52123071881384, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.225231647491455, "step": 9000}
{"episode_reward": 52.84793271329819, "episode": 10.0, "batch_reward": 0.034117233728989955, "critic_loss": 0.030154924518894403, "actor_loss": -38.10599165138602, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.218331575393677, "step": 10000}
{"episode_reward": 26.239092743504813, "episode": 11.0, "batch_reward": 0.03288834773004055, "critic_loss": 0.02587727961456403, "actor_loss": -40.70473087500036, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.37057018280029, "step": 11000}
{"episode_reward": 14.457374999706255, "episode": 12.0, "batch_reward": 0.033136257952079175, "critic_loss": 0.015297013945411891, "actor_loss": -38.38393060651421, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.239895343780518, "step": 12000}
{"episode_reward": 69.68289339094807, "episode": 13.0, "batch_reward": 0.03669429668597877, "critic_loss": 0.03396780906803906, "actor_loss": -37.622672719568016, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.23465847969055, "step": 13000}
{"episode_reward": 103.39516285805296, "episode": 14.0, "batch_reward": 0.042958012714982036, "critic_loss": 0.15145446296641604, "actor_loss": -36.10489201900363, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.25666356086731, "step": 14000}
{"episode_reward": 130.76738167219742, "episode": 15.0, "batch_reward": 0.04957506032660604, "critic_loss": 0.2146240894049406, "actor_loss": -42.20022600674629, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.212493419647217, "step": 15000}
{"episode_reward": 98.65410021878805, "episode": 16.0, "batch_reward": 0.05231328047066927, "critic_loss": 0.22215306548029184, "actor_loss": -41.975070680379865, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.236968278884888, "step": 16000}
{"episode_reward": 110.09922551660317, "episode": 17.0, "batch_reward": 0.05483943969756365, "critic_loss": 0.1932324308939278, "actor_loss": -39.24647144699097, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.274240732192993, "step": 17000}
{"episode_reward": 47.979402544043275, "episode": 18.0, "batch_reward": 0.05445447159931063, "critic_loss": 0.19098359083384275, "actor_loss": -38.1925458316803, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.226701498031616, "step": 18000}
{"episode_reward": 75.5183024567541, "episode": 19.0, "batch_reward": 0.05534522775933146, "critic_loss": 0.2030829726010561, "actor_loss": -40.16394012355804, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.24599599838257, "step": 19000}
{"episode_reward": 69.65837959931389, "episode": 20.0, "batch_reward": 0.05554766065999866, "critic_loss": 0.20193934655934573, "actor_loss": -41.53773865795136, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.260000705718994, "step": 20000}
{"episode_reward": 66.07909129584073, "episode": 21.0, "batch_reward": 0.05663719714805484, "critic_loss": 0.21648999314010142, "actor_loss": -43.115392820358274, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.213847398757935, "step": 21000}
{"episode_reward": 65.90519798717891, "episode": 22.0, "batch_reward": 0.057429388977587224, "critic_loss": 0.22677900898456574, "actor_loss": -41.183297769546506, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.250808715820312, "step": 22000}
{"episode_reward": 86.29777100033581, "episode": 23.0, "batch_reward": 0.0582996208705008, "critic_loss": 0.20073340006917714, "actor_loss": -40.53416971492767, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.255951166152954, "step": 23000}
{"episode_reward": 66.67677077565669, "episode": 24.0, "batch_reward": 0.05748164261505008, "critic_loss": 0.20219254928454758, "actor_loss": -43.08296307182312, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.26510787010193, "step": 24000}
{"episode_reward": 43.9296165962143, "episode": 25.0, "batch_reward": 0.060215371306985614, "critic_loss": 0.25025485699623823, "actor_loss": -40.664388703346255, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.29250431060791, "step": 25000}
{"episode_reward": 189.00967669400404, "episode": 26.0, "batch_reward": 0.06308772624656558, "critic_loss": 0.2714472093358636, "actor_loss": -40.70725229167938, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.2581627368927, "step": 26000}
{"episode_reward": 67.00288950587273, "episode": 27.0, "batch_reward": 0.0644421802982688, "critic_loss": 0.28620911280065775, "actor_loss": -41.06566164779663, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.28181266784668, "step": 27000}
{"episode_reward": 115.23922446449966, "episode": 28.0, "batch_reward": 0.06554981326684356, "critic_loss": 0.16597927533090115, "actor_loss": -40.802286699295045, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.304073333740234, "step": 28000}
{"episode_reward": 74.7423490922838, "episode": 29.0, "batch_reward": 0.06559187205135822, "critic_loss": 0.1329221995137632, "actor_loss": -43.28460050010681, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.235975742340088, "step": 29000}
{"episode_reward": 64.7452559554265, "episode": 30.0, "batch_reward": 0.06568984483927488, "critic_loss": 0.11468637282401323, "actor_loss": -42.937405689239505, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.256986141204834, "step": 30000}
{"episode_reward": 88.75922221045136, "episode": 31.0, "batch_reward": 0.06560470718890428, "critic_loss": 0.1107088030539453, "actor_loss": -43.85528763961792, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.25693392753601, "step": 31000}
{"episode_reward": 44.4553533031048, "episode": 32.0, "batch_reward": 0.0665119221881032, "critic_loss": 0.10755685343965889, "actor_loss": -43.76743601036072, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.263312339782715, "step": 32000}
{"episode_reward": 98.02743900211377, "episode": 33.0, "batch_reward": 0.06607767368853092, "critic_loss": 0.08785012251883745, "actor_loss": -43.20231007957459, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.288520336151123, "step": 33000}
{"episode_reward": 21.79073507374065, "episode": 34.0, "batch_reward": 0.0649253510311246, "critic_loss": 0.06758326618559658, "actor_loss": -39.32656525802612, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.266213178634644, "step": 34000}
{"episode_reward": 29.9573108977565, "episode": 35.0, "batch_reward": 0.06332696027681231, "critic_loss": 0.05945666582509875, "actor_loss": -43.28003097915649, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.263593196868896, "step": 35000}
{"episode_reward": 19.79928583055982, "episode": 36.0, "batch_reward": 0.06290726508945227, "critic_loss": 0.051959479566663504, "actor_loss": -40.860009410858154, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.26211714744568, "step": 36000}
{"episode_reward": 39.5165998487122, "episode": 37.0, "batch_reward": 0.06289756687730551, "critic_loss": 0.05463463416323066, "actor_loss": -40.37387540245056, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.267963886260986, "step": 37000}
{"episode_reward": 92.13712901738293, "episode": 38.0, "batch_reward": 0.06517186148464679, "critic_loss": 0.056908801639452576, "actor_loss": -42.316777591705325, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.25700044631958, "step": 38000}
{"episode_reward": 184.24500769486187, "episode": 39.0, "batch_reward": 0.0665878850221634, "critic_loss": 0.05993299797922373, "actor_loss": -44.6490605506897, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.26444172859192, "step": 39000}
{"episode_reward": 63.12271982951882, "episode": 40.0, "batch_reward": 0.0674496114514768, "critic_loss": 0.060765704376623035, "actor_loss": -43.929160041809084, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.21690797805786, "step": 40000}
{"episode_reward": 146.41788533715948, "episode": 41.0, "batch_reward": 0.0711085860952735, "critic_loss": 0.07058928569592536, "actor_loss": -43.51397938346863, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.259713888168335, "step": 41000}
{"episode_reward": 309.0255632070886, "episode": 42.0, "batch_reward": 0.07462268671393395, "critic_loss": 0.07410137445852161, "actor_loss": -42.025709497451786, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.24393916130066, "step": 42000}
{"episode_reward": 93.92404153855696, "episode": 43.0, "batch_reward": 0.07485537261515855, "critic_loss": 0.09263587860949338, "actor_loss": -42.49052833366394, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.25629210472107, "step": 43000}
{"episode_reward": 80.24733984524937, "episode": 44.0, "batch_reward": 0.07496775669977068, "critic_loss": 0.10027788423001766, "actor_loss": -41.86869812583923, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.280503273010254, "step": 44000}
{"episode_reward": 103.32884363650025, "episode": 45.0, "batch_reward": 0.0762551428116858, "critic_loss": 0.11386103872954846, "actor_loss": -44.038582107543945, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.196211099624634, "step": 45000}
{"episode_reward": 137.93834202360878, "episode": 46.0, "batch_reward": 0.07604819762334228, "critic_loss": 0.12456078889220953, "actor_loss": -43.90155150699616, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.27003026008606, "step": 46000}
{"episode_reward": 15.411770145034268, "episode": 47.0, "batch_reward": 0.07621127215400338, "critic_loss": 0.13520489951595663, "actor_loss": -42.59387996482849, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.29456639289856, "step": 47000}
{"episode_reward": 155.69997955397483, "episode": 48.0, "batch_reward": 0.07876616994291544, "critic_loss": 0.16272440107539296, "actor_loss": -41.342598768234254, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.278095483779907, "step": 48000}
{"episode_reward": 192.09871669313074, "episode": 49.0, "batch_reward": 0.0821357164606452, "critic_loss": 0.18281946266442536, "actor_loss": -42.74258521270752, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.25008511543274, "step": 49000}
{"episode_reward": 316.93813418595005, "episode": 50.0, "batch_reward": 0.08580857202783226, "critic_loss": 0.21449664306640626, "actor_loss": -43.38424607086181, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.28553795814514, "step": 50000}
{"episode_reward": 178.646544226161, "episode": 51.0, "batch_reward": 0.08897893092036248, "critic_loss": 0.22684263414144515, "actor_loss": -41.068524766921996, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.27452564239502, "step": 51000}
{"episode_reward": 402.06915651585336, "episode": 52.0, "batch_reward": 0.09384805810451508, "critic_loss": 0.23947937463968993, "actor_loss": -44.769725793838504, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.23412251472473, "step": 52000}
{"episode_reward": 325.0007726700887, "episode": 53.0, "batch_reward": 0.09965422198176384, "critic_loss": 0.2596416511386633, "actor_loss": -43.82283142662048, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.230740308761597, "step": 53000}
{"episode_reward": 348.75350898150435, "episode": 54.0, "batch_reward": 0.10124607750028372, "critic_loss": 0.2770132141858339, "actor_loss": -44.239494119644164, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.252938270568848, "step": 54000}
{"episode_reward": 65.0675362683917, "episode": 55.0, "batch_reward": 0.10075607811659575, "critic_loss": 0.29358385092020034, "actor_loss": -42.26250121498108, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.265146732330322, "step": 55000}
{"episode_reward": 73.91088862549572, "episode": 56.0, "batch_reward": 0.10302833820879459, "critic_loss": 0.3057256851494312, "actor_loss": -45.220128591537474, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.226255655288696, "step": 56000}
{"episode_reward": 268.78517461057925, "episode": 57.0, "batch_reward": 0.10347359776496887, "critic_loss": 0.34049973241984843, "actor_loss": -45.74687611579895, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.25900626182556, "step": 57000}
{"episode_reward": 92.99033542125723, "episode": 58.0, "batch_reward": 0.10348307229578495, "critic_loss": 0.3286802527531981, "actor_loss": -42.36477857589722, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.28460955619812, "step": 58000}
{"episode_reward": 95.18959207877312, "episode": 59.0, "batch_reward": 0.10535813369601965, "critic_loss": 0.34377047050744297, "actor_loss": -43.56221759796143, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.218350410461426, "step": 59000}
{"episode_reward": 345.7370165856584, "episode": 60.0, "batch_reward": 0.10873760454356671, "critic_loss": 0.3817304684370756, "actor_loss": -48.17584144210815, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.236905097961426, "step": 60000}
{"episode_reward": 216.615266268619, "episode": 61.0, "batch_reward": 0.11160312552005053, "critic_loss": 0.3553259929269552, "actor_loss": -44.03632872581482, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.366137742996216, "step": 61000}
{"episode_reward": 416.22071585253303, "episode": 62.0, "batch_reward": 0.11514521268010139, "critic_loss": 0.3765776812285185, "actor_loss": -43.615164846420285, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.270495414733887, "step": 62000}
{"episode_reward": 285.67669511302154, "episode": 63.0, "batch_reward": 0.11767903097718954, "critic_loss": 0.3548886033445597, "actor_loss": -46.165672269821165, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.25595259666443, "step": 63000}
{"episode_reward": 377.1826663998559, "episode": 64.0, "batch_reward": 0.12301799409091473, "critic_loss": 0.36760939700901507, "actor_loss": -45.35755826759338, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.246710538864136, "step": 64000}
{"episode_reward": 430.0499649227309, "episode": 65.0, "batch_reward": 0.1255608341023326, "critic_loss": 0.39121258744597437, "actor_loss": -46.46457618141174, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.294543981552124, "step": 65000}
{"episode_reward": 91.95897168793546, "episode": 66.0, "batch_reward": 0.1266910252198577, "critic_loss": 0.4086299434602261, "actor_loss": -46.84671416473389, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.24900484085083, "step": 66000}
{"episode_reward": 389.3962239174028, "episode": 67.0, "batch_reward": 0.1300393511876464, "critic_loss": 0.421121856674552, "actor_loss": -49.3522601852417, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.234968900680542, "step": 67000}
{"episode_reward": 304.5255028336251, "episode": 68.0, "batch_reward": 0.13433539494872093, "critic_loss": 0.41680392777919767, "actor_loss": -44.9269848613739, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.262004613876343, "step": 68000}
{"episode_reward": 389.6839706400365, "episode": 69.0, "batch_reward": 0.13701807934045793, "critic_loss": 0.41651693001389506, "actor_loss": -47.770147108078, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.23789691925049, "step": 69000}
{"episode_reward": 260.7242763733887, "episode": 70.0, "batch_reward": 0.13986475863307715, "critic_loss": 0.4103429262936115, "actor_loss": -48.578205219268796, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.235209226608276, "step": 70000}
{"episode_reward": 466.3382917757829, "episode": 71.0, "batch_reward": 0.1426991218626499, "critic_loss": 0.4377894995063543, "actor_loss": -45.82056042861939, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.34245276451111, "step": 71000}
{"episode_reward": 387.0396119367867, "episode": 72.0, "batch_reward": 0.1473281866684556, "critic_loss": 0.4545259495228529, "actor_loss": -47.052309829711916, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.253849983215332, "step": 72000}
{"episode_reward": 275.85141444236945, "episode": 73.0, "batch_reward": 0.14851663614809513, "critic_loss": 0.4905584958046675, "actor_loss": -47.322700370788574, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.254998922348022, "step": 73000}
{"episode_reward": 436.5843026690206, "episode": 74.0, "batch_reward": 0.15150356958061456, "critic_loss": 0.4993232931047678, "actor_loss": -49.01447286224365, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.26184868812561, "step": 74000}
{"episode_reward": 129.2604289589638, "episode": 75.0, "batch_reward": 0.1529905023947358, "critic_loss": 0.5293121672719717, "actor_loss": -48.48620966148376, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.247949838638306, "step": 75000}
{"episode_reward": 463.9823339477148, "episode": 76.0, "batch_reward": 0.15712640696763994, "critic_loss": 0.5656474977880717, "actor_loss": -48.44691267967224, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.281742334365845, "step": 76000}
{"episode_reward": 488.2863429893456, "episode": 77.0, "batch_reward": 0.1615724601149559, "critic_loss": 0.5894258207082749, "actor_loss": -48.67636143684387, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.254515409469604, "step": 77000}
{"episode_reward": 312.0162551498604, "episode": 78.0, "batch_reward": 0.1635928254723549, "critic_loss": 0.5904262070059776, "actor_loss": -50.32175238800049, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.25235104560852, "step": 78000}
{"episode_reward": 438.9880358499701, "episode": 79.0, "batch_reward": 0.16689594666659832, "critic_loss": 0.6012148331552744, "actor_loss": -47.344305267333986, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.243079900741577, "step": 79000}
{"episode_reward": 372.38499917029765, "episode": 80.0, "batch_reward": 0.16865541169792414, "critic_loss": 0.6359915165007114, "actor_loss": -48.13006351089478, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.26702070236206, "step": 80000}
{"episode_reward": 385.22621414227234, "episode": 81.0, "batch_reward": 0.17249271102249622, "critic_loss": 0.5920745377838612, "actor_loss": -49.62226047897339, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.299461126327515, "step": 81000}
{"episode_reward": 509.5252372914409, "episode": 82.0, "batch_reward": 0.1769590683504939, "critic_loss": 0.6025338180065155, "actor_loss": -52.14099850845337, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.251741886138916, "step": 82000}
{"episode_reward": 491.51769425514505, "episode": 83.0, "batch_reward": 0.18092284521460533, "critic_loss": 0.5600314809381962, "actor_loss": -50.509440097808834, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.257738828659058, "step": 83000}
{"episode_reward": 522.310432911054, "episode": 84.0, "batch_reward": 0.1823483280017972, "critic_loss": 0.49108482302725315, "actor_loss": -50.83067783355713, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.27218270301819, "step": 84000}
{"episode_reward": 119.96733550351924, "episode": 85.0, "batch_reward": 0.18244626961648464, "critic_loss": 0.47645344264805317, "actor_loss": -51.87178242492676, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.274543285369873, "step": 85000}
{"episode_reward": 241.16328083085438, "episode": 86.0, "batch_reward": 0.18239540272951127, "critic_loss": 0.48600160858035085, "actor_loss": -50.23543248748779, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.256915807724, "step": 86000}
{"episode_reward": 347.55534412046046, "episode": 87.0, "batch_reward": 0.18551576094329358, "critic_loss": 0.4833456512838602, "actor_loss": -50.61151860046387, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.23708963394165, "step": 87000}
{"episode_reward": 494.93848349820183, "episode": 88.0, "batch_reward": 0.18972691608965397, "critic_loss": 0.4775985556393862, "actor_loss": -49.003395885467526, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.28622555732727, "step": 88000}
{"episode_reward": 486.8201074689324, "episode": 89.0, "batch_reward": 0.19352995175123214, "critic_loss": 0.4847257586121559, "actor_loss": -50.516015312194824, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.267584800720215, "step": 89000}
{"episode_reward": 562.0957129771562, "episode": 90.0, "batch_reward": 0.1948264485001564, "critic_loss": 0.5221579238474369, "actor_loss": -52.12141663360596, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.281190395355225, "step": 90000}
{"episode_reward": 136.07774183700428, "episode": 91.0, "batch_reward": 0.19716750159859658, "critic_loss": 0.5569749495089054, "actor_loss": -50.86540187072754, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.29972529411316, "step": 91000}
{"episode_reward": 443.647149445882, "episode": 92.0, "batch_reward": 0.19823638820648193, "critic_loss": 0.612644004881382, "actor_loss": -50.793374614715574, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.21637725830078, "step": 92000}
{"episode_reward": 312.8712049389628, "episode": 93.0, "batch_reward": 0.19961337147653102, "critic_loss": 0.6406674226522445, "actor_loss": -50.729422050476074, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.26511812210083, "step": 93000}
{"episode_reward": 310.7889391734601, "episode": 94.0, "batch_reward": 0.2013388211429119, "critic_loss": 0.6600997996032238, "actor_loss": -50.02586972427368, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.27617597579956, "step": 94000}
{"episode_reward": 454.34746072031163, "episode": 95.0, "batch_reward": 0.20483376598358155, "critic_loss": 0.6797666029632091, "actor_loss": -53.01153105163574, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.218714237213135, "step": 95000}
{"episode_reward": 387.64477981874865, "episode": 96.0, "batch_reward": 0.20662901778519155, "critic_loss": 0.7001490354239941, "actor_loss": -51.71875399398804, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.240999698638916, "step": 96000}
{"episode_reward": 543.566586444444, "episode": 97.0, "batch_reward": 0.20858641715347767, "critic_loss": 0.7550996976494789, "actor_loss": -52.466290771484374, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.260892391204834, "step": 97000}
{"episode_reward": 441.6718263202255, "episode": 98.0, "batch_reward": 0.21126220382750036, "critic_loss": 0.7256796145141124, "actor_loss": -52.08158954620362, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.267998218536377, "step": 98000}
{"episode_reward": 470.58279590093923, "episode": 99.0, "batch_reward": 0.21555040153861046, "critic_loss": 0.7543877303302288, "actor_loss": -52.419644580841066, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.277089834213257, "step": 99000}
{"episode_reward": 621.6795826362588, "episode": 100.0, "batch_reward": 0.21930275982618333, "critic_loss": 0.7720655645728112, "actor_loss": -51.66494525146484, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.297388076782227, "step": 100000}
{"episode_reward": 615.4459291052249, "episode": 101.0, "batch_reward": 0.22202254223823548, "critic_loss": 0.7746898612976074, "actor_loss": -53.91520492935181, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.27616095542908, "step": 101000}
{"episode_reward": 150.59344920166342, "episode": 102.0, "batch_reward": 0.22078075776994227, "critic_loss": 0.7657197948694229, "actor_loss": -53.19307611083985, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.27770733833313, "step": 102000}
{"episode_reward": 471.07948590851396, "episode": 103.0, "batch_reward": 0.2225129566192627, "critic_loss": 0.8001059381961823, "actor_loss": -53.64903904342651, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.24031949043274, "step": 103000}
{"episode_reward": 424.97073683727615, "episode": 104.0, "batch_reward": 0.22673494783043863, "critic_loss": 0.8071439714133739, "actor_loss": -53.4731342010498, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.252384185791016, "step": 104000}
{"episode_reward": 524.5030787757295, "episode": 105.0, "batch_reward": 0.22904882469773294, "critic_loss": 0.7837854636013508, "actor_loss": -53.7425490989685, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.27245044708252, "step": 105000}
{"episode_reward": 566.9253087742612, "episode": 106.0, "batch_reward": 0.2333488394320011, "critic_loss": 0.7969569744765759, "actor_loss": -52.674538665771486, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.24201536178589, "step": 106000}
{"episode_reward": 563.2446070929309, "episode": 107.0, "batch_reward": 0.23701460264623164, "critic_loss": 0.8188762464225292, "actor_loss": -53.96952382659912, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.265921354293823, "step": 107000}
{"episode_reward": 588.9711551253916, "episode": 108.0, "batch_reward": 0.23782894936203958, "critic_loss": 0.847029981970787, "actor_loss": -54.54231429672241, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.303100109100342, "step": 108000}
{"episode_reward": 447.06125834470873, "episode": 109.0, "batch_reward": 0.24196590247750283, "critic_loss": 0.8662047257423401, "actor_loss": -55.06547093963623, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.233562231063843, "step": 109000}
{"episode_reward": 656.4171643137661, "episode": 110.0, "batch_reward": 0.2455872927159071, "critic_loss": 0.8909481833577156, "actor_loss": -56.304314735412596, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.272341012954712, "step": 110000}
{"episode_reward": 628.2994180712857, "episode": 111.0, "batch_reward": 0.24768881921470165, "critic_loss": 0.9061961530447006, "actor_loss": -57.02760333633423, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.27928566932678, "step": 111000}
{"episode_reward": 658.0070924527879, "episode": 112.0, "batch_reward": 0.25295316517353056, "critic_loss": 1.0002391346693038, "actor_loss": -56.1623814163208, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.64161252975464, "step": 112000}
{"episode_reward": 644.6287190740258, "episode": 113.0, "batch_reward": 0.2546977563202381, "critic_loss": 1.0160702327489852, "actor_loss": -56.117560222625734, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.632291555404663, "step": 113000}
{"episode_reward": 436.76810032521587, "episode": 114.0, "batch_reward": 0.25824107940495017, "critic_loss": 1.0974167225956917, "actor_loss": -58.9391591796875, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.249358654022217, "step": 114000}
{"episode_reward": 652.7986252917468, "episode": 115.0, "batch_reward": 0.26115991900861263, "critic_loss": 1.1653907139897346, "actor_loss": -58.043584915161134, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.40642023086548, "step": 115000}
{"episode_reward": 589.7890096129859, "episode": 116.0, "batch_reward": 0.2640933933109045, "critic_loss": 1.2601926364302636, "actor_loss": -59.31523677062988, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.311803817749023, "step": 116000}
{"episode_reward": 420.83093749270904, "episode": 117.0, "batch_reward": 0.26479284891486166, "critic_loss": 1.3661365815401076, "actor_loss": -58.277047080993654, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.266706466674805, "step": 117000}
{"episode_reward": 256.2415941431798, "episode": 118.0, "batch_reward": 0.26555071672797204, "critic_loss": 1.4102505779862404, "actor_loss": -59.86852390289307, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.288890838623047, "step": 118000}
{"episode_reward": 680.819560701371, "episode": 119.0, "batch_reward": 0.2687351574599743, "critic_loss": 1.4915367327928544, "actor_loss": -60.29227280426026, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.318202257156372, "step": 119000}
{"episode_reward": 654.4614801408549, "episode": 120.0, "batch_reward": 0.2706008616387844, "critic_loss": 1.453485343515873, "actor_loss": -59.321578224182126, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.31518006324768, "step": 120000}
{"episode_reward": 688.5423622125104, "episode": 121.0, "batch_reward": 0.2765726634711027, "critic_loss": 1.3995471566915512, "actor_loss": -60.432830749511716, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.76716732978821, "step": 121000}
{"episode_reward": 713.4997565363818, "episode": 122.0, "batch_reward": 0.2787973870038986, "critic_loss": 1.415021506547928, "actor_loss": -61.59417338562012, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.438862562179565, "step": 122000}
{"episode_reward": 694.0541460046586, "episode": 123.0, "batch_reward": 0.2833136124312878, "critic_loss": 1.3841782802343368, "actor_loss": -60.1806678314209, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.31024932861328, "step": 123000}
{"episode_reward": 686.3894281943305, "episode": 124.0, "batch_reward": 0.2848480199128389, "critic_loss": 1.2400717520713807, "actor_loss": -61.72776162719727, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.83881664276123, "step": 124000}
{"episode_reward": 683.3572155104049, "episode": 125.0, "batch_reward": 0.28936424921452997, "critic_loss": 1.1704481524825097, "actor_loss": -59.961184692382815, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.996830701828003, "step": 125000}
{"episode_reward": 709.2711203051044, "episode": 126.0, "batch_reward": 0.29250389961898327, "critic_loss": 1.1139024406671525, "actor_loss": -62.00019329071045, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.258742094039917, "step": 126000}
{"episode_reward": 732.675176420832, "episode": 127.0, "batch_reward": 0.2943776177167892, "critic_loss": 1.0753273390829563, "actor_loss": -62.223627822875976, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.4271879196167, "step": 127000}
{"episode_reward": 711.9612246003541, "episode": 128.0, "batch_reward": 0.296877451390028, "critic_loss": 1.0833782304227353, "actor_loss": -62.0751216506958, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.447895765304565, "step": 128000}
{"episode_reward": 20.544261130464328, "episode": 129.0, "batch_reward": 0.296961544200778, "critic_loss": 1.0507300115823746, "actor_loss": -62.4293743057251, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.864846229553223, "step": 129000}
{"episode_reward": 748.317435888932, "episode": 130.0, "batch_reward": 0.300268802896142, "critic_loss": 1.0213757770061493, "actor_loss": -62.69071280670166, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.539600610733032, "step": 130000}
{"episode_reward": 596.075571325594, "episode": 131.0, "batch_reward": 0.3029825883805752, "critic_loss": 0.957131793320179, "actor_loss": -62.87525577545166, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.960880279541016, "step": 131000}
{"episode_reward": 701.9101611111814, "episode": 132.0, "batch_reward": 0.30558598300814627, "critic_loss": 0.9438708875477314, "actor_loss": -62.04461248016357, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.932337999343872, "step": 132000}
{"episode_reward": 648.6429519862088, "episode": 133.0, "batch_reward": 0.3069525623470545, "critic_loss": 0.9276366834640503, "actor_loss": -62.80156289672851, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.399155139923096, "step": 133000}
{"episode_reward": 639.1420400751251, "episode": 134.0, "batch_reward": 0.3065899543315172, "critic_loss": 0.9262185400128364, "actor_loss": -63.47547721862793, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.292770624160767, "step": 134000}
{"episode_reward": 16.270240481565892, "episode": 135.0, "batch_reward": 0.3086594923585653, "critic_loss": 0.9254054316580296, "actor_loss": -62.55793620300293, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.609928607940674, "step": 135000}
{"episode_reward": 776.7184617837914, "episode": 136.0, "batch_reward": 0.31411523108184336, "critic_loss": 0.9583190119564533, "actor_loss": -63.46146980285644, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.159976959228516, "step": 136000}
{"episode_reward": 765.020694700112, "episode": 137.0, "batch_reward": 0.3126269427537918, "critic_loss": 0.9862953040599823, "actor_loss": -62.45627514648437, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.418755531311035, "step": 137000}
{"episode_reward": 22.890776523390166, "episode": 138.0, "batch_reward": 0.3136400469392538, "critic_loss": 1.035281791329384, "actor_loss": -61.570491539001466, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.80778455734253, "step": 138000}
{"episode_reward": 751.7215461768394, "episode": 139.0, "batch_reward": 0.3163788510411978, "critic_loss": 1.0283930349051953, "actor_loss": -61.960053253173825, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.972506761550903, "step": 139000}
{"episode_reward": 715.1352182810219, "episode": 140.0, "batch_reward": 0.3162570820748806, "critic_loss": 1.0321054508388043, "actor_loss": -61.60811664581299, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.547855377197266, "step": 140000}
{"episode_reward": 701.9490735403485, "episode": 141.0, "batch_reward": 0.3188812878727913, "critic_loss": 1.0136667138040065, "actor_loss": -61.14677089691162, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.67732810974121, "step": 141000}
{"episode_reward": 14.513652714222724, "episode": 142.0, "batch_reward": 0.31723334337770936, "critic_loss": 1.0478445811867714, "actor_loss": -63.06063368225097, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.90708613395691, "step": 142000}
{"episode_reward": 787.1710684271296, "episode": 143.0, "batch_reward": 0.3223816694021225, "critic_loss": 1.0710954678058624, "actor_loss": -62.3508204574585, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.464032888412476, "step": 143000}
{"episode_reward": 776.5745464182315, "episode": 144.0, "batch_reward": 0.32725831377506254, "critic_loss": 1.066364111930132, "actor_loss": -63.23454589080811, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.32479190826416, "step": 144000}
{"episode_reward": 667.8737903216758, "episode": 145.0, "batch_reward": 0.3297188194692135, "critic_loss": 1.0615427681207656, "actor_loss": -62.79922891998291, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.41768527030945, "step": 145000}
{"episode_reward": 777.7656639659683, "episode": 146.0, "batch_reward": 0.3315335044413805, "critic_loss": 1.1004650955796242, "actor_loss": -64.14065590667725, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.828025579452515, "step": 146000}
{"episode_reward": 710.4675452695855, "episode": 147.0, "batch_reward": 0.3346249971985817, "critic_loss": 1.1457583522200585, "actor_loss": -63.81072708129883, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.06219172477722, "step": 147000}
{"episode_reward": 720.1847168582543, "episode": 148.0, "batch_reward": 0.33699500001966953, "critic_loss": 1.1574905675649643, "actor_loss": -64.0378367843628, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.7763774394989, "step": 148000}
{"episode_reward": 775.6118705577173, "episode": 149.0, "batch_reward": 0.3389953896701336, "critic_loss": 1.1885152398347854, "actor_loss": -64.29808646392823, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.432769775390625, "step": 149000}
{"episode_reward": 715.8997623360625, "episode": 150.0, "batch_reward": 0.3441200640201569, "critic_loss": 1.2082468808293343, "actor_loss": -64.83213383483887, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "step": 150000}
