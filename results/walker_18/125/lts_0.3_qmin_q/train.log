{"episode_reward": 0.0, "episode": 1.0, "duration": 21.75075936317444, "step": 1000}
{"episode_reward": 28.177075776326152, "episode": 2.0, "duration": 1.934800386428833, "step": 2000}
{"episode_reward": 69.84046218736019, "episode": 3.0, "batch_reward": 0.04894824736329586, "critic_loss": 0.1383065796963729, "actor_loss": -76.67794538774983, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499180007, "duration": 63.21533703804016, "step": 3000}
{"episode_reward": 67.91384883418299, "episode": 4.0, "batch_reward": 0.058751548264175654, "critic_loss": 0.19761473444849254, "actor_loss": -72.05834539794922, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.916916131973267, "step": 4000}
{"episode_reward": 76.12904240943419, "episode": 5.0, "batch_reward": 0.061054973874241115, "critic_loss": 0.12217329170182348, "actor_loss": -70.67608515930176, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.259268522262573, "step": 5000}
{"episode_reward": 53.25583415183238, "episode": 6.0, "batch_reward": 0.05681688172742724, "critic_loss": 0.13031641597300767, "actor_loss": -69.4737571105957, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.46367335319519, "step": 6000}
{"episode_reward": 33.76499373817485, "episode": 7.0, "batch_reward": 0.05621702066063881, "critic_loss": 0.1099324685074389, "actor_loss": -68.14552215576173, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.95978879928589, "step": 7000}
{"episode_reward": 61.51464404418433, "episode": 8.0, "batch_reward": 0.05544326139241457, "critic_loss": 0.10609474766254424, "actor_loss": -66.76695733642578, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.193960189819336, "step": 8000}
{"episode_reward": 39.75922649619556, "episode": 9.0, "batch_reward": 0.05640825253725052, "critic_loss": 0.1455012916252017, "actor_loss": -66.33582367706299, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.469741821289062, "step": 9000}
{"episode_reward": 115.47687410764385, "episode": 10.0, "batch_reward": 0.060782254870980976, "critic_loss": 0.1521186786815524, "actor_loss": -64.24780415344239, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.706167936325073, "step": 10000}
{"episode_reward": 45.57581110732098, "episode": 11.0, "batch_reward": 0.05951238701120019, "critic_loss": 0.13639248334616422, "actor_loss": -64.09539375305175, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.822803258895874, "step": 11000}
{"episode_reward": 67.11560775950474, "episode": 12.0, "batch_reward": 0.058162476047873495, "critic_loss": 0.12569263201206923, "actor_loss": -62.82101190948487, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.495176315307617, "step": 12000}
{"episode_reward": 24.621087409273077, "episode": 13.0, "batch_reward": 0.05751866368204355, "critic_loss": 0.12860092205181717, "actor_loss": -61.831752395629884, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.665324449539185, "step": 13000}
{"episode_reward": 63.00905974224887, "episode": 14.0, "batch_reward": 0.057755939640104774, "critic_loss": 0.11517851495742798, "actor_loss": -59.83080339050293, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.466794967651367, "step": 14000}
{"episode_reward": 65.8113664026203, "episode": 15.0, "batch_reward": 0.05893078187480569, "critic_loss": 0.12029308879002928, "actor_loss": -60.005195220947265, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.451407432556152, "step": 15000}
{"episode_reward": 74.45851938890344, "episode": 16.0, "batch_reward": 0.05941652849316597, "critic_loss": 0.1007824909761548, "actor_loss": -58.818307792663575, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.944374322891235, "step": 16000}
{"episode_reward": 67.06076299441482, "episode": 17.0, "batch_reward": 0.060570918850600716, "critic_loss": 0.11987239527702331, "actor_loss": -57.20536137390137, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.24966788291931, "step": 17000}
{"episode_reward": 84.88588043947425, "episode": 18.0, "batch_reward": 0.062234588865190746, "critic_loss": 0.10417015650495887, "actor_loss": -55.53470000457764, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.48404335975647, "step": 18000}
{"episode_reward": 91.28981863738565, "episode": 19.0, "batch_reward": 0.06222143303602934, "critic_loss": 0.09579715052247048, "actor_loss": -56.506817329406736, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.47909951210022, "step": 19000}
{"episode_reward": 25.206378317047825, "episode": 20.0, "batch_reward": 0.0621851414963603, "critic_loss": 0.10275843280926347, "actor_loss": -54.958618309021, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.804887533187866, "step": 20000}
{"episode_reward": 104.28010008746543, "episode": 21.0, "batch_reward": 0.06693438315764069, "critic_loss": 0.10965807812288403, "actor_loss": -55.23583354949951, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.86146783828735, "step": 21000}
{"episode_reward": 258.8672285112903, "episode": 22.0, "batch_reward": 0.07777224981412291, "critic_loss": 0.11608728317543865, "actor_loss": -52.930242645263675, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.00341486930847, "step": 22000}
{"episode_reward": 325.3665323100785, "episode": 23.0, "batch_reward": 0.08747257572412491, "critic_loss": 0.10770607692375779, "actor_loss": -50.53636612701416, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.687935829162598, "step": 23000}
{"episode_reward": 175.11505480868624, "episode": 24.0, "batch_reward": 0.08843987560644746, "critic_loss": 0.12399616716429591, "actor_loss": -51.2861477432251, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.65036129951477, "step": 24000}
{"episode_reward": 136.36353676440834, "episode": 25.0, "batch_reward": 0.0907968387529254, "critic_loss": 0.13143226088955998, "actor_loss": -50.57051181030273, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.966921091079712, "step": 25000}
{"episode_reward": 95.99582235617298, "episode": 26.0, "batch_reward": 0.08871357906237244, "critic_loss": 0.1247420013025403, "actor_loss": -50.47470404052734, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.84866690635681, "step": 26000}
{"episode_reward": 57.5023453148181, "episode": 27.0, "batch_reward": 0.09263272918015718, "critic_loss": 0.12898220678418876, "actor_loss": -49.97662294006348, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.591776847839355, "step": 27000}
{"episode_reward": 213.4725507561725, "episode": 28.0, "batch_reward": 0.09246081189066171, "critic_loss": 0.13470799404382705, "actor_loss": -49.73504702758789, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.03217124938965, "step": 28000}
{"episode_reward": 49.19396943563856, "episode": 29.0, "batch_reward": 0.09150713895261288, "critic_loss": 0.14120989200100303, "actor_loss": -49.349131820678714, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.03203296661377, "step": 29000}
{"episode_reward": 57.46409121104014, "episode": 30.0, "batch_reward": 0.09214650109037757, "critic_loss": 0.16093793645501137, "actor_loss": -48.89581914520264, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.467392921447754, "step": 30000}
{"episode_reward": 119.59486643574229, "episode": 31.0, "batch_reward": 0.09108708076179027, "critic_loss": 0.1528730077072978, "actor_loss": -47.9107629776001, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.9384024143219, "step": 31000}
{"episode_reward": 59.83848719203143, "episode": 32.0, "batch_reward": 0.09186193188279868, "critic_loss": 0.18583375155180692, "actor_loss": -49.17459252166748, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.47034740447998, "step": 32000}
{"episode_reward": 110.80631755275022, "episode": 33.0, "batch_reward": 0.09049649303033948, "critic_loss": 0.20345020230859517, "actor_loss": -47.98531424713135, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.98708748817444, "step": 33000}
{"episode_reward": 36.617184260471, "episode": 34.0, "batch_reward": 0.0891133133880794, "critic_loss": 0.19559577729552985, "actor_loss": -45.24380751037598, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.43964147567749, "step": 34000}
{"episode_reward": 68.91616577352048, "episode": 35.0, "batch_reward": 0.08843057795241475, "critic_loss": 0.19242048689723015, "actor_loss": -47.53962146759033, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.455036640167236, "step": 35000}
{"episode_reward": 34.629316019037205, "episode": 36.0, "batch_reward": 0.0865781587511301, "critic_loss": 0.20061061975359917, "actor_loss": -47.367376663208006, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.015583276748657, "step": 36000}
{"episode_reward": 35.670249624148354, "episode": 37.0, "batch_reward": 0.08596360577642917, "critic_loss": 0.229138932839036, "actor_loss": -46.33033532714844, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.871769428253174, "step": 37000}
{"episode_reward": 73.09765912379368, "episode": 38.0, "batch_reward": 0.08533807207271457, "critic_loss": 0.20696487935632468, "actor_loss": -45.19565042877197, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.610249757766724, "step": 38000}
{"episode_reward": 46.49524806732512, "episode": 39.0, "batch_reward": 0.08387765234708786, "critic_loss": 0.18561172819137572, "actor_loss": -47.31263002777099, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.930030822753906, "step": 39000}
{"episode_reward": 44.55074307062928, "episode": 40.0, "batch_reward": 0.08438717190921306, "critic_loss": 0.20182574709504844, "actor_loss": -46.44947718811035, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.946317434310913, "step": 40000}
{"episode_reward": 160.31006201047782, "episode": 41.0, "batch_reward": 0.08954905404523016, "critic_loss": 0.21440490730851888, "actor_loss": -46.27119655227661, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.76987862586975, "step": 41000}
{"episode_reward": 331.15848566443304, "episode": 42.0, "batch_reward": 0.09358285322412849, "critic_loss": 0.23344889593869447, "actor_loss": -43.12077146148682, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.01440715789795, "step": 42000}
{"episode_reward": 321.91554772871564, "episode": 43.0, "batch_reward": 0.09923313418775796, "critic_loss": 0.25212661689519883, "actor_loss": -43.75942515563965, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.339319944381714, "step": 43000}
{"episode_reward": 347.2119576586122, "episode": 44.0, "batch_reward": 0.10558042519539594, "critic_loss": 0.27019323670864104, "actor_loss": -44.32657155227661, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.4651358127594, "step": 44000}
{"episode_reward": 355.19210775262906, "episode": 45.0, "batch_reward": 0.10943711674958467, "critic_loss": 0.28888450826704504, "actor_loss": -45.63721285247803, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.60500192642212, "step": 45000}
{"episode_reward": 281.3317013006418, "episode": 46.0, "batch_reward": 0.11200375643372536, "critic_loss": 0.30050045785307883, "actor_loss": -46.32519981765747, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.485292673110962, "step": 46000}
{"episode_reward": 92.95128831495859, "episode": 47.0, "batch_reward": 0.11393041656911373, "critic_loss": 0.3027971078157425, "actor_loss": -44.99830161285401, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.467857122421265, "step": 47000}
{"episode_reward": 347.5230496675144, "episode": 48.0, "batch_reward": 0.11962731865793466, "critic_loss": 0.28454546538740394, "actor_loss": -44.66796618652344, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.9278507232666, "step": 48000}
{"episode_reward": 380.8063444162563, "episode": 49.0, "batch_reward": 0.12532740093022585, "critic_loss": 0.26713844061642883, "actor_loss": -46.29227574539185, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.85437321662903, "step": 49000}
{"episode_reward": 350.44063114239304, "episode": 50.0, "batch_reward": 0.12986190897226332, "critic_loss": 0.2568268130719662, "actor_loss": -45.39038946533203, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.950363397598267, "step": 50000}
{"episode_reward": 414.67285423740776, "episode": 51.0, "batch_reward": 0.1354776128232479, "critic_loss": 0.2581087988168001, "actor_loss": -44.35930625534058, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.982853174209595, "step": 51000}
{"episode_reward": 394.96976029293467, "episode": 52.0, "batch_reward": 0.13898352815955878, "critic_loss": 0.26366439460217955, "actor_loss": -47.479670387268065, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.820115089416504, "step": 52000}
{"episode_reward": 333.3137208429527, "episode": 53.0, "batch_reward": 0.14407627855241298, "critic_loss": 0.25293885767459867, "actor_loss": -47.21534338760376, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.45145058631897, "step": 53000}
{"episode_reward": 379.5104110343376, "episode": 54.0, "batch_reward": 0.14851185669004918, "critic_loss": 0.2574782420322299, "actor_loss": -45.884481231689456, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.209732055664062, "step": 54000}
{"episode_reward": 390.8709057511618, "episode": 55.0, "batch_reward": 0.1529065036997199, "critic_loss": 0.2720191082060337, "actor_loss": -45.15562228393555, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.757415533065796, "step": 55000}
{"episode_reward": 393.78858228390914, "episode": 56.0, "batch_reward": 0.15827166824042796, "critic_loss": 0.2739340669065714, "actor_loss": -45.99809634399414, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.503141164779663, "step": 56000}
{"episode_reward": 409.8281255626501, "episode": 57.0, "batch_reward": 0.16238547529280187, "critic_loss": 0.29891711723804476, "actor_loss": -47.472148414611816, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.469216108322144, "step": 57000}
{"episode_reward": 396.88536140852807, "episode": 58.0, "batch_reward": 0.16620652344822884, "critic_loss": 0.2737023646980524, "actor_loss": -44.834990467071535, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.70075535774231, "step": 58000}
{"episode_reward": 382.0854953231269, "episode": 59.0, "batch_reward": 0.1695888892263174, "critic_loss": 0.28796031469851735, "actor_loss": -48.71770767211914, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.46469736099243, "step": 59000}
{"episode_reward": 383.37099269377313, "episode": 60.0, "batch_reward": 0.1738201395869255, "critic_loss": 0.2760114900395274, "actor_loss": -47.99598286437988, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.09225559234619, "step": 60000}
{"episode_reward": 415.1138173336058, "episode": 61.0, "batch_reward": 0.17496571753919124, "critic_loss": 0.4143082568347454, "actor_loss": -47.13328979492187, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.51202630996704, "step": 61000}
{"episode_reward": 275.52015890139575, "episode": 62.0, "batch_reward": 0.17549961394071578, "critic_loss": 0.4157579241245985, "actor_loss": -45.548056190490726, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.48794150352478, "step": 62000}
{"episode_reward": 61.85237608058899, "episode": 63.0, "batch_reward": 0.17381742399930955, "critic_loss": 0.49835755726695063, "actor_loss": -47.77314761352539, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.84831476211548, "step": 63000}
{"episode_reward": 63.91395851386649, "episode": 64.0, "batch_reward": 0.17492624411731958, "critic_loss": 0.8991521279364825, "actor_loss": -47.77194185638428, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.173423051834106, "step": 64000}
{"episode_reward": 315.5032122278837, "episode": 65.0, "batch_reward": 0.1746334331780672, "critic_loss": 0.7533221212923527, "actor_loss": -48.9439859085083, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.49215316772461, "step": 65000}
{"episode_reward": 75.09967050773865, "episode": 66.0, "batch_reward": 0.176400859169662, "critic_loss": 0.7147862483412027, "actor_loss": -49.23782907104492, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.583385705947876, "step": 66000}
{"episode_reward": 415.06654730102736, "episode": 67.0, "batch_reward": 0.1793533618748188, "critic_loss": 0.7544328541457653, "actor_loss": -50.97561167907715, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.536556005477905, "step": 67000}
{"episode_reward": 393.95147734184803, "episode": 68.0, "batch_reward": 0.18056533260643481, "critic_loss": 0.8608584076315164, "actor_loss": -49.022382942199705, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.492400407791138, "step": 68000}
{"episode_reward": 99.66525074131881, "episode": 69.0, "batch_reward": 0.18084990960359573, "critic_loss": 1.0611398033499717, "actor_loss": -49.38412350463867, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.633742332458496, "step": 69000}
{"episode_reward": 386.7930515459782, "episode": 70.0, "batch_reward": 0.18292560228705407, "critic_loss": 1.0848545513749122, "actor_loss": -51.26858200073242, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.909273386001587, "step": 70000}
{"episode_reward": 113.94254197769423, "episode": 71.0, "batch_reward": 0.18297752144932747, "critic_loss": 1.2129453900754452, "actor_loss": -50.72572602844238, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.43612790107727, "step": 71000}
{"episode_reward": 281.89241966821874, "episode": 72.0, "batch_reward": 0.18502394925057888, "critic_loss": 1.8309390162825585, "actor_loss": -51.81606606292725, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.75645136833191, "step": 72000}
{"episode_reward": 382.7376283542761, "episode": 73.0, "batch_reward": 0.18611212638020516, "critic_loss": 1.7097726734280587, "actor_loss": -52.877670951843264, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.14199185371399, "step": 73000}
{"episode_reward": 135.67332961701663, "episode": 74.0, "batch_reward": 0.18569930258393288, "critic_loss": 1.561575224161148, "actor_loss": -54.15229619598389, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.48774528503418, "step": 74000}
{"episode_reward": 131.08286309339871, "episode": 75.0, "batch_reward": 0.1846742048561573, "critic_loss": 1.6171358416974544, "actor_loss": -53.9024624710083, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.071465015411377, "step": 75000}
{"episode_reward": 110.32067127737533, "episode": 76.0, "batch_reward": 0.18277267411351203, "critic_loss": 2.3416279090046883, "actor_loss": -55.4590957107544, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.26750612258911, "step": 76000}
{"episode_reward": 180.82691675088594, "episode": 77.0, "batch_reward": 0.1829032475799322, "critic_loss": 2.3585630877614023, "actor_loss": -56.74659229278564, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.486109495162964, "step": 77000}
{"episode_reward": 86.42713833208131, "episode": 78.0, "batch_reward": 0.18147870659828186, "critic_loss": 2.6291179042458532, "actor_loss": -57.523481269836424, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.75932788848877, "step": 78000}
{"episode_reward": 97.3844592703471, "episode": 79.0, "batch_reward": 0.18018993912637235, "critic_loss": 2.9953489898443224, "actor_loss": -58.32595423126221, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.663990259170532, "step": 79000}
{"episode_reward": 30.25292670801302, "episode": 80.0, "batch_reward": 0.17761662240326404, "critic_loss": 3.076236451625824, "actor_loss": -60.28973762512207, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.579333543777466, "step": 80000}
{"episode_reward": 33.271190606727245, "episode": 81.0, "batch_reward": 0.17710441590845585, "critic_loss": 3.4960841606855393, "actor_loss": -63.97243613433838, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.04042673110962, "step": 81000}
{"episode_reward": 65.42057136359826, "episode": 82.0, "batch_reward": 0.17648205697536468, "critic_loss": 4.164870270490646, "actor_loss": -67.49130320739746, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.46603560447693, "step": 82000}
{"episode_reward": 145.46349736130415, "episode": 83.0, "batch_reward": 0.17559687536209823, "critic_loss": 4.764884582281113, "actor_loss": -71.42548385620117, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.002463817596436, "step": 83000}
{"episode_reward": 136.4754332731574, "episode": 84.0, "batch_reward": 0.17478967756032943, "critic_loss": 4.547527298569679, "actor_loss": -73.76941665649414, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.97552514076233, "step": 84000}
{"episode_reward": 160.31990954695698, "episode": 85.0, "batch_reward": 0.17343877905607225, "critic_loss": 3.7418243246078493, "actor_loss": -75.03597274780273, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.52806329727173, "step": 85000}
{"episode_reward": 45.1408723775324, "episode": 86.0, "batch_reward": 0.1723090159893036, "critic_loss": 3.1591189798116686, "actor_loss": -75.89927268981934, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.56378746032715, "step": 86000}
{"episode_reward": 14.990687462043944, "episode": 87.0, "batch_reward": 0.17106374901533128, "critic_loss": 3.0200717604160308, "actor_loss": -76.66701206970215, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.963033199310303, "step": 87000}
{"episode_reward": 66.31386171529252, "episode": 88.0, "batch_reward": 0.16995336377620698, "critic_loss": 3.075190032124519, "actor_loss": -78.15387692260742, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.473653316497803, "step": 88000}
{"episode_reward": 54.91084496162979, "episode": 89.0, "batch_reward": 0.1678424088731408, "critic_loss": 3.1158754473924635, "actor_loss": -79.52108460998535, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.438249588012695, "step": 89000}
{"episode_reward": 27.279522372240162, "episode": 90.0, "batch_reward": 0.1676305499523878, "critic_loss": 3.05300618070364, "actor_loss": -80.56424044799805, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.545655488967896, "step": 90000}
{"episode_reward": 141.58129033643579, "episode": 91.0, "batch_reward": 0.16715304319560528, "critic_loss": 2.7161386666297913, "actor_loss": -81.07757600402832, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.36971092224121, "step": 91000}
{"episode_reward": 22.51183160071504, "episode": 92.0, "batch_reward": 0.1665614418014884, "critic_loss": 2.3346097818613054, "actor_loss": -81.02019479370117, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.47513699531555, "step": 92000}
{"episode_reward": 251.1013774987408, "episode": 93.0, "batch_reward": 0.1675928201302886, "critic_loss": 1.9878649313449859, "actor_loss": -80.77038838195801, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.782018184661865, "step": 93000}
{"episode_reward": 375.37478184008813, "episode": 94.0, "batch_reward": 0.16930861657112836, "critic_loss": 1.7352564200758933, "actor_loss": -80.48980520629883, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.255797147750854, "step": 94000}
{"episode_reward": 402.8990329548203, "episode": 95.0, "batch_reward": 0.1715534795075655, "critic_loss": 1.5216454659700394, "actor_loss": -80.27940480041504, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.487414360046387, "step": 95000}
{"episode_reward": 149.78475076669508, "episode": 96.0, "batch_reward": 0.1720543166846037, "critic_loss": 1.3119778538942337, "actor_loss": -79.9434896697998, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.60042977333069, "step": 96000}
{"episode_reward": 416.47433939179314, "episode": 97.0, "batch_reward": 0.17504656814783812, "critic_loss": 1.0962560771107674, "actor_loss": -79.21421852111817, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.89346742630005, "step": 97000}
{"episode_reward": 405.50881663315727, "episode": 98.0, "batch_reward": 0.1785052884221077, "critic_loss": 0.8931775569617748, "actor_loss": -78.44314985656739, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.845216751098633, "step": 98000}
{"episode_reward": 420.8347834341413, "episode": 99.0, "batch_reward": 0.1798343416452408, "critic_loss": 0.7693956790268421, "actor_loss": -77.30905029296875, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.84838557243347, "step": 99000}
{"episode_reward": 416.9062529705677, "episode": 100.0, "batch_reward": 0.18301861964166163, "critic_loss": 0.6136708700060844, "actor_loss": -76.11007257080078, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.856709003448486, "step": 100000}
{"episode_reward": 432.88876054766024, "episode": 101.0, "batch_reward": 0.1843902042657137, "critic_loss": 0.5518451253175736, "actor_loss": -75.00562315368653, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.93617248535156, "step": 101000}
{"episode_reward": 416.6696091509944, "episode": 102.0, "batch_reward": 0.18554634779691695, "critic_loss": 0.5958182750493288, "actor_loss": -73.64158297729492, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.162543773651123, "step": 102000}
{"episode_reward": 360.8190597887869, "episode": 103.0, "batch_reward": 0.1878292269706726, "critic_loss": 0.5188842510282994, "actor_loss": -72.46606747436523, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.722379207611084, "step": 103000}
{"episode_reward": 393.9375305036727, "episode": 104.0, "batch_reward": 0.19082783411443233, "critic_loss": 0.4667462827861309, "actor_loss": -71.19830477905273, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.513133764266968, "step": 104000}
{"episode_reward": 409.83960889937026, "episode": 105.0, "batch_reward": 0.19300697979331016, "critic_loss": 0.4715998924225569, "actor_loss": -69.59616341400147, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.463579177856445, "step": 105000}
{"episode_reward": 414.9894527651367, "episode": 106.0, "batch_reward": 0.19441579759120942, "critic_loss": 0.40988954475522044, "actor_loss": -68.07342664337158, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.55433201789856, "step": 106000}
{"episode_reward": 362.0319368465844, "episode": 107.0, "batch_reward": 0.19666204869747161, "critic_loss": 0.39324103176593783, "actor_loss": -67.6878290939331, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.49088406562805, "step": 107000}
{"episode_reward": 440.036332544534, "episode": 108.0, "batch_reward": 0.19895095260441303, "critic_loss": 0.3533559047579765, "actor_loss": -67.26399872589111, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.486554622650146, "step": 108000}
{"episode_reward": 182.36598037127504, "episode": 109.0, "batch_reward": 0.19880494083464145, "critic_loss": 0.3708151914030314, "actor_loss": -66.26244954681397, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.171181440353394, "step": 109000}
{"episode_reward": 321.1230579231065, "episode": 110.0, "batch_reward": 0.19946707665920257, "critic_loss": 0.34483325520157815, "actor_loss": -65.35078793334961, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.914944887161255, "step": 110000}
{"episode_reward": 138.2439389799937, "episode": 111.0, "batch_reward": 0.19761111932992936, "critic_loss": 0.3362980060130358, "actor_loss": -64.4162166595459, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.83296513557434, "step": 111000}
{"episode_reward": 89.35186855252701, "episode": 112.0, "batch_reward": 0.1970441112667322, "critic_loss": 0.33479660895466806, "actor_loss": -63.65688421630859, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.98142123222351, "step": 112000}
{"episode_reward": 142.85273829194472, "episode": 113.0, "batch_reward": 0.1970719993710518, "critic_loss": 0.3263919123858213, "actor_loss": -62.947434257507325, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.698021173477173, "step": 113000}
{"episode_reward": 176.43133546094472, "episode": 114.0, "batch_reward": 0.19576032815873623, "critic_loss": 0.32428838032484053, "actor_loss": -62.34031170654297, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.679085731506348, "step": 114000}
{"episode_reward": 115.93137542035895, "episode": 115.0, "batch_reward": 0.1956054544299841, "critic_loss": 0.3285938789844513, "actor_loss": -60.76460340118408, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.92830991744995, "step": 115000}
{"episode_reward": 108.53606779412642, "episode": 116.0, "batch_reward": 0.1954386393725872, "critic_loss": 0.35021918126940726, "actor_loss": -60.848061798095706, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.003273248672485, "step": 116000}
{"episode_reward": 193.7453887871835, "episode": 117.0, "batch_reward": 0.19394991694390773, "critic_loss": 0.3316762519478798, "actor_loss": -60.52210777282715, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.620721578598022, "step": 117000}
{"episode_reward": 79.97982447612654, "episode": 118.0, "batch_reward": 0.19444957876205443, "critic_loss": 0.33677047848701475, "actor_loss": -60.35878213500977, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.006205320358276, "step": 118000}
{"episode_reward": 96.43549701959887, "episode": 119.0, "batch_reward": 0.19362821465730667, "critic_loss": 0.30620363813638685, "actor_loss": -58.360321601867675, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.10184669494629, "step": 119000}
{"episode_reward": 123.76282635436395, "episode": 120.0, "batch_reward": 0.19178451420366763, "critic_loss": 0.29749814135581254, "actor_loss": -57.403006385803224, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.51466679573059, "step": 120000}
{"episode_reward": 80.52019623557143, "episode": 121.0, "batch_reward": 0.19241634042561054, "critic_loss": 0.2967723356038332, "actor_loss": -56.758437324523925, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.1519033908844, "step": 121000}
{"episode_reward": 95.09573312371494, "episode": 122.0, "batch_reward": 0.19176334927976132, "critic_loss": 0.3021670727431774, "actor_loss": -56.67947208404541, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.645265579223633, "step": 122000}
{"episode_reward": 397.8705167904217, "episode": 123.0, "batch_reward": 0.19365450935065745, "critic_loss": 0.33514340850710866, "actor_loss": -56.835569961547854, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.491723775863647, "step": 123000}
{"episode_reward": 331.6629252071616, "episode": 124.0, "batch_reward": 0.19515699595212938, "critic_loss": 0.42988201130926607, "actor_loss": -56.84486338043213, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.78348731994629, "step": 124000}
{"episode_reward": 475.95799532968687, "episode": 125.0, "batch_reward": 0.19758178213238717, "critic_loss": 0.4300361932814121, "actor_loss": -56.228389389038085, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.688588857650757, "step": 125000}
{"episode_reward": 478.98704863494805, "episode": 126.0, "batch_reward": 0.19880519983172418, "critic_loss": 0.446448483094573, "actor_loss": -56.40044627380371, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.466662168502808, "step": 126000}
{"episode_reward": 477.87714488744103, "episode": 127.0, "batch_reward": 0.2016085701584816, "critic_loss": 0.455262414932251, "actor_loss": -56.623333526611326, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.464443683624268, "step": 127000}
{"episode_reward": 469.4251828490271, "episode": 128.0, "batch_reward": 0.2035067419707775, "critic_loss": 0.4810709354430437, "actor_loss": -56.900513259887695, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.43747115135193, "step": 128000}
{"episode_reward": 417.84634018283987, "episode": 129.0, "batch_reward": 0.20546331098675727, "critic_loss": 0.4755890989303589, "actor_loss": -57.53115658569336, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.46579885482788, "step": 129000}
{"episode_reward": 473.94499836761344, "episode": 130.0, "batch_reward": 0.20723386657238008, "critic_loss": 0.4710527160614729, "actor_loss": -55.52117979431152, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.038126707077026, "step": 130000}
{"episode_reward": 427.061188244066, "episode": 131.0, "batch_reward": 0.20961459867656232, "critic_loss": 0.4485223931670189, "actor_loss": -56.22825430297851, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.505653381347656, "step": 131000}
{"episode_reward": 491.48879965498264, "episode": 132.0, "batch_reward": 0.21149678802490235, "critic_loss": 0.4259430621266365, "actor_loss": -54.67288673400879, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.676973819732666, "step": 132000}
{"episode_reward": 465.32809156828574, "episode": 133.0, "batch_reward": 0.21153270684182643, "critic_loss": 0.4180200762450695, "actor_loss": -56.415642082214355, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.95061469078064, "step": 133000}
{"episode_reward": 95.77523739105393, "episode": 134.0, "batch_reward": 0.21231785535812378, "critic_loss": 0.40880044677853583, "actor_loss": -56.448593246459964, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.030758380889893, "step": 134000}
{"episode_reward": 440.35609429636474, "episode": 135.0, "batch_reward": 0.21377251134812833, "critic_loss": 0.3792966155856848, "actor_loss": -55.255133529663084, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.472783088684082, "step": 135000}
{"episode_reward": 504.28979228874965, "episode": 136.0, "batch_reward": 0.21666050092875958, "critic_loss": 0.35956531342864034, "actor_loss": -55.093603050231934, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.11319923400879, "step": 136000}
{"episode_reward": 491.10124538968904, "episode": 137.0, "batch_reward": 0.21808724381029607, "critic_loss": 0.3532652790993452, "actor_loss": -53.852893043518065, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.858931064605713, "step": 137000}
{"episode_reward": 476.3580960832734, "episode": 138.0, "batch_reward": 0.22026125007867814, "critic_loss": 0.34610479970276353, "actor_loss": -53.09771527099609, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.518383502960205, "step": 138000}
{"episode_reward": 520.8908963289105, "episode": 139.0, "batch_reward": 0.22078951473534109, "critic_loss": 0.3605682861357927, "actor_loss": -53.78281637573242, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.486584663391113, "step": 139000}
{"episode_reward": 88.88243164096953, "episode": 140.0, "batch_reward": 0.22073683881759643, "critic_loss": 0.3532288383841515, "actor_loss": -53.88485157775879, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.873271942138672, "step": 140000}
{"episode_reward": 554.6203731392058, "episode": 141.0, "batch_reward": 0.22256908410787582, "critic_loss": 0.3684639080762863, "actor_loss": -52.67226503753662, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.838929414749146, "step": 141000}
{"episode_reward": 94.30985285932151, "episode": 142.0, "batch_reward": 0.22259518358111383, "critic_loss": 0.3813056447058916, "actor_loss": -52.299212944030764, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.91121816635132, "step": 142000}
{"episode_reward": 521.0952614175063, "episode": 143.0, "batch_reward": 0.22589822612702848, "critic_loss": 0.3802344385385513, "actor_loss": -53.20959392547607, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.405536890029907, "step": 143000}
{"episode_reward": 514.0133663921922, "episode": 144.0, "batch_reward": 0.22653697285056115, "critic_loss": 0.38555892261862756, "actor_loss": -52.22404174804687, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.456425428390503, "step": 144000}
{"episode_reward": 70.06444131424308, "episode": 145.0, "batch_reward": 0.22756030805408956, "critic_loss": 0.38886996929347517, "actor_loss": -51.85793569946289, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.05353331565857, "step": 145000}
{"episode_reward": 592.0264140351229, "episode": 146.0, "batch_reward": 0.22831801377236843, "critic_loss": 0.36824500253796577, "actor_loss": -53.24660095214844, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.842967987060547, "step": 146000}
{"episode_reward": 380.4077422722695, "episode": 147.0, "batch_reward": 0.2292243338227272, "critic_loss": 0.3730776482075453, "actor_loss": -52.57388451385498, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.472209453582764, "step": 147000}
{"episode_reward": 550.1663313008578, "episode": 148.0, "batch_reward": 0.23180752605199814, "critic_loss": 0.3786075499355793, "actor_loss": -52.692677963256834, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.588749170303345, "step": 148000}
{"episode_reward": 611.6715806033492, "episode": 149.0, "batch_reward": 0.23315908469259738, "critic_loss": 0.3789503035247326, "actor_loss": -51.68850895690918, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.888330221176147, "step": 149000}
{"episode_reward": 568.0538018934575, "episode": 150.0, "batch_reward": 0.2361298105418682, "critic_loss": 0.37945445396006106, "actor_loss": -52.31068762207031, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "step": 150000}
