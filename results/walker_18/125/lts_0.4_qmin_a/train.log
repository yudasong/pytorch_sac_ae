{"episode_reward": 0.0, "episode": 1.0, "duration": 21.367470264434814, "step": 1000}
{"episode_reward": 28.177075776326152, "episode": 2.0, "duration": 1.8663249015808105, "step": 2000}
{"episode_reward": 69.84046218736019, "episode": 3.0, "batch_reward": 0.04688787416354065, "critic_loss": 0.010061594749346378, "actor_loss": -31.819872079964945, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499180007, "duration": 61.10304522514343, "step": 3000}
{"episode_reward": 14.626452043724674, "episode": 4.0, "batch_reward": 0.04217838409543037, "critic_loss": 0.005839412936125882, "actor_loss": -35.045441100418564, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.399893760681152, "step": 4000}
{"episode_reward": 62.65981115256753, "episode": 5.0, "batch_reward": 0.0556218062825501, "critic_loss": 0.009258470830973238, "actor_loss": -27.426184703856705, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.4178307056427, "step": 5000}
{"episode_reward": 119.71211822530984, "episode": 6.0, "batch_reward": 0.060299154106527565, "critic_loss": 0.014078187529928982, "actor_loss": -31.083783534254877, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.440972089767456, "step": 6000}
{"episode_reward": 68.17203905195686, "episode": 7.0, "batch_reward": 0.0625059694610536, "critic_loss": 0.028978549082763493, "actor_loss": -32.14293753854558, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.40077042579651, "step": 7000}
{"episode_reward": 89.42412453774996, "episode": 8.0, "batch_reward": 0.0662107194699347, "critic_loss": 0.028774773844517768, "actor_loss": -30.485476664960384, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.432287216186523, "step": 8000}
{"episode_reward": 73.36413325988248, "episode": 9.0, "batch_reward": 0.0658533961623907, "critic_loss": 0.027765347950160505, "actor_loss": -34.67207450807095, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.433360815048218, "step": 9000}
{"episode_reward": 64.72759479700578, "episode": 10.0, "batch_reward": 0.06502880088984966, "critic_loss": 0.026904752011410894, "actor_loss": -32.506940751791, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.395572185516357, "step": 10000}
{"episode_reward": 59.156518883557595, "episode": 11.0, "batch_reward": 0.06474505742639303, "critic_loss": 0.030821345298551024, "actor_loss": -33.035132345438, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.52286982536316, "step": 11000}
{"episode_reward": 59.30405584898095, "episode": 12.0, "batch_reward": 0.06598503644764424, "critic_loss": 0.04403295275010168, "actor_loss": -33.404719702482225, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.38127875328064, "step": 12000}
{"episode_reward": 76.48661460554024, "episode": 13.0, "batch_reward": 0.06563841335847974, "critic_loss": 0.04671327307261527, "actor_loss": -33.650597823143, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.4250648021698, "step": 13000}
{"episode_reward": 66.93618947712224, "episode": 14.0, "batch_reward": 0.0657355826869607, "critic_loss": 0.04777474252320826, "actor_loss": -29.704208588838576, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.43539834022522, "step": 14000}
{"episode_reward": 61.99681673617601, "episode": 15.0, "batch_reward": 0.06884268916770817, "critic_loss": 0.04998827414680272, "actor_loss": -34.80705245637893, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.385758638381958, "step": 15000}
{"episode_reward": 121.5047471534801, "episode": 16.0, "batch_reward": 0.06890951212495565, "critic_loss": 0.05090796135738492, "actor_loss": -35.13309924983978, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.414109468460083, "step": 16000}
{"episode_reward": 57.69429332558411, "episode": 17.0, "batch_reward": 0.07294201459735632, "critic_loss": 0.06016409558057785, "actor_loss": -31.68316928911209, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.421583652496338, "step": 17000}
{"episode_reward": 219.8586833625067, "episode": 18.0, "batch_reward": 0.07888604429364204, "critic_loss": 0.07289084178768099, "actor_loss": -32.50476715946198, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.409830331802368, "step": 18000}
{"episode_reward": 122.66563985937844, "episode": 19.0, "batch_reward": 0.08005521527677774, "critic_loss": 0.07896540282666684, "actor_loss": -35.4760759973526, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.412951946258545, "step": 19000}
{"episode_reward": 75.39874468340842, "episode": 20.0, "batch_reward": 0.07932506027072668, "critic_loss": 0.08084724750742316, "actor_loss": -36.39781023836136, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.427359342575073, "step": 20000}
{"episode_reward": 62.98996041539729, "episode": 21.0, "batch_reward": 0.07782767859101296, "critic_loss": 0.09400439955666662, "actor_loss": -36.91164281511307, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.472391843795776, "step": 21000}
{"episode_reward": 52.906633406785076, "episode": 22.0, "batch_reward": 0.07989493216201662, "critic_loss": 0.10037560915574431, "actor_loss": -35.861745164871216, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.411026000976562, "step": 22000}
{"episode_reward": 123.99805280001267, "episode": 23.0, "batch_reward": 0.07917925320565701, "critic_loss": 0.1022309580296278, "actor_loss": -32.71364616727829, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.440584182739258, "step": 23000}
{"episode_reward": 50.46311778953057, "episode": 24.0, "batch_reward": 0.08525681753829122, "critic_loss": 0.14185544442757964, "actor_loss": -35.8500720667839, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.382188081741333, "step": 24000}
{"episode_reward": 348.57962205956983, "episode": 25.0, "batch_reward": 0.09199650540947914, "critic_loss": 0.17830382387340069, "actor_loss": -33.05407272720337, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.41221594810486, "step": 25000}
{"episode_reward": 164.1062342783334, "episode": 26.0, "batch_reward": 0.09266782289743423, "critic_loss": 0.15324680413678288, "actor_loss": -34.75212988185883, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.41171956062317, "step": 26000}
{"episode_reward": 83.56693562114896, "episode": 27.0, "batch_reward": 0.09264791160821914, "critic_loss": 0.17587216025590896, "actor_loss": -34.97894673538208, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.407836437225342, "step": 27000}
{"episode_reward": 89.55371807237074, "episode": 28.0, "batch_reward": 0.09158950511366129, "critic_loss": 0.1812401009351015, "actor_loss": -34.14082003211975, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.428011894226074, "step": 28000}
{"episode_reward": 61.59815060140451, "episode": 29.0, "batch_reward": 0.09116754718124867, "critic_loss": 0.18102843730524182, "actor_loss": -36.558880343437195, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.426665782928467, "step": 29000}
{"episode_reward": 77.35957285268907, "episode": 30.0, "batch_reward": 0.09437273285537959, "critic_loss": 0.18904199113696812, "actor_loss": -35.53095199394226, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.41202425956726, "step": 30000}
{"episode_reward": 358.70055587105674, "episode": 31.0, "batch_reward": 0.09887232546508312, "critic_loss": 0.1843572862111032, "actor_loss": -35.687788454055784, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.48436117172241, "step": 31000}
{"episode_reward": 73.66779122123867, "episode": 32.0, "batch_reward": 0.10351080964505673, "critic_loss": 0.17051291601359844, "actor_loss": -39.161510120391846, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.38657808303833, "step": 32000}
{"episode_reward": 393.9512692533379, "episode": 33.0, "batch_reward": 0.11229208975285292, "critic_loss": 0.1934628573730588, "actor_loss": -38.84724347400665, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.40350914001465, "step": 33000}
{"episode_reward": 376.8097173299927, "episode": 34.0, "batch_reward": 0.1203880862519145, "critic_loss": 0.1762365762963891, "actor_loss": -32.960239042282105, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.40135669708252, "step": 34000}
{"episode_reward": 391.74317559624524, "episode": 35.0, "batch_reward": 0.12494707569479942, "critic_loss": 0.1942995908781886, "actor_loss": -38.02474750900269, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.416046857833862, "step": 35000}
{"episode_reward": 144.10968373206123, "episode": 36.0, "batch_reward": 0.12422299620509147, "critic_loss": 0.17503956718742847, "actor_loss": -37.23176773262024, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.403684616088867, "step": 36000}
{"episode_reward": 71.60486397170244, "episode": 37.0, "batch_reward": 0.12190585973858833, "critic_loss": 0.16765072679519652, "actor_loss": -36.022518688201906, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.44030213356018, "step": 37000}
{"episode_reward": 76.02171673638519, "episode": 38.0, "batch_reward": 0.12561767281591893, "critic_loss": 0.1831579614803195, "actor_loss": -36.657641134262086, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.42664885520935, "step": 38000}
{"episode_reward": 385.5268669196197, "episode": 39.0, "batch_reward": 0.1312083565071225, "critic_loss": 0.19614980445802213, "actor_loss": -41.09650135231018, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.42677664756775, "step": 39000}
{"episode_reward": 204.3855099044985, "episode": 40.0, "batch_reward": 0.1334514615163207, "critic_loss": 0.18138510279357434, "actor_loss": -38.844581939697264, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.411211490631104, "step": 40000}
{"episode_reward": 383.49777406801616, "episode": 41.0, "batch_reward": 0.1408313671424985, "critic_loss": 0.2052629073560238, "actor_loss": -40.212969974517826, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.44716930389404, "step": 41000}
{"episode_reward": 394.0225744774812, "episode": 42.0, "batch_reward": 0.14600198647379875, "critic_loss": 0.21298753928393124, "actor_loss": -40.27150916862488, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.433753967285156, "step": 42000}
{"episode_reward": 390.0655683511136, "episode": 43.0, "batch_reward": 0.15294465348124503, "critic_loss": 0.22274206361174584, "actor_loss": -41.00077590942383, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.3752658367157, "step": 43000}
{"episode_reward": 426.03661764808317, "episode": 44.0, "batch_reward": 0.15926807221770287, "critic_loss": 0.24184781827032567, "actor_loss": -40.418938060760496, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.405133485794067, "step": 44000}
{"episode_reward": 423.6847011094105, "episode": 45.0, "batch_reward": 0.16432934860885143, "critic_loss": 0.25752582209557295, "actor_loss": -44.55269417572021, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.41160297393799, "step": 45000}
{"episode_reward": 362.37162048479377, "episode": 46.0, "batch_reward": 0.1671961519420147, "critic_loss": 0.2764702822268009, "actor_loss": -44.14446709442139, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.39729070663452, "step": 46000}
{"episode_reward": 293.8353356410434, "episode": 47.0, "batch_reward": 0.16858687400072814, "critic_loss": 0.29217617444694044, "actor_loss": -43.47832400894165, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.408944368362427, "step": 47000}
{"episode_reward": 216.6411469902687, "episode": 48.0, "batch_reward": 0.1721548812687397, "critic_loss": 0.30919398096203804, "actor_loss": -43.11133225631714, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.4099063873291, "step": 48000}
{"episode_reward": 377.59780637601614, "episode": 49.0, "batch_reward": 0.17700574266910554, "critic_loss": 0.34781484280526637, "actor_loss": -45.171544761657714, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.375274181365967, "step": 49000}
{"episode_reward": 258.66072113729905, "episode": 50.0, "batch_reward": 0.17814497601985932, "critic_loss": 0.4022168572843075, "actor_loss": -45.14871314239502, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.389028787612915, "step": 50000}
{"episode_reward": 291.77885873832014, "episode": 51.0, "batch_reward": 0.1800549322143197, "critic_loss": 0.45340318587422374, "actor_loss": -43.58445013427735, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.43760013580322, "step": 51000}
{"episode_reward": 365.05887968335134, "episode": 52.0, "batch_reward": 0.18135394629836082, "critic_loss": 0.4400170507580042, "actor_loss": -47.060256172180175, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.406108379364014, "step": 52000}
{"episode_reward": 87.55756471679247, "episode": 53.0, "batch_reward": 0.18230304515361787, "critic_loss": 0.4994672784805298, "actor_loss": -47.16301342010498, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.416810035705566, "step": 53000}
{"episode_reward": 379.6358345709641, "episode": 54.0, "batch_reward": 0.1868618176728487, "critic_loss": 0.5057557165175677, "actor_loss": -46.913734703063966, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.390341997146606, "step": 54000}
{"episode_reward": 509.7636249774139, "episode": 55.0, "batch_reward": 0.1895120413005352, "critic_loss": 0.4929452402293682, "actor_loss": -44.63870564651489, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.42361807823181, "step": 55000}
{"episode_reward": 59.82419798490031, "episode": 56.0, "batch_reward": 0.1871297959536314, "critic_loss": 0.46512400022149086, "actor_loss": -47.406219341278074, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.42594337463379, "step": 56000}
{"episode_reward": 126.7208398787907, "episode": 57.0, "batch_reward": 0.18697575521469117, "critic_loss": 0.43689953136444093, "actor_loss": -47.596025115966796, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.39023208618164, "step": 57000}
{"episode_reward": 62.53748325627887, "episode": 58.0, "batch_reward": 0.18493607108294963, "critic_loss": 0.4294195844680071, "actor_loss": -44.3744619140625, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.440439701080322, "step": 58000}
{"episode_reward": 106.63941823571461, "episode": 59.0, "batch_reward": 0.18194191561639309, "critic_loss": 0.44502036944031714, "actor_loss": -46.819985626220706, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.422621250152588, "step": 59000}
{"episode_reward": 93.76545588858478, "episode": 60.0, "batch_reward": 0.18408056595921515, "critic_loss": 0.4423000050187111, "actor_loss": -47.93025971603394, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.376088619232178, "step": 60000}
{"episode_reward": 440.9958803275152, "episode": 61.0, "batch_reward": 0.1885352141112089, "critic_loss": 0.4509660298526287, "actor_loss": -46.26712044906616, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.54460954666138, "step": 61000}
{"episode_reward": 502.48882043769413, "episode": 62.0, "batch_reward": 0.19199794398248196, "critic_loss": 0.4648063511103392, "actor_loss": -45.712965160369876, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.436073303222656, "step": 62000}
{"episode_reward": 244.73952538383236, "episode": 63.0, "batch_reward": 0.19417180399596692, "critic_loss": 0.5577902658879756, "actor_loss": -46.725885303497314, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.40365982055664, "step": 63000}
{"episode_reward": 529.5826241598562, "episode": 64.0, "batch_reward": 0.19942855785787106, "critic_loss": 0.7251142223775386, "actor_loss": -47.62936386108399, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.41212034225464, "step": 64000}
{"episode_reward": 494.06073640179295, "episode": 65.0, "batch_reward": 0.2041270365267992, "critic_loss": 0.8050031389296055, "actor_loss": -49.65395941925049, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.42204999923706, "step": 65000}
{"episode_reward": 308.5705441354198, "episode": 66.0, "batch_reward": 0.20507896798849107, "critic_loss": 0.8397244195938111, "actor_loss": -50.52820158004761, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.408117532730103, "step": 66000}
{"episode_reward": 394.0095570014445, "episode": 67.0, "batch_reward": 0.20759038665890694, "critic_loss": 0.7838777303397656, "actor_loss": -53.25499394607544, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.41765785217285, "step": 67000}
{"episode_reward": 204.14146201543758, "episode": 68.0, "batch_reward": 0.20756693054735662, "critic_loss": 0.7211848585307599, "actor_loss": -50.1440128288269, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.42160439491272, "step": 68000}
{"episode_reward": 484.7634914103659, "episode": 69.0, "batch_reward": 0.2091395877301693, "critic_loss": 0.6518990675210953, "actor_loss": -52.72137955093384, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.42438316345215, "step": 69000}
{"episode_reward": 138.77710138857702, "episode": 70.0, "batch_reward": 0.21152466407418252, "critic_loss": 0.5918482310175895, "actor_loss": -53.648928833007815, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.4231915473938, "step": 70000}
{"episode_reward": 579.9273463844295, "episode": 71.0, "batch_reward": 0.21543201880156995, "critic_loss": 0.5742741559445858, "actor_loss": -51.65229637908936, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.51169276237488, "step": 71000}
{"episode_reward": 398.5755722451168, "episode": 72.0, "batch_reward": 0.21836887122690676, "critic_loss": 0.5480704399049282, "actor_loss": -52.41975958251953, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.422399044036865, "step": 72000}
{"episode_reward": 446.2155351098739, "episode": 73.0, "batch_reward": 0.22153869269788265, "critic_loss": 0.5304244748353958, "actor_loss": -52.95294814682007, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.420037746429443, "step": 73000}
{"episode_reward": 432.11128607226294, "episode": 74.0, "batch_reward": 0.2237417066693306, "critic_loss": 0.5284667756259441, "actor_loss": -53.646560745239256, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.411734342575073, "step": 74000}
{"episode_reward": 228.0225339976679, "episode": 75.0, "batch_reward": 0.22259079471230506, "critic_loss": 0.5288723928630352, "actor_loss": -52.72377159118653, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.433168411254883, "step": 75000}
{"episode_reward": 93.69209556324178, "episode": 76.0, "batch_reward": 0.2229331970065832, "critic_loss": 0.5187427219152451, "actor_loss": -52.482508514404294, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.39509415626526, "step": 76000}
{"episode_reward": 555.4053149758186, "episode": 77.0, "batch_reward": 0.22521992345154285, "critic_loss": 0.5258934977203608, "actor_loss": -52.6160492515564, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.445712327957153, "step": 77000}
{"episode_reward": 111.29609420228506, "episode": 78.0, "batch_reward": 0.22638533338904382, "critic_loss": 0.5203345198631286, "actor_loss": -53.217677852630615, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.4087073802948, "step": 78000}
{"episode_reward": 536.753467259774, "episode": 79.0, "batch_reward": 0.22865444539487362, "critic_loss": 0.5150884088873863, "actor_loss": -51.529382606506346, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.43420433998108, "step": 79000}
{"episode_reward": 97.50386704138822, "episode": 80.0, "batch_reward": 0.2290525302439928, "critic_loss": 0.5136345630288124, "actor_loss": -51.691504653930664, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.409859657287598, "step": 80000}
{"episode_reward": 453.80094207212, "episode": 81.0, "batch_reward": 0.23261237020790576, "critic_loss": 0.5562852420210839, "actor_loss": -53.33074034118653, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.50077295303345, "step": 81000}
{"episode_reward": 548.5894500486212, "episode": 82.0, "batch_reward": 0.2360310355722904, "critic_loss": 0.621810112029314, "actor_loss": -53.57329816436768, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.401550769805908, "step": 82000}
{"episode_reward": 572.0473312011945, "episode": 83.0, "batch_reward": 0.24112521678209306, "critic_loss": 0.7048268317878247, "actor_loss": -53.83153800201416, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.411341667175293, "step": 83000}
{"episode_reward": 668.0434729150772, "episode": 84.0, "batch_reward": 0.24435951116681098, "critic_loss": 0.8144943676888943, "actor_loss": -55.07696094512939, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.45576810836792, "step": 84000}
{"episode_reward": 422.1724917740663, "episode": 85.0, "batch_reward": 0.24654194270074367, "critic_loss": 0.8354101875424385, "actor_loss": -55.623096008300784, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.38358473777771, "step": 85000}
{"episode_reward": 618.039710679064, "episode": 86.0, "batch_reward": 0.24803719374537467, "critic_loss": 0.8304103052914142, "actor_loss": -55.1636241607666, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.42425775527954, "step": 86000}
{"episode_reward": 15.902694991884154, "episode": 87.0, "batch_reward": 0.2493000590801239, "critic_loss": 0.8081058658063411, "actor_loss": -54.29349229431153, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.41881036758423, "step": 87000}
{"episode_reward": 657.3256386098733, "episode": 88.0, "batch_reward": 0.2511199657320976, "critic_loss": 0.8361024278104305, "actor_loss": -54.222834075927736, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.409990787506104, "step": 88000}
{"episode_reward": 297.75988493104546, "episode": 89.0, "batch_reward": 0.2543585830926895, "critic_loss": 0.8616917450428009, "actor_loss": -55.61741541290283, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.413711309432983, "step": 89000}
{"episode_reward": 666.8554728696857, "episode": 90.0, "batch_reward": 0.2577424869686365, "critic_loss": 0.8524984371960163, "actor_loss": -56.59762767791748, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.403148889541626, "step": 90000}
{"episode_reward": 662.4985052856192, "episode": 91.0, "batch_reward": 0.26349411784112453, "critic_loss": 0.841767944008112, "actor_loss": -55.89245341491699, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.46442723274231, "step": 91000}
{"episode_reward": 643.019625538862, "episode": 92.0, "batch_reward": 0.2679143440872431, "critic_loss": 0.8496038814485073, "actor_loss": -57.2661643447876, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.41258955001831, "step": 92000}
{"episode_reward": 640.0559898922804, "episode": 93.0, "batch_reward": 0.27236177000403405, "critic_loss": 0.8465162796080112, "actor_loss": -56.36289196014404, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.403665781021118, "step": 93000}
{"episode_reward": 703.5339728629821, "episode": 94.0, "batch_reward": 0.2760625180751085, "critic_loss": 0.8378318935036659, "actor_loss": -57.00074406433105, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.426826238632202, "step": 94000}
{"episode_reward": 717.0731887463401, "episode": 95.0, "batch_reward": 0.281154862716794, "critic_loss": 0.8679880336225033, "actor_loss": -58.27237509918213, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.420833349227905, "step": 95000}
{"episode_reward": 564.8669832373155, "episode": 96.0, "batch_reward": 0.2840730256289244, "critic_loss": 0.9095017664134503, "actor_loss": -57.67848150634766, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.38036012649536, "step": 96000}
{"episode_reward": 645.6905080003992, "episode": 97.0, "batch_reward": 0.28757892914116384, "critic_loss": 0.932169569671154, "actor_loss": -58.76626936340332, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.440275192260742, "step": 97000}
{"episode_reward": 739.0551958084935, "episode": 98.0, "batch_reward": 0.2931453079283238, "critic_loss": 0.9708847195208072, "actor_loss": -58.553486457824704, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.435726165771484, "step": 98000}
{"episode_reward": 753.5584254240953, "episode": 99.0, "batch_reward": 0.29803606334328653, "critic_loss": 1.0177510914802552, "actor_loss": -58.70595082092285, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.424904108047485, "step": 99000}
{"episode_reward": 791.6864070020636, "episode": 100.0, "batch_reward": 0.30262376721203327, "critic_loss": 1.0466696379184723, "actor_loss": -58.5413083190918, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.411104440689087, "step": 100000}
{"episode_reward": 751.4828436246987, "episode": 101.0, "batch_reward": 0.30722331017255783, "critic_loss": 1.0653951251506806, "actor_loss": -60.405568214416505, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.5850670337677, "step": 101000}
{"episode_reward": 789.9293220019447, "episode": 102.0, "batch_reward": 0.30965796804428103, "critic_loss": 1.067099371612072, "actor_loss": -60.38459809112549, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.432421684265137, "step": 102000}
{"episode_reward": 788.9619211434858, "episode": 103.0, "batch_reward": 0.31544717624783514, "critic_loss": 1.1023435978889464, "actor_loss": -60.620252990722655, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.403239727020264, "step": 103000}
{"episode_reward": 764.6155661352022, "episode": 104.0, "batch_reward": 0.3200100931972265, "critic_loss": 1.1506483191251755, "actor_loss": -61.09043293762207, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.412907361984253, "step": 104000}
{"episode_reward": 793.272344076463, "episode": 105.0, "batch_reward": 0.3258180019259453, "critic_loss": 1.0768452870547771, "actor_loss": -59.72291305541992, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.404597997665405, "step": 105000}
{"episode_reward": 812.6124798752984, "episode": 106.0, "batch_reward": 0.32986724527180195, "critic_loss": 1.1119236684441567, "actor_loss": -59.663746780395506, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.430132627487183, "step": 106000}
{"episode_reward": 847.0550761705202, "episode": 107.0, "batch_reward": 0.3345245378911495, "critic_loss": 1.0966891258955003, "actor_loss": -61.93243951416016, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.433277130126953, "step": 107000}
{"episode_reward": 763.4254676184531, "episode": 108.0, "batch_reward": 0.3390558744221926, "critic_loss": 1.0632753447890282, "actor_loss": -62.86224129486084, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.415037393569946, "step": 108000}
{"episode_reward": 834.5882197740349, "episode": 109.0, "batch_reward": 0.34200789979100227, "critic_loss": 1.1443207193613052, "actor_loss": -62.712681098937985, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.41894221305847, "step": 109000}
{"episode_reward": 702.999672682589, "episode": 110.0, "batch_reward": 0.3467192538678646, "critic_loss": 1.1524254996776582, "actor_loss": -64.01123962402343, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.391422033309937, "step": 110000}
{"episode_reward": 788.9370270885379, "episode": 111.0, "batch_reward": 0.35101687821745875, "critic_loss": 1.158769831240177, "actor_loss": -64.19745820617676, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.50917434692383, "step": 111000}
{"episode_reward": 831.271432549962, "episode": 112.0, "batch_reward": 0.354833752065897, "critic_loss": 1.1190457953214645, "actor_loss": -64.38816150665284, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.436009168624878, "step": 112000}
{"episode_reward": 831.4287917700593, "episode": 113.0, "batch_reward": 0.3599578031897545, "critic_loss": 1.1477597382366658, "actor_loss": -65.04853369903564, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.388371467590332, "step": 113000}
{"episode_reward": 847.1364594904679, "episode": 114.0, "batch_reward": 0.3638208169341087, "critic_loss": 1.1039860571026803, "actor_loss": -66.69938233947754, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.41791558265686, "step": 114000}
{"episode_reward": 865.3737540576591, "episode": 115.0, "batch_reward": 0.36755390417575834, "critic_loss": 1.1211639977693557, "actor_loss": -66.21109943389892, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.41051697731018, "step": 115000}
{"episode_reward": 853.4268181959196, "episode": 116.0, "batch_reward": 0.371930115044117, "critic_loss": 1.1264028423428536, "actor_loss": -67.31593259429931, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.400744676589966, "step": 116000}
{"episode_reward": 743.0989185677764, "episode": 117.0, "batch_reward": 0.3756883274912834, "critic_loss": 1.156900436401367, "actor_loss": -67.09632607269288, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.425768852233887, "step": 117000}
{"episode_reward": 816.06355762159, "episode": 118.0, "batch_reward": 0.3789106793999672, "critic_loss": 1.1329223899841308, "actor_loss": -68.52662857818603, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.41893744468689, "step": 118000}
{"episode_reward": 872.9207540637368, "episode": 119.0, "batch_reward": 0.38349410763382913, "critic_loss": 1.1137930342555047, "actor_loss": -67.71680635070801, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.379456520080566, "step": 119000}
{"episode_reward": 835.511087032213, "episode": 120.0, "batch_reward": 0.3853474594652653, "critic_loss": 1.1191325525641442, "actor_loss": -67.33005192565918, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.390294075012207, "step": 120000}
{"episode_reward": 857.260516367971, "episode": 121.0, "batch_reward": 0.39176863300800324, "critic_loss": 1.1250757222771646, "actor_loss": -68.19766535186767, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.45311641693115, "step": 121000}
{"episode_reward": 858.2253205467799, "episode": 122.0, "batch_reward": 0.39468133610486983, "critic_loss": 1.1338666176199914, "actor_loss": -68.88818449401856, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.421395301818848, "step": 122000}
{"episode_reward": 834.9574049603881, "episode": 123.0, "batch_reward": 0.3970320941507816, "critic_loss": 1.161287479519844, "actor_loss": -68.3747904586792, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.421969413757324, "step": 123000}
{"episode_reward": 554.7882535769221, "episode": 124.0, "batch_reward": 0.4000594583153725, "critic_loss": 1.1836994638442992, "actor_loss": -69.4123113861084, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.398515701293945, "step": 124000}
{"episode_reward": 877.1125553211043, "episode": 125.0, "batch_reward": 0.40515622213482855, "critic_loss": 1.1875977862477303, "actor_loss": -69.01873601531983, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.43111538887024, "step": 125000}
{"episode_reward": 877.2942476715123, "episode": 126.0, "batch_reward": 0.4076501121222973, "critic_loss": 1.1805700535178185, "actor_loss": -70.23057611083985, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.42887258529663, "step": 126000}
{"episode_reward": 869.2365833257423, "episode": 127.0, "batch_reward": 0.4108992275595665, "critic_loss": 1.1589838804602624, "actor_loss": -70.30712072753906, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.38273811340332, "step": 127000}
{"episode_reward": 897.7932828786044, "episode": 128.0, "batch_reward": 0.4144632683098316, "critic_loss": 1.1707059690952302, "actor_loss": -70.92076350402832, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.408663511276245, "step": 128000}
{"episode_reward": 851.0547631882808, "episode": 129.0, "batch_reward": 0.41807772958278655, "critic_loss": 1.146246205151081, "actor_loss": -71.39130323791504, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.442427158355713, "step": 129000}
{"episode_reward": 888.987478819987, "episode": 130.0, "batch_reward": 0.4211739599406719, "critic_loss": 1.138807402074337, "actor_loss": -70.64758209991454, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.42267394065857, "step": 130000}
{"episode_reward": 877.317285944617, "episode": 131.0, "batch_reward": 0.42677747121453286, "critic_loss": 1.1570878306031227, "actor_loss": -71.28871371459961, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.52142143249512, "step": 131000}
{"episode_reward": 878.1192711505824, "episode": 132.0, "batch_reward": 0.4297518847584724, "critic_loss": 1.1593698704242705, "actor_loss": -71.28447454071045, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.4831964969635, "step": 132000}
{"episode_reward": 864.9230795608684, "episode": 133.0, "batch_reward": 0.43172674027085306, "critic_loss": 1.1605157639980317, "actor_loss": -72.49576768493652, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.697449207305908, "step": 133000}
{"episode_reward": 876.7341620273522, "episode": 134.0, "batch_reward": 0.4317303179204464, "critic_loss": 1.228612777531147, "actor_loss": -73.01028661346436, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.40861678123474, "step": 134000}
{"episode_reward": 327.4330718847317, "episode": 135.0, "batch_reward": 0.43316372177004814, "critic_loss": 1.267230032324791, "actor_loss": -72.02570182800292, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.666191339492798, "step": 135000}
{"episode_reward": 917.0041499399072, "episode": 136.0, "batch_reward": 0.4405844598412514, "critic_loss": 1.291456708908081, "actor_loss": -72.5622657699585, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.376611709594727, "step": 136000}
{"episode_reward": 900.2865485668968, "episode": 137.0, "batch_reward": 0.44169771537184715, "critic_loss": 1.3373111508488655, "actor_loss": -72.4608886566162, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.395044326782227, "step": 137000}
{"episode_reward": 891.411442951044, "episode": 138.0, "batch_reward": 0.4452559405863285, "critic_loss": 1.3275636593103408, "actor_loss": -72.46913707733154, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.386584043502808, "step": 138000}
{"episode_reward": 845.7820727891304, "episode": 139.0, "batch_reward": 0.447829224139452, "critic_loss": 1.292312128007412, "actor_loss": -73.02766636657715, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.429737329483032, "step": 139000}
{"episode_reward": 914.1071978518518, "episode": 140.0, "batch_reward": 0.4494569510221481, "critic_loss": 1.2828154712319375, "actor_loss": -73.19971321105957, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.43420386314392, "step": 140000}
{"episode_reward": 893.7877507685685, "episode": 141.0, "batch_reward": 0.4539778465628624, "critic_loss": 1.2733394172787666, "actor_loss": -73.43970434570312, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.54701590538025, "step": 141000}
{"episode_reward": 885.1449746129663, "episode": 142.0, "batch_reward": 0.45671737772226334, "critic_loss": 1.2313733661174775, "actor_loss": -73.98453618621826, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.423381090164185, "step": 142000}
{"episode_reward": 950.5817935715226, "episode": 143.0, "batch_reward": 0.45899640184640883, "critic_loss": 1.190983584702015, "actor_loss": -74.21501487731933, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.44991636276245, "step": 143000}
{"episode_reward": 849.9733220436945, "episode": 144.0, "batch_reward": 0.46377424931526184, "critic_loss": 1.190593986093998, "actor_loss": -74.19580125427247, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.414387941360474, "step": 144000}
{"episode_reward": 869.3729076659544, "episode": 145.0, "batch_reward": 0.4678344230055809, "critic_loss": 1.1653286631703377, "actor_loss": -74.69637353515625, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.435226440429688, "step": 145000}
{"episode_reward": 915.5389321447378, "episode": 146.0, "batch_reward": 0.4688034524321556, "critic_loss": 1.1777713171839714, "actor_loss": -75.39497868347168, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.430027961730957, "step": 146000}
{"episode_reward": 887.0225003512114, "episode": 147.0, "batch_reward": 0.47212947154045104, "critic_loss": 1.1953826093673705, "actor_loss": -75.22379774475098, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.42181158065796, "step": 147000}
{"episode_reward": 899.6950994872057, "episode": 148.0, "batch_reward": 0.4750028633475304, "critic_loss": 1.2012818155884744, "actor_loss": -75.39409668731689, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.69033908843994, "step": 148000}
{"episode_reward": 954.9908672569236, "episode": 149.0, "batch_reward": 0.479111699283123, "critic_loss": 1.2130647171735764, "actor_loss": -75.71021589660644, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.53626251220703, "step": 149000}
{"episode_reward": 914.3077501537546, "episode": 150.0, "batch_reward": 0.4834740555882454, "critic_loss": 1.1970261208415032, "actor_loss": -76.09648252868652, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "step": 150000}
