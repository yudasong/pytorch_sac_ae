{"episode": 1.0, "duration": 24.486957550048828, "episode_reward": 28.177075776326152, "step": 1000}
{"episode": 2.0, "duration": 2.0339066982269287, "episode_reward": 69.84046218736019, "step": 2000}
{"episode": 3.0, "batch_reward": 0.050153662755255624, "actor_loss": -79.78297927447346, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499180007, "duration": 54.37061524391174, "episode_reward": 55.652699805092745, "step": 3000}
{"episode": 4.0, "batch_reward": 0.0493765956684947, "actor_loss": -76.42604113769531, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.152470111846924, "episode_reward": 25.937577222127906, "step": 4000}
{"episode": 5.0, "batch_reward": 0.05154027335718274, "actor_loss": -75.31371549987793, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.473074197769165, "episode_reward": 74.96188932258825, "step": 5000}
{"episode": 6.0, "batch_reward": 0.048328378222882745, "actor_loss": -74.18228045654297, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.23250460624695, "episode_reward": 16.25453891452411, "step": 6000}
{"episode": 7.0, "batch_reward": 0.04996879129856825, "actor_loss": -73.29140682983399, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.755723237991333, "episode_reward": 64.84143565791148, "step": 7000}
{"episode": 8.0, "batch_reward": 0.04627865190804005, "actor_loss": -72.5294402923584, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.07636857032776, "episode_reward": 16.27474479323367, "step": 8000}
{"episode": 9.0, "batch_reward": 0.049989135649055244, "actor_loss": -72.63163606262206, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.21756887435913, "episode_reward": 139.86014427244064, "step": 9000}
{"episode": 10.0, "batch_reward": 0.05876836943998933, "actor_loss": -66.22702462005616, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 4089.2599959373474, "episode_reward": 109.1799329766173, "step": 10000}
{"episode": 11.0, "batch_reward": 0.06122364146262407, "actor_loss": -67.45481739807128, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 37.97805213928223, "episode_reward": 82.70412426542734, "step": 11000}
{"episode": 12.0, "batch_reward": 0.07015900262817741, "actor_loss": -63.942258506774905, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 438.2651240825653, "episode_reward": 272.88497389995183, "step": 12000}
{"episode": 13.0, "batch_reward": 0.08654843178763985, "actor_loss": -65.48964140319825, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.045034885406494, "episode_reward": 227.5883985761104, "step": 13000}
{"episode": 14.0, "batch_reward": 0.09459647900611162, "actor_loss": -63.23433388519287, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 448.46392250061035, "episode_reward": 239.26186067331798, "step": 14000}
{"episode": 15.0, "batch_reward": 0.11044496345520019, "actor_loss": -64.75580651855469, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.23170757293701, "episode_reward": 356.837689042272, "step": 15000}
{"episode": 16.0, "batch_reward": 0.11861310958862305, "actor_loss": -62.21030096435547, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 445.91724967956543, "episode_reward": 74.00310195055135, "step": 16000}
{"episode": 17.0, "batch_reward": 0.11756643795967102, "actor_loss": -62.572187438964846, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.45163059234619, "episode_reward": 132.7430651271513, "step": 17000}
{"episode": 18.0, "batch_reward": 0.12400293456763029, "actor_loss": -60.33959244537353, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 433.79711294174194, "episode_reward": 310.4237292713016, "step": 18000}
{"episode": 19.0, "batch_reward": 0.1352890552803874, "actor_loss": -61.10740955352783, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.966918230056763, "episode_reward": 290.21294399541307, "step": 19000}
{"episode": 20.0, "batch_reward": 0.1346191531047225, "actor_loss": -60.12452931213379, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 441.87043285369873, "episode_reward": 67.73668133437448, "step": 20000}
{"episode": 21.0, "batch_reward": 0.13295638316124678, "actor_loss": -60.6531039352417, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 45.26335430145264, "episode_reward": 107.96010066768837, "step": 21000}
{"episode": 22.0, "batch_reward": 0.13433315274119378, "actor_loss": -60.4999178314209, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 439.2156915664673, "episode_reward": 193.31985806158252, "step": 22000}
{"episode": 23.0, "batch_reward": 0.13878226289153098, "actor_loss": -61.42260385131836, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.05268955230713, "episode_reward": 272.1075916236337, "step": 23000}
{"episode": 24.0, "batch_reward": 0.13865535947680474, "actor_loss": -59.31473992919922, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 455.0601472854614, "episode_reward": 80.3677110635128, "step": 24000}
{"episode": 25.0, "batch_reward": 0.13624859461188316, "actor_loss": -59.51329672241211, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.48174214363098, "episode_reward": 67.04158202502492, "step": 25000}
{"episode": 26.0, "batch_reward": 0.13466868701577187, "actor_loss": -57.41481296539307, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 440.0122916698456, "episode_reward": 105.93995989390731, "step": 26000}
{"episode": 27.0, "batch_reward": 0.1358694141730666, "actor_loss": -57.56834118652344, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.78373122215271, "episode_reward": 161.62328487573387, "step": 27000}
{"episode": 28.0, "batch_reward": 0.13405955248326062, "actor_loss": -57.100752143859864, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 445.85963797569275, "episode_reward": 58.97348554613336, "step": 28000}
{"episode": 29.0, "batch_reward": 0.13529765225946902, "actor_loss": -57.299524658203126, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.682634353637695, "episode_reward": 385.8693939088583, "step": 29000}
{"episode": 30.0, "batch_reward": 0.1424864671602845, "actor_loss": -57.8473034286499, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 442.7734477519989, "episode_reward": 216.43008878400374, "step": 30000}
{"episode": 31.0, "batch_reward": 0.14414918871968985, "actor_loss": -58.426659286499024, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 44.72209811210632, "episode_reward": 154.53746132217697, "step": 31000}
{"episode": 32.0, "batch_reward": 0.14717629876732827, "actor_loss": -57.35159218597412, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 441.59020829200745, "episode_reward": 330.78699883394796, "step": 32000}
{"episode": 33.0, "batch_reward": 0.14804210042953492, "actor_loss": -58.08334716033936, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.094985008239746, "episode_reward": 70.54349262067062, "step": 33000}
{"episode": 34.0, "batch_reward": 0.15193097540736197, "actor_loss": -55.94946115875244, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 449.40144324302673, "episode_reward": 445.25656304725044, "step": 34000}
{"episode": 35.0, "batch_reward": 0.1588274525180459, "actor_loss": -56.603352172851565, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.969779014587402, "episode_reward": 372.8439860336374, "step": 35000}
{"episode": 36.0, "batch_reward": 0.1606551497131586, "actor_loss": -56.844513412475585, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 441.4546408653259, "episode_reward": 101.69592516423172, "step": 36000}
{"episode": 37.0, "batch_reward": 0.16370796172320842, "actor_loss": -57.177364112854, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.8599534034729, "episode_reward": 381.64046322714614, "step": 37000}
{"episode": 38.0, "batch_reward": 0.16825782130658626, "actor_loss": -58.85429570770264, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 447.56514620780945, "episode_reward": 334.52462038588726, "step": 38000}
{"episode": 39.0, "batch_reward": 0.1729195585846901, "actor_loss": -59.40538935089111, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.002948999404907, "episode_reward": 264.81943868877687, "step": 39000}
{"episode": 40.0, "batch_reward": 0.17710814580321313, "actor_loss": -58.235567283630374, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 444.1746451854706, "episode_reward": 452.38428307493996, "step": 40000}
{"episode": 41.0, "batch_reward": 0.18392848186939956, "actor_loss": -58.79462914276123, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.63540244102478, "episode_reward": 421.36456801769674, "step": 41000}
{"episode": 42.0, "batch_reward": 0.1882067874073982, "actor_loss": -60.62290508270264, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 438.79829144477844, "episode_reward": 422.70496760822897, "step": 42000}
{"episode": 43.0, "batch_reward": 0.19498570148646832, "actor_loss": -61.113953758239745, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 15.994039535522461, "episode_reward": 476.8856087668257, "step": 43000}
{"episode": 44.0, "batch_reward": 0.20123843164741992, "actor_loss": -62.532882263183595, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 447.82575011253357, "episode_reward": 410.18731408781156, "step": 44000}
{"episode": 45.0, "batch_reward": 0.20338521005213261, "actor_loss": -62.61937503051758, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.140605211257935, "episode_reward": 297.4883985926876, "step": 45000}
{"episode": 46.0, "batch_reward": 0.20474293038249017, "actor_loss": -63.84612674713135, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 433.72897839546204, "episode_reward": 91.10230008833454, "step": 46000}
{"episode": 47.0, "batch_reward": 0.20250224941968917, "actor_loss": -63.7925004272461, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.15515398979187, "episode_reward": 137.51594360627362, "step": 47000}
{"episode": 48.0, "batch_reward": 0.20544741326570512, "actor_loss": -61.878535583496095, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 447.9676442146301, "episode_reward": 412.6652623456465, "step": 48000}
{"episode": 49.0, "batch_reward": 0.2078628466129303, "actor_loss": -62.023646003723144, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.69132161140442, "episode_reward": 295.28848106818197, "step": 49000}
{"episode": 50.0, "batch_reward": 0.2104227435439825, "actor_loss": -60.672791625976565, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 441.94645261764526, "episode_reward": 509.13197776890036, "step": 50000}
{"episode": 51.0, "batch_reward": 0.21636701487004756, "actor_loss": -61.34509680938721, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.07551622390747, "episode_reward": 554.3985599421525, "step": 51000}
{"episode": 52.0, "batch_reward": 0.22207411155104637, "actor_loss": -61.02537344360351, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 440.47152376174927, "episode_reward": 464.7432331407781, "step": 52000}
{"episode": 53.0, "batch_reward": 0.22659144604206086, "actor_loss": -61.454867446899414, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.407257080078125, "episode_reward": 425.9342917610324, "step": 53000}
{"episode": 54.0, "batch_reward": 0.2302052083015442, "actor_loss": -61.4355606842041, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 435.9380633831024, "episode_reward": 439.524415964575, "step": 54000}
{"episode": 55.0, "batch_reward": 0.23137413810193538, "actor_loss": -61.51773380279541, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.063343286514282, "episode_reward": 106.05222137378281, "step": 55000}
{"episode": 56.0, "batch_reward": 0.23045310886204243, "actor_loss": -60.858514945983885, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 423.0669083595276, "episode_reward": 371.2241215366869, "step": 56000}
{"episode": 57.0, "batch_reward": 0.23183191898465155, "actor_loss": -60.99972911071777, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.016045808792114, "episode_reward": 120.20399254593661, "step": 57000}
{"episode": 58.0, "batch_reward": 0.2307597920447588, "actor_loss": -62.07255928039551, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 425.503963470459, "episode_reward": 281.614371421195, "step": 58000}
{"episode": 59.0, "batch_reward": 0.23211358304321766, "actor_loss": -62.334655174255374, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.839807748794556, "episode_reward": 383.58894670147055, "step": 59000}
{"episode": 60.0, "batch_reward": 0.2363783473968506, "actor_loss": -63.18675735473633, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 426.90552377700806, "episode_reward": 406.9117758830225, "step": 60000}
{"episode": 61.0, "batch_reward": 0.23902437138557434, "actor_loss": -63.457753356933594, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 37.689945220947266, "episode_reward": 462.7913971374665, "step": 61000}
{"episode": 62.0, "batch_reward": 0.24345983865857124, "actor_loss": -64.50670733642578, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 430.9757032394409, "episode_reward": 476.9582199666099, "step": 62000}
{"episode": 63.0, "batch_reward": 0.24268721850216388, "actor_loss": -64.61474632263183, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.859850883483887, "episode_reward": 60.39866024360011, "step": 63000}
{"episode": 64.0, "batch_reward": 0.24445417173206807, "actor_loss": -63.29365622711182, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 429.3080017566681, "episode_reward": 476.54653719131477, "step": 64000}
{"episode": 65.0, "batch_reward": 0.24401023828983306, "actor_loss": -63.25421188354492, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.960295915603638, "episode_reward": 65.56278022395489, "step": 65000}
{"episode": 66.0, "batch_reward": 0.24365309673547744, "actor_loss": -63.31475740814209, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 425.51521134376526, "episode_reward": 513.9924480582429, "step": 66000}
{"episode": 67.0, "batch_reward": 0.24764291037619113, "actor_loss": -63.6438850479126, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.863526821136475, "episode_reward": 507.4384654779239, "step": 67000}
{"episode": 68.0, "batch_reward": 0.25281613650918006, "actor_loss": -62.116445976257324, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 429.30576491355896, "episode_reward": 419.03487214221815, "step": 68000}
{"episode": 69.0, "batch_reward": 0.2540629252791405, "actor_loss": -62.28172143554688, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.949224710464478, "episode_reward": 454.39473840541854, "step": 69000}
{"episode": 70.0, "batch_reward": 0.2548907409310341, "actor_loss": -64.40012369537354, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 422.5113046169281, "episode_reward": 168.6934985135476, "step": 70000}
{"episode": 71.0, "batch_reward": 0.2536568910330534, "actor_loss": -64.45011515808106, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 39.80141830444336, "episode_reward": 98.74352691599418, "step": 71000}
{"episode": 72.0, "batch_reward": 0.2527845672667027, "actor_loss": -63.662817367553714, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 432.91328597068787, "episode_reward": 382.9874627122353, "step": 72000}
{"episode": 73.0, "batch_reward": 0.2564237918406725, "actor_loss": -63.945656074523924, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.820268154144287, "episode_reward": 479.8207753110765, "step": 73000}
{"episode": 74.0, "batch_reward": 0.25885835257172585, "actor_loss": -64.53784507751465, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 430.58739280700684, "episode_reward": 508.12194202658264, "step": 74000}
{"episode": 75.0, "batch_reward": 0.2617753260284662, "actor_loss": -64.79492636871338, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.977636575698853, "episode_reward": 400.7385178005673, "step": 75000}
{"episode": 76.0, "batch_reward": 0.2622834780216217, "actor_loss": -64.92600387573242, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 435.65868735313416, "episode_reward": 417.6409721519588, "step": 76000}
{"episode": 77.0, "batch_reward": 0.26652525559067725, "actor_loss": -65.32051235961914, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.805808305740356, "episode_reward": 524.8108082846848, "step": 77000}
{"episode": 78.0, "batch_reward": 0.26684885904192923, "actor_loss": -64.24868505859375, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 430.97898054122925, "episode_reward": 75.87360052637172, "step": 78000}
{"episode": 79.0, "batch_reward": 0.26829618844389913, "actor_loss": -64.41343490600586, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.52828288078308, "episode_reward": 473.4039345437447, "step": 79000}
{"episode": 80.0, "batch_reward": 0.2709588513821363, "actor_loss": -65.1940071258545, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 433.4842474460602, "episode_reward": 532.6618966864519, "step": 80000}
{"episode": 81.0, "batch_reward": 0.27296934913098814, "actor_loss": -65.38323195648194, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 36.2750449180603, "episode_reward": 461.6682041385787, "step": 81000}
{"episode": 82.0, "batch_reward": 0.2722499739378691, "actor_loss": -66.4102100982666, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 436.29190278053284, "episode_reward": 164.27609577152742, "step": 82000}
{"episode": 83.0, "batch_reward": 0.27276849013566973, "actor_loss": -66.28790405273438, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.878010034561157, "episode_reward": 465.4250635484451, "step": 83000}
{"episode": 84.0, "batch_reward": 0.2766554089039564, "actor_loss": -66.44422744750976, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 435.40309262275696, "episode_reward": 493.4376149769772, "step": 84000}
{"episode": 85.0, "batch_reward": 0.27849555280804633, "actor_loss": -66.45882715606689, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.497191190719604, "episode_reward": 461.53198063329, "step": 85000}
{"episode": 86.0, "batch_reward": 0.28117753958702085, "actor_loss": -65.16051570129395, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 451.116406917572, "episode_reward": 503.10737047796044, "step": 86000}
{"episode": 87.0, "batch_reward": 0.2825539079159498, "actor_loss": -65.3963090209961, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.653620958328247, "episode_reward": 467.833217966398, "step": 87000}
{"episode": 88.0, "batch_reward": 0.285853296995163, "actor_loss": -65.4655905456543, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 440.5641074180603, "episode_reward": 495.1686694819814, "step": 88000}
{"episode": 89.0, "batch_reward": 0.28684776243567467, "actor_loss": -65.51620001983643, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.668614864349365, "episode_reward": 522.9141167362452, "step": 89000}
{"episode": 90.0, "batch_reward": 0.29168506868183613, "actor_loss": -65.93901031494141, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 446.29284954071045, "episode_reward": 476.4660076129415, "step": 90000}
{"episode": 91.0, "batch_reward": 0.2940870365053415, "actor_loss": -66.08312926483154, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 37.101811170578, "episode_reward": 510.6944506357037, "step": 91000}
{"episode": 92.0, "batch_reward": 0.29503272503614425, "actor_loss": -66.0134753112793, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 435.92145252227783, "episode_reward": 502.36975682182657, "step": 92000}
{"episode": 93.0, "batch_reward": 0.2987050149291754, "actor_loss": -66.2961226196289, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.187076568603516, "episode_reward": 543.3911644377321, "step": 93000}
{"episode": 94.0, "batch_reward": 0.3003486693948507, "actor_loss": -66.35400545501709, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 441.3920030593872, "episode_reward": 497.316457058068, "step": 94000}
{"episode": 95.0, "batch_reward": 0.30004084123671054, "actor_loss": -66.45023619079589, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.15701413154602, "episode_reward": 309.70832607717483, "step": 95000}
{"episode": 96.0, "batch_reward": 0.30266790157556533, "actor_loss": -67.36472925567627, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 444.31777262687683, "episode_reward": 527.1561310083941, "step": 96000}
{"episode": 97.0, "batch_reward": 0.3039180362969637, "actor_loss": -67.51783232879639, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.527039766311646, "episode_reward": 490.586708608672, "step": 97000}
{"episode": 98.0, "batch_reward": 0.3064861145615578, "actor_loss": -67.7207597808838, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 443.86129570007324, "episode_reward": 546.7413408660138, "step": 98000}
{"episode": 99.0, "batch_reward": 0.30956446449458597, "actor_loss": -67.94862742614747, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.571532249450684, "episode_reward": 493.79130564159817, "step": 99000}
{"episode": 100.0, "batch_reward": 0.3104086801409721, "actor_loss": -67.2815463180542, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 434.2028977870941, "episode_reward": 526.6998850558649, "step": 100000}
{"episode": 101.0, "batch_reward": 0.3132291671782732, "actor_loss": -67.51061125946045, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.95136070251465, "episode_reward": 612.4487319101524, "step": 101000}
{"episode": 102.0, "batch_reward": 0.31684474751353264, "actor_loss": -68.68564112854004, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 443.07102227211, "episode_reward": 560.5556959511687, "step": 102000}
{"episode": 103.0, "batch_reward": 0.31788626781105994, "actor_loss": -68.83591682434081, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.129819631576538, "episode_reward": 391.6883125199048, "step": 103000}
{"episode": 104.0, "batch_reward": 0.31835494543612003, "actor_loss": -68.80493109130859, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 440.9061436653137, "episode_reward": 435.54802756584024, "step": 104000}
{"episode": 105.0, "batch_reward": 0.3193399108946323, "actor_loss": -68.96092056274414, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.23859667778015, "episode_reward": 603.5209200834665, "step": 105000}
{"episode": 106.0, "batch_reward": 0.32164661902189257, "actor_loss": -69.19480252075195, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 442.12099957466125, "episode_reward": 457.65736316044223, "step": 106000}
{"episode": 107.0, "batch_reward": 0.3235818860828876, "actor_loss": -69.33383477783204, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.3686842918396, "episode_reward": 567.2118772711575, "step": 107000}
{"episode": 108.0, "batch_reward": 0.324578111320734, "actor_loss": -69.23076039123535, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 449.4532949924469, "episode_reward": 18.684475966001585, "step": 108000}
{"episode": 109.0, "batch_reward": 0.3236817883104086, "actor_loss": -69.29322827148438, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.79867458343506, "episode_reward": 577.3372576450427, "step": 109000}
{"episode": 110.0, "batch_reward": 0.32550552880764005, "actor_loss": -68.46210990905762, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 438.8167521953583, "episode_reward": 565.5508494582633, "step": 110000}
{"episode": 111.0, "batch_reward": 0.32976588974893095, "actor_loss": -68.69353977966308, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 40.85201025009155, "episode_reward": 615.9033066524785, "step": 111000}
{"episode": 112.0, "batch_reward": 0.33096176612377165, "actor_loss": -68.45996215820313, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 447.0908000469208, "episode_reward": 541.6341876353163, "step": 112000}
{"episode": 113.0, "batch_reward": 0.3310823630988598, "actor_loss": -68.57142189788819, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.70484757423401, "episode_reward": 233.9565403334971, "step": 113000}
{"episode": 114.0, "batch_reward": 0.332331299379468, "actor_loss": -68.32068067932128, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 448.60579800605774, "episode_reward": 548.8195413588463, "step": 114000}
{"episode": 115.0, "batch_reward": 0.3340814646482468, "actor_loss": -68.41356161499023, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.914212942123413, "episode_reward": 494.4899706384572, "step": 115000}
{"episode": 116.0, "batch_reward": 0.33547205209732056, "actor_loss": -68.1665125579834, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 442.8374693393707, "episode_reward": 594.6892532261172, "step": 116000}
{"episode": 117.0, "batch_reward": 0.3368438676595688, "actor_loss": -68.39422244262695, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.19508123397827, "episode_reward": 497.067285224321, "step": 117000}
{"episode": 118.0, "batch_reward": 0.3379858590364456, "actor_loss": -68.16286349487305, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 445.0305075645447, "episode_reward": 477.75992093859, "step": 118000}
{"episode": 119.0, "batch_reward": 0.34067782694101334, "actor_loss": -68.41990591430664, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.76185369491577, "episode_reward": 324.711923779153, "step": 119000}
{"episode": 120.0, "batch_reward": 0.3409021039009094, "actor_loss": -68.85037078094483, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 450.7517931461334, "episode_reward": 519.1180760727337, "step": 120000}
{"episode": 121.0, "batch_reward": 0.3424428953826427, "actor_loss": -68.8875590209961, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.60356616973877, "episode_reward": 533.2737695369764, "step": 121000}
{"episode": 122.0, "batch_reward": 0.34286172804236414, "actor_loss": -68.23941494750977, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 441.9233708381653, "episode_reward": 446.0349504118174, "step": 122000}
{"episode": 123.0, "batch_reward": 0.3410797554254532, "actor_loss": -68.24839524841309, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.21792221069336, "episode_reward": 402.7417190415762, "step": 123000}
{"episode": 124.0, "batch_reward": 0.3433691650927067, "actor_loss": -66.56533210754395, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 447.0247845649719, "episode_reward": 543.5703121440282, "step": 124000}
{"episode": 125.0, "batch_reward": 0.3456817699968815, "actor_loss": -66.88389296722413, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.389657258987427, "episode_reward": 593.9439831972378, "step": 125000}
{"episode": 126.0, "batch_reward": 0.34856174492836, "actor_loss": -66.66430729675292, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 440.25044345855713, "episode_reward": 426.1300853896559, "step": 126000}
{"episode": 127.0, "batch_reward": 0.35054106485843656, "actor_loss": -66.74523295593262, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.754031658172607, "episode_reward": 473.9930272805638, "step": 127000}
{"episode": 128.0, "batch_reward": 0.3504156867861748, "actor_loss": -66.99876933288574, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 447.39682245254517, "episode_reward": 507.88084387578135, "step": 128000}
{"episode": 129.0, "batch_reward": 0.35040288454294205, "actor_loss": -67.10787705993653, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.32584047317505, "episode_reward": 543.7981135713705, "step": 129000}
{"episode": 130.0, "batch_reward": 0.35114690670371057, "actor_loss": -67.07062721252441, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 442.2228548526764, "episode_reward": 554.7899939301011, "step": 130000}
{"episode": 131.0, "batch_reward": 0.352263640999794, "actor_loss": -67.03859467315674, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.22273111343384, "episode_reward": 585.8714062731359, "step": 131000}
{"episode": 132.0, "batch_reward": 0.3545851480662823, "actor_loss": -67.54557120513915, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 438.0691077709198, "episode_reward": 446.2978072257732, "step": 132000}
{"episode": 133.0, "batch_reward": 0.3552892725467682, "actor_loss": -67.77973934173583, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.678012371063232, "episode_reward": 522.8332495818499, "step": 133000}
{"episode": 134.0, "batch_reward": 0.35710955974459646, "actor_loss": -68.15799285888671, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 441.67360258102417, "episode_reward": 388.7653701340948, "step": 134000}
{"episode": 135.0, "batch_reward": 0.3570539086461067, "actor_loss": -68.20110601043702, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 19.291985273361206, "episode_reward": 571.619526405195, "step": 135000}
{"episode": 136.0, "batch_reward": 0.3595455077588558, "actor_loss": -69.44636201477051, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 442.657434463501, "episode_reward": 497.9173129481503, "step": 136000}
{"episode": 137.0, "batch_reward": 0.36033184027671816, "actor_loss": -69.48717556762695, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.755539655685425, "episode_reward": 546.5287047170099, "step": 137000}
{"episode": 138.0, "batch_reward": 0.36015271323919296, "actor_loss": -70.99876927185059, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 447.2135169506073, "episode_reward": 534.685665888372, "step": 138000}
{"episode": 139.0, "batch_reward": 0.3622275624871254, "actor_loss": -70.9669711151123, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.478327751159668, "episode_reward": 540.7650364478224, "step": 139000}
{"episode": 140.0, "batch_reward": 0.3642175250351429, "actor_loss": -72.01628038024903, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 442.81130862236023, "episode_reward": 620.4558993624787, "step": 140000}
{"episode": 141.0, "batch_reward": 0.36539853903651237, "actor_loss": -71.93473190307617, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 38.99516296386719, "episode_reward": 543.4600557975032, "step": 141000}
{"episode": 142.0, "batch_reward": 0.3659926247596741, "actor_loss": -71.12687089538574, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 419.61489367485046, "episode_reward": 627.5429527368154, "step": 142000}
{"episode": 143.0, "batch_reward": 0.3670123890936375, "actor_loss": -71.34066670227051, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 17.081772089004517, "episode_reward": 490.5035449283657, "step": 143000}
{"episode": 144.0, "batch_reward": 0.3700217835903168, "actor_loss": -70.91051011657714, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 430.8093457221985, "episode_reward": 485.8838225105796, "step": 144000}
{"episode": 145.0, "batch_reward": 0.37149289274215697, "actor_loss": -71.04409889221192, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.423254013061523, "episode_reward": 583.7470425202381, "step": 145000}
{"episode": 146.0, "batch_reward": 0.37200025177001955, "actor_loss": -70.1719888458252, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 419.78533959388733, "episode_reward": 505.73373650067657, "step": 146000}
{"episode": 147.0, "batch_reward": 0.3736827305853367, "actor_loss": -70.48038298034668, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 18.893181800842285, "episode_reward": 533.0417844061168, "step": 147000}
{"episode": 148.0, "batch_reward": 0.37450370648503306, "actor_loss": -70.48173770141601, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 429.148558139801, "episode_reward": 626.1687383721181, "step": 148000}
{"episode": 149.0, "batch_reward": 0.3745427460372448, "actor_loss": -70.31376263427734, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 16.13156819343567, "episode_reward": 600.5961202327273, "step": 149000}
{"episode": 150.0, "batch_reward": 0.37702056124806405, "actor_loss": -70.54077978515625, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "step": 150000}
