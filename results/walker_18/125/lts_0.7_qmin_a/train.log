{"episode_reward": 0.0, "episode": 1.0, "duration": 22.127557039260864, "step": 1000}
{"episode_reward": 28.177075776326152, "episode": 2.0, "duration": 1.8804652690887451, "step": 2000}
{"episode_reward": 69.84046218736019, "episode": 3.0, "batch_reward": 0.04693736313342571, "critic_loss": 0.010780782206216904, "actor_loss": -57.27334987265425, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499180007, "duration": 62.8661162853241, "step": 3000}
{"episode_reward": 12.376561115156614, "episode": 4.0, "batch_reward": 0.03796191956847906, "critic_loss": 0.0027368216469767503, "actor_loss": -56.55514585697651, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.206229209899902, "step": 4000}
{"episode_reward": 42.262738188871914, "episode": 5.0, "batch_reward": 0.03802323986589909, "critic_loss": 0.00430008265923243, "actor_loss": -50.57633070552349, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.802751541137695, "step": 5000}
{"episode_reward": 38.782258739346, "episode": 6.0, "batch_reward": 0.04198261931911111, "critic_loss": 0.006787423640955239, "actor_loss": -53.98919659435749, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.422534704208374, "step": 6000}
{"episode_reward": 76.09742811289058, "episode": 7.0, "batch_reward": 0.046020746521651744, "critic_loss": 0.009757895112270489, "actor_loss": -59.98222832751274, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.70950961112976, "step": 7000}
{"episode_reward": 62.08448676508375, "episode": 8.0, "batch_reward": 0.04545092505216598, "critic_loss": 0.013376297052949668, "actor_loss": -55.517443026185035, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.889830827713013, "step": 8000}
{"episode_reward": 19.37242306704891, "episode": 9.0, "batch_reward": 0.043989600464701656, "critic_loss": 0.012059838307090103, "actor_loss": -54.05535721898079, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.50916028022766, "step": 9000}
{"episode_reward": 41.3372854730775, "episode": 10.0, "batch_reward": 0.044554699447005984, "critic_loss": 0.010511200798675418, "actor_loss": -53.77034361058474, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.137561082839966, "step": 10000}
{"episode_reward": 68.69798742186872, "episode": 11.0, "batch_reward": 0.04675197199732065, "critic_loss": 0.013349634399171919, "actor_loss": -55.243907016158104, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.94180226325989, "step": 11000}
{"episode_reward": 62.48992350408893, "episode": 12.0, "batch_reward": 0.04774284729361534, "critic_loss": 0.015802687889896333, "actor_loss": -52.411662051171064, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.668654918670654, "step": 12000}
{"episode_reward": 34.06954701481379, "episode": 13.0, "batch_reward": 0.045373410943895576, "critic_loss": 0.015248347632121295, "actor_loss": -52.72757579274476, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.03842544555664, "step": 13000}
{"episode_reward": 16.782159981904663, "episode": 14.0, "batch_reward": 0.04491723810881376, "critic_loss": 0.017878904397133737, "actor_loss": -50.47189589676261, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.524309873580933, "step": 14000}
{"episode_reward": 65.71460463285878, "episode": 15.0, "batch_reward": 0.04690777520090342, "critic_loss": 0.0209294178574346, "actor_loss": -58.12365108927712, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.424968719482422, "step": 15000}
{"episode_reward": 71.8012676624279, "episode": 16.0, "batch_reward": 0.04779234182089567, "critic_loss": 0.023151364978402852, "actor_loss": -55.41430266768485, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.82050061225891, "step": 16000}
{"episode_reward": 64.97442256609283, "episode": 17.0, "batch_reward": 0.047998563267290593, "critic_loss": 0.028958407251164317, "actor_loss": -53.0285293187052, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.546926975250244, "step": 17000}
{"episode_reward": 45.83486677550385, "episode": 18.0, "batch_reward": 0.04967856226116419, "critic_loss": 0.04032072908803821, "actor_loss": -53.69814352499694, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.258570671081543, "step": 18000}
{"episode_reward": 84.34472926816068, "episode": 19.0, "batch_reward": 0.049561735074967146, "critic_loss": 0.044884186321869496, "actor_loss": -53.094968077003955, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.287492752075195, "step": 19000}
{"episode_reward": 19.667545817181782, "episode": 20.0, "batch_reward": 0.04961327188462019, "critic_loss": 0.040460594532079994, "actor_loss": -55.05217244800925, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.40151596069336, "step": 20000}
{"episode_reward": 85.65795138604558, "episode": 21.0, "batch_reward": 0.05163428958132863, "critic_loss": 0.04124040855746716, "actor_loss": -55.71682187592983, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.66676425933838, "step": 21000}
{"episode_reward": 80.82384457245158, "episode": 22.0, "batch_reward": 0.053120010506361726, "critic_loss": 0.046038227428682146, "actor_loss": -54.250098700523374, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.68267560005188, "step": 22000}
{"episode_reward": 88.76824716764382, "episode": 23.0, "batch_reward": 0.0545006088539958, "critic_loss": 0.045195123188197614, "actor_loss": -55.9841409676075, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.910524368286133, "step": 23000}
{"episode_reward": 87.2377312057819, "episode": 24.0, "batch_reward": 0.05558401836082339, "critic_loss": 0.04545358778350055, "actor_loss": -56.1144820253849, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.55572199821472, "step": 24000}
{"episode_reward": 75.89200719217608, "episode": 25.0, "batch_reward": 0.05643750346451998, "critic_loss": 0.041717528719455006, "actor_loss": -53.55528049945831, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.099587440490723, "step": 25000}
{"episode_reward": 70.33110267194446, "episode": 26.0, "batch_reward": 0.056983297042548654, "critic_loss": 0.04813227095454931, "actor_loss": -54.87056466126442, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.16572117805481, "step": 26000}
{"episode_reward": 76.96845197801747, "episode": 27.0, "batch_reward": 0.05754776427522302, "critic_loss": 0.0452717422824353, "actor_loss": -55.34741806268692, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.422624111175537, "step": 27000}
{"episode_reward": 70.05553325491864, "episode": 28.0, "batch_reward": 0.05822775253653526, "critic_loss": 0.04309439017716795, "actor_loss": -53.56360070633888, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.50013566017151, "step": 28000}
{"episode_reward": 84.11175479783932, "episode": 29.0, "batch_reward": 0.05906179554760456, "critic_loss": 0.04466665436141193, "actor_loss": -55.84725066828728, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.249738216400146, "step": 29000}
{"episode_reward": 59.35655579492315, "episode": 30.0, "batch_reward": 0.05833939836919308, "critic_loss": 0.03990977513231337, "actor_loss": -53.71304093670845, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.629650354385376, "step": 30000}
{"episode_reward": 55.94295255990912, "episode": 31.0, "batch_reward": 0.05789637340977788, "critic_loss": 0.035698650426231326, "actor_loss": -55.82181215190887, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.68791127204895, "step": 31000}
{"episode_reward": 15.953665512563294, "episode": 32.0, "batch_reward": 0.05742245861887932, "critic_loss": 0.03705314190033823, "actor_loss": -53.61570594000816, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.61049485206604, "step": 32000}
{"episode_reward": 49.90002307392212, "episode": 33.0, "batch_reward": 0.057651567477732896, "critic_loss": 0.039091388289816675, "actor_loss": -56.34670102643967, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.910379648208618, "step": 33000}
{"episode_reward": 81.24506741860046, "episode": 34.0, "batch_reward": 0.059211369086056946, "critic_loss": 0.03748084428906441, "actor_loss": -52.95941901469231, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.40939497947693, "step": 34000}
{"episode_reward": 96.73820788628773, "episode": 35.0, "batch_reward": 0.05839713675528765, "critic_loss": 0.040607235773466525, "actor_loss": -55.32531517505646, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.116549253463745, "step": 35000}
{"episode_reward": 17.337845522195213, "episode": 36.0, "batch_reward": 0.058833370227366684, "critic_loss": 0.03561050426866859, "actor_loss": -51.34645766782761, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.797038078308105, "step": 36000}
{"episode_reward": 102.48795103516751, "episode": 37.0, "batch_reward": 0.0615176892504096, "critic_loss": 0.047283251178450884, "actor_loss": -53.98102901291847, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.431283950805664, "step": 37000}
{"episode_reward": 190.29694314093132, "episode": 38.0, "batch_reward": 0.06332262882590294, "critic_loss": 0.057081098860129714, "actor_loss": -55.303201794862744, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.983550786972046, "step": 38000}
{"episode_reward": 94.52118356934737, "episode": 39.0, "batch_reward": 0.06525086718797683, "critic_loss": 0.06636404959112406, "actor_loss": -55.83078390645981, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.754765033721924, "step": 39000}
{"episode_reward": 180.73229971573886, "episode": 40.0, "batch_reward": 0.06859166533872485, "critic_loss": 0.09003056657500565, "actor_loss": -56.45804231977463, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.400617122650146, "step": 40000}
{"episode_reward": 268.0178036741048, "episode": 41.0, "batch_reward": 0.07211692475900054, "critic_loss": 0.110708387658, "actor_loss": -55.59550528430939, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.92792344093323, "step": 41000}
{"episode_reward": 102.07570606063761, "episode": 42.0, "batch_reward": 0.07196584503352642, "critic_loss": 0.12815689590200782, "actor_loss": -53.48708107256889, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.41676163673401, "step": 42000}
{"episode_reward": 51.350871401456885, "episode": 43.0, "batch_reward": 0.07161761985346675, "critic_loss": 0.1328445135317743, "actor_loss": -53.853027547121044, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.720696687698364, "step": 43000}
{"episode_reward": 52.77373105090682, "episode": 44.0, "batch_reward": 0.07287346696853637, "critic_loss": 0.16236451334133745, "actor_loss": -52.9546001996994, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.002518892288208, "step": 44000}
{"episode_reward": 135.68523743597441, "episode": 45.0, "batch_reward": 0.0730184034369886, "critic_loss": 0.17568767032772303, "actor_loss": -54.96917477607727, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.416709899902344, "step": 45000}
{"episode_reward": 102.63740445531823, "episode": 46.0, "batch_reward": 0.07386830132454633, "critic_loss": 0.1769290497303009, "actor_loss": -53.78394096565246, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.74394917488098, "step": 46000}
{"episode_reward": 101.35805629237251, "episode": 47.0, "batch_reward": 0.07458093225210904, "critic_loss": 0.17430193154886364, "actor_loss": -55.43338303184509, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.90396738052368, "step": 47000}
{"episode_reward": 85.80789920239224, "episode": 48.0, "batch_reward": 0.07596977868303656, "critic_loss": 0.1757858554236591, "actor_loss": -51.840054476737976, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.053470373153687, "step": 48000}
{"episode_reward": 142.24244609663458, "episode": 49.0, "batch_reward": 0.07564220697060227, "critic_loss": 0.1803835754953325, "actor_loss": -55.75026967144012, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.914843797683716, "step": 49000}
{"episode_reward": 70.00466949933782, "episode": 50.0, "batch_reward": 0.07534900684282184, "critic_loss": 0.19553244550526142, "actor_loss": -55.40507240390777, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.775205850601196, "step": 50000}
{"episode_reward": 66.70181526716702, "episode": 51.0, "batch_reward": 0.07728107097372412, "critic_loss": 0.2095681540518999, "actor_loss": -55.17407581853867, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.08495306968689, "step": 51000}
{"episode_reward": 177.3446526662329, "episode": 52.0, "batch_reward": 0.07723970913887024, "critic_loss": 0.20012267845869064, "actor_loss": -55.77196120262146, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.397869348526, "step": 52000}
{"episode_reward": 71.73921110991992, "episode": 53.0, "batch_reward": 0.07903296003490687, "critic_loss": 0.21298563609272242, "actor_loss": -54.97272732591629, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.249753952026367, "step": 53000}
{"episode_reward": 190.07870000792792, "episode": 54.0, "batch_reward": 0.08066294603794813, "critic_loss": 0.21221364948153495, "actor_loss": -55.94280988121033, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.425745725631714, "step": 54000}
{"episode_reward": 246.0686022371467, "episode": 55.0, "batch_reward": 0.08188280187174678, "critic_loss": 0.227287131793797, "actor_loss": -56.130452526569364, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.373373985290527, "step": 55000}
{"episode_reward": 70.25546859298284, "episode": 56.0, "batch_reward": 0.08290964872390032, "critic_loss": 0.22045889123156667, "actor_loss": -56.70967411518097, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.788042306900024, "step": 56000}
{"episode_reward": 103.27216157306519, "episode": 57.0, "batch_reward": 0.08352916231006384, "critic_loss": 0.24261849491298199, "actor_loss": -55.87122004127502, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.06109046936035, "step": 57000}
{"episode_reward": 120.54580033697054, "episode": 58.0, "batch_reward": 0.08320280776172877, "critic_loss": 0.25972925139963626, "actor_loss": -54.63909543800354, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.620368003845215, "step": 58000}
{"episode_reward": 79.56013867472635, "episode": 59.0, "batch_reward": 0.08333205981180072, "critic_loss": 0.3023349312953651, "actor_loss": -54.269088858604434, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.71992063522339, "step": 59000}
{"episode_reward": 82.0157969782947, "episode": 60.0, "batch_reward": 0.08397813998535275, "critic_loss": 0.32905870985984803, "actor_loss": -56.171588646888736, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.184950590133667, "step": 60000}
{"episode_reward": 89.12818897368552, "episode": 61.0, "batch_reward": 0.08321201750263572, "critic_loss": 0.2940686735883355, "actor_loss": -55.08234632015228, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.20123648643494, "step": 61000}
{"episode_reward": 87.25434513239091, "episode": 62.0, "batch_reward": 0.08266299426928163, "critic_loss": 0.2539460178092122, "actor_loss": -56.55727705097198, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.076267957687378, "step": 62000}
{"episode_reward": 17.805560287835185, "episode": 63.0, "batch_reward": 0.08340207983925939, "critic_loss": 0.24689017140865327, "actor_loss": -54.68947671890259, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.75397515296936, "step": 63000}
{"episode_reward": 136.27330329833984, "episode": 64.0, "batch_reward": 0.08355753139033914, "critic_loss": 0.2534843707233667, "actor_loss": -55.844464297294614, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.517146348953247, "step": 64000}
{"episode_reward": 75.23045577371998, "episode": 65.0, "batch_reward": 0.08338094027340412, "critic_loss": 0.24286840867996215, "actor_loss": -55.72207769870758, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.44350838661194, "step": 65000}
{"episode_reward": 88.25833877561091, "episode": 66.0, "batch_reward": 0.08386076470464468, "critic_loss": 0.2472033550143242, "actor_loss": -55.90132626581192, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.15315532684326, "step": 66000}
{"episode_reward": 151.45844099316983, "episode": 67.0, "batch_reward": 0.08584599808230996, "critic_loss": 0.2647307186275721, "actor_loss": -56.724861031532285, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.350265741348267, "step": 67000}
{"episode_reward": 179.62034751482315, "episode": 68.0, "batch_reward": 0.08597866224125028, "critic_loss": 0.2827072213739157, "actor_loss": -53.7607636680603, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.442818880081177, "step": 68000}
{"episode_reward": 192.35387050327634, "episode": 69.0, "batch_reward": 0.0893851587921381, "critic_loss": 0.2797489401474595, "actor_loss": -53.96622742748261, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.703805685043335, "step": 69000}
{"episode_reward": 260.4778615112582, "episode": 70.0, "batch_reward": 0.09242385785281658, "critic_loss": 0.2654189862459898, "actor_loss": -56.99817580127716, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.919524908065796, "step": 70000}
{"episode_reward": 437.3068612866019, "episode": 71.0, "batch_reward": 0.09716169223934412, "critic_loss": 0.28402141455560925, "actor_loss": -56.306544751167294, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.24638509750366, "step": 71000}
{"episode_reward": 458.3367404643952, "episode": 72.0, "batch_reward": 0.10186901245266199, "critic_loss": 0.2974746930152178, "actor_loss": -55.563016794204714, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.976878881454468, "step": 72000}
{"episode_reward": 410.5100342420545, "episode": 73.0, "batch_reward": 0.10545810379087925, "critic_loss": 0.3054421299546957, "actor_loss": -56.17553386211395, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.250661849975586, "step": 73000}
{"episode_reward": 431.79231303744604, "episode": 74.0, "batch_reward": 0.1092707294151187, "critic_loss": 0.30770078269392254, "actor_loss": -57.59322024822235, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.474213361740112, "step": 74000}
{"episode_reward": 426.8917110309231, "episode": 75.0, "batch_reward": 0.11449893560260534, "critic_loss": 0.31770101676136253, "actor_loss": -57.48337562942505, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.440812826156616, "step": 75000}
{"episode_reward": 426.14241304004224, "episode": 76.0, "batch_reward": 0.12009106990695, "critic_loss": 0.32487004148960114, "actor_loss": -58.749447647094726, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.36253571510315, "step": 76000}
{"episode_reward": 554.0523391964806, "episode": 77.0, "batch_reward": 0.12377190154790878, "critic_loss": 0.35054808206111193, "actor_loss": -56.42926340961456, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.818967819213867, "step": 77000}
{"episode_reward": 411.1518101874847, "episode": 78.0, "batch_reward": 0.12677899002283813, "critic_loss": 0.3487776500880718, "actor_loss": -57.573696820259094, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.517578125, "step": 78000}
{"episode_reward": 77.77024709304942, "episode": 79.0, "batch_reward": 0.12525981017947196, "critic_loss": 0.367911422662437, "actor_loss": -54.56851061916351, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.760603666305542, "step": 79000}
{"episode_reward": 89.48166433278317, "episode": 80.0, "batch_reward": 0.1253403030335903, "critic_loss": 0.39772163923084736, "actor_loss": -56.66855589962005, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.505594730377197, "step": 80000}
{"episode_reward": 69.36231594189955, "episode": 81.0, "batch_reward": 0.12730218321084977, "critic_loss": 0.43880592203140256, "actor_loss": -57.218767130851745, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.36016035079956, "step": 81000}
{"episode_reward": 474.0493118348639, "episode": 82.0, "batch_reward": 0.12812439835816622, "critic_loss": 0.43619333127140997, "actor_loss": -59.80411681079865, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.416676998138428, "step": 82000}
{"episode_reward": 78.0095861056883, "episode": 83.0, "batch_reward": 0.13122375874221326, "critic_loss": 0.4859317470192909, "actor_loss": -55.5571124715805, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.724868297576904, "step": 83000}
{"episode_reward": 313.05464026492757, "episode": 84.0, "batch_reward": 0.1329013679549098, "critic_loss": 0.480709323450923, "actor_loss": -58.946822525978085, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.904627561569214, "step": 84000}
{"episode_reward": 428.8508219258014, "episode": 85.0, "batch_reward": 0.13491778484731912, "critic_loss": 0.5033889785110951, "actor_loss": -58.391245396614075, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.509398937225342, "step": 85000}
{"episode_reward": 184.6618643426072, "episode": 86.0, "batch_reward": 0.1352246556803584, "critic_loss": 0.5091538322269916, "actor_loss": -57.302279559135435, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.928869485855103, "step": 86000}
{"episode_reward": 80.2961132278343, "episode": 87.0, "batch_reward": 0.1350361125320196, "critic_loss": 0.513978557780385, "actor_loss": -57.05626655006409, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.735429048538208, "step": 87000}
{"episode_reward": 150.4579840368315, "episode": 88.0, "batch_reward": 0.13606191185861827, "critic_loss": 0.5263769681304693, "actor_loss": -55.67165244102478, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.285064935684204, "step": 88000}
{"episode_reward": 474.39415147228857, "episode": 89.0, "batch_reward": 0.14117154321819544, "critic_loss": 0.5793837105929851, "actor_loss": -59.02785767936707, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.890477895736694, "step": 89000}
{"episode_reward": 450.1661724524405, "episode": 90.0, "batch_reward": 0.14353262843936682, "critic_loss": 0.5957087836861611, "actor_loss": -60.69852623367309, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.828779458999634, "step": 90000}
{"episode_reward": 389.86136969691, "episode": 91.0, "batch_reward": 0.14655585887283087, "critic_loss": 0.6008709233403206, "actor_loss": -58.25044064903259, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.84015941619873, "step": 91000}
{"episode_reward": 527.9244885822934, "episode": 92.0, "batch_reward": 0.14979403965175153, "critic_loss": 0.6463391826152801, "actor_loss": -57.311022743225095, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.4518301486969, "step": 92000}
{"episode_reward": 492.28124507401736, "episode": 93.0, "batch_reward": 0.15350349102914335, "critic_loss": 0.6787033254951239, "actor_loss": -57.64409921455383, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.958555459976196, "step": 93000}
{"episode_reward": 550.9424478222606, "episode": 94.0, "batch_reward": 0.15884466271847486, "critic_loss": 0.7017367655038833, "actor_loss": -58.0090874710083, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.393890619277954, "step": 94000}
{"episode_reward": 519.2591769084113, "episode": 95.0, "batch_reward": 0.16194897679239512, "critic_loss": 0.7422087654173374, "actor_loss": -60.965985891342164, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.473297595977783, "step": 95000}
{"episode_reward": 561.2509558116634, "episode": 96.0, "batch_reward": 0.1647629737406969, "critic_loss": 0.7480580796897411, "actor_loss": -60.98469987297058, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.96116304397583, "step": 96000}
{"episode_reward": 108.91080454077178, "episode": 97.0, "batch_reward": 0.16668576938658952, "critic_loss": 0.771356128975749, "actor_loss": -61.76266847419739, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.483623027801514, "step": 97000}
{"episode_reward": 508.0490080544306, "episode": 98.0, "batch_reward": 0.16983769734948873, "critic_loss": 0.7594348450005054, "actor_loss": -58.53535739326477, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.507415533065796, "step": 98000}
{"episode_reward": 592.6483695530313, "episode": 99.0, "batch_reward": 0.1747911236807704, "critic_loss": 0.8147143092155457, "actor_loss": -58.95026000404358, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.663531064987183, "step": 99000}
{"episode_reward": 585.951639913675, "episode": 100.0, "batch_reward": 0.178265141941607, "critic_loss": 0.7940477916002273, "actor_loss": -59.653977853775025, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.050864934921265, "step": 100000}
{"episode_reward": 639.9141889769899, "episode": 101.0, "batch_reward": 0.1819196247830987, "critic_loss": 0.8027303048968315, "actor_loss": -60.73384259223938, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.41400456428528, "step": 101000}
{"episode_reward": 601.5101570429525, "episode": 102.0, "batch_reward": 0.18543022342771293, "critic_loss": 0.8594813489317894, "actor_loss": -60.48162496185303, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.21980118751526, "step": 102000}
{"episode_reward": 574.6653870367883, "episode": 103.0, "batch_reward": 0.18905987679958344, "critic_loss": 0.9036691759228707, "actor_loss": -60.39514032173157, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.7439067363739, "step": 103000}
{"episode_reward": 517.5460583864677, "episode": 104.0, "batch_reward": 0.19345483948290348, "critic_loss": 0.9529100045263768, "actor_loss": -60.66075503730774, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.81612515449524, "step": 104000}
{"episode_reward": 486.9163771954427, "episode": 105.0, "batch_reward": 0.19645006908476353, "critic_loss": 0.9975211600661278, "actor_loss": -60.81688925361633, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.937769174575806, "step": 105000}
{"episode_reward": 357.28705167202384, "episode": 106.0, "batch_reward": 0.196830974817276, "critic_loss": 0.9976340922117233, "actor_loss": -59.38593832397461, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.260356903076172, "step": 106000}
{"episode_reward": 409.3722488760784, "episode": 107.0, "batch_reward": 0.19862474343180656, "critic_loss": 1.0773843168318271, "actor_loss": -60.76996095466614, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.89165735244751, "step": 107000}
{"episode_reward": 343.64463698324363, "episode": 108.0, "batch_reward": 0.20078889334201813, "critic_loss": 1.0854083745777607, "actor_loss": -60.7462140045166, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.43869948387146, "step": 108000}
{"episode_reward": 475.7036849370359, "episode": 109.0, "batch_reward": 0.20259187452495098, "critic_loss": 1.0777710882425309, "actor_loss": -62.576819074630734, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.797951459884644, "step": 109000}
{"episode_reward": 86.72866863682776, "episode": 110.0, "batch_reward": 0.20387928637117148, "critic_loss": 1.1393013623952866, "actor_loss": -61.097890783309936, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.742531299591064, "step": 110000}
{"episode_reward": 542.6488348476116, "episode": 111.0, "batch_reward": 0.20563080812990667, "critic_loss": 1.1658650561869144, "actor_loss": -63.52608961868286, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.9225869178772, "step": 111000}
{"episode_reward": 586.1751194449829, "episode": 112.0, "batch_reward": 0.21004875119030475, "critic_loss": 1.2590747179985047, "actor_loss": -61.53532124710083, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.757013082504272, "step": 112000}
{"episode_reward": 651.849490606861, "episode": 113.0, "batch_reward": 0.21235739259421826, "critic_loss": 1.34784757527709, "actor_loss": -61.66910693740845, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.731202363967896, "step": 113000}
{"episode_reward": 624.1222332953952, "episode": 114.0, "batch_reward": 0.2178705982416868, "critic_loss": 1.3433357700109483, "actor_loss": -63.47146802902222, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 22.02396035194397, "step": 114000}
{"episode_reward": 512.4157274344194, "episode": 115.0, "batch_reward": 0.22016579699516298, "critic_loss": 1.4197221143245697, "actor_loss": -62.43889011955261, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.998861074447632, "step": 115000}
{"episode_reward": 678.6859699312078, "episode": 116.0, "batch_reward": 0.22611215445399285, "critic_loss": 1.4655061062574386, "actor_loss": -63.12045013809204, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.272613525390625, "step": 116000}
{"episode_reward": 760.4611849466988, "episode": 117.0, "batch_reward": 0.22799876582622527, "critic_loss": 1.4141741898059845, "actor_loss": -62.90440020370483, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.898746490478516, "step": 117000}
{"episode_reward": 661.6858943817526, "episode": 118.0, "batch_reward": 0.23367003439366818, "critic_loss": 1.5342376297712326, "actor_loss": -63.73265545654297, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.531962156295776, "step": 118000}
{"episode_reward": 671.9231433686284, "episode": 119.0, "batch_reward": 0.23668677441775798, "critic_loss": 1.607401478588581, "actor_loss": -64.36502715301513, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.1329402923584, "step": 119000}
{"episode_reward": 574.6999841908371, "episode": 120.0, "batch_reward": 0.23855852121114732, "critic_loss": 1.6700424178242683, "actor_loss": -62.6706989364624, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.387863874435425, "step": 120000}
{"episode_reward": 705.0339517904184, "episode": 121.0, "batch_reward": 0.24388471849262713, "critic_loss": 1.6456356998682022, "actor_loss": -63.470524143218995, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.709798097610474, "step": 121000}
{"episode_reward": 697.9229114119316, "episode": 122.0, "batch_reward": 0.24752112796902656, "critic_loss": 1.7607758958935738, "actor_loss": -63.49588028717041, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.941356897354126, "step": 122000}
{"episode_reward": 726.9737557921082, "episode": 123.0, "batch_reward": 0.2511142176389694, "critic_loss": 1.8248259345293045, "actor_loss": -60.972051425933834, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.76757025718689, "step": 123000}
{"episode_reward": 829.2209898876686, "episode": 124.0, "batch_reward": 0.25439661264419555, "critic_loss": 1.8169727513194085, "actor_loss": -64.01975258255005, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.889190912246704, "step": 124000}
{"episode_reward": 622.5239893709407, "episode": 125.0, "batch_reward": 0.2579272413849831, "critic_loss": 1.7607180490493775, "actor_loss": -64.36942782592773, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.571573734283447, "step": 125000}
{"episode_reward": 737.7625956027507, "episode": 126.0, "batch_reward": 0.2603418433517218, "critic_loss": 1.7646141296625137, "actor_loss": -64.67837496566773, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.5158634185791, "step": 126000}
{"episode_reward": 694.1535270036815, "episode": 127.0, "batch_reward": 0.2644179528802633, "critic_loss": 1.874369812488556, "actor_loss": -64.85989595413209, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.672239780426025, "step": 127000}
{"episode_reward": 772.3415927612685, "episode": 128.0, "batch_reward": 0.2673650965243578, "critic_loss": 1.8613887816667556, "actor_loss": -66.81293786239624, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.427746295928955, "step": 128000}
{"episode_reward": 607.2124902535116, "episode": 129.0, "batch_reward": 0.2711227463334799, "critic_loss": 1.8420829812288284, "actor_loss": -67.21148580551147, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.826318740844727, "step": 129000}
{"episode_reward": 742.9990355269475, "episode": 130.0, "batch_reward": 0.2758537037372589, "critic_loss": 1.8448889698386193, "actor_loss": -66.02576127624512, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.986788272857666, "step": 130000}
{"episode_reward": 767.5122715522248, "episode": 131.0, "batch_reward": 0.2803602270781994, "critic_loss": 1.8360205159783363, "actor_loss": -68.56508560943604, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 41.879764795303345, "step": 131000}
{"episode_reward": 719.4729950832252, "episode": 132.0, "batch_reward": 0.28134180064499376, "critic_loss": 1.836984938442707, "actor_loss": -66.8066897239685, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.581550359725952, "step": 132000}
{"episode_reward": 487.595290867658, "episode": 133.0, "batch_reward": 0.2838172575980425, "critic_loss": 1.8137565472722053, "actor_loss": -67.38346605300903, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.946535110473633, "step": 133000}
{"episode_reward": 780.6729141756246, "episode": 134.0, "batch_reward": 0.28679450733959677, "critic_loss": 1.9016455237865448, "actor_loss": -67.75316287994384, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.732935667037964, "step": 134000}
{"episode_reward": 610.4030078166835, "episode": 135.0, "batch_reward": 0.288708221539855, "critic_loss": 1.847991891682148, "actor_loss": -68.12736001205444, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.999900341033936, "step": 135000}
{"episode_reward": 708.4337565655838, "episode": 136.0, "batch_reward": 0.2954511562138796, "critic_loss": 1.8367104616761207, "actor_loss": -69.68777224349975, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.94596004486084, "step": 136000}
{"episode_reward": 826.2450658558615, "episode": 137.0, "batch_reward": 0.29780378951132297, "critic_loss": 1.8435090379714967, "actor_loss": -67.41594248580932, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.57596755027771, "step": 137000}
{"episode_reward": 750.2648972250553, "episode": 138.0, "batch_reward": 0.30024976044893265, "critic_loss": 1.8430039058923722, "actor_loss": -66.80581559371949, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.339099407196045, "step": 138000}
{"episode_reward": 733.2327367194475, "episode": 139.0, "batch_reward": 0.30204164670407774, "critic_loss": 1.7836552910804748, "actor_loss": -67.20392450332642, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.819504022598267, "step": 139000}
{"episode_reward": 90.84071539907926, "episode": 140.0, "batch_reward": 0.30072269186377526, "critic_loss": 1.8859029381871224, "actor_loss": -66.9339222831726, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.120317220687866, "step": 140000}
{"episode_reward": 788.7745102534165, "episode": 141.0, "batch_reward": 0.3023043990135193, "critic_loss": 1.8693426055312157, "actor_loss": -66.44720275115967, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 42.19160270690918, "step": 141000}
{"episode_reward": 83.93087922813334, "episode": 142.0, "batch_reward": 0.3038426153957844, "critic_loss": 1.8815589339137078, "actor_loss": -67.96084782028198, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.80965781211853, "step": 142000}
{"episode_reward": 830.6929159675595, "episode": 143.0, "batch_reward": 0.30808933937549593, "critic_loss": 1.9204205753803254, "actor_loss": -68.3264921875, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.723003149032593, "step": 143000}
{"episode_reward": 828.3875512693841, "episode": 144.0, "batch_reward": 0.3121254222244024, "critic_loss": 1.9005004276037216, "actor_loss": -68.9615467376709, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.67988657951355, "step": 144000}
{"episode_reward": 677.9154879127367, "episode": 145.0, "batch_reward": 0.3148791905641556, "critic_loss": 1.907239818751812, "actor_loss": -68.50514818954468, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.999362468719482, "step": 145000}
{"episode_reward": 730.368071840853, "episode": 146.0, "batch_reward": 0.3168125307112932, "critic_loss": 1.963917033612728, "actor_loss": -68.19183507156372, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.818010091781616, "step": 146000}
{"episode_reward": 758.6047593386384, "episode": 147.0, "batch_reward": 0.3188559824228287, "critic_loss": 2.004661546885967, "actor_loss": -69.217551071167, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 20.525398015975952, "step": 147000}
{"episode_reward": 687.9157687717733, "episode": 148.0, "batch_reward": 0.32324602258205415, "critic_loss": 2.026384111762047, "actor_loss": -67.84018704986572, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.1690993309021, "step": 148000}
{"episode_reward": 826.8740473036522, "episode": 149.0, "batch_reward": 0.32632424454391, "critic_loss": 2.014728402197361, "actor_loss": -69.00487213897705, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "duration": 21.37833833694458, "step": 149000}
{"episode_reward": 746.051337340166, "episode": 150.0, "batch_reward": 0.33090637570619585, "critic_loss": 2.0109909648895266, "actor_loss": -69.10528937530518, "actor_target_entropy": -6.0, "alpha_value": 0.0024772593499179114, "step": 150000}
