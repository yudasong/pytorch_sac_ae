{"episode_reward": 0.0, "episode": 1.0, "duration": 21.03821849822998, "step": 1000}
{"episode_reward": 28.002640152663393, "episode": 2.0, "duration": 1.8388123512268066, "step": 2000}
{"episode_reward": 481.4321918933315, "episode": 3.0, "batch_reward": 0.2740570498818594, "critic_loss": 0.4170776001311573, "actor_loss": -84.41094340262961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.45308351516724, "step": 3000}
{"episode_reward": 503.6685024007891, "episode": 4.0, "batch_reward": 0.3623187702596188, "critic_loss": 0.5955074706971646, "actor_loss": -84.47713954162597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.56411123275757, "step": 4000}
{"episode_reward": 562.7634910276512, "episode": 5.0, "batch_reward": 0.4040761097371578, "critic_loss": 0.8603603812158108, "actor_loss": -84.90148332214355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.525991916656494, "step": 5000}
{"episode_reward": 505.30029524016766, "episode": 6.0, "batch_reward": 0.4193235010802746, "critic_loss": 1.1034783200025557, "actor_loss": -85.28333377075195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.546571016311646, "step": 6000}
{"episode_reward": 491.57981546468926, "episode": 7.0, "batch_reward": 0.43988196486234665, "critic_loss": 1.2549449005723, "actor_loss": -85.02506457519532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.558980703353882, "step": 7000}
{"episode_reward": 533.7229324728359, "episode": 8.0, "batch_reward": 0.4565450182557106, "critic_loss": 1.392724979043007, "actor_loss": -84.89600329589844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.553491830825806, "step": 8000}
{"episode_reward": 627.4069695587746, "episode": 9.0, "batch_reward": 0.4766805930137634, "critic_loss": 1.414386804521084, "actor_loss": -85.2048045501709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.560030460357666, "step": 9000}
{"episode_reward": 660.1747500123872, "episode": 10.0, "batch_reward": 0.49592606496810915, "critic_loss": 1.5835731956958772, "actor_loss": -85.50987240600585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.561179876327515, "step": 10000}
{"episode_reward": 562.7343817521993, "episode": 11.0, "batch_reward": 0.5000694759190083, "critic_loss": 1.8290477623939514, "actor_loss": -85.14046284484863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.29219126701355, "step": 11000}
{"episode_reward": 612.4960773426527, "episode": 12.0, "batch_reward": 0.5111969661414624, "critic_loss": 2.0584765478372575, "actor_loss": -84.99217611694336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.5714910030365, "step": 12000}
{"episode_reward": 612.9726197587923, "episode": 13.0, "batch_reward": 0.5177797602117061, "critic_loss": 2.3282172758579254, "actor_loss": -84.85958480834961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.573623657226562, "step": 13000}
{"episode_reward": 611.0203557450631, "episode": 14.0, "batch_reward": 0.528396575152874, "critic_loss": 2.443334475517273, "actor_loss": -84.69769540405274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.55601716041565, "step": 14000}
{"episode_reward": 641.3693079769156, "episode": 15.0, "batch_reward": 0.5352453249692917, "critic_loss": 2.340183534383774, "actor_loss": -85.25952035522461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.570029258728027, "step": 15000}
{"episode_reward": 719.5429425926928, "episode": 16.0, "batch_reward": 0.528498081356287, "critic_loss": 2.1727617384195326, "actor_loss": -84.50703570556641, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.55883479118347, "step": 16000}
{"episode_reward": 15.150655790022608, "episode": 17.0, "batch_reward": 0.5199450652301312, "critic_loss": 1.9989177284240722, "actor_loss": -83.6549040222168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.565775156021118, "step": 17000}
{"episode_reward": 794.6823853120467, "episode": 18.0, "batch_reward": 0.5312656978368759, "critic_loss": 2.0036299287080763, "actor_loss": -84.06250898742675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.56564998626709, "step": 18000}
{"episode_reward": 773.3528309872755, "episode": 19.0, "batch_reward": 0.5453840750157833, "critic_loss": 1.8510813974142075, "actor_loss": -84.52570021057129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.57976794242859, "step": 19000}
{"episode_reward": 795.6321062750113, "episode": 20.0, "batch_reward": 0.5610644869506359, "critic_loss": 1.7389963487386704, "actor_loss": -85.47480764770508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.5703125, "step": 20000}
{"episode_reward": 838.0666730431433, "episode": 21.0, "batch_reward": 0.5751023526191712, "critic_loss": 1.661175235271454, "actor_loss": -84.20060232543945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.2628231048584, "step": 21000}
{"episode_reward": 808.0025705151091, "episode": 22.0, "batch_reward": 0.5858995525836944, "critic_loss": 1.5572411384582519, "actor_loss": -85.26814764404297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.55481195449829, "step": 22000}
{"episode_reward": 854.1532955678183, "episode": 23.0, "batch_reward": 0.5963682523965835, "critic_loss": 1.547142453312874, "actor_loss": -84.92799559020996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.557220220565796, "step": 23000}
{"episode_reward": 754.6858513291812, "episode": 24.0, "batch_reward": 0.6032658141851425, "critic_loss": 1.5652701476812363, "actor_loss": -85.57963677978516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.56158447265625, "step": 24000}
{"episode_reward": 760.0423766442863, "episode": 25.0, "batch_reward": 0.6016135459542274, "critic_loss": 1.6361611431241037, "actor_loss": -85.80144268035889, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.556089639663696, "step": 25000}
{"episode_reward": 569.4392852417633, "episode": 26.0, "batch_reward": 0.6071572363972664, "critic_loss": 1.747887412071228, "actor_loss": -85.16283071899414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.569193363189697, "step": 26000}
{"episode_reward": 809.5761067428084, "episode": 27.0, "batch_reward": 0.6121962043642998, "critic_loss": 1.8259721596240996, "actor_loss": -85.55388026428223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.557674646377563, "step": 27000}
{"episode_reward": 726.6348200795647, "episode": 28.0, "batch_reward": 0.6210576196312905, "critic_loss": 1.9514988249540328, "actor_loss": -85.41601507568359, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.828964948654175, "step": 28000}
{"episode_reward": 839.419194974251, "episode": 29.0, "batch_reward": 0.626471863925457, "critic_loss": 2.013909138917923, "actor_loss": -85.78699140930176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.587954998016357, "step": 29000}
{"episode_reward": 807.8184209768185, "episode": 30.0, "batch_reward": 0.6346628358364105, "critic_loss": 2.061530032992363, "actor_loss": -85.1678187713623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.52837061882019, "step": 30000}
{"episode_reward": 775.2204030496196, "episode": 31.0, "batch_reward": 0.6398061873316765, "critic_loss": 2.0563622155189516, "actor_loss": -86.29386207580566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.26099228858948, "step": 31000}
{"episode_reward": 893.5955940514119, "episode": 32.0, "batch_reward": 0.6470833158493042, "critic_loss": 2.0387515243291854, "actor_loss": -86.7254680633545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.54229474067688, "step": 32000}
{"episode_reward": 858.973113894188, "episode": 33.0, "batch_reward": 0.6532238528728486, "critic_loss": 1.9725158123970032, "actor_loss": -86.8461160736084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.5573992729187, "step": 33000}
{"episode_reward": 867.7497934379898, "episode": 34.0, "batch_reward": 0.6587118855118752, "critic_loss": 1.9922788834571838, "actor_loss": -87.05101095581054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.556500911712646, "step": 34000}
{"episode_reward": 833.0948801536509, "episode": 35.0, "batch_reward": 0.6647189237475395, "critic_loss": 1.97455850481987, "actor_loss": -87.1202561340332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.869311809539795, "step": 35000}
{"episode_reward": 821.7443222416022, "episode": 36.0, "batch_reward": 0.6688815145492554, "critic_loss": 1.9629330883026124, "actor_loss": -87.6308307800293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.536932945251465, "step": 36000}
{"episode_reward": 828.6276707532955, "episode": 37.0, "batch_reward": 0.6731944303512574, "critic_loss": 2.008314222216606, "actor_loss": -87.03130838012696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.536238431930542, "step": 37000}
{"episode_reward": 830.0350642419074, "episode": 38.0, "batch_reward": 0.6778691972494125, "critic_loss": 1.980256809592247, "actor_loss": -86.8871028137207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.542449235916138, "step": 38000}
{"episode_reward": 860.862713773421, "episode": 39.0, "batch_reward": 0.6828056359887124, "critic_loss": 1.9417733036279679, "actor_loss": -86.89591622924804, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.56179976463318, "step": 39000}
{"episode_reward": 922.7256147909173, "episode": 40.0, "batch_reward": 0.6903967615365982, "critic_loss": 1.8929050660133362, "actor_loss": -87.75481103515625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.561030626296997, "step": 40000}
{"episode_reward": 958.9173618209638, "episode": 41.0, "batch_reward": 0.6958250440955162, "critic_loss": 1.8382816352844238, "actor_loss": -87.67944549560546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.26764726638794, "step": 41000}
{"episode_reward": 892.1377221488437, "episode": 42.0, "batch_reward": 0.6998648476004601, "critic_loss": 1.839149908900261, "actor_loss": -87.81109297180176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.5501925945282, "step": 42000}
{"episode_reward": 889.1102239230866, "episode": 43.0, "batch_reward": 0.7065990775823593, "critic_loss": 1.7938828147053718, "actor_loss": -88.10857992553711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.562732934951782, "step": 43000}
{"episode_reward": 953.1275493895088, "episode": 44.0, "batch_reward": 0.7092008191943169, "critic_loss": 1.8290067403316497, "actor_loss": -89.44979731750489, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.551887035369873, "step": 44000}
{"episode_reward": 883.4918574829107, "episode": 45.0, "batch_reward": 0.7151523243188858, "critic_loss": 1.7609511702060698, "actor_loss": -88.62450001525879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.56769561767578, "step": 45000}
{"episode_reward": 952.4972030885463, "episode": 46.0, "batch_reward": 0.7194713529348373, "critic_loss": 1.7970987331867219, "actor_loss": -87.92055458068847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.551756620407104, "step": 46000}
{"episode_reward": 924.120763850672, "episode": 47.0, "batch_reward": 0.7246341218948364, "critic_loss": 1.7859289420843125, "actor_loss": -88.5564715423584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.562678813934326, "step": 47000}
{"episode_reward": 868.8143742722326, "episode": 48.0, "batch_reward": 0.7263387178778649, "critic_loss": 1.8107486752271653, "actor_loss": -88.41788870239257, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.554017305374146, "step": 48000}
{"episode_reward": 758.2492604340736, "episode": 49.0, "batch_reward": 0.7264309714436531, "critic_loss": 1.7854766539335252, "actor_loss": -89.32413543701172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.555885553359985, "step": 49000}
{"episode_reward": 815.8786224906461, "episode": 50.0, "batch_reward": 0.729872383415699, "critic_loss": 1.7799121676683425, "actor_loss": -89.02704627990722, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.557488203048706, "step": 50000}
{"episode_reward": 918.0207702552761, "episode": 51.0, "batch_reward": 0.7328844885826111, "critic_loss": 1.7648421872258186, "actor_loss": -88.96660400390626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.25266098976135, "step": 51000}
{"episode_reward": 857.2881407615512, "episode": 52.0, "batch_reward": 0.7369974997639656, "critic_loss": 1.8016200288534165, "actor_loss": -88.76314291381836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.565139532089233, "step": 52000}
{"episode_reward": 881.8079424158065, "episode": 53.0, "batch_reward": 0.7395880340337754, "critic_loss": 1.7890041387677194, "actor_loss": -89.47712019348144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.570432901382446, "step": 53000}
{"episode_reward": 941.9994631074704, "episode": 54.0, "batch_reward": 0.7425483129024506, "critic_loss": 1.8165530037879944, "actor_loss": -89.8768773803711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.5583016872406, "step": 54000}
{"episode_reward": 921.92589936846, "episode": 55.0, "batch_reward": 0.7438786117434502, "critic_loss": 1.7734401049017907, "actor_loss": -89.7084917755127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.549563884735107, "step": 55000}
{"episode_reward": 842.6140888758437, "episode": 56.0, "batch_reward": 0.7475219926834107, "critic_loss": 1.821382856488228, "actor_loss": -89.74181225585937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.57303810119629, "step": 56000}
{"episode_reward": 920.6593006420896, "episode": 57.0, "batch_reward": 0.752084919333458, "critic_loss": 1.8441568388938905, "actor_loss": -89.8775849456787, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.575281381607056, "step": 57000}
{"episode_reward": 940.6341101175435, "episode": 58.0, "batch_reward": 0.752580603659153, "critic_loss": 1.8438581446409226, "actor_loss": -89.99978507995606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.568986415863037, "step": 58000}
{"episode_reward": 813.0102530300699, "episode": 59.0, "batch_reward": 0.7548362659215927, "critic_loss": 1.81649202978611, "actor_loss": -89.97545046997071, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.574987649917603, "step": 59000}
{"episode_reward": 906.391425365801, "episode": 60.0, "batch_reward": 0.7581527119278908, "critic_loss": 1.830457927465439, "actor_loss": -90.07822077941894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.565428256988525, "step": 60000}
{"episode_reward": 936.6811293103855, "episode": 61.0, "batch_reward": 0.7619722862839698, "critic_loss": 1.7863148434758187, "actor_loss": -90.1688797454834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.306071758270264, "step": 61000}
{"episode_reward": 946.7413346993206, "episode": 62.0, "batch_reward": 0.7636930993199349, "critic_loss": 1.8265381291508676, "actor_loss": -90.27059504699707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.5722599029541, "step": 62000}
{"episode_reward": 915.1132610444108, "episode": 63.0, "batch_reward": 0.7665335583090782, "critic_loss": 1.7982917697429657, "actor_loss": -90.42253825378418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.558942079544067, "step": 63000}
{"episode_reward": 914.1121911395446, "episode": 64.0, "batch_reward": 0.7678879010081291, "critic_loss": 1.7736555685400963, "actor_loss": -90.78371627807617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.58131217956543, "step": 64000}
{"episode_reward": 895.6404212984721, "episode": 65.0, "batch_reward": 0.7700153877735137, "critic_loss": 1.749692321062088, "actor_loss": -90.52229914855957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.5693519115448, "step": 65000}
{"episode_reward": 892.9001571722262, "episode": 66.0, "batch_reward": 0.772037175834179, "critic_loss": 1.7448652782440186, "actor_loss": -90.55073332214356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.571584701538086, "step": 66000}
{"episode_reward": 908.7504708723831, "episode": 67.0, "batch_reward": 0.7752299621105194, "critic_loss": 1.8180149013996125, "actor_loss": -91.09667596435547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.56638789176941, "step": 67000}
{"episode_reward": 882.7657124068154, "episode": 68.0, "batch_reward": 0.777036268234253, "critic_loss": 1.8017159813642503, "actor_loss": -91.53612168884277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.569063186645508, "step": 68000}
{"episode_reward": 922.3644098470663, "episode": 69.0, "batch_reward": 0.7768189969062805, "critic_loss": 1.7563305867314338, "actor_loss": -90.7449584197998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.586585521697998, "step": 69000}
{"episode_reward": 898.6134917186424, "episode": 70.0, "batch_reward": 0.7799244838953018, "critic_loss": 1.7441889398097992, "actor_loss": -90.95718231201172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.57212781906128, "step": 70000}
{"episode_reward": 882.811828521019, "episode": 71.0, "batch_reward": 0.7814127551913261, "critic_loss": 1.7003830515742302, "actor_loss": -90.78753732299805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.257540464401245, "step": 71000}
{"episode_reward": 926.2127409343998, "episode": 72.0, "batch_reward": 0.7823177725672722, "critic_loss": 1.6540541359186172, "actor_loss": -91.38754873657227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.55756139755249, "step": 72000}
{"episode_reward": 864.6622790286832, "episode": 73.0, "batch_reward": 0.7858332036733627, "critic_loss": 1.7451754308342933, "actor_loss": -91.58066006469727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.572813510894775, "step": 73000}
{"episode_reward": 855.7520234055573, "episode": 74.0, "batch_reward": 0.7814450591802597, "critic_loss": 1.7691638106107712, "actor_loss": -91.06413998413086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.552443504333496, "step": 74000}
{"episode_reward": 620.9947830641908, "episode": 75.0, "batch_reward": 0.782385697066784, "critic_loss": 1.7626940864920617, "actor_loss": -91.16320777893067, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.598361492156982, "step": 75000}
{"episode_reward": 900.748118760092, "episode": 76.0, "batch_reward": 0.7835674046278, "critic_loss": 1.7885429080724715, "actor_loss": -91.41886299133301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.559696435928345, "step": 76000}
{"episode_reward": 846.7574142892347, "episode": 77.0, "batch_reward": 0.783962119102478, "critic_loss": 1.805528180360794, "actor_loss": -91.27778816223145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.56208324432373, "step": 77000}
{"episode_reward": 899.3599527865857, "episode": 78.0, "batch_reward": 0.7875027708411216, "critic_loss": 1.6866790068149566, "actor_loss": -91.58703703308106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.56190848350525, "step": 78000}
{"episode_reward": 919.7884111158165, "episode": 79.0, "batch_reward": 0.7887446942925453, "critic_loss": 1.73070541536808, "actor_loss": -92.0171363067627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.568756580352783, "step": 79000}
{"episode_reward": 864.8063670063277, "episode": 80.0, "batch_reward": 0.7893921710252761, "critic_loss": 1.6729097734093665, "actor_loss": -91.7708464050293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.61981964111328, "step": 80000}
{"episode_reward": 920.3180761713667, "episode": 81.0, "batch_reward": 0.7912067957520484, "critic_loss": 1.6646258544921875, "actor_loss": -91.46520614624023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.270004749298096, "step": 81000}
{"episode_reward": 881.0476529887056, "episode": 82.0, "batch_reward": 0.7937412158846855, "critic_loss": 1.7060402874946594, "actor_loss": -91.60409980773926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.565566778182983, "step": 82000}
{"episode_reward": 885.7624993601817, "episode": 83.0, "batch_reward": 0.7944720587134362, "critic_loss": 1.6711708439588546, "actor_loss": -91.91154362487794, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.563284873962402, "step": 83000}
{"episode_reward": 942.6721923337834, "episode": 84.0, "batch_reward": 0.7960037794709206, "critic_loss": 1.672523054242134, "actor_loss": -92.11775814819336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.558393716812134, "step": 84000}
{"episode_reward": 869.0882353727276, "episode": 85.0, "batch_reward": 0.7942200592160225, "critic_loss": 1.664630834877491, "actor_loss": -91.97496357727051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.56503653526306, "step": 85000}
{"episode_reward": 779.0242554589612, "episode": 86.0, "batch_reward": 0.7976463389396667, "critic_loss": 1.6094112777709961, "actor_loss": -92.02148606872558, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.564867734909058, "step": 86000}
{"episode_reward": 929.5261545010795, "episode": 87.0, "batch_reward": 0.7969412391185761, "critic_loss": 1.6063901202082633, "actor_loss": -92.15856823730469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.55905318260193, "step": 87000}
{"episode_reward": 928.9960571113735, "episode": 88.0, "batch_reward": 0.7993478047251701, "critic_loss": 1.6695267007350922, "actor_loss": -91.96835116577148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.569539070129395, "step": 88000}
{"episode_reward": 801.2509142514446, "episode": 89.0, "batch_reward": 0.7975397450327874, "critic_loss": 1.7218926665186882, "actor_loss": -92.06981694030762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.560188055038452, "step": 89000}
{"episode_reward": 910.4450994431103, "episode": 90.0, "batch_reward": 0.8010771297812462, "critic_loss": 1.6736239038705827, "actor_loss": -92.05412161254883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.56863307952881, "step": 90000}
{"episode_reward": 882.7213499119356, "episode": 91.0, "batch_reward": 0.8000832580327988, "critic_loss": 1.698285376727581, "actor_loss": -92.12223477172851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.25049066543579, "step": 91000}
{"episode_reward": 830.3244979340179, "episode": 92.0, "batch_reward": 0.8007705098986626, "critic_loss": 1.6497354723215103, "actor_loss": -92.4947427368164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.55069398880005, "step": 92000}
{"episode_reward": 896.5045233969493, "episode": 93.0, "batch_reward": 0.8026049846410751, "critic_loss": 1.7052000054717065, "actor_loss": -92.10619770812988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.56296396255493, "step": 93000}
{"episode_reward": 937.8426415955844, "episode": 94.0, "batch_reward": 0.8042314788103103, "critic_loss": 1.6832400400042533, "actor_loss": -92.39414918518067, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.5656099319458, "step": 94000}
{"episode_reward": 879.7122639422649, "episode": 95.0, "batch_reward": 0.8031715214252472, "critic_loss": 1.6901166365146636, "actor_loss": -92.62409393310547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.55785584449768, "step": 95000}
{"episode_reward": 837.968862419201, "episode": 96.0, "batch_reward": 0.8048587743639946, "critic_loss": 1.710269582927227, "actor_loss": -92.61533062744141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.56229543685913, "step": 96000}
{"episode_reward": 727.0204525285162, "episode": 97.0, "batch_reward": 0.8037785158157349, "critic_loss": 1.6571633724570274, "actor_loss": -92.37350393676758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.558050394058228, "step": 97000}
{"episode_reward": 914.0461054465151, "episode": 98.0, "batch_reward": 0.8054415221214295, "critic_loss": 1.6866377007365227, "actor_loss": -92.70537692260743, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.55864191055298, "step": 98000}
{"episode_reward": 855.9205935982503, "episode": 99.0, "batch_reward": 0.8066462407112122, "critic_loss": 1.664442259311676, "actor_loss": -92.35519546508789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.566715955734253, "step": 99000}
{"episode_reward": 919.2079801122079, "episode": 100.0, "batch_reward": 0.8064352169632911, "critic_loss": 1.6588144953250885, "actor_loss": -92.6200389251709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.566605806350708, "step": 100000}
{"episode_reward": 950.2679859101095, "episode": 101.0, "batch_reward": 0.8091473684906959, "critic_loss": 1.648887838602066, "actor_loss": -92.33079782104492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.28028702735901, "step": 101000}
{"episode_reward": 940.0555819811138, "episode": 102.0, "batch_reward": 0.8094344287514686, "critic_loss": 1.6415810275673866, "actor_loss": -92.68470556640625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.559884786605835, "step": 102000}
{"episode_reward": 895.2701790832588, "episode": 103.0, "batch_reward": 0.8099072566032409, "critic_loss": 1.6389941945672035, "actor_loss": -92.38185961914063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.566230535507202, "step": 103000}
{"episode_reward": 941.8580540220485, "episode": 104.0, "batch_reward": 0.8114717415571213, "critic_loss": 1.5910992784500122, "actor_loss": -92.40460433959962, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.563974142074585, "step": 104000}
{"episode_reward": 839.8364444298159, "episode": 105.0, "batch_reward": 0.8125513620376587, "critic_loss": 1.5625810851454736, "actor_loss": -92.65952821350098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.572421073913574, "step": 105000}
{"episode_reward": 914.067028285225, "episode": 106.0, "batch_reward": 0.812513351738453, "critic_loss": 1.6136148688793182, "actor_loss": -92.61208570861817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.569823265075684, "step": 106000}
{"episode_reward": 876.4693117759119, "episode": 107.0, "batch_reward": 0.8132596663832664, "critic_loss": 1.5595261505842208, "actor_loss": -92.40297218322753, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.561918258666992, "step": 107000}
{"episode_reward": 921.9236472995701, "episode": 108.0, "batch_reward": 0.8150983006358147, "critic_loss": 1.60281803804636, "actor_loss": -92.8575818939209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.571646451950073, "step": 108000}
{"episode_reward": 913.9041089510081, "episode": 109.0, "batch_reward": 0.81655217897892, "critic_loss": 1.5990557723045349, "actor_loss": -92.76123899841309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.565377473831177, "step": 109000}
{"episode_reward": 867.3608456059127, "episode": 110.0, "batch_reward": 0.8146936577558518, "critic_loss": 1.5570596874952316, "actor_loss": -93.11453048706055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.567140340805054, "step": 110000}
{"episode_reward": 889.3824314133865, "episode": 111.0, "batch_reward": 0.8160615742206574, "critic_loss": 1.5213941498994827, "actor_loss": -92.7568366241455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.23671221733093, "step": 111000}
{"episode_reward": 895.5220196989183, "episode": 112.0, "batch_reward": 0.816000679910183, "critic_loss": 1.5235589807629586, "actor_loss": -92.85056359863282, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.564265966415405, "step": 112000}
{"episode_reward": 900.354106952615, "episode": 113.0, "batch_reward": 0.8191623905897141, "critic_loss": 1.4968032831549645, "actor_loss": -92.85248092651368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.5605411529541, "step": 113000}
{"episode_reward": 899.5571974972243, "episode": 114.0, "batch_reward": 0.8202589944005012, "critic_loss": 1.5581007496714592, "actor_loss": -93.08215919494629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.562084197998047, "step": 114000}
{"episode_reward": 924.2730597947697, "episode": 115.0, "batch_reward": 0.8208130459189416, "critic_loss": 1.606161014676094, "actor_loss": -93.07676594543457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.565813541412354, "step": 115000}
{"episode_reward": 922.8848667518382, "episode": 116.0, "batch_reward": 0.8221559638381004, "critic_loss": 1.5739309849739074, "actor_loss": -93.09311376953124, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.56389021873474, "step": 116000}
{"episode_reward": 899.5718169774478, "episode": 117.0, "batch_reward": 0.822166575551033, "critic_loss": 1.6567698718905448, "actor_loss": -92.86484815979004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.558265924453735, "step": 117000}
{"episode_reward": 913.7921218944067, "episode": 118.0, "batch_reward": 0.8219337902665138, "critic_loss": 1.5724918887019157, "actor_loss": -92.9940271911621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.574331045150757, "step": 118000}
{"episode_reward": 881.2940112558598, "episode": 119.0, "batch_reward": 0.8223288488984108, "critic_loss": 1.5482746127843856, "actor_loss": -93.11863246154785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.56709051132202, "step": 119000}
{"episode_reward": 872.469495012955, "episode": 120.0, "batch_reward": 0.8231835080981255, "critic_loss": 1.5212414019107818, "actor_loss": -92.80848789978027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.566131353378296, "step": 120000}
{"episode_reward": 907.6466393916646, "episode": 121.0, "batch_reward": 0.8251019427180291, "critic_loss": 1.5115300631523132, "actor_loss": -93.1224835510254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.28951025009155, "step": 121000}
{"episode_reward": 905.0660843795313, "episode": 122.0, "batch_reward": 0.8239683058857917, "critic_loss": 1.4772825420498847, "actor_loss": -93.2701890411377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.562145471572876, "step": 122000}
{"episode_reward": 826.1437182976948, "episode": 123.0, "batch_reward": 0.825211367726326, "critic_loss": 1.5286421555280685, "actor_loss": -93.40397497558594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.569541931152344, "step": 123000}
{"episode_reward": 869.5199199331342, "episode": 124.0, "batch_reward": 0.8247766057252884, "critic_loss": 1.569454451560974, "actor_loss": -93.24994180297851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.56699228286743, "step": 124000}
{"episode_reward": 844.0762254468393, "episode": 125.0, "batch_reward": 0.8239988396167756, "critic_loss": 1.545890387237072, "actor_loss": -93.1428529663086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.557316541671753, "step": 125000}
{"episode_reward": 817.3159733778236, "episode": 126.0, "batch_reward": 0.8247700870037079, "critic_loss": 1.545495214164257, "actor_loss": -93.37088414001465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.563064098358154, "step": 126000}
{"episode_reward": 881.78012307282, "episode": 127.0, "batch_reward": 0.8253563020825386, "critic_loss": 1.561095166862011, "actor_loss": -93.25657081604004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.571458101272583, "step": 127000}
{"episode_reward": 920.9276537051389, "episode": 128.0, "batch_reward": 0.8265386362671852, "critic_loss": 1.6000943748950958, "actor_loss": -93.06814213562012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.556396484375, "step": 128000}
{"episode_reward": 920.162685253393, "episode": 129.0, "batch_reward": 0.8261155947446823, "critic_loss": 1.5604265136122704, "actor_loss": -93.25213429260253, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.573585748672485, "step": 129000}
{"episode_reward": 909.2621307579718, "episode": 130.0, "batch_reward": 0.8278553149700165, "critic_loss": 1.497210167646408, "actor_loss": -93.40902946472168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.569849491119385, "step": 130000}
{"episode_reward": 922.8194631892607, "episode": 131.0, "batch_reward": 0.829262025654316, "critic_loss": 1.4797626740336418, "actor_loss": -92.96548236083984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.220850706100464, "step": 131000}
{"episode_reward": 918.3312349903958, "episode": 132.0, "batch_reward": 0.8291042134165764, "critic_loss": 1.405602158367634, "actor_loss": -93.5953194732666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.554694414138794, "step": 132000}
{"episode_reward": 903.630951284791, "episode": 133.0, "batch_reward": 0.8291859754920006, "critic_loss": 1.3736425176858902, "actor_loss": -93.2017921447754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.571677207946777, "step": 133000}
{"episode_reward": 922.247068531004, "episode": 134.0, "batch_reward": 0.8299909135103226, "critic_loss": 1.3515792554020882, "actor_loss": -93.42264897155762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.564743041992188, "step": 134000}
{"episode_reward": 871.0431635211539, "episode": 135.0, "batch_reward": 0.8294637724757195, "critic_loss": 1.398953872680664, "actor_loss": -93.52868940734864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.573421716690063, "step": 135000}
{"episode_reward": 891.1750083349351, "episode": 136.0, "batch_reward": 0.8305320462584496, "critic_loss": 1.4135744849443435, "actor_loss": -93.38544491577149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.558929204940796, "step": 136000}
{"episode_reward": 876.1655365150652, "episode": 137.0, "batch_reward": 0.8309440656900405, "critic_loss": 1.452482803285122, "actor_loss": -93.58139016723632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.568060398101807, "step": 137000}
{"episode_reward": 889.1984414365114, "episode": 138.0, "batch_reward": 0.8314363284707069, "critic_loss": 1.5025724537968637, "actor_loss": -93.79603616333007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.570473432540894, "step": 138000}
{"episode_reward": 914.2128924917811, "episode": 139.0, "batch_reward": 0.8322699100375176, "critic_loss": 1.4733484367132186, "actor_loss": -93.27935452270508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.580990314483643, "step": 139000}
{"episode_reward": 914.3241406129491, "episode": 140.0, "batch_reward": 0.8317254294753075, "critic_loss": 1.4447412959337234, "actor_loss": -93.70287800598145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.568569898605347, "step": 140000}
{"episode_reward": 933.5129673602407, "episode": 141.0, "batch_reward": 0.8348687577843666, "critic_loss": 1.3642237940728665, "actor_loss": -93.55981004333496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.263028621673584, "step": 141000}
{"episode_reward": 940.404498814256, "episode": 142.0, "batch_reward": 0.8352175872921944, "critic_loss": 1.4177665829062462, "actor_loss": -93.5686305847168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.53948473930359, "step": 142000}
{"episode_reward": 874.173051226187, "episode": 143.0, "batch_reward": 0.8353903139829636, "critic_loss": 1.3644047039151193, "actor_loss": -93.63228999328614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.560658931732178, "step": 143000}
{"episode_reward": 903.2234010909804, "episode": 144.0, "batch_reward": 0.8350313370227813, "critic_loss": 1.3807470840513707, "actor_loss": -93.77437574768066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.56140446662903, "step": 144000}
{"episode_reward": 912.695003770089, "episode": 145.0, "batch_reward": 0.8356225746870041, "critic_loss": 1.411549067556858, "actor_loss": -93.73627713012695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.563739776611328, "step": 145000}
{"episode_reward": 869.3119322185097, "episode": 146.0, "batch_reward": 0.8348171231150627, "critic_loss": 1.4558952311277389, "actor_loss": -93.35880554199218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.563704013824463, "step": 146000}
{"episode_reward": 916.504067605227, "episode": 147.0, "batch_reward": 0.835637634754181, "critic_loss": 1.4008576456308366, "actor_loss": -93.60102247619629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.568967580795288, "step": 147000}
{"episode_reward": 923.9468904326294, "episode": 148.0, "batch_reward": 0.8372801830172538, "critic_loss": 1.3556500928401947, "actor_loss": -93.60302798461915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.549918174743652, "step": 148000}
{"episode_reward": 899.9072964697472, "episode": 149.0, "batch_reward": 0.8376369745135307, "critic_loss": 1.368528824210167, "actor_loss": -93.75855947875976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.57579517364502, "step": 149000}
{"episode_reward": 912.9422696346451, "episode": 150.0, "batch_reward": 0.8372588230371475, "critic_loss": 1.386130001604557, "actor_loss": -93.8357276763916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
