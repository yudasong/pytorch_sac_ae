{"episode_reward": 0.0, "episode": 1.0, "duration": 22.04848027229309, "step": 1000}
{"episode_reward": 28.002640152663393, "episode": 2.0, "duration": 1.8713555335998535, "step": 2000}
{"episode_reward": 481.4321918933315, "episode": 3.0, "batch_reward": 0.24158124448796756, "critic_loss": 0.09487560258978911, "actor_loss": -46.38534688068276, "actor_target_entropy": -6.0, "alpha_value": 0.00244617320470393, "duration": 63.98882746696472, "step": 3000}
{"episode_reward": 34.75405357629403, "episode": 4.0, "batch_reward": 0.16114195591956376, "critic_loss": 0.20456206569820642, "actor_loss": -43.804978421211246, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.62059187889099, "step": 4000}
{"episode_reward": 22.254701320954887, "episode": 5.0, "batch_reward": 0.14827586543560028, "critic_loss": 0.26432527604699135, "actor_loss": -43.37320471858978, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.087082147598267, "step": 5000}
{"episode_reward": 168.89573894165565, "episode": 6.0, "batch_reward": 0.137880832336843, "critic_loss": 0.22255211244523526, "actor_loss": -44.853585562705995, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.711822748184204, "step": 6000}
{"episode_reward": 32.88445869311029, "episode": 7.0, "batch_reward": 0.13773669221252202, "critic_loss": 0.2970103188604116, "actor_loss": -41.36877262210846, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.667069911956787, "step": 7000}
{"episode_reward": 183.3365815955432, "episode": 8.0, "batch_reward": 0.1289028524905443, "critic_loss": 0.2350131945386529, "actor_loss": -40.32417142105103, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.627628326416016, "step": 8000}
{"episode_reward": 27.14571102411648, "episode": 9.0, "batch_reward": 0.11895238200575113, "critic_loss": 0.2756725687086582, "actor_loss": -42.39140232849121, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.967689514160156, "step": 9000}
{"episode_reward": 49.347011633911166, "episode": 10.0, "batch_reward": 0.11017006137222052, "critic_loss": 0.27879517536610365, "actor_loss": -41.847489892959594, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.679065704345703, "step": 10000}
{"episode_reward": 23.727712422320028, "episode": 11.0, "batch_reward": 0.10769246924296022, "critic_loss": 0.36211066441237927, "actor_loss": -40.92348575592041, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 42.25823450088501, "step": 11000}
{"episode_reward": 89.07445977149482, "episode": 12.0, "batch_reward": 0.10685307263582945, "critic_loss": 0.4611024296730757, "actor_loss": -41.06429454898834, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.634918212890625, "step": 12000}
{"episode_reward": 190.64282859433945, "episode": 13.0, "batch_reward": 0.11499515959620475, "critic_loss": 0.6177515575736761, "actor_loss": -41.04853729915619, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.687991857528687, "step": 13000}
{"episode_reward": 167.37839625745102, "episode": 14.0, "batch_reward": 0.12139153942465782, "critic_loss": 0.8512580553293229, "actor_loss": -41.59077445220947, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.137157917022705, "step": 14000}
{"episode_reward": 304.3472214532373, "episode": 15.0, "batch_reward": 0.1305309269875288, "critic_loss": 1.0142795056700706, "actor_loss": -43.893641526222225, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.751266956329346, "step": 15000}
{"episode_reward": 120.95774370064596, "episode": 16.0, "batch_reward": 0.12779696240276098, "critic_loss": 1.0771706689596177, "actor_loss": -43.535047721862796, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.73474431037903, "step": 16000}
{"episode_reward": 86.36947281871242, "episode": 17.0, "batch_reward": 0.12749251251667737, "critic_loss": 0.9499265786707402, "actor_loss": -43.585712533950804, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.026447057724, "step": 17000}
{"episode_reward": 135.72776514841937, "episode": 18.0, "batch_reward": 0.1278287838920951, "critic_loss": 0.9296948084235191, "actor_loss": -44.10752255821228, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.51822805404663, "step": 18000}
{"episode_reward": 111.81235768159397, "episode": 19.0, "batch_reward": 0.1344061923623085, "critic_loss": 0.9907354608476162, "actor_loss": -44.26155884170532, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.688835859298706, "step": 19000}
{"episode_reward": 471.5255771023939, "episode": 20.0, "batch_reward": 0.14995146799087525, "critic_loss": 1.0661956598758697, "actor_loss": -47.64992759895325, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.677053213119507, "step": 20000}
{"episode_reward": 298.4569827611261, "episode": 21.0, "batch_reward": 0.15924457531422376, "critic_loss": 1.0314027129411698, "actor_loss": -43.500600938797, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.42807936668396, "step": 21000}
{"episode_reward": 433.0035420958051, "episode": 22.0, "batch_reward": 0.16698533073067665, "critic_loss": 1.0791466091275215, "actor_loss": -48.806063844680786, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.08835244178772, "step": 22000}
{"episode_reward": 197.1756085382473, "episode": 23.0, "batch_reward": 0.16763851634413005, "critic_loss": 0.965150494068861, "actor_loss": -47.58896089553833, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.006265878677368, "step": 23000}
{"episode_reward": 205.94570795259455, "episode": 24.0, "batch_reward": 0.17164332170039415, "critic_loss": 0.9748159585297108, "actor_loss": -47.79263168716431, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.756850719451904, "step": 24000}
{"episode_reward": 413.986851230396, "episode": 25.0, "batch_reward": 0.18446483910083772, "critic_loss": 0.9568776335716248, "actor_loss": -49.57938262557983, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.168583631515503, "step": 25000}
{"episode_reward": 381.7333347290066, "episode": 26.0, "batch_reward": 0.19314458271861076, "critic_loss": 0.9429620570838452, "actor_loss": -49.16246153259277, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.338193893432617, "step": 26000}
{"episode_reward": 394.00408305878165, "episode": 27.0, "batch_reward": 0.196178872525692, "critic_loss": 0.8999444123208523, "actor_loss": -48.39279884338379, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.95285415649414, "step": 27000}
{"episode_reward": 408.776788248889, "episode": 28.0, "batch_reward": 0.20486383516341447, "critic_loss": 0.8886839602887631, "actor_loss": -50.381765449523925, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.133716821670532, "step": 28000}
{"episode_reward": 304.8392471199157, "episode": 29.0, "batch_reward": 0.2119284526258707, "critic_loss": 0.9548029066324234, "actor_loss": -50.24953160858154, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.048719882965088, "step": 29000}
{"episode_reward": 684.7593044932992, "episode": 30.0, "batch_reward": 0.2302574720531702, "critic_loss": 1.1732168136835097, "actor_loss": -48.70303029251099, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.203280687332153, "step": 30000}
{"episode_reward": 610.2093232050624, "episode": 31.0, "batch_reward": 0.24377508798241615, "critic_loss": 1.342986002266407, "actor_loss": -51.19058932495117, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 42.207085847854614, "step": 31000}
{"episode_reward": 594.8470072042135, "episode": 32.0, "batch_reward": 0.25098665118217467, "critic_loss": 1.3692360521554947, "actor_loss": -53.82619762420654, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.760811805725098, "step": 32000}
{"episode_reward": 465.89548079930955, "episode": 33.0, "batch_reward": 0.26001020027697086, "critic_loss": 1.409607037782669, "actor_loss": -53.889900035858155, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.242848873138428, "step": 33000}
{"episode_reward": 539.5173263047799, "episode": 34.0, "batch_reward": 0.26910201108455656, "critic_loss": 1.5155358543395996, "actor_loss": -52.777475723266605, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.293508052825928, "step": 34000}
{"episode_reward": 674.731516914303, "episode": 35.0, "batch_reward": 0.27701785841584203, "critic_loss": 1.7066459501981734, "actor_loss": -55.09640647506714, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.862386465072632, "step": 35000}
{"episode_reward": 655.1009978997198, "episode": 36.0, "batch_reward": 0.28963522882759574, "critic_loss": 1.8913943946361542, "actor_loss": -56.18383121871948, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.170310497283936, "step": 36000}
{"episode_reward": 659.7536034913259, "episode": 37.0, "batch_reward": 0.30187868781387805, "critic_loss": 1.8671481613516807, "actor_loss": -55.4493466835022, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.617454051971436, "step": 37000}
{"episode_reward": 773.4857961435691, "episode": 38.0, "batch_reward": 0.31217410883307456, "critic_loss": 2.050642308354378, "actor_loss": -56.891777622222904, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.666561365127563, "step": 38000}
{"episode_reward": 747.907629772769, "episode": 39.0, "batch_reward": 0.32580899983644485, "critic_loss": 2.1001614835262297, "actor_loss": -57.232440071105955, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.27832531929016, "step": 39000}
{"episode_reward": 787.7406875598641, "episode": 40.0, "batch_reward": 0.3374324340969324, "critic_loss": 2.201530724644661, "actor_loss": -58.19258062744141, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.489534616470337, "step": 40000}
{"episode_reward": 731.5568432427472, "episode": 41.0, "batch_reward": 0.34727315160632133, "critic_loss": 2.2114340111017228, "actor_loss": -58.18675260162353, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 42.2814199924469, "step": 41000}
{"episode_reward": 816.7232490992566, "episode": 42.0, "batch_reward": 0.35938615643978117, "critic_loss": 2.246761232495308, "actor_loss": -59.723100807189944, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.45965051651001, "step": 42000}
{"episode_reward": 785.3967475532993, "episode": 43.0, "batch_reward": 0.3675841391682625, "critic_loss": 2.3982857949733734, "actor_loss": -61.990921180725095, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.96232843399048, "step": 43000}
{"episode_reward": 756.8573254545809, "episode": 44.0, "batch_reward": 0.37676777070760725, "critic_loss": 2.534727976799011, "actor_loss": -64.16611093902588, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.25483465194702, "step": 44000}
{"episode_reward": 765.1632419790759, "episode": 45.0, "batch_reward": 0.3865985211133957, "critic_loss": 2.9526075422763824, "actor_loss": -63.33535906982422, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.633838653564453, "step": 45000}
{"episode_reward": 830.1872681881723, "episode": 46.0, "batch_reward": 0.3933289652466774, "critic_loss": 3.2272989758253097, "actor_loss": -63.32219976043701, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.655986070632935, "step": 46000}
{"episode_reward": 779.2611364966424, "episode": 47.0, "batch_reward": 0.4045102191269398, "critic_loss": 5.066718116879463, "actor_loss": -65.11055503845215, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.109184503555298, "step": 47000}
{"episode_reward": 832.5209656939105, "episode": 48.0, "batch_reward": 0.4124444894492626, "critic_loss": 5.5161670932769775, "actor_loss": -65.7873264465332, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.44660711288452, "step": 48000}
{"episode_reward": 616.1886184755505, "episode": 49.0, "batch_reward": 0.4145180034637451, "critic_loss": 14.214976108193397, "actor_loss": -68.34206065368652, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.657485485076904, "step": 49000}
{"episode_reward": 256.40940865535725, "episode": 50.0, "batch_reward": 0.4078620664477348, "critic_loss": 16.32372678375244, "actor_loss": -70.10542676544189, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.5958034992218, "step": 50000}
{"episode_reward": 61.87958489998667, "episode": 51.0, "batch_reward": 0.40177399000525477, "critic_loss": 25.212141389846803, "actor_loss": -75.86684777069092, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.13717794418335, "step": 51000}
{"episode_reward": 36.703523067010174, "episode": 52.0, "batch_reward": 0.39410603034496305, "critic_loss": 50.76220837688446, "actor_loss": -86.98899858093262, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.743261098861694, "step": 52000}
{"episode_reward": 35.669050247552754, "episode": 53.0, "batch_reward": 0.38782977229356763, "critic_loss": 85.38262894821167, "actor_loss": -98.0484415435791, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.75490665435791, "step": 53000}
{"episode_reward": 38.345506134172616, "episode": 54.0, "batch_reward": 0.38162312403321264, "critic_loss": 104.36583430480957, "actor_loss": -109.59743557739257, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.662993907928467, "step": 54000}
{"episode_reward": 38.05711728858357, "episode": 55.0, "batch_reward": 0.3707158928215504, "critic_loss": 117.38864628601074, "actor_loss": -126.97424044799804, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.076988697052002, "step": 55000}
{"episode_reward": 14.050452722516143, "episode": 56.0, "batch_reward": 0.3655879537165165, "critic_loss": 127.10749434661865, "actor_loss": -139.77573872375487, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.34256410598755, "step": 56000}
{"episode_reward": 45.333603554828606, "episode": 57.0, "batch_reward": 0.36095238621532916, "critic_loss": 147.51315406417848, "actor_loss": -158.27050312805176, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.665006160736084, "step": 57000}
{"episode_reward": 62.75035267039069, "episode": 58.0, "batch_reward": 0.3554276624917984, "critic_loss": 150.5131916732788, "actor_loss": -166.0910615081787, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.0029456615448, "step": 58000}
{"episode_reward": 68.64988799422217, "episode": 59.0, "batch_reward": 0.351540503308177, "critic_loss": 148.54004304504394, "actor_loss": -180.24391960144044, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.00748372077942, "step": 59000}
{"episode_reward": 59.568236942004745, "episode": 60.0, "batch_reward": 0.3485739792883396, "critic_loss": 129.77082089996338, "actor_loss": -182.1149832611084, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.180550575256348, "step": 60000}
{"episode_reward": 164.97724027595672, "episode": 61.0, "batch_reward": 0.34584617426991465, "critic_loss": 116.72143967437744, "actor_loss": -195.49351446533203, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 42.025590658187866, "step": 61000}
{"episode_reward": 179.6532686108582, "episode": 62.0, "batch_reward": 0.34136506110429765, "critic_loss": 99.10230567932129, "actor_loss": -183.28575341796875, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.263828992843628, "step": 62000}
{"episode_reward": 37.901213754806015, "episode": 63.0, "batch_reward": 0.33838286839425563, "critic_loss": 82.08275387573242, "actor_loss": -199.91176567077636, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.857473850250244, "step": 63000}
{"episode_reward": 273.5381301659506, "episode": 64.0, "batch_reward": 0.33608855862915515, "critic_loss": 67.24190657043457, "actor_loss": -188.48732484436036, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.647987365722656, "step": 64000}
{"episode_reward": 132.1354754820042, "episode": 65.0, "batch_reward": 0.3312148519307375, "critic_loss": 56.04652164268494, "actor_loss": -191.54150921630858, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.709656238555908, "step": 65000}
{"episode_reward": 66.83961963440952, "episode": 66.0, "batch_reward": 0.32723323115706443, "critic_loss": 46.300532957077024, "actor_loss": -186.85904823303224, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.221487283706665, "step": 66000}
{"episode_reward": 46.86321418578436, "episode": 67.0, "batch_reward": 0.32291135166585444, "critic_loss": 39.67343385887146, "actor_loss": -178.52291061401368, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.66924524307251, "step": 67000}
{"episode_reward": 79.73402291001173, "episode": 68.0, "batch_reward": 0.3200763376802206, "critic_loss": 34.52159284210205, "actor_loss": -175.63763655090332, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.012084007263184, "step": 68000}
{"episode_reward": 15.767953634711809, "episode": 69.0, "batch_reward": 0.3148020479679108, "critic_loss": 29.211468214035033, "actor_loss": -183.5061570892334, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.086303234100342, "step": 69000}
{"episode_reward": 104.37079432694087, "episode": 70.0, "batch_reward": 0.3124499405473471, "critic_loss": 26.57703154182434, "actor_loss": -179.2060666809082, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.81230092048645, "step": 70000}
{"episode_reward": 110.63837974650596, "episode": 71.0, "batch_reward": 0.30947213181853295, "critic_loss": 23.191930183410644, "actor_loss": -178.95226205444337, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 42.018892765045166, "step": 71000}
{"episode_reward": 16.814515568321205, "episode": 72.0, "batch_reward": 0.30657965222001077, "critic_loss": 21.187635340690612, "actor_loss": -175.38735928344727, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.626699924468994, "step": 72000}
{"episode_reward": 16.396101825514954, "episode": 73.0, "batch_reward": 0.30103385652601716, "critic_loss": 18.473928191185, "actor_loss": -171.34818682861328, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.985719442367554, "step": 73000}
{"episode_reward": 16.56915714897359, "episode": 74.0, "batch_reward": 0.2988544238060713, "critic_loss": 17.368286375045777, "actor_loss": -167.38518951416015, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.4588520526886, "step": 74000}
{"episode_reward": 14.780588862207564, "episode": 75.0, "batch_reward": 0.293042706862092, "critic_loss": 16.78347583961487, "actor_loss": -164.6029288330078, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.67150855064392, "step": 75000}
{"episode_reward": 17.378060017074414, "episode": 76.0, "batch_reward": 0.28733700986206534, "critic_loss": 15.723406062126159, "actor_loss": -163.6140192718506, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.205848693847656, "step": 76000}
{"episode_reward": 16.07882784732219, "episode": 77.0, "batch_reward": 0.28572600248456004, "critic_loss": 14.601013354301452, "actor_loss": -157.3890174255371, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.6504328250885, "step": 77000}
{"episode_reward": 206.92037207112432, "episode": 78.0, "batch_reward": 0.2856951430141926, "critic_loss": 12.984789900302887, "actor_loss": -158.50546705627443, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.846164226531982, "step": 78000}
{"episode_reward": 118.98655347013757, "episode": 79.0, "batch_reward": 0.28502356819808483, "critic_loss": 11.84532897043228, "actor_loss": -147.7461153411865, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.13011384010315, "step": 79000}
{"episode_reward": 19.1424531938952, "episode": 80.0, "batch_reward": 0.282296423971653, "critic_loss": 10.381245829105378, "actor_loss": -145.91720056152343, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.276190996170044, "step": 80000}
{"episode_reward": 308.18515774094806, "episode": 81.0, "batch_reward": 0.2830150784254074, "critic_loss": 8.843933713436126, "actor_loss": -142.03084651184082, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 42.41389799118042, "step": 81000}
{"episode_reward": 505.4038154993029, "episode": 82.0, "batch_reward": 0.2838638326972723, "critic_loss": 7.531097788333893, "actor_loss": -143.74628134155273, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.347466707229614, "step": 82000}
{"episode_reward": 24.202353357868258, "episode": 83.0, "batch_reward": 0.2840395032316446, "critic_loss": 6.77799481678009, "actor_loss": -134.85945024108887, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.2621910572052, "step": 83000}
{"episode_reward": 684.0563239098104, "episode": 84.0, "batch_reward": 0.28582557921111584, "critic_loss": 5.765834528446198, "actor_loss": -130.81901347351075, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.8572199344635, "step": 84000}
{"episode_reward": 343.7744293810794, "episode": 85.0, "batch_reward": 0.28974322699010374, "critic_loss": 5.371168617725372, "actor_loss": -131.71700985717774, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.64462685585022, "step": 85000}
{"episode_reward": 869.543245605433, "episode": 86.0, "batch_reward": 0.2961388249248266, "critic_loss": 4.859633908510208, "actor_loss": -128.6021384124756, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.39435911178589, "step": 86000}
{"episode_reward": 796.726362370911, "episode": 87.0, "batch_reward": 0.3016059516966343, "critic_loss": 4.512031182646751, "actor_loss": -123.28383154296876, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.19569492340088, "step": 87000}
{"episode_reward": 830.6511055587524, "episode": 88.0, "batch_reward": 0.30860223326087, "critic_loss": 4.010716929554939, "actor_loss": -121.40585537719727, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.74202871322632, "step": 88000}
{"episode_reward": 680.4009466584023, "episode": 89.0, "batch_reward": 0.31482667398452757, "critic_loss": 3.9709388452768324, "actor_loss": -121.84464808654785, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.723742485046387, "step": 89000}
{"episode_reward": 772.1575715973071, "episode": 90.0, "batch_reward": 0.319254275649786, "critic_loss": 3.788051184415817, "actor_loss": -119.06179304504394, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.9245445728302, "step": 90000}
{"episode_reward": 837.6917354945087, "episode": 91.0, "batch_reward": 0.32600837503373625, "critic_loss": 3.9090991480350494, "actor_loss": -118.1450888519287, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.832499742507935, "step": 91000}
{"episode_reward": 897.0962424106976, "episode": 92.0, "batch_reward": 0.3297099806666374, "critic_loss": 3.756983830332756, "actor_loss": -112.6489529724121, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.263590335845947, "step": 92000}
{"episode_reward": 908.1738170867873, "episode": 93.0, "batch_reward": 0.3356649827808142, "critic_loss": 3.665898919582367, "actor_loss": -113.78336776733398, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.845201015472412, "step": 93000}
{"episode_reward": 880.7917279590606, "episode": 94.0, "batch_reward": 0.34370310145616534, "critic_loss": 3.427826385617256, "actor_loss": -109.06535591125488, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.120989322662354, "step": 94000}
{"episode_reward": 887.6178924934155, "episode": 95.0, "batch_reward": 0.34813047960400584, "critic_loss": 3.3936267372369766, "actor_loss": -105.59018875122071, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.890254735946655, "step": 95000}
{"episode_reward": 739.3056212603869, "episode": 96.0, "batch_reward": 0.3517849649488926, "critic_loss": 3.144147283196449, "actor_loss": -106.65530891418457, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.143163919448853, "step": 96000}
{"episode_reward": 926.0724883001004, "episode": 97.0, "batch_reward": 0.356985606610775, "critic_loss": 3.092588556647301, "actor_loss": -106.07938766479492, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.044543743133545, "step": 97000}
{"episode_reward": 900.9893823370536, "episode": 98.0, "batch_reward": 0.36141021326184275, "critic_loss": 2.9409108078479766, "actor_loss": -101.7832819519043, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.704993963241577, "step": 98000}
{"episode_reward": 849.514333082412, "episode": 99.0, "batch_reward": 0.36873786890506743, "critic_loss": 2.8571306047439573, "actor_loss": -101.22302987670898, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.271227598190308, "step": 99000}
{"episode_reward": 881.0951443439492, "episode": 100.0, "batch_reward": 0.3728779012262821, "critic_loss": 2.7640215587615966, "actor_loss": -100.70236935424805, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.530308485031128, "step": 100000}
{"episode_reward": 872.1795370977167, "episode": 101.0, "batch_reward": 0.37926651576161385, "critic_loss": 2.7178624716997146, "actor_loss": -100.44718399047852, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.632367849349976, "step": 101000}
{"episode_reward": 882.3576964979943, "episode": 102.0, "batch_reward": 0.38481486985087393, "critic_loss": 2.663556539773941, "actor_loss": -98.2745947113037, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.635655403137207, "step": 102000}
{"episode_reward": 812.2128740927122, "episode": 103.0, "batch_reward": 0.38920305415987966, "critic_loss": 2.467343091726303, "actor_loss": -97.4461711883545, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.609089136123657, "step": 103000}
{"episode_reward": 940.2190078049441, "episode": 104.0, "batch_reward": 0.3934128632247448, "critic_loss": 2.2763202887773515, "actor_loss": -97.60758387756347, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.909963846206665, "step": 104000}
{"episode_reward": 948.9622480900866, "episode": 105.0, "batch_reward": 0.4013707275390625, "critic_loss": 2.1863314774036406, "actor_loss": -96.02301232910156, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.4221134185791, "step": 105000}
{"episode_reward": 897.4202748959019, "episode": 106.0, "batch_reward": 0.40370377504825594, "critic_loss": 2.1677710334062574, "actor_loss": -95.75817384338379, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.947952032089233, "step": 106000}
{"episode_reward": 928.8340160064985, "episode": 107.0, "batch_reward": 0.40717938968539236, "critic_loss": 2.0736946295499803, "actor_loss": -94.756007522583, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.156707763671875, "step": 107000}
{"episode_reward": 921.2339149252792, "episode": 108.0, "batch_reward": 0.4130831840634346, "critic_loss": 2.0517351559996606, "actor_loss": -92.98447305297852, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.431731700897217, "step": 108000}
{"episode_reward": 920.9304440651491, "episode": 109.0, "batch_reward": 0.4187818982005119, "critic_loss": 1.9375937370061875, "actor_loss": -93.04753567504883, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.11426091194153, "step": 109000}
{"episode_reward": 895.9630647561327, "episode": 110.0, "batch_reward": 0.42307159209251405, "critic_loss": 2.0339529709219932, "actor_loss": -92.03408731079102, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.045262336730957, "step": 110000}
{"episode_reward": 896.4283377158636, "episode": 111.0, "batch_reward": 0.4270966794490814, "critic_loss": 2.080678361237049, "actor_loss": -91.88554418945313, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.11285042762756, "step": 111000}
{"episode_reward": 961.4199619331539, "episode": 112.0, "batch_reward": 0.42883618906140325, "critic_loss": 1.9392371146082878, "actor_loss": -90.74574546813965, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.17046332359314, "step": 112000}
{"episode_reward": 706.8570620612192, "episode": 113.0, "batch_reward": 0.4353433554768562, "critic_loss": 1.8899216465353965, "actor_loss": -91.04408465576172, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.575151205062866, "step": 113000}
{"episode_reward": 952.3057464356378, "episode": 114.0, "batch_reward": 0.4396051747202873, "critic_loss": 1.7975917356610298, "actor_loss": -90.21213475036622, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.793020725250244, "step": 114000}
{"episode_reward": 921.5368855044605, "episode": 115.0, "batch_reward": 0.44270722115039823, "critic_loss": 1.9072693645954133, "actor_loss": -89.81616288757324, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.105961084365845, "step": 115000}
{"episode_reward": 904.6445031325553, "episode": 116.0, "batch_reward": 0.4477915153503418, "critic_loss": 1.775490573644638, "actor_loss": -89.5706042175293, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.043938636779785, "step": 116000}
{"episode_reward": 961.0761079451765, "episode": 117.0, "batch_reward": 0.4527449139654636, "critic_loss": 1.7589676366448403, "actor_loss": -89.61890731811523, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.26581335067749, "step": 117000}
{"episode_reward": 892.3606834178537, "episode": 118.0, "batch_reward": 0.45533403372764586, "critic_loss": 1.8362746323943138, "actor_loss": -89.21895616149902, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.59555459022522, "step": 118000}
{"episode_reward": 939.5901237254458, "episode": 119.0, "batch_reward": 0.45980377197265626, "critic_loss": 1.7888526654839516, "actor_loss": -88.78388371276856, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.640050888061523, "step": 119000}
{"episode_reward": 917.4560384827853, "episode": 120.0, "batch_reward": 0.4628805375397205, "critic_loss": 1.7283737585544585, "actor_loss": -88.52245094299316, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.519407510757446, "step": 120000}
{"episode_reward": 846.2217542629994, "episode": 121.0, "batch_reward": 0.4659282637536526, "critic_loss": 1.6671659668684007, "actor_loss": -88.19039080810546, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.16881775856018, "step": 121000}
{"episode_reward": 846.4967838025932, "episode": 122.0, "batch_reward": 0.4711043149232864, "critic_loss": 1.7632897190451622, "actor_loss": -87.79667024230957, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.54499888420105, "step": 122000}
{"episode_reward": 912.4892952533673, "episode": 123.0, "batch_reward": 0.47431712144613264, "critic_loss": 1.75917109978199, "actor_loss": -87.6006763305664, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.628839254379272, "step": 123000}
{"episode_reward": 955.9121000442184, "episode": 124.0, "batch_reward": 0.4786939522624016, "critic_loss": 1.7601827960014342, "actor_loss": -87.39167227172851, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.615174055099487, "step": 124000}
{"episode_reward": 927.5865549829026, "episode": 125.0, "batch_reward": 0.4810444590449333, "critic_loss": 1.7209661759138106, "actor_loss": -87.06140280151367, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.064778566360474, "step": 125000}
{"episode_reward": 931.8153428507784, "episode": 126.0, "batch_reward": 0.4833885151743889, "critic_loss": 1.7069160323143004, "actor_loss": -86.75962768554687, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.355961799621582, "step": 126000}
{"episode_reward": 944.0006804704137, "episode": 127.0, "batch_reward": 0.4872162719666958, "critic_loss": 1.619270964384079, "actor_loss": -86.53757319641113, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.28022313117981, "step": 127000}
{"episode_reward": 922.2484661825642, "episode": 128.0, "batch_reward": 0.4917727303206921, "critic_loss": 1.6140570975542068, "actor_loss": -86.52226544189453, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.980600118637085, "step": 128000}
{"episode_reward": 938.505652507243, "episode": 129.0, "batch_reward": 0.4947367971241474, "critic_loss": 1.5831576808094978, "actor_loss": -86.26817684936523, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.7335102558136, "step": 129000}
{"episode_reward": 958.1556312024691, "episode": 130.0, "batch_reward": 0.49747256135940554, "critic_loss": 1.6117845631837844, "actor_loss": -86.25618179321289, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.226568460464478, "step": 130000}
{"episode_reward": 871.9101082381331, "episode": 131.0, "batch_reward": 0.5007053781151771, "critic_loss": 1.5886056934595107, "actor_loss": -86.16361399841308, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.39749836921692, "step": 131000}
{"episode_reward": 966.6857665057224, "episode": 132.0, "batch_reward": 0.5044002233743667, "critic_loss": 1.636261721909046, "actor_loss": -86.15602032470703, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.17204999923706, "step": 132000}
{"episode_reward": 913.2286321121401, "episode": 133.0, "batch_reward": 0.5079846684634686, "critic_loss": 1.5590950122475624, "actor_loss": -85.9462587738037, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.253732681274414, "step": 133000}
{"episode_reward": 971.9777703344457, "episode": 134.0, "batch_reward": 0.5095916258692741, "critic_loss": 1.5606415335536004, "actor_loss": -85.9005527191162, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.276275634765625, "step": 134000}
{"episode_reward": 937.394307324096, "episode": 135.0, "batch_reward": 0.513731419801712, "critic_loss": 1.5965698144435883, "actor_loss": -86.02696333312988, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.132853031158447, "step": 135000}
{"episode_reward": 942.8330208231511, "episode": 136.0, "batch_reward": 0.5178410227298736, "critic_loss": 1.4881504362225533, "actor_loss": -86.00783990478516, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.01823592185974, "step": 136000}
{"episode_reward": 905.3796138768679, "episode": 137.0, "batch_reward": 0.5210782295465469, "critic_loss": 1.5327233870029449, "actor_loss": -86.02180111694337, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.64127016067505, "step": 137000}
{"episode_reward": 933.9979904782989, "episode": 138.0, "batch_reward": 0.5192909190952778, "critic_loss": 1.6006663954854012, "actor_loss": -85.6655016784668, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.508589506149292, "step": 138000}
{"episode_reward": 70.57463405767224, "episode": 139.0, "batch_reward": 0.519666044652462, "critic_loss": 1.5942578148841857, "actor_loss": -85.43379444885254, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.086979389190674, "step": 139000}
{"episode_reward": 916.340608601427, "episode": 140.0, "batch_reward": 0.5210246257781982, "critic_loss": 1.4769685283899308, "actor_loss": -85.33005743408204, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.669216871261597, "step": 140000}
{"episode_reward": 942.466958147313, "episode": 141.0, "batch_reward": 0.5268893028497696, "critic_loss": 1.4558585293292998, "actor_loss": -85.28553407287598, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.9782931804657, "step": 141000}
{"episode_reward": 942.2253103320306, "episode": 142.0, "batch_reward": 0.5278618601858616, "critic_loss": 1.5012641731500627, "actor_loss": -85.3138263244629, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.67412829399109, "step": 142000}
{"episode_reward": 861.3781840814231, "episode": 143.0, "batch_reward": 0.5301470295488835, "critic_loss": 1.4902921885848046, "actor_loss": -85.31446936035157, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.447785139083862, "step": 143000}
{"episode_reward": 883.2077828227907, "episode": 144.0, "batch_reward": 0.5342210015058517, "critic_loss": 1.52136609095335, "actor_loss": -85.43107757568359, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.934540033340454, "step": 144000}
{"episode_reward": 939.5566810209681, "episode": 145.0, "batch_reward": 0.5362727048695087, "critic_loss": 1.4806326179504394, "actor_loss": -85.69141871643066, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.644031524658203, "step": 145000}
{"episode_reward": 946.9046781740755, "episode": 146.0, "batch_reward": 0.5368762061595916, "critic_loss": 1.5473115970492364, "actor_loss": -85.21345303344727, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.40535283088684, "step": 146000}
{"episode_reward": 927.0835442829954, "episode": 147.0, "batch_reward": 0.5411592057645321, "critic_loss": 1.5417369600534439, "actor_loss": -85.39573262023926, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.991897344589233, "step": 147000}
{"episode_reward": 956.3845856823714, "episode": 148.0, "batch_reward": 0.5443323779404163, "critic_loss": 1.4931060925722122, "actor_loss": -85.38001985168457, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.64832067489624, "step": 148000}
{"episode_reward": 877.3940939491807, "episode": 149.0, "batch_reward": 0.5472917145490647, "critic_loss": 1.5106719191670417, "actor_loss": -85.34751284790039, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.674601078033447, "step": 149000}
{"episode_reward": 900.7945421609818, "episode": 150.0, "batch_reward": 0.5495351994335651, "critic_loss": 1.626143693268299, "actor_loss": -85.5389005126953, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "step": 150000}
