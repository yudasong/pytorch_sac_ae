{"episode_reward": 0.0, "episode": 1.0, "duration": 22.159828186035156, "step": 1000}
{"episode_reward": 28.002640152663393, "episode": 2.0, "duration": 1.9181644916534424, "step": 2000}
{"episode_reward": 481.4321918933315, "episode": 3.0, "batch_reward": 0.26492391715510044, "critic_loss": 0.4607206100586177, "actor_loss": -84.21373819913708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 69.68788886070251, "step": 3000}
{"episode_reward": 368.45658470485563, "episode": 4.0, "batch_reward": 0.3060629758387804, "critic_loss": 0.5058796091675758, "actor_loss": -83.06961894226075, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.215815544128418, "step": 4000}
{"episode_reward": 435.5979479952815, "episode": 5.0, "batch_reward": 0.295828683167696, "critic_loss": 0.4339620573818684, "actor_loss": -81.55828985595703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.27832555770874, "step": 5000}
{"episode_reward": 23.42429550708356, "episode": 6.0, "batch_reward": 0.2920774347633123, "critic_loss": 0.755891583532095, "actor_loss": -80.75001333618164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.246369123458862, "step": 6000}
{"episode_reward": 552.1573613991386, "episode": 7.0, "batch_reward": 0.3366033967137337, "critic_loss": 1.1277488543689251, "actor_loss": -81.62324726867676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.21242332458496, "step": 7000}
{"episode_reward": 606.4740898577946, "episode": 8.0, "batch_reward": 0.3608684318065643, "critic_loss": 1.4451259667873382, "actor_loss": -81.95094682312012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.46659207344055, "step": 8000}
{"episode_reward": 508.3294712923904, "episode": 9.0, "batch_reward": 0.3972638357281685, "critic_loss": 1.3033575600385665, "actor_loss": -82.44861434936523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.192278146743774, "step": 9000}
{"episode_reward": 713.7084539312481, "episode": 10.0, "batch_reward": 0.4328032275438309, "critic_loss": 1.1913668599128724, "actor_loss": -83.43835034179688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.191107749938965, "step": 10000}
{"episode_reward": 757.6664391102922, "episode": 11.0, "batch_reward": 0.4585639274418354, "critic_loss": 1.1499826119542123, "actor_loss": -83.4225895690918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.011693716049194, "step": 11000}
{"episode_reward": 688.302724330409, "episode": 12.0, "batch_reward": 0.4755403704047203, "critic_loss": 1.109584679722786, "actor_loss": -83.81047926330567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.203691720962524, "step": 12000}
{"episode_reward": 650.1478089865896, "episode": 13.0, "batch_reward": 0.4712978176474571, "critic_loss": 1.0412140082120895, "actor_loss": -82.99486526489258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.224915742874146, "step": 13000}
{"episode_reward": 256.03116255033507, "episode": 14.0, "batch_reward": 0.474948739618063, "critic_loss": 1.0579819396734238, "actor_loss": -82.86321952819824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.190284729003906, "step": 14000}
{"episode_reward": 739.7611569027845, "episode": 15.0, "batch_reward": 0.49346518152952196, "critic_loss": 1.146438950240612, "actor_loss": -83.36004103088379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.212236881256104, "step": 15000}
{"episode_reward": 751.9370364333683, "episode": 16.0, "batch_reward": 0.5087231986522674, "critic_loss": 1.2457927745580673, "actor_loss": -83.84151908874512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.211223363876343, "step": 16000}
{"episode_reward": 736.8607221153545, "episode": 17.0, "batch_reward": 0.5286989061832428, "critic_loss": 1.282724142730236, "actor_loss": -83.38995098876953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.20885682106018, "step": 17000}
{"episode_reward": 834.396038060637, "episode": 18.0, "batch_reward": 0.5377482522130013, "critic_loss": 1.4096848592162132, "actor_loss": -83.73189280700683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.179893970489502, "step": 18000}
{"episode_reward": 623.4057027371475, "episode": 19.0, "batch_reward": 0.5458153128921985, "critic_loss": 1.5789087854623796, "actor_loss": -83.71076844787598, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.188178777694702, "step": 19000}
{"episode_reward": 773.057314468559, "episode": 20.0, "batch_reward": 0.5493134140074253, "critic_loss": 1.6065953327417373, "actor_loss": -84.4581417388916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.138643503189087, "step": 20000}
{"episode_reward": 463.3984064835105, "episode": 21.0, "batch_reward": 0.556539817482233, "critic_loss": 1.6356943562030792, "actor_loss": -83.34681944274902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.84774351119995, "step": 21000}
{"episode_reward": 819.4748843996533, "episode": 22.0, "batch_reward": 0.564182619780302, "critic_loss": 1.6939602706432342, "actor_loss": -84.18372848510742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.139270067214966, "step": 22000}
{"episode_reward": 699.6456706833319, "episode": 23.0, "batch_reward": 0.5730761487483979, "critic_loss": 1.746413260936737, "actor_loss": -83.71744863891601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.05778980255127, "step": 23000}
{"episode_reward": 825.4285190475072, "episode": 24.0, "batch_reward": 0.5759088621139526, "critic_loss": 1.7618500701785087, "actor_loss": -84.17989343261719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.736008167266846, "step": 24000}
{"episode_reward": 523.9354684906591, "episode": 25.0, "batch_reward": 0.5833172297179698, "critic_loss": 1.7931735565662383, "actor_loss": -84.87695379638672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.241032123565674, "step": 25000}
{"episode_reward": 859.3153379259553, "episode": 26.0, "batch_reward": 0.5907298038899899, "critic_loss": 1.78754842287302, "actor_loss": -84.39514285278321, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.25357151031494, "step": 26000}
{"episode_reward": 771.0447638728684, "episode": 27.0, "batch_reward": 0.5996647180914879, "critic_loss": 1.8667054972052575, "actor_loss": -84.54918672180176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.229868412017822, "step": 27000}
{"episode_reward": 887.8913818147861, "episode": 28.0, "batch_reward": 0.6118675984442234, "critic_loss": 1.8531641768217086, "actor_loss": -84.7062742767334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.236982822418213, "step": 28000}
{"episode_reward": 902.9577180643722, "episode": 29.0, "batch_reward": 0.6198497828245163, "critic_loss": 1.7530178163647652, "actor_loss": -85.20856219482422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.22517991065979, "step": 29000}
{"episode_reward": 862.3311537725891, "episode": 30.0, "batch_reward": 0.629952097594738, "critic_loss": 1.6778587684035302, "actor_loss": -85.16405142211914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.243731021881104, "step": 30000}
{"episode_reward": 857.4883696252191, "episode": 31.0, "batch_reward": 0.6381830669641495, "critic_loss": 1.5447865726947785, "actor_loss": -85.3222392578125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.921547651290894, "step": 31000}
{"episode_reward": 924.1568743567756, "episode": 32.0, "batch_reward": 0.6473060222268104, "critic_loss": 1.5319278509616852, "actor_loss": -85.72746003723145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.209845304489136, "step": 32000}
{"episode_reward": 900.2379859209, "episode": 33.0, "batch_reward": 0.654254237651825, "critic_loss": 1.4006942029595375, "actor_loss": -86.18040673828125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.213637113571167, "step": 33000}
{"episode_reward": 917.4530401689154, "episode": 34.0, "batch_reward": 0.6619072744846344, "critic_loss": 1.3608753296136855, "actor_loss": -86.3022788848877, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.24138045310974, "step": 34000}
{"episode_reward": 796.8191778815623, "episode": 35.0, "batch_reward": 0.6663209101557732, "critic_loss": 1.293048362314701, "actor_loss": -86.67800959777831, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.206770658493042, "step": 35000}
{"episode_reward": 882.088305334733, "episode": 36.0, "batch_reward": 0.6728058922886848, "critic_loss": 1.306734288930893, "actor_loss": -87.26377108764649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.223058938980103, "step": 36000}
{"episode_reward": 751.6496597032436, "episode": 37.0, "batch_reward": 0.6754395505785942, "critic_loss": 1.2988592365384102, "actor_loss": -86.4626040802002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.235809087753296, "step": 37000}
{"episode_reward": 918.6194622282813, "episode": 38.0, "batch_reward": 0.6783525122404098, "critic_loss": 1.3490376698970794, "actor_loss": -86.18113464355469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.171607732772827, "step": 38000}
{"episode_reward": 839.014205608499, "episode": 39.0, "batch_reward": 0.6858672355413437, "critic_loss": 1.3464510206580163, "actor_loss": -86.82560655212403, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.253154277801514, "step": 39000}
{"episode_reward": 954.3530019259712, "episode": 40.0, "batch_reward": 0.692460199534893, "critic_loss": 1.3533956968784333, "actor_loss": -87.23961375427245, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.21251630783081, "step": 40000}
{"episode_reward": 951.2601846381034, "episode": 41.0, "batch_reward": 0.6978429089784622, "critic_loss": 1.3460561722517013, "actor_loss": -87.10336293029785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.836867570877075, "step": 41000}
{"episode_reward": 894.4301165709485, "episode": 42.0, "batch_reward": 0.7042815110683441, "critic_loss": 1.3669022045135497, "actor_loss": -87.33122846984864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.1703040599823, "step": 42000}
{"episode_reward": 923.6765741473166, "episode": 43.0, "batch_reward": 0.7085390617847442, "critic_loss": 1.3684950507283211, "actor_loss": -87.62012216186524, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.18858528137207, "step": 43000}
{"episode_reward": 964.3325443204985, "episode": 44.0, "batch_reward": 0.7135856340527534, "critic_loss": 1.3605677361488342, "actor_loss": -88.95485952758789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.19155740737915, "step": 44000}
{"episode_reward": 900.4224797494963, "episode": 45.0, "batch_reward": 0.7189461023807525, "critic_loss": 1.3823593720793723, "actor_loss": -88.45846949768067, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.199204683303833, "step": 45000}
{"episode_reward": 881.8658246138976, "episode": 46.0, "batch_reward": 0.720485313653946, "critic_loss": 1.431988969027996, "actor_loss": -87.87122129821778, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.195162534713745, "step": 46000}
{"episode_reward": 947.6647272487154, "episode": 47.0, "batch_reward": 0.7259573748111725, "critic_loss": 1.3875744913220405, "actor_loss": -88.47222860717774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.178983688354492, "step": 47000}
{"episode_reward": 930.540305917164, "episode": 48.0, "batch_reward": 0.7314987052083015, "critic_loss": 1.369011988580227, "actor_loss": -88.47312724304199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.183407306671143, "step": 48000}
{"episode_reward": 923.583523694489, "episode": 49.0, "batch_reward": 0.7344441558718682, "critic_loss": 1.3450951926112176, "actor_loss": -89.3296107788086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.180437326431274, "step": 49000}
{"episode_reward": 882.8487651583813, "episode": 50.0, "batch_reward": 0.7372125548124313, "critic_loss": 1.3908293439149857, "actor_loss": -88.95091807556152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.15640902519226, "step": 50000}
{"episode_reward": 892.4497304314251, "episode": 51.0, "batch_reward": 0.7403266900777816, "critic_loss": 1.3886185312271118, "actor_loss": -88.93771003723144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.817344188690186, "step": 51000}
{"episode_reward": 903.2273935926917, "episode": 52.0, "batch_reward": 0.7450501236319542, "critic_loss": 1.3622391505241394, "actor_loss": -89.06881816101074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.11003041267395, "step": 52000}
{"episode_reward": 964.7065536102322, "episode": 53.0, "batch_reward": 0.7470961880087853, "critic_loss": 1.2684676214456558, "actor_loss": -89.66307139587403, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.109189748764038, "step": 53000}
{"episode_reward": 957.5843668379582, "episode": 54.0, "batch_reward": 0.7534760881662369, "critic_loss": 1.2259725009799003, "actor_loss": -90.1449461517334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.094436407089233, "step": 54000}
{"episode_reward": 914.5820377595038, "episode": 55.0, "batch_reward": 0.754271959900856, "critic_loss": 1.192670050740242, "actor_loss": -89.88518801879883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.54444670677185, "step": 55000}
{"episode_reward": 919.5666170171439, "episode": 56.0, "batch_reward": 0.758953362584114, "critic_loss": 1.1792053567767142, "actor_loss": -89.94634870910645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.225663661956787, "step": 56000}
{"episode_reward": 936.7727876893191, "episode": 57.0, "batch_reward": 0.7633742344975472, "critic_loss": 1.1595035466849803, "actor_loss": -90.10541723632812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.23741054534912, "step": 57000}
{"episode_reward": 956.9117069537317, "episode": 58.0, "batch_reward": 0.7637695817947387, "critic_loss": 1.1205136895775796, "actor_loss": -90.16841809082031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.255757093429565, "step": 58000}
{"episode_reward": 911.7247017738839, "episode": 59.0, "batch_reward": 0.7679231426119805, "critic_loss": 1.0912915904521943, "actor_loss": -90.23817468261718, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.219506978988647, "step": 59000}
{"episode_reward": 989.9835342470386, "episode": 60.0, "batch_reward": 0.7705226979851723, "critic_loss": 1.117365551650524, "actor_loss": -90.55487077331543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.24110221862793, "step": 60000}
{"episode_reward": 933.1319631116671, "episode": 61.0, "batch_reward": 0.7740433545708656, "critic_loss": 1.0523657152950763, "actor_loss": -90.57452243041992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.94052290916443, "step": 61000}
{"episode_reward": 951.2923824831788, "episode": 62.0, "batch_reward": 0.7780248776078225, "critic_loss": 1.0419170926809311, "actor_loss": -90.85853677368164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.18916392326355, "step": 62000}
{"episode_reward": 938.6138231814768, "episode": 63.0, "batch_reward": 0.7799398866891861, "critic_loss": 1.028493809312582, "actor_loss": -91.00038591003418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.242222785949707, "step": 63000}
{"episode_reward": 974.0658893578333, "episode": 64.0, "batch_reward": 0.782681191444397, "critic_loss": 1.0348537960648536, "actor_loss": -91.07522158813477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.21338129043579, "step": 64000}
{"episode_reward": 899.617103519916, "episode": 65.0, "batch_reward": 0.7838647171854973, "critic_loss": 0.9845155580341816, "actor_loss": -90.9902523651123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.258025646209717, "step": 65000}
{"episode_reward": 951.9073577076666, "episode": 66.0, "batch_reward": 0.7871447393298149, "critic_loss": 0.96636521089077, "actor_loss": -91.1973684539795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.214900016784668, "step": 66000}
{"episode_reward": 946.4156019831984, "episode": 67.0, "batch_reward": 0.7892801169157028, "critic_loss": 0.9598467962145806, "actor_loss": -91.61543000793458, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.20207953453064, "step": 67000}
{"episode_reward": 924.2567228707417, "episode": 68.0, "batch_reward": 0.790880406677723, "critic_loss": 0.9741309651136398, "actor_loss": -92.0152426147461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.27218270301819, "step": 68000}
{"episode_reward": 895.7750642579499, "episode": 69.0, "batch_reward": 0.7915313761234284, "critic_loss": 0.973025487601757, "actor_loss": -91.3672739868164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.209908485412598, "step": 69000}
{"episode_reward": 940.5304473631188, "episode": 70.0, "batch_reward": 0.7953157550692558, "critic_loss": 0.9824312171041966, "actor_loss": -91.6398564453125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.235496520996094, "step": 70000}
{"episode_reward": 907.0942095155391, "episode": 71.0, "batch_reward": 0.7955532358288765, "critic_loss": 0.9448394486606121, "actor_loss": -91.42412490844727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.85821056365967, "step": 71000}
{"episode_reward": 931.9170698331363, "episode": 72.0, "batch_reward": 0.7968002296090126, "critic_loss": 0.9282547951638699, "actor_loss": -91.68633070373535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.190857887268066, "step": 72000}
{"episode_reward": 853.8886202752169, "episode": 73.0, "batch_reward": 0.7986896244883537, "critic_loss": 0.9591227150857449, "actor_loss": -91.86352384948731, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.165390968322754, "step": 73000}
{"episode_reward": 844.7151315753775, "episode": 74.0, "batch_reward": 0.7997902352213859, "critic_loss": 0.9051592745482921, "actor_loss": -91.72679234313965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.22757625579834, "step": 74000}
{"episode_reward": 890.4260043041701, "episode": 75.0, "batch_reward": 0.799909308552742, "critic_loss": 0.9475479755401611, "actor_loss": -91.91289230346679, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.22170090675354, "step": 75000}
{"episode_reward": 932.570532001328, "episode": 76.0, "batch_reward": 0.8023120605349541, "critic_loss": 0.9329817658364773, "actor_loss": -91.9184465789795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.193860054016113, "step": 76000}
{"episode_reward": 895.9041658709709, "episode": 77.0, "batch_reward": 0.8019764838814736, "critic_loss": 0.946283074438572, "actor_loss": -92.04930552673339, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.207947254180908, "step": 77000}
{"episode_reward": 926.5947649685452, "episode": 78.0, "batch_reward": 0.8053718952536583, "critic_loss": 0.9125241784453392, "actor_loss": -92.28295066833496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.20483660697937, "step": 78000}
{"episode_reward": 931.5553464121066, "episode": 79.0, "batch_reward": 0.807642607986927, "critic_loss": 0.908754581719637, "actor_loss": -92.44359242248535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.2086923122406, "step": 79000}
{"episode_reward": 904.6733350603947, "episode": 80.0, "batch_reward": 0.8088716478943825, "critic_loss": 0.9525779787003994, "actor_loss": -92.39764376831054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.195656299591064, "step": 80000}
{"episode_reward": 947.6297819265676, "episode": 81.0, "batch_reward": 0.8117267429828644, "critic_loss": 0.9694392528235912, "actor_loss": -92.29252323913575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.80357313156128, "step": 81000}
{"episode_reward": 911.0174561464148, "episode": 82.0, "batch_reward": 0.8110137363672256, "critic_loss": 0.9718464884459972, "actor_loss": -92.2770502319336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.123673915863037, "step": 82000}
{"episode_reward": 969.5098664769273, "episode": 83.0, "batch_reward": 0.8139112522602081, "critic_loss": 0.9538050928115844, "actor_loss": -92.55581855773926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.137219667434692, "step": 83000}
{"episode_reward": 883.5857506862656, "episode": 84.0, "batch_reward": 0.8127756714224815, "critic_loss": 0.9879477860927581, "actor_loss": -92.74089350891113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.331207752227783, "step": 84000}
{"episode_reward": 844.4801790104243, "episode": 85.0, "batch_reward": 0.8134631432294845, "critic_loss": 0.9487710620462895, "actor_loss": -92.65271755981445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.138404846191406, "step": 85000}
{"episode_reward": 890.3691319108701, "episode": 86.0, "batch_reward": 0.8145301564931869, "critic_loss": 0.9764600013792515, "actor_loss": -92.40321673583985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.97050642967224, "step": 86000}
{"episode_reward": 939.108244175268, "episode": 87.0, "batch_reward": 0.8158185611963272, "critic_loss": 0.9909015409648418, "actor_loss": -92.97018734741211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.4182231426239, "step": 87000}
{"episode_reward": 988.1785411580975, "episode": 88.0, "batch_reward": 0.8182945598959923, "critic_loss": 0.9554616786837578, "actor_loss": -92.58516532897949, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.260138034820557, "step": 88000}
{"episode_reward": 920.0800349776518, "episode": 89.0, "batch_reward": 0.8199467636942863, "critic_loss": 0.9884514738023281, "actor_loss": -92.66482505798339, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.261346578598022, "step": 89000}
{"episode_reward": 920.3754182462144, "episode": 90.0, "batch_reward": 0.8228974691629409, "critic_loss": 0.9626408911347389, "actor_loss": -92.8066219329834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.45474076271057, "step": 90000}
{"episode_reward": 901.3415833739305, "episode": 91.0, "batch_reward": 0.8217285985946655, "critic_loss": 0.9734862705469132, "actor_loss": -92.77534677124024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.910463094711304, "step": 91000}
{"episode_reward": 985.380557477643, "episode": 92.0, "batch_reward": 0.8237290476560593, "critic_loss": 0.9397757540345192, "actor_loss": -93.06007130432128, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.228848218917847, "step": 92000}
{"episode_reward": 914.316319800083, "episode": 93.0, "batch_reward": 0.8251176596879959, "critic_loss": 0.9396040264070034, "actor_loss": -92.95663230895997, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.181369066238403, "step": 93000}
{"episode_reward": 949.7691765253693, "episode": 94.0, "batch_reward": 0.8264404497742653, "critic_loss": 0.9331128816306591, "actor_loss": -93.11229147338867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.25788187980652, "step": 94000}
{"episode_reward": 905.6791385246803, "episode": 95.0, "batch_reward": 0.8256405425667763, "critic_loss": 0.9500708566904068, "actor_loss": -93.28778596496582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.20882272720337, "step": 95000}
{"episode_reward": 853.8186740568601, "episode": 96.0, "batch_reward": 0.827434231698513, "critic_loss": 0.9557831310331821, "actor_loss": -93.30412767028808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.21951198577881, "step": 96000}
{"episode_reward": 946.9415621978716, "episode": 97.0, "batch_reward": 0.8276767702102661, "critic_loss": 0.9172831907272339, "actor_loss": -93.08934503173828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.232650995254517, "step": 97000}
{"episode_reward": 954.6649712412213, "episode": 98.0, "batch_reward": 0.8287619820833206, "critic_loss": 0.9057465597987175, "actor_loss": -93.55889050292969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.19304847717285, "step": 98000}
{"episode_reward": 968.0498147687472, "episode": 99.0, "batch_reward": 0.8305735395550727, "critic_loss": 0.948863959133625, "actor_loss": -93.13809165954589, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.243093013763428, "step": 99000}
{"episode_reward": 970.3304958163793, "episode": 100.0, "batch_reward": 0.832291566312313, "critic_loss": 0.9381369920372963, "actor_loss": -93.25464884948731, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.251277685165405, "step": 100000}
{"episode_reward": 919.363973473856, "episode": 101.0, "batch_reward": 0.8332415224909783, "critic_loss": 0.9033164588809013, "actor_loss": -93.31588479614258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.01166224479675, "step": 101000}
{"episode_reward": 969.0564548437593, "episode": 102.0, "batch_reward": 0.8356154049038887, "critic_loss": 0.9321284386217594, "actor_loss": -93.57404933166504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.119362831115723, "step": 102000}
{"episode_reward": 978.0965654184739, "episode": 103.0, "batch_reward": 0.8357888721823692, "critic_loss": 0.9295743531584739, "actor_loss": -93.47816523742675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.087416648864746, "step": 103000}
{"episode_reward": 947.3164197646436, "episode": 104.0, "batch_reward": 0.8377142720222474, "critic_loss": 0.9433108624517917, "actor_loss": -93.47997137451172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0645809173584, "step": 104000}
{"episode_reward": 956.3228713005999, "episode": 105.0, "batch_reward": 0.838620454609394, "critic_loss": 0.9440477244257927, "actor_loss": -93.59705207824707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13148021697998, "step": 105000}
{"episode_reward": 958.3703976962869, "episode": 106.0, "batch_reward": 0.8393765138983726, "critic_loss": 0.9189615278840065, "actor_loss": -93.5855461883545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.108176469802856, "step": 106000}
{"episode_reward": 965.3190020467873, "episode": 107.0, "batch_reward": 0.8407921575903893, "critic_loss": 0.9051758818626404, "actor_loss": -93.51334794616699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09096932411194, "step": 107000}
{"episode_reward": 909.7923997910704, "episode": 108.0, "batch_reward": 0.8404581159949303, "critic_loss": 0.9100504221022129, "actor_loss": -93.86372471618652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08662700653076, "step": 108000}
{"episode_reward": 953.972088506391, "episode": 109.0, "batch_reward": 0.8429680944681167, "critic_loss": 0.8730199893116951, "actor_loss": -93.7810541229248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1069815158844, "step": 109000}
{"episode_reward": 924.6281606234867, "episode": 110.0, "batch_reward": 0.8435531116724014, "critic_loss": 0.9009604563713074, "actor_loss": -93.96687916564942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10548686981201, "step": 110000}
{"episode_reward": 932.0790688030664, "episode": 111.0, "batch_reward": 0.8436518577337265, "critic_loss": 0.8845769895911216, "actor_loss": -93.73899005126952, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.787039279937744, "step": 111000}
{"episode_reward": 930.8628418180714, "episode": 112.0, "batch_reward": 0.8438269175887108, "critic_loss": 0.8799650513231755, "actor_loss": -93.99290852355956, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12469458580017, "step": 112000}
{"episode_reward": 970.5172327993783, "episode": 113.0, "batch_reward": 0.8462322244048118, "critic_loss": 0.8606711740791798, "actor_loss": -93.90074478149414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.128668308258057, "step": 113000}
{"episode_reward": 953.802035149883, "episode": 114.0, "batch_reward": 0.8471756947636604, "critic_loss": 0.8475761630237103, "actor_loss": -94.03186796569824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.147773504257202, "step": 114000}
{"episode_reward": 884.2050968863733, "episode": 115.0, "batch_reward": 0.8482206924557686, "critic_loss": 0.881380883127451, "actor_loss": -94.06649555969238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15571165084839, "step": 115000}
{"episode_reward": 958.9675173280873, "episode": 116.0, "batch_reward": 0.8484727789759636, "critic_loss": 0.8470125129520893, "actor_loss": -94.05876248168946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.128763437271118, "step": 116000}
{"episode_reward": 989.0062328094701, "episode": 117.0, "batch_reward": 0.8495894547104835, "critic_loss": 0.8491515650451184, "actor_loss": -94.03792408752442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.138949871063232, "step": 117000}
{"episode_reward": 913.7805618297868, "episode": 118.0, "batch_reward": 0.8507361030578613, "critic_loss": 0.8362662243247032, "actor_loss": -94.02625177001953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16805601119995, "step": 118000}
{"episode_reward": 953.2038074770746, "episode": 119.0, "batch_reward": 0.850692438364029, "critic_loss": 0.7802566029131413, "actor_loss": -94.1192015838623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16431474685669, "step": 119000}
{"episode_reward": 957.6926997140706, "episode": 120.0, "batch_reward": 0.8505864597558975, "critic_loss": 0.7960904315114021, "actor_loss": -94.09725, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.129453420639038, "step": 120000}
{"episode_reward": 940.0525918961542, "episode": 121.0, "batch_reward": 0.8524894690513611, "critic_loss": 0.8005689953565598, "actor_loss": -94.2044405670166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.730347633361816, "step": 121000}
{"episode_reward": 911.9082694205197, "episode": 122.0, "batch_reward": 0.8536736236214638, "critic_loss": 0.8120960786640644, "actor_loss": -94.33904113769532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.084389686584473, "step": 122000}
{"episode_reward": 925.0087273038647, "episode": 123.0, "batch_reward": 0.8528737317919731, "critic_loss": 0.7827055868208408, "actor_loss": -94.31472650146485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.109462022781372, "step": 123000}
{"episode_reward": 896.1263207135668, "episode": 124.0, "batch_reward": 0.8521937489509582, "critic_loss": 0.8449649922549725, "actor_loss": -94.30243417358399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12925696372986, "step": 124000}
{"episode_reward": 910.9948587282023, "episode": 125.0, "batch_reward": 0.8517909153103829, "critic_loss": 0.812498399168253, "actor_loss": -94.15736651611329, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.111963987350464, "step": 125000}
{"episode_reward": 926.451285464791, "episode": 126.0, "batch_reward": 0.8541129062175751, "critic_loss": 0.7971382530033588, "actor_loss": -94.33102223205566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.143803358078003, "step": 126000}
{"episode_reward": 949.9564445333506, "episode": 127.0, "batch_reward": 0.855150070130825, "critic_loss": 0.8014152463674545, "actor_loss": -94.33090953063964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16139793395996, "step": 127000}
{"episode_reward": 953.5850345095151, "episode": 128.0, "batch_reward": 0.8565640614628792, "critic_loss": 0.8326590177118778, "actor_loss": -94.38181660461426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.113112449645996, "step": 128000}
{"episode_reward": 953.1288623439563, "episode": 129.0, "batch_reward": 0.8575927022099495, "critic_loss": 0.8292464707195759, "actor_loss": -94.33108372497558, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.087208032608032, "step": 129000}
{"episode_reward": 973.9160227368776, "episode": 130.0, "batch_reward": 0.8571419254541397, "critic_loss": 0.8245288698226213, "actor_loss": -94.45647094726563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.088749170303345, "step": 130000}
{"episode_reward": 910.9993736516291, "episode": 131.0, "batch_reward": 0.8590195667147636, "critic_loss": 0.7967759938687086, "actor_loss": -94.27973561096191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.68014574050903, "step": 131000}
{"episode_reward": 963.7598266864776, "episode": 132.0, "batch_reward": 0.8585115470290184, "critic_loss": 0.7678609272241592, "actor_loss": -94.50390158081055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.138987064361572, "step": 132000}
{"episode_reward": 929.7907922476479, "episode": 133.0, "batch_reward": 0.8612574607133865, "critic_loss": 0.8056572079062462, "actor_loss": -94.4412763519287, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15425944328308, "step": 133000}
{"episode_reward": 927.2200809195207, "episode": 134.0, "batch_reward": 0.8593513178825378, "critic_loss": 0.8323893007934093, "actor_loss": -94.47450842285156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.096220016479492, "step": 134000}
{"episode_reward": 932.8164116004434, "episode": 135.0, "batch_reward": 0.8585397369265556, "critic_loss": 0.8488300193846225, "actor_loss": -94.52679891967773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.083903312683105, "step": 135000}
{"episode_reward": 904.1708872447855, "episode": 136.0, "batch_reward": 0.8609854449629784, "critic_loss": 0.8368400356471538, "actor_loss": -94.52305546569825, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07162117958069, "step": 136000}
{"episode_reward": 953.7828732193283, "episode": 137.0, "batch_reward": 0.8625969641208648, "critic_loss": 0.8249206159412861, "actor_loss": -94.58555963134765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09693431854248, "step": 137000}
{"episode_reward": 944.7176469566391, "episode": 138.0, "batch_reward": 0.8617011923193931, "critic_loss": 0.8360630595684051, "actor_loss": -94.51084130859375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.085206270217896, "step": 138000}
{"episode_reward": 915.8869322008962, "episode": 139.0, "batch_reward": 0.8617339605689048, "critic_loss": 0.852634257465601, "actor_loss": -94.50304531860351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.18326759338379, "step": 139000}
{"episode_reward": 929.8483755998082, "episode": 140.0, "batch_reward": 0.8621035853624344, "critic_loss": 0.8303626513183117, "actor_loss": -94.61413653564453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.170854568481445, "step": 140000}
{"episode_reward": 953.0335272640729, "episode": 141.0, "batch_reward": 0.8655444164872169, "critic_loss": 0.8095710308253765, "actor_loss": -94.63144610595702, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.78533601760864, "step": 141000}
{"episode_reward": 949.928743734487, "episode": 142.0, "batch_reward": 0.8651374850273132, "critic_loss": 0.8381004010289907, "actor_loss": -94.6254275970459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.109755039215088, "step": 142000}
{"episode_reward": 934.1345953010498, "episode": 143.0, "batch_reward": 0.8646520963907242, "critic_loss": 0.7882697923481464, "actor_loss": -94.64279084777831, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.094541311264038, "step": 143000}
{"episode_reward": 935.6216149507178, "episode": 144.0, "batch_reward": 0.8657433827519416, "critic_loss": 0.7773204051852226, "actor_loss": -94.76145768737793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.112165927886963, "step": 144000}
{"episode_reward": 950.3111458613988, "episode": 145.0, "batch_reward": 0.8668460996747017, "critic_loss": 0.8016295408904552, "actor_loss": -94.70128938293458, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11026096343994, "step": 145000}
{"episode_reward": 921.6232040794242, "episode": 146.0, "batch_reward": 0.8657771145701408, "critic_loss": 0.7920370416492224, "actor_loss": -94.46772734069825, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.083274126052856, "step": 146000}
{"episode_reward": 952.718408190748, "episode": 147.0, "batch_reward": 0.865974396109581, "critic_loss": 0.7849563328623772, "actor_loss": -94.69914450073242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.100085735321045, "step": 147000}
{"episode_reward": 845.1673521411082, "episode": 148.0, "batch_reward": 0.8671417015194893, "critic_loss": 0.8012949185371399, "actor_loss": -94.78275968933106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.106472969055176, "step": 148000}
{"episode_reward": 821.8546450630156, "episode": 149.0, "batch_reward": 0.8674227902889252, "critic_loss": 0.7889577785134315, "actor_loss": -94.7246950378418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15417194366455, "step": 149000}
{"episode_reward": 914.1152027459804, "episode": 150.0, "batch_reward": 0.867408061504364, "critic_loss": 0.8008008441627026, "actor_loss": -94.7402650756836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
