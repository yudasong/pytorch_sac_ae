{"episode_reward": 0.0, "episode": 1.0, "duration": 35.37176489830017, "step": 1000}
{"episode_reward": 28.002640152663393, "episode": 2.0, "duration": 3.2817327976226807, "step": 2000}
{"episode_reward": 481.4321918933315, "episode": 3.0, "batch_reward": 0.2629312694559657, "critic_loss": 0.5631130916619548, "actor_loss": -82.45101310482688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 88.70201826095581, "step": 3000}
{"episode_reward": 381.7841729384471, "episode": 4.0, "batch_reward": 0.3122396803796291, "critic_loss": 0.7783008388876915, "actor_loss": -82.24861215209961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.045812845230103, "step": 4000}
{"episode_reward": 479.7483337579997, "episode": 5.0, "batch_reward": 0.3520452570617199, "critic_loss": 0.8484738479852676, "actor_loss": -82.75533903503418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.79094171524048, "step": 5000}
{"episode_reward": 470.5711658451499, "episode": 6.0, "batch_reward": 0.36476674485206606, "critic_loss": 0.8219850558340549, "actor_loss": -82.19767039489746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.50258231163025, "step": 6000}
{"episode_reward": 359.98368809257835, "episode": 7.0, "batch_reward": 0.3863376832604408, "critic_loss": 0.7976478724479675, "actor_loss": -82.2744591064453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.249714374542236, "step": 7000}
{"episode_reward": 675.6130816693183, "episode": 8.0, "batch_reward": 0.4191912282109261, "critic_loss": 0.9397930384874343, "actor_loss": -82.62186584472656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.30059504508972, "step": 8000}
{"episode_reward": 587.7260120921623, "episode": 9.0, "batch_reward": 0.43695129054784776, "critic_loss": 1.1563095846176148, "actor_loss": -82.22956597900391, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.257054567337036, "step": 9000}
{"episode_reward": 582.6187392087239, "episode": 10.0, "batch_reward": 0.45908291852474215, "critic_loss": 1.2088733004331589, "actor_loss": -82.36049961853027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.22561264038086, "step": 10000}
{"episode_reward": 723.3777906635394, "episode": 11.0, "batch_reward": 0.4875549610257149, "critic_loss": 1.2493789564967155, "actor_loss": -82.76950141906738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.60356307029724, "step": 11000}
{"episode_reward": 741.3452434550202, "episode": 12.0, "batch_reward": 0.5084310664832592, "critic_loss": 1.211747271180153, "actor_loss": -83.13183197021485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.2939350605011, "step": 12000}
{"episode_reward": 730.8069481493031, "episode": 13.0, "batch_reward": 0.526751818805933, "critic_loss": 1.142255743086338, "actor_loss": -83.45326086425781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.32954168319702, "step": 13000}
{"episode_reward": 729.8959086517756, "episode": 14.0, "batch_reward": 0.5399896857738495, "critic_loss": 1.1561443479061126, "actor_loss": -83.65059059143067, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.972690105438232, "step": 14000}
{"episode_reward": 687.5973458102566, "episode": 15.0, "batch_reward": 0.551969499617815, "critic_loss": 1.1467481978535652, "actor_loss": -83.41527442932129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.256455421447754, "step": 15000}
{"episode_reward": 721.0905259649186, "episode": 16.0, "batch_reward": 0.5660183413028717, "critic_loss": 1.1739019059538842, "actor_loss": -83.70565841674805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.601621627807617, "step": 16000}
{"episode_reward": 766.4533286495346, "episode": 17.0, "batch_reward": 0.5786729657948018, "critic_loss": 1.0797171852588654, "actor_loss": -83.9883609008789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.02057123184204, "step": 17000}
{"episode_reward": 819.1022964088099, "episode": 18.0, "batch_reward": 0.5921491141915322, "critic_loss": 1.102667953789234, "actor_loss": -84.17319934082032, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.79882264137268, "step": 18000}
{"episode_reward": 833.9048836258307, "episode": 19.0, "batch_reward": 0.5910938553214073, "critic_loss": 1.024877462565899, "actor_loss": -84.00440026855469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.96881079673767, "step": 19000}
{"episode_reward": 517.2866330683502, "episode": 20.0, "batch_reward": 0.6033460035324096, "critic_loss": 1.0331044226288795, "actor_loss": -83.83079074096679, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.407837390899658, "step": 20000}
{"episode_reward": 877.7213030815132, "episode": 21.0, "batch_reward": 0.6157269173264504, "critic_loss": 1.0341082212924957, "actor_loss": -84.89052128601074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.98702836036682, "step": 21000}
{"episode_reward": 842.7624111135422, "episode": 22.0, "batch_reward": 0.6237115883231164, "critic_loss": 1.0833681213259696, "actor_loss": -84.2994116821289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.23279571533203, "step": 22000}
{"episode_reward": 837.9229411080966, "episode": 23.0, "batch_reward": 0.6351967896819115, "critic_loss": 1.1130541803836822, "actor_loss": -84.882986038208, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.177093982696533, "step": 23000}
{"episode_reward": 841.660321684567, "episode": 24.0, "batch_reward": 0.6436916698813439, "critic_loss": 1.128698793411255, "actor_loss": -85.17842346191406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.252896785736084, "step": 24000}
{"episode_reward": 828.2965344961941, "episode": 25.0, "batch_reward": 0.6514615634083748, "critic_loss": 1.122787763118744, "actor_loss": -85.33510418701172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.527523040771484, "step": 25000}
{"episode_reward": 879.2496591008725, "episode": 26.0, "batch_reward": 0.6590302040576935, "critic_loss": 1.0766459841132163, "actor_loss": -85.80355738830566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.1673846244812, "step": 26000}
{"episode_reward": 875.3242828857457, "episode": 27.0, "batch_reward": 0.6688170674443245, "critic_loss": 1.0213013655543328, "actor_loss": -86.23597210693359, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.877577781677246, "step": 27000}
{"episode_reward": 897.8574019008612, "episode": 28.0, "batch_reward": 0.6738644816279411, "critic_loss": 0.9819024761319161, "actor_loss": -86.18235733032226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.330735206604004, "step": 28000}
{"episode_reward": 759.1535849276813, "episode": 29.0, "batch_reward": 0.6783787733316422, "critic_loss": 0.9252126229405403, "actor_loss": -86.4586990814209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.693509817123413, "step": 29000}
{"episode_reward": 878.5799702506719, "episode": 30.0, "batch_reward": 0.687237223803997, "critic_loss": 0.8662744634747506, "actor_loss": -87.07924850463867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.44730544090271, "step": 30000}
{"episode_reward": 807.7438715037777, "episode": 31.0, "batch_reward": 0.6912064782977104, "critic_loss": 0.8361170389056206, "actor_loss": -86.93091954040527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.72019743919373, "step": 31000}
{"episode_reward": 915.2750257268356, "episode": 32.0, "batch_reward": 0.697308586359024, "critic_loss": 0.8240266955196858, "actor_loss": -86.69092477416993, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.49922251701355, "step": 32000}
{"episode_reward": 831.7881291413539, "episode": 33.0, "batch_reward": 0.703295778632164, "critic_loss": 0.8019275595843792, "actor_loss": -86.91841044616699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.49250888824463, "step": 33000}
{"episode_reward": 937.8849055134099, "episode": 34.0, "batch_reward": 0.7099847176074982, "critic_loss": 0.7763033622801304, "actor_loss": -87.39878134155273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.2559597492218, "step": 34000}
{"episode_reward": 893.2925429434684, "episode": 35.0, "batch_reward": 0.7159300141334534, "critic_loss": 0.7776408722698689, "actor_loss": -87.21087170410156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.5778865814209, "step": 35000}
{"episode_reward": 871.7176255837427, "episode": 36.0, "batch_reward": 0.718854032933712, "critic_loss": 0.8060168841779232, "actor_loss": -87.31923071289063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.32062077522278, "step": 36000}
{"episode_reward": 836.4586035698968, "episode": 37.0, "batch_reward": 0.7218154055476189, "critic_loss": 0.7855228665769101, "actor_loss": -87.68313813781738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.59317946434021, "step": 37000}
{"episode_reward": 917.1184455027308, "episode": 38.0, "batch_reward": 0.7274985609054565, "critic_loss": 0.780650303542614, "actor_loss": -87.7254162902832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.99301528930664, "step": 38000}
{"episode_reward": 883.3563287031361, "episode": 39.0, "batch_reward": 0.7314704827666283, "critic_loss": 0.7806244711577892, "actor_loss": -87.89826316833496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.131224632263184, "step": 39000}
{"episode_reward": 832.1250001750326, "episode": 40.0, "batch_reward": 0.7347552453279496, "critic_loss": 0.8364852185845375, "actor_loss": -88.04218133544921, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.763948678970337, "step": 40000}
{"episode_reward": 907.0302000723221, "episode": 41.0, "batch_reward": 0.7370869811177254, "critic_loss": 0.8360882420241833, "actor_loss": -88.1875711364746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.632883310318, "step": 41000}
{"episode_reward": 890.6677572332928, "episode": 42.0, "batch_reward": 0.7425825374722481, "critic_loss": 0.8276020593941211, "actor_loss": -88.27091040039062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.53156042098999, "step": 42000}
{"episode_reward": 865.3872070669761, "episode": 43.0, "batch_reward": 0.7460964577198028, "critic_loss": 0.8258405853807926, "actor_loss": -88.14852174377441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.88895297050476, "step": 43000}
{"episode_reward": 947.0484597102746, "episode": 44.0, "batch_reward": 0.7505480098724365, "critic_loss": 0.7896813496351242, "actor_loss": -88.03317138671875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.95823884010315, "step": 44000}
{"episode_reward": 957.6599503386424, "episode": 45.0, "batch_reward": 0.7541839292645455, "critic_loss": 0.7771212554275989, "actor_loss": -88.55973852539063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.506004810333252, "step": 45000}
{"episode_reward": 952.5512277692492, "episode": 46.0, "batch_reward": 0.7578997275829316, "critic_loss": 0.7772788279652596, "actor_loss": -88.9160912322998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.437648057937622, "step": 46000}
{"episode_reward": 901.3253851585846, "episode": 47.0, "batch_reward": 0.7627033138275147, "critic_loss": 0.7822204015851021, "actor_loss": -88.88072227478027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.817573308944702, "step": 47000}
{"episode_reward": 946.0169756396912, "episode": 48.0, "batch_reward": 0.7660708984732628, "critic_loss": 0.7527451930344105, "actor_loss": -89.11653227233887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.846851348876953, "step": 48000}
{"episode_reward": 898.3448838784125, "episode": 49.0, "batch_reward": 0.76731784003973, "critic_loss": 0.8179261718392372, "actor_loss": -88.81806986999511, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.56282925605774, "step": 49000}
{"episode_reward": 865.3292042644691, "episode": 50.0, "batch_reward": 0.7702750654220581, "critic_loss": 0.7659148238003254, "actor_loss": -89.30973931884766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.366893768310547, "step": 50000}
{"episode_reward": 908.9249152226371, "episode": 51.0, "batch_reward": 0.7643560384511947, "critic_loss": 0.7687433969378471, "actor_loss": -89.38212742614746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.70647859573364, "step": 51000}
{"episode_reward": 11.212005276280282, "episode": 52.0, "batch_reward": 0.7588418384790421, "critic_loss": 0.7777820037603378, "actor_loss": -89.12307528686523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.92948341369629, "step": 52000}
{"episode_reward": 911.7046645786821, "episode": 53.0, "batch_reward": 0.7605539945363998, "critic_loss": 0.7745970928668976, "actor_loss": -88.86153173828124, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.0372531414032, "step": 53000}
{"episode_reward": 951.6420991061005, "episode": 54.0, "batch_reward": 0.7662296894788742, "critic_loss": 0.7677658156752586, "actor_loss": -88.98969146728516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.653931856155396, "step": 54000}
{"episode_reward": 898.950663130275, "episode": 55.0, "batch_reward": 0.7596681358218194, "critic_loss": 0.7700357994735241, "actor_loss": -89.27135066223144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.855154275894165, "step": 55000}
{"episode_reward": 547.8965145197847, "episode": 56.0, "batch_reward": 0.7627944304347039, "critic_loss": 0.7880319406092167, "actor_loss": -89.31087283325195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.40043616294861, "step": 56000}
{"episode_reward": 829.5307472126841, "episode": 57.0, "batch_reward": 0.7640087230205536, "critic_loss": 0.7789365321099758, "actor_loss": -89.48894323730468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.220057249069214, "step": 57000}
{"episode_reward": 925.8874411551388, "episode": 58.0, "batch_reward": 0.7661429973244667, "critic_loss": 0.7451978497207165, "actor_loss": -89.33267883300782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.835453748703003, "step": 58000}
{"episode_reward": 905.1894126275331, "episode": 59.0, "batch_reward": 0.7704128053188324, "critic_loss": 0.7415210512578487, "actor_loss": -89.71511415100098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.65632700920105, "step": 59000}
{"episode_reward": 973.9298436321485, "episode": 60.0, "batch_reward": 0.7742198358178138, "critic_loss": 0.7207697302401066, "actor_loss": -89.80850857543945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.07217240333557, "step": 60000}
{"episode_reward": 955.0066600073999, "episode": 61.0, "batch_reward": 0.7753399932980537, "critic_loss": 0.7151092389822006, "actor_loss": -90.08439358520508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.72217154502869, "step": 61000}
{"episode_reward": 920.4965216848954, "episode": 62.0, "batch_reward": 0.7797703947424889, "critic_loss": 0.6828934144377709, "actor_loss": -89.94509968566895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.112170696258545, "step": 62000}
{"episode_reward": 961.2825074527289, "episode": 63.0, "batch_reward": 0.7807759439349174, "critic_loss": 0.709833276629448, "actor_loss": -90.46853567504883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.165847063064575, "step": 63000}
{"episode_reward": 870.4046163110801, "episode": 64.0, "batch_reward": 0.7805976964831353, "critic_loss": 0.7413961355090142, "actor_loss": -90.2340140838623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.220120668411255, "step": 64000}
{"episode_reward": 770.3426805017781, "episode": 65.0, "batch_reward": 0.7821267006397248, "critic_loss": 0.728608857691288, "actor_loss": -90.44432145690918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.433961868286133, "step": 65000}
{"episode_reward": 953.7330046075434, "episode": 66.0, "batch_reward": 0.7851476670503617, "critic_loss": 0.7377372620403767, "actor_loss": -90.4850166015625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.34236979484558, "step": 66000}
{"episode_reward": 910.5252076036593, "episode": 67.0, "batch_reward": 0.786620376110077, "critic_loss": 0.748979146540165, "actor_loss": -90.44966397094727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.271198749542236, "step": 67000}
{"episode_reward": 897.4322562653167, "episode": 68.0, "batch_reward": 0.7889917325973511, "critic_loss": 0.7153230250477791, "actor_loss": -90.52848179626464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.974305629730225, "step": 68000}
{"episode_reward": 943.413117525615, "episode": 69.0, "batch_reward": 0.7896515154242516, "critic_loss": 0.7364204518496991, "actor_loss": -90.92033688354492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.644684553146362, "step": 69000}
{"episode_reward": 938.774654587219, "episode": 70.0, "batch_reward": 0.791994632422924, "critic_loss": 0.7380321137011051, "actor_loss": -90.96369659423829, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.941813230514526, "step": 70000}
{"episode_reward": 668.7342447841381, "episode": 71.0, "batch_reward": 0.7921787257194519, "critic_loss": 0.7564057945907116, "actor_loss": -91.15530435180663, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.86444211006165, "step": 71000}
{"episode_reward": 930.5268827325859, "episode": 72.0, "batch_reward": 0.7929226194620133, "critic_loss": 0.7232533477842807, "actor_loss": -91.17646937561035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.154175996780396, "step": 72000}
{"episode_reward": 929.9043331191876, "episode": 73.0, "batch_reward": 0.7959899849295616, "critic_loss": 0.7226183051168918, "actor_loss": -91.23875813293456, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.061859607696533, "step": 73000}
{"episode_reward": 891.6918817001595, "episode": 74.0, "batch_reward": 0.7973856118917465, "critic_loss": 0.7089681890904903, "actor_loss": -91.31623558044434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.509167671203613, "step": 74000}
{"episode_reward": 940.4348941945786, "episode": 75.0, "batch_reward": 0.796834264755249, "critic_loss": 0.7006665824949742, "actor_loss": -91.3999351196289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.338578939437866, "step": 75000}
{"episode_reward": 941.8509555538263, "episode": 76.0, "batch_reward": 0.7998951151371002, "critic_loss": 0.7091065593361855, "actor_loss": -91.52704112243653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.203768491744995, "step": 76000}
{"episode_reward": 909.1674868184487, "episode": 77.0, "batch_reward": 0.8007512174248695, "critic_loss": 0.7065347757637501, "actor_loss": -91.50671575927734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.411019802093506, "step": 77000}
{"episode_reward": 914.6734693747804, "episode": 78.0, "batch_reward": 0.8036130622625351, "critic_loss": 0.6770383439958095, "actor_loss": -91.7446450805664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.32630181312561, "step": 78000}
{"episode_reward": 977.1882470587259, "episode": 79.0, "batch_reward": 0.8049557371139526, "critic_loss": 0.6652587510049343, "actor_loss": -91.59885949707031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.07318925857544, "step": 79000}
{"episode_reward": 940.9969101059908, "episode": 80.0, "batch_reward": 0.8073524609208107, "critic_loss": 0.6481888144910336, "actor_loss": -91.75778852844238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.452925443649292, "step": 80000}
{"episode_reward": 959.0895434222078, "episode": 81.0, "batch_reward": 0.8099032436013222, "critic_loss": 0.6552981105446816, "actor_loss": -91.86919226074218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.08774447441101, "step": 81000}
{"episode_reward": 815.4410149905244, "episode": 82.0, "batch_reward": 0.8091930245757103, "critic_loss": 0.6369614197909832, "actor_loss": -92.03713143920899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.038808584213257, "step": 82000}
{"episode_reward": 969.2857675047082, "episode": 83.0, "batch_reward": 0.8122481142878533, "critic_loss": 0.654765846312046, "actor_loss": -91.99148738098144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.041065216064453, "step": 83000}
{"episode_reward": 958.3011972796521, "episode": 84.0, "batch_reward": 0.8121062802672386, "critic_loss": 0.6394068467617035, "actor_loss": -92.08531184387208, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.76997661590576, "step": 84000}
{"episode_reward": 897.9849041859384, "episode": 85.0, "batch_reward": 0.8128946768641472, "critic_loss": 0.6302546832412481, "actor_loss": -92.24023341369629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.846860885620117, "step": 85000}
{"episode_reward": 955.7824309710934, "episode": 86.0, "batch_reward": 0.8159589264392852, "critic_loss": 0.6134819332063198, "actor_loss": -92.34170153808594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.40561270713806, "step": 86000}
{"episode_reward": 925.0830543368721, "episode": 87.0, "batch_reward": 0.8167864617109298, "critic_loss": 0.6394394895136356, "actor_loss": -92.35124829101562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.919418811798096, "step": 87000}
{"episode_reward": 968.955634656669, "episode": 88.0, "batch_reward": 0.8184772179126739, "critic_loss": 0.618760957211256, "actor_loss": -92.46497344970703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.734956741333008, "step": 88000}
{"episode_reward": 956.1476906702011, "episode": 89.0, "batch_reward": 0.8195424785017967, "critic_loss": 0.6069293868541717, "actor_loss": -92.59172859191895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.3577561378479, "step": 89000}
{"episode_reward": 918.980083697223, "episode": 90.0, "batch_reward": 0.8225655701160431, "critic_loss": 0.6051159844696522, "actor_loss": -92.68904669189453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.05757975578308, "step": 90000}
{"episode_reward": 880.9779266853111, "episode": 91.0, "batch_reward": 0.8216304830908775, "critic_loss": 0.6144654664248228, "actor_loss": -92.71564059448242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.0972158908844, "step": 91000}
{"episode_reward": 872.3874892039258, "episode": 92.0, "batch_reward": 0.8224732693433762, "critic_loss": 0.5935854962170124, "actor_loss": -92.65589823913574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.886788606643677, "step": 92000}
{"episode_reward": 912.3327919575191, "episode": 93.0, "batch_reward": 0.8227613484859466, "critic_loss": 0.6155120020508766, "actor_loss": -92.76303735351563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.859359741210938, "step": 93000}
{"episode_reward": 959.1470973720816, "episode": 94.0, "batch_reward": 0.8243214579820632, "critic_loss": 0.6308148053586483, "actor_loss": -92.68234413146973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.845858335494995, "step": 94000}
{"episode_reward": 775.0474203520461, "episode": 95.0, "batch_reward": 0.8240823360085487, "critic_loss": 0.6321254481673241, "actor_loss": -92.6211101989746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.56213617324829, "step": 95000}
{"episode_reward": 903.257104655491, "episode": 96.0, "batch_reward": 0.8261148694157601, "critic_loss": 0.6121920635700225, "actor_loss": -92.84113130187988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.837331295013428, "step": 96000}
{"episode_reward": 944.0551457810227, "episode": 97.0, "batch_reward": 0.8262482658028603, "critic_loss": 0.5917248496115207, "actor_loss": -92.96215139770507, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.03331732749939, "step": 97000}
{"episode_reward": 978.4300496076494, "episode": 98.0, "batch_reward": 0.8281720123887062, "critic_loss": 0.6026427153646946, "actor_loss": -92.81146574401855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.97977066040039, "step": 98000}
{"episode_reward": 932.8976971525376, "episode": 99.0, "batch_reward": 0.8293094375133514, "critic_loss": 0.6046415999382734, "actor_loss": -92.93280070495605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.698277950286865, "step": 99000}
{"episode_reward": 967.4099286727972, "episode": 100.0, "batch_reward": 0.8301094043254852, "critic_loss": 0.5951670857667923, "actor_loss": -92.99183178710938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.837294816970825, "step": 100000}
{"episode_reward": 921.3723777219782, "episode": 101.0, "batch_reward": 0.8317946749329567, "critic_loss": 0.5911647886931897, "actor_loss": -93.15582136535645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.00328707695007, "step": 101000}
{"episode_reward": 932.8440786950362, "episode": 102.0, "batch_reward": 0.8327836285829544, "critic_loss": 0.5819181768000126, "actor_loss": -93.06351289367676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.13366985321045, "step": 102000}
{"episode_reward": 919.4117450595448, "episode": 103.0, "batch_reward": 0.8333590550422668, "critic_loss": 0.5856690971404314, "actor_loss": -93.12498402404785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.593689441680908, "step": 103000}
{"episode_reward": 964.0555186345927, "episode": 104.0, "batch_reward": 0.8341522603034973, "critic_loss": 0.578380912527442, "actor_loss": -93.24029873657227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.570308208465576, "step": 104000}
{"episode_reward": 948.9469543563671, "episode": 105.0, "batch_reward": 0.8357618442773819, "critic_loss": 0.586085469007492, "actor_loss": -93.19290533447266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.73719620704651, "step": 105000}
{"episode_reward": 930.5754358856409, "episode": 106.0, "batch_reward": 0.836131567299366, "critic_loss": 0.5618645002245903, "actor_loss": -93.32947268676757, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.94718313217163, "step": 106000}
{"episode_reward": 946.6751432231403, "episode": 107.0, "batch_reward": 0.8371406830549241, "critic_loss": 0.5636309396475554, "actor_loss": -93.30193408203125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.34573483467102, "step": 107000}
{"episode_reward": 927.2413315808568, "episode": 108.0, "batch_reward": 0.8386315612196922, "critic_loss": 0.5571432494521141, "actor_loss": -93.24433813476563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.744834661483765, "step": 108000}
{"episode_reward": 941.9065599899867, "episode": 109.0, "batch_reward": 0.8405399887561799, "critic_loss": 0.5892339803427458, "actor_loss": -93.35126452636719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.89614701271057, "step": 109000}
{"episode_reward": 952.839209300908, "episode": 110.0, "batch_reward": 0.8399976803064346, "critic_loss": 0.5633184872567654, "actor_loss": -93.38171664428711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.197158098220825, "step": 110000}
{"episode_reward": 925.9724829355848, "episode": 111.0, "batch_reward": 0.8414042168855667, "critic_loss": 0.576555118188262, "actor_loss": -93.45487329101563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.2126133441925, "step": 111000}
{"episode_reward": 948.226835087085, "episode": 112.0, "batch_reward": 0.8417963907718659, "critic_loss": 0.5422686844617128, "actor_loss": -93.44954248046875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.60415005683899, "step": 112000}
{"episode_reward": 975.8315429911031, "episode": 113.0, "batch_reward": 0.8439396091103554, "critic_loss": 0.548404312133789, "actor_loss": -93.58784370422363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.509032249450684, "step": 113000}
{"episode_reward": 901.3784241268659, "episode": 114.0, "batch_reward": 0.8454377307891846, "critic_loss": 0.5612236301600934, "actor_loss": -93.56589276123047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.252434968948364, "step": 114000}
{"episode_reward": 936.878685775732, "episode": 115.0, "batch_reward": 0.8453357477784157, "critic_loss": 0.5579400136619806, "actor_loss": -93.58307293701172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.080363273620605, "step": 115000}
{"episode_reward": 964.2138392477331, "episode": 116.0, "batch_reward": 0.8459272248148918, "critic_loss": 0.5364612142294646, "actor_loss": -93.56471185302735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.48063588142395, "step": 116000}
{"episode_reward": 946.7161712939621, "episode": 117.0, "batch_reward": 0.8479056434631348, "critic_loss": 0.5275862361043692, "actor_loss": -93.71151370239258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.96562671661377, "step": 117000}
{"episode_reward": 931.8951312209583, "episode": 118.0, "batch_reward": 0.847528508901596, "critic_loss": 0.5537579247057438, "actor_loss": -93.69801109313966, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.12632727622986, "step": 118000}
{"episode_reward": 931.3096349493835, "episode": 119.0, "batch_reward": 0.8482351511120796, "critic_loss": 0.5470863497257232, "actor_loss": -93.6653243560791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.657519102096558, "step": 119000}
{"episode_reward": 915.5177888098888, "episode": 120.0, "batch_reward": 0.8481094278097153, "critic_loss": 0.5304512300044298, "actor_loss": -93.73377322387695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.42825961112976, "step": 120000}
{"episode_reward": 941.7815711981327, "episode": 121.0, "batch_reward": 0.8500561519861222, "critic_loss": 0.5089871726036072, "actor_loss": -93.78679989624024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.49332761764526, "step": 121000}
{"episode_reward": 963.2684617888034, "episode": 122.0, "batch_reward": 0.8507581644654274, "critic_loss": 0.521362972587347, "actor_loss": -93.73208921813965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.556018829345703, "step": 122000}
{"episode_reward": 939.8398812421923, "episode": 123.0, "batch_reward": 0.8520016213059425, "critic_loss": 0.5226634559780359, "actor_loss": -93.79599406433105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.404637575149536, "step": 123000}
{"episode_reward": 929.5768360806105, "episode": 124.0, "batch_reward": 0.8512405666708946, "critic_loss": 0.5119093860834837, "actor_loss": -93.72315022277832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.207683801651, "step": 124000}
{"episode_reward": 914.8175137696013, "episode": 125.0, "batch_reward": 0.8515536463856697, "critic_loss": 0.5094470897763967, "actor_loss": -93.83188023376465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.395585536956787, "step": 125000}
{"episode_reward": 959.1834064810698, "episode": 126.0, "batch_reward": 0.8531204060912132, "critic_loss": 0.5072567179501056, "actor_loss": -93.81909001159669, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.624023914337158, "step": 126000}
{"episode_reward": 970.83516259607, "episode": 127.0, "batch_reward": 0.8532124776244163, "critic_loss": 0.5049173872619868, "actor_loss": -93.83695880126953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.76628828048706, "step": 127000}
{"episode_reward": 965.0906051424187, "episode": 128.0, "batch_reward": 0.8546162866950036, "critic_loss": 0.50941229121387, "actor_loss": -93.90046920776368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.03596019744873, "step": 128000}
{"episode_reward": 934.456019016065, "episode": 129.0, "batch_reward": 0.8552130810022354, "critic_loss": 0.49926575215160846, "actor_loss": -93.90655833435059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.743963956832886, "step": 129000}
{"episode_reward": 968.0646387737248, "episode": 130.0, "batch_reward": 0.8563081287741661, "critic_loss": 0.5016083757728338, "actor_loss": -94.01863023376465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.852707386016846, "step": 130000}
{"episode_reward": 934.3918249327705, "episode": 131.0, "batch_reward": 0.8568219980001449, "critic_loss": 0.4973177754878998, "actor_loss": -94.0281799621582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.97207760810852, "step": 131000}
{"episode_reward": 920.3479816004232, "episode": 132.0, "batch_reward": 0.8574787957072258, "critic_loss": 0.4894950852841139, "actor_loss": -94.05692454528808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.58721089363098, "step": 132000}
{"episode_reward": 931.1833134454489, "episode": 133.0, "batch_reward": 0.858732025384903, "critic_loss": 0.5058800238668919, "actor_loss": -94.15100631713867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.974769353866577, "step": 133000}
{"episode_reward": 932.1236196611252, "episode": 134.0, "batch_reward": 0.8585967270731926, "critic_loss": 0.4870051652789116, "actor_loss": -94.09239421081543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.792866945266724, "step": 134000}
{"episode_reward": 971.0020165177958, "episode": 135.0, "batch_reward": 0.8580854468345642, "critic_loss": 0.5168776647150517, "actor_loss": -94.06682904052734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.1118905544281, "step": 135000}
{"episode_reward": 867.940860196136, "episode": 136.0, "batch_reward": 0.8597528547048569, "critic_loss": 0.5007945862412453, "actor_loss": -94.16499267578125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.8918354511261, "step": 136000}
{"episode_reward": 932.5406628798492, "episode": 137.0, "batch_reward": 0.8598450872898101, "critic_loss": 0.49240311175584794, "actor_loss": -94.18906941223145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.36452555656433, "step": 137000}
{"episode_reward": 936.1718775839132, "episode": 138.0, "batch_reward": 0.8575351672768593, "critic_loss": 0.5071884032785893, "actor_loss": -94.06939846801758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.33219265937805, "step": 138000}
{"episode_reward": 397.3588341117931, "episode": 139.0, "batch_reward": 0.8562717207074165, "critic_loss": 0.5123960836529732, "actor_loss": -94.12699365234376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.0986008644104, "step": 139000}
{"episode_reward": 900.5370418776065, "episode": 140.0, "batch_reward": 0.8557628831267357, "critic_loss": 0.5089209417104721, "actor_loss": -94.08933915710449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.52330183982849, "step": 140000}
{"episode_reward": 956.7404724246595, "episode": 141.0, "batch_reward": 0.8589308513998986, "critic_loss": 0.49771793629229066, "actor_loss": -94.22552095031739, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.68578457832336, "step": 141000}
{"episode_reward": 946.7376776444651, "episode": 142.0, "batch_reward": 0.8594323789477348, "critic_loss": 0.515772134155035, "actor_loss": -94.22369348144531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.7564857006073, "step": 142000}
{"episode_reward": 946.5938730005388, "episode": 143.0, "batch_reward": 0.8591474838256836, "critic_loss": 0.533524396315217, "actor_loss": -94.20327058410645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.14015793800354, "step": 143000}
{"episode_reward": 918.0413354441118, "episode": 144.0, "batch_reward": 0.860106953561306, "critic_loss": 0.5067904591262341, "actor_loss": -94.26705380249024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.242482662200928, "step": 144000}
{"episode_reward": 965.9807466847195, "episode": 145.0, "batch_reward": 0.8612037603259086, "critic_loss": 0.5134370637834073, "actor_loss": -94.23743504333495, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.928351640701294, "step": 145000}
{"episode_reward": 937.8107987938668, "episode": 146.0, "batch_reward": 0.8600051026940346, "critic_loss": 0.5274940004050732, "actor_loss": -94.20950006103516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.168264150619507, "step": 146000}
{"episode_reward": 939.8661247889098, "episode": 147.0, "batch_reward": 0.8606045414805412, "critic_loss": 0.5170834909081459, "actor_loss": -94.28215589904785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.491796016693115, "step": 147000}
{"episode_reward": 965.7443620919079, "episode": 148.0, "batch_reward": 0.8624863169193268, "critic_loss": 0.5225709050893783, "actor_loss": -94.30936253356934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.170830011367798, "step": 148000}
{"episode_reward": 854.4164390718963, "episode": 149.0, "batch_reward": 0.8618137528896331, "critic_loss": 0.5259237778931856, "actor_loss": -94.29265657043457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.4233615398407, "step": 149000}
{"episode_reward": 935.6950876905663, "episode": 150.0, "batch_reward": 0.863195046544075, "critic_loss": 0.5016936782300472, "actor_loss": -94.31532008361816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
