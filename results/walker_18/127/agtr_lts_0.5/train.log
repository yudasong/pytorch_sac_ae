{"episode_reward": 0.0, "episode": 1.0, "duration": 21.08964443206787, "step": 1000}
{"episode_reward": 28.002640152663393, "episode": 2.0, "duration": 1.8319509029388428, "step": 2000}
{"episode_reward": 481.4321918933315, "episode": 3.0, "batch_reward": 0.2527056082352752, "critic_loss": 0.6212073615259948, "actor_loss": -84.32195471572417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.59041094779968, "step": 3000}
{"episode_reward": 248.7489018332908, "episode": 4.0, "batch_reward": 0.25642060916125775, "critic_loss": 1.069083963572979, "actor_loss": -84.66979830932617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11957883834839, "step": 4000}
{"episode_reward": 248.7075342387258, "episode": 5.0, "batch_reward": 0.26360639405250547, "critic_loss": 0.9383312869668007, "actor_loss": -84.50125994873046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.109227657318115, "step": 5000}
{"episode_reward": 415.9675288745197, "episode": 6.0, "batch_reward": 0.3006891311109066, "critic_loss": 0.9508438637256622, "actor_loss": -84.870424118042, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.116360187530518, "step": 6000}
{"episode_reward": 551.6112488662369, "episode": 7.0, "batch_reward": 0.3441237742304802, "critic_loss": 0.9874951336979866, "actor_loss": -84.75430284118653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.108588457107544, "step": 7000}
{"episode_reward": 581.4616510101829, "episode": 8.0, "batch_reward": 0.3436028489768505, "critic_loss": 0.8880995692908764, "actor_loss": -83.62291397094727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.109806299209595, "step": 8000}
{"episode_reward": 15.487693579413099, "episode": 9.0, "batch_reward": 0.3311307693123817, "critic_loss": 0.9210782380998135, "actor_loss": -82.52756318664551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.124243021011353, "step": 9000}
{"episode_reward": 495.15190463638055, "episode": 10.0, "batch_reward": 0.32357917468249797, "critic_loss": 0.9240769160985947, "actor_loss": -81.6769105834961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.424909591674805, "step": 10000}
{"episode_reward": 14.235868452525217, "episode": 11.0, "batch_reward": 0.3224274400770664, "critic_loss": 1.1390872346758842, "actor_loss": -80.9287341003418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.83257746696472, "step": 11000}
{"episode_reward": 661.5856743972855, "episode": 12.0, "batch_reward": 0.35091614663600923, "critic_loss": 1.1283150913715363, "actor_loss": -81.25793751525879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08220601081848, "step": 12000}
{"episode_reward": 458.5873246948143, "episode": 13.0, "batch_reward": 0.3627575912475586, "critic_loss": 1.0881794961094857, "actor_loss": -80.98950898742676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.106029272079468, "step": 13000}
{"episode_reward": 731.373935539506, "episode": 14.0, "batch_reward": 0.39107543814182283, "critic_loss": 1.1176101837158203, "actor_loss": -81.21771264648437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11282706260681, "step": 14000}
{"episode_reward": 773.9115844339797, "episode": 15.0, "batch_reward": 0.4145331962108612, "critic_loss": 1.1736479861140252, "actor_loss": -81.68605783081054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10834789276123, "step": 15000}
{"episode_reward": 639.6431705416019, "episode": 16.0, "batch_reward": 0.42934351405501364, "critic_loss": 1.3022911961078645, "actor_loss": -81.72437446594239, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09855580329895, "step": 16000}
{"episode_reward": 695.2327955992386, "episode": 17.0, "batch_reward": 0.45289745372533796, "critic_loss": 1.3487691655158998, "actor_loss": -82.01036106872559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.127479791641235, "step": 17000}
{"episode_reward": 795.6920095952394, "episode": 18.0, "batch_reward": 0.4546219430267811, "critic_loss": 1.346159498155117, "actor_loss": -82.01683506774903, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11836886405945, "step": 18000}
{"episode_reward": 151.61883285144728, "episode": 19.0, "batch_reward": 0.4335017273724079, "critic_loss": 1.333143372952938, "actor_loss": -81.49636781311035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.107512950897217, "step": 19000}
{"episode_reward": 34.84667447564252, "episode": 20.0, "batch_reward": 0.42027310609817503, "critic_loss": 1.2110346868038178, "actor_loss": -81.69306240844726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.110013484954834, "step": 20000}
{"episode_reward": 530.4493910013181, "episode": 21.0, "batch_reward": 0.43703569692373273, "critic_loss": 1.1817437744736672, "actor_loss": -81.33282948303223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.9043333530426, "step": 21000}
{"episode_reward": 843.3784476018947, "episode": 22.0, "batch_reward": 0.4369378970861435, "critic_loss": 1.042096862912178, "actor_loss": -82.07800898742676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.109254121780396, "step": 22000}
{"episode_reward": 17.680516851499156, "episode": 23.0, "batch_reward": 0.4372091630101204, "critic_loss": 1.0233208778500558, "actor_loss": -81.8025450592041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.103372812271118, "step": 23000}
{"episode_reward": 829.0657413109616, "episode": 24.0, "batch_reward": 0.4512229241728783, "critic_loss": 0.9945602986216545, "actor_loss": -81.89217121887206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.105268239974976, "step": 24000}
{"episode_reward": 529.8431941405748, "episode": 25.0, "batch_reward": 0.44144602221250534, "critic_loss": 0.9782563431859016, "actor_loss": -81.6681166229248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10254144668579, "step": 25000}
{"episode_reward": 14.898586759574695, "episode": 26.0, "batch_reward": 0.43908737662434577, "critic_loss": 1.0016242070198058, "actor_loss": -81.34522386169434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10078239440918, "step": 26000}
{"episode_reward": 907.3121630175764, "episode": 27.0, "batch_reward": 0.4576863718926907, "critic_loss": 0.9844177618026734, "actor_loss": -81.3864895477295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.098368406295776, "step": 27000}
{"episode_reward": 922.6984631926964, "episode": 28.0, "batch_reward": 0.47331373405456545, "critic_loss": 1.0360524994134903, "actor_loss": -81.85830531311035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.107737064361572, "step": 28000}
{"episode_reward": 895.2301307035091, "episode": 29.0, "batch_reward": 0.4882017083466053, "critic_loss": 1.0395367284417152, "actor_loss": -82.0304263305664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.098541021347046, "step": 29000}
{"episode_reward": 874.1696226552865, "episode": 30.0, "batch_reward": 0.5033427757620812, "critic_loss": 1.1652717456817627, "actor_loss": -81.97032473754882, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.094306468963623, "step": 30000}
{"episode_reward": 884.5016421802864, "episode": 31.0, "batch_reward": 0.5160520180463791, "critic_loss": 1.2201964725852013, "actor_loss": -82.7342565460205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.79119944572449, "step": 31000}
{"episode_reward": 890.5477355618419, "episode": 32.0, "batch_reward": 0.528839865475893, "critic_loss": 1.4009050746560097, "actor_loss": -83.53861154174805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.103679656982422, "step": 32000}
{"episode_reward": 941.4365532662465, "episode": 33.0, "batch_reward": 0.5401387516856193, "critic_loss": 1.5433588472008706, "actor_loss": -83.88882772827148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.104540586471558, "step": 33000}
{"episode_reward": 958.2463106875978, "episode": 34.0, "batch_reward": 0.5506459191739559, "critic_loss": 1.564072048485279, "actor_loss": -84.27872521972657, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.106925010681152, "step": 34000}
{"episode_reward": 878.189481429015, "episode": 35.0, "batch_reward": 0.5620653221309185, "critic_loss": 1.5036965969204903, "actor_loss": -85.17311738586426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09982967376709, "step": 35000}
{"episode_reward": 904.4323787798821, "episode": 36.0, "batch_reward": 0.5707545497715473, "critic_loss": 1.8086976726055146, "actor_loss": -85.99105947875977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10916304588318, "step": 36000}
{"episode_reward": 681.4737823798076, "episode": 37.0, "batch_reward": 0.5745349011719226, "critic_loss": 1.9904154789447785, "actor_loss": -86.40638409423828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.100492000579834, "step": 37000}
{"episode_reward": 967.041156044016, "episode": 38.0, "batch_reward": 0.5743004484176636, "critic_loss": 2.2003330278396604, "actor_loss": -87.35385076904296, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10978865623474, "step": 38000}
{"episode_reward": 37.53188297536168, "episode": 39.0, "batch_reward": 0.5607898045480252, "critic_loss": 2.3709180076122283, "actor_loss": -88.6733959197998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.111066818237305, "step": 39000}
{"episode_reward": 33.17951495157993, "episode": 40.0, "batch_reward": 0.5522712877690792, "critic_loss": 2.6498319927453995, "actor_loss": -89.78710249328613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11609435081482, "step": 40000}
{"episode_reward": 360.22622615990844, "episode": 41.0, "batch_reward": 0.5399732215106487, "critic_loss": 2.745065490603447, "actor_loss": -90.66595988464356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.83240079879761, "step": 41000}
{"episode_reward": 35.113153206399495, "episode": 42.0, "batch_reward": 0.5333704189658165, "critic_loss": 2.771351353406906, "actor_loss": -91.46907551574706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10056757926941, "step": 42000}
{"episode_reward": 113.30122512724651, "episode": 43.0, "batch_reward": 0.5184350823163986, "critic_loss": 3.6949275838136675, "actor_loss": -92.17001429748535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.110474109649658, "step": 43000}
{"episode_reward": 23.071748339245516, "episode": 44.0, "batch_reward": 0.507297345906496, "critic_loss": 5.637990435600281, "actor_loss": -93.05416366577148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.099870204925537, "step": 44000}
{"episode_reward": 54.55347951579675, "episode": 45.0, "batch_reward": 0.4983786738216877, "critic_loss": 6.352059223175049, "actor_loss": -94.6491324005127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10312247276306, "step": 45000}
{"episode_reward": 47.46989012747017, "episode": 46.0, "batch_reward": 0.4890290625691414, "critic_loss": 5.764352066278458, "actor_loss": -95.97414192199707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1138014793396, "step": 46000}
{"episode_reward": 52.646835032169356, "episode": 47.0, "batch_reward": 0.47910021704435346, "critic_loss": 4.856333842515945, "actor_loss": -96.50539221191406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.414059162139893, "step": 47000}
{"episode_reward": 33.602311111572455, "episode": 48.0, "batch_reward": 0.47162644982337953, "critic_loss": 4.09451923429966, "actor_loss": -96.94693054199219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07816767692566, "step": 48000}
{"episode_reward": 46.40803020821388, "episode": 49.0, "batch_reward": 0.4625005585551262, "critic_loss": 3.5222810163497926, "actor_loss": -96.12772694396973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.074324369430542, "step": 49000}
{"episode_reward": 31.80698943607273, "episode": 50.0, "batch_reward": 0.45120737317204473, "critic_loss": 3.116426959514618, "actor_loss": -96.76510289001465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10009527206421, "step": 50000}
{"episode_reward": 125.11925634122298, "episode": 51.0, "batch_reward": 0.44497860127687455, "critic_loss": 2.4723573286533354, "actor_loss": -96.96926052856445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.89643478393555, "step": 51000}
{"episode_reward": 41.57281742718374, "episode": 52.0, "batch_reward": 0.43791688057780265, "critic_loss": 2.0276295250058176, "actor_loss": -96.11284027099609, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11721634864807, "step": 52000}
{"episode_reward": 46.600619400507775, "episode": 53.0, "batch_reward": 0.4325204958617687, "critic_loss": 1.7188903471827508, "actor_loss": -94.24829905700683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.425448417663574, "step": 53000}
{"episode_reward": 392.5769741372239, "episode": 54.0, "batch_reward": 0.43558117496967313, "critic_loss": 1.5190217081308366, "actor_loss": -93.04450675964355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09468364715576, "step": 54000}
{"episode_reward": 697.6998326626921, "episode": 55.0, "batch_reward": 0.43986492756009105, "critic_loss": 1.3549176759719848, "actor_loss": -92.57607749938965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.065508127212524, "step": 55000}
{"episode_reward": 810.7788503624256, "episode": 56.0, "batch_reward": 0.44876629710197447, "critic_loss": 1.3185637435913087, "actor_loss": -91.57718647766113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06847620010376, "step": 56000}
{"episode_reward": 917.2725607382415, "episode": 57.0, "batch_reward": 0.45666077533364297, "critic_loss": 1.265696083664894, "actor_loss": -91.12391627502441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.115604162216187, "step": 57000}
{"episode_reward": 908.005284251949, "episode": 58.0, "batch_reward": 0.4642191026508808, "critic_loss": 1.288125768840313, "actor_loss": -90.56378173828125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.094120979309082, "step": 58000}
{"episode_reward": 872.1363388754144, "episode": 59.0, "batch_reward": 0.473715427339077, "critic_loss": 1.2543269209861756, "actor_loss": -90.67175990295411, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.095324516296387, "step": 59000}
{"episode_reward": 846.7611756437952, "episode": 60.0, "batch_reward": 0.4799940522015095, "critic_loss": 1.191366059422493, "actor_loss": -90.4295089263916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.103983879089355, "step": 60000}
{"episode_reward": 905.4705444551101, "episode": 61.0, "batch_reward": 0.48528355661034583, "critic_loss": 1.1674110924005507, "actor_loss": -90.34821453857423, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.81090807914734, "step": 61000}
{"episode_reward": 922.9065661661137, "episode": 62.0, "batch_reward": 0.4935913699269295, "critic_loss": 1.1167074838280677, "actor_loss": -89.87093591308594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08800196647644, "step": 62000}
{"episode_reward": 941.3616782774235, "episode": 63.0, "batch_reward": 0.4986496472656727, "critic_loss": 1.1197248979210854, "actor_loss": -89.79250576782226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09778928756714, "step": 63000}
{"episode_reward": 967.9873508236288, "episode": 64.0, "batch_reward": 0.5052781981229783, "critic_loss": 1.0769707824587822, "actor_loss": -89.4096629486084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.090022563934326, "step": 64000}
{"episode_reward": 954.4191672596266, "episode": 65.0, "batch_reward": 0.5142262839078903, "critic_loss": 1.0840346878170968, "actor_loss": -89.4068524169922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.118533611297607, "step": 65000}
{"episode_reward": 967.7146458540622, "episode": 66.0, "batch_reward": 0.5210706295371056, "critic_loss": 1.1379230675697327, "actor_loss": -89.39726086425782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.099242687225342, "step": 66000}
{"episode_reward": 943.6320889842902, "episode": 67.0, "batch_reward": 0.5289126355350018, "critic_loss": 1.1101063922941685, "actor_loss": -89.29407502746582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.099085330963135, "step": 67000}
{"episode_reward": 956.0833216460146, "episode": 68.0, "batch_reward": 0.5336882437765599, "critic_loss": 1.086335014283657, "actor_loss": -89.28191835021973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.089879751205444, "step": 68000}
{"episode_reward": 944.5065550354789, "episode": 69.0, "batch_reward": 0.5391688852012158, "critic_loss": 0.9803002218008041, "actor_loss": -89.45943293762207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09699296951294, "step": 69000}
{"episode_reward": 949.4353511911191, "episode": 70.0, "batch_reward": 0.546215247631073, "critic_loss": 0.9835403745174408, "actor_loss": -89.44902293395997, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.101791381835938, "step": 70000}
{"episode_reward": 949.5474443422864, "episode": 71.0, "batch_reward": 0.5522687361836434, "critic_loss": 0.944363776743412, "actor_loss": -89.61594706726075, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.79308748245239, "step": 71000}
{"episode_reward": 952.7233333581694, "episode": 72.0, "batch_reward": 0.5574909096062184, "critic_loss": 0.9294705350100995, "actor_loss": -89.6650608215332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.087934017181396, "step": 72000}
{"episode_reward": 971.7599245260487, "episode": 73.0, "batch_reward": 0.562962276339531, "critic_loss": 0.9185949821472168, "actor_loss": -89.69606996154785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.104355096817017, "step": 73000}
{"episode_reward": 856.1603226103141, "episode": 74.0, "batch_reward": 0.5671830817759037, "critic_loss": 0.8738525007367134, "actor_loss": -89.53489688110352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.093292474746704, "step": 74000}
{"episode_reward": 972.1304978393788, "episode": 75.0, "batch_reward": 0.5696716175675393, "critic_loss": 0.8525073550343514, "actor_loss": -89.34741136169434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0877628326416, "step": 75000}
{"episode_reward": 919.8924061446575, "episode": 76.0, "batch_reward": 0.5774954283833503, "critic_loss": 0.8150494551956654, "actor_loss": -89.38140753173828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.099058389663696, "step": 76000}
{"episode_reward": 927.7572221543547, "episode": 77.0, "batch_reward": 0.581476060628891, "critic_loss": 0.8341039867103099, "actor_loss": -89.59597567749023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.091106414794922, "step": 77000}
{"episode_reward": 947.680154365764, "episode": 78.0, "batch_reward": 0.5866684961616992, "critic_loss": 0.7841923313736916, "actor_loss": -89.68568836975098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.094833612442017, "step": 78000}
{"episode_reward": 947.5712386254437, "episode": 79.0, "batch_reward": 0.5913438724279404, "critic_loss": 0.7766140455007553, "actor_loss": -89.79353886413574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.094192028045654, "step": 79000}
{"episode_reward": 903.8626358231254, "episode": 80.0, "batch_reward": 0.593494883030653, "critic_loss": 0.79127353271842, "actor_loss": -89.84788981628418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.106777906417847, "step": 80000}
{"episode_reward": 921.5924474857203, "episode": 81.0, "batch_reward": 0.6014102207124233, "critic_loss": 0.7534858381152153, "actor_loss": -89.87718292236327, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.799227714538574, "step": 81000}
{"episode_reward": 951.7960943046274, "episode": 82.0, "batch_reward": 0.6024670832157135, "critic_loss": 0.7531705877482892, "actor_loss": -89.80844526672364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.103475093841553, "step": 82000}
{"episode_reward": 939.3617663940037, "episode": 83.0, "batch_reward": 0.6073467108607292, "critic_loss": 0.7396849810779095, "actor_loss": -89.80695233154297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.103424072265625, "step": 83000}
{"episode_reward": 968.735360906673, "episode": 84.0, "batch_reward": 0.611483397334814, "critic_loss": 0.7576576978862286, "actor_loss": -89.89024835205078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.087623357772827, "step": 84000}
{"episode_reward": 917.466088784245, "episode": 85.0, "batch_reward": 0.6142196044325828, "critic_loss": 0.7465793701708316, "actor_loss": -89.77992028808593, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.087278604507446, "step": 85000}
{"episode_reward": 942.0250373059937, "episode": 86.0, "batch_reward": 0.6171573934257031, "critic_loss": 0.7484555234611034, "actor_loss": -89.93440676879882, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0982506275177, "step": 86000}
{"episode_reward": 886.4729111000714, "episode": 87.0, "batch_reward": 0.6222267307639122, "critic_loss": 0.7462056818008422, "actor_loss": -90.01974198913574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.095820426940918, "step": 87000}
{"episode_reward": 976.0630640856947, "episode": 88.0, "batch_reward": 0.6249875940084457, "critic_loss": 0.7759245352447033, "actor_loss": -90.03911260986328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08772087097168, "step": 88000}
{"episode_reward": 935.9336376031332, "episode": 89.0, "batch_reward": 0.6279017929434776, "critic_loss": 0.7503299652338028, "actor_loss": -89.90837913513184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.102424383163452, "step": 89000}
{"episode_reward": 889.2291061957175, "episode": 90.0, "batch_reward": 0.6314042091965676, "critic_loss": 0.7297655134499073, "actor_loss": -89.97661952209472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.094159841537476, "step": 90000}
{"episode_reward": 925.9868847956325, "episode": 91.0, "batch_reward": 0.6365055780410767, "critic_loss": 0.7400322230458259, "actor_loss": -90.02811349487305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.7942533493042, "step": 91000}
{"episode_reward": 930.8099899304217, "episode": 92.0, "batch_reward": 0.6394386613965034, "critic_loss": 0.7557731463015079, "actor_loss": -90.19483097839355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09548568725586, "step": 92000}
{"episode_reward": 915.8970093702591, "episode": 93.0, "batch_reward": 0.6430564205050469, "critic_loss": 0.7424680650830269, "actor_loss": -90.02321127319335, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.100782871246338, "step": 93000}
{"episode_reward": 964.7227118030567, "episode": 94.0, "batch_reward": 0.6442111996412277, "critic_loss": 0.772957445204258, "actor_loss": -90.17979676818848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09234595298767, "step": 94000}
{"episode_reward": 874.6129254548878, "episode": 95.0, "batch_reward": 0.6474480495452881, "critic_loss": 0.7286177194714546, "actor_loss": -90.2518035736084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.095510721206665, "step": 95000}
{"episode_reward": 905.6567574823633, "episode": 96.0, "batch_reward": 0.6535524464845658, "critic_loss": 0.7685128083527089, "actor_loss": -90.13600422668458, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09657645225525, "step": 96000}
{"episode_reward": 963.3075784751163, "episode": 97.0, "batch_reward": 0.6537681229114533, "critic_loss": 0.7865976246297359, "actor_loss": -90.04166972351074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09412980079651, "step": 97000}
{"episode_reward": 930.3705687379721, "episode": 98.0, "batch_reward": 0.6555694111585617, "critic_loss": 0.7717929625809192, "actor_loss": -90.26025604248046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09184169769287, "step": 98000}
{"episode_reward": 935.3243829356998, "episode": 99.0, "batch_reward": 0.6609032245278359, "critic_loss": 0.7775096978247166, "actor_loss": -90.26959497070312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09369707107544, "step": 99000}
{"episode_reward": 985.5312071857802, "episode": 100.0, "batch_reward": 0.6626316524744034, "critic_loss": 0.7694221608638764, "actor_loss": -90.30809379577637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09926414489746, "step": 100000}
{"episode_reward": 944.3465745423258, "episode": 101.0, "batch_reward": 0.6655504390001297, "critic_loss": 0.7422540819942951, "actor_loss": -90.38482305908204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.80536890029907, "step": 101000}
{"episode_reward": 921.0004551653876, "episode": 102.0, "batch_reward": 0.6679942119717598, "critic_loss": 0.7941320177316665, "actor_loss": -90.53907968139649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11706829071045, "step": 102000}
{"episode_reward": 973.892154274406, "episode": 103.0, "batch_reward": 0.6694687494039535, "critic_loss": 0.790322185844183, "actor_loss": -90.49573361206055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09121060371399, "step": 103000}
{"episode_reward": 928.0273013080156, "episode": 104.0, "batch_reward": 0.6723730957508087, "critic_loss": 0.7705997502803803, "actor_loss": -90.4795800628662, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08621597290039, "step": 104000}
{"episode_reward": 956.323228456035, "episode": 105.0, "batch_reward": 0.6749972255825997, "critic_loss": 0.738498473316431, "actor_loss": -90.61797639465333, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.100208520889282, "step": 105000}
{"episode_reward": 947.9417961464188, "episode": 106.0, "batch_reward": 0.6793514738678932, "critic_loss": 0.7419327306449414, "actor_loss": -90.64773168945312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09008479118347, "step": 106000}
{"episode_reward": 965.3714031563575, "episode": 107.0, "batch_reward": 0.6824372119903565, "critic_loss": 0.7016224842369556, "actor_loss": -90.6201661529541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08878803253174, "step": 107000}
{"episode_reward": 974.8413397191642, "episode": 108.0, "batch_reward": 0.6839871541857719, "critic_loss": 0.6737019440233707, "actor_loss": -90.82962652587891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09549832344055, "step": 108000}
{"episode_reward": 945.2040598977494, "episode": 109.0, "batch_reward": 0.6873112741708756, "critic_loss": 0.6973489507138729, "actor_loss": -90.78626156616211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.082593202590942, "step": 109000}
{"episode_reward": 934.4255648136495, "episode": 110.0, "batch_reward": 0.689142740726471, "critic_loss": 0.7172403346002102, "actor_loss": -90.84213722229003, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.093944549560547, "step": 110000}
{"episode_reward": 946.4167402960289, "episode": 111.0, "batch_reward": 0.6919128394126892, "critic_loss": 0.7105648728311061, "actor_loss": -90.79431658935547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.80840468406677, "step": 111000}
{"episode_reward": 952.2208542086444, "episode": 112.0, "batch_reward": 0.6937936437129975, "critic_loss": 0.7433159538507461, "actor_loss": -91.12353649902344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.093812465667725, "step": 112000}
{"episode_reward": 976.1003013820559, "episode": 113.0, "batch_reward": 0.6954566317796708, "critic_loss": 0.7162109863460064, "actor_loss": -91.02141610717773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09379267692566, "step": 113000}
{"episode_reward": 957.9128784266376, "episode": 114.0, "batch_reward": 0.6979407936930656, "critic_loss": 0.7711664108633995, "actor_loss": -91.30334072875976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.097658395767212, "step": 114000}
{"episode_reward": 920.0536609976195, "episode": 115.0, "batch_reward": 0.7004031199216842, "critic_loss": 0.9783465665280819, "actor_loss": -91.30892800903321, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09441065788269, "step": 115000}
{"episode_reward": 956.6159131369957, "episode": 116.0, "batch_reward": 0.7036396719813347, "critic_loss": 0.817433835670352, "actor_loss": -91.21958555603027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0963032245636, "step": 116000}
{"episode_reward": 960.1316946544281, "episode": 117.0, "batch_reward": 0.7069243695139885, "critic_loss": 0.7526534752845764, "actor_loss": -91.19252250671387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.091146230697632, "step": 117000}
{"episode_reward": 942.2608291110704, "episode": 118.0, "batch_reward": 0.7061852738857269, "critic_loss": 0.7424806428551673, "actor_loss": -91.14571725463867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.098018884658813, "step": 118000}
{"episode_reward": 940.1001600681893, "episode": 119.0, "batch_reward": 0.7078798503279686, "critic_loss": 0.7134824512898922, "actor_loss": -91.1248327178955, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.090861558914185, "step": 119000}
{"episode_reward": 929.2255483416943, "episode": 120.0, "batch_reward": 0.7106461811065674, "critic_loss": 0.6852294470220804, "actor_loss": -91.28597236633301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.093067407608032, "step": 120000}
{"episode_reward": 925.1282145654313, "episode": 121.0, "batch_reward": 0.7116205849051476, "critic_loss": 0.6742075080871582, "actor_loss": -91.34678726196289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.82061505317688, "step": 121000}
{"episode_reward": 971.4056402889137, "episode": 122.0, "batch_reward": 0.7167583307623864, "critic_loss": 0.7932725231945514, "actor_loss": -91.56504821777344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.095694065093994, "step": 122000}
{"episode_reward": 923.134102895787, "episode": 123.0, "batch_reward": 0.7159863848686219, "critic_loss": 0.6934386494755745, "actor_loss": -91.55284622192383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.094087600708008, "step": 123000}
{"episode_reward": 949.4392964990612, "episode": 124.0, "batch_reward": 0.715257682800293, "critic_loss": 0.8249381235539913, "actor_loss": -91.51623159790039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.094706296920776, "step": 124000}
{"episode_reward": 930.8366224963771, "episode": 125.0, "batch_reward": 0.7199413025975228, "critic_loss": 0.8069320055246353, "actor_loss": -91.42692576599121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09190583229065, "step": 125000}
{"episode_reward": 940.8173511367016, "episode": 126.0, "batch_reward": 0.7208537867069245, "critic_loss": 0.9291327705085277, "actor_loss": -91.44491586303711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.092776775360107, "step": 126000}
{"episode_reward": 960.6714758926427, "episode": 127.0, "batch_reward": 0.724043791949749, "critic_loss": 1.2641320505142213, "actor_loss": -91.57132189941406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.105995655059814, "step": 127000}
{"episode_reward": 961.4782254592341, "episode": 128.0, "batch_reward": 0.7247486473917961, "critic_loss": 1.8278183396160603, "actor_loss": -91.5492660369873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.091798782348633, "step": 128000}
{"episode_reward": 978.6756653484631, "episode": 129.0, "batch_reward": 0.7254235950112343, "critic_loss": 1.7929820815622806, "actor_loss": -91.54511491394042, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.100475311279297, "step": 129000}
{"episode_reward": 969.3087784015863, "episode": 130.0, "batch_reward": 0.7287756022810936, "critic_loss": 2.9331239610910416, "actor_loss": -91.63450309753418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10832142829895, "step": 130000}
{"episode_reward": 945.6375142845583, "episode": 131.0, "batch_reward": 0.7296528766751289, "critic_loss": 6.070501883804798, "actor_loss": -91.9402748413086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.82176232337952, "step": 131000}
{"episode_reward": 244.84744944207353, "episode": 132.0, "batch_reward": 0.7227593042850494, "critic_loss": 8.499637236773967, "actor_loss": -92.92751284790039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11723017692566, "step": 132000}
{"episode_reward": 40.41429233105494, "episode": 133.0, "batch_reward": 0.7202650010585785, "critic_loss": 15.104596618175506, "actor_loss": -94.82015161132813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.108479022979736, "step": 133000}
{"episode_reward": 92.64981196911616, "episode": 134.0, "batch_reward": 0.7125766108036041, "critic_loss": 26.611770616054535, "actor_loss": -101.34781800842285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10517406463623, "step": 134000}
{"episode_reward": 16.150509402353876, "episode": 135.0, "batch_reward": 0.7068102515935898, "critic_loss": 27.904605650901793, "actor_loss": -111.4547918548584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.114579916000366, "step": 135000}
{"episode_reward": 58.06552453592993, "episode": 136.0, "batch_reward": 0.7038204109072685, "critic_loss": 23.92911386680603, "actor_loss": -119.45959550476074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.097979307174683, "step": 136000}
{"episode_reward": 43.71074886311029, "episode": 137.0, "batch_reward": 0.7005083296298981, "critic_loss": 22.29378870487213, "actor_loss": -125.15142459106445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.110863208770752, "step": 137000}
{"episode_reward": 132.98844157459177, "episode": 138.0, "batch_reward": 0.6947413123846055, "critic_loss": 21.38592557001114, "actor_loss": -128.0320246734619, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.100224256515503, "step": 138000}
{"episode_reward": 152.3931265736655, "episode": 139.0, "batch_reward": 0.6903441125154495, "critic_loss": 20.554435434341432, "actor_loss": -131.11830575561524, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.111052751541138, "step": 139000}
{"episode_reward": 153.89808694979936, "episode": 140.0, "batch_reward": 0.6845037733316421, "critic_loss": 16.762325961589813, "actor_loss": -130.25783653259276, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.113788843154907, "step": 140000}
{"episode_reward": 203.25958487424458, "episode": 141.0, "batch_reward": 0.6859970591068267, "critic_loss": 12.765979985713958, "actor_loss": -129.83574647521974, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.891308069229126, "step": 141000}
{"episode_reward": 182.4587110129195, "episode": 142.0, "batch_reward": 0.6803585176467896, "critic_loss": 10.197411539793015, "actor_loss": -129.84867030334473, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09102725982666, "step": 142000}
{"episode_reward": 151.741185264558, "episode": 143.0, "batch_reward": 0.6760160747170448, "critic_loss": 8.855460344791412, "actor_loss": -128.72743853759766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.092774152755737, "step": 143000}
{"episode_reward": 28.128541748937785, "episode": 144.0, "batch_reward": 0.672142377614975, "critic_loss": 7.355353177070618, "actor_loss": -127.19946896362305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.111504077911377, "step": 144000}
{"episode_reward": 252.96637740683562, "episode": 145.0, "batch_reward": 0.6720023609995842, "critic_loss": 6.541005540966988, "actor_loss": -123.74710525512695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.089062929153442, "step": 145000}
{"episode_reward": 814.1856833027022, "episode": 146.0, "batch_reward": 0.6698976759314537, "critic_loss": 5.673941328525543, "actor_loss": -126.73448844909667, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.098053455352783, "step": 146000}
{"episode_reward": 27.329342104707493, "episode": 147.0, "batch_reward": 0.6651671428084374, "critic_loss": 4.749446680784225, "actor_loss": -124.18239135742188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0931715965271, "step": 147000}
{"episode_reward": 28.85449003476419, "episode": 148.0, "batch_reward": 0.6622052022218704, "critic_loss": 4.355377567529678, "actor_loss": -122.56624575805664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09923005104065, "step": 148000}
{"episode_reward": 29.250282820905372, "episode": 149.0, "batch_reward": 0.6579772818088532, "critic_loss": 3.6793690078258514, "actor_loss": -121.4409504852295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.096468210220337, "step": 149000}
{"episode_reward": 27.07465710947834, "episode": 150.0, "batch_reward": 0.6536881632804871, "critic_loss": 3.2059462493658066, "actor_loss": -118.70069947814942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
