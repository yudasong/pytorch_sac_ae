{"episode_reward": 0.0, "episode": 1.0, "duration": 33.456737756729126, "step": 1000}
{"episode_reward": 28.002640152663393, "episode": 2.0, "duration": 2.9514353275299072, "step": 2000}
{"episode_reward": 481.4321918933315, "episode": 3.0, "batch_reward": 0.26359324416107793, "critic_loss": 0.4735774766578003, "actor_loss": -84.29783349191727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 90.50980424880981, "step": 3000}
{"episode_reward": 417.6781248124224, "episode": 4.0, "batch_reward": 0.3493122904598713, "critic_loss": 0.5859444825053215, "actor_loss": -83.93016087341309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.396376132965088, "step": 4000}
{"episode_reward": 612.0402483047487, "episode": 5.0, "batch_reward": 0.3801711339354515, "critic_loss": 0.7879884260296821, "actor_loss": -83.1363374786377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.001919269561768, "step": 5000}
{"episode_reward": 345.55471458598765, "episode": 6.0, "batch_reward": 0.3861107000410557, "critic_loss": 1.0039036285877228, "actor_loss": -83.36562492370605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.720216751098633, "step": 6000}
{"episode_reward": 489.67931575706274, "episode": 7.0, "batch_reward": 0.4171516187787056, "critic_loss": 1.2187678934931756, "actor_loss": -83.08180838012696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.674587965011597, "step": 7000}
{"episode_reward": 652.3923075696939, "episode": 8.0, "batch_reward": 0.42936246606707573, "critic_loss": 1.3366878857016564, "actor_loss": -82.79223818969727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.19202160835266, "step": 8000}
{"episode_reward": 463.1781776843974, "episode": 9.0, "batch_reward": 0.4471900635063648, "critic_loss": 1.4126026790142059, "actor_loss": -83.15914325714111, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.840068578720093, "step": 9000}
{"episode_reward": 609.0868266448895, "episode": 10.0, "batch_reward": 0.46250858849287035, "critic_loss": 1.544512161910534, "actor_loss": -83.48843522644043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.535562753677368, "step": 10000}
{"episode_reward": 605.488573692911, "episode": 11.0, "batch_reward": 0.4496408296525478, "critic_loss": 1.4351178063750267, "actor_loss": -82.65523477172852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.196913719177246, "step": 11000}
{"episode_reward": 118.42283052614893, "episode": 12.0, "batch_reward": 0.42033049392700195, "critic_loss": 1.3577622453570366, "actor_loss": -81.28030461120605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.552192449569702, "step": 12000}
{"episode_reward": 28.24615759760495, "episode": 13.0, "batch_reward": 0.41349316996335983, "critic_loss": 1.5232798398733138, "actor_loss": -80.67610771179199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.599514722824097, "step": 13000}
{"episode_reward": 662.6732410007149, "episode": 14.0, "batch_reward": 0.4287153526842594, "critic_loss": 1.6469909006357193, "actor_loss": -80.49882958984375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.873216152191162, "step": 14000}
{"episode_reward": 655.8966896455216, "episode": 15.0, "batch_reward": 0.4472226834595203, "critic_loss": 1.6046665187478066, "actor_loss": -81.5837586517334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.27304196357727, "step": 15000}
{"episode_reward": 701.3619091179993, "episode": 16.0, "batch_reward": 0.46427721455693244, "critic_loss": 1.6455649446249008, "actor_loss": -81.471535446167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.935130834579468, "step": 16000}
{"episode_reward": 688.4727787302132, "episode": 17.0, "batch_reward": 0.4781842978000641, "critic_loss": 1.574586312711239, "actor_loss": -80.88346714782715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.202493906021118, "step": 17000}
{"episode_reward": 680.9488259082644, "episode": 18.0, "batch_reward": 0.48705638271570206, "critic_loss": 1.4975018696188926, "actor_loss": -81.40819831085206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.68960475921631, "step": 18000}
{"episode_reward": 640.5885399217897, "episode": 19.0, "batch_reward": 0.49436169931292534, "critic_loss": 1.5659271389245988, "actor_loss": -81.71446375274658, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.855640172958374, "step": 19000}
{"episode_reward": 689.379756634563, "episode": 20.0, "batch_reward": 0.5077334361076355, "critic_loss": 1.6295456821918488, "actor_loss": -82.84947560882568, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.654113054275513, "step": 20000}
{"episode_reward": 752.6537169423374, "episode": 21.0, "batch_reward": 0.5228966621458531, "critic_loss": 1.5981293699145318, "actor_loss": -81.07578423309326, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.95821404457092, "step": 21000}
{"episode_reward": 716.8160902205537, "episode": 22.0, "batch_reward": 0.5274627102911472, "critic_loss": 1.6978880529999734, "actor_loss": -82.32899568176269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.01807975769043, "step": 22000}
{"episode_reward": 700.9776761575297, "episode": 23.0, "batch_reward": 0.5382427704334259, "critic_loss": 1.7368132694959642, "actor_loss": -81.79347227478027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.438195943832397, "step": 23000}
{"episode_reward": 813.6539392562871, "episode": 24.0, "batch_reward": 0.5504738610088825, "critic_loss": 1.7550257053375244, "actor_loss": -82.71653494262695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.416630268096924, "step": 24000}
{"episode_reward": 787.7741681973761, "episode": 25.0, "batch_reward": 0.5624402785897255, "critic_loss": 1.8141628317832947, "actor_loss": -83.51289965057373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.444013833999634, "step": 25000}
{"episode_reward": 883.6081496004443, "episode": 26.0, "batch_reward": 0.5720819116830825, "critic_loss": 1.8239051039814949, "actor_loss": -82.76933471679688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.678562879562378, "step": 26000}
{"episode_reward": 791.6712260424429, "episode": 27.0, "batch_reward": 0.5822059895396232, "critic_loss": 1.8146564821004867, "actor_loss": -83.36698985290528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.555184841156006, "step": 27000}
{"episode_reward": 823.8140935491745, "episode": 28.0, "batch_reward": 0.5887377110123634, "critic_loss": 1.8699825565814971, "actor_loss": -82.88416847991944, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.390080451965332, "step": 28000}
{"episode_reward": 569.3569988581422, "episode": 29.0, "batch_reward": 0.5904491072297097, "critic_loss": 1.9155002386569977, "actor_loss": -83.23764211273193, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.613338232040405, "step": 29000}
{"episode_reward": 860.1711381736362, "episode": 30.0, "batch_reward": 0.6017370656132698, "critic_loss": 1.9432838640213013, "actor_loss": -82.35120984649659, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.98177146911621, "step": 30000}
{"episode_reward": 848.3140622058193, "episode": 31.0, "batch_reward": 0.6064131707549095, "critic_loss": 2.0040292302370073, "actor_loss": -83.79541771697998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.164021253585815, "step": 31000}
{"episode_reward": 804.61770450417, "episode": 32.0, "batch_reward": 0.6130817516446113, "critic_loss": 2.020324719429016, "actor_loss": -84.36565145874023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.457557439804077, "step": 32000}
{"episode_reward": 858.0861155173745, "episode": 33.0, "batch_reward": 0.6222677826881409, "critic_loss": 2.0867120448350907, "actor_loss": -84.56162698364258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.39044976234436, "step": 33000}
{"episode_reward": 885.3663291829868, "episode": 34.0, "batch_reward": 0.6216688202023506, "critic_loss": 2.128936345696449, "actor_loss": -84.55731109619141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.773128509521484, "step": 34000}
{"episode_reward": 555.8662741024251, "episode": 35.0, "batch_reward": 0.6252524877786636, "critic_loss": 2.3370102924108505, "actor_loss": -84.52284146118164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.609873294830322, "step": 35000}
{"episode_reward": 747.0389210260172, "episode": 36.0, "batch_reward": 0.6307906236648559, "critic_loss": 2.3981430530548096, "actor_loss": -85.18760858917236, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.088438272476196, "step": 36000}
{"episode_reward": 856.464678889952, "episode": 37.0, "batch_reward": 0.6388409930467606, "critic_loss": 2.4210930082798003, "actor_loss": -84.33599499511719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.653595209121704, "step": 37000}
{"episode_reward": 857.3854648204325, "episode": 38.0, "batch_reward": 0.6385416553020478, "critic_loss": 2.464528094768524, "actor_loss": -83.77436427307128, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.42898178100586, "step": 38000}
{"episode_reward": 725.3981519552433, "episode": 39.0, "batch_reward": 0.6448383358716965, "critic_loss": 2.4620252808332443, "actor_loss": -83.88441469573975, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.662031888961792, "step": 39000}
{"episode_reward": 919.8407227404995, "episode": 40.0, "batch_reward": 0.6426556212902069, "critic_loss": 2.524356997847557, "actor_loss": -84.62698830413818, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.348458766937256, "step": 40000}
{"episode_reward": 149.04165292676993, "episode": 41.0, "batch_reward": 0.6413445746898652, "critic_loss": 2.540715388894081, "actor_loss": -84.19985948944091, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.04609775543213, "step": 41000}
{"episode_reward": 907.8145866809934, "episode": 42.0, "batch_reward": 0.645959547817707, "critic_loss": 2.515010809659958, "actor_loss": -84.32308155822754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.263192892074585, "step": 42000}
{"episode_reward": 758.7947642234858, "episode": 43.0, "batch_reward": 0.6497639551162719, "critic_loss": 2.4808485285043718, "actor_loss": -84.60035417175293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.349477767944336, "step": 43000}
{"episode_reward": 922.5973368760338, "episode": 44.0, "batch_reward": 0.653944185256958, "critic_loss": 2.4123805171251296, "actor_loss": -86.65468425750733, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.5874924659729, "step": 44000}
{"episode_reward": 807.6458342663738, "episode": 45.0, "batch_reward": 0.657624336540699, "critic_loss": 2.4424037442207336, "actor_loss": -85.29231425476074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.270284414291382, "step": 45000}
{"episode_reward": 662.3919440429931, "episode": 46.0, "batch_reward": 0.6576652861237526, "critic_loss": 2.4352116632461547, "actor_loss": -84.13081607818603, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.860223531723022, "step": 46000}
{"episode_reward": 872.1467835655255, "episode": 47.0, "batch_reward": 0.6625366140007972, "critic_loss": 2.4968047683238983, "actor_loss": -85.01566477966308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.433050632476807, "step": 47000}
{"episode_reward": 888.3709949699141, "episode": 48.0, "batch_reward": 0.6677598903179168, "critic_loss": 2.4699903341531755, "actor_loss": -84.86241571044921, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.775184154510498, "step": 48000}
{"episode_reward": 876.099773183819, "episode": 49.0, "batch_reward": 0.6717973495721817, "critic_loss": 2.438036409020424, "actor_loss": -86.3254062576294, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.455547332763672, "step": 49000}
{"episode_reward": 821.9780830060776, "episode": 50.0, "batch_reward": 0.6742878698706627, "critic_loss": 2.461006200671196, "actor_loss": -85.74303185272217, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.31805658340454, "step": 50000}
{"episode_reward": 837.5415214314945, "episode": 51.0, "batch_reward": 0.6806213437914849, "critic_loss": 2.44844391310215, "actor_loss": -85.79024345397949, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.270055055618286, "step": 51000}
{"episode_reward": 948.4168462847855, "episode": 52.0, "batch_reward": 0.6767878895998001, "critic_loss": 2.523835020661354, "actor_loss": -85.18187634277344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.280078649520874, "step": 52000}
{"episode_reward": 27.493042490366303, "episode": 53.0, "batch_reward": 0.6705316733717919, "critic_loss": 2.3934687823057175, "actor_loss": -85.87251849365235, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.349671125411987, "step": 53000}
{"episode_reward": 899.2924086494897, "episode": 54.0, "batch_reward": 0.6765905888676643, "critic_loss": 2.4031923469305037, "actor_loss": -86.42947966766357, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.358601808547974, "step": 54000}
{"episode_reward": 898.865989493559, "episode": 55.0, "batch_reward": 0.6788912780284881, "critic_loss": 2.373651007890701, "actor_loss": -86.22334886169433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.865816354751587, "step": 55000}
{"episode_reward": 886.9904713970237, "episode": 56.0, "batch_reward": 0.683258462548256, "critic_loss": 2.3586931408643723, "actor_loss": -86.23363835906983, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.672454357147217, "step": 56000}
{"episode_reward": 919.1330552945769, "episode": 57.0, "batch_reward": 0.6883109962940216, "critic_loss": 2.319833408117294, "actor_loss": -86.3801536102295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.572842121124268, "step": 57000}
{"episode_reward": 930.2035689577343, "episode": 58.0, "batch_reward": 0.6901029841303825, "critic_loss": 2.3802610362768175, "actor_loss": -86.59907991027832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.666999340057373, "step": 58000}
{"episode_reward": 805.5306404226226, "episode": 59.0, "batch_reward": 0.6941184341907501, "critic_loss": 2.3186064157485964, "actor_loss": -86.54963474273681, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.07184648513794, "step": 59000}
{"episode_reward": 974.0677159690364, "episode": 60.0, "batch_reward": 0.698682144343853, "critic_loss": 2.27653835773468, "actor_loss": -86.6155753326416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.365134954452515, "step": 60000}
{"episode_reward": 929.9830292961091, "episode": 61.0, "batch_reward": 0.7026913897395134, "critic_loss": 2.288559883236885, "actor_loss": -86.67207054901122, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.062557220458984, "step": 61000}
{"episode_reward": 934.1348388849025, "episode": 62.0, "batch_reward": 0.7077110017538071, "critic_loss": 2.4074982453584672, "actor_loss": -86.92614784240723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.7133207321167, "step": 62000}
{"episode_reward": 922.6318341432388, "episode": 63.0, "batch_reward": 0.7083008571267128, "critic_loss": 2.4088998279571534, "actor_loss": -87.16541863250733, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.578344106674194, "step": 63000}
{"episode_reward": 888.5412015460838, "episode": 64.0, "batch_reward": 0.7123956121206284, "critic_loss": 2.31036127281189, "actor_loss": -87.68343814849854, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.6158185005188, "step": 64000}
{"episode_reward": 877.9051828971516, "episode": 65.0, "batch_reward": 0.7141261158585548, "critic_loss": 2.2920346632003783, "actor_loss": -87.22261744689942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.74082040786743, "step": 65000}
{"episode_reward": 861.35412342906, "episode": 66.0, "batch_reward": 0.7169561293721199, "critic_loss": 2.3001802709102632, "actor_loss": -87.23698179626464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.875064611434937, "step": 66000}
{"episode_reward": 873.3586567598323, "episode": 67.0, "batch_reward": 0.7206156371831894, "critic_loss": 2.3229810914993285, "actor_loss": -88.17948881530762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.187296390533447, "step": 67000}
{"episode_reward": 931.9982808934842, "episode": 68.0, "batch_reward": 0.7223991218209267, "critic_loss": 2.3782446620464324, "actor_loss": -88.74440562438964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.31619620323181, "step": 68000}
{"episode_reward": 886.4472925172349, "episode": 69.0, "batch_reward": 0.7227099309563637, "critic_loss": 2.4094248312711715, "actor_loss": -87.3275336151123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.48815941810608, "step": 69000}
{"episode_reward": 923.9221661330794, "episode": 70.0, "batch_reward": 0.728968706548214, "critic_loss": 2.344518746972084, "actor_loss": -87.786267578125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.064186573028564, "step": 70000}
{"episode_reward": 833.1246526113604, "episode": 71.0, "batch_reward": 0.7277040337920189, "critic_loss": 2.5156387112140655, "actor_loss": -87.37128498840332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.35843086242676, "step": 71000}
{"episode_reward": 904.7902566235238, "episode": 72.0, "batch_reward": 0.7318855398893356, "critic_loss": 2.5822273045778275, "actor_loss": -88.44245040893554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.591524362564087, "step": 72000}
{"episode_reward": 892.019397900444, "episode": 73.0, "batch_reward": 0.7338401030302047, "critic_loss": 2.6044241755008697, "actor_loss": -88.64749388122559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.365144968032837, "step": 73000}
{"episode_reward": 875.673129652654, "episode": 74.0, "batch_reward": 0.7351230115890502, "critic_loss": 2.5500324541330337, "actor_loss": -87.93118383789063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.623398065567017, "step": 74000}
{"episode_reward": 921.6958621060605, "episode": 75.0, "batch_reward": 0.7377992183566093, "critic_loss": 2.49917682826519, "actor_loss": -88.17263377380371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.698960781097412, "step": 75000}
{"episode_reward": 888.9348421403841, "episode": 76.0, "batch_reward": 0.7415678755044938, "critic_loss": 2.556984379887581, "actor_loss": -88.65433628845214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.726583242416382, "step": 76000}
{"episode_reward": 941.2464129005491, "episode": 77.0, "batch_reward": 0.7422939518094063, "critic_loss": 2.5701982802152634, "actor_loss": -88.42219741821289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.152763843536377, "step": 77000}
{"episode_reward": 939.0340119007349, "episode": 78.0, "batch_reward": 0.7457153508663178, "critic_loss": 2.6471643682718278, "actor_loss": -88.8885698852539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.43274760246277, "step": 78000}
{"episode_reward": 931.5366244751265, "episode": 79.0, "batch_reward": 0.748615021288395, "critic_loss": 2.876899237394333, "actor_loss": -89.55265773010254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.703489065170288, "step": 79000}
{"episode_reward": 951.964799598416, "episode": 80.0, "batch_reward": 0.7507670578956605, "critic_loss": 2.7106109929084776, "actor_loss": -89.26396089172363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.302823305130005, "step": 80000}
{"episode_reward": 952.3861801633396, "episode": 81.0, "batch_reward": 0.7545063978433609, "critic_loss": 2.6063348971605302, "actor_loss": -88.70381100463867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.3259916305542, "step": 81000}
{"episode_reward": 933.5698359007152, "episode": 82.0, "batch_reward": 0.7556371314525604, "critic_loss": 2.9652418040037154, "actor_loss": -88.86428163146972, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.832961082458496, "step": 82000}
{"episode_reward": 934.6958801892459, "episode": 83.0, "batch_reward": 0.7578706575632095, "critic_loss": 3.703809854626656, "actor_loss": -89.41065560913086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.724096298217773, "step": 83000}
{"episode_reward": 648.9224354317337, "episode": 84.0, "batch_reward": 0.7568358530402184, "critic_loss": 3.162273519039154, "actor_loss": -89.8600424194336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.51067328453064, "step": 84000}
{"episode_reward": 918.3483918860287, "episode": 85.0, "batch_reward": 0.7562517272830009, "critic_loss": 3.1608886152505873, "actor_loss": -89.52613027954102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.580620527267456, "step": 85000}
{"episode_reward": 942.9334906088702, "episode": 86.0, "batch_reward": 0.7621395146846771, "critic_loss": 3.514622763633728, "actor_loss": -89.6496629333496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.724778652191162, "step": 86000}
{"episode_reward": 963.8920441448286, "episode": 87.0, "batch_reward": 0.7621862804293632, "critic_loss": 3.9647794450521467, "actor_loss": -89.91212522888183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.956406593322754, "step": 87000}
{"episode_reward": 955.207387941344, "episode": 88.0, "batch_reward": 0.7661402363181115, "critic_loss": 2.74680818259716, "actor_loss": -89.54976210021972, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.696221351623535, "step": 88000}
{"episode_reward": 930.1327432105908, "episode": 89.0, "batch_reward": 0.7671753833293915, "critic_loss": 4.208126247763634, "actor_loss": -89.90904405212402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.899133682250977, "step": 89000}
{"episode_reward": 894.6604480823187, "episode": 90.0, "batch_reward": 0.769433199763298, "critic_loss": 3.2864579548835753, "actor_loss": -89.76653015136719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.413122177124023, "step": 90000}
{"episode_reward": 894.6425103388151, "episode": 91.0, "batch_reward": 0.7690627244710923, "critic_loss": 3.2922188384532927, "actor_loss": -89.94845832824707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.125484466552734, "step": 91000}
{"episode_reward": 932.2345816878899, "episode": 92.0, "batch_reward": 0.7700895196795463, "critic_loss": 3.6927925037145615, "actor_loss": -90.54360523986817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.398809909820557, "step": 92000}
{"episode_reward": 893.938344762322, "episode": 93.0, "batch_reward": 0.7708302725553513, "critic_loss": 3.285062578201294, "actor_loss": -89.84836610412597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.761064052581787, "step": 93000}
{"episode_reward": 901.7087426572051, "episode": 94.0, "batch_reward": 0.7735439648032189, "critic_loss": 3.384292364358902, "actor_loss": -90.3976340637207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.00347661972046, "step": 94000}
{"episode_reward": 907.8359063986277, "episode": 95.0, "batch_reward": 0.7740460293292999, "critic_loss": 3.523162200689316, "actor_loss": -90.80243241882324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.741525888442993, "step": 95000}
{"episode_reward": 836.496145373243, "episode": 96.0, "batch_reward": 0.7765674622058868, "critic_loss": 3.3865918428897857, "actor_loss": -90.82609548950195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.366953134536743, "step": 96000}
{"episode_reward": 928.7547012939029, "episode": 97.0, "batch_reward": 0.776226282119751, "critic_loss": 3.1064968914985656, "actor_loss": -90.54789784240722, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.24384903907776, "step": 97000}
{"episode_reward": 885.3221470615945, "episode": 98.0, "batch_reward": 0.7781783084869385, "critic_loss": 3.1975170361995695, "actor_loss": -91.08867251586913, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.41025471687317, "step": 98000}
{"episode_reward": 902.0722005575883, "episode": 99.0, "batch_reward": 0.7801950629353523, "critic_loss": 2.842435428023338, "actor_loss": -90.54181504821777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.586178302764893, "step": 99000}
{"episode_reward": 935.675691360312, "episode": 100.0, "batch_reward": 0.7814520297646522, "critic_loss": 3.0975540763139726, "actor_loss": -90.99091496276856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.170806884765625, "step": 100000}
{"episode_reward": 940.008488617068, "episode": 101.0, "batch_reward": 0.7824666895866395, "critic_loss": 3.206758948683739, "actor_loss": -90.45736654663087, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.33790826797485, "step": 101000}
{"episode_reward": 965.4824924367457, "episode": 102.0, "batch_reward": 0.7828805971741676, "critic_loss": 3.0448450454473495, "actor_loss": -90.97752217102051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.620353937149048, "step": 102000}
{"episode_reward": 64.72061687958828, "episode": 103.0, "batch_reward": 0.7785154126286506, "critic_loss": 3.1922849481105806, "actor_loss": -90.32428338623046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.229327917099, "step": 103000}
{"episode_reward": 952.5734141203644, "episode": 104.0, "batch_reward": 0.7791229149699211, "critic_loss": 3.149569340467453, "actor_loss": -90.37568081665039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.689706563949585, "step": 104000}
{"episode_reward": 852.6670800467944, "episode": 105.0, "batch_reward": 0.7819074176549912, "critic_loss": 2.939347779273987, "actor_loss": -90.76817819213868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.81842303276062, "step": 105000}
{"episode_reward": 959.1687175124725, "episode": 106.0, "batch_reward": 0.7824663860797882, "critic_loss": 2.6908797003030775, "actor_loss": -90.75016491699219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.850046634674072, "step": 106000}
{"episode_reward": 849.4867037053584, "episode": 107.0, "batch_reward": 0.782655474126339, "critic_loss": 2.7767991525530813, "actor_loss": -90.41730432128907, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.050724744796753, "step": 107000}
{"episode_reward": 966.0650101490152, "episode": 108.0, "batch_reward": 0.7837902292609215, "critic_loss": 2.874233267903328, "actor_loss": -91.18295037841797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.33686351776123, "step": 108000}
{"episode_reward": 879.0512003827512, "episode": 109.0, "batch_reward": 0.7880007875561714, "critic_loss": 3.1548306987285613, "actor_loss": -91.08896536254883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.9510600566864, "step": 109000}
{"episode_reward": 934.237392403831, "episode": 110.0, "batch_reward": 0.7857401050925255, "critic_loss": 2.624471055626869, "actor_loss": -91.5642261505127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.659125804901123, "step": 110000}
{"episode_reward": 937.33598312237, "episode": 111.0, "batch_reward": 0.7880217344760895, "critic_loss": 2.619704666256905, "actor_loss": -91.08875817871093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 60.21619439125061, "step": 111000}
{"episode_reward": 967.280933167726, "episode": 112.0, "batch_reward": 0.7899401853084564, "critic_loss": 2.6048199989795684, "actor_loss": -91.23486799621583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.770092725753784, "step": 112000}
{"episode_reward": 907.8850432244078, "episode": 113.0, "batch_reward": 0.7913232721686363, "critic_loss": 2.547320915699005, "actor_loss": -91.13490080261231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.478753328323364, "step": 113000}
{"episode_reward": 933.9950603767611, "episode": 114.0, "batch_reward": 0.7928046918511391, "critic_loss": 2.6354814940690994, "actor_loss": -91.52370726013183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.650777101516724, "step": 114000}
{"episode_reward": 928.1264191311061, "episode": 115.0, "batch_reward": 0.7939245335459709, "critic_loss": 2.5984270451068876, "actor_loss": -91.45259893798828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.532886743545532, "step": 115000}
{"episode_reward": 947.5891837281549, "episode": 116.0, "batch_reward": 0.7945887156128884, "critic_loss": 2.713547732114792, "actor_loss": -91.52992503356934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.935505867004395, "step": 116000}
{"episode_reward": 950.1045078482676, "episode": 117.0, "batch_reward": 0.796411698281765, "critic_loss": 2.454235971331596, "actor_loss": -91.22153186035156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.902135610580444, "step": 117000}
{"episode_reward": 945.208829417408, "episode": 118.0, "batch_reward": 0.7979942574501038, "critic_loss": 2.631611380815506, "actor_loss": -91.45079847717285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.81428337097168, "step": 118000}
{"episode_reward": 938.8146057522357, "episode": 119.0, "batch_reward": 0.7987804973125457, "critic_loss": 2.4644181820750237, "actor_loss": -91.73149681091309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.742893934249878, "step": 119000}
{"episode_reward": 879.0853979222162, "episode": 120.0, "batch_reward": 0.7994050948619843, "critic_loss": 2.940364070773125, "actor_loss": -91.16542416381836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.593472480773926, "step": 120000}
{"episode_reward": 949.3180649434988, "episode": 121.0, "batch_reward": 0.8023168439865113, "critic_loss": 2.4261207847595214, "actor_loss": -91.68059048461915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.13970494270325, "step": 121000}
{"episode_reward": 920.2074775178835, "episode": 122.0, "batch_reward": 0.8022576020956039, "critic_loss": 2.5188497756123542, "actor_loss": -91.91922914123535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.4852511882782, "step": 122000}
{"episode_reward": 883.5668420754484, "episode": 123.0, "batch_reward": 0.8022498770356178, "critic_loss": 2.535916718840599, "actor_loss": -92.00913154602051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.744066953659058, "step": 123000}
{"episode_reward": 928.6741958563017, "episode": 124.0, "batch_reward": 0.8023790833950043, "critic_loss": 2.6326044364571572, "actor_loss": -91.86962413024902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.482335805892944, "step": 124000}
{"episode_reward": 874.2974481486946, "episode": 125.0, "batch_reward": 0.8025335944294929, "critic_loss": 2.893760917365551, "actor_loss": -91.76188153076171, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.510989904403687, "step": 125000}
{"episode_reward": 955.7612577018848, "episode": 126.0, "batch_reward": 0.8021206434369087, "critic_loss": 2.6425755227804184, "actor_loss": -92.06078733825683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.651366472244263, "step": 126000}
{"episode_reward": 864.5684169194712, "episode": 127.0, "batch_reward": 0.804971527993679, "critic_loss": 2.5575808693170545, "actor_loss": -91.9425251159668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.306577682495117, "step": 127000}
{"episode_reward": 931.8042182299387, "episode": 128.0, "batch_reward": 0.8057729507684708, "critic_loss": 2.8295401297211646, "actor_loss": -91.72993476867676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.672832250595093, "step": 128000}
{"episode_reward": 934.1084050834326, "episode": 129.0, "batch_reward": 0.8063922410607338, "critic_loss": 2.9751915547847747, "actor_loss": -92.03181732177734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.22267746925354, "step": 129000}
{"episode_reward": 826.4153608315725, "episode": 130.0, "batch_reward": 0.8069108920693397, "critic_loss": 2.7201529443264008, "actor_loss": -92.22865037536621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.979835033416748, "step": 130000}
{"episode_reward": 918.5008489948054, "episode": 131.0, "batch_reward": 0.8083715356588363, "critic_loss": 2.6461343529224397, "actor_loss": -91.58124359130859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.95161056518555, "step": 131000}
{"episode_reward": 934.9417710064084, "episode": 132.0, "batch_reward": 0.8095851639509201, "critic_loss": 2.5144798323512076, "actor_loss": -92.43085241699218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.6788227558136, "step": 132000}
{"episode_reward": 923.7238321075644, "episode": 133.0, "batch_reward": 0.8120378438234329, "critic_loss": 2.48430489975214, "actor_loss": -92.00109825134277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.431453227996826, "step": 133000}
{"episode_reward": 949.6507792282921, "episode": 134.0, "batch_reward": 0.8095643320679664, "critic_loss": 2.57937964117527, "actor_loss": -92.142433883667, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.660685062408447, "step": 134000}
{"episode_reward": 924.9885413870207, "episode": 135.0, "batch_reward": 0.8098979025483132, "critic_loss": 2.486587438941002, "actor_loss": -92.38461022949218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.621763944625854, "step": 135000}
{"episode_reward": 847.4525699555977, "episode": 136.0, "batch_reward": 0.8128606511950492, "critic_loss": 2.5545492121577262, "actor_loss": -92.20309507751465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.00990080833435, "step": 136000}
{"episode_reward": 919.1443923505362, "episode": 137.0, "batch_reward": 0.8130445222854614, "critic_loss": 2.5206076591014863, "actor_loss": -92.53038914489746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.642320156097412, "step": 137000}
{"episode_reward": 904.7206582315574, "episode": 138.0, "batch_reward": 0.8131307252049446, "critic_loss": 2.44017244207859, "actor_loss": -92.82334219360351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.148698806762695, "step": 138000}
{"episode_reward": 932.38837581299, "episode": 139.0, "batch_reward": 0.8136514046192169, "critic_loss": 2.4943935155272485, "actor_loss": -92.05778964233399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.194855451583862, "step": 139000}
{"episode_reward": 945.1726941132601, "episode": 140.0, "batch_reward": 0.8144688497185707, "critic_loss": 2.3940040830373763, "actor_loss": -92.65506350708007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.759724378585815, "step": 140000}
{"episode_reward": 936.8375010829666, "episode": 141.0, "batch_reward": 0.8190049543380737, "critic_loss": 2.323524006187916, "actor_loss": -92.57384452819824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 50.50751495361328, "step": 141000}
{"episode_reward": 949.0354993478452, "episode": 142.0, "batch_reward": 0.8165960853099823, "critic_loss": 2.3848432488441467, "actor_loss": -92.43311387634277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.058562755584717, "step": 142000}
{"episode_reward": 913.799017560068, "episode": 143.0, "batch_reward": 0.8171574413776398, "critic_loss": 2.2780455359220504, "actor_loss": -92.55714228820801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.13104248046875, "step": 143000}
{"episode_reward": 862.7351207500698, "episode": 144.0, "batch_reward": 0.8162669702172279, "critic_loss": 2.3487273263931274, "actor_loss": -92.71519151306153, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.769832134246826, "step": 144000}
{"episode_reward": 925.4563219495275, "episode": 145.0, "batch_reward": 0.820529695212841, "critic_loss": 2.2977139569520952, "actor_loss": -92.81838360595704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.80770754814148, "step": 145000}
{"episode_reward": 882.2721290325693, "episode": 146.0, "batch_reward": 0.8187745022177696, "critic_loss": 2.3003301364183426, "actor_loss": -92.29911204528808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.763919353485107, "step": 146000}
{"episode_reward": 924.6403730153535, "episode": 147.0, "batch_reward": 0.8185453451275826, "critic_loss": 2.2656011521220205, "actor_loss": -92.59662098693848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.973103523254395, "step": 147000}
{"episode_reward": 839.8058897157196, "episode": 148.0, "batch_reward": 0.8211200948953629, "critic_loss": 2.2306295488476753, "actor_loss": -92.58918048095703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.463232040405273, "step": 148000}
{"episode_reward": 939.1007939911849, "episode": 149.0, "batch_reward": 0.819524058997631, "critic_loss": 2.1627916660308837, "actor_loss": -92.79939967346192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.207921981811523, "step": 149000}
{"episode_reward": 922.1062631993955, "episode": 150.0, "batch_reward": 0.820813673377037, "critic_loss": 2.114630871653557, "actor_loss": -92.97253080749512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
