{"episode_reward": 0.0, "episode": 1.0, "duration": 21.206326961517334, "step": 1000}
{"episode_reward": 28.002640152663393, "episode": 2.0, "duration": 1.8384974002838135, "step": 2000}
{"episode_reward": 481.4321918933315, "episode": 3.0, "batch_reward": 0.2701191950655254, "critic_loss": 0.4438243957684214, "actor_loss": -84.29537970583742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.86709403991699, "step": 3000}
{"episode_reward": 499.65960519459765, "episode": 4.0, "batch_reward": 0.35828009498119356, "critic_loss": 0.6430401248335839, "actor_loss": -84.84531478881836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.238853693008423, "step": 4000}
{"episode_reward": 547.0616205938952, "episode": 5.0, "batch_reward": 0.398175449937582, "critic_loss": 0.6784465537369251, "actor_loss": -85.1962127380371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.19664740562439, "step": 5000}
{"episode_reward": 509.00861187049594, "episode": 6.0, "batch_reward": 0.42757307028770447, "critic_loss": 0.7812027150690556, "actor_loss": -85.51100062561035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.19172430038452, "step": 6000}
{"episode_reward": 597.2631181604455, "episode": 7.0, "batch_reward": 0.44975637090206144, "critic_loss": 1.0455909020900727, "actor_loss": -85.19958781433105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.191534280776978, "step": 7000}
{"episode_reward": 598.5857445703172, "episode": 8.0, "batch_reward": 0.4860741772353649, "critic_loss": 1.228084544479847, "actor_loss": -85.85246502685547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.198596954345703, "step": 8000}
{"episode_reward": 712.3732217665857, "episode": 9.0, "batch_reward": 0.5160721140205861, "critic_loss": 1.2700746551752091, "actor_loss": -86.21695011901855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.265146493911743, "step": 9000}
{"episode_reward": 845.7736340627443, "episode": 10.0, "batch_reward": 0.5145787866711616, "critic_loss": 1.3386398990154267, "actor_loss": -85.54507415771485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.44655466079712, "step": 10000}
{"episode_reward": 313.69711878436135, "episode": 11.0, "batch_reward": 0.5233534547686577, "critic_loss": 1.543189069747925, "actor_loss": -85.3258302307129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.01317358016968, "step": 11000}
{"episode_reward": 776.2226691044748, "episode": 12.0, "batch_reward": 0.5462505942285061, "critic_loss": 1.5442716664671898, "actor_loss": -85.83173915100097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.210991621017456, "step": 12000}
{"episode_reward": 728.8305895394429, "episode": 13.0, "batch_reward": 0.5583951598107815, "critic_loss": 1.5798951071500777, "actor_loss": -85.70777278137207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.220773935317993, "step": 13000}
{"episode_reward": 688.4760778980939, "episode": 14.0, "batch_reward": 0.5690496475696564, "critic_loss": 1.7553924901485443, "actor_loss": -85.81808326721192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.212810277938843, "step": 14000}
{"episode_reward": 746.0567402111877, "episode": 15.0, "batch_reward": 0.5819978679716588, "critic_loss": 1.6724558928608895, "actor_loss": -86.41155303955078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.21476149559021, "step": 15000}
{"episode_reward": 812.8788421948625, "episode": 16.0, "batch_reward": 0.5992402319014073, "critic_loss": 1.686580741584301, "actor_loss": -86.5785121459961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20433735847473, "step": 16000}
{"episode_reward": 827.9169034591532, "episode": 17.0, "batch_reward": 0.6144652578830719, "critic_loss": 1.6205901272296905, "actor_loss": -86.83455921936036, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.218229055404663, "step": 17000}
{"episode_reward": 802.3365281994705, "episode": 18.0, "batch_reward": 0.6226672514677047, "critic_loss": 1.6061053755879402, "actor_loss": -87.07479026794434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.206098079681396, "step": 18000}
{"episode_reward": 777.1620239420746, "episode": 19.0, "batch_reward": 0.6328566122055054, "critic_loss": 1.4790962566137313, "actor_loss": -87.36351130676269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.21990942955017, "step": 19000}
{"episode_reward": 879.5845625872312, "episode": 20.0, "batch_reward": 0.6444614788293839, "critic_loss": 1.4004530934691428, "actor_loss": -88.00468325805664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.22222352027893, "step": 20000}
{"episode_reward": 901.2552938938913, "episode": 21.0, "batch_reward": 0.6599538566470147, "critic_loss": 1.3355233027935027, "actor_loss": -87.5686056213379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.03981685638428, "step": 21000}
{"episode_reward": 900.3325622848807, "episode": 22.0, "batch_reward": 0.6671140168309212, "critic_loss": 1.2974677445888518, "actor_loss": -88.2629546661377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.210925340652466, "step": 22000}
{"episode_reward": 854.4567418303837, "episode": 23.0, "batch_reward": 0.6786381980776787, "critic_loss": 1.2775545786619187, "actor_loss": -88.11070162963867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.2131986618042, "step": 23000}
{"episode_reward": 870.0401334177917, "episode": 24.0, "batch_reward": 0.6858177594542504, "critic_loss": 1.2187682774662971, "actor_loss": -88.41939521789551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.207124948501587, "step": 24000}
{"episode_reward": 891.2025371090194, "episode": 25.0, "batch_reward": 0.6957935587763786, "critic_loss": 1.1818432048559189, "actor_loss": -88.86020075988769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.206817626953125, "step": 25000}
{"episode_reward": 878.8445988178551, "episode": 26.0, "batch_reward": 0.703308268904686, "critic_loss": 1.157790972173214, "actor_loss": -88.86779792785644, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.21261239051819, "step": 26000}
{"episode_reward": 942.3704687763021, "episode": 27.0, "batch_reward": 0.711877236187458, "critic_loss": 1.0685569459795952, "actor_loss": -88.8452501525879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.2073233127594, "step": 27000}
{"episode_reward": 937.6826486770192, "episode": 28.0, "batch_reward": 0.7217865456938743, "critic_loss": 1.0474660958647728, "actor_loss": -89.47911515808106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20638918876648, "step": 28000}
{"episode_reward": 964.6553328854006, "episode": 29.0, "batch_reward": 0.7253660311698914, "critic_loss": 0.9947001287341117, "actor_loss": -89.32684956359863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.207296133041382, "step": 29000}
{"episode_reward": 898.4721273234501, "episode": 30.0, "batch_reward": 0.7351909494996071, "critic_loss": 0.9546423240303993, "actor_loss": -89.48461172485352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.211389303207397, "step": 30000}
{"episode_reward": 935.6043355868917, "episode": 31.0, "batch_reward": 0.7410458652377129, "critic_loss": 0.8991239367127418, "actor_loss": -89.70826583862305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.960153341293335, "step": 31000}
{"episode_reward": 924.1138770271292, "episode": 32.0, "batch_reward": 0.7461726579070092, "critic_loss": 0.871276011377573, "actor_loss": -90.01370335388184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.195781230926514, "step": 32000}
{"episode_reward": 916.6848690860279, "episode": 33.0, "batch_reward": 0.7530394027233124, "critic_loss": 0.8497061150074006, "actor_loss": -90.17885969543457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.203600883483887, "step": 33000}
{"episode_reward": 925.2238341441563, "episode": 34.0, "batch_reward": 0.7568428499698638, "critic_loss": 0.7984683286547661, "actor_loss": -90.34842774963379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.213027477264404, "step": 34000}
{"episode_reward": 935.2111370705022, "episode": 35.0, "batch_reward": 0.7610466659665108, "critic_loss": 0.8380362402796745, "actor_loss": -90.50720492553711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.208792209625244, "step": 35000}
{"episode_reward": 798.2146404216417, "episode": 36.0, "batch_reward": 0.7620277485251427, "critic_loss": 0.8298525661230087, "actor_loss": -90.81464070129394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.209108114242554, "step": 36000}
{"episode_reward": 867.82351750197, "episode": 37.0, "batch_reward": 0.7657255175113677, "critic_loss": 0.8023068184554577, "actor_loss": -90.48628538513184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.207868576049805, "step": 37000}
{"episode_reward": 918.4310355493683, "episode": 38.0, "batch_reward": 0.7600925268530846, "critic_loss": 0.8544227052032948, "actor_loss": -90.2852894744873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20839524269104, "step": 38000}
{"episode_reward": 361.2837797659464, "episode": 39.0, "batch_reward": 0.7486804597377777, "critic_loss": 0.8100522649288178, "actor_loss": -89.99556510925294, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.19995641708374, "step": 39000}
{"episode_reward": 17.205559136102863, "episode": 40.0, "batch_reward": 0.740757513821125, "critic_loss": 0.8133774975240231, "actor_loss": -89.9302146911621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.215410709381104, "step": 40000}
{"episode_reward": 958.6714080946905, "episode": 41.0, "batch_reward": 0.7455514029264451, "critic_loss": 0.8484750678539276, "actor_loss": -89.69120686340332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.319573163986206, "step": 41000}
{"episode_reward": 927.2437796581883, "episode": 42.0, "batch_reward": 0.7502106928229332, "critic_loss": 0.82553413438797, "actor_loss": -90.06848368835449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.201505184173584, "step": 42000}
{"episode_reward": 901.1677974326906, "episode": 43.0, "batch_reward": 0.7557401390075683, "critic_loss": 0.8224677717983723, "actor_loss": -90.38517010498047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.179625034332275, "step": 43000}
{"episode_reward": 977.3186145171913, "episode": 44.0, "batch_reward": 0.7593930951356888, "critic_loss": 0.8273597392141819, "actor_loss": -90.79890608215332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.186403036117554, "step": 44000}
{"episode_reward": 908.0945208707976, "episode": 45.0, "batch_reward": 0.762202252984047, "critic_loss": 0.7591261021494865, "actor_loss": -90.57031307983398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.210903644561768, "step": 45000}
{"episode_reward": 939.943752274155, "episode": 46.0, "batch_reward": 0.7652896354794503, "critic_loss": 0.7886382821798325, "actor_loss": -90.38795100402832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.21024990081787, "step": 46000}
{"episode_reward": 934.2242922068605, "episode": 47.0, "batch_reward": 0.7706813521385193, "critic_loss": 0.823155755162239, "actor_loss": -90.67464988708497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.509750604629517, "step": 47000}
{"episode_reward": 893.9827797511941, "episode": 48.0, "batch_reward": 0.7743789944052696, "critic_loss": 0.8469080637991429, "actor_loss": -90.7791082611084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.18018412590027, "step": 48000}
{"episode_reward": 929.5671310632667, "episode": 49.0, "batch_reward": 0.77551822412014, "critic_loss": 0.8606774740219116, "actor_loss": -91.13439175415039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.167988061904907, "step": 49000}
{"episode_reward": 880.750585609243, "episode": 50.0, "batch_reward": 0.7774165452122689, "critic_loss": 0.8782046782970429, "actor_loss": -91.10383052062988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.186330318450928, "step": 50000}
{"episode_reward": 883.2149634033952, "episode": 51.0, "batch_reward": 0.7801559068560601, "critic_loss": 0.8875581402182579, "actor_loss": -91.11363313293457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.01436233520508, "step": 51000}
{"episode_reward": 919.2175146230646, "episode": 52.0, "batch_reward": 0.7826716857552528, "critic_loss": 0.930889028608799, "actor_loss": -90.98103929138183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.207255125045776, "step": 52000}
{"episode_reward": 903.5554411159094, "episode": 53.0, "batch_reward": 0.7836246135830879, "critic_loss": 0.9114268853068351, "actor_loss": -91.30455842590332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.2043297290802, "step": 53000}
{"episode_reward": 948.3842400025585, "episode": 54.0, "batch_reward": 0.7792911348342896, "critic_loss": 0.9015151742100715, "actor_loss": -91.34701919555664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.200780391693115, "step": 54000}
{"episode_reward": 19.552476200978678, "episode": 55.0, "batch_reward": 0.7722156851291656, "critic_loss": 0.8513057070076465, "actor_loss": -90.84986660766602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20186471939087, "step": 55000}
{"episode_reward": 815.2110176641863, "episode": 56.0, "batch_reward": 0.774455817103386, "critic_loss": 0.8726561200618744, "actor_loss": -90.93465257263183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.206969738006592, "step": 56000}
{"episode_reward": 897.9470530766915, "episode": 57.0, "batch_reward": 0.7770630092024803, "critic_loss": 0.8591232559680939, "actor_loss": -90.99909796142578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.216490983963013, "step": 57000}
{"episode_reward": 924.2940524361085, "episode": 58.0, "batch_reward": 0.7734008933901787, "critic_loss": 0.860799350887537, "actor_loss": -90.88218717956543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.196412801742554, "step": 58000}
{"episode_reward": 591.4266132579879, "episode": 59.0, "batch_reward": 0.7774140625, "critic_loss": 0.8946175780892373, "actor_loss": -90.9966959991455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.210444688796997, "step": 59000}
{"episode_reward": 892.8691896272717, "episode": 60.0, "batch_reward": 0.7794118983745575, "critic_loss": 0.8881352251768112, "actor_loss": -91.12122798156739, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.206458568572998, "step": 60000}
{"episode_reward": 966.9321465241684, "episode": 61.0, "batch_reward": 0.782350824713707, "critic_loss": 0.9583576102852821, "actor_loss": -90.85211833190918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.07895302772522, "step": 61000}
{"episode_reward": 924.9754968341437, "episode": 62.0, "batch_reward": 0.7840614773631096, "critic_loss": 0.9928786701261997, "actor_loss": -91.26599334716796, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.21345567703247, "step": 62000}
{"episode_reward": 908.8919031717152, "episode": 63.0, "batch_reward": 0.7861092682480812, "critic_loss": 0.9975224998891353, "actor_loss": -90.96379556274414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.206876039505005, "step": 63000}
{"episode_reward": 903.0709676132476, "episode": 64.0, "batch_reward": 0.7874916707873344, "critic_loss": 1.0179776434600354, "actor_loss": -91.0980085144043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.19613814353943, "step": 64000}
{"episode_reward": 860.5430367527298, "episode": 65.0, "batch_reward": 0.7892952293157578, "critic_loss": 1.0103234086632729, "actor_loss": -91.27159696960449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20772933959961, "step": 65000}
{"episode_reward": 956.4874850445602, "episode": 66.0, "batch_reward": 0.7902162313461304, "critic_loss": 1.0086251686513423, "actor_loss": -91.05428355407714, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.21389365196228, "step": 66000}
{"episode_reward": 954.0323406116274, "episode": 67.0, "batch_reward": 0.791985165476799, "critic_loss": 1.0327006815075874, "actor_loss": -91.37300770568848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20529007911682, "step": 67000}
{"episode_reward": 922.6850285312739, "episode": 68.0, "batch_reward": 0.796634007692337, "critic_loss": 1.0320189168155194, "actor_loss": -91.71522526550292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.202374935150146, "step": 68000}
{"episode_reward": 897.8999902402285, "episode": 69.0, "batch_reward": 0.7978114470243454, "critic_loss": 1.0132550328969956, "actor_loss": -91.32858290100097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.217301607131958, "step": 69000}
{"episode_reward": 958.4063121297406, "episode": 70.0, "batch_reward": 0.8002546196579933, "critic_loss": 0.9983410359919072, "actor_loss": -91.36407713317871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.213072299957275, "step": 70000}
{"episode_reward": 953.4936775761252, "episode": 71.0, "batch_reward": 0.8018885761499405, "critic_loss": 0.9823759284317494, "actor_loss": -91.44999826049805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.09424710273743, "step": 71000}
{"episode_reward": 953.7846782339727, "episode": 72.0, "batch_reward": 0.80304273802042, "critic_loss": 0.970064103782177, "actor_loss": -91.7155339050293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.195235013961792, "step": 72000}
{"episode_reward": 898.1668230337752, "episode": 73.0, "batch_reward": 0.8042241413593292, "critic_loss": 0.9724739805757999, "actor_loss": -91.88881237792968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.201463222503662, "step": 73000}
{"episode_reward": 934.3890071857171, "episode": 74.0, "batch_reward": 0.8076817143559456, "critic_loss": 0.9699363833069802, "actor_loss": -92.00348204040527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20309567451477, "step": 74000}
{"episode_reward": 961.9105641751864, "episode": 75.0, "batch_reward": 0.8091859502196312, "critic_loss": 0.8934031027853488, "actor_loss": -92.02990478515625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.2093985080719, "step": 75000}
{"episode_reward": 948.8364889145059, "episode": 76.0, "batch_reward": 0.8090080019831657, "critic_loss": 0.9253440066874027, "actor_loss": -92.08247019958496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.200003147125244, "step": 76000}
{"episode_reward": 859.1065137389356, "episode": 77.0, "batch_reward": 0.8110664507746697, "critic_loss": 0.9468379880189896, "actor_loss": -92.24744166564942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20946764945984, "step": 77000}
{"episode_reward": 959.4115571678733, "episode": 78.0, "batch_reward": 0.8133821435570717, "critic_loss": 0.9091825133264064, "actor_loss": -92.2761290435791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.2028386592865, "step": 78000}
{"episode_reward": 964.6414888151146, "episode": 79.0, "batch_reward": 0.816186425626278, "critic_loss": 0.8700641819536686, "actor_loss": -92.46069403076172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.204230070114136, "step": 79000}
{"episode_reward": 949.6599045691705, "episode": 80.0, "batch_reward": 0.8173650375008583, "critic_loss": 0.9461964392066002, "actor_loss": -92.60620568847656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.212494611740112, "step": 80000}
{"episode_reward": 952.6447284809831, "episode": 81.0, "batch_reward": 0.8208801295161248, "critic_loss": 0.9361276308298111, "actor_loss": -92.60317971801757, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.00720572471619, "step": 81000}
{"episode_reward": 887.9312329173351, "episode": 82.0, "batch_reward": 0.8201783580780029, "critic_loss": 1.076822550266981, "actor_loss": -92.38081208801269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.204382181167603, "step": 82000}
{"episode_reward": 956.981622900759, "episode": 83.0, "batch_reward": 0.8222820461988449, "critic_loss": 1.3904860817492009, "actor_loss": -92.693215133667, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20327401161194, "step": 83000}
{"episode_reward": 939.9097384180182, "episode": 84.0, "batch_reward": 0.8218373729586601, "critic_loss": 1.9098415324687958, "actor_loss": -92.77035319519042, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.206237077713013, "step": 84000}
{"episode_reward": 943.0153234228275, "episode": 85.0, "batch_reward": 0.8232504712343216, "critic_loss": 2.2898472824990748, "actor_loss": -92.62361154174805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.203961849212646, "step": 85000}
{"episode_reward": 911.7968518836444, "episode": 86.0, "batch_reward": 0.8237419479489326, "critic_loss": 5.151258698582649, "actor_loss": -93.07175430297852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.214083433151245, "step": 86000}
{"episode_reward": 684.9604671233468, "episode": 87.0, "batch_reward": 0.8209553991556168, "critic_loss": 9.42831855392456, "actor_loss": -95.10753591918946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.214669466018677, "step": 87000}
{"episode_reward": 418.5218001830024, "episode": 88.0, "batch_reward": 0.8148112569451332, "critic_loss": 16.85148843717575, "actor_loss": -101.30837591552735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.203828811645508, "step": 88000}
{"episode_reward": 134.13539373174692, "episode": 89.0, "batch_reward": 0.808184557557106, "critic_loss": 31.830314568519594, "actor_loss": -112.73779011535645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.215083122253418, "step": 89000}
{"episode_reward": 123.04611111859306, "episode": 90.0, "batch_reward": 0.8000759244561195, "critic_loss": 51.71080177688599, "actor_loss": -125.03125787353515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.21271276473999, "step": 90000}
{"episode_reward": 62.418114247771086, "episode": 91.0, "batch_reward": 0.792117896437645, "critic_loss": 69.39821990966797, "actor_loss": -135.80126797485352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.04721713066101, "step": 91000}
{"episode_reward": 298.5112029030645, "episode": 92.0, "batch_reward": 0.7864710964560508, "critic_loss": 82.06862641906739, "actor_loss": -138.26796185302734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.19927144050598, "step": 92000}
{"episode_reward": 514.3286246749, "episode": 93.0, "batch_reward": 0.7859373568892479, "critic_loss": 92.67266144561768, "actor_loss": -145.22738079833985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.21032190322876, "step": 93000}
{"episode_reward": 466.2432397122728, "episode": 94.0, "batch_reward": 0.7790082353949547, "critic_loss": 93.82967978286743, "actor_loss": -141.10438536071777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.211937189102173, "step": 94000}
{"episode_reward": 172.65864056666354, "episode": 95.0, "batch_reward": 0.7726713194847107, "critic_loss": 90.82704992294312, "actor_loss": -137.286571975708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.210453510284424, "step": 95000}
{"episode_reward": 140.4810955322803, "episode": 96.0, "batch_reward": 0.7666916698217392, "critic_loss": 79.62658010864257, "actor_loss": -145.3445558319092, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.218939065933228, "step": 96000}
{"episode_reward": 253.66902198914485, "episode": 97.0, "batch_reward": 0.7591105980873107, "critic_loss": 75.50842474174499, "actor_loss": -152.21115965270997, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.21817946434021, "step": 97000}
{"episode_reward": 320.6649833269108, "episode": 98.0, "batch_reward": 0.7600265424251557, "critic_loss": 66.48185615921021, "actor_loss": -139.1059976196289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.210728645324707, "step": 98000}
{"episode_reward": 694.887014151742, "episode": 99.0, "batch_reward": 0.7582669741511345, "critic_loss": 57.57834632301331, "actor_loss": -147.49355459594727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.216899633407593, "step": 99000}
{"episode_reward": 641.3946605037277, "episode": 100.0, "batch_reward": 0.757032653093338, "critic_loss": 53.01351515007019, "actor_loss": -146.7230460357666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.22465944290161, "step": 100000}
{"episode_reward": 525.5202681843497, "episode": 101.0, "batch_reward": 0.7529451956152916, "critic_loss": 48.9140508480072, "actor_loss": -148.61143634033203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.1525821685791, "step": 101000}
{"episode_reward": 178.62139472066627, "episode": 102.0, "batch_reward": 0.7452596143484116, "critic_loss": 51.18192251968384, "actor_loss": -143.2038557739258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.21158528327942, "step": 102000}
{"episode_reward": 37.67385431940844, "episode": 103.0, "batch_reward": 0.7374980472326279, "critic_loss": 57.17892270851135, "actor_loss": -143.82039808654784, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.197224855422974, "step": 103000}
{"episode_reward": 108.47342126115352, "episode": 104.0, "batch_reward": 0.7331182615756988, "critic_loss": 96.15222545623779, "actor_loss": -155.27334336853028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.223860025405884, "step": 104000}
{"episode_reward": 73.99751021814428, "episode": 105.0, "batch_reward": 0.7273780331611633, "critic_loss": 158.82342082214356, "actor_loss": -165.82226844787598, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.234974145889282, "step": 105000}
{"episode_reward": 89.5778106681776, "episode": 106.0, "batch_reward": 0.7219157687425614, "critic_loss": 227.67000451660155, "actor_loss": -176.83871401977538, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.212990522384644, "step": 106000}
{"episode_reward": 108.80151028371913, "episode": 107.0, "batch_reward": 0.7152330684065819, "critic_loss": 273.6768638153076, "actor_loss": -196.94978617858888, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.195476293563843, "step": 107000}
{"episode_reward": 164.7441832159821, "episode": 108.0, "batch_reward": 0.7091550257205963, "critic_loss": 282.3944899902344, "actor_loss": -183.30885412597655, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.22053861618042, "step": 108000}
{"episode_reward": 162.14458046928317, "episode": 109.0, "batch_reward": 0.7047483678460121, "critic_loss": 240.29786833190917, "actor_loss": -202.835330078125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.224124670028687, "step": 109000}
{"episode_reward": 205.34319607735446, "episode": 110.0, "batch_reward": 0.7014911882281304, "critic_loss": 196.80844678497314, "actor_loss": -188.6196908416748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.21197819709778, "step": 110000}
{"episode_reward": 262.9558879611311, "episode": 111.0, "batch_reward": 0.6984864436984062, "critic_loss": 161.48380476379396, "actor_loss": -213.7092433319092, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.03272080421448, "step": 111000}
{"episode_reward": 488.4540642405565, "episode": 112.0, "batch_reward": 0.6981854808926582, "critic_loss": 138.20275470733642, "actor_loss": -195.07274072265625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.204339742660522, "step": 112000}
{"episode_reward": 676.523949297394, "episode": 113.0, "batch_reward": 0.6988606885075569, "critic_loss": 121.57212571716309, "actor_loss": -209.1768871459961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.203800201416016, "step": 113000}
{"episode_reward": 737.7335060133045, "episode": 114.0, "batch_reward": 0.6971764766573906, "critic_loss": 107.45658876800537, "actor_loss": -200.42305471801757, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.21071434020996, "step": 114000}
{"episode_reward": 727.2981252238474, "episode": 115.0, "batch_reward": 0.7009524612426757, "critic_loss": 91.36449407196045, "actor_loss": -199.53957598876954, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.207103967666626, "step": 115000}
{"episode_reward": 839.7396085015129, "episode": 116.0, "batch_reward": 0.7008111889362335, "critic_loss": 81.4894153881073, "actor_loss": -197.55571627807618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.210875988006592, "step": 116000}
{"episode_reward": 902.7144421878162, "episode": 117.0, "batch_reward": 0.7003853244781494, "critic_loss": 71.39631711387634, "actor_loss": -203.9756438446045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.21324610710144, "step": 117000}
{"episode_reward": 840.9445126087086, "episode": 118.0, "batch_reward": 0.7033355954885483, "critic_loss": 64.37484485244751, "actor_loss": -200.28577224731444, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20640516281128, "step": 118000}
{"episode_reward": 871.6579403963739, "episode": 119.0, "batch_reward": 0.7068545742034912, "critic_loss": 55.80254668045044, "actor_loss": -198.6266566925049, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.209295988082886, "step": 119000}
{"episode_reward": 909.8197736413697, "episode": 120.0, "batch_reward": 0.7067826120853424, "critic_loss": 48.195075250625614, "actor_loss": -195.5475659790039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.22986888885498, "step": 120000}
{"episode_reward": 947.9229025614042, "episode": 121.0, "batch_reward": 0.7091928154826165, "critic_loss": 42.24968683052063, "actor_loss": -191.2339780883789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.08133840560913, "step": 121000}
{"episode_reward": 907.9107046311432, "episode": 122.0, "batch_reward": 0.7070935662388802, "critic_loss": 36.03871771717071, "actor_loss": -183.2624299316406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.204286813735962, "step": 122000}
{"episode_reward": 819.2786879174711, "episode": 123.0, "batch_reward": 0.710411645770073, "critic_loss": 31.77523829269409, "actor_loss": -182.76484815979003, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.199658632278442, "step": 123000}
{"episode_reward": 950.0157953857629, "episode": 124.0, "batch_reward": 0.7096270810961723, "critic_loss": 30.311804392814636, "actor_loss": -170.49770338439941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.208394050598145, "step": 124000}
{"episode_reward": 842.1740627108452, "episode": 125.0, "batch_reward": 0.7112688959240914, "critic_loss": 27.44603137779236, "actor_loss": -177.2182799987793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.190624952316284, "step": 125000}
{"episode_reward": 804.3825406375618, "episode": 126.0, "batch_reward": 0.7126625563502311, "critic_loss": 28.442669726371765, "actor_loss": -169.7344183807373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.197330951690674, "step": 126000}
{"episode_reward": 508.83729253571715, "episode": 127.0, "batch_reward": 0.7124204621315002, "critic_loss": 25.440548141002655, "actor_loss": -167.56333892822266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.216344594955444, "step": 127000}
{"episode_reward": 964.9943515511874, "episode": 128.0, "batch_reward": 0.7132507247924804, "critic_loss": 21.836964854717255, "actor_loss": -166.43275926208497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.198875665664673, "step": 128000}
{"episode_reward": 924.260647095275, "episode": 129.0, "batch_reward": 0.7156196231842041, "critic_loss": 20.788683544635774, "actor_loss": -166.04447987365722, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.228316068649292, "step": 129000}
{"episode_reward": 406.35741180742457, "episode": 130.0, "batch_reward": 0.7136589867472649, "critic_loss": 23.341226354122163, "actor_loss": -161.8856912841797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.204983949661255, "step": 130000}
{"episode_reward": 727.6235150596318, "episode": 131.0, "batch_reward": 0.7112234896421432, "critic_loss": 22.178309163570404, "actor_loss": -167.51282415771485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.07777190208435, "step": 131000}
{"episode_reward": 312.430290806777, "episode": 132.0, "batch_reward": 0.7071831948757171, "critic_loss": 24.068911059379577, "actor_loss": -156.8870671081543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.219239711761475, "step": 132000}
{"episode_reward": 170.64072867300095, "episode": 133.0, "batch_reward": 0.7061142706274987, "critic_loss": 39.92670771789551, "actor_loss": -166.7914598236084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.217491626739502, "step": 133000}
{"episode_reward": 91.24221014234031, "episode": 134.0, "batch_reward": 0.6997152877449989, "critic_loss": 79.59026696014405, "actor_loss": -170.42745198059083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.210551261901855, "step": 134000}
{"episode_reward": 91.62351737197258, "episode": 135.0, "batch_reward": 0.6947830004692077, "critic_loss": 134.67318367767334, "actor_loss": -174.92077249145507, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.207707405090332, "step": 135000}
{"episode_reward": 103.43042297258893, "episode": 136.0, "batch_reward": 0.6896225864291191, "critic_loss": 196.43280597686768, "actor_loss": -185.78416204833985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.21826195716858, "step": 136000}
{"episode_reward": 96.22570732737618, "episode": 137.0, "batch_reward": 0.6860625770688057, "critic_loss": 219.61347026062012, "actor_loss": -198.1527984008789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.227806091308594, "step": 137000}
{"episode_reward": 156.81355079263858, "episode": 138.0, "batch_reward": 0.6830021140575409, "critic_loss": 193.00795496368409, "actor_loss": -199.08271994018554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.219430685043335, "step": 138000}
{"episode_reward": 58.40676270634661, "episode": 139.0, "batch_reward": 0.6764588841795921, "critic_loss": 159.03813623046875, "actor_loss": -204.56825062561035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.217952966690063, "step": 139000}
{"episode_reward": 27.15833610668994, "episode": 140.0, "batch_reward": 0.674817165672779, "critic_loss": 129.12627543640136, "actor_loss": -191.47914483642577, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.216357469558716, "step": 140000}
{"episode_reward": 848.3398409447229, "episode": 141.0, "batch_reward": 0.6775704374909401, "critic_loss": 104.57792046356201, "actor_loss": -201.4775754699707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.03620886802673, "step": 141000}
{"episode_reward": 789.3384376563375, "episode": 142.0, "batch_reward": 0.6771609299778938, "critic_loss": 88.7850394821167, "actor_loss": -200.57912754821777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20596408843994, "step": 142000}
{"episode_reward": 101.30846173218272, "episode": 143.0, "batch_reward": 0.6735323094725609, "critic_loss": 74.41762770462036, "actor_loss": -203.02394038391114, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.227203845977783, "step": 143000}
{"episode_reward": 722.9915954413223, "episode": 144.0, "batch_reward": 0.6742248699069023, "critic_loss": 64.04458587646485, "actor_loss": -190.22978746032715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.231566429138184, "step": 144000}
{"episode_reward": 788.0983423365196, "episode": 145.0, "batch_reward": 0.6765451599955559, "critic_loss": 55.8284715385437, "actor_loss": -186.10181698608397, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.209648609161377, "step": 145000}
{"episode_reward": 868.3823501448046, "episode": 146.0, "batch_reward": 0.6776313483119011, "critic_loss": 48.58279470252991, "actor_loss": -196.10397807312012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.195009231567383, "step": 146000}
{"episode_reward": 848.9404211016705, "episode": 147.0, "batch_reward": 0.6768255553245545, "critic_loss": 40.5507413930893, "actor_loss": -185.71696282958985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.196718454360962, "step": 147000}
{"episode_reward": 908.2003690631569, "episode": 148.0, "batch_reward": 0.6788385303616524, "critic_loss": 35.86113422870636, "actor_loss": -180.96110186767578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.220349073410034, "step": 148000}
{"episode_reward": 673.7666122349943, "episode": 149.0, "batch_reward": 0.6767147834300995, "critic_loss": 34.212184742927555, "actor_loss": -181.49957273864746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.229146003723145, "step": 149000}
{"episode_reward": 154.4123198343641, "episode": 150.0, "batch_reward": 0.6717736785411834, "critic_loss": 29.853633924484253, "actor_loss": -179.4668674926758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
