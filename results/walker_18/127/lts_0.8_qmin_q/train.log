{"episode_reward": 0.0, "episode": 1.0, "duration": 24.274235010147095, "step": 1000}
{"episode_reward": 28.002640152663393, "episode": 2.0, "duration": 1.949704885482788, "step": 2000}
{"episode_reward": 481.4321918933315, "episode": 3.0, "batch_reward": 0.24212513890374537, "critic_loss": 0.4549354062542672, "actor_loss": -83.0310654199424, "actor_target_entropy": -6.0, "alpha_value": 0.00244617320470393, "duration": 63.332467555999756, "step": 3000}
{"episode_reward": 35.056736365705056, "episode": 4.0, "batch_reward": 0.16859373705089092, "critic_loss": 0.4746558552533388, "actor_loss": -76.99221450805663, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.11656165122986, "step": 4000}
{"episode_reward": 65.6044480713085, "episode": 5.0, "batch_reward": 0.16774432773143053, "critic_loss": 0.6401445554196834, "actor_loss": -75.90588942718506, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.425214290618896, "step": 5000}
{"episode_reward": 312.97330942045977, "episode": 6.0, "batch_reward": 0.18039417999982835, "critic_loss": 1.5129205509722232, "actor_loss": -76.52039493560791, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.402111530303955, "step": 6000}
{"episode_reward": 85.63344428011993, "episode": 7.0, "batch_reward": 0.17811046504974365, "critic_loss": 0.9802234212756157, "actor_loss": -76.28904991912842, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.2458975315094, "step": 7000}
{"episode_reward": 321.60589756759197, "episode": 8.0, "batch_reward": 0.17993909331411123, "critic_loss": 0.8825156859457493, "actor_loss": -75.75601824188233, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.727219343185425, "step": 8000}
{"episode_reward": 38.24878743968405, "episode": 9.0, "batch_reward": 0.16267444379627705, "critic_loss": 0.8897287758886814, "actor_loss": -75.39790450286866, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 24.004091501235962, "step": 9000}
{"episode_reward": 24.304636380175953, "episode": 10.0, "batch_reward": 0.1557395033761859, "critic_loss": 0.8663917119204998, "actor_loss": -75.27532289123535, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.218079566955566, "step": 10000}
{"episode_reward": 161.10722897620067, "episode": 11.0, "batch_reward": 0.15957958218455315, "critic_loss": 0.9967299517691135, "actor_loss": -74.49998955535888, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 42.094194650650024, "step": 11000}
{"episode_reward": 321.07804527251227, "episode": 12.0, "batch_reward": 0.16411669781804084, "critic_loss": 0.8522636421918869, "actor_loss": -73.68824403381348, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.90310287475586, "step": 12000}
{"episode_reward": 18.11576090518248, "episode": 13.0, "batch_reward": 0.15352032367140056, "critic_loss": 0.7327126535773277, "actor_loss": -72.81851271820068, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.69955086708069, "step": 13000}
{"episode_reward": 168.49997619111585, "episode": 14.0, "batch_reward": 0.16691137717664242, "critic_loss": 0.9159969609677792, "actor_loss": -72.48137357330322, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.433393001556396, "step": 14000}
{"episode_reward": 409.20696885761026, "episode": 15.0, "batch_reward": 0.18653642115741967, "critic_loss": 0.9499615591466427, "actor_loss": -73.66839193725586, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.735922813415527, "step": 15000}
{"episode_reward": 395.125835072212, "episode": 16.0, "batch_reward": 0.1990133303105831, "critic_loss": 0.9883455376625061, "actor_loss": -73.34247816467285, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.409509420394897, "step": 16000}
{"episode_reward": 477.876428062841, "episode": 17.0, "batch_reward": 0.21732643423974515, "critic_loss": 1.122299188375473, "actor_loss": -72.89951663208008, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.881677627563477, "step": 17000}
{"episode_reward": 544.9290445291743, "episode": 18.0, "batch_reward": 0.23747754749655722, "critic_loss": 1.1031318178772926, "actor_loss": -73.74582063293457, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.108144521713257, "step": 18000}
{"episode_reward": 609.7147237921488, "episode": 19.0, "batch_reward": 0.2534354531019926, "critic_loss": 1.0623359657526017, "actor_loss": -74.38178596496581, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.102456092834473, "step": 19000}
{"episode_reward": 517.1305164010438, "episode": 20.0, "batch_reward": 0.2722864498198032, "critic_loss": 1.0279068110585212, "actor_loss": -75.80936406707764, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.760249614715576, "step": 20000}
{"episode_reward": 598.1089892102167, "episode": 21.0, "batch_reward": 0.2891776961684227, "critic_loss": 1.0747792834043504, "actor_loss": -73.61263896179199, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 43.267837047576904, "step": 21000}
{"episode_reward": 590.1120012283582, "episode": 22.0, "batch_reward": 0.3012541957199574, "critic_loss": 1.072675073802471, "actor_loss": -75.18981776428222, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.923444986343384, "step": 22000}
{"episode_reward": 585.4598499621513, "episode": 23.0, "batch_reward": 0.31751518182456495, "critic_loss": 1.1561904610395433, "actor_loss": -74.5719029159546, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.366170406341553, "step": 23000}
{"episode_reward": 643.2370212624597, "episode": 24.0, "batch_reward": 0.3291623480618, "critic_loss": 1.1877078465223312, "actor_loss": -75.62147961425781, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.247215509414673, "step": 24000}
{"episode_reward": 601.6515547112094, "episode": 25.0, "batch_reward": 0.3402261553406715, "critic_loss": 1.2768541523218155, "actor_loss": -76.40958076477051, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.51227641105652, "step": 25000}
{"episode_reward": 623.1539080090657, "episode": 26.0, "batch_reward": 0.3524625558257103, "critic_loss": 1.2906961026787758, "actor_loss": -75.3472716217041, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.607685804367065, "step": 26000}
{"episode_reward": 736.0451449428836, "episode": 27.0, "batch_reward": 0.3651125336289406, "critic_loss": 1.3437724927067756, "actor_loss": -76.13622818756103, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.808700799942017, "step": 27000}
{"episode_reward": 679.284225825767, "episode": 28.0, "batch_reward": 0.3791308097243309, "critic_loss": 1.3547993856072427, "actor_loss": -75.80833572387695, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.085427284240723, "step": 28000}
{"episode_reward": 760.6723752224461, "episode": 29.0, "batch_reward": 0.3902396090626717, "critic_loss": 1.3874216325879096, "actor_loss": -76.4813457107544, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.313365936279297, "step": 29000}
{"episode_reward": 673.8759986456475, "episode": 30.0, "batch_reward": 0.40332682567834854, "critic_loss": 1.429010616004467, "actor_loss": -75.35570333099365, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.668633699417114, "step": 30000}
{"episode_reward": 724.6121467906207, "episode": 31.0, "batch_reward": 0.4123698878288269, "critic_loss": 1.4735422866344452, "actor_loss": -77.24712204742431, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 43.839808225631714, "step": 31000}
{"episode_reward": 765.3082355221588, "episode": 32.0, "batch_reward": 0.4243130812942982, "critic_loss": 1.5374489534497262, "actor_loss": -78.07550283813477, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.65719437599182, "step": 32000}
{"episode_reward": 748.7021395779052, "episode": 33.0, "batch_reward": 0.42971605083346365, "critic_loss": 1.5960524414777755, "actor_loss": -78.13255005645752, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.253451347351074, "step": 33000}
{"episode_reward": 559.7587448155111, "episode": 34.0, "batch_reward": 0.43644639283418657, "critic_loss": 1.6164042653441428, "actor_loss": -78.2417001953125, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.76923942565918, "step": 34000}
{"episode_reward": 723.1198487895111, "episode": 35.0, "batch_reward": 0.4459444959461689, "critic_loss": 1.6640617161393165, "actor_loss": -78.34401760101318, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.56553363800049, "step": 35000}
{"episode_reward": 723.3364117109107, "episode": 36.0, "batch_reward": 0.45361639475822446, "critic_loss": 1.7155068161487579, "actor_loss": -79.21949272918701, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.185131311416626, "step": 36000}
{"episode_reward": 694.8674120952568, "episode": 37.0, "batch_reward": 0.46002662950754164, "critic_loss": 1.7688986476063728, "actor_loss": -77.95724166107178, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.753361225128174, "step": 37000}
{"episode_reward": 729.3888803233328, "episode": 38.0, "batch_reward": 0.4673095262348652, "critic_loss": 1.7990024120807648, "actor_loss": -77.52496794891357, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.224867582321167, "step": 38000}
{"episode_reward": 755.5678343475287, "episode": 39.0, "batch_reward": 0.47439503502845765, "critic_loss": 1.861626175045967, "actor_loss": -77.58687248229981, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.40040922164917, "step": 39000}
{"episode_reward": 771.1720135214401, "episode": 40.0, "batch_reward": 0.4845205326974392, "critic_loss": 1.8690800459384918, "actor_loss": -79.01661463928222, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.325653076171875, "step": 40000}
{"episode_reward": 835.0589820794993, "episode": 41.0, "batch_reward": 0.490255400121212, "critic_loss": 1.8656438632011414, "actor_loss": -78.75976862335204, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 43.18964672088623, "step": 41000}
{"episode_reward": 712.413431576636, "episode": 42.0, "batch_reward": 0.4945161631703377, "critic_loss": 1.9073986253738404, "actor_loss": -79.03611321258545, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.860187292099, "step": 42000}
{"episode_reward": 711.5599940642618, "episode": 43.0, "batch_reward": 0.5028377848565578, "critic_loss": 1.8548424820899962, "actor_loss": -79.36441915130615, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.346012592315674, "step": 43000}
{"episode_reward": 825.8803316172712, "episode": 44.0, "batch_reward": 0.5074808338880539, "critic_loss": 1.9089284844398497, "actor_loss": -81.94189051818847, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 24.193297386169434, "step": 44000}
{"episode_reward": 766.1426555595891, "episode": 45.0, "batch_reward": 0.5164980206787586, "critic_loss": 1.9396818212270737, "actor_loss": -80.40226667022705, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.28974676132202, "step": 45000}
{"episode_reward": 716.3373587611358, "episode": 46.0, "batch_reward": 0.5186550921201706, "critic_loss": 1.915075951695442, "actor_loss": -78.88902284240723, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.59834623336792, "step": 46000}
{"episode_reward": 814.873121400764, "episode": 47.0, "batch_reward": 0.5249743744134903, "critic_loss": 1.880281787097454, "actor_loss": -80.06209660339356, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.06135106086731, "step": 47000}
{"episode_reward": 739.9022638648566, "episode": 48.0, "batch_reward": 0.5303268567323685, "critic_loss": 1.8880813363194466, "actor_loss": -79.84659117126465, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 24.375612020492554, "step": 48000}
{"episode_reward": 763.1304952288245, "episode": 49.0, "batch_reward": 0.531040199816227, "critic_loss": 1.9204694372415543, "actor_loss": -81.5394214630127, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.52453327178955, "step": 49000}
{"episode_reward": 529.610842970991, "episode": 50.0, "batch_reward": 0.5352829291522503, "critic_loss": 1.8775574443936347, "actor_loss": -80.84605280303956, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.24263596534729, "step": 50000}
{"episode_reward": 770.0583950941065, "episode": 51.0, "batch_reward": 0.5390497096776963, "critic_loss": 1.882742192029953, "actor_loss": -80.69277361297607, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 43.832706451416016, "step": 51000}
{"episode_reward": 765.4927912251727, "episode": 52.0, "batch_reward": 0.5447763368785381, "critic_loss": 1.944911013484001, "actor_loss": -80.21923092651367, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.999606370925903, "step": 52000}
{"episode_reward": 764.0767070296746, "episode": 53.0, "batch_reward": 0.5486261502504349, "critic_loss": 1.8845232855081557, "actor_loss": -81.62666929626465, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.826908349990845, "step": 53000}
{"episode_reward": 813.9063949449958, "episode": 54.0, "batch_reward": 0.554279566526413, "critic_loss": 1.8861520920991897, "actor_loss": -82.33250861358643, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.197715282440186, "step": 54000}
{"episode_reward": 838.9954725960482, "episode": 55.0, "batch_reward": 0.5578062305748462, "critic_loss": 1.8982261488437653, "actor_loss": -82.09888089752198, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.611998081207275, "step": 55000}
{"episode_reward": 755.7163236584429, "episode": 56.0, "batch_reward": 0.5629720136523246, "critic_loss": 1.9087437816858293, "actor_loss": -82.10969132232665, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.020195960998535, "step": 56000}
{"episode_reward": 811.0725616217171, "episode": 57.0, "batch_reward": 0.5683927294313907, "critic_loss": 1.8961590285301209, "actor_loss": -82.29598533630372, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.744998455047607, "step": 57000}
{"episode_reward": 823.6140237637837, "episode": 58.0, "batch_reward": 0.5712573847174645, "critic_loss": 1.9589946610927582, "actor_loss": -82.59065090179443, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.31109929084778, "step": 58000}
{"episode_reward": 786.5347723634119, "episode": 59.0, "batch_reward": 0.5767886781394481, "critic_loss": 2.0044169187545777, "actor_loss": -82.58311466217042, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.603025674819946, "step": 59000}
{"episode_reward": 812.1067512377638, "episode": 60.0, "batch_reward": 0.5785395270287991, "critic_loss": 1.981936862707138, "actor_loss": -82.62318640136719, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.576451063156128, "step": 60000}
{"episode_reward": 800.7219527957484, "episode": 61.0, "batch_reward": 0.5820088576376438, "critic_loss": 1.9606366307735443, "actor_loss": -82.68334494018555, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 44.610522985458374, "step": 61000}
{"episode_reward": 733.9179350142092, "episode": 62.0, "batch_reward": 0.5865205793082714, "critic_loss": 1.9226763746142388, "actor_loss": -82.92772367858886, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.98085927963257, "step": 62000}
{"episode_reward": 871.0031966726232, "episode": 63.0, "batch_reward": 0.5910130180716514, "critic_loss": 1.9176762619018555, "actor_loss": -83.21942607879639, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.421811819076538, "step": 63000}
{"episode_reward": 843.9387771531216, "episode": 64.0, "batch_reward": 0.5954227232933045, "critic_loss": 1.8990438013672828, "actor_loss": -83.93477648925781, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.196213722229004, "step": 64000}
{"episode_reward": 798.3280316336311, "episode": 65.0, "batch_reward": 0.5979943967163562, "critic_loss": 1.9042846487760543, "actor_loss": -83.27592192840577, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 24.179234743118286, "step": 65000}
{"episode_reward": 791.4988302988231, "episode": 66.0, "batch_reward": 0.5997855014204979, "critic_loss": 1.9116432332396507, "actor_loss": -83.34157115936279, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.732149124145508, "step": 66000}
{"episode_reward": 838.2820683869746, "episode": 67.0, "batch_reward": 0.6035564202070236, "critic_loss": 1.9937367491722107, "actor_loss": -84.33751903533935, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.96620535850525, "step": 67000}
{"episode_reward": 657.0588452299272, "episode": 68.0, "batch_reward": 0.6046853587031364, "critic_loss": 2.0229566890001296, "actor_loss": -85.16951612854004, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.73346185684204, "step": 68000}
{"episode_reward": 775.257498427951, "episode": 69.0, "batch_reward": 0.6048113186657429, "critic_loss": 2.0179693061113357, "actor_loss": -83.34465742492675, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.270759344100952, "step": 69000}
{"episode_reward": 800.0768798803822, "episode": 70.0, "batch_reward": 0.6084827509522438, "critic_loss": 1.9848472573161124, "actor_loss": -83.78553074645995, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.819908380508423, "step": 70000}
{"episode_reward": 692.7470843591597, "episode": 71.0, "batch_reward": 0.6127372226715088, "critic_loss": 1.9545366295576097, "actor_loss": -83.44086489868164, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 43.038745164871216, "step": 71000}
{"episode_reward": 843.452316516461, "episode": 72.0, "batch_reward": 0.6135659803152085, "critic_loss": 1.9887902475595474, "actor_loss": -84.70231367492676, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.03733515739441, "step": 72000}
{"episode_reward": 770.6373552665873, "episode": 73.0, "batch_reward": 0.615672440469265, "critic_loss": 1.9536312892436982, "actor_loss": -84.92494917297363, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 24.34043788909912, "step": 73000}
{"episode_reward": 786.584911219227, "episode": 74.0, "batch_reward": 0.6180054221153259, "critic_loss": 1.9589789110422133, "actor_loss": -84.07408391571045, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.1267352104187, "step": 74000}
{"episode_reward": 794.5009892419162, "episode": 75.0, "batch_reward": 0.619504729449749, "critic_loss": 1.9175570582151413, "actor_loss": -84.20247289276124, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.898509740829468, "step": 75000}
{"episode_reward": 870.0103418190841, "episode": 76.0, "batch_reward": 0.6225385518670082, "critic_loss": 1.886180778801441, "actor_loss": -84.86523403930664, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.885456800460815, "step": 76000}
{"episode_reward": 823.6077930492879, "episode": 77.0, "batch_reward": 0.6260930255651475, "critic_loss": 1.88622172665596, "actor_loss": -84.55752395629882, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.511131048202515, "step": 77000}
{"episode_reward": 869.4756401657793, "episode": 78.0, "batch_reward": 0.6300313218832015, "critic_loss": 1.9375661331415177, "actor_loss": -85.13787429809571, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.986937522888184, "step": 78000}
{"episode_reward": 910.7812327410242, "episode": 79.0, "batch_reward": 0.6333371132612229, "critic_loss": 1.852542643427849, "actor_loss": -86.11977783203125, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.258496522903442, "step": 79000}
{"episode_reward": 767.7296938163763, "episode": 80.0, "batch_reward": 0.6354444185495377, "critic_loss": 1.8167429614663124, "actor_loss": -85.6544181060791, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.31408143043518, "step": 80000}
{"episode_reward": 889.6408117820879, "episode": 81.0, "batch_reward": 0.6393585953116417, "critic_loss": 1.8710690528154372, "actor_loss": -84.86381990814209, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.72892475128174, "step": 81000}
{"episode_reward": 809.3233784368911, "episode": 82.0, "batch_reward": 0.6405929390192032, "critic_loss": 1.8328965060710907, "actor_loss": -85.07026078033448, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 24.387176513671875, "step": 82000}
{"episode_reward": 876.8335612308226, "episode": 83.0, "batch_reward": 0.643660717189312, "critic_loss": 1.8348773725032805, "actor_loss": -85.74686721801758, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.723318576812744, "step": 83000}
{"episode_reward": 790.5264930139488, "episode": 84.0, "batch_reward": 0.6450294787287713, "critic_loss": 1.8413078751564025, "actor_loss": -86.28599359893799, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.335971117019653, "step": 84000}
{"episode_reward": 788.0466171595536, "episode": 85.0, "batch_reward": 0.6461204977035523, "critic_loss": 1.892962390422821, "actor_loss": -85.98760587310791, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.419599056243896, "step": 85000}
{"episode_reward": 852.0535581150151, "episode": 86.0, "batch_reward": 0.649189112842083, "critic_loss": 1.9468982329964637, "actor_loss": -85.96647911071777, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.24972891807556, "step": 86000}
{"episode_reward": 798.5343648859196, "episode": 87.0, "batch_reward": 0.652522240459919, "critic_loss": 1.9232420803904533, "actor_loss": -86.42439679718018, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.788837432861328, "step": 87000}
{"episode_reward": 896.6358046019062, "episode": 88.0, "batch_reward": 0.6543693494200706, "critic_loss": 1.8849996779561042, "actor_loss": -85.77900346374511, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.648167848587036, "step": 88000}
{"episode_reward": 825.9388967126881, "episode": 89.0, "batch_reward": 0.656238552570343, "critic_loss": 1.9193313917517663, "actor_loss": -86.29010346984863, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.27134418487549, "step": 89000}
{"episode_reward": 810.3723349153677, "episode": 90.0, "batch_reward": 0.6569740953445434, "critic_loss": 1.8734371013641358, "actor_loss": -86.07237076568603, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.701032638549805, "step": 90000}
{"episode_reward": 832.4719914022411, "episode": 91.0, "batch_reward": 0.6592365416288376, "critic_loss": 1.9121258710622788, "actor_loss": -86.33938093566894, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 45.87152147293091, "step": 91000}
{"episode_reward": 815.2425324661116, "episode": 92.0, "batch_reward": 0.6605676934123039, "critic_loss": 1.9425104018449784, "actor_loss": -87.18610871887208, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.38477873802185, "step": 92000}
{"episode_reward": 750.5715869982675, "episode": 93.0, "batch_reward": 0.6601830453276635, "critic_loss": 1.985541655778885, "actor_loss": -86.18029682922364, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.410048961639404, "step": 93000}
{"episode_reward": 914.9753886443422, "episode": 94.0, "batch_reward": 0.6651363095641136, "critic_loss": 1.9037218524217605, "actor_loss": -86.97825059509277, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.636834621429443, "step": 94000}
{"episode_reward": 833.7119559809696, "episode": 95.0, "batch_reward": 0.6661984412074089, "critic_loss": 1.8661461092829705, "actor_loss": -87.55597399902344, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.858301162719727, "step": 95000}
{"episode_reward": 850.382005509228, "episode": 96.0, "batch_reward": 0.669532910823822, "critic_loss": 1.8876351263523101, "actor_loss": -87.59725749206542, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.240389108657837, "step": 96000}
{"episode_reward": 877.2853951855573, "episode": 97.0, "batch_reward": 0.6696849312186242, "critic_loss": 1.8768489060401916, "actor_loss": -87.18827600097656, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.539052724838257, "step": 97000}
{"episode_reward": 889.4814206936533, "episode": 98.0, "batch_reward": 0.6731691455245018, "critic_loss": 1.8828988104462623, "actor_loss": -87.843716506958, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.40698266029358, "step": 98000}
{"episode_reward": 890.7206795166858, "episode": 99.0, "batch_reward": 0.6751843093633652, "critic_loss": 1.8583315049409865, "actor_loss": -87.12096334838867, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.807381629943848, "step": 99000}
{"episode_reward": 917.8412227755408, "episode": 100.0, "batch_reward": 0.6788482512831688, "critic_loss": 1.8604169496297835, "actor_loss": -87.79514871215821, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.576828956604004, "step": 100000}
{"episode_reward": 870.8103207675422, "episode": 101.0, "batch_reward": 0.6793645446896553, "critic_loss": 1.9452226067781448, "actor_loss": -86.98219593811035, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.442599058151245, "step": 101000}
{"episode_reward": 827.8378625336586, "episode": 102.0, "batch_reward": 0.6819837456941604, "critic_loss": 1.889298127770424, "actor_loss": -87.81310305786133, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.595057249069214, "step": 102000}
{"episode_reward": 904.6153061982126, "episode": 103.0, "batch_reward": 0.6813324022293091, "critic_loss": 1.898017062008381, "actor_loss": -87.11355531311035, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.50436496734619, "step": 103000}
{"episode_reward": 840.7003256434704, "episode": 104.0, "batch_reward": 0.6854292187094688, "critic_loss": 1.872916099846363, "actor_loss": -87.26398146057129, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.832406044006348, "step": 104000}
{"episode_reward": 867.0219850288869, "episode": 105.0, "batch_reward": 0.687491887331009, "critic_loss": 1.8632317196130752, "actor_loss": -87.67246807861328, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.99513864517212, "step": 105000}
{"episode_reward": 920.962151916599, "episode": 106.0, "batch_reward": 0.6881254122257233, "critic_loss": 1.8615131618380547, "actor_loss": -87.70365605163575, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.719377756118774, "step": 106000}
{"episode_reward": 818.1913209503388, "episode": 107.0, "batch_reward": 0.6895669687390328, "critic_loss": 1.8650816683769227, "actor_loss": -87.30044146728515, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 24.45447540283203, "step": 107000}
{"episode_reward": 889.718821487677, "episode": 108.0, "batch_reward": 0.6907919633984566, "critic_loss": 1.8467035375833512, "actor_loss": -88.25106211853027, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.029234170913696, "step": 108000}
{"episode_reward": 867.4458834683533, "episode": 109.0, "batch_reward": 0.6946546715497971, "critic_loss": 1.8104166393876076, "actor_loss": -88.01872993469239, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.600769519805908, "step": 109000}
{"episode_reward": 866.8645947996457, "episode": 110.0, "batch_reward": 0.6944075282216072, "critic_loss": 1.84642674857378, "actor_loss": -88.83156808471679, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.20384979248047, "step": 110000}
{"episode_reward": 810.8396663413697, "episode": 111.0, "batch_reward": 0.6950454272627831, "critic_loss": 1.8755462079048157, "actor_loss": -88.11081999206543, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 46.3578999042511, "step": 111000}
{"episode_reward": 892.530980128192, "episode": 112.0, "batch_reward": 0.6959856266379356, "critic_loss": 1.8820216211080552, "actor_loss": -88.28140153503418, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.040408849716187, "step": 112000}
{"episode_reward": 859.2901607346033, "episode": 113.0, "batch_reward": 0.6991850609183311, "critic_loss": 1.8052523644566536, "actor_loss": -88.27814776611328, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.789883375167847, "step": 113000}
{"episode_reward": 881.7710823156859, "episode": 114.0, "batch_reward": 0.7023784225583076, "critic_loss": 1.8237166106104852, "actor_loss": -88.71423042297363, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.67790651321411, "step": 114000}
{"episode_reward": 867.9109442461599, "episode": 115.0, "batch_reward": 0.7037484837770462, "critic_loss": 1.759244846701622, "actor_loss": -88.65503089904786, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.98711323738098, "step": 115000}
{"episode_reward": 863.0404440899216, "episode": 116.0, "batch_reward": 0.705090747654438, "critic_loss": 1.745290540933609, "actor_loss": -88.77916067504883, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.222407817840576, "step": 116000}
{"episode_reward": 907.6098071495177, "episode": 117.0, "batch_reward": 0.7066799576878547, "critic_loss": 1.7032125052809715, "actor_loss": -88.25973760986328, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.58833932876587, "step": 117000}
{"episode_reward": 840.2390108135303, "episode": 118.0, "batch_reward": 0.7062314316034317, "critic_loss": 1.7107331625223159, "actor_loss": -88.53837835693359, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.691964864730835, "step": 118000}
{"episode_reward": 864.1614991521425, "episode": 119.0, "batch_reward": 0.7090803362727165, "critic_loss": 1.761664267241955, "actor_loss": -88.88666305541992, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.060290098190308, "step": 119000}
{"episode_reward": 869.7240616567708, "episode": 120.0, "batch_reward": 0.7092705080509186, "critic_loss": 1.706250176012516, "actor_loss": -88.15017416381836, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.184252500534058, "step": 120000}
{"episode_reward": 915.8978076327678, "episode": 121.0, "batch_reward": 0.7120533912777901, "critic_loss": 1.6823282909393311, "actor_loss": -88.8108377532959, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.32459473609924, "step": 121000}
{"episode_reward": 865.0143504791236, "episode": 122.0, "batch_reward": 0.7120549932122231, "critic_loss": 1.6757847584486008, "actor_loss": -89.15019900512695, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.24782967567444, "step": 122000}
{"episode_reward": 703.5334132215244, "episode": 123.0, "batch_reward": 0.7126386803984642, "critic_loss": 1.721885447204113, "actor_loss": -89.36920222473144, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 24.653359413146973, "step": 123000}
{"episode_reward": 881.1759670169379, "episode": 124.0, "batch_reward": 0.7133203179240227, "critic_loss": 1.7779208064079284, "actor_loss": -89.1476880493164, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.789766311645508, "step": 124000}
{"episode_reward": 877.6885211093118, "episode": 125.0, "batch_reward": 0.7153365744948387, "critic_loss": 1.7375659024119376, "actor_loss": -89.01134832763672, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.254180669784546, "step": 125000}
{"episode_reward": 919.0687655492624, "episode": 126.0, "batch_reward": 0.7169332066178322, "critic_loss": 1.7499682002663612, "actor_loss": -89.4508705444336, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.15082550048828, "step": 126000}
{"episode_reward": 878.0364941270719, "episode": 127.0, "batch_reward": 0.7170915491580964, "critic_loss": 1.7380444828867911, "actor_loss": -89.2195074005127, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.582085132598877, "step": 127000}
{"episode_reward": 914.501816364809, "episode": 128.0, "batch_reward": 0.7194634065628052, "critic_loss": 1.668755516767502, "actor_loss": -88.79870669555665, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.79716992378235, "step": 128000}
{"episode_reward": 849.1986368680277, "episode": 129.0, "batch_reward": 0.7208109720945358, "critic_loss": 1.6967713369131088, "actor_loss": -89.28218794250488, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.04817485809326, "step": 129000}
{"episode_reward": 891.923527408981, "episode": 130.0, "batch_reward": 0.7212091344594955, "critic_loss": 1.6838508676290511, "actor_loss": -89.59405142211914, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.64533042907715, "step": 130000}
{"episode_reward": 853.8254365955893, "episode": 131.0, "batch_reward": 0.7236217831373215, "critic_loss": 1.6435558936595918, "actor_loss": -88.62183622741699, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 42.36952590942383, "step": 131000}
{"episode_reward": 925.8813547601069, "episode": 132.0, "batch_reward": 0.7246784075498581, "critic_loss": 1.6884580511450769, "actor_loss": -89.90985987854003, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.845067501068115, "step": 132000}
{"episode_reward": 839.1299271757864, "episode": 133.0, "batch_reward": 0.7265360403060913, "critic_loss": 1.6918365479111672, "actor_loss": -89.1323616027832, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.72579789161682, "step": 133000}
{"episode_reward": 870.9043230164419, "episode": 134.0, "batch_reward": 0.7260531622767449, "critic_loss": 1.6044976796507835, "actor_loss": -89.50197573852539, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.985745668411255, "step": 134000}
{"episode_reward": 931.9300063093094, "episode": 135.0, "batch_reward": 0.7266626917123794, "critic_loss": 1.6318647139072417, "actor_loss": -89.84818318176269, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.493526935577393, "step": 135000}
{"episode_reward": 874.4584832207393, "episode": 136.0, "batch_reward": 0.728783501625061, "critic_loss": 1.6709126854538918, "actor_loss": -89.49948458862305, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.300562143325806, "step": 136000}
{"episode_reward": 889.1777626641469, "episode": 137.0, "batch_reward": 0.7303708584904671, "critic_loss": 1.660466550886631, "actor_loss": -89.9368881225586, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.665826082229614, "step": 137000}
{"episode_reward": 850.5858308303618, "episode": 138.0, "batch_reward": 0.7301317230463028, "critic_loss": 1.62034991979599, "actor_loss": -90.37819906616211, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.338199138641357, "step": 138000}
{"episode_reward": 844.4152444509817, "episode": 139.0, "batch_reward": 0.7308023106455803, "critic_loss": 1.639811224937439, "actor_loss": -89.28469284057617, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.574071168899536, "step": 139000}
{"episode_reward": 835.6976892572641, "episode": 140.0, "batch_reward": 0.7311599736809731, "critic_loss": 1.643130806684494, "actor_loss": -90.26086662292481, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.631645441055298, "step": 140000}
{"episode_reward": 866.5986355159285, "episode": 141.0, "batch_reward": 0.7344006466865539, "critic_loss": 1.6244506315588951, "actor_loss": -89.90206336975098, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.89575695991516, "step": 141000}
{"episode_reward": 843.6126930114674, "episode": 142.0, "batch_reward": 0.7342367240190506, "critic_loss": 1.5976224611997605, "actor_loss": -89.8377525024414, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.63312840461731, "step": 142000}
{"episode_reward": 821.2469341767513, "episode": 143.0, "batch_reward": 0.7350604934692383, "critic_loss": 1.630146938443184, "actor_loss": -89.94998130798339, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.818636655807495, "step": 143000}
{"episode_reward": 880.3866926687177, "episode": 144.0, "batch_reward": 0.7356428263187409, "critic_loss": 1.6415983027219772, "actor_loss": -90.27258665466309, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.732072114944458, "step": 144000}
{"episode_reward": 920.7856151133299, "episode": 145.0, "batch_reward": 0.7372010813951493, "critic_loss": 1.639369655072689, "actor_loss": -90.25885493469238, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.373226642608643, "step": 145000}
{"episode_reward": 836.9098783612596, "episode": 146.0, "batch_reward": 0.7367462592720986, "critic_loss": 1.624505099773407, "actor_loss": -89.59001541137695, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.82297658920288, "step": 146000}
{"episode_reward": 885.915610584327, "episode": 147.0, "batch_reward": 0.737129812002182, "critic_loss": 1.634761862397194, "actor_loss": -90.06443013000488, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.142021656036377, "step": 147000}
{"episode_reward": 901.9524916537365, "episode": 148.0, "batch_reward": 0.7407078186273575, "critic_loss": 1.6303326466679573, "actor_loss": -89.98028157043457, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.795856714248657, "step": 148000}
{"episode_reward": 890.7547279019125, "episode": 149.0, "batch_reward": 0.7409430720806122, "critic_loss": 1.630257337629795, "actor_loss": -90.33189376831055, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.695800065994263, "step": 149000}
{"episode_reward": 872.4507647131819, "episode": 150.0, "batch_reward": 0.7408387522697448, "critic_loss": 1.610713330924511, "actor_loss": -90.55234980773926, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "step": 150000}
