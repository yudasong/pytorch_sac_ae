{"episode": 1.0, "duration": 24.347550868988037, "episode_reward": 28.002640152663393, "step": 1000}
{"episode": 2.0, "duration": 2.032916307449341, "episode_reward": 481.4321918933315, "step": 2000}
{"episode": 3.0, "batch_reward": 0.24058257786183804, "actor_loss": -84.49253178444229, "actor_target_entropy": -6.0, "alpha_value": 0.00244617320470393, "duration": 54.663116693496704, "episode_reward": 25.717144543117495, "step": 3000}
{"episode": 4.0, "batch_reward": 0.17392540960758923, "actor_loss": -79.79573498535156, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.79517364501953, "episode_reward": 136.28729857324458, "step": 4000}
{"episode": 5.0, "batch_reward": 0.18189312745630742, "actor_loss": -80.07469293212891, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.678724765777588, "episode_reward": 295.8269876997876, "step": 5000}
{"episode": 6.0, "batch_reward": 0.20512975272536277, "actor_loss": -80.69900334167481, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.210914134979248, "episode_reward": 266.28629186119525, "step": 6000}
{"episode": 7.0, "batch_reward": 0.22044501127302646, "actor_loss": -81.02688949584962, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.937775135040283, "episode_reward": 446.2555719070384, "step": 7000}
{"episode": 8.0, "batch_reward": 0.2387548065930605, "actor_loss": -81.50628833007812, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.57950520515442, "episode_reward": 302.1424218875491, "step": 8000}
{"episode": 9.0, "batch_reward": 0.2534850634932518, "actor_loss": -81.95759680175782, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.530285120010376, "episode_reward": 432.4437317185599, "step": 9000}
{"episode": 10.0, "batch_reward": 0.2629661203920841, "actor_loss": -78.49544233703614, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 4080.930637359619, "episode_reward": 188.76253440135588, "step": 10000}
{"episode": 11.0, "batch_reward": 0.2491221165806055, "actor_loss": -77.95083403015137, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 37.51074242591858, "episode_reward": 23.198736196534824, "step": 11000}
{"episode": 12.0, "batch_reward": 0.22977580624818802, "actor_loss": -74.40293339538574, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 437.9169728755951, "episode_reward": 18.54489438855004, "step": 12000}
{"episode": 13.0, "batch_reward": 0.22588245049118996, "actor_loss": -73.84904119873048, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.982986450195312, "episode_reward": 395.7004588583546, "step": 13000}
{"episode": 14.0, "batch_reward": 0.23645189607143402, "actor_loss": -72.68802813720703, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 448.95285630226135, "episode_reward": 301.7572019351481, "step": 14000}
{"episode": 15.0, "batch_reward": 0.23889052079617978, "actor_loss": -73.17855477905273, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.088058471679688, "episode_reward": 268.4663804529431, "step": 15000}
{"episode": 16.0, "batch_reward": 0.23374925297498703, "actor_loss": -72.50333416748047, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 444.7364413738251, "episode_reward": 17.05696084291984, "step": 16000}
{"episode": 17.0, "batch_reward": 0.22623460686206817, "actor_loss": -71.91588929748535, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.59713840484619, "episode_reward": 311.46807242146787, "step": 17000}
{"episode": 18.0, "batch_reward": 0.236926988735795, "actor_loss": -71.62793547058105, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 434.54185009002686, "episode_reward": 456.5490252046438, "step": 18000}
{"episode": 19.0, "batch_reward": 0.23853385862708093, "actor_loss": -71.4206065826416, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.184030771255493, "episode_reward": 18.074639004134287, "step": 19000}
{"episode": 20.0, "batch_reward": 0.2394352868795395, "actor_loss": -70.80897650146484, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 440.21688628196716, "episode_reward": 518.1416705335789, "step": 20000}
{"episode": 21.0, "batch_reward": 0.24768022187054156, "actor_loss": -71.09141268920898, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 45.27263021469116, "episode_reward": 309.0132145999582, "step": 21000}
{"episode": 22.0, "batch_reward": 0.24436812920868398, "actor_loss": -70.0767294921875, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 438.52690267562866, "episode_reward": 15.651562756689566, "step": 22000}
{"episode": 23.0, "batch_reward": 0.24481393361091613, "actor_loss": -70.05114889526367, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.9054274559021, "episode_reward": 544.5446487617265, "step": 23000}
{"episode": 24.0, "batch_reward": 0.25917649737000464, "actor_loss": -69.90559413146973, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 454.53814458847046, "episode_reward": 523.6414324434886, "step": 24000}
{"episode": 25.0, "batch_reward": 0.2598594086021185, "actor_loss": -69.7925262298584, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.31783413887024, "episode_reward": 22.770228712587226, "step": 25000}
{"episode": 26.0, "batch_reward": 0.259852245002985, "actor_loss": -69.65673336791993, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 438.9050350189209, "episode_reward": 547.3168415305414, "step": 26000}
{"episode": 27.0, "batch_reward": 0.26224424031376836, "actor_loss": -69.9053269958496, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.404752254486084, "episode_reward": 121.93433541132141, "step": 27000}
{"episode": 28.0, "batch_reward": 0.263359415858984, "actor_loss": -70.66031576538086, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 445.96152997016907, "episode_reward": 500.0675402028491, "step": 28000}
{"episode": 29.0, "batch_reward": 0.2731644489020109, "actor_loss": -71.14372932434082, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.129923343658447, "episode_reward": 523.947961459627, "step": 29000}
{"episode": 30.0, "batch_reward": 0.28008377489447595, "actor_loss": -71.10594779968261, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 440.15534377098083, "episode_reward": 451.2519541791014, "step": 30000}
{"episode": 31.0, "batch_reward": 0.2842456565797329, "actor_loss": -71.40273431396484, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 44.05668663978577, "episode_reward": 421.03048692476744, "step": 31000}
{"episode": 32.0, "batch_reward": 0.2896850313842297, "actor_loss": -71.50251823425293, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 439.67048478126526, "episode_reward": 533.713414113844, "step": 32000}
{"episode": 33.0, "batch_reward": 0.297410773396492, "actor_loss": -71.94773797607422, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.00038456916809, "episode_reward": 535.2657655468792, "step": 33000}
{"episode": 34.0, "batch_reward": 0.3043388448655605, "actor_loss": -72.52297082519532, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 448.56244373321533, "episode_reward": 405.2395852750657, "step": 34000}
{"episode": 35.0, "batch_reward": 0.30338131467998025, "actor_loss": -72.53194261169433, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.52182626724243, "episode_reward": 332.54516514615364, "step": 35000}
{"episode": 36.0, "batch_reward": 0.30936565141379835, "actor_loss": -72.00393605041504, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 439.4872841835022, "episode_reward": 561.486859191864, "step": 36000}
{"episode": 37.0, "batch_reward": 0.3158203081190586, "actor_loss": -72.14359765625, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.703121662139893, "episode_reward": 517.3347828293421, "step": 37000}
{"episode": 38.0, "batch_reward": 0.3148216899186373, "actor_loss": -72.43827803039551, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 448.4775393009186, "episode_reward": 16.602819142880783, "step": 38000}
{"episode": 39.0, "batch_reward": 0.31058634792268275, "actor_loss": -72.04185043334961, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.162343978881836, "episode_reward": 281.6667939813256, "step": 39000}
{"episode": 40.0, "batch_reward": 0.3124464753270149, "actor_loss": -72.01904537963867, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 440.66239500045776, "episode_reward": 576.2406894966639, "step": 40000}
{"episode": 41.0, "batch_reward": 0.3202138082832098, "actor_loss": -72.39445031738282, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 42.713271617889404, "episode_reward": 598.1530594056214, "step": 41000}
{"episode": 42.0, "batch_reward": 0.32547468197345736, "actor_loss": -72.39391995239258, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 438.4862587451935, "episode_reward": 619.5472535746434, "step": 42000}
{"episode": 43.0, "batch_reward": 0.3328509331047535, "actor_loss": -72.75396884155273, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.57099676132202, "episode_reward": 691.0908542293145, "step": 43000}
{"episode": 44.0, "batch_reward": 0.3426596585512161, "actor_loss": -71.7491159210205, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 445.1415717601776, "episode_reward": 654.7612790670182, "step": 44000}
{"episode": 45.0, "batch_reward": 0.35043205615878104, "actor_loss": -71.95377778625489, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.692819595336914, "episode_reward": 652.926657906164, "step": 45000}
{"episode": 46.0, "batch_reward": 0.3577890160381794, "actor_loss": -73.06568516540527, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 434.8121235370636, "episode_reward": 649.6034201899542, "step": 46000}
{"episode": 47.0, "batch_reward": 0.354461777806282, "actor_loss": -72.82401498413086, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 15.964759588241577, "episode_reward": 15.270004611993784, "step": 47000}
{"episode": 48.0, "batch_reward": 0.35340655490756034, "actor_loss": -72.40868112182618, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 447.29132556915283, "episode_reward": 519.966615997465, "step": 48000}
{"episode": 49.0, "batch_reward": 0.35849832302331924, "actor_loss": -72.7626414642334, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.908243417739868, "episode_reward": 610.3825605400446, "step": 49000}
{"episode": 50.0, "batch_reward": 0.3637883564531803, "actor_loss": -72.8908196105957, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 440.4600143432617, "episode_reward": 581.1998763377549, "step": 50000}
{"episode": 51.0, "batch_reward": 0.36312194490432737, "actor_loss": -72.6951862335205, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 37.55297517776489, "episode_reward": 17.15298887851816, "step": 51000}
{"episode": 52.0, "batch_reward": 0.36026255002617835, "actor_loss": -72.07449694824219, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 440.6061725616455, "episode_reward": 621.7753650575393, "step": 52000}
{"episode": 53.0, "batch_reward": 0.36614509293437003, "actor_loss": -72.35884405517578, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.941893339157104, "episode_reward": 638.7927848616068, "step": 53000}
{"episode": 54.0, "batch_reward": 0.37098668384552, "actor_loss": -73.31801406860352, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 436.72304105758667, "episode_reward": 622.6619949775925, "step": 54000}
{"episode": 55.0, "batch_reward": 0.3698464508354664, "actor_loss": -73.08860125732421, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.855032682418823, "episode_reward": 14.964741963552205, "step": 55000}
{"episode": 56.0, "batch_reward": 0.36776957684755324, "actor_loss": -72.59758682250977, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 422.56126260757446, "episode_reward": 655.2258445088931, "step": 56000}
{"episode": 57.0, "batch_reward": 0.374735789835453, "actor_loss": -72.97574163818359, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.82648992538452, "episode_reward": 576.6240497864774, "step": 57000}
{"episode": 58.0, "batch_reward": 0.37683225309848783, "actor_loss": -72.90611293029785, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 425.60166931152344, "episode_reward": 614.7056521959021, "step": 58000}
{"episode": 59.0, "batch_reward": 0.3816213966906071, "actor_loss": -73.06735350036621, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.47538423538208, "episode_reward": 644.2990212688862, "step": 59000}
{"episode": 60.0, "batch_reward": 0.38743779972195624, "actor_loss": -72.75422454833985, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 427.12605261802673, "episode_reward": 690.1322931502735, "step": 60000}
{"episode": 61.0, "batch_reward": 0.39088447007536886, "actor_loss": -73.07594680786133, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 39.15343260765076, "episode_reward": 602.9951858235958, "step": 61000}
{"episode": 62.0, "batch_reward": 0.393654664337635, "actor_loss": -72.7156810760498, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 429.37720704078674, "episode_reward": 656.7310749916345, "step": 62000}
{"episode": 63.0, "batch_reward": 0.3975301064550877, "actor_loss": -72.91338348388672, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.472005128860474, "episode_reward": 651.2866932146306, "step": 63000}
{"episode": 64.0, "batch_reward": 0.40330810061097144, "actor_loss": -73.55127265930176, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 428.50342869758606, "episode_reward": 620.3691631759538, "step": 64000}
{"episode": 65.0, "batch_reward": 0.40170649594068525, "actor_loss": -73.27459989929199, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.875782012939453, "episode_reward": 17.952471775772032, "step": 65000}
{"episode": 66.0, "batch_reward": 0.40200856897234916, "actor_loss": -73.29733949279785, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 425.78357768058777, "episode_reward": 711.2800244745146, "step": 66000}
{"episode": 67.0, "batch_reward": 0.40633750343322755, "actor_loss": -73.54746325683594, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 15.79008674621582, "episode_reward": 686.1380497512761, "step": 67000}
{"episode": 68.0, "batch_reward": 0.40723571500182154, "actor_loss": -73.67163070678711, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 427.67579650878906, "episode_reward": 453.08536595697984, "step": 68000}
{"episode": 69.0, "batch_reward": 0.4110646738409996, "actor_loss": -73.86231085205078, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.908713340759277, "episode_reward": 689.8160020152496, "step": 69000}
{"episode": 70.0, "batch_reward": 0.4160134379863739, "actor_loss": -74.60440238952637, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 420.9315187931061, "episode_reward": 750.7205582053292, "step": 70000}
{"episode": 71.0, "batch_reward": 0.41786757692694665, "actor_loss": -74.74683627319335, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 40.45466613769531, "episode_reward": 704.8836291410157, "step": 71000}
{"episode": 72.0, "batch_reward": 0.42328922960162163, "actor_loss": -75.47216264343261, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 432.9513409137726, "episode_reward": 657.4789850458307, "step": 72000}
{"episode": 73.0, "batch_reward": 0.4247857608795166, "actor_loss": -75.60193821716308, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.954895973205566, "episode_reward": 519.2411209178946, "step": 73000}
{"episode": 74.0, "batch_reward": 0.42695370098948476, "actor_loss": -75.05143957519532, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 428.9728422164917, "episode_reward": 664.2181347480603, "step": 74000}
{"episode": 75.0, "batch_reward": 0.4299430302679539, "actor_loss": -75.17547071838379, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.855610132217407, "episode_reward": 551.8598431717687, "step": 75000}
{"episode": 76.0, "batch_reward": 0.43119948205351827, "actor_loss": -74.48052502441406, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 437.48797082901, "episode_reward": 575.4512389902179, "step": 76000}
{"episode": 77.0, "batch_reward": 0.43433505353331564, "actor_loss": -74.60992224121094, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.468032598495483, "episode_reward": 340.5705848042758, "step": 77000}
{"episode": 78.0, "batch_reward": 0.4327730692923069, "actor_loss": -75.60210786437989, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 428.0920031070709, "episode_reward": 684.7237488603666, "step": 78000}
{"episode": 79.0, "batch_reward": 0.43524849411845207, "actor_loss": -75.81060810852051, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.70197081565857, "episode_reward": 616.1911775192807, "step": 79000}
{"episode": 80.0, "batch_reward": 0.43853908687829973, "actor_loss": -75.35618954467773, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 434.71896839141846, "episode_reward": 668.0559852999081, "step": 80000}
{"episode": 81.0, "batch_reward": 0.44154709187150004, "actor_loss": -75.5551957244873, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 36.33604860305786, "episode_reward": 766.5188264180284, "step": 81000}
{"episode": 82.0, "batch_reward": 0.44344380143284795, "actor_loss": -75.22890484619141, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 434.2932550907135, "episode_reward": 532.2646007915653, "step": 82000}
{"episode": 83.0, "batch_reward": 0.44536811411380767, "actor_loss": -75.41412280273437, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.13550877571106, "episode_reward": 537.4878484471105, "step": 83000}
{"episode": 84.0, "batch_reward": 0.44591168183088303, "actor_loss": -75.29266328430175, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 438.71763849258423, "episode_reward": 629.7983896277822, "step": 84000}
{"episode": 85.0, "batch_reward": 0.4481801413297653, "actor_loss": -75.34176063537598, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 15.769490242004395, "episode_reward": 630.5552146737062, "step": 85000}
{"episode": 86.0, "batch_reward": 0.4500860301554203, "actor_loss": -75.74319822692871, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 450.8015534877777, "episode_reward": 576.8472243783311, "step": 86000}
{"episode": 87.0, "batch_reward": 0.45346252152323724, "actor_loss": -75.85693719482421, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.794861316680908, "episode_reward": 616.3238626084291, "step": 87000}
{"episode": 88.0, "batch_reward": 0.4542249279022217, "actor_loss": -75.98276658630371, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 441.6256422996521, "episode_reward": 628.9935002890707, "step": 88000}
{"episode": 89.0, "batch_reward": 0.45547669869661334, "actor_loss": -76.06317628479005, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.3506281375885, "episode_reward": 645.891840236165, "step": 89000}
{"episode": 90.0, "batch_reward": 0.46082067999243737, "actor_loss": -76.45664039611816, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 448.13061594963074, "episode_reward": 701.4362201503819, "step": 90000}
{"episode": 91.0, "batch_reward": 0.45941899219155313, "actor_loss": -76.36654336547852, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 37.685049057006836, "episode_reward": 629.7169186726302, "step": 91000}
{"episode": 92.0, "batch_reward": 0.46281856995820997, "actor_loss": -77.4662255859375, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 430.9667763710022, "episode_reward": 306.57687295514546, "step": 92000}
{"episode": 93.0, "batch_reward": 0.4630415498018265, "actor_loss": -77.49293881225586, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.887616872787476, "episode_reward": 638.651089024406, "step": 93000}
{"episode": 94.0, "batch_reward": 0.4629235886335373, "actor_loss": -77.41938337707519, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 444.9436388015747, "episode_reward": 611.3738801140555, "step": 94000}
{"episode": 95.0, "batch_reward": 0.46293435522913934, "actor_loss": -77.37926943969727, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.398082971572876, "episode_reward": 555.1087955569878, "step": 95000}
{"episode": 96.0, "batch_reward": 0.467079925596714, "actor_loss": -78.57397276306152, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 441.1633622646332, "episode_reward": 509.0472460913368, "step": 96000}
{"episode": 97.0, "batch_reward": 0.46684589582681657, "actor_loss": -78.71235383605958, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.300950050354004, "episode_reward": 670.5179525217079, "step": 97000}
{"episode": 98.0, "batch_reward": 0.4678380708694458, "actor_loss": -78.26392900085449, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 442.2266447544098, "episode_reward": 736.7956001939556, "step": 98000}
{"episode": 99.0, "batch_reward": 0.47250961723923685, "actor_loss": -78.39542622375488, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.171061992645264, "episode_reward": 785.4660899043839, "step": 99000}
{"episode": 100.0, "batch_reward": 0.4759862118959427, "actor_loss": -77.95126927185059, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 438.23785281181335, "episode_reward": 690.1383345050812, "step": 100000}
{"episode": 101.0, "batch_reward": 0.4756044996380806, "actor_loss": -77.85587501525879, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 37.21110773086548, "episode_reward": 700.1567534129985, "step": 101000}
{"episode": 102.0, "batch_reward": 0.47962643405795097, "actor_loss": -77.66932272338867, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 449.20353507995605, "episode_reward": 671.3873977631225, "step": 102000}
{"episode": 103.0, "batch_reward": 0.48007316356897356, "actor_loss": -77.77850303649902, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.874321699142456, "episode_reward": 342.1024952525521, "step": 103000}
{"episode": 104.0, "batch_reward": 0.4776598486304283, "actor_loss": -77.22408764648438, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 440.01481008529663, "episode_reward": 638.470649390495, "step": 104000}
{"episode": 105.0, "batch_reward": 0.48007456967234613, "actor_loss": -77.34702645874023, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.177396535873413, "episode_reward": 716.77376514118, "step": 105000}
{"episode": 106.0, "batch_reward": 0.4828709079027176, "actor_loss": -77.56898052978515, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 444.8495543003082, "episode_reward": 690.0583793984251, "step": 106000}
{"episode": 107.0, "batch_reward": 0.4860189727544785, "actor_loss": -77.81159394836426, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.573250770568848, "episode_reward": 787.8423536443107, "step": 107000}
{"episode": 108.0, "batch_reward": 0.48679695490002634, "actor_loss": -77.79034504699707, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 447.42402243614197, "episode_reward": 584.9760698077185, "step": 108000}
{"episode": 109.0, "batch_reward": 0.4876762302815914, "actor_loss": -78.01073690795899, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.16001605987549, "episode_reward": 628.3907824729403, "step": 109000}
{"episode": 110.0, "batch_reward": 0.48992395064234734, "actor_loss": -77.10637498474121, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 440.57689571380615, "episode_reward": 717.4956009252733, "step": 110000}
{"episode": 111.0, "batch_reward": 0.49277194395661356, "actor_loss": -77.31707427978516, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 35.95292544364929, "episode_reward": 701.3238074409459, "step": 111000}
{"episode": 112.0, "batch_reward": 0.4929949451982975, "actor_loss": -78.02743405151367, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 451.06104612350464, "episode_reward": 647.4430737184116, "step": 112000}
{"episode": 113.0, "batch_reward": 0.49513877817988394, "actor_loss": -77.92878315734863, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.766947269439697, "episode_reward": 433.3418175813059, "step": 113000}
{"episode": 114.0, "batch_reward": 0.49577263194322585, "actor_loss": -77.55302922058105, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 446.8370716571808, "episode_reward": 674.6390901652522, "step": 114000}
{"episode": 115.0, "batch_reward": 0.49733573630452155, "actor_loss": -77.74614805603028, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.428019762039185, "episode_reward": 607.5781286238316, "step": 115000}
{"episode": 116.0, "batch_reward": 0.49701882523298263, "actor_loss": -79.39385415649414, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 437.3266406059265, "episode_reward": 748.0117207171804, "step": 116000}
{"episode": 117.0, "batch_reward": 0.49904089945554736, "actor_loss": -79.53937040710449, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.319041967391968, "episode_reward": 638.6784180955739, "step": 117000}
{"episode": 118.0, "batch_reward": 0.5013690724372863, "actor_loss": -79.2936262512207, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 447.7180278301239, "episode_reward": 589.0280974637171, "step": 118000}
{"episode": 119.0, "batch_reward": 0.49993687349557875, "actor_loss": -79.13195889282227, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.66289734840393, "episode_reward": 566.19361109435, "step": 119000}
{"episode": 120.0, "batch_reward": 0.5006159085333347, "actor_loss": -79.06057969665527, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 447.0112862586975, "episode_reward": 633.0478068158743, "step": 120000}
{"episode": 121.0, "batch_reward": 0.5034940413534641, "actor_loss": -79.24491751098633, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.09396481513977, "episode_reward": 637.5380564483493, "step": 121000}
{"episode": 122.0, "batch_reward": 0.5040915781259536, "actor_loss": -78.43386888122559, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 447.57644152641296, "episode_reward": 611.9506599593774, "step": 122000}
{"episode": 123.0, "batch_reward": 0.5045510236024856, "actor_loss": -78.59502122497558, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.180927753448486, "episode_reward": 447.99197489428946, "step": 123000}
{"episode": 124.0, "batch_reward": 0.5028555379807949, "actor_loss": -78.03410231018066, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 448.7047302722931, "episode_reward": 391.1292949932298, "step": 124000}
{"episode": 125.0, "batch_reward": 0.5037776179909706, "actor_loss": -78.01628065490722, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.747912645339966, "episode_reward": 496.39540785510377, "step": 125000}
{"episode": 126.0, "batch_reward": 0.5020841076672077, "actor_loss": -77.02863475036621, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 439.55622458457947, "episode_reward": 670.386271181077, "step": 126000}
{"episode": 127.0, "batch_reward": 0.5046316179335117, "actor_loss": -77.16589453125, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.402719020843506, "episode_reward": 552.7656106917221, "step": 127000}
{"episode": 128.0, "batch_reward": 0.5052715942263604, "actor_loss": -75.14080036926269, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 451.8140678405762, "episode_reward": 520.2830286786948, "step": 128000}
{"episode": 129.0, "batch_reward": 0.506040838778019, "actor_loss": -75.24680001831055, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.264376640319824, "episode_reward": 669.0891993644624, "step": 129000}
{"episode": 130.0, "batch_reward": 0.505922984868288, "actor_loss": -74.27681916809082, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 437.19009017944336, "episode_reward": 682.8106109054152, "step": 130000}
{"episode": 131.0, "batch_reward": 0.5073276513814926, "actor_loss": -74.3384070892334, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 38.483227014541626, "episode_reward": 718.3604862977858, "step": 131000}
{"episode": 132.0, "batch_reward": 0.5110017217695713, "actor_loss": -74.01434281921387, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 441.93873023986816, "episode_reward": 733.9740785631096, "step": 132000}
{"episode": 133.0, "batch_reward": 0.5110480235517025, "actor_loss": -74.02820693969727, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 15.768255949020386, "episode_reward": 548.2644380008638, "step": 133000}
{"episode": 134.0, "batch_reward": 0.5132823756635189, "actor_loss": -75.03416093444824, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 443.47984862327576, "episode_reward": 700.6495643882816, "step": 134000}
{"episode": 135.0, "batch_reward": 0.5111272519826889, "actor_loss": -74.87455854797363, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.14005732536316, "episode_reward": 556.1659610676578, "step": 135000}
{"episode": 136.0, "batch_reward": 0.5147897678613663, "actor_loss": -74.34042355346679, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 442.6338357925415, "episode_reward": 630.4745974209167, "step": 136000}
{"episode": 137.0, "batch_reward": 0.5139396775364876, "actor_loss": -74.24861367797851, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.671691417694092, "episode_reward": 716.503760751503, "step": 137000}
{"episode": 138.0, "batch_reward": 0.5150863918662071, "actor_loss": -74.07136387634277, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 453.2520897388458, "episode_reward": 618.1135270134913, "step": 138000}
{"episode": 139.0, "batch_reward": 0.5166011827290058, "actor_loss": -74.19074873352051, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.234188079833984, "episode_reward": 734.7110703018906, "step": 139000}
{"episode": 140.0, "batch_reward": 0.5197149842083454, "actor_loss": -75.38704861450195, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 441.5417561531067, "episode_reward": 690.0733651694796, "step": 140000}
{"episode": 141.0, "batch_reward": 0.519208950072527, "actor_loss": -75.33539892578125, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 39.48851752281189, "episode_reward": 817.7056527695944, "step": 141000}
{"episode": 142.0, "batch_reward": 0.5216279286444188, "actor_loss": -76.34863069152831, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 425.18508100509644, "episode_reward": 691.5504457355896, "step": 142000}
{"episode": 143.0, "batch_reward": 0.522943621903658, "actor_loss": -76.39575192260742, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.5541570186615, "episode_reward": 655.4546398876666, "step": 143000}
{"episode": 144.0, "batch_reward": 0.5225573319792748, "actor_loss": -75.79058647155762, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 425.94078612327576, "episode_reward": 520.1771899335147, "step": 144000}
{"episode": 145.0, "batch_reward": 0.5230852400958538, "actor_loss": -75.90252799987793, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.981143951416016, "episode_reward": 737.2771148564705, "step": 145000}
{"episode": 146.0, "batch_reward": 0.52474676913023, "actor_loss": -75.44529800415039, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 423.16708159446716, "episode_reward": 601.9176824491667, "step": 146000}
{"episode": 147.0, "batch_reward": 0.5256480537652969, "actor_loss": -75.39382289123535, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.640032052993774, "episode_reward": 692.4951577830325, "step": 147000}
{"episode": 148.0, "batch_reward": 0.5272339882254601, "actor_loss": -75.95799050903321, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 431.1832196712494, "episode_reward": 660.6344572010687, "step": 148000}
{"episode": 149.0, "batch_reward": 0.5268843717575074, "actor_loss": -75.8749727935791, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.024096488952637, "episode_reward": 761.5031187425507, "step": 149000}
{"episode": 150.0, "batch_reward": 0.5290617932081223, "actor_loss": -75.26412564086914, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "step": 150000}
