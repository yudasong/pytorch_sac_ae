{"episode_reward": 0.0, "episode": 1.0, "duration": 20.87805485725403, "step": 1000}
{"episode_reward": 28.002640152663393, "episode": 2.0, "duration": 1.8059508800506592, "step": 2000}
{"episode_reward": 481.4321918933315, "episode": 3.0, "batch_reward": 0.26608328822852373, "critic_loss": 0.49505935324136713, "actor_loss": -83.92009845625262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 59.962029457092285, "step": 3000}
{"episode_reward": 371.2299778795773, "episode": 4.0, "batch_reward": 0.3219271466135979, "critic_loss": 0.695196371614933, "actor_loss": -82.68110189819336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.016058444976807, "step": 4000}
{"episode_reward": 506.072726888287, "episode": 5.0, "batch_reward": 0.3758870778977871, "critic_loss": 0.7808144474923611, "actor_loss": -83.56173225402831, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.054626941680908, "step": 5000}
{"episode_reward": 569.9892792083633, "episode": 6.0, "batch_reward": 0.40634096232056616, "critic_loss": 0.9375220691561699, "actor_loss": -83.82066912841798, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04573082923889, "step": 6000}
{"episode_reward": 578.1295113244535, "episode": 7.0, "batch_reward": 0.43651993852853777, "critic_loss": 1.0536878752708434, "actor_loss": -83.32555001831055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04391074180603, "step": 7000}
{"episode_reward": 624.789619279805, "episode": 8.0, "batch_reward": 0.4221675972342491, "critic_loss": 0.907084785848856, "actor_loss": -81.68554853820801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.062874794006348, "step": 8000}
{"episode_reward": 10.359881370180604, "episode": 9.0, "batch_reward": 0.41382067230343816, "critic_loss": 0.9635844048261643, "actor_loss": -81.00467434692384, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.0156192779541, "step": 9000}
{"episode_reward": 693.5006577288273, "episode": 10.0, "batch_reward": 0.4084832100272179, "critic_loss": 0.8755769335329533, "actor_loss": -80.06818270874024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.048619747161865, "step": 10000}
{"episode_reward": 11.861024450904708, "episode": 11.0, "batch_reward": 0.39950339287519454, "critic_loss": 0.9900621793270111, "actor_loss": -78.8813038482666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.64248991012573, "step": 11000}
{"episode_reward": 643.6693715542251, "episode": 12.0, "batch_reward": 0.42252855718135834, "critic_loss": 1.2055859430432319, "actor_loss": -79.37267308044433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.00785255432129, "step": 12000}
{"episode_reward": 685.6369602795029, "episode": 13.0, "batch_reward": 0.44008818703889846, "critic_loss": 1.2809545186758042, "actor_loss": -79.459978515625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.023159503936768, "step": 13000}
{"episode_reward": 663.8102810615572, "episode": 14.0, "batch_reward": 0.4598809159398079, "critic_loss": 1.3450622491836548, "actor_loss": -79.72310018920898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.01623797416687, "step": 14000}
{"episode_reward": 679.6090860684819, "episode": 15.0, "batch_reward": 0.47096157366037367, "critic_loss": 1.350817310631275, "actor_loss": -80.46621347045898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.053319215774536, "step": 15000}
{"episode_reward": 707.6867408431975, "episode": 16.0, "batch_reward": 0.4686705995798111, "critic_loss": 1.255375388622284, "actor_loss": -80.06269093322754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03762197494507, "step": 16000}
{"episode_reward": 14.631093240887585, "episode": 17.0, "batch_reward": 0.46643208974599837, "critic_loss": 1.2059109684824945, "actor_loss": -79.80874653625489, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.040260553359985, "step": 17000}
{"episode_reward": 817.0641980811332, "episode": 18.0, "batch_reward": 0.48237539958953857, "critic_loss": 1.1943077076077462, "actor_loss": -80.095336227417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.042676210403442, "step": 18000}
{"episode_reward": 782.0338657062125, "episode": 19.0, "batch_reward": 0.4884787740409374, "critic_loss": 1.1742213202118874, "actor_loss": -80.18184748840332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.018434762954712, "step": 19000}
{"episode_reward": 524.5170915417626, "episode": 20.0, "batch_reward": 0.5015287210345268, "critic_loss": 1.178063154220581, "actor_loss": -81.03476718139649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.014364004135132, "step": 20000}
{"episode_reward": 818.6663992242809, "episode": 21.0, "batch_reward": 0.5185078626871109, "critic_loss": 1.0989104566574097, "actor_loss": -80.15709648132324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.568705797195435, "step": 21000}
{"episode_reward": 842.6906946852417, "episode": 22.0, "batch_reward": 0.5301309838593006, "critic_loss": 1.1574216943979263, "actor_loss": -81.51679133605957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03612494468689, "step": 22000}
{"episode_reward": 806.0054960030233, "episode": 23.0, "batch_reward": 0.5449885668456554, "critic_loss": 1.1727717121839523, "actor_loss": -81.46343585205078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05234956741333, "step": 23000}
{"episode_reward": 822.7175785556927, "episode": 24.0, "batch_reward": 0.5574710726439953, "critic_loss": 1.1435997074246407, "actor_loss": -81.64710356140137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.046930074691772, "step": 24000}
{"episode_reward": 837.7893722190423, "episode": 25.0, "batch_reward": 0.5667903341650963, "critic_loss": 1.19085666847229, "actor_loss": -82.06995579528808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03389573097229, "step": 25000}
{"episode_reward": 842.8477572786347, "episode": 26.0, "batch_reward": 0.5808754521608352, "critic_loss": 1.2052374591231345, "actor_loss": -82.12583070373535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.030433654785156, "step": 26000}
{"episode_reward": 932.8376827125553, "episode": 27.0, "batch_reward": 0.591809564858675, "critic_loss": 1.1648861144781113, "actor_loss": -82.15482371520996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.01561427116394, "step": 27000}
{"episode_reward": 883.8354604518963, "episode": 28.0, "batch_reward": 0.6060004278421401, "critic_loss": 1.1397194712758065, "actor_loss": -82.94276477050781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05978775024414, "step": 28000}
{"episode_reward": 900.371463541634, "episode": 29.0, "batch_reward": 0.6129231404960156, "critic_loss": 1.0852611362338067, "actor_loss": -83.03464321899413, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.018951654434204, "step": 29000}
{"episode_reward": 899.3555318995145, "episode": 30.0, "batch_reward": 0.6252311495542526, "critic_loss": 1.091007383286953, "actor_loss": -82.90724334716796, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04143261909485, "step": 30000}
{"episode_reward": 908.6116893361317, "episode": 31.0, "batch_reward": 0.6340554079413414, "critic_loss": 1.037611481487751, "actor_loss": -83.66724383544921, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.929900884628296, "step": 31000}
{"episode_reward": 931.1203916746722, "episode": 32.0, "batch_reward": 0.6417920913696289, "critic_loss": 1.026395865559578, "actor_loss": -84.45696020507812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.044548988342285, "step": 32000}
{"episode_reward": 872.4721673764188, "episode": 33.0, "batch_reward": 0.6512985283732414, "critic_loss": 0.9929682609140873, "actor_loss": -84.57204251098632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.013428211212158, "step": 33000}
{"episode_reward": 884.7128029248602, "episode": 34.0, "batch_reward": 0.6569736751914025, "critic_loss": 0.9648411482572555, "actor_loss": -84.4130869293213, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.02668070793152, "step": 34000}
{"episode_reward": 887.088360085112, "episode": 35.0, "batch_reward": 0.6644193407297134, "critic_loss": 0.9402152490317821, "actor_loss": -84.99625895690917, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.025936603546143, "step": 35000}
{"episode_reward": 894.8902483009741, "episode": 36.0, "batch_reward": 0.6702919673919677, "critic_loss": 0.9235851054787636, "actor_loss": -85.36007263183593, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.01617956161499, "step": 36000}
{"episode_reward": 904.5897006905885, "episode": 37.0, "batch_reward": 0.6761195718050003, "critic_loss": 0.9061637171804905, "actor_loss": -85.11856036376953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.033487796783447, "step": 37000}
{"episode_reward": 938.871710990368, "episode": 38.0, "batch_reward": 0.6860271910429001, "critic_loss": 0.8986901766955853, "actor_loss": -85.64188789367675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.012386798858643, "step": 38000}
{"episode_reward": 930.2207621746218, "episode": 39.0, "batch_reward": 0.6912340214848518, "critic_loss": 0.8608405196368695, "actor_loss": -85.74436396789551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.034738302230835, "step": 39000}
{"episode_reward": 946.7211971495705, "episode": 40.0, "batch_reward": 0.6993472702503204, "critic_loss": 0.8588579968810082, "actor_loss": -86.13962875366211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.049930334091187, "step": 40000}
{"episode_reward": 972.3063220187701, "episode": 41.0, "batch_reward": 0.7004193969368935, "critic_loss": 0.8486164646148682, "actor_loss": -86.0853102722168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.57941484451294, "step": 41000}
{"episode_reward": 831.3166091875366, "episode": 42.0, "batch_reward": 0.7074341015815735, "critic_loss": 0.875321181178093, "actor_loss": -86.44335627746582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05676531791687, "step": 42000}
{"episode_reward": 948.6647897106541, "episode": 43.0, "batch_reward": 0.7127614176273346, "critic_loss": 0.846441288292408, "actor_loss": -87.03480473327637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05088186264038, "step": 43000}
{"episode_reward": 941.8280926234811, "episode": 44.0, "batch_reward": 0.7155315110683441, "critic_loss": 0.8505304737985134, "actor_loss": -87.54569456481934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04072403907776, "step": 44000}
{"episode_reward": 930.1125185127984, "episode": 45.0, "batch_reward": 0.7225084708929062, "critic_loss": 0.847526182949543, "actor_loss": -87.34731216430664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.048274993896484, "step": 45000}
{"episode_reward": 967.4063394814712, "episode": 46.0, "batch_reward": 0.7273951811790467, "critic_loss": 0.8290914179682731, "actor_loss": -87.3666316986084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.049249172210693, "step": 46000}
{"episode_reward": 934.1230465257946, "episode": 47.0, "batch_reward": 0.732896374464035, "critic_loss": 0.8311948708295822, "actor_loss": -87.83480726623534, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.036356210708618, "step": 47000}
{"episode_reward": 944.4085505576074, "episode": 48.0, "batch_reward": 0.7382089436650277, "critic_loss": 0.7774182806909085, "actor_loss": -88.06857478332519, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.031113386154175, "step": 48000}
{"episode_reward": 881.2225648782888, "episode": 49.0, "batch_reward": 0.7398997878432274, "critic_loss": 0.7901408528089523, "actor_loss": -88.63831874084472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.00362730026245, "step": 49000}
{"episode_reward": 882.7418133620515, "episode": 50.0, "batch_reward": 0.7417090028524399, "critic_loss": 0.7707008273303508, "actor_loss": -88.40524885559083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03945541381836, "step": 50000}
{"episode_reward": 914.2158226573177, "episode": 51.0, "batch_reward": 0.7457162004113197, "critic_loss": 0.7763834519982338, "actor_loss": -88.39184852600097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.580538749694824, "step": 51000}
{"episode_reward": 955.0540627616873, "episode": 52.0, "batch_reward": 0.7516204217672348, "critic_loss": 0.7733345350623131, "actor_loss": -88.68592337036132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.056914806365967, "step": 52000}
{"episode_reward": 931.0997984088682, "episode": 53.0, "batch_reward": 0.7528271483182907, "critic_loss": 0.7640198934674263, "actor_loss": -89.19209648132325, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.98725914955139, "step": 53000}
{"episode_reward": 912.9213554462093, "episode": 54.0, "batch_reward": 0.7576874755620956, "critic_loss": 0.7255406582355499, "actor_loss": -89.47622909545899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.987000942230225, "step": 54000}
{"episode_reward": 939.927724088967, "episode": 55.0, "batch_reward": 0.7582229124307632, "critic_loss": 0.7290946461260319, "actor_loss": -89.07987571716309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.009567975997925, "step": 55000}
{"episode_reward": 915.4608179923842, "episode": 56.0, "batch_reward": 0.7619462414979935, "critic_loss": 0.7212371748387814, "actor_loss": -89.39877180480957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.020638704299927, "step": 56000}
{"episode_reward": 910.4309136718772, "episode": 57.0, "batch_reward": 0.7654151254296303, "critic_loss": 0.6992127044796944, "actor_loss": -89.41871215820312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.029789209365845, "step": 57000}
{"episode_reward": 926.7065266815175, "episode": 58.0, "batch_reward": 0.7673053293228149, "critic_loss": 0.7201270242035389, "actor_loss": -89.97250328063964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.990073442459106, "step": 58000}
{"episode_reward": 916.9038420745021, "episode": 59.0, "batch_reward": 0.7708296141624451, "critic_loss": 0.7592475765943527, "actor_loss": -89.95734371948242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.041605949401855, "step": 59000}
{"episode_reward": 933.1597496008968, "episode": 60.0, "batch_reward": 0.772885802268982, "critic_loss": 0.6998879837989808, "actor_loss": -90.29899475097656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.032315015792847, "step": 60000}
{"episode_reward": 950.7044239137946, "episode": 61.0, "batch_reward": 0.7774185423254967, "critic_loss": 0.6736190994083882, "actor_loss": -90.20777758789062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.568912506103516, "step": 61000}
{"episode_reward": 959.6165749542985, "episode": 62.0, "batch_reward": 0.7792211371064186, "critic_loss": 0.6880730817317963, "actor_loss": -90.80314170837403, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.055427074432373, "step": 62000}
{"episode_reward": 926.3727314014135, "episode": 63.0, "batch_reward": 0.7820419520735741, "critic_loss": 0.6837162195444108, "actor_loss": -90.43312268066406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.050639867782593, "step": 63000}
{"episode_reward": 865.1396021618656, "episode": 64.0, "batch_reward": 0.7827320676445961, "critic_loss": 0.693034546405077, "actor_loss": -90.79965838623046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.034425973892212, "step": 64000}
{"episode_reward": 884.2117404004456, "episode": 65.0, "batch_reward": 0.7832817417383194, "critic_loss": 0.6985147539973259, "actor_loss": -90.7537908782959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.000460386276245, "step": 65000}
{"episode_reward": 907.4954679791085, "episode": 66.0, "batch_reward": 0.785754686653614, "critic_loss": 0.6945068291723728, "actor_loss": -90.92856002807618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.012026071548462, "step": 66000}
{"episode_reward": 915.7302593057414, "episode": 67.0, "batch_reward": 0.7892836558222771, "critic_loss": 0.6823384261131287, "actor_loss": -91.27773626708985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.00385069847107, "step": 67000}
{"episode_reward": 938.6330985006783, "episode": 68.0, "batch_reward": 0.7908833557963372, "critic_loss": 0.6884028828144073, "actor_loss": -91.37443380737305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.02152419090271, "step": 68000}
{"episode_reward": 951.9479625036521, "episode": 69.0, "batch_reward": 0.7916119371056557, "critic_loss": 0.6683103086650372, "actor_loss": -91.19679330444336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.042520999908447, "step": 69000}
{"episode_reward": 930.6741675349504, "episode": 70.0, "batch_reward": 0.7954305327534675, "critic_loss": 0.6839976510405541, "actor_loss": -91.31616011047363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03734588623047, "step": 70000}
{"episode_reward": 900.001984508382, "episode": 71.0, "batch_reward": 0.796717984855175, "critic_loss": 0.6531580717265606, "actor_loss": -91.32817247009277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.630070209503174, "step": 71000}
{"episode_reward": 863.4871690435481, "episode": 72.0, "batch_reward": 0.7976988453269005, "critic_loss": 0.6349208958745003, "actor_loss": -91.43114122009277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.041114330291748, "step": 72000}
{"episode_reward": 928.5527798566435, "episode": 73.0, "batch_reward": 0.79930588555336, "critic_loss": 0.6443142029643059, "actor_loss": -91.50197302246093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.051743984222412, "step": 73000}
{"episode_reward": 923.758389388784, "episode": 74.0, "batch_reward": 0.7947266671061516, "critic_loss": 0.6336888904571534, "actor_loss": -91.41395837402344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.050812244415283, "step": 74000}
{"episode_reward": 15.727918271022336, "episode": 75.0, "batch_reward": 0.7886397366523743, "critic_loss": 0.6416809200644493, "actor_loss": -91.194960647583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.01226234436035, "step": 75000}
{"episode_reward": 926.2261334783918, "episode": 76.0, "batch_reward": 0.79158073335886, "critic_loss": 0.6571433824896813, "actor_loss": -91.10599278259278, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.102298498153687, "step": 76000}
{"episode_reward": 862.6408576098931, "episode": 77.0, "batch_reward": 0.7922092910408973, "critic_loss": 0.6721850960850716, "actor_loss": -91.33381553649902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.262412548065186, "step": 77000}
{"episode_reward": 936.7147266904477, "episode": 78.0, "batch_reward": 0.7943597133159638, "critic_loss": 0.6814504381120204, "actor_loss": -91.27170237731933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.038716554641724, "step": 78000}
{"episode_reward": 925.3669736179511, "episode": 79.0, "batch_reward": 0.7973260259628296, "critic_loss": 0.6681174449026585, "actor_loss": -91.60184146118164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.99446725845337, "step": 79000}
{"episode_reward": 940.7383087651556, "episode": 80.0, "batch_reward": 0.7994602141976357, "critic_loss": 0.6993529810905457, "actor_loss": -91.62146018981933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.034098148345947, "step": 80000}
{"episode_reward": 928.3191024909895, "episode": 81.0, "batch_reward": 0.7995074355006218, "critic_loss": 0.7109879803955554, "actor_loss": -91.63733134460449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.569963455200195, "step": 81000}
{"episode_reward": 852.3130644322433, "episode": 82.0, "batch_reward": 0.8003938582539558, "critic_loss": 0.76160292288661, "actor_loss": -91.4391817932129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.063318729400635, "step": 82000}
{"episode_reward": 933.7221863936961, "episode": 83.0, "batch_reward": 0.8015140252709388, "critic_loss": 0.7633349830210209, "actor_loss": -91.72810165405274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.354096174240112, "step": 83000}
{"episode_reward": 806.5149950469256, "episode": 84.0, "batch_reward": 0.8020921139121056, "critic_loss": 0.7431700263023376, "actor_loss": -91.78386267089844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.00523614883423, "step": 84000}
{"episode_reward": 885.3942591868785, "episode": 85.0, "batch_reward": 0.8034962911605835, "critic_loss": 0.7423210990726947, "actor_loss": -91.64113815307617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.99760103225708, "step": 85000}
{"episode_reward": 947.3681572094745, "episode": 86.0, "batch_reward": 0.8042725476622582, "critic_loss": 0.7077222231775522, "actor_loss": -91.70754496765137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.019293069839478, "step": 86000}
{"episode_reward": 934.403472161694, "episode": 87.0, "batch_reward": 0.8074805904626846, "critic_loss": 0.6886007756590843, "actor_loss": -91.99145948791504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.060783624649048, "step": 87000}
{"episode_reward": 938.7305218948541, "episode": 88.0, "batch_reward": 0.8097272646427155, "critic_loss": 0.7146545742452145, "actor_loss": -91.97889950561523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.01086664199829, "step": 88000}
{"episode_reward": 879.5554482265211, "episode": 89.0, "batch_reward": 0.808018276154995, "critic_loss": 0.7257991483211518, "actor_loss": -91.76327699279786, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.01423478126526, "step": 89000}
{"episode_reward": 910.2281939854789, "episode": 90.0, "batch_reward": 0.8113978573083878, "critic_loss": 0.702530912578106, "actor_loss": -91.94129856872559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.02624273300171, "step": 90000}
{"episode_reward": 926.0621675373527, "episode": 91.0, "batch_reward": 0.8119487392306328, "critic_loss": 0.7088436083495617, "actor_loss": -91.97497772216796, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.586297035217285, "step": 91000}
{"episode_reward": 948.9579384766907, "episode": 92.0, "batch_reward": 0.811763208270073, "critic_loss": 0.7000138882398605, "actor_loss": -92.2851674041748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.02312731742859, "step": 92000}
{"episode_reward": 935.1482331717748, "episode": 93.0, "batch_reward": 0.8142528513073921, "critic_loss": 0.6321050893962383, "actor_loss": -92.21973635864258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05201554298401, "step": 93000}
{"episode_reward": 962.8034019484245, "episode": 94.0, "batch_reward": 0.8158325192332267, "critic_loss": 0.6759962628483772, "actor_loss": -92.43700315856934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.021803855895996, "step": 94000}
{"episode_reward": 897.6320643141744, "episode": 95.0, "batch_reward": 0.8162324942350387, "critic_loss": 0.672437536329031, "actor_loss": -92.62656001281738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.026898860931396, "step": 95000}
{"episode_reward": 903.8572453405719, "episode": 96.0, "batch_reward": 0.8183112518191338, "critic_loss": 0.7518355794250965, "actor_loss": -92.43865777587891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.0434410572052, "step": 96000}
{"episode_reward": 959.8506678280382, "episode": 97.0, "batch_reward": 0.8180048773884774, "critic_loss": 0.6630199129879475, "actor_loss": -92.40730271911622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.065204858779907, "step": 97000}
{"episode_reward": 978.9741723306705, "episode": 98.0, "batch_reward": 0.8188561784029007, "critic_loss": 0.6598425095379352, "actor_loss": -92.71109545898437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.037580966949463, "step": 98000}
{"episode_reward": 919.0678877901139, "episode": 99.0, "batch_reward": 0.8216797450184822, "critic_loss": 0.6508402538895607, "actor_loss": -92.68407104492188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05695676803589, "step": 99000}
{"episode_reward": 973.9681269373314, "episode": 100.0, "batch_reward": 0.8226274832487106, "critic_loss": 0.6512647439241409, "actor_loss": -92.737130859375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.056020259857178, "step": 100000}
{"episode_reward": 916.9290775261496, "episode": 101.0, "batch_reward": 0.8242522525787354, "critic_loss": 0.6946949823200703, "actor_loss": -92.76164997863769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.58010292053223, "step": 101000}
{"episode_reward": 950.9014751067555, "episode": 102.0, "batch_reward": 0.8216646094918251, "critic_loss": 0.6738448075950145, "actor_loss": -92.78175651550293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.017343997955322, "step": 102000}
{"episode_reward": 56.93388088188526, "episode": 103.0, "batch_reward": 0.8157967160344124, "critic_loss": 0.6718120235800743, "actor_loss": -92.5735266571045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.015511512756348, "step": 103000}
{"episode_reward": 894.9137508765782, "episode": 104.0, "batch_reward": 0.8188008400201797, "critic_loss": 0.6475101840496064, "actor_loss": -92.50543350219726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03065323829651, "step": 104000}
{"episode_reward": 966.7670491150914, "episode": 105.0, "batch_reward": 0.8207101413607597, "critic_loss": 0.662927292406559, "actor_loss": -92.67260005187988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.036690950393677, "step": 105000}
{"episode_reward": 951.958504584852, "episode": 106.0, "batch_reward": 0.8203732584118844, "critic_loss": 0.6871300458014011, "actor_loss": -92.62877226257324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03757357597351, "step": 106000}
{"episode_reward": 801.7440948736905, "episode": 107.0, "batch_reward": 0.821726021707058, "critic_loss": 0.6944715222418308, "actor_loss": -92.64537673950196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.042480945587158, "step": 107000}
{"episode_reward": 924.3260924992253, "episode": 108.0, "batch_reward": 0.822283293068409, "critic_loss": 0.662697130933404, "actor_loss": -92.91105438232422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.021451711654663, "step": 108000}
{"episode_reward": 951.6514092795543, "episode": 109.0, "batch_reward": 0.8240666057467461, "critic_loss": 0.6770474359989166, "actor_loss": -92.77209236145019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.028963565826416, "step": 109000}
{"episode_reward": 863.8345169201563, "episode": 110.0, "batch_reward": 0.822724024951458, "critic_loss": 0.6923120023012161, "actor_loss": -92.85527130126952, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.034744262695312, "step": 110000}
{"episode_reward": 924.4356939394656, "episode": 111.0, "batch_reward": 0.8248838383555412, "critic_loss": 0.6895772200822831, "actor_loss": -92.82312362670899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.577019453048706, "step": 111000}
{"episode_reward": 957.0674272573336, "episode": 112.0, "batch_reward": 0.8248644823431969, "critic_loss": 0.68535638448596, "actor_loss": -93.07619570922851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04705834388733, "step": 112000}
{"episode_reward": 961.6955820403829, "episode": 113.0, "batch_reward": 0.8280732262730598, "critic_loss": 0.6854585491418839, "actor_loss": -92.82736442565918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.07293701171875, "step": 113000}
{"episode_reward": 915.6961074448752, "episode": 114.0, "batch_reward": 0.8280483983755111, "critic_loss": 0.6754918624162674, "actor_loss": -93.06886581420899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04724884033203, "step": 114000}
{"episode_reward": 947.968505160864, "episode": 115.0, "batch_reward": 0.83075742405653, "critic_loss": 0.6895544956028461, "actor_loss": -93.03312718200684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.049666166305542, "step": 115000}
{"episode_reward": 955.1387806390011, "episode": 116.0, "batch_reward": 0.8309150388240815, "critic_loss": 0.6676462262272834, "actor_loss": -93.05491868591308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.025333642959595, "step": 116000}
{"episode_reward": 969.9394323161885, "episode": 117.0, "batch_reward": 0.8320948885083198, "critic_loss": 0.6422835421711206, "actor_loss": -92.96644863891602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04759383201599, "step": 117000}
{"episode_reward": 944.5525782872064, "episode": 118.0, "batch_reward": 0.8317275488376618, "critic_loss": 0.6637815328389406, "actor_loss": -93.00611074829102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.02945590019226, "step": 118000}
{"episode_reward": 936.0565671223544, "episode": 119.0, "batch_reward": 0.8337446339726448, "critic_loss": 0.6629302057623864, "actor_loss": -93.04244288635253, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04464888572693, "step": 119000}
{"episode_reward": 944.5408487916679, "episode": 120.0, "batch_reward": 0.834633641242981, "critic_loss": 0.6468397112190724, "actor_loss": -93.11511933898926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.058754682540894, "step": 120000}
{"episode_reward": 945.106902142338, "episode": 121.0, "batch_reward": 0.8356798102855683, "critic_loss": 0.6278910511732101, "actor_loss": -93.14264158630371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.598816871643066, "step": 121000}
{"episode_reward": 956.3214435237215, "episode": 122.0, "batch_reward": 0.8364155820608139, "critic_loss": 0.6527884094268084, "actor_loss": -93.30102648925781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.052939653396606, "step": 122000}
{"episode_reward": 888.4786421848233, "episode": 123.0, "batch_reward": 0.8372739155888558, "critic_loss": 0.6696880364269018, "actor_loss": -93.33280952453613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.054036378860474, "step": 123000}
{"episode_reward": 900.6849987897757, "episode": 124.0, "batch_reward": 0.8344645564556121, "critic_loss": 0.6588309134691953, "actor_loss": -93.29068003845215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.049238920211792, "step": 124000}
{"episode_reward": 751.825857669792, "episode": 125.0, "batch_reward": 0.8348937863707543, "critic_loss": 0.6450760362297296, "actor_loss": -93.20741761779786, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04935622215271, "step": 125000}
{"episode_reward": 965.3353199361567, "episode": 126.0, "batch_reward": 0.8359239123463631, "critic_loss": 0.6591176243722439, "actor_loss": -93.34544769287109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.029923915863037, "step": 126000}
{"episode_reward": 893.2964978119887, "episode": 127.0, "batch_reward": 0.8372032316923141, "critic_loss": 0.690438977047801, "actor_loss": -93.44728918457031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.050984859466553, "step": 127000}
{"episode_reward": 966.3439281329712, "episode": 128.0, "batch_reward": 0.8376593781709671, "critic_loss": 0.6685375561863184, "actor_loss": -93.42602212524415, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.035940170288086, "step": 128000}
{"episode_reward": 943.8991257961615, "episode": 129.0, "batch_reward": 0.8391481297016143, "critic_loss": 0.6565702514648437, "actor_loss": -93.3785224609375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04066014289856, "step": 129000}
{"episode_reward": 894.1733597409209, "episode": 130.0, "batch_reward": 0.8391996376514435, "critic_loss": 0.705245321214199, "actor_loss": -93.36452014160156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03703022003174, "step": 130000}
{"episode_reward": 950.726154837661, "episode": 131.0, "batch_reward": 0.8397634850740433, "critic_loss": 0.6692774866223336, "actor_loss": -93.3352520904541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.566715240478516, "step": 131000}
{"episode_reward": 955.6260385097064, "episode": 132.0, "batch_reward": 0.8410191216468811, "critic_loss": 0.6870781827121973, "actor_loss": -93.41310662841796, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04128336906433, "step": 132000}
{"episode_reward": 943.1798301812, "episode": 133.0, "batch_reward": 0.8436084643006325, "critic_loss": 0.6629229212254286, "actor_loss": -93.42387301635742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.036600589752197, "step": 133000}
{"episode_reward": 936.8910518575931, "episode": 134.0, "batch_reward": 0.8419299374818802, "critic_loss": 0.6564402746111154, "actor_loss": -93.48029057312012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.016549348831177, "step": 134000}
{"episode_reward": 974.8301560116302, "episode": 135.0, "batch_reward": 0.8422888075113296, "critic_loss": 0.64852140006423, "actor_loss": -93.57234391784668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.050025701522827, "step": 135000}
{"episode_reward": 901.3884504861319, "episode": 136.0, "batch_reward": 0.8439637874960899, "critic_loss": 0.6420038282871247, "actor_loss": -93.63065983581544, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.015841722488403, "step": 136000}
{"episode_reward": 941.1399859997614, "episode": 137.0, "batch_reward": 0.8446067205667496, "critic_loss": 0.6934052131325007, "actor_loss": -93.56846141052246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.042071104049683, "step": 137000}
{"episode_reward": 931.9935320033371, "episode": 138.0, "batch_reward": 0.8456966584920883, "critic_loss": 0.6805761336535215, "actor_loss": -93.61403216552735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.041054248809814, "step": 138000}
{"episode_reward": 942.6551908591869, "episode": 139.0, "batch_reward": 0.8455168929696083, "critic_loss": 0.7266667673289776, "actor_loss": -93.5354142150879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.046523571014404, "step": 139000}
{"episode_reward": 933.5853916054881, "episode": 140.0, "batch_reward": 0.8453303919434547, "critic_loss": 0.6654596158564091, "actor_loss": -93.53529200744629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05631375312805, "step": 140000}
{"episode_reward": 952.4215813992503, "episode": 141.0, "batch_reward": 0.8492338977456093, "critic_loss": 0.6414949640780687, "actor_loss": -93.72076690673828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.57037687301636, "step": 141000}
{"episode_reward": 958.1125546701006, "episode": 142.0, "batch_reward": 0.848438845872879, "critic_loss": 0.6407354539930821, "actor_loss": -93.74322119140625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.049468278884888, "step": 142000}
{"episode_reward": 919.7919454310262, "episode": 143.0, "batch_reward": 0.8492391219139099, "critic_loss": 0.6305575151145458, "actor_loss": -93.76172660827636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05863094329834, "step": 143000}
{"episode_reward": 932.8532018254256, "episode": 144.0, "batch_reward": 0.8489053601026535, "critic_loss": 0.6462282485812902, "actor_loss": -93.75632577514648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.047334671020508, "step": 144000}
{"episode_reward": 929.619893226145, "episode": 145.0, "batch_reward": 0.8515736247897148, "critic_loss": 0.6597526077181101, "actor_loss": -93.91109938049317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.047762393951416, "step": 145000}
{"episode_reward": 932.9775740230588, "episode": 146.0, "batch_reward": 0.8494589259624481, "critic_loss": 0.6545128778517246, "actor_loss": -93.66116082763672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.06328845024109, "step": 146000}
{"episode_reward": 903.3560217187037, "episode": 147.0, "batch_reward": 0.8505731248259545, "critic_loss": 0.6709847046285867, "actor_loss": -93.77591455078125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.01298499107361, "step": 147000}
{"episode_reward": 958.4120249958142, "episode": 148.0, "batch_reward": 0.8522042130827904, "critic_loss": 0.6421009783148766, "actor_loss": -93.91528913879395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.030901432037354, "step": 148000}
{"episode_reward": 918.1931946184201, "episode": 149.0, "batch_reward": 0.851796944797039, "critic_loss": 0.6383004023134708, "actor_loss": -93.88015864562988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.029426336288452, "step": 149000}
{"episode_reward": 962.4976897290283, "episode": 150.0, "batch_reward": 0.8530118070244789, "critic_loss": 0.6626677672713995, "actor_loss": -93.96558969116211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
