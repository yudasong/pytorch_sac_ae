{"episode": 1.0, "duration": 26.399168252944946, "episode_reward": 28.002640152663393, "step": 1000}
{"episode": 2.0, "duration": 1.9869647026062012, "episode_reward": 481.4321918933315, "step": 2000}
{"episode": 3.0, "batch_reward": 0.26691520271717845, "actor_loss": -85.23726735872572, "actor_target_entropy": -6.0, "alpha_value": 0.00244617320470393, "duration": 54.288904666900635, "episode_reward": 452.7483830151504, "step": 3000}
{"episode": 4.0, "batch_reward": 0.33788392433524134, "actor_loss": -85.92966801452637, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.02273726463318, "episode_reward": 462.519234781411, "step": 4000}
{"episode": 5.0, "batch_reward": 0.3387978310883045, "actor_loss": -85.15249531555176, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.528407335281372, "episode_reward": 296.7166335319475, "step": 5000}
{"episode": 6.0, "batch_reward": 0.355475056797266, "actor_loss": -85.2821706085205, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.105121850967407, "episode_reward": 489.39664316072395, "step": 6000}
{"episode": 7.0, "batch_reward": 0.37915770334005355, "actor_loss": -85.72666693115234, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.458810806274414, "episode_reward": 406.2835496138341, "step": 7000}
{"episode": 8.0, "batch_reward": 0.3805450811088085, "actor_loss": -85.43375178527832, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.767680406570435, "episode_reward": 507.24231329439993, "step": 8000}
{"episode": 9.0, "batch_reward": 0.40172801980376244, "actor_loss": -85.97980865478516, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.5088894367218, "episode_reward": 563.544312887866, "step": 9000}
{"episode": 10.0, "batch_reward": 0.4026368316113949, "actor_loss": -80.93450733947753, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 4161.352612257004, "episode_reward": 383.4288384570381, "step": 10000}
{"episode": 11.0, "batch_reward": 0.4131046932339668, "actor_loss": -81.30817427062988, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 40.7442946434021, "episode_reward": 584.523292791998, "step": 11000}
{"episode": 12.0, "batch_reward": 0.4259928847551346, "actor_loss": -79.68837391662598, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 457.20017671585083, "episode_reward": 487.3520444973793, "step": 12000}
{"episode": 13.0, "batch_reward": 0.4239412606358528, "actor_loss": -80.10811102294922, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.15886664390564, "episode_reward": 312.0557658697321, "step": 13000}
{"episode": 14.0, "batch_reward": 0.42465306505560874, "actor_loss": -79.26431675720215, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 438.10202956199646, "episode_reward": 557.6266224967884, "step": 14000}
{"episode": 15.0, "batch_reward": 0.4346381506323814, "actor_loss": -79.69060668945312, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.805771827697754, "episode_reward": 513.783471054289, "step": 15000}
{"episode": 16.0, "batch_reward": 0.4348845292925835, "actor_loss": -78.40983203125, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 453.76370215415955, "episode_reward": 458.38675581557266, "step": 16000}
{"episode": 17.0, "batch_reward": 0.43835127463936807, "actor_loss": -78.58593479919433, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.903438329696655, "episode_reward": 488.3138314062524, "step": 17000}
{"episode": 18.0, "batch_reward": 0.43907140293717384, "actor_loss": -77.38777502441407, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 452.049852848053, "episode_reward": 376.3349222721381, "step": 18000}
{"episode": 19.0, "batch_reward": 0.4395726250708103, "actor_loss": -77.52868374633789, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.493096113204956, "episode_reward": 610.3299303659721, "step": 19000}
{"episode": 20.0, "batch_reward": 0.43476178315281866, "actor_loss": -77.2219602355957, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 456.42803478240967, "episode_reward": 17.685397918207194, "step": 20000}
{"episode": 21.0, "batch_reward": 0.4289881189167499, "actor_loss": -76.83934761047364, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 37.676952838897705, "episode_reward": 632.695810108813, "step": 21000}
{"episode": 22.0, "batch_reward": 0.4313015479147434, "actor_loss": -76.49460452270507, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 442.1526083946228, "episode_reward": 390.7570524303851, "step": 22000}
{"episode": 23.0, "batch_reward": 0.43275640076398847, "actor_loss": -76.80017654418945, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.028245210647583, "episode_reward": 454.6959517149309, "step": 23000}
{"episode": 24.0, "batch_reward": 0.43599369224905965, "actor_loss": -75.78224879455567, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 428.6715466976166, "episode_reward": 564.175144174227, "step": 24000}
{"episode": 25.0, "batch_reward": 0.4375582223236561, "actor_loss": -76.16872283935547, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.057109117507935, "episode_reward": 405.3494285894268, "step": 25000}
{"episode": 26.0, "batch_reward": 0.43902438336610794, "actor_loss": -76.32981489562988, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 431.4488573074341, "episode_reward": 629.6427415836347, "step": 26000}
{"episode": 27.0, "batch_reward": 0.45038648128509523, "actor_loss": -76.69963040161133, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.846741199493408, "episode_reward": 639.3943928189321, "step": 27000}
{"episode": 28.0, "batch_reward": 0.44988670587539675, "actor_loss": -75.74118243408203, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 434.95084524154663, "episode_reward": 426.2641328575717, "step": 28000}
{"episode": 29.0, "batch_reward": 0.4512804315090179, "actor_loss": -75.85193019104004, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.547653198242188, "episode_reward": 415.12313551349297, "step": 29000}
{"episode": 30.0, "batch_reward": 0.44152519190311434, "actor_loss": -75.39976135253906, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 455.1228675842285, "episode_reward": 15.33864084480845, "step": 30000}
{"episode": 31.0, "batch_reward": 0.43093756872415545, "actor_loss": -74.91003225708008, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 40.974244594573975, "episode_reward": 135.09802179220043, "step": 31000}
{"episode": 32.0, "batch_reward": 0.41819999051094053, "actor_loss": -74.06445297241211, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 457.7020814418793, "episode_reward": 15.72822061561939, "step": 32000}
{"episode": 33.0, "batch_reward": 0.41452878528833387, "actor_loss": -73.81648529052734, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.588900566101074, "episode_reward": 545.7839029046726, "step": 33000}
{"episode": 34.0, "batch_reward": 0.42110170498490335, "actor_loss": -74.07872019958496, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 461.9605481624603, "episode_reward": 685.2466373738225, "step": 34000}
{"episode": 35.0, "batch_reward": 0.41887995395064354, "actor_loss": -74.04834739685059, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.55855131149292, "episode_reward": 32.801448460720316, "step": 35000}
{"episode": 36.0, "batch_reward": 0.41685559758543966, "actor_loss": -74.51332426452636, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 455.14218759536743, "episode_reward": 698.1223173047846, "step": 36000}
{"episode": 37.0, "batch_reward": 0.4248152639567852, "actor_loss": -74.74227558898926, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.21248722076416, "episode_reward": 595.1605073018177, "step": 37000}
{"episode": 38.0, "batch_reward": 0.4200130851566792, "actor_loss": -74.02936433410645, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 456.19392466545105, "episode_reward": 55.56273239689405, "step": 38000}
{"episode": 39.0, "batch_reward": 0.4186789262890816, "actor_loss": -73.9183896331787, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.8642635345459, "episode_reward": 428.54863970955984, "step": 39000}
{"episode": 40.0, "batch_reward": 0.42225601950287817, "actor_loss": -73.29919163513183, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 460.78691840171814, "episode_reward": 723.192930306646, "step": 40000}
{"episode": 41.0, "batch_reward": 0.42340656244754793, "actor_loss": -73.52042443847657, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 43.80702066421509, "episode_reward": 533.1614251801067, "step": 41000}
{"episode": 42.0, "batch_reward": 0.4290861929655075, "actor_loss": -72.93701527404785, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 447.0013258457184, "episode_reward": 616.2928783065835, "step": 42000}
{"episode": 43.0, "batch_reward": 0.43500507992506027, "actor_loss": -73.19743078613281, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.048259496688843, "episode_reward": 502.06704883968104, "step": 43000}
{"episode": 44.0, "batch_reward": 0.4372768326997757, "actor_loss": -73.24738792419434, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 462.50320982933044, "episode_reward": 706.4551711730444, "step": 44000}
{"episode": 45.0, "batch_reward": 0.4430719327628613, "actor_loss": -73.49008390808106, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.5555477142334, "episode_reward": 750.1856714393417, "step": 45000}
{"episode": 46.0, "batch_reward": 0.44948795181512835, "actor_loss": -73.16384671020508, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 461.40400195121765, "episode_reward": 726.9346257394209, "step": 46000}
{"episode": 47.0, "batch_reward": 0.4559077863395214, "actor_loss": -73.43461044311523, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.127166271209717, "episode_reward": 733.8550916310716, "step": 47000}
{"episode": 48.0, "batch_reward": 0.4610065909028053, "actor_loss": -72.82963305664063, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 455.72762966156006, "episode_reward": 689.1092484033322, "step": 48000}
{"episode": 49.0, "batch_reward": 0.4642643149793148, "actor_loss": -73.04700776672364, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.833958864212036, "episode_reward": 714.9938479438922, "step": 49000}
{"episode": 50.0, "batch_reward": 0.4701773332953453, "actor_loss": -72.5642137298584, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 440.9157073497772, "episode_reward": 723.9572093928563, "step": 50000}
{"episode": 51.0, "batch_reward": 0.47518350365757944, "actor_loss": -72.84065684509277, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 37.17745280265808, "episode_reward": 607.4496964674424, "step": 51000}
{"episode": 52.0, "batch_reward": 0.47827145165205004, "actor_loss": -72.48120101928711, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 456.09779930114746, "episode_reward": 770.1413961407258, "step": 52000}
{"episode": 53.0, "batch_reward": 0.4857334086298943, "actor_loss": -72.70244761657715, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.642828941345215, "episode_reward": 793.7888155059336, "step": 53000}
{"episode": 54.0, "batch_reward": 0.49074684152007103, "actor_loss": -71.81343083190917, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 464.6605236530304, "episode_reward": 657.0509839184288, "step": 54000}
{"episode": 55.0, "batch_reward": 0.489905920624733, "actor_loss": -71.80282177734375, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.05021834373474, "episode_reward": 758.8027001104352, "step": 55000}
{"episode": 56.0, "batch_reward": 0.49670765292644503, "actor_loss": -70.76493070983886, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 457.79369139671326, "episode_reward": 698.588069809725, "step": 56000}
{"episode": 57.0, "batch_reward": 0.5022123094499111, "actor_loss": -71.00491789245605, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.650025844573975, "episode_reward": 786.2969340639643, "step": 57000}
{"episode": 58.0, "batch_reward": 0.5028495422899723, "actor_loss": -70.7492710723877, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 453.7304165363312, "episode_reward": 542.1692874307992, "step": 58000}
{"episode": 59.0, "batch_reward": 0.5059894733130932, "actor_loss": -70.79244883728028, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.380045175552368, "episode_reward": 821.3132527354746, "step": 59000}
{"episode": 60.0, "batch_reward": 0.5117490776777267, "actor_loss": -70.87855612182616, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 456.3803617954254, "episode_reward": 795.900803396106, "step": 60000}
{"episode": 61.0, "batch_reward": 0.5172098489999771, "actor_loss": -71.02055546569824, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 39.59141445159912, "episode_reward": 773.1248095645401, "step": 61000}
{"episode": 62.0, "batch_reward": 0.5214087843000889, "actor_loss": -70.81210551452637, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 459.9922721385956, "episode_reward": 765.0216929458538, "step": 62000}
{"episode": 63.0, "batch_reward": 0.5233566614091396, "actor_loss": -71.10477229309082, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.8623149394989, "episode_reward": 751.2277204058388, "step": 63000}
{"episode": 64.0, "batch_reward": 0.5299917365610599, "actor_loss": -70.77905436706543, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 464.61279368400574, "episode_reward": 828.954878779763, "step": 64000}
{"episode": 65.0, "batch_reward": 0.5310115150809288, "actor_loss": -70.85401557922363, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.116636753082275, "episode_reward": 564.0552768957197, "step": 65000}
{"episode": 66.0, "batch_reward": 0.5322785849869252, "actor_loss": -70.27378895568847, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 459.99861001968384, "episode_reward": 741.1886000034153, "step": 66000}
{"episode": 67.0, "batch_reward": 0.53867451313138, "actor_loss": -70.59431315612792, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.53236484527588, "episode_reward": 760.5258449728997, "step": 67000}
{"episode": 68.0, "batch_reward": 0.5403667689561844, "actor_loss": -70.77850421142578, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 460.9366457462311, "episode_reward": 801.8818960981797, "step": 68000}
{"episode": 69.0, "batch_reward": 0.5433182132542134, "actor_loss": -70.86687406921386, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.433130502700806, "episode_reward": 819.9503441083579, "step": 69000}
{"episode": 70.0, "batch_reward": 0.5426879568099976, "actor_loss": -70.73311555480957, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 458.13018321990967, "episode_reward": 15.957183634172996, "step": 70000}
{"episode": 71.0, "batch_reward": 0.539465644299984, "actor_loss": -70.51456617736817, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 38.6239492893219, "episode_reward": 828.3216241852003, "step": 71000}
{"episode": 72.0, "batch_reward": 0.5455852897763253, "actor_loss": -70.65708676147462, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 458.74281311035156, "episode_reward": 868.1605921123357, "step": 72000}
{"episode": 73.0, "batch_reward": 0.5484972619116306, "actor_loss": -70.76698788452148, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.525851249694824, "episode_reward": 844.0755658143718, "step": 73000}
{"episode": 74.0, "batch_reward": 0.5512635608911515, "actor_loss": -70.77492463684082, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 454.9352207183838, "episode_reward": 850.8010917589494, "step": 74000}
{"episode": 75.0, "batch_reward": 0.5579568801522254, "actor_loss": -70.95701638793945, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.005590438842773, "episode_reward": 829.3021515927181, "step": 75000}
{"episode": 76.0, "batch_reward": 0.5591887329220772, "actor_loss": -71.36152281188964, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 456.50546979904175, "episode_reward": 784.2006452605187, "step": 76000}
{"episode": 77.0, "batch_reward": 0.5646878656446934, "actor_loss": -71.61902561950684, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.881041049957275, "episode_reward": 871.1466485039971, "step": 77000}
{"episode": 78.0, "batch_reward": 0.5620421957373619, "actor_loss": -71.82329895019531, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 461.16805958747864, "episode_reward": 83.11762267802735, "step": 78000}
{"episode": 79.0, "batch_reward": 0.5630406869351864, "actor_loss": -71.7989421081543, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.778027057647705, "episode_reward": 889.4309315203782, "step": 79000}
{"episode": 80.0, "batch_reward": 0.5651591835021973, "actor_loss": -71.53648818969727, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 456.02621054649353, "episode_reward": 814.1753756522425, "step": 80000}
{"episode": 81.0, "batch_reward": 0.569043914437294, "actor_loss": -71.69839549255371, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.17667317390442, "episode_reward": 805.2399401612352, "step": 81000}
{"episode": 82.0, "batch_reward": 0.5708667013049126, "actor_loss": -71.72119364929199, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 455.0637686252594, "episode_reward": 765.2885875149942, "step": 82000}
{"episode": 83.0, "batch_reward": 0.570720600694418, "actor_loss": -71.85855216979981, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.414300441741943, "episode_reward": 23.403626749669613, "step": 83000}
{"episode": 84.0, "batch_reward": 0.566549730449915, "actor_loss": -71.71659410095215, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 457.5866451263428, "episode_reward": 871.6982448826551, "step": 84000}
{"episode": 85.0, "batch_reward": 0.5669611792862416, "actor_loss": -71.79384686279298, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.061127185821533, "episode_reward": 89.4319302264849, "step": 85000}
{"episode": 86.0, "batch_reward": 0.5662629953920841, "actor_loss": -72.48373497009277, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 463.98078632354736, "episode_reward": 853.6738962055914, "step": 86000}
{"episode": 87.0, "batch_reward": 0.5688293423056603, "actor_loss": -72.63667175292969, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.02498745918274, "episode_reward": 829.6165501172571, "step": 87000}
{"episode": 88.0, "batch_reward": 0.5715832658410073, "actor_loss": -72.18000952148438, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 466.91374135017395, "episode_reward": 798.4851299137033, "step": 88000}
{"episode": 89.0, "batch_reward": 0.5743050723969937, "actor_loss": -72.36304275512695, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.99787926673889, "episode_reward": 875.4439725359344, "step": 89000}
{"episode": 90.0, "batch_reward": 0.5779621793329716, "actor_loss": -72.31505145263672, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 462.2858462333679, "episode_reward": 745.9958315009687, "step": 90000}
{"episode": 91.0, "batch_reward": 0.5796248123943806, "actor_loss": -72.31107466125488, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 40.5564649105072, "episode_reward": 861.8839089062664, "step": 91000}
{"episode": 92.0, "batch_reward": 0.5815816512107849, "actor_loss": -72.57616317749023, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 450.65500593185425, "episode_reward": 892.2729512042945, "step": 92000}
{"episode": 93.0, "batch_reward": 0.5858534778952599, "actor_loss": -72.8524637298584, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.972972869873047, "episode_reward": 900.5461359534212, "step": 93000}
{"episode": 94.0, "batch_reward": 0.5871206825077534, "actor_loss": -72.71405535888672, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 458.5996742248535, "episode_reward": 741.2126645303671, "step": 94000}
{"episode": 95.0, "batch_reward": 0.5918284968733788, "actor_loss": -72.91538877868652, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.640599727630615, "episode_reward": 834.052123988708, "step": 95000}
{"episode": 96.0, "batch_reward": 0.5930121288001537, "actor_loss": -73.28353625488282, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 460.56428623199463, "episode_reward": 926.8268609251327, "step": 96000}
{"episode": 97.0, "batch_reward": 0.6004837902188301, "actor_loss": -73.66502835083008, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.458167791366577, "episode_reward": 867.5093737119781, "step": 97000}
{"episode": 98.0, "batch_reward": 0.5997103420197963, "actor_loss": -73.09284727478027, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 462.02039408683777, "episode_reward": 873.4584841629799, "step": 98000}
{"episode": 99.0, "batch_reward": 0.6034152368307114, "actor_loss": -73.27302790832519, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.40988302230835, "episode_reward": 853.8603733085596, "step": 99000}
{"episode": 100.0, "batch_reward": 0.6049761917591095, "actor_loss": -73.72284684753419, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 458.5018365383148, "episode_reward": 803.0295995425583, "step": 100000}
{"episode": 101.0, "batch_reward": 0.6048713456094265, "actor_loss": -73.64655587768554, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.598249435424805, "episode_reward": 475.7506545919817, "step": 101000}
{"episode": 102.0, "batch_reward": 0.6049363608658314, "actor_loss": -73.97339324951172, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 458.1363308429718, "episode_reward": 812.7319197422328, "step": 102000}
{"episode": 103.0, "batch_reward": 0.6093510901927948, "actor_loss": -74.15036050415038, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.8352210521698, "episode_reward": 901.3923784668638, "step": 103000}
{"episode": 104.0, "batch_reward": 0.6098972278237342, "actor_loss": -74.61256246948243, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 460.4406337738037, "episode_reward": 860.4930756529488, "step": 104000}
{"episode": 105.0, "batch_reward": 0.6120722905397415, "actor_loss": -74.53928161621094, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.495869159698486, "episode_reward": 841.8314021437637, "step": 105000}
{"episode": 106.0, "batch_reward": 0.6153359661698341, "actor_loss": -74.56123141479492, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 456.6311469078064, "episode_reward": 888.863620247637, "step": 106000}
{"episode": 107.0, "batch_reward": 0.6180466228127479, "actor_loss": -74.6249217529297, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.847675561904907, "episode_reward": 889.930121139677, "step": 107000}
{"episode": 108.0, "batch_reward": 0.621254208624363, "actor_loss": -74.83950393676758, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 459.7167811393738, "episode_reward": 939.782668742645, "step": 108000}
{"episode": 109.0, "batch_reward": 0.623913473546505, "actor_loss": -75.04543142700196, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.443392038345337, "episode_reward": 875.6501723021698, "step": 109000}
{"episode": 110.0, "batch_reward": 0.62496999001503, "actor_loss": -75.25769525146484, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 465.12430000305176, "episode_reward": 835.418545833227, "step": 110000}
{"episode": 111.0, "batch_reward": 0.6264431758522987, "actor_loss": -75.30346446228027, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.178778648376465, "episode_reward": 884.128492688057, "step": 111000}
{"episode": 112.0, "batch_reward": 0.6288828561902047, "actor_loss": -75.29434214782715, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 453.8496196269989, "episode_reward": 853.6844740954675, "step": 112000}
{"episode": 113.0, "batch_reward": 0.6323294966220856, "actor_loss": -75.40331489562988, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.646910190582275, "episode_reward": 857.0643867512179, "step": 113000}
{"episode": 114.0, "batch_reward": 0.6334992024898529, "actor_loss": -75.71236729431152, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 456.3349554538727, "episode_reward": 839.497946938532, "step": 114000}
{"episode": 115.0, "batch_reward": 0.636691166639328, "actor_loss": -75.87365145874024, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.828396797180176, "episode_reward": 762.9077341281155, "step": 115000}
{"episode": 116.0, "batch_reward": 0.6378198531270027, "actor_loss": -75.57326521301269, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 467.852098941803, "episode_reward": 970.102296845833, "step": 116000}
{"episode": 117.0, "batch_reward": 0.6404497894048691, "actor_loss": -75.7793406982422, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.597939252853394, "episode_reward": 868.6057241794364, "step": 117000}
{"episode": 118.0, "batch_reward": 0.6407689579725265, "actor_loss": -75.63455349731446, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 450.4313416481018, "episode_reward": 818.3439434939089, "step": 118000}
{"episode": 119.0, "batch_reward": 0.6428553766608238, "actor_loss": -75.68265444946289, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.931626796722412, "episode_reward": 948.4122543170599, "step": 119000}
{"episode": 120.0, "batch_reward": 0.6459142036437988, "actor_loss": -75.86243406677247, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 462.4511630535126, "episode_reward": 867.0061662422681, "step": 120000}
{"episode": 121.0, "batch_reward": 0.6478592761158943, "actor_loss": -75.93441059875488, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.628960609436035, "episode_reward": 946.4486266744096, "step": 121000}
{"episode": 122.0, "batch_reward": 0.6500842267274857, "actor_loss": -75.94719364929199, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 463.7554450035095, "episode_reward": 860.5664438013971, "step": 122000}
{"episode": 123.0, "batch_reward": 0.649829264998436, "actor_loss": -76.17214123535156, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.433191061019897, "episode_reward": 908.6119067119157, "step": 123000}
{"episode": 124.0, "batch_reward": 0.6533603184223175, "actor_loss": -76.2663441619873, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 464.2225670814514, "episode_reward": 775.7255093571475, "step": 124000}
{"episode": 125.0, "batch_reward": 0.6545487753152848, "actor_loss": -76.31582400512696, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.395840883255005, "episode_reward": 843.3415339595398, "step": 125000}
{"episode": 126.0, "batch_reward": 0.6565174779891968, "actor_loss": -76.64195542907714, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 459.04696893692017, "episode_reward": 911.1278987350009, "step": 126000}
{"episode": 127.0, "batch_reward": 0.6569706689715386, "actor_loss": -76.72026988220215, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.75002884864807, "episode_reward": 834.4143611176303, "step": 127000}
{"episode": 128.0, "batch_reward": 0.6590551879405976, "actor_loss": -77.12036497497559, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 466.2349169254303, "episode_reward": 781.149201729725, "step": 128000}
{"episode": 129.0, "batch_reward": 0.6601354001164437, "actor_loss": -77.10445881652832, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.50517702102661, "episode_reward": 839.3129523804234, "step": 129000}
{"episode": 130.0, "batch_reward": 0.6615035039186478, "actor_loss": -77.42868789672852, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 471.4042389392853, "episode_reward": 869.3670812192134, "step": 130000}
{"episode": 131.0, "batch_reward": 0.6619797620177269, "actor_loss": -77.37624118041992, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 40.62577247619629, "episode_reward": 866.130663945808, "step": 131000}
{"episode": 132.0, "batch_reward": 0.6637321531772613, "actor_loss": -77.42302058410644, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 467.13486433029175, "episode_reward": 842.4531318528453, "step": 132000}
{"episode": 133.0, "batch_reward": 0.6669691351652145, "actor_loss": -77.59501335144043, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.084524393081665, "episode_reward": 907.0379349212682, "step": 133000}
{"episode": 134.0, "batch_reward": 0.6700009688735008, "actor_loss": -77.76827732849121, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 465.67228627204895, "episode_reward": 887.0323242427525, "step": 134000}
{"episode": 135.0, "batch_reward": 0.6698675698637963, "actor_loss": -77.70335778808594, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.906569480895996, "episode_reward": 896.05958541336, "step": 135000}
{"episode": 136.0, "batch_reward": 0.6724613953828812, "actor_loss": -77.87273818969726, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 460.533185005188, "episode_reward": 823.90165663977, "step": 136000}
{"episode": 137.0, "batch_reward": 0.6729127134084701, "actor_loss": -77.82584700012207, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.22342085838318, "episode_reward": 876.8296903182464, "step": 137000}
{"episode": 138.0, "batch_reward": 0.6737363471388816, "actor_loss": -78.50389781188964, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 458.954199552536, "episode_reward": 810.1771226211937, "step": 138000}
{"episode": 139.0, "batch_reward": 0.674584898352623, "actor_loss": -78.5526036529541, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.94699501991272, "episode_reward": 566.6660055758448, "step": 139000}
{"episode": 140.0, "batch_reward": 0.6737953897118568, "actor_loss": -79.55384010314941, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 466.2884430885315, "episode_reward": 742.2156979425564, "step": 140000}
{"episode": 141.0, "batch_reward": 0.6742871704697609, "actor_loss": -79.4725246887207, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 36.97446131706238, "episode_reward": 814.3676761004491, "step": 141000}
{"episode": 142.0, "batch_reward": 0.6748308013677597, "actor_loss": -79.69713583374023, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 421.5554533004761, "episode_reward": 818.9412593955518, "step": 142000}
{"episode": 143.0, "batch_reward": 0.6772193783521652, "actor_loss": -79.89535084533692, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.512574195861816, "episode_reward": 793.2286690665804, "step": 143000}
{"episode": 144.0, "batch_reward": 0.676091891348362, "actor_loss": -80.40663467407227, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 438.870938539505, "episode_reward": 738.7336162876168, "step": 144000}
{"episode": 145.0, "batch_reward": 0.678427252292633, "actor_loss": -80.47974757385253, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.32299041748047, "episode_reward": 810.6475080672333, "step": 145000}
{"episode": 146.0, "batch_reward": 0.679696733891964, "actor_loss": -80.50582061767578, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 432.138498544693, "episode_reward": 766.8651812990917, "step": 146000}
{"episode": 147.0, "batch_reward": 0.6790781996846199, "actor_loss": -80.48447610473633, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.91199278831482, "episode_reward": 824.7359157447362, "step": 147000}
{"episode": 148.0, "batch_reward": 0.6798533419966698, "actor_loss": -80.34541740417481, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 426.1368064880371, "episode_reward": 807.4056616677573, "step": 148000}
{"episode": 149.0, "batch_reward": 0.679088822722435, "actor_loss": -80.44305453491211, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.08539342880249, "episode_reward": 762.5747267017534, "step": 149000}
{"episode": 150.0, "batch_reward": 0.6818330209851265, "actor_loss": -80.26469941711426, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "step": 150000}
