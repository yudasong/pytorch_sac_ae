{"episode_reward": 0.0, "episode": 1.0, "duration": 22.101553440093994, "step": 1000}
{"episode_reward": 28.002640152663393, "episode": 2.0, "duration": 1.9125185012817383, "step": 2000}
{"episode_reward": 481.4321918933315, "episode": 3.0, "batch_reward": 0.2603595951282012, "critic_loss": 0.6380567110555694, "actor_loss": -84.29146752389921, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 69.36468505859375, "step": 3000}
{"episode_reward": 399.41058922495387, "episode": 4.0, "batch_reward": 0.3314250589311123, "critic_loss": 1.012251573562622, "actor_loss": -85.68519207763671, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.12309741973877, "step": 4000}
{"episode_reward": 478.28072024724065, "episode": 5.0, "batch_reward": 0.34950159123539926, "critic_loss": 1.177643926680088, "actor_loss": -86.1475754699707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.101796865463257, "step": 5000}
{"episode_reward": 328.65261770720696, "episode": 6.0, "batch_reward": 0.3520320420265198, "critic_loss": 1.103477836549282, "actor_loss": -85.01057347106934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.131880044937134, "step": 6000}
{"episode_reward": 352.46018379066896, "episode": 7.0, "batch_reward": 0.35884766548871994, "critic_loss": 1.2280166690349579, "actor_loss": -83.64967190551758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.36183476448059, "step": 7000}
{"episode_reward": 574.3905722664102, "episode": 8.0, "batch_reward": 0.3838264022469521, "critic_loss": 1.3130215290784837, "actor_loss": -83.2873517150879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.076172351837158, "step": 8000}
{"episode_reward": 454.6055541951394, "episode": 9.0, "batch_reward": 0.3975632123053074, "critic_loss": 1.4334723649024963, "actor_loss": -82.95294264221191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.05595827102661, "step": 9000}
{"episode_reward": 575.8668382882447, "episode": 10.0, "batch_reward": 0.4099666047990322, "critic_loss": 1.3545296303629875, "actor_loss": -82.60186299133301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.01455283164978, "step": 10000}
{"episode_reward": 351.7629250600637, "episode": 11.0, "batch_reward": 0.4087849372625351, "critic_loss": 1.2383801286816598, "actor_loss": -81.7583006439209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.643784284591675, "step": 11000}
{"episode_reward": 596.9356167354492, "episode": 12.0, "batch_reward": 0.4298520699739456, "critic_loss": 1.233167225420475, "actor_loss": -81.7904951324463, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.559139251708984, "step": 12000}
{"episode_reward": 546.5509297182944, "episode": 13.0, "batch_reward": 0.42768814659118654, "critic_loss": 1.2299431411027908, "actor_loss": -81.0679353942871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.212530612945557, "step": 13000}
{"episode_reward": 268.3633933886697, "episode": 14.0, "batch_reward": 0.42984337654709814, "critic_loss": 1.2880860516428947, "actor_loss": -80.66307887268066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.194589138031006, "step": 14000}
{"episode_reward": 758.0351890562175, "episode": 15.0, "batch_reward": 0.44888443771004677, "critic_loss": 1.4699959251880645, "actor_loss": -81.23910621643067, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.18429660797119, "step": 15000}
{"episode_reward": 675.2619503161684, "episode": 16.0, "batch_reward": 0.46094782850146293, "critic_loss": 1.5771580966114997, "actor_loss": -81.09416801452636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.18273949623108, "step": 16000}
{"episode_reward": 667.9238582650728, "episode": 17.0, "batch_reward": 0.4768557656407356, "critic_loss": 1.5965350198149681, "actor_loss": -81.00393113708496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.206000566482544, "step": 17000}
{"episode_reward": 668.4909925804827, "episode": 18.0, "batch_reward": 0.4883615169525147, "critic_loss": 1.6430586851835252, "actor_loss": -80.97661024475097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.225067853927612, "step": 18000}
{"episode_reward": 772.0270620017957, "episode": 19.0, "batch_reward": 0.5043083491027355, "critic_loss": 1.6602133543491364, "actor_loss": -81.01688081359863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.13702654838562, "step": 19000}
{"episode_reward": 810.5254733242558, "episode": 20.0, "batch_reward": 0.522227672457695, "critic_loss": 1.648037803888321, "actor_loss": -81.91722129821777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.194949626922607, "step": 20000}
{"episode_reward": 852.7206784947463, "episode": 21.0, "batch_reward": 0.5401359300017357, "critic_loss": 1.6822855710983275, "actor_loss": -81.16839581298828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.854127645492554, "step": 21000}
{"episode_reward": 854.9435519940082, "episode": 22.0, "batch_reward": 0.5536103901863099, "critic_loss": 1.5797693250775338, "actor_loss": -82.49000788879394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.203641891479492, "step": 22000}
{"episode_reward": 905.2660676491586, "episode": 23.0, "batch_reward": 0.5696359440088272, "critic_loss": 1.4581492536067964, "actor_loss": -82.54771783447265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.142524480819702, "step": 23000}
{"episode_reward": 840.1457594957376, "episode": 24.0, "batch_reward": 0.5790250249803066, "critic_loss": 1.301323434829712, "actor_loss": -82.70919088745117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.184629917144775, "step": 24000}
{"episode_reward": 857.6411721373098, "episode": 25.0, "batch_reward": 0.5901260617375373, "critic_loss": 1.2444081283211708, "actor_loss": -83.20629080200196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.18208646774292, "step": 25000}
{"episode_reward": 642.5715240581693, "episode": 26.0, "batch_reward": 0.5963124787807464, "critic_loss": 1.1388426656723023, "actor_loss": -83.17389784240723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.134825468063354, "step": 26000}
{"episode_reward": 891.7917592410358, "episode": 27.0, "batch_reward": 0.6035390936732292, "critic_loss": 1.1497941234111786, "actor_loss": -83.0603420715332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.211495399475098, "step": 27000}
{"episode_reward": 852.4695341835176, "episode": 28.0, "batch_reward": 0.6174129656553269, "critic_loss": 1.1373362347483635, "actor_loss": -83.82224980163575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.1851704120636, "step": 28000}
{"episode_reward": 874.9887384953344, "episode": 29.0, "batch_reward": 0.6206911855340004, "critic_loss": 1.1234916182160377, "actor_loss": -83.8775654296875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.129501581192017, "step": 29000}
{"episode_reward": 786.5821139725725, "episode": 30.0, "batch_reward": 0.630396951854229, "critic_loss": 1.117104252576828, "actor_loss": -83.5866549987793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.09476900100708, "step": 30000}
{"episode_reward": 884.0384445788288, "episode": 31.0, "batch_reward": 0.6386982722282409, "critic_loss": 1.1124251049757004, "actor_loss": -84.22439147949218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.805700063705444, "step": 31000}
{"episode_reward": 910.2030553534427, "episode": 32.0, "batch_reward": 0.6461847333312034, "critic_loss": 1.087614040017128, "actor_loss": -84.95355337524414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.176259994506836, "step": 32000}
{"episode_reward": 819.249691956879, "episode": 33.0, "batch_reward": 0.6513053585290909, "critic_loss": 1.0388254283070564, "actor_loss": -84.82526455688476, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.154714584350586, "step": 33000}
{"episode_reward": 929.8150030772792, "episode": 34.0, "batch_reward": 0.6616035500764846, "critic_loss": 1.0397017473578454, "actor_loss": -84.55169143676758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.141706943511963, "step": 34000}
{"episode_reward": 858.1759642349606, "episode": 35.0, "batch_reward": 0.6673798435330391, "critic_loss": 1.0649014536738395, "actor_loss": -85.08886972045899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.132204294204712, "step": 35000}
{"episode_reward": 920.9003853533369, "episode": 36.0, "batch_reward": 0.6732866997718812, "critic_loss": 1.0096793028116227, "actor_loss": -85.34978378295898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.158987045288086, "step": 36000}
{"episode_reward": 915.642188817505, "episode": 37.0, "batch_reward": 0.681346513569355, "critic_loss": 0.9704891342520714, "actor_loss": -85.0906443786621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.140222311019897, "step": 37000}
{"episode_reward": 967.9130024595279, "episode": 38.0, "batch_reward": 0.6889969065785408, "critic_loss": 0.9299960994720459, "actor_loss": -85.54532398986817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.111674785614014, "step": 38000}
{"episode_reward": 932.1474822173551, "episode": 39.0, "batch_reward": 0.6945009651780129, "critic_loss": 0.9565619016885758, "actor_loss": -85.61480805969238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.087790966033936, "step": 39000}
{"episode_reward": 922.3206516137327, "episode": 40.0, "batch_reward": 0.7021280529499054, "critic_loss": 0.9224770411252975, "actor_loss": -85.90125158691406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.053146839141846, "step": 40000}
{"episode_reward": 978.8674347278378, "episode": 41.0, "batch_reward": 0.7063186621665954, "critic_loss": 0.905129999935627, "actor_loss": -85.87303549194336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.68358826637268, "step": 41000}
{"episode_reward": 934.4905801077894, "episode": 42.0, "batch_reward": 0.7123477471470833, "critic_loss": 0.9036299262344837, "actor_loss": -86.31132411193848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.034091472625732, "step": 42000}
{"episode_reward": 904.5110229377855, "episode": 43.0, "batch_reward": 0.7177750130295754, "critic_loss": 0.8983026117682457, "actor_loss": -87.00661235046387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.468790292739868, "step": 43000}
{"episode_reward": 969.410970807533, "episode": 44.0, "batch_reward": 0.7217098544239998, "critic_loss": 0.8714329714179039, "actor_loss": -87.61212176513672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.152702569961548, "step": 44000}
{"episode_reward": 758.2702015741527, "episode": 45.0, "batch_reward": 0.7241847841739655, "critic_loss": 0.896295554459095, "actor_loss": -87.40809510803223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.172641038894653, "step": 45000}
{"episode_reward": 946.8022734256904, "episode": 46.0, "batch_reward": 0.7270180946588516, "critic_loss": 0.9608551578223705, "actor_loss": -87.50705560302734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.205899238586426, "step": 46000}
{"episode_reward": 904.2680414686434, "episode": 47.0, "batch_reward": 0.7324235457777977, "critic_loss": 0.8861812044084072, "actor_loss": -88.03060275268555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.176332473754883, "step": 47000}
{"episode_reward": 948.249598190575, "episode": 48.0, "batch_reward": 0.7378627909421921, "critic_loss": 0.8598299014568329, "actor_loss": -88.19927026367188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.180988788604736, "step": 48000}
{"episode_reward": 954.3224203259591, "episode": 49.0, "batch_reward": 0.7422722018361092, "critic_loss": 0.7551795545518398, "actor_loss": -88.77533308410645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.16246509552002, "step": 49000}
{"episode_reward": 931.8153216506304, "episode": 50.0, "batch_reward": 0.7447509171962738, "critic_loss": 0.7198569658696652, "actor_loss": -88.45185484313964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.14718198776245, "step": 50000}
{"episode_reward": 902.7973814091051, "episode": 51.0, "batch_reward": 0.7404793626666069, "critic_loss": 0.7095514783263206, "actor_loss": -88.10477078247071, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.81966423988342, "step": 51000}
{"episode_reward": 15.591115791641469, "episode": 52.0, "batch_reward": 0.7344788290858268, "critic_loss": 0.7026268556714058, "actor_loss": -87.97484712219239, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.167896270751953, "step": 52000}
{"episode_reward": 941.6458435348874, "episode": 53.0, "batch_reward": 0.7366580562591553, "critic_loss": 0.7429328285455704, "actor_loss": -88.51397032165528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.19173812866211, "step": 53000}
{"episode_reward": 899.1746641217028, "episode": 54.0, "batch_reward": 0.7416189489960671, "critic_loss": 0.7250730218291283, "actor_loss": -88.79390075683594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.136609077453613, "step": 54000}
{"episode_reward": 944.9646230212327, "episode": 55.0, "batch_reward": 0.7427855191230774, "critic_loss": 0.741603939473629, "actor_loss": -88.31422773742676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.151844024658203, "step": 55000}
{"episode_reward": 924.0647363160291, "episode": 56.0, "batch_reward": 0.7484167352318764, "critic_loss": 0.7396959248483181, "actor_loss": -88.65510218811035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.218926191329956, "step": 56000}
{"episode_reward": 904.4813410695455, "episode": 57.0, "batch_reward": 0.7506512577533722, "critic_loss": 0.7447738346159458, "actor_loss": -88.60377635192872, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.145638942718506, "step": 57000}
{"episode_reward": 941.9932414264603, "episode": 58.0, "batch_reward": 0.7530859594941139, "critic_loss": 0.7335856181979179, "actor_loss": -89.13021531677246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.165939807891846, "step": 58000}
{"episode_reward": 905.1982582787463, "episode": 59.0, "batch_reward": 0.7581487180590629, "critic_loss": 0.7322892702519893, "actor_loss": -89.1016565246582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.166879892349243, "step": 59000}
{"episode_reward": 944.8640490119193, "episode": 60.0, "batch_reward": 0.7590538979172706, "critic_loss": 0.727874381273985, "actor_loss": -89.40146192932129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.094852685928345, "step": 60000}
{"episode_reward": 925.3594225646817, "episode": 61.0, "batch_reward": 0.76405121332407, "critic_loss": 0.7466994211673736, "actor_loss": -89.19263786315918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.724178314208984, "step": 61000}
{"episode_reward": 940.4498349487433, "episode": 62.0, "batch_reward": 0.7668894826769829, "critic_loss": 0.7612282481789588, "actor_loss": -89.86276597595214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.181318283081055, "step": 62000}
{"episode_reward": 932.1108532739306, "episode": 63.0, "batch_reward": 0.7684602598547936, "critic_loss": 0.7558508307039737, "actor_loss": -89.37470806884765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.14021325111389, "step": 63000}
{"episode_reward": 956.8938305414728, "episode": 64.0, "batch_reward": 0.7707868450880051, "critic_loss": 0.7288135511875152, "actor_loss": -89.87799647521973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.160154819488525, "step": 64000}
{"episode_reward": 897.3255841907525, "episode": 65.0, "batch_reward": 0.7722046137452125, "critic_loss": 0.7300389949977398, "actor_loss": -89.81718431091309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.138111352920532, "step": 65000}
{"episode_reward": 940.625870085931, "episode": 66.0, "batch_reward": 0.775523705482483, "critic_loss": 0.7084427234530449, "actor_loss": -90.07643557739257, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.164394855499268, "step": 66000}
{"episode_reward": 941.0517990440991, "episode": 67.0, "batch_reward": 0.7788409948945045, "critic_loss": 0.7143608190119266, "actor_loss": -90.46813688659668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.14540934562683, "step": 67000}
{"episode_reward": 899.9489819660824, "episode": 68.0, "batch_reward": 0.7797650309801102, "critic_loss": 0.7289437883496285, "actor_loss": -90.55166551208497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.14127254486084, "step": 68000}
{"episode_reward": 909.2052438218344, "episode": 69.0, "batch_reward": 0.7803698800802231, "critic_loss": 0.7322060306966305, "actor_loss": -90.28197540283203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.095303535461426, "step": 69000}
{"episode_reward": 924.8907186049311, "episode": 70.0, "batch_reward": 0.7851280100345611, "critic_loss": 0.7262349623143673, "actor_loss": -90.47782331848144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.090038537979126, "step": 70000}
{"episode_reward": 947.6859251889134, "episode": 71.0, "batch_reward": 0.7857616742253304, "critic_loss": 0.7117616618573666, "actor_loss": -90.50039665222168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.69491696357727, "step": 71000}
{"episode_reward": 944.5219329009233, "episode": 72.0, "batch_reward": 0.7888266956210136, "critic_loss": 0.7132274292111397, "actor_loss": -90.66931564331054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.067567348480225, "step": 72000}
{"episode_reward": 946.1001885446709, "episode": 73.0, "batch_reward": 0.791832437157631, "critic_loss": 0.7334722673594951, "actor_loss": -90.88522122192383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.058084726333618, "step": 73000}
{"episode_reward": 907.0159637356383, "episode": 74.0, "batch_reward": 0.7922151876091957, "critic_loss": 0.75814722058177, "actor_loss": -91.133404296875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.894582509994507, "step": 74000}
{"episode_reward": 913.4682288345473, "episode": 75.0, "batch_reward": 0.7923069968819618, "critic_loss": 0.7827047864496708, "actor_loss": -91.30171061706542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.406036615371704, "step": 75000}
{"episode_reward": 922.366773900376, "episode": 76.0, "batch_reward": 0.7949224506020546, "critic_loss": 0.7767334917783737, "actor_loss": -91.27736898803711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.169849157333374, "step": 76000}
{"episode_reward": 889.9471178768107, "episode": 77.0, "batch_reward": 0.7960519073605538, "critic_loss": 0.758846752256155, "actor_loss": -91.49761505126953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.197295427322388, "step": 77000}
{"episode_reward": 944.9169115212882, "episode": 78.0, "batch_reward": 0.7981006511449814, "critic_loss": 0.715870511084795, "actor_loss": -91.41041941833497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.21978211402893, "step": 78000}
{"episode_reward": 897.0485920352068, "episode": 79.0, "batch_reward": 0.8003215611577034, "critic_loss": 0.6884563077390194, "actor_loss": -91.73279188537597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.17709183692932, "step": 79000}
{"episode_reward": 930.3478976396702, "episode": 80.0, "batch_reward": 0.8016092755198478, "critic_loss": 0.6612498828470706, "actor_loss": -91.7689144897461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.16111421585083, "step": 80000}
{"episode_reward": 959.173203836845, "episode": 81.0, "batch_reward": 0.8051405743956566, "critic_loss": 0.6714315975606442, "actor_loss": -91.88593151855468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.760926723480225, "step": 81000}
{"episode_reward": 928.7491781181901, "episode": 82.0, "batch_reward": 0.804564110159874, "critic_loss": 0.64591235268116, "actor_loss": -91.6866611480713, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.2116379737854, "step": 82000}
{"episode_reward": 909.2623433562105, "episode": 83.0, "batch_reward": 0.8063592602610588, "critic_loss": 0.6358871752917766, "actor_loss": -91.95276205444335, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.1469624042511, "step": 83000}
{"episode_reward": 941.7503373200408, "episode": 84.0, "batch_reward": 0.8084983570575714, "critic_loss": 0.6532518158257008, "actor_loss": -92.05103288269044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.172708988189697, "step": 84000}
{"episode_reward": 899.7578121145366, "episode": 85.0, "batch_reward": 0.8076361314058303, "critic_loss": 0.6544384177625179, "actor_loss": -91.85010566711426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.19827437400818, "step": 85000}
{"episode_reward": 945.783422853372, "episode": 86.0, "batch_reward": 0.8116198149323464, "critic_loss": 0.6348279750347138, "actor_loss": -92.04098147583008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.134881019592285, "step": 86000}
{"episode_reward": 964.0119380983564, "episode": 87.0, "batch_reward": 0.812738926589489, "critic_loss": 0.6209317756295204, "actor_loss": -92.21776867675781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.20466709136963, "step": 87000}
{"episode_reward": 966.7607530374883, "episode": 88.0, "batch_reward": 0.8100526388883591, "critic_loss": 0.6509705414772033, "actor_loss": -92.01282934570312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.215104579925537, "step": 88000}
{"episode_reward": 13.96553638341365, "episode": 89.0, "batch_reward": 0.804289996445179, "critic_loss": 0.6329609994292259, "actor_loss": -91.5696015625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.10207748413086, "step": 89000}
{"episode_reward": 930.8878183973476, "episode": 90.0, "batch_reward": 0.8077994467616081, "critic_loss": 0.6003269012868404, "actor_loss": -91.70699551391601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.167914628982544, "step": 90000}
{"episode_reward": 911.7571236558067, "episode": 91.0, "batch_reward": 0.8080368950366974, "critic_loss": 0.6374149358868599, "actor_loss": -91.6054695892334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.75275444984436, "step": 91000}
{"episode_reward": 948.1265960813872, "episode": 92.0, "batch_reward": 0.809486086010933, "critic_loss": 0.649340283960104, "actor_loss": -91.96540403747558, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.14762043952942, "step": 92000}
{"episode_reward": 889.7535253306029, "episode": 93.0, "batch_reward": 0.8089650812745094, "critic_loss": 0.6548822228908538, "actor_loss": -91.74333082580566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.327524185180664, "step": 93000}
{"episode_reward": 915.6796177695934, "episode": 94.0, "batch_reward": 0.8105052908062935, "critic_loss": 0.6316926617920399, "actor_loss": -92.09717698669434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.10931706428528, "step": 94000}
{"episode_reward": 910.1949277065926, "episode": 95.0, "batch_reward": 0.81309778881073, "critic_loss": 0.5850454414784908, "actor_loss": -92.3143295288086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.150203943252563, "step": 95000}
{"episode_reward": 917.0507300682216, "episode": 96.0, "batch_reward": 0.8144471406340599, "critic_loss": 0.5991534774005413, "actor_loss": -92.15182759094239, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.359230995178223, "step": 96000}
{"episode_reward": 915.5200002291853, "episode": 97.0, "batch_reward": 0.8128603724837303, "critic_loss": 0.5869374465048313, "actor_loss": -92.0750421447754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.15417194366455, "step": 97000}
{"episode_reward": 932.1127893814378, "episode": 98.0, "batch_reward": 0.8154649460315704, "critic_loss": 0.597782191157341, "actor_loss": -92.48537042236327, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.087749242782593, "step": 98000}
{"episode_reward": 879.0544868245881, "episode": 99.0, "batch_reward": 0.8171019464731216, "critic_loss": 0.598702009677887, "actor_loss": -92.43758853149414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.101483821868896, "step": 99000}
{"episode_reward": 901.7331269355379, "episode": 100.0, "batch_reward": 0.8169122587442398, "critic_loss": 0.5949312738925219, "actor_loss": -92.4100609741211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.086089372634888, "step": 100000}
{"episode_reward": 952.4752685440388, "episode": 101.0, "batch_reward": 0.8189976315498352, "critic_loss": 0.6169288999885321, "actor_loss": -92.50122201538086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.7213408946991, "step": 101000}
{"episode_reward": 901.3442711981279, "episode": 102.0, "batch_reward": 0.8178264974951744, "critic_loss": 0.6257654474675656, "actor_loss": -92.62951213073731, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.032212257385254, "step": 102000}
{"episode_reward": 738.3230501411623, "episode": 103.0, "batch_reward": 0.8183370040655136, "critic_loss": 0.6163074105679989, "actor_loss": -92.65245526123047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.096402645111084, "step": 103000}
{"episode_reward": 956.6578160472208, "episode": 104.0, "batch_reward": 0.8203489214777947, "critic_loss": 0.6247633692622184, "actor_loss": -92.56365168762207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.03607964515686, "step": 104000}
{"episode_reward": 948.3379206685739, "episode": 105.0, "batch_reward": 0.8211800783872605, "critic_loss": 0.6034535879194737, "actor_loss": -92.66818087768554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.029728174209595, "step": 105000}
{"episode_reward": 960.1604698398252, "episode": 106.0, "batch_reward": 0.8231814407110214, "critic_loss": 0.5908856884688138, "actor_loss": -92.67108236694335, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.38123846054077, "step": 106000}
{"episode_reward": 943.2184740544781, "episode": 107.0, "batch_reward": 0.8231038197278976, "critic_loss": 0.5940466329753399, "actor_loss": -92.76460494995118, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.944000482559204, "step": 107000}
{"episode_reward": 967.7397248658464, "episode": 108.0, "batch_reward": 0.8240300469994545, "critic_loss": 0.5847200282067061, "actor_loss": -93.05869784545898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.148056745529175, "step": 108000}
{"episode_reward": 925.5218550208054, "episode": 109.0, "batch_reward": 0.8264750053882599, "critic_loss": 0.5663811271041632, "actor_loss": -92.98331379699707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.161367416381836, "step": 109000}
{"episode_reward": 908.2265543351134, "episode": 110.0, "batch_reward": 0.8257883549332619, "critic_loss": 0.5838138186335564, "actor_loss": -93.07661819458008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.132872104644775, "step": 110000}
{"episode_reward": 892.3414533943043, "episode": 111.0, "batch_reward": 0.8269092266559601, "critic_loss": 0.5834961720257997, "actor_loss": -92.9316538848877, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.79432129859924, "step": 111000}
{"episode_reward": 945.4303797935752, "episode": 112.0, "batch_reward": 0.8277223007678985, "critic_loss": 0.5881036519110203, "actor_loss": -93.20903538513184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.163716793060303, "step": 112000}
{"episode_reward": 958.844246015858, "episode": 113.0, "batch_reward": 0.8307510649561882, "critic_loss": 0.5905101152062416, "actor_loss": -93.00727241516114, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.130874633789062, "step": 113000}
{"episode_reward": 961.1487561588775, "episode": 114.0, "batch_reward": 0.8309327638149262, "critic_loss": 0.6162475521713495, "actor_loss": -93.18400770568847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.16007351875305, "step": 114000}
{"episode_reward": 931.105108645366, "episode": 115.0, "batch_reward": 0.8321068195700645, "critic_loss": 0.6020131594836712, "actor_loss": -93.22987200927734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.103466272354126, "step": 115000}
{"episode_reward": 959.8694812896886, "episode": 116.0, "batch_reward": 0.8327829788327217, "critic_loss": 0.5627485693097115, "actor_loss": -93.23939183044433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.173603534698486, "step": 116000}
{"episode_reward": 951.8370375699003, "episode": 117.0, "batch_reward": 0.8345150390863418, "critic_loss": 0.5855103865265846, "actor_loss": -93.2077858428955, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.176737546920776, "step": 117000}
{"episode_reward": 922.2146218227364, "episode": 118.0, "batch_reward": 0.8340215832591057, "critic_loss": 0.5814580158442259, "actor_loss": -93.22459582519531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.122961044311523, "step": 118000}
{"episode_reward": 936.7081102662594, "episode": 119.0, "batch_reward": 0.8359191814064979, "critic_loss": 0.6042660546153784, "actor_loss": -93.25600859069824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.17957043647766, "step": 119000}
{"episode_reward": 900.8724371406952, "episode": 120.0, "batch_reward": 0.8358022934198379, "critic_loss": 0.5948289080411195, "actor_loss": -93.31828138732911, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.12515926361084, "step": 120000}
{"episode_reward": 947.2337883138222, "episode": 121.0, "batch_reward": 0.8374990789294243, "critic_loss": 0.5971493321806193, "actor_loss": -93.37695417785645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.768319845199585, "step": 121000}
{"episode_reward": 962.5699081816623, "episode": 122.0, "batch_reward": 0.8376421614289283, "critic_loss": 0.6116364959776401, "actor_loss": -93.53284619140625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.10906219482422, "step": 122000}
{"episode_reward": 863.0890328678187, "episode": 123.0, "batch_reward": 0.8389255905747414, "critic_loss": 0.5847363151609898, "actor_loss": -93.56586445617675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.120261192321777, "step": 123000}
{"episode_reward": 910.532847310222, "episode": 124.0, "batch_reward": 0.8375771362781524, "critic_loss": 0.6284078318774701, "actor_loss": -93.52831619262696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.055469751358032, "step": 124000}
{"episode_reward": 915.3798484451679, "episode": 125.0, "batch_reward": 0.8386633390784264, "critic_loss": 0.6256485052108764, "actor_loss": -93.5009654083252, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.117218255996704, "step": 125000}
{"episode_reward": 963.4970525345135, "episode": 126.0, "batch_reward": 0.8399382899403572, "critic_loss": 0.6149202063083649, "actor_loss": -93.64478680419921, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.151256561279297, "step": 126000}
{"episode_reward": 935.1101361046449, "episode": 127.0, "batch_reward": 0.8379476884007454, "critic_loss": 0.6196330086290837, "actor_loss": -93.57942012023926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.17235016822815, "step": 127000}
{"episode_reward": 60.11752316688356, "episode": 128.0, "batch_reward": 0.8340284725427628, "critic_loss": 0.604316530391574, "actor_loss": -93.40706799316406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.135783910751343, "step": 128000}
{"episode_reward": 912.7095132373028, "episode": 129.0, "batch_reward": 0.8354738518595696, "critic_loss": 0.6205098665505647, "actor_loss": -93.36776699829102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.106496334075928, "step": 129000}
{"episode_reward": 955.7830619710065, "episode": 130.0, "batch_reward": 0.8368099579215049, "critic_loss": 0.6124094634503127, "actor_loss": -93.41483361816407, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.111940622329712, "step": 130000}
{"episode_reward": 919.0985780072009, "episode": 131.0, "batch_reward": 0.8359497258663178, "critic_loss": 0.5995662633776665, "actor_loss": -93.27290913391113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.67685627937317, "step": 131000}
{"episode_reward": 958.8065479535519, "episode": 132.0, "batch_reward": 0.8379691762328147, "critic_loss": 0.5935850414484739, "actor_loss": -93.43770753479004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.08761739730835, "step": 132000}
{"episode_reward": 901.9322593496097, "episode": 133.0, "batch_reward": 0.838605298280716, "critic_loss": 0.595476954266429, "actor_loss": -93.39051094055176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.067492246627808, "step": 133000}
{"episode_reward": 966.7403674174781, "episode": 134.0, "batch_reward": 0.8385559043884278, "critic_loss": 0.6010887739062309, "actor_loss": -93.4807950592041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.054494380950928, "step": 134000}
{"episode_reward": 963.9720564563701, "episode": 135.0, "batch_reward": 0.8387932181954384, "critic_loss": 0.5852641653865576, "actor_loss": -93.59120538330077, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.02517580986023, "step": 135000}
{"episode_reward": 916.8088222014538, "episode": 136.0, "batch_reward": 0.8408375471830368, "critic_loss": 0.5724305286854505, "actor_loss": -93.64979244995118, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.07686138153076, "step": 136000}
{"episode_reward": 938.7806403547265, "episode": 137.0, "batch_reward": 0.8418943213820458, "critic_loss": 0.6001264548301697, "actor_loss": -93.61537759399414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.003409385681152, "step": 137000}
{"episode_reward": 945.74149327064, "episode": 138.0, "batch_reward": 0.8422743048071861, "critic_loss": 0.5635797378122807, "actor_loss": -93.63603912353516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.485903024673462, "step": 138000}
{"episode_reward": 945.0770702939785, "episode": 139.0, "batch_reward": 0.8417194015979766, "critic_loss": 0.5694412910044193, "actor_loss": -93.55349394226074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.153011798858643, "step": 139000}
{"episode_reward": 936.3572742875939, "episode": 140.0, "batch_reward": 0.8413037092089654, "critic_loss": 0.586524065554142, "actor_loss": -93.58903823852539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.180936813354492, "step": 140000}
{"episode_reward": 925.2045453494763, "episode": 141.0, "batch_reward": 0.8455755462050438, "critic_loss": 0.6019773123711347, "actor_loss": -93.76387384033202, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.796703815460205, "step": 141000}
{"episode_reward": 925.2123084065151, "episode": 142.0, "batch_reward": 0.8447607024312019, "critic_loss": 0.5790361654609442, "actor_loss": -93.78271955871583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.16348695755005, "step": 142000}
{"episode_reward": 886.6961943170732, "episode": 143.0, "batch_reward": 0.8445810359120369, "critic_loss": 0.6219705371558666, "actor_loss": -93.76393075561523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.163617372512817, "step": 143000}
{"episode_reward": 906.1105991872961, "episode": 144.0, "batch_reward": 0.8457517867684364, "critic_loss": 0.6024390748143196, "actor_loss": -93.81347468566895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.13988184928894, "step": 144000}
{"episode_reward": 938.515259241775, "episode": 145.0, "batch_reward": 0.847157516181469, "critic_loss": 0.591403559036553, "actor_loss": -93.91384817504883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.14715838432312, "step": 145000}
{"episode_reward": 947.5623695298375, "episode": 146.0, "batch_reward": 0.8458493168950081, "critic_loss": 0.625933742582798, "actor_loss": -93.73657389831543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.182146787643433, "step": 146000}
{"episode_reward": 927.7924473779514, "episode": 147.0, "batch_reward": 0.8456676230430603, "critic_loss": 0.6158601002842188, "actor_loss": -93.82986582946778, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.163907527923584, "step": 147000}
{"episode_reward": 960.0400974287132, "episode": 148.0, "batch_reward": 0.848364849627018, "critic_loss": 0.6067420996427536, "actor_loss": -93.88715928649903, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.186628580093384, "step": 148000}
{"episode_reward": 924.4501558206786, "episode": 149.0, "batch_reward": 0.8495745716691017, "critic_loss": 0.5729726956337691, "actor_loss": -93.91646784973145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.12207341194153, "step": 149000}
{"episode_reward": 948.7683590551932, "episode": 150.0, "batch_reward": 0.8495652555823326, "critic_loss": 0.57570421859622, "actor_loss": -93.96872787475586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
