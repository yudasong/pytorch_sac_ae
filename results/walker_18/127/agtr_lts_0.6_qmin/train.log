{"episode_reward": 0.0, "episode": 1.0, "duration": 20.985039710998535, "step": 1000}
{"episode_reward": 28.002640152663393, "episode": 2.0, "duration": 1.8159711360931396, "step": 2000}
{"episode_reward": 481.4321918933315, "episode": 3.0, "batch_reward": 0.2664294876170659, "critic_loss": 0.4672261415625183, "actor_loss": -84.08323447787318, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 59.45128631591797, "step": 3000}
{"episode_reward": 498.22604809004986, "episode": 4.0, "batch_reward": 0.3384287404716015, "critic_loss": 0.5322872676253319, "actor_loss": -84.11834764099122, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.896239519119263, "step": 4000}
{"episode_reward": 320.66808337927205, "episode": 5.0, "batch_reward": 0.3543285081088543, "critic_loss": 0.7461623195111752, "actor_loss": -83.15714865112305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.902757167816162, "step": 5000}
{"episode_reward": 543.0595957410023, "episode": 6.0, "batch_reward": 0.3917463152706623, "critic_loss": 0.8915127390027047, "actor_loss": -83.41221081542969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.908864498138428, "step": 6000}
{"episode_reward": 647.6424005203407, "episode": 7.0, "batch_reward": 0.44575749787688257, "critic_loss": 1.0733724310398103, "actor_loss": -83.53285977172851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.8907732963562, "step": 7000}
{"episode_reward": 737.3361925345067, "episode": 8.0, "batch_reward": 0.455288932710886, "critic_loss": 1.126429706454277, "actor_loss": -83.71454187011719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.888962030410767, "step": 8000}
{"episode_reward": 444.76651669080104, "episode": 9.0, "batch_reward": 0.47742093217372894, "critic_loss": 1.3497469435334206, "actor_loss": -83.91688343811035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.87312364578247, "step": 9000}
{"episode_reward": 773.6651179707425, "episode": 10.0, "batch_reward": 0.509969200283289, "critic_loss": 1.4121564866900445, "actor_loss": -84.34809704589844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.88246488571167, "step": 10000}
{"episode_reward": 771.9608537676966, "episode": 11.0, "batch_reward": 0.5285266030430794, "critic_loss": 1.4836872400045396, "actor_loss": -84.55379946899414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.52653193473816, "step": 11000}
{"episode_reward": 733.7830284220934, "episode": 12.0, "batch_reward": 0.5522847981750965, "critic_loss": 1.4167099335789681, "actor_loss": -85.10400411987305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.92020869255066, "step": 12000}
{"episode_reward": 786.9644729792776, "episode": 13.0, "batch_reward": 0.5693955923318863, "critic_loss": 1.3809183830618859, "actor_loss": -85.04132705688477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.912688732147217, "step": 13000}
{"episode_reward": 630.4466237155578, "episode": 14.0, "batch_reward": 0.5770139964818954, "critic_loss": 1.278486009657383, "actor_loss": -85.08986071777343, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.900999069213867, "step": 14000}
{"episode_reward": 828.6395004628162, "episode": 15.0, "batch_reward": 0.5875452720224857, "critic_loss": 1.336604763329029, "actor_loss": -85.70861724853516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.898115396499634, "step": 15000}
{"episode_reward": 682.5904661534561, "episode": 16.0, "batch_reward": 0.5990784511566162, "critic_loss": 1.3892887992262841, "actor_loss": -85.54569134521485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.90753698348999, "step": 16000}
{"episode_reward": 681.7332033721057, "episode": 17.0, "batch_reward": 0.6083326589465141, "critic_loss": 1.3713448920845985, "actor_loss": -85.46985218811035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.918723344802856, "step": 17000}
{"episode_reward": 883.1808479261975, "episode": 18.0, "batch_reward": 0.6216662095189095, "critic_loss": 1.3536783048510552, "actor_loss": -85.66878164672852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.917765617370605, "step": 18000}
{"episode_reward": 889.418679228499, "episode": 19.0, "batch_reward": 0.6313984549641609, "critic_loss": 1.457629079401493, "actor_loss": -85.85672213745117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.918558359146118, "step": 19000}
{"episode_reward": 745.0585110074911, "episode": 20.0, "batch_reward": 0.6369408575892448, "critic_loss": 1.5348705021739006, "actor_loss": -86.38386978149414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.904956817626953, "step": 20000}
{"episode_reward": 708.5859934052079, "episode": 21.0, "batch_reward": 0.6484525592923165, "critic_loss": 1.5611011489629745, "actor_loss": -85.55617999267578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.56094694137573, "step": 21000}
{"episode_reward": 863.2285993899764, "episode": 22.0, "batch_reward": 0.6541145308017731, "critic_loss": 1.5219939950704575, "actor_loss": -86.56944981384278, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.92060875892639, "step": 22000}
{"episode_reward": 869.9464788799968, "episode": 23.0, "batch_reward": 0.6643202497363091, "critic_loss": 1.552626285791397, "actor_loss": -86.22393040466308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.93229651451111, "step": 23000}
{"episode_reward": 838.8421643982059, "episode": 24.0, "batch_reward": 0.6738659798502922, "critic_loss": 1.4654759104847908, "actor_loss": -86.70333476257325, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.909502744674683, "step": 24000}
{"episode_reward": 933.5737707648908, "episode": 25.0, "batch_reward": 0.6853470866680145, "critic_loss": 1.459735077381134, "actor_loss": -87.29532113647461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.90905785560608, "step": 25000}
{"episode_reward": 934.5134241996794, "episode": 26.0, "batch_reward": 0.690052470266819, "critic_loss": 1.3840716151595116, "actor_loss": -87.18636389160156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.899925470352173, "step": 26000}
{"episode_reward": 858.054399733825, "episode": 27.0, "batch_reward": 0.6994967630505562, "critic_loss": 1.3816513615250587, "actor_loss": -87.06805963134765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.888669967651367, "step": 27000}
{"episode_reward": 836.9278090255307, "episode": 28.0, "batch_reward": 0.7057816362977027, "critic_loss": 1.4056955935955047, "actor_loss": -87.78173684692383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.8714656829834, "step": 28000}
{"episode_reward": 922.9851055659831, "episode": 29.0, "batch_reward": 0.7095929426550865, "critic_loss": 1.317530392765999, "actor_loss": -87.44134864807128, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.9017231464386, "step": 29000}
{"episode_reward": 839.9194502256552, "episode": 30.0, "batch_reward": 0.7184224638342858, "critic_loss": 1.2028095005750656, "actor_loss": -87.4765789642334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.90247106552124, "step": 30000}
{"episode_reward": 915.090068223889, "episode": 31.0, "batch_reward": 0.725263314306736, "critic_loss": 1.1449267727136612, "actor_loss": -87.91104483032227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.53171467781067, "step": 31000}
{"episode_reward": 918.4354030425865, "episode": 32.0, "batch_reward": 0.7284072288870811, "critic_loss": 1.0934226294755935, "actor_loss": -88.1800618133545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.99485206604004, "step": 32000}
{"episode_reward": 872.9435656074323, "episode": 33.0, "batch_reward": 0.7342387887239457, "critic_loss": 1.0154400061964988, "actor_loss": -88.23803649902344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15910005569458, "step": 33000}
{"episode_reward": 895.7030867812101, "episode": 34.0, "batch_reward": 0.7375528529286385, "critic_loss": 1.0743327859640122, "actor_loss": -88.33263766479492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.876046419143677, "step": 34000}
{"episode_reward": 776.1277654234368, "episode": 35.0, "batch_reward": 0.7412637793421746, "critic_loss": 1.0871616427898407, "actor_loss": -88.5221343536377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.852338314056396, "step": 35000}
{"episode_reward": 868.1212295966977, "episode": 36.0, "batch_reward": 0.7415315646529198, "critic_loss": 1.126973618388176, "actor_loss": -89.00504429626464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.850823163986206, "step": 36000}
{"episode_reward": 822.3060027694685, "episode": 37.0, "batch_reward": 0.7463206617236138, "critic_loss": 1.077337710916996, "actor_loss": -88.57251496887207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.878885746002197, "step": 37000}
{"episode_reward": 906.9735423191721, "episode": 38.0, "batch_reward": 0.7507966002821922, "critic_loss": 1.0360477481484414, "actor_loss": -88.71410000610352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.91532826423645, "step": 38000}
{"episode_reward": 931.5459067085843, "episode": 39.0, "batch_reward": 0.7521878356337547, "critic_loss": 1.0302402536273003, "actor_loss": -88.73829006958007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.92905044555664, "step": 39000}
{"episode_reward": 854.7745341582728, "episode": 40.0, "batch_reward": 0.7599585319161415, "critic_loss": 1.009631674170494, "actor_loss": -89.1525580291748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.880133152008057, "step": 40000}
{"episode_reward": 957.6707461540534, "episode": 41.0, "batch_reward": 0.7607136470079422, "critic_loss": 1.0038228480219842, "actor_loss": -88.75310292053223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.50683116912842, "step": 41000}
{"episode_reward": 933.7059214823523, "episode": 42.0, "batch_reward": 0.7662304680347443, "critic_loss": 0.9713514583110809, "actor_loss": -89.26659284973144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.894057035446167, "step": 42000}
{"episode_reward": 882.3343251666067, "episode": 43.0, "batch_reward": 0.7703790989518166, "critic_loss": 0.9185674777030944, "actor_loss": -89.7134984588623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.893866539001465, "step": 43000}
{"episode_reward": 963.2190154944597, "episode": 44.0, "batch_reward": 0.7727080964446068, "critic_loss": 0.9610713048577308, "actor_loss": -90.31647520446778, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.873818159103394, "step": 44000}
{"episode_reward": 856.8162105055334, "episode": 45.0, "batch_reward": 0.7767993237972259, "critic_loss": 0.9162069943547249, "actor_loss": -90.06105842590333, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.91868495941162, "step": 45000}
{"episode_reward": 941.1938791653153, "episode": 46.0, "batch_reward": 0.7780423871278763, "critic_loss": 0.9481995186209679, "actor_loss": -89.69780361938477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.922231197357178, "step": 46000}
{"episode_reward": 949.0800057227054, "episode": 47.0, "batch_reward": 0.7841561068892479, "critic_loss": 0.9362277366518974, "actor_loss": -90.10510122680664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.89905858039856, "step": 47000}
{"episode_reward": 971.9588158776245, "episode": 48.0, "batch_reward": 0.7856376436948777, "critic_loss": 1.0030191516876221, "actor_loss": -90.14359089660644, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.906793117523193, "step": 48000}
{"episode_reward": 795.6509368986739, "episode": 49.0, "batch_reward": 0.7863906955718994, "critic_loss": 1.0491736049056053, "actor_loss": -90.62031143188477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.871216535568237, "step": 49000}
{"episode_reward": 899.2968586183669, "episode": 50.0, "batch_reward": 0.7881345705389976, "critic_loss": 1.0626741948127747, "actor_loss": -90.53855462646484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.896467924118042, "step": 50000}
{"episode_reward": 834.549362884838, "episode": 51.0, "batch_reward": 0.7915067790746689, "critic_loss": 1.0665205137729645, "actor_loss": -90.53992196655274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.51138639450073, "step": 51000}
{"episode_reward": 928.797976008059, "episode": 52.0, "batch_reward": 0.7937537185549736, "critic_loss": 1.071605478465557, "actor_loss": -90.30049937438964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.90654492378235, "step": 52000}
{"episode_reward": 957.6768494072252, "episode": 53.0, "batch_reward": 0.7953137365579606, "critic_loss": 1.0683303534388542, "actor_loss": -90.78617013549805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.897207736968994, "step": 53000}
{"episode_reward": 912.5805298288949, "episode": 54.0, "batch_reward": 0.7985174522399903, "critic_loss": 1.0586853880882263, "actor_loss": -91.21108320617675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.899565935134888, "step": 54000}
{"episode_reward": 865.7740309004131, "episode": 55.0, "batch_reward": 0.7989346951246261, "critic_loss": 1.0484444954395293, "actor_loss": -90.7841261291504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.88875436782837, "step": 55000}
{"episode_reward": 942.6425023159892, "episode": 56.0, "batch_reward": 0.8016734498739243, "critic_loss": 1.0802736970484257, "actor_loss": -90.94089100646973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.885507583618164, "step": 56000}
{"episode_reward": 873.7736617507451, "episode": 57.0, "batch_reward": 0.8043133267760276, "critic_loss": 1.0286802863776683, "actor_loss": -91.07063795471191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.897595643997192, "step": 57000}
{"episode_reward": 952.0033915309349, "episode": 58.0, "batch_reward": 0.8049295886158944, "critic_loss": 0.968577977180481, "actor_loss": -91.20639353942872, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.880852937698364, "step": 58000}
{"episode_reward": 902.5308133570677, "episode": 59.0, "batch_reward": 0.8084370276331901, "critic_loss": 0.9734122190475464, "actor_loss": -91.41709657287598, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.895933151245117, "step": 59000}
{"episode_reward": 952.8337022968019, "episode": 60.0, "batch_reward": 0.8111174247264862, "critic_loss": 0.9431195002198219, "actor_loss": -91.66690896606445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.876357793807983, "step": 60000}
{"episode_reward": 966.34546885208, "episode": 61.0, "batch_reward": 0.8123923389911651, "critic_loss": 0.8940503273010254, "actor_loss": -91.36283499145507, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.50805330276489, "step": 61000}
{"episode_reward": 952.9872842884578, "episode": 62.0, "batch_reward": 0.8138183122277259, "critic_loss": 0.9318635398149491, "actor_loss": -91.81026936340332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.8814914226532, "step": 62000}
{"episode_reward": 774.6262496522895, "episode": 63.0, "batch_reward": 0.8146500964164733, "critic_loss": 0.9088469981253147, "actor_loss": -91.52685974121094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.891031503677368, "step": 63000}
{"episode_reward": 922.4434928903481, "episode": 64.0, "batch_reward": 0.8146876113414765, "critic_loss": 0.8832523582279682, "actor_loss": -91.65903665161133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.90051579475403, "step": 64000}
{"episode_reward": 873.3801219668308, "episode": 65.0, "batch_reward": 0.8163768315911293, "critic_loss": 0.9007572660148144, "actor_loss": -91.80494731140136, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.89347553253174, "step": 65000}
{"episode_reward": 918.391000603157, "episode": 66.0, "batch_reward": 0.8182859129905701, "critic_loss": 0.8839249927997589, "actor_loss": -91.78411499023437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.90862512588501, "step": 66000}
{"episode_reward": 947.0857656555044, "episode": 67.0, "batch_reward": 0.8208727273344993, "critic_loss": 0.8978191325664521, "actor_loss": -92.12645358276367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.889241933822632, "step": 67000}
{"episode_reward": 937.8087991811491, "episode": 68.0, "batch_reward": 0.822616058588028, "critic_loss": 0.9029765897095203, "actor_loss": -92.3555213470459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.872790098190308, "step": 68000}
{"episode_reward": 923.0545257148409, "episode": 69.0, "batch_reward": 0.8224278009533882, "critic_loss": 0.9020879333019256, "actor_loss": -91.93361695861816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.90666651725769, "step": 69000}
{"episode_reward": 930.7518652902156, "episode": 70.0, "batch_reward": 0.8254683824777603, "critic_loss": 0.850965552687645, "actor_loss": -92.02651119995117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.899377584457397, "step": 70000}
{"episode_reward": 947.6159138667624, "episode": 71.0, "batch_reward": 0.8265446597933769, "critic_loss": 0.8371968697309494, "actor_loss": -92.02959411621094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.65895462036133, "step": 71000}
{"episode_reward": 921.5090173309205, "episode": 72.0, "batch_reward": 0.8262701432704925, "critic_loss": 0.8422495713531971, "actor_loss": -92.22104981994629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.846054077148438, "step": 72000}
{"episode_reward": 850.883504386068, "episode": 73.0, "batch_reward": 0.8282443696856499, "critic_loss": 0.8380184386074543, "actor_loss": -92.36885012817383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.836230278015137, "step": 73000}
{"episode_reward": 884.1522305139994, "episode": 74.0, "batch_reward": 0.8298506687283516, "critic_loss": 0.8621633389890194, "actor_loss": -92.40724946594239, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.863598108291626, "step": 74000}
{"episode_reward": 924.83120257377, "episode": 75.0, "batch_reward": 0.8307460067272187, "critic_loss": 0.8414750895798206, "actor_loss": -92.44862239074708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.892004251480103, "step": 75000}
{"episode_reward": 937.000019142425, "episode": 76.0, "batch_reward": 0.8309414486289024, "critic_loss": 0.8381341525912285, "actor_loss": -92.43818559265137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.86881995201111, "step": 76000}
{"episode_reward": 869.0640336554102, "episode": 77.0, "batch_reward": 0.831000869512558, "critic_loss": 0.8567480826675892, "actor_loss": -92.5863155670166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.881757020950317, "step": 77000}
{"episode_reward": 870.3713688613128, "episode": 78.0, "batch_reward": 0.8322307676076889, "critic_loss": 0.8739677901566029, "actor_loss": -92.56929666137695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.874151468276978, "step": 78000}
{"episode_reward": 947.751600669881, "episode": 79.0, "batch_reward": 0.8352630356550217, "critic_loss": 0.8503404491245746, "actor_loss": -92.77791674804688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.898691415786743, "step": 79000}
{"episode_reward": 931.6817416595009, "episode": 80.0, "batch_reward": 0.8349544456601143, "critic_loss": 0.8313894854187965, "actor_loss": -92.88339837646484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.212828874588013, "step": 80000}
{"episode_reward": 944.1927307168752, "episode": 81.0, "batch_reward": 0.8375365286469459, "critic_loss": 0.8361646434664727, "actor_loss": -92.86789294433594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.46435332298279, "step": 81000}
{"episode_reward": 919.1874757948435, "episode": 82.0, "batch_reward": 0.8374947578907013, "critic_loss": 0.8442707230746747, "actor_loss": -92.69223344421387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.848092794418335, "step": 82000}
{"episode_reward": 937.3958740270455, "episode": 83.0, "batch_reward": 0.8402648509144783, "critic_loss": 0.8448855502307415, "actor_loss": -93.06117329406739, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.872742176055908, "step": 83000}
{"episode_reward": 913.0544885768552, "episode": 84.0, "batch_reward": 0.8399639717936516, "critic_loss": 0.8593019604086876, "actor_loss": -93.1046047668457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.882670164108276, "step": 84000}
{"episode_reward": 907.2358542629502, "episode": 85.0, "batch_reward": 0.84042521327734, "critic_loss": 0.8163715333044529, "actor_loss": -92.99749111938476, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.904918670654297, "step": 85000}
{"episode_reward": 926.2700467921437, "episode": 86.0, "batch_reward": 0.8416619061231613, "critic_loss": 0.8341663953661919, "actor_loss": -93.0139610748291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.90431833267212, "step": 86000}
{"episode_reward": 914.0386269477161, "episode": 87.0, "batch_reward": 0.8414228618741035, "critic_loss": 0.8216094850897789, "actor_loss": -93.33960244750976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.875182151794434, "step": 87000}
{"episode_reward": 918.1610480161181, "episode": 88.0, "batch_reward": 0.8435334982275963, "critic_loss": 0.8296325224339962, "actor_loss": -93.05584811401367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.89340114593506, "step": 88000}
{"episode_reward": 936.1211047229367, "episode": 89.0, "batch_reward": 0.8439428460001945, "critic_loss": 0.8087898321151733, "actor_loss": -93.00560302734375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.90432858467102, "step": 89000}
{"episode_reward": 910.2908450049921, "episode": 90.0, "batch_reward": 0.8458294451832772, "critic_loss": 0.7950509937703609, "actor_loss": -93.13380186462402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.877739429473877, "step": 90000}
{"episode_reward": 860.7892759325791, "episode": 91.0, "batch_reward": 0.8464406611323356, "critic_loss": 0.8282766660451889, "actor_loss": -93.1446220703125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.48913216590881, "step": 91000}
{"episode_reward": 943.5876311767347, "episode": 92.0, "batch_reward": 0.8462390645742416, "critic_loss": 0.7933106251358986, "actor_loss": -93.36475741577148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.89606022834778, "step": 92000}
{"episode_reward": 932.3433905048859, "episode": 93.0, "batch_reward": 0.846785367846489, "critic_loss": 0.7953587695658207, "actor_loss": -93.224416015625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.905328273773193, "step": 93000}
{"episode_reward": 924.7820754422933, "episode": 94.0, "batch_reward": 0.8475879961848259, "critic_loss": 0.8299258726835251, "actor_loss": -93.46065588378906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.88826608657837, "step": 94000}
{"episode_reward": 910.2169047985617, "episode": 95.0, "batch_reward": 0.8483248925805091, "critic_loss": 0.8414922548830509, "actor_loss": -93.70013600158691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.85371994972229, "step": 95000}
{"episode_reward": 902.0124042812721, "episode": 96.0, "batch_reward": 0.8506678276658058, "critic_loss": 0.8585563921630383, "actor_loss": -93.51587937927246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.892794132232666, "step": 96000}
{"episode_reward": 954.6006347320908, "episode": 97.0, "batch_reward": 0.8499779940843583, "critic_loss": 0.8281637679040432, "actor_loss": -93.3076217956543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.890084743499756, "step": 97000}
{"episode_reward": 965.8140777302253, "episode": 98.0, "batch_reward": 0.8509623310565948, "critic_loss": 0.7696307102739811, "actor_loss": -93.8445555419922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.861671924591064, "step": 98000}
{"episode_reward": 937.1990218992454, "episode": 99.0, "batch_reward": 0.8534450747966766, "critic_loss": 0.7520449811518193, "actor_loss": -93.56712086486816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.873661279678345, "step": 99000}
{"episode_reward": 962.4428118420186, "episode": 100.0, "batch_reward": 0.8540671336650848, "critic_loss": 0.7841334652602673, "actor_loss": -93.59050933837891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.898399829864502, "step": 100000}
{"episode_reward": 936.2578920470547, "episode": 101.0, "batch_reward": 0.8543525603413582, "critic_loss": 0.7362563650608063, "actor_loss": -93.62481507873535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.47231483459473, "step": 101000}
{"episode_reward": 949.9536980978111, "episode": 102.0, "batch_reward": 0.8549930731654167, "critic_loss": 0.8065361618995667, "actor_loss": -93.8095752105713, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.88286066055298, "step": 102000}
{"episode_reward": 794.2153638293111, "episode": 103.0, "batch_reward": 0.8542186511158943, "critic_loss": 0.8280822457671165, "actor_loss": -93.83722636413574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.883179903030396, "step": 103000}
{"episode_reward": 917.7012497755738, "episode": 104.0, "batch_reward": 0.8561438847780227, "critic_loss": 0.7996095318496227, "actor_loss": -93.70782542419434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.86719560623169, "step": 104000}
{"episode_reward": 929.8320482825164, "episode": 105.0, "batch_reward": 0.8553616802096367, "critic_loss": 0.7800140421688556, "actor_loss": -93.73874034118653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.880481004714966, "step": 105000}
{"episode_reward": 964.5847231459591, "episode": 106.0, "batch_reward": 0.8572868614792823, "critic_loss": 0.7829124255180359, "actor_loss": -93.84656961059571, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.90264391899109, "step": 106000}
{"episode_reward": 958.7484344964868, "episode": 107.0, "batch_reward": 0.8566701531410217, "critic_loss": 0.7549802406430245, "actor_loss": -93.67366535949706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.888410329818726, "step": 107000}
{"episode_reward": 751.8454507848335, "episode": 108.0, "batch_reward": 0.8568997974395752, "critic_loss": 0.7416207420527935, "actor_loss": -94.08994232177734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.89248037338257, "step": 108000}
{"episode_reward": 939.6732880450757, "episode": 109.0, "batch_reward": 0.8594129308462143, "critic_loss": 0.7541032177805901, "actor_loss": -93.94823136901856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.893918752670288, "step": 109000}
{"episode_reward": 892.0126521627709, "episode": 110.0, "batch_reward": 0.8578330075144768, "critic_loss": 0.7565005781054497, "actor_loss": -94.17441374206543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.899341583251953, "step": 110000}
{"episode_reward": 910.2850203496429, "episode": 111.0, "batch_reward": 0.8588046237230301, "critic_loss": 0.752854080170393, "actor_loss": -93.85322885131836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.495243549346924, "step": 111000}
{"episode_reward": 920.2383970615165, "episode": 112.0, "batch_reward": 0.8587164332270623, "critic_loss": 0.7842182549387217, "actor_loss": -94.15773483276367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.87047839164734, "step": 112000}
{"episode_reward": 909.9576717568664, "episode": 113.0, "batch_reward": 0.8612451303005219, "critic_loss": 0.8038234602808952, "actor_loss": -94.00061863708495, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.874266624450684, "step": 113000}
{"episode_reward": 920.593966575469, "episode": 114.0, "batch_reward": 0.8614988670349121, "critic_loss": 0.7673524092137813, "actor_loss": -94.16710563659667, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.867475271224976, "step": 114000}
{"episode_reward": 900.8248016051095, "episode": 115.0, "batch_reward": 0.8613292756080627, "critic_loss": 0.7768152469396591, "actor_loss": -94.16403541564941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.861724853515625, "step": 115000}
{"episode_reward": 915.1494481542719, "episode": 116.0, "batch_reward": 0.8604925000071526, "critic_loss": 0.8100692337155342, "actor_loss": -94.09073587036133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.894989252090454, "step": 116000}
{"episode_reward": 892.011626056835, "episode": 117.0, "batch_reward": 0.8622760761976243, "critic_loss": 0.7822757253348828, "actor_loss": -94.07548280334473, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.878260612487793, "step": 117000}
{"episode_reward": 926.5937086824573, "episode": 118.0, "batch_reward": 0.8624848689436913, "critic_loss": 0.7628619537651539, "actor_loss": -94.12300912475585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.85212755203247, "step": 118000}
{"episode_reward": 944.7577362645677, "episode": 119.0, "batch_reward": 0.8630600568652153, "critic_loss": 0.801926037311554, "actor_loss": -94.10508135986328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.862316846847534, "step": 119000}
{"episode_reward": 919.5323611958532, "episode": 120.0, "batch_reward": 0.8624860219955445, "critic_loss": 0.745985802769661, "actor_loss": -94.14382669067383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.87414813041687, "step": 120000}
{"episode_reward": 950.9013871028097, "episode": 121.0, "batch_reward": 0.8653851028680801, "critic_loss": 0.7263519539237022, "actor_loss": -94.24329846191407, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.49146628379822, "step": 121000}
{"episode_reward": 940.3429311845982, "episode": 122.0, "batch_reward": 0.86516719353199, "critic_loss": 0.7645792339742183, "actor_loss": -94.35957778930664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.891271114349365, "step": 122000}
{"episode_reward": 896.3661054941138, "episode": 123.0, "batch_reward": 0.8641942967176437, "critic_loss": 0.7715652666687965, "actor_loss": -94.32582405090332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.879939794540405, "step": 123000}
{"episode_reward": 910.3814549219873, "episode": 124.0, "batch_reward": 0.8635022644996643, "critic_loss": 0.7422401961684227, "actor_loss": -94.45339659118652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.87072205543518, "step": 124000}
{"episode_reward": 888.6502536224507, "episode": 125.0, "batch_reward": 0.8635512480735779, "critic_loss": 0.748001088052988, "actor_loss": -94.30485609436035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.86658811569214, "step": 125000}
{"episode_reward": 970.8513410189985, "episode": 126.0, "batch_reward": 0.8650412915945053, "critic_loss": 0.7313028635382652, "actor_loss": -94.41790151977538, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.863895177841187, "step": 126000}
{"episode_reward": 932.7192575487416, "episode": 127.0, "batch_reward": 0.8661197165250778, "critic_loss": 0.7362066108584404, "actor_loss": -94.4845703125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.909465074539185, "step": 127000}
{"episode_reward": 965.5560703682941, "episode": 128.0, "batch_reward": 0.866708283007145, "critic_loss": 0.7488531241118908, "actor_loss": -94.4927258605957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.89031457901001, "step": 128000}
{"episode_reward": 925.8195215564629, "episode": 129.0, "batch_reward": 0.8677632828950882, "critic_loss": 0.7354316286742687, "actor_loss": -94.43594201660156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.88101029396057, "step": 129000}
{"episode_reward": 963.463789623593, "episode": 130.0, "batch_reward": 0.8684706915616989, "critic_loss": 0.751174504250288, "actor_loss": -94.52912153625488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.893001079559326, "step": 130000}
{"episode_reward": 938.5534963197258, "episode": 131.0, "batch_reward": 0.8691139051914215, "critic_loss": 0.7778062104433775, "actor_loss": -94.40305545043945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.50198435783386, "step": 131000}
{"episode_reward": 958.6184948126922, "episode": 132.0, "batch_reward": 0.868909904897213, "critic_loss": 0.7013806566148997, "actor_loss": -94.61461822509766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.89193344116211, "step": 132000}
{"episode_reward": 891.3063093832512, "episode": 133.0, "batch_reward": 0.8705534247756004, "critic_loss": 0.679248332798481, "actor_loss": -94.54805932617188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.896538496017456, "step": 133000}
{"episode_reward": 961.2826014548039, "episode": 134.0, "batch_reward": 0.8701726250648498, "critic_loss": 0.695870751157403, "actor_loss": -94.60175025939941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.88555073738098, "step": 134000}
{"episode_reward": 926.0205493451058, "episode": 135.0, "batch_reward": 0.8694556843042374, "critic_loss": 0.7106220273673535, "actor_loss": -94.71378887939453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.854980945587158, "step": 135000}
{"episode_reward": 902.6518450518338, "episode": 136.0, "batch_reward": 0.8709442442059517, "critic_loss": 0.6959276529848576, "actor_loss": -94.72328073120117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.898853063583374, "step": 136000}
{"episode_reward": 944.6410042148077, "episode": 137.0, "batch_reward": 0.871898881494999, "critic_loss": 0.7051260856389999, "actor_loss": -94.67512174987793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.896419525146484, "step": 137000}
{"episode_reward": 939.8703056954997, "episode": 138.0, "batch_reward": 0.8716616151928902, "critic_loss": 0.7196151854395867, "actor_loss": -94.6584415588379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.89453363418579, "step": 138000}
{"episode_reward": 942.0352042928159, "episode": 139.0, "batch_reward": 0.8709631892442703, "critic_loss": 0.7327148487269879, "actor_loss": -94.61155056762695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.91177749633789, "step": 139000}
{"episode_reward": 913.0108146904925, "episode": 140.0, "batch_reward": 0.8710870103836059, "critic_loss": 0.7557062909007073, "actor_loss": -94.72186083984376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.916855573654175, "step": 140000}
{"episode_reward": 964.8634149993808, "episode": 141.0, "batch_reward": 0.8753211100697518, "critic_loss": 0.7292468197345734, "actor_loss": -94.73788777160645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.491570711135864, "step": 141000}
{"episode_reward": 963.9082199095094, "episode": 142.0, "batch_reward": 0.8745425516963005, "critic_loss": 0.7257591643333435, "actor_loss": -94.70484283447266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.888686656951904, "step": 142000}
{"episode_reward": 848.5445265864886, "episode": 143.0, "batch_reward": 0.8742641785144806, "critic_loss": 0.7311413942277432, "actor_loss": -94.6334442138672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.899681329727173, "step": 143000}
{"episode_reward": 923.1823902560014, "episode": 144.0, "batch_reward": 0.8749956311583519, "critic_loss": 0.7066131802499295, "actor_loss": -94.82369667053223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.89974308013916, "step": 144000}
{"episode_reward": 949.1438834135114, "episode": 145.0, "batch_reward": 0.876008801817894, "critic_loss": 0.6868227138519287, "actor_loss": -94.85885134887695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.90065836906433, "step": 145000}
{"episode_reward": 906.1898072701073, "episode": 146.0, "batch_reward": 0.8750360757112503, "critic_loss": 0.717635640218854, "actor_loss": -94.60524044799804, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.908984899520874, "step": 146000}
{"episode_reward": 912.6961504366667, "episode": 147.0, "batch_reward": 0.8747414801120758, "critic_loss": 0.7335831104516983, "actor_loss": -94.77028044128419, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.914076328277588, "step": 147000}
{"episode_reward": 802.2213877135569, "episode": 148.0, "batch_reward": 0.8752025511264802, "critic_loss": 0.7440562440156937, "actor_loss": -94.80812353515626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.865599155426025, "step": 148000}
{"episode_reward": 942.920477526034, "episode": 149.0, "batch_reward": 0.8759459509253502, "critic_loss": 0.713670158714056, "actor_loss": -94.78769583129883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.880655765533447, "step": 149000}
{"episode_reward": 943.2762644019923, "episode": 150.0, "batch_reward": 0.8757637295722961, "critic_loss": 0.74769184230268, "actor_loss": -94.73514836120606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
