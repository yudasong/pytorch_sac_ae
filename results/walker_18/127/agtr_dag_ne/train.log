{"episode": 1.0, "duration": 20.3112370967865, "episode_reward": 28.002640152663393, "step": 1000}
{"episode": 2.0, "duration": 1.80535888671875, "episode_reward": 481.4321918933315, "step": 2000}
{"episode": 3.0, "batch_reward": 0.26531616159382165, "critic_loss": 0.4908285080348106, "actor_loss": -82.84517259662654, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 64.22262954711914, "episode_reward": 420.66032668092083, "step": 3000}
{"episode": 4.0, "batch_reward": 0.29070640648901463, "critic_loss": 0.5078819934427738, "actor_loss": -81.74329618835449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.197463512420654, "episode_reward": 260.55355565550866, "step": 4000}
{"episode": 5.0, "batch_reward": 0.32291191881895065, "critic_loss": 0.6298071893155575, "actor_loss": -82.1497550201416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.64697265625, "episode_reward": 526.548682635587, "step": 5000}
{"episode": 6.0, "batch_reward": 0.35801888862252235, "critic_loss": 0.6763318954408168, "actor_loss": -83.19132801818847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.93233871459961, "episode_reward": 540.5732495699187, "step": 6000}
{"episode": 7.0, "batch_reward": 0.3946555874347687, "critic_loss": 0.8012780619263649, "actor_loss": -84.18498400878906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.232990026474, "episode_reward": 614.6022045366241, "step": 7000}
{"episode": 8.0, "batch_reward": 0.40702110683917997, "critic_loss": 0.8406844417750835, "actor_loss": -84.23194187927245, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.853468656539917, "episode_reward": 471.0449580266211, "step": 8000}
{"episode": 9.0, "batch_reward": 0.42363539201021194, "critic_loss": 0.9385901340246201, "actor_loss": -84.69030151367187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.228606939315796, "episode_reward": 549.3207597719118, "step": 9000}
{"episode": 10.0, "batch_reward": 0.4434993760883808, "critic_loss": 1.0144962867498397, "actor_loss": -81.54442749023437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 4087.3851721286774, "episode_reward": 640.6565148016415, "step": 10000}
{"episode": 11.0, "batch_reward": 0.45901818150281903, "critic_loss": 1.056092201769352, "actor_loss": -81.97905815124511, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 46.791100025177, "episode_reward": 593.9276802025836, "step": 11000}
{"episode": 12.0, "batch_reward": 0.4690787063539028, "critic_loss": 1.1783998202085495, "actor_loss": -80.3624412689209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 480.915744304657, "episode_reward": 553.0975225304026, "step": 12000}
{"episode": 13.0, "batch_reward": 0.4742868464887142, "critic_loss": 1.1515108098387719, "actor_loss": -80.51974639892578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.73070001602173, "episode_reward": 517.7482524799701, "step": 13000}
{"episode": 14.0, "batch_reward": 0.48182739850878714, "critic_loss": 1.1636299706101418, "actor_loss": -78.91635192871094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 441.9345631599426, "episode_reward": 611.0267792543416, "step": 14000}
{"episode": 15.0, "batch_reward": 0.4850710982978344, "critic_loss": 1.1473566250801086, "actor_loss": -79.02263932800292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.84038519859314, "episode_reward": 480.21950104052314, "step": 15000}
{"episode": 16.0, "batch_reward": 0.48863242214918134, "critic_loss": 1.146702098965645, "actor_loss": -78.46508993530273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 455.49825835227966, "episode_reward": 555.7015392642002, "step": 16000}
{"episode": 17.0, "batch_reward": 0.49091839426755907, "critic_loss": 1.0519927161335945, "actor_loss": -78.48809594726562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.143553733825684, "episode_reward": 564.4209491603217, "step": 17000}
{"episode": 18.0, "batch_reward": 0.489876184374094, "critic_loss": 0.9947005128860473, "actor_loss": -77.79442720031739, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 460.2756085395813, "episode_reward": 243.90750931307792, "step": 18000}
{"episode": 19.0, "batch_reward": 0.47361568051576614, "critic_loss": 1.0340941677689552, "actor_loss": -77.71751686096191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.825736045837402, "episode_reward": 173.31824298944701, "step": 19000}
{"episode": 20.0, "batch_reward": 0.4648383497297764, "critic_loss": 1.159412525653839, "actor_loss": -77.54311158752441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 435.2170820236206, "episode_reward": 561.8824756310609, "step": 20000}
{"episode": 21.0, "batch_reward": 0.4727738745808601, "critic_loss": 1.1661330015063285, "actor_loss": -77.9105837097168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.970643758773804, "episode_reward": 626.2375138297054, "step": 21000}
{"episode": 22.0, "batch_reward": 0.46689632660150526, "critic_loss": 1.2342550482153893, "actor_loss": -77.44245164489746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 480.84560894966125, "episode_reward": 22.9127505335982, "step": 22000}
{"episode": 23.0, "batch_reward": 0.4597565267086029, "critic_loss": 1.3007002475857734, "actor_loss": -76.9629210205078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.59636163711548, "episode_reward": 676.1719950523444, "step": 23000}
