{"episode": 1.0, "duration": 18.608097553253174, "episode_reward": 28.002640152663393, "step": 1000}
{"episode": 2.0, "duration": 1.6298086643218994, "episode_reward": 481.4321918933315, "step": 2000}
{"episode": 3.0, "batch_reward": 0.24042021602680383, "actor_loss": -84.4530424505007, "actor_target_entropy": -6.0, "alpha_value": 0.00244617320470393, "duration": 67.10230469703674, "episode_reward": 19.732599889372278, "step": 3000}
{"episode": 4.0, "batch_reward": 0.16346927713602782, "actor_loss": -78.38929594421387, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.55224323272705, "episode_reward": 54.77180082112706, "step": 4000}
{"episode": 5.0, "batch_reward": 0.14629269218444824, "actor_loss": -78.06868019104004, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.073408603668213, "episode_reward": 211.52667863903318, "step": 5000}
{"episode": 6.0, "batch_reward": 0.16284433160722256, "actor_loss": -78.73421926879882, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.575040817260742, "episode_reward": 221.3570320296073, "step": 6000}
{"episode": 7.0, "batch_reward": 0.18507949905097484, "actor_loss": -79.65845417785644, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.008174419403076, "episode_reward": 332.781337817597, "step": 7000}
{"episode": 8.0, "batch_reward": 0.1891391305476427, "actor_loss": -79.6247504272461, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.092491388320923, "episode_reward": 157.15474998393458, "step": 8000}
{"episode": 9.0, "batch_reward": 0.19245434781908988, "actor_loss": -79.54819770812988, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.164019107818604, "episode_reward": 206.46143426200985, "step": 9000}
{"episode": 10.0, "batch_reward": 0.2028089916706085, "actor_loss": -79.69630209350586, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.422199249267578, "episode_reward": 472.92921526053595, "step": 10000}
{"episode": 11.0, "batch_reward": 0.22897067560255527, "actor_loss": -80.48377320861816, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 40.11381459236145, "episode_reward": 449.0424161954428, "step": 11000}
{"episode": 12.0, "batch_reward": 0.24600536631047726, "actor_loss": -80.96511860656739, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.027974605560303, "episode_reward": 453.39165329377556, "step": 12000}
{"episode": 13.0, "batch_reward": 0.26536285001039506, "actor_loss": -81.504490524292, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.40067481994629, "episode_reward": 479.169058601562, "step": 13000}
{"episode": 14.0, "batch_reward": 0.28163491690158843, "actor_loss": -82.0417523803711, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.10584545135498, "episode_reward": 513.3641188287994, "step": 14000}
{"episode": 15.0, "batch_reward": 0.2975434906631708, "actor_loss": -82.51009126281738, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.065234661102295, "episode_reward": 474.905792273324, "step": 15000}
{"episode": 16.0, "batch_reward": 0.3043504692018032, "actor_loss": -82.83109651184083, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.930482864379883, "episode_reward": 401.0224916382948, "step": 16000}
{"episode": 17.0, "batch_reward": 0.30752934578061103, "actor_loss": -82.8113876953125, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.268653392791748, "episode_reward": 274.06773878100904, "step": 17000}
{"episode": 18.0, "batch_reward": 0.31369195753335954, "actor_loss": -82.9812748260498, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.10887312889099, "episode_reward": 555.3279749244249, "step": 18000}
{"episode": 19.0, "batch_reward": 0.31690557198226454, "actor_loss": -83.02371492004394, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.99130916595459, "episode_reward": 246.8424849468297, "step": 19000}
{"episode": 20.0, "batch_reward": 0.3174110215008259, "actor_loss": -82.95344105529786, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.700750827789307, "episode_reward": 389.00487366502404, "step": 20000}
{"episode": 21.0, "batch_reward": 0.3255353266298771, "actor_loss": -83.20874340820312, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 42.08745574951172, "episode_reward": 518.3420690635141, "step": 21000}
{"episode": 22.0, "batch_reward": 0.3256349874138832, "actor_loss": -83.1723025970459, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.934975624084473, "episode_reward": 223.96556934175976, "step": 22000}
{"episode": 23.0, "batch_reward": 0.3299821894168854, "actor_loss": -83.2855411529541, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.064974069595337, "episode_reward": 566.5485981950306, "step": 23000}
{"episode": 24.0, "batch_reward": 0.3388968387544155, "actor_loss": -83.4661883392334, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.836103439331055, "episode_reward": 528.2990785837861, "step": 24000}
{"episode": 25.0, "batch_reward": 0.34775826954841615, "actor_loss": -83.65685090637207, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.15208649635315, "episode_reward": 489.3669826152324, "step": 25000}
{"episode": 26.0, "batch_reward": 0.35334321776032446, "actor_loss": -83.96460256958008, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.646533012390137, "episode_reward": 588.3618377672236, "step": 26000}
{"episode": 27.0, "batch_reward": 0.36189626771211625, "actor_loss": -84.13686206054687, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.74950623512268, "episode_reward": 502.82710046557366, "step": 27000}
{"episode": 28.0, "batch_reward": 0.3673212946355343, "actor_loss": -84.279765914917, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.118530750274658, "episode_reward": 529.717512145891, "step": 28000}
{"episode": 29.0, "batch_reward": 0.37263067391514776, "actor_loss": -84.43978495788575, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.018532752990723, "episode_reward": 489.28859365195655, "step": 29000}
{"episode": 30.0, "batch_reward": 0.37840083131194113, "actor_loss": -84.60733312988282, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.604243993759155, "episode_reward": 538.6525798064806, "step": 30000}
{"episode": 31.0, "batch_reward": 0.38115512710809707, "actor_loss": -84.70264619445801, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 42.44148278236389, "episode_reward": 475.68009727603203, "step": 31000}
{"episode": 32.0, "batch_reward": 0.3859415139555931, "actor_loss": -84.83473916625977, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.95225429534912, "episode_reward": 515.6202693937502, "step": 32000}
{"episode": 33.0, "batch_reward": 0.38968430614471433, "actor_loss": -84.87794998168945, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.75144672393799, "episode_reward": 550.5187825662696, "step": 33000}
{"episode": 34.0, "batch_reward": 0.39388740313053133, "actor_loss": -85.07367903137207, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.54682421684265, "episode_reward": 574.3997296492655, "step": 34000}
{"episode": 35.0, "batch_reward": 0.39424591317772867, "actor_loss": -85.0231630706787, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.47479748725891, "episode_reward": 293.7434017808437, "step": 35000}
{"episode": 36.0, "batch_reward": 0.395495356708765, "actor_loss": -84.97556036376953, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.07272958755493, "episode_reward": 526.6019466423395, "step": 36000}
{"episode": 37.0, "batch_reward": 0.4008463176488876, "actor_loss": -85.12380924987794, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.940638303756714, "episode_reward": 603.9544038299919, "step": 37000}
{"episode": 38.0, "batch_reward": 0.4031645002961159, "actor_loss": -85.12922898864745, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.320395946502686, "episode_reward": 404.0130601556059, "step": 38000}
{"episode": 39.0, "batch_reward": 0.40604461571574213, "actor_loss": -85.27861508178711, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.793978691101074, "episode_reward": 518.5348875156145, "step": 39000}
{"episode": 40.0, "batch_reward": 0.40913384211063386, "actor_loss": -85.3261340637207, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.152182817459106, "episode_reward": 623.0905974806336, "step": 40000}
{"episode": 41.0, "batch_reward": 0.412676546305418, "actor_loss": -85.40738822937011, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 42.10264492034912, "episode_reward": 490.3896648378359, "step": 41000}
{"episode": 42.0, "batch_reward": 0.4164677384495735, "actor_loss": -85.5606478881836, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.472159147262573, "episode_reward": 614.8520982307998, "step": 42000}
{"episode": 43.0, "batch_reward": 0.41880435729026794, "actor_loss": -85.6158793182373, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.119819164276123, "episode_reward": 592.016950839634, "step": 43000}
{"episode": 44.0, "batch_reward": 0.4245476510822773, "actor_loss": -85.76815211486816, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.20636773109436, "episode_reward": 654.3703301009816, "step": 44000}
{"episode": 45.0, "batch_reward": 0.43032824963331223, "actor_loss": -85.90705418395996, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.9514901638031, "episode_reward": 638.6486884016423, "step": 45000}
{"episode": 46.0, "batch_reward": 0.43196471670269965, "actor_loss": -85.92091032409668, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.90364098548889, "episode_reward": 509.8768841160027, "step": 46000}
{"episode": 47.0, "batch_reward": 0.4356074757575989, "actor_loss": -86.12320204162597, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.954169034957886, "episode_reward": 595.6378904206042, "step": 47000}
{"episode": 48.0, "batch_reward": 0.43910732337832453, "actor_loss": -86.14358093261718, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.705963134765625, "episode_reward": 547.6781771554729, "step": 48000}
{"episode": 49.0, "batch_reward": 0.44128619998693464, "actor_loss": -86.21457911682128, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.711066722869873, "episode_reward": 495.5233922313848, "step": 49000}
{"episode": 50.0, "batch_reward": 0.442791721701622, "actor_loss": -86.24480700683594, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.063288927078247, "episode_reward": 571.9129877781265, "step": 50000}
{"episode": 51.0, "batch_reward": 0.44642498037219047, "actor_loss": -86.31373269653321, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 40.95512533187866, "episode_reward": 593.872564590681, "step": 51000}
{"episode": 52.0, "batch_reward": 0.4466329302787781, "actor_loss": -86.30614695739746, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.28658390045166, "episode_reward": 299.63917188943526, "step": 52000}
{"episode": 53.0, "batch_reward": 0.44440716966986654, "actor_loss": -86.2393921508789, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.965566396713257, "episode_reward": 613.9791972597403, "step": 53000}
{"episode": 54.0, "batch_reward": 0.4495301097929478, "actor_loss": -86.3785989074707, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.921711444854736, "episode_reward": 638.6828980096836, "step": 54000}
{"episode": 55.0, "batch_reward": 0.44753007051348687, "actor_loss": -86.3622871246338, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.386716842651367, "episode_reward": 385.45184903404424, "step": 55000}
{"episode": 56.0, "batch_reward": 0.4500358955860138, "actor_loss": -86.43619398498535, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.109923839569092, "episode_reward": 624.7238930878807, "step": 56000}
{"episode": 57.0, "batch_reward": 0.4530322286784649, "actor_loss": -86.44073350524903, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.98638677597046, "episode_reward": 635.8116741701252, "step": 57000}
{"episode": 58.0, "batch_reward": 0.4538896364569664, "actor_loss": -86.47956770324707, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.191033840179443, "episode_reward": 209.91414783148733, "step": 58000}
{"episode": 59.0, "batch_reward": 0.4519742605984211, "actor_loss": -86.38133302307129, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.72194766998291, "episode_reward": 461.089520377395, "step": 59000}
{"episode": 60.0, "batch_reward": 0.4534001251757145, "actor_loss": -86.44189793395996, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.56561589241028, "episode_reward": 506.5847042572086, "step": 60000}
{"episode": 61.0, "batch_reward": 0.45333320274949074, "actor_loss": -86.41210289001465, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.459636211395264, "episode_reward": 645.8135929800299, "step": 61000}
{"episode": 62.0, "batch_reward": 0.45591587299108505, "actor_loss": -86.49339022827148, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.00601029396057, "episode_reward": 542.461595674838, "step": 62000}
{"episode": 63.0, "batch_reward": 0.4588162831068039, "actor_loss": -86.59795080566406, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.862181663513184, "episode_reward": 566.6305310444648, "step": 63000}
{"episode": 64.0, "batch_reward": 0.45904095587134364, "actor_loss": -86.61920803833007, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.894435167312622, "episode_reward": 451.30424837456115, "step": 64000}
{"episode": 65.0, "batch_reward": 0.45951711758971214, "actor_loss": -86.66136277770997, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.68218684196472, "episode_reward": 650.5093487344305, "step": 65000}
{"episode": 66.0, "batch_reward": 0.4621318705379963, "actor_loss": -86.71251202392578, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.62894296646118, "episode_reward": 526.5841965716994, "step": 66000}
{"episode": 67.0, "batch_reward": 0.4642713485956192, "actor_loss": -86.77680151367187, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.227193355560303, "episode_reward": 651.5549578945233, "step": 67000}
{"episode": 68.0, "batch_reward": 0.46511601787805557, "actor_loss": -86.75941619873046, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.193738222122192, "episode_reward": 603.0383871195364, "step": 68000}
{"episode": 69.0, "batch_reward": 0.46887109127640725, "actor_loss": -86.8871803741455, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.946479320526123, "episode_reward": 636.0448421803158, "step": 69000}
{"episode": 70.0, "batch_reward": 0.4689304768741131, "actor_loss": -86.8727596130371, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.944620370864868, "episode_reward": 210.62248038436005, "step": 70000}
{"episode": 71.0, "batch_reward": 0.46604333516955376, "actor_loss": -86.81349819946288, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.476218938827515, "episode_reward": 551.3783561520524, "step": 71000}
{"episode": 72.0, "batch_reward": 0.46850283339619636, "actor_loss": -86.87887702941894, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.896674156188965, "episode_reward": 568.6595069983953, "step": 72000}
{"episode": 73.0, "batch_reward": 0.47082015058398247, "actor_loss": -86.91588928222656, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.804067611694336, "episode_reward": 564.6342323419403, "step": 73000}
{"episode": 74.0, "batch_reward": 0.4714285739958286, "actor_loss": -86.9999447479248, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.746201038360596, "episode_reward": 530.7826535361103, "step": 74000}
{"episode": 75.0, "batch_reward": 0.4707780427932739, "actor_loss": -86.95320080566407, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.051029443740845, "episode_reward": 508.04932450784406, "step": 75000}
{"episode": 76.0, "batch_reward": 0.47231623861193656, "actor_loss": -86.97725239562989, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.88851237297058, "episode_reward": 663.1833319699199, "step": 76000}
{"episode": 77.0, "batch_reward": 0.4735168724060059, "actor_loss": -87.01974682617187, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.0564923286438, "episode_reward": 534.594934934278, "step": 77000}
{"episode": 78.0, "batch_reward": 0.47537402176856997, "actor_loss": -87.02922610473632, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.88644289970398, "episode_reward": 620.6139084899438, "step": 78000}
{"episode": 79.0, "batch_reward": 0.4773911034166813, "actor_loss": -87.12062225341796, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.001979112625122, "episode_reward": 660.3146753404924, "step": 79000}
{"episode": 80.0, "batch_reward": 0.47899142155051233, "actor_loss": -87.1510591583252, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.638733386993408, "episode_reward": 521.486877001722, "step": 80000}
{"episode": 81.0, "batch_reward": 0.4811385275125504, "actor_loss": -87.21112257385253, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 43.56721591949463, "episode_reward": 610.5456326851363, "step": 81000}
{"episode": 82.0, "batch_reward": 0.48121157866716385, "actor_loss": -87.24573051452637, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.951316833496094, "episode_reward": 457.523926177658, "step": 82000}
{"episode": 83.0, "batch_reward": 0.48065011236071586, "actor_loss": -87.23534642028808, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.677043914794922, "episode_reward": 615.7802031382073, "step": 83000}
{"episode": 84.0, "batch_reward": 0.484286001175642, "actor_loss": -87.30988681030273, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.606518983840942, "episode_reward": 620.8241052738337, "step": 84000}
{"episode": 85.0, "batch_reward": 0.4844857787489891, "actor_loss": -87.30421377563476, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.82597541809082, "episode_reward": 566.3474383893303, "step": 85000}
{"episode": 86.0, "batch_reward": 0.48657188314199445, "actor_loss": -87.37276448059082, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.4255428314209, "episode_reward": 696.7006923896541, "step": 86000}
{"episode": 87.0, "batch_reward": 0.48848411405086517, "actor_loss": -87.44103005981445, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 26.049116611480713, "episode_reward": 772.5775148587596, "step": 87000}
{"episode": 88.0, "batch_reward": 0.4900649996995926, "actor_loss": -87.49340653991699, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.199463844299316, "episode_reward": 503.84292503966884, "step": 88000}
{"episode": 89.0, "batch_reward": 0.4913915154635906, "actor_loss": -87.43077066040038, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.407029628753662, "episode_reward": 532.6259127634419, "step": 89000}
{"episode": 90.0, "batch_reward": 0.4926753874719143, "actor_loss": -87.48193882751465, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.161251544952393, "episode_reward": 621.5251930206612, "step": 90000}
{"episode": 91.0, "batch_reward": 0.49395502579212186, "actor_loss": -87.49685600280762, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 45.673752546310425, "episode_reward": 367.5978524826361, "step": 91000}
{"episode": 92.0, "batch_reward": 0.492060951679945, "actor_loss": -87.44315432739258, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.25731658935547, "episode_reward": 624.0005630644973, "step": 92000}
{"episode": 93.0, "batch_reward": 0.4930263554751873, "actor_loss": -87.45217506408692, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.180500268936157, "episode_reward": 633.6219727141178, "step": 93000}
{"episode": 94.0, "batch_reward": 0.4949368788897991, "actor_loss": -87.49809680175781, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.771347045898438, "episode_reward": 736.6413216672423, "step": 94000}
{"episode": 95.0, "batch_reward": 0.49859752374887467, "actor_loss": -87.60418408203125, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.97823190689087, "episode_reward": 693.5199327941618, "step": 95000}
{"episode": 96.0, "batch_reward": 0.50038957670331, "actor_loss": -87.67015287780762, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.269757747650146, "episode_reward": 650.1407580389163, "step": 96000}
{"episode": 97.0, "batch_reward": 0.5033298504352569, "actor_loss": -87.72651901245118, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.964800596237183, "episode_reward": 717.3105382967854, "step": 97000}
{"episode": 98.0, "batch_reward": 0.5043579322993755, "actor_loss": -87.76684857177735, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.689839839935303, "episode_reward": 636.9425698037679, "step": 98000}
{"episode": 99.0, "batch_reward": 0.5044710556864739, "actor_loss": -87.82775883483886, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.301838874816895, "episode_reward": 554.0243320812054, "step": 99000}
{"episode": 100.0, "batch_reward": 0.506721410214901, "actor_loss": -87.86776631164551, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.92550754547119, "episode_reward": 723.6576367438257, "step": 100000}
{"episode": 101.0, "batch_reward": 0.5070746230781078, "actor_loss": -87.8446234588623, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 45.90425634384155, "episode_reward": 696.6028754265005, "step": 101000}
{"episode": 102.0, "batch_reward": 0.5079977472424507, "actor_loss": -87.8355525970459, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.04152226448059, "episode_reward": 63.06356527773903, "step": 102000}
{"episode": 103.0, "batch_reward": 0.5034924092292785, "actor_loss": -87.67249531555176, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.573578596115112, "episode_reward": 44.72731588194163, "step": 103000}
{"episode": 104.0, "batch_reward": 0.49903994891047476, "actor_loss": -87.56665823364258, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.46397829055786, "episode_reward": 427.71492082766787, "step": 104000}
{"episode": 105.0, "batch_reward": 0.5004158662855626, "actor_loss": -87.65422148132325, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.592808485031128, "episode_reward": 580.0638181979488, "step": 105000}
{"episode": 106.0, "batch_reward": 0.5014105231463909, "actor_loss": -87.64800886535645, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.031720638275146, "episode_reward": 672.9774908373672, "step": 106000}
{"episode": 107.0, "batch_reward": 0.5018921050727367, "actor_loss": -87.64959725952149, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.859718561172485, "episode_reward": 630.8383968101531, "step": 107000}
{"episode": 108.0, "batch_reward": 0.5035266981422901, "actor_loss": -87.67633825683593, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.539186000823975, "episode_reward": 668.7951772829982, "step": 108000}
{"episode": 109.0, "batch_reward": 0.5054379573464394, "actor_loss": -87.72878031921387, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.42108941078186, "episode_reward": 671.203741378383, "step": 109000}
{"episode": 110.0, "batch_reward": 0.5063146077394486, "actor_loss": -87.76609646606445, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.97234845161438, "episode_reward": 607.077624829898, "step": 110000}
{"episode": 111.0, "batch_reward": 0.507697317391634, "actor_loss": -87.76642956542969, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 45.61355495452881, "episode_reward": 702.6898194155308, "step": 111000}
{"episode": 112.0, "batch_reward": 0.5097770477533341, "actor_loss": -87.84886862182617, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.099167108535767, "episode_reward": 613.25785080941, "step": 112000}
{"episode": 113.0, "batch_reward": 0.5097089413106441, "actor_loss": -87.83812387084961, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.133922338485718, "episode_reward": 665.6065008514303, "step": 113000}
{"episode": 114.0, "batch_reward": 0.5114078039824963, "actor_loss": -87.88084727478028, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.022485971450806, "episode_reward": 521.9865777221241, "step": 114000}
{"episode": 115.0, "batch_reward": 0.5116779983639718, "actor_loss": -87.89835400390625, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.13390827178955, "episode_reward": 621.4908898932733, "step": 115000}
{"episode": 116.0, "batch_reward": 0.5130276416540146, "actor_loss": -87.92692520141601, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.959345817565918, "episode_reward": 666.4686315469561, "step": 116000}
{"episode": 117.0, "batch_reward": 0.5141528870165348, "actor_loss": -87.97735646057129, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.344860315322876, "episode_reward": 647.8949056616229, "step": 117000}
{"episode": 118.0, "batch_reward": 0.5140753955841064, "actor_loss": -87.92871032714844, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.069742679595947, "episode_reward": 642.6040953667306, "step": 118000}
{"episode": 119.0, "batch_reward": 0.5149689947664737, "actor_loss": -87.96670419311523, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.215675354003906, "episode_reward": 563.9307215659918, "step": 119000}
{"episode": 120.0, "batch_reward": 0.5188135228157044, "actor_loss": -88.05219624328613, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.724583387374878, "episode_reward": 698.5643811594894, "step": 120000}
{"episode": 121.0, "batch_reward": 0.5177201685011387, "actor_loss": -88.03455667114258, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 46.03873133659363, "episode_reward": 649.5439128626754, "step": 121000}
{"episode": 122.0, "batch_reward": 0.5198598681986332, "actor_loss": -88.13321954345703, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.062875509262085, "episode_reward": 697.2451541274276, "step": 122000}
{"episode": 123.0, "batch_reward": 0.5224931836426258, "actor_loss": -88.16321246337891, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.067888498306274, "episode_reward": 696.0514693616286, "step": 123000}
{"episode": 124.0, "batch_reward": 0.52150560054183, "actor_loss": -88.11274674987793, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.10257625579834, "episode_reward": 575.0719532548989, "step": 124000}
{"episode": 125.0, "batch_reward": 0.5220414879620076, "actor_loss": -88.09267086791992, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.07236671447754, "episode_reward": 729.2089129315822, "step": 125000}
{"episode": 126.0, "batch_reward": 0.5230572833716869, "actor_loss": -88.16726174926758, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.5818030834198, "episode_reward": 603.8145832529783, "step": 126000}
{"episode": 127.0, "batch_reward": 0.5230686261057854, "actor_loss": -88.21668991088868, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.061192750930786, "episode_reward": 620.6408364267122, "step": 127000}
{"episode": 128.0, "batch_reward": 0.5249674196243286, "actor_loss": -88.25902876281738, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.848968505859375, "episode_reward": 707.9428636779548, "step": 128000}
{"episode": 129.0, "batch_reward": 0.5261405826508999, "actor_loss": -88.25538357543945, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.60205864906311, "episode_reward": 661.2797452894761, "step": 129000}
{"episode": 130.0, "batch_reward": 0.526229352235794, "actor_loss": -88.20115498352051, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.246960163116455, "episode_reward": 575.8828235731212, "step": 130000}
{"episode": 131.0, "batch_reward": 0.5285074614286422, "actor_loss": -88.24999124145508, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 45.9309868812561, "episode_reward": 609.4636842031958, "step": 131000}
{"episode": 132.0, "batch_reward": 0.5282124348282814, "actor_loss": -88.30302398681641, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.638098001480103, "episode_reward": 699.2392061796807, "step": 132000}
{"episode": 133.0, "batch_reward": 0.5307666329145432, "actor_loss": -88.3123373260498, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.732430696487427, "episode_reward": 663.2159189526302, "step": 133000}
{"episode": 134.0, "batch_reward": 0.5317928206324577, "actor_loss": -88.36273023986817, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.151202917099, "episode_reward": 675.1850438668714, "step": 134000}
{"episode": 135.0, "batch_reward": 0.5317426752150058, "actor_loss": -88.41236827087403, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.589200496673584, "episode_reward": 638.0870155850776, "step": 135000}
{"episode": 136.0, "batch_reward": 0.5317227844595909, "actor_loss": -88.42023095703125, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.249462127685547, "episode_reward": 665.7367089344255, "step": 136000}
{"episode": 137.0, "batch_reward": 0.534479208022356, "actor_loss": -88.47630876159668, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.259609937667847, "episode_reward": 660.7944193991473, "step": 137000}
{"episode": 138.0, "batch_reward": 0.5340615748167038, "actor_loss": -88.42262062072754, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.37768268585205, "episode_reward": 421.98260243805413, "step": 138000}
{"episode": 139.0, "batch_reward": 0.5329424787759781, "actor_loss": -88.38556130981445, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.287380695343018, "episode_reward": 740.4049177238602, "step": 139000}
{"episode": 140.0, "batch_reward": 0.5357473522424698, "actor_loss": -88.45801860046387, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 23.37738609313965, "episode_reward": 712.9355167385387, "step": 140000}
{"episode": 141.0, "batch_reward": 0.5347066958844662, "actor_loss": -88.37221894836426, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 45.51559257507324, "episode_reward": 189.30933698297267, "step": 141000}
{"episode": 142.0, "batch_reward": 0.5363736718595028, "actor_loss": -88.41043074035645, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.902905225753784, "episode_reward": 656.8990596566381, "step": 142000}
{"episode": 143.0, "batch_reward": 0.5352418022453785, "actor_loss": -88.33852680969238, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.82013487815857, "episode_reward": 681.8103591845423, "step": 143000}
{"episode": 144.0, "batch_reward": 0.5345428746342659, "actor_loss": -88.40261946105957, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.226842880249023, "episode_reward": 23.730749410978845, "step": 144000}
{"episode": 145.0, "batch_reward": 0.5340713487267494, "actor_loss": -88.24524980163574, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.319380283355713, "episode_reward": 709.7917539966005, "step": 145000}
{"episode": 146.0, "batch_reward": 0.5356113148927688, "actor_loss": -88.32652008056641, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.814013719558716, "episode_reward": 666.6733823349169, "step": 146000}
{"episode": 147.0, "batch_reward": 0.5338370395898819, "actor_loss": -88.33496929931641, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.802773237228394, "episode_reward": 692.9679355671735, "step": 147000}
{"episode": 148.0, "batch_reward": 0.5368017780482769, "actor_loss": -88.45762086486816, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.298988342285156, "episode_reward": 657.236966240083, "step": 148000}
{"episode": 149.0, "batch_reward": 0.5364256627857685, "actor_loss": -88.37931951904297, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.805838346481323, "episode_reward": 699.684092102055, "step": 149000}
{"episode": 150.0, "batch_reward": 0.5378071652352809, "actor_loss": -88.40372059631348, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "step": 150000}
