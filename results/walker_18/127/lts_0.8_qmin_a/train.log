{"episode_reward": 0.0, "episode": 1.0, "duration": 21.56792426109314, "step": 1000}
{"episode_reward": 28.002640152663393, "episode": 2.0, "duration": 1.8634889125823975, "step": 2000}
{"episode_reward": 481.4321918933315, "episode": 3.0, "batch_reward": 0.24325230547232243, "critic_loss": 0.0997747838442506, "actor_loss": -70.69187446244034, "actor_target_entropy": -6.0, "alpha_value": 0.00244617320470393, "duration": 62.866156816482544, "step": 3000}
{"episode_reward": 74.1755125118862, "episode": 4.0, "batch_reward": 0.18779896016418934, "critic_loss": 0.2999701843187213, "actor_loss": -67.1317914185524, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.477588653564453, "step": 4000}
{"episode_reward": 101.83416285285756, "episode": 5.0, "batch_reward": 0.15574301449954508, "critic_loss": 0.3224500477015972, "actor_loss": -62.389552904605864, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.696613073349, "step": 5000}
{"episode_reward": 18.309821165931023, "episode": 6.0, "batch_reward": 0.13348674850910902, "critic_loss": 0.42479957212507724, "actor_loss": -63.81458151197433, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.945063829421997, "step": 6000}
{"episode_reward": 84.89034122997903, "episode": 7.0, "batch_reward": 0.13031980401277543, "critic_loss": 0.5875955323576927, "actor_loss": -61.87872032928467, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.916662454605103, "step": 7000}
{"episode_reward": 100.683157619704, "episode": 8.0, "batch_reward": 0.12417803495377303, "critic_loss": 0.6623585633933544, "actor_loss": -61.32861666727066, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.965826511383057, "step": 8000}
{"episode_reward": 78.73176710229853, "episode": 9.0, "batch_reward": 0.11996216072142124, "critic_loss": 0.5682141173183918, "actor_loss": -62.48212202835083, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.229869604110718, "step": 9000}
{"episode_reward": 92.10440031145046, "episode": 10.0, "batch_reward": 0.11990700577944517, "critic_loss": 0.5093187138736248, "actor_loss": -62.82835854148865, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.00816297531128, "step": 10000}
{"episode_reward": 112.39768181729274, "episode": 11.0, "batch_reward": 0.12897814594209195, "critic_loss": 0.49034309861063957, "actor_loss": -62.3818927564621, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.20726752281189, "step": 11000}
{"episode_reward": 288.0222294730252, "episode": 12.0, "batch_reward": 0.13432434909790755, "critic_loss": 0.49406350097060203, "actor_loss": -62.150127416610715, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.7506685256958, "step": 12000}
{"episode_reward": 150.35054858973027, "episode": 13.0, "batch_reward": 0.13765938560664653, "critic_loss": 0.5085233275890351, "actor_loss": -62.25010256099701, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.17767310142517, "step": 13000}
{"episode_reward": 171.8879165774952, "episode": 14.0, "batch_reward": 0.1387755811661482, "critic_loss": 0.4810215050578117, "actor_loss": -61.535878092765806, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.693573474884033, "step": 14000}
{"episode_reward": 232.99533340851073, "episode": 15.0, "batch_reward": 0.15352828773856164, "critic_loss": 0.5334422066509724, "actor_loss": -64.01387441253662, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.73503804206848, "step": 15000}
{"episode_reward": 429.6595279947696, "episode": 16.0, "batch_reward": 0.17117330551892518, "critic_loss": 0.6329775418639183, "actor_loss": -63.62530866336822, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.879734992980957, "step": 16000}
{"episode_reward": 383.9407639727515, "episode": 17.0, "batch_reward": 0.18496688065677883, "critic_loss": 0.6763677914738655, "actor_loss": -62.591908637046814, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.346076250076294, "step": 17000}
{"episode_reward": 449.9570598674919, "episode": 18.0, "batch_reward": 0.19912559124827384, "critic_loss": 0.768765912592411, "actor_loss": -64.02856927394868, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.446667671203613, "step": 18000}
{"episode_reward": 421.54723994091347, "episode": 19.0, "batch_reward": 0.2126518073529005, "critic_loss": 0.9303213736414909, "actor_loss": -65.15372124958039, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.02025604248047, "step": 19000}
{"episode_reward": 468.4133706288345, "episode": 20.0, "batch_reward": 0.22558478105068208, "critic_loss": 1.0493777225613594, "actor_loss": -67.57130157279968, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.706664085388184, "step": 20000}
{"episode_reward": 454.75067271807706, "episode": 21.0, "batch_reward": 0.23721164825558663, "critic_loss": 1.178366338610649, "actor_loss": -63.75180454826355, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.873032331466675, "step": 21000}
{"episode_reward": 518.2683959835111, "episode": 22.0, "batch_reward": 0.24986048324406146, "critic_loss": 1.3261034181118012, "actor_loss": -66.61197830200196, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.081719160079956, "step": 22000}
{"episode_reward": 473.7119893061138, "episode": 23.0, "batch_reward": 0.26263676725327967, "critic_loss": 1.4639212604761123, "actor_loss": -65.7105228099823, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.589040279388428, "step": 23000}
{"episode_reward": 569.8574377813621, "episode": 24.0, "batch_reward": 0.2744281010329723, "critic_loss": 1.4431675622463227, "actor_loss": -67.58279959487915, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.02660894393921, "step": 24000}
{"episode_reward": 537.9225275470701, "episode": 25.0, "batch_reward": 0.28870734940469267, "critic_loss": 1.4493461104035377, "actor_loss": -69.15151752662659, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.781020164489746, "step": 25000}
{"episode_reward": 634.9191792076991, "episode": 26.0, "batch_reward": 0.301673717290163, "critic_loss": 1.4495037140250207, "actor_loss": -67.62914939308166, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.445204973220825, "step": 26000}
{"episode_reward": 693.8568762746223, "episode": 27.0, "batch_reward": 0.3164316554367542, "critic_loss": 1.463122727394104, "actor_loss": -69.02863816642761, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.884536266326904, "step": 27000}
{"episode_reward": 707.0241882122602, "episode": 28.0, "batch_reward": 0.328936777099967, "critic_loss": 1.5364113078713417, "actor_loss": -68.35964632034302, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.65948462486267, "step": 28000}
{"episode_reward": 591.9045184403238, "episode": 29.0, "batch_reward": 0.33873120200634005, "critic_loss": 1.6553696244955063, "actor_loss": -69.50132710266114, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.4669508934021, "step": 29000}
{"episode_reward": 586.4962183837426, "episode": 30.0, "batch_reward": 0.3488791469335556, "critic_loss": 1.7954633806943894, "actor_loss": -67.81158360290527, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.765251398086548, "step": 30000}
{"episode_reward": 647.1492749219555, "episode": 31.0, "batch_reward": 0.35812519788742064, "critic_loss": 1.918778352022171, "actor_loss": -70.61907191848755, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.52569651603699, "step": 31000}
{"episode_reward": 703.9237017404249, "episode": 32.0, "batch_reward": 0.36597553044557574, "critic_loss": 2.0096707050800324, "actor_loss": -71.74493811416626, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.22324776649475, "step": 32000}
{"episode_reward": 517.1316854414546, "episode": 33.0, "batch_reward": 0.3733877330720425, "critic_loss": 2.2341387811899187, "actor_loss": -72.05010894012452, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.447471618652344, "step": 33000}
{"episode_reward": 622.4429809328226, "episode": 34.0, "batch_reward": 0.37996093136072157, "critic_loss": 2.431312315106392, "actor_loss": -72.22242764663696, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.435938119888306, "step": 34000}
{"episode_reward": 645.2594137971572, "episode": 35.0, "batch_reward": 0.3881267363131046, "critic_loss": 2.5878917343616488, "actor_loss": -72.44409516143799, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.311457872390747, "step": 35000}
{"episode_reward": 661.3711485220254, "episode": 36.0, "batch_reward": 0.396370198816061, "critic_loss": 2.6902372221946718, "actor_loss": -73.63323947143554, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.757357597351074, "step": 36000}
{"episode_reward": 664.2215133201142, "episode": 37.0, "batch_reward": 0.40323861786723136, "critic_loss": 2.66591064286232, "actor_loss": -72.15546337509156, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.466665029525757, "step": 37000}
{"episode_reward": 712.0232699086848, "episode": 38.0, "batch_reward": 0.40929886266589166, "critic_loss": 2.6978184629678728, "actor_loss": -71.63381729507446, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.39091730117798, "step": 38000}
{"episode_reward": 683.2341529575566, "episode": 39.0, "batch_reward": 0.4198756220936775, "critic_loss": 2.6964194244146347, "actor_loss": -71.89124004364014, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.613154888153076, "step": 39000}
{"episode_reward": 733.952800822306, "episode": 40.0, "batch_reward": 0.4275180116891861, "critic_loss": 2.647887634396553, "actor_loss": -73.75252160263061, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.572408199310303, "step": 40000}
{"episode_reward": 743.974684592946, "episode": 41.0, "batch_reward": 0.43427182552218435, "critic_loss": 2.6713002141714095, "actor_loss": -73.48222542572022, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 42.07678723335266, "step": 41000}
{"episode_reward": 710.207399656165, "episode": 42.0, "batch_reward": 0.44246017062664034, "critic_loss": 2.692545070409775, "actor_loss": -73.85863362121582, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.521309852600098, "step": 42000}
{"episode_reward": 646.9094757892306, "episode": 43.0, "batch_reward": 0.44874872094392776, "critic_loss": 2.6669335477352143, "actor_loss": -74.34521293640137, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.947450876235962, "step": 43000}
{"episode_reward": 820.8375813696107, "episode": 44.0, "batch_reward": 0.45483936861157415, "critic_loss": 2.621963935136795, "actor_loss": -77.81662395477295, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.75858235359192, "step": 44000}
{"episode_reward": 720.0480889904252, "episode": 45.0, "batch_reward": 0.4623665554821491, "critic_loss": 2.6743636968135833, "actor_loss": -75.72518363189697, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.750430822372437, "step": 45000}
{"episode_reward": 778.8960683300072, "episode": 46.0, "batch_reward": 0.4665222154557705, "critic_loss": 2.688547073364258, "actor_loss": -73.80932585906983, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.761534452438354, "step": 46000}
{"episode_reward": 615.9751184232271, "episode": 47.0, "batch_reward": 0.47174851018190384, "critic_loss": 2.780676817417145, "actor_loss": -75.43480764389038, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.264869213104248, "step": 47000}
{"episode_reward": 787.1197410280399, "episode": 48.0, "batch_reward": 0.47851961824297906, "critic_loss": 2.7490284934043885, "actor_loss": -75.236789894104, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.694259643554688, "step": 48000}
{"episode_reward": 626.4779668456956, "episode": 49.0, "batch_reward": 0.48211230444908143, "critic_loss": 2.6774196484088897, "actor_loss": -77.66739859008788, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.980182647705078, "step": 49000}
{"episode_reward": 694.4852782222184, "episode": 50.0, "batch_reward": 0.4847494470179081, "critic_loss": 2.6366846545934677, "actor_loss": -76.8218584060669, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.207597494125366, "step": 50000}
{"episode_reward": 673.5375527374795, "episode": 51.0, "batch_reward": 0.49129768991470335, "critic_loss": 2.5927038457393645, "actor_loss": -76.72057476043702, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 42.086791038513184, "step": 51000}
{"episode_reward": 795.9971565010878, "episode": 52.0, "batch_reward": 0.49858911013603213, "critic_loss": 2.597920338869095, "actor_loss": -76.18959983062744, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.335370302200317, "step": 52000}
{"episode_reward": 845.0350274577236, "episode": 53.0, "batch_reward": 0.5031250470876694, "critic_loss": 2.4842604467868803, "actor_loss": -77.92042001342773, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.45124101638794, "step": 53000}
{"episode_reward": 858.0270493463913, "episode": 54.0, "batch_reward": 0.508881143629551, "critic_loss": 2.518012698531151, "actor_loss": -78.82484719085693, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.83986186981201, "step": 54000}
{"episode_reward": 682.355791707757, "episode": 55.0, "batch_reward": 0.5098724548816681, "critic_loss": 2.562305012822151, "actor_loss": -78.39826094055175, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.18653678894043, "step": 55000}
{"episode_reward": 665.1404560446291, "episode": 56.0, "batch_reward": 0.5148125639855862, "critic_loss": 2.5857919332981107, "actor_loss": -78.34564724731446, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.450950145721436, "step": 56000}
{"episode_reward": 793.575478648483, "episode": 57.0, "batch_reward": 0.5213040241003036, "critic_loss": 2.76366214966774, "actor_loss": -78.64803093719482, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.89506459236145, "step": 57000}
{"episode_reward": 875.9555484261456, "episode": 58.0, "batch_reward": 0.5256312654018402, "critic_loss": 2.664140109062195, "actor_loss": -79.04895211791992, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.746504068374634, "step": 58000}
{"episode_reward": 708.3719626949713, "episode": 59.0, "batch_reward": 0.5300249533951282, "critic_loss": 2.7984210805892946, "actor_loss": -78.9778991394043, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.42526602745056, "step": 59000}
{"episode_reward": 823.0853795548707, "episode": 60.0, "batch_reward": 0.5347312467396259, "critic_loss": 2.8191568522453307, "actor_loss": -79.01136797332764, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.88167142868042, "step": 60000}
{"episode_reward": 724.2824033791532, "episode": 61.0, "batch_reward": 0.538132076472044, "critic_loss": 2.9012381051778795, "actor_loss": -79.01723355102538, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.1529107093811, "step": 61000}
{"episode_reward": 820.2184847300177, "episode": 62.0, "batch_reward": 0.5436391695737839, "critic_loss": 2.833600770831108, "actor_loss": -79.34640528869629, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.024282932281494, "step": 62000}
{"episode_reward": 871.1082667130056, "episode": 63.0, "batch_reward": 0.5482138803601265, "critic_loss": 2.8725433650016785, "actor_loss": -79.73281469726562, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.125568389892578, "step": 63000}
{"episode_reward": 812.7399092425915, "episode": 64.0, "batch_reward": 0.552422707259655, "critic_loss": 2.9023453751802446, "actor_loss": -80.61283110809326, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.578927278518677, "step": 64000}
{"episode_reward": 764.4111983449271, "episode": 65.0, "batch_reward": 0.5550693547129631, "critic_loss": 2.8749834131002427, "actor_loss": -79.7794416885376, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.97761106491089, "step": 65000}
{"episode_reward": 853.0644970304936, "episode": 66.0, "batch_reward": 0.5581604751348496, "critic_loss": 2.885358538031578, "actor_loss": -79.70290405273437, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.018348932266235, "step": 66000}
{"episode_reward": 694.7679111978941, "episode": 67.0, "batch_reward": 0.5623680795431137, "critic_loss": 3.0269043509960176, "actor_loss": -81.03938089752197, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.719807624816895, "step": 67000}
{"episode_reward": 811.6563924639102, "episode": 68.0, "batch_reward": 0.5637301042079925, "critic_loss": 3.0539329706430434, "actor_loss": -82.20292795562744, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.87895369529724, "step": 68000}
{"episode_reward": 845.3657368715625, "episode": 69.0, "batch_reward": 0.5679657902717591, "critic_loss": 3.0566522382497787, "actor_loss": -79.82094398498535, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.804760694503784, "step": 69000}
{"episode_reward": 770.3185971802858, "episode": 70.0, "batch_reward": 0.5722844921052456, "critic_loss": 3.1362375530004503, "actor_loss": -80.40489808654785, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.820524215698242, "step": 70000}
{"episode_reward": 840.3500308902618, "episode": 71.0, "batch_reward": 0.5752599647641182, "critic_loss": 3.1041320123672484, "actor_loss": -79.94320600891113, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.273624658584595, "step": 71000}
{"episode_reward": 816.2765040686895, "episode": 72.0, "batch_reward": 0.5776374642848968, "critic_loss": 3.293484024524689, "actor_loss": -81.54752019500732, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.78879690170288, "step": 72000}
{"episode_reward": 584.1490745481618, "episode": 73.0, "batch_reward": 0.58031500056386, "critic_loss": 3.213752733707428, "actor_loss": -81.91022554016114, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.97279191017151, "step": 73000}
{"episode_reward": 805.939961404748, "episode": 74.0, "batch_reward": 0.5820999465882778, "critic_loss": 3.298345713019371, "actor_loss": -80.78361841583252, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.72785449028015, "step": 74000}
{"episode_reward": 794.7967793576163, "episode": 75.0, "batch_reward": 0.5837922203540802, "critic_loss": 3.4375045710802077, "actor_loss": -81.00465436553955, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.64544439315796, "step": 75000}
{"episode_reward": 854.887416710764, "episode": 76.0, "batch_reward": 0.5898727871179581, "critic_loss": 3.388697973847389, "actor_loss": -81.88950924682617, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.94236135482788, "step": 76000}
{"episode_reward": 844.6753624604689, "episode": 77.0, "batch_reward": 0.5913992622494697, "critic_loss": 3.3515369910001755, "actor_loss": -81.36891330718994, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.77293610572815, "step": 77000}
{"episode_reward": 861.7453116844679, "episode": 78.0, "batch_reward": 0.5956335597038269, "critic_loss": 3.4250342807769774, "actor_loss": -82.12139627838135, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.471901416778564, "step": 78000}
{"episode_reward": 875.99557628751, "episode": 79.0, "batch_reward": 0.5999707126617432, "critic_loss": 3.5818390157222746, "actor_loss": -83.53999034881592, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.66817831993103, "step": 79000}
{"episode_reward": 856.4892913279507, "episode": 80.0, "batch_reward": 0.6026229093670845, "critic_loss": 3.68542819583416, "actor_loss": -82.90304279327393, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.47160768508911, "step": 80000}
{"episode_reward": 927.047186030564, "episode": 81.0, "batch_reward": 0.6079380921125412, "critic_loss": 3.6465744416713717, "actor_loss": -81.84794584655762, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.149815797805786, "step": 81000}
{"episode_reward": 797.8719430123825, "episode": 82.0, "batch_reward": 0.6080514602959156, "critic_loss": 3.6856090406179427, "actor_loss": -82.13340200805663, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.946062803268433, "step": 82000}
{"episode_reward": 884.4577456117096, "episode": 83.0, "batch_reward": 0.6123260653614998, "critic_loss": 3.629941065788269, "actor_loss": -83.0418155670166, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.77327036857605, "step": 83000}
{"episode_reward": 885.5680141689728, "episode": 84.0, "batch_reward": 0.6165509903430939, "critic_loss": 3.572724230885506, "actor_loss": -83.80825232696533, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.53276491165161, "step": 84000}
{"episode_reward": 857.4872866323311, "episode": 85.0, "batch_reward": 0.6184315814971924, "critic_loss": 3.4944308018684387, "actor_loss": -83.38408922576905, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.921406745910645, "step": 85000}
{"episode_reward": 881.5458006924472, "episode": 86.0, "batch_reward": 0.6214154187440872, "critic_loss": 3.479774190068245, "actor_loss": -83.421365234375, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.069535970687866, "step": 86000}
{"episode_reward": 838.9464391880332, "episode": 87.0, "batch_reward": 0.6215437963604927, "critic_loss": 3.516359454035759, "actor_loss": -83.89237712860107, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.56954598426819, "step": 87000}
{"episode_reward": 865.3270394620699, "episode": 88.0, "batch_reward": 0.6273525205254554, "critic_loss": 3.346140960693359, "actor_loss": -83.11979837036132, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.904970407485962, "step": 88000}
{"episode_reward": 860.1959746726695, "episode": 89.0, "batch_reward": 0.6296005519628525, "critic_loss": 3.448823120713234, "actor_loss": -83.87865664672852, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.758776664733887, "step": 89000}
{"episode_reward": 839.247512101978, "episode": 90.0, "batch_reward": 0.6329400839209557, "critic_loss": 3.409018170595169, "actor_loss": -83.65074968719482, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.499012231826782, "step": 90000}
{"episode_reward": 866.3922964197458, "episode": 91.0, "batch_reward": 0.6339785405993461, "critic_loss": 3.459968965768814, "actor_loss": -83.93571356964111, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 42.18774724006653, "step": 91000}
{"episode_reward": 792.02494780137, "episode": 92.0, "batch_reward": 0.6363194565176964, "critic_loss": 3.423277773976326, "actor_loss": -85.14553088378906, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.606799602508545, "step": 92000}
{"episode_reward": 851.3472457996561, "episode": 93.0, "batch_reward": 0.6371923541426658, "critic_loss": 3.4097967975139616, "actor_loss": -83.85528723144532, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.222586154937744, "step": 93000}
{"episode_reward": 857.9617953553275, "episode": 94.0, "batch_reward": 0.6417827033400536, "critic_loss": 3.366430101633072, "actor_loss": -84.8155862197876, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.637078046798706, "step": 94000}
{"episode_reward": 873.9698971201609, "episode": 95.0, "batch_reward": 0.6426666306853295, "critic_loss": 3.2679437831640246, "actor_loss": -85.65746423339844, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.42165970802307, "step": 95000}
{"episode_reward": 828.4826230883244, "episode": 96.0, "batch_reward": 0.6464766244888306, "critic_loss": 3.3052007732391355, "actor_loss": -85.66053087615967, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.1570987701416, "step": 96000}
{"episode_reward": 882.4199291447845, "episode": 97.0, "batch_reward": 0.6468708234429359, "critic_loss": 3.4204696633815765, "actor_loss": -85.20680727386474, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.7363862991333, "step": 97000}
{"episode_reward": 905.8999469890675, "episode": 98.0, "batch_reward": 0.6485437659025193, "critic_loss": 3.2785093076229095, "actor_loss": -86.02728958129883, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.435178518295288, "step": 98000}
{"episode_reward": 865.6171499049451, "episode": 99.0, "batch_reward": 0.6517081615328789, "critic_loss": 3.4227001422643664, "actor_loss": -85.11496146392822, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.018275022506714, "step": 99000}
{"episode_reward": 812.0658884498205, "episode": 100.0, "batch_reward": 0.6541938806176185, "critic_loss": 3.5677324080467225, "actor_loss": -85.95261241149902, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.01751160621643, "step": 100000}
{"episode_reward": 835.2760887578115, "episode": 101.0, "batch_reward": 0.6560494118928909, "critic_loss": 3.4870269693136215, "actor_loss": -84.99135593414307, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.12218952178955, "step": 101000}
{"episode_reward": 907.6282614934363, "episode": 102.0, "batch_reward": 0.6600977694392204, "critic_loss": 3.554444712638855, "actor_loss": -86.0596614151001, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.790260791778564, "step": 102000}
{"episode_reward": 851.0693792458687, "episode": 103.0, "batch_reward": 0.6590511069297791, "critic_loss": 3.550571686387062, "actor_loss": -85.25657601165771, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.585429668426514, "step": 103000}
{"episode_reward": 836.6981730106291, "episode": 104.0, "batch_reward": 0.6620619381666184, "critic_loss": 3.458873997092247, "actor_loss": -85.3362373123169, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.4065682888031, "step": 104000}
{"episode_reward": 756.5674868350977, "episode": 105.0, "batch_reward": 0.6639605198502541, "critic_loss": 3.2835020418167113, "actor_loss": -85.93297059631348, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.741079568862915, "step": 105000}
{"episode_reward": 914.5466952041154, "episode": 106.0, "batch_reward": 0.6654255453944207, "critic_loss": 3.331873937368393, "actor_loss": -85.95308140563965, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.812580347061157, "step": 106000}
{"episode_reward": 886.0392911157967, "episode": 107.0, "batch_reward": 0.6677465611696243, "critic_loss": 3.311145865678787, "actor_loss": -85.40743093109131, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.11438012123108, "step": 107000}
{"episode_reward": 911.4392677895567, "episode": 108.0, "batch_reward": 0.6695891209244728, "critic_loss": 3.278480946779251, "actor_loss": -86.58562831878662, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.038758754730225, "step": 108000}
{"episode_reward": 895.9940267311176, "episode": 109.0, "batch_reward": 0.6730778452157974, "critic_loss": 3.1024820339679717, "actor_loss": -86.30532702636718, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.714404821395874, "step": 109000}
{"episode_reward": 841.7167884618651, "episode": 110.0, "batch_reward": 0.6726037378311157, "critic_loss": 3.226416718006134, "actor_loss": -87.25082943725586, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.165074825286865, "step": 110000}
{"episode_reward": 834.9534327186498, "episode": 111.0, "batch_reward": 0.6742232226729393, "critic_loss": 3.0656477224826815, "actor_loss": -86.43659414672851, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.696189403533936, "step": 111000}
{"episode_reward": 928.5870334542187, "episode": 112.0, "batch_reward": 0.67617657995224, "critic_loss": 3.2089397575855254, "actor_loss": -86.64231707763672, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.21400499343872, "step": 112000}
{"episode_reward": 933.5359460851084, "episode": 113.0, "batch_reward": 0.6793939383029938, "critic_loss": 3.3286667252779005, "actor_loss": -86.5756561126709, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.76404070854187, "step": 113000}
{"episode_reward": 869.8824634685412, "episode": 114.0, "batch_reward": 0.6824516707658768, "critic_loss": 3.189143526673317, "actor_loss": -87.15652502441407, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.942169666290283, "step": 114000}
{"episode_reward": 847.0006255219489, "episode": 115.0, "batch_reward": 0.6835286984443665, "critic_loss": 3.268403056025505, "actor_loss": -87.1468924255371, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.99450659751892, "step": 115000}
{"episode_reward": 886.4351014270155, "episode": 116.0, "batch_reward": 0.6848583552837372, "critic_loss": 3.254157294034958, "actor_loss": -87.26508326721192, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.893434286117554, "step": 116000}
{"episode_reward": 905.7601244568144, "episode": 117.0, "batch_reward": 0.6880561402440071, "critic_loss": 3.1835469788312913, "actor_loss": -86.69633006286621, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.499834299087524, "step": 117000}
{"episode_reward": 883.5229385231469, "episode": 118.0, "batch_reward": 0.6882117226719856, "critic_loss": 3.1442994236946107, "actor_loss": -87.08974371337891, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.030385732650757, "step": 118000}
{"episode_reward": 895.9491365256251, "episode": 119.0, "batch_reward": 0.6901309875845909, "critic_loss": 3.2601052626371385, "actor_loss": -87.476830078125, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.764893770217896, "step": 119000}
{"episode_reward": 847.6146024739148, "episode": 120.0, "batch_reward": 0.6904994102716446, "critic_loss": 3.174522201180458, "actor_loss": -86.62097604370118, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.474323749542236, "step": 120000}
{"episode_reward": 915.8791844043233, "episode": 121.0, "batch_reward": 0.6932529814243317, "critic_loss": 3.03079091155529, "actor_loss": -87.35802404785156, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 42.09521961212158, "step": 121000}
{"episode_reward": 875.993869319325, "episode": 122.0, "batch_reward": 0.6953389852643013, "critic_loss": 2.9556907942295076, "actor_loss": -87.87125875854493, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.43134355545044, "step": 122000}
{"episode_reward": 860.702592356301, "episode": 123.0, "batch_reward": 0.6968699951767922, "critic_loss": 2.9019938830137253, "actor_loss": -88.16853762817382, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.407782793045044, "step": 123000}
{"episode_reward": 841.1530860642473, "episode": 124.0, "batch_reward": 0.6956902455091476, "critic_loss": 2.889909814476967, "actor_loss": -87.8810339050293, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.950329065322876, "step": 124000}
{"episode_reward": 847.567508994912, "episode": 125.0, "batch_reward": 0.6967645578384399, "critic_loss": 2.9097848653793337, "actor_loss": -87.63399046325684, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.716972589492798, "step": 125000}
{"episode_reward": 921.8440273725145, "episode": 126.0, "batch_reward": 0.6999007059931756, "critic_loss": 3.026707318305969, "actor_loss": -88.27822268676758, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.227033853530884, "step": 126000}
{"episode_reward": 916.765986399143, "episode": 127.0, "batch_reward": 0.7013468171358108, "critic_loss": 3.063501834988594, "actor_loss": -87.98441166687012, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.73496699333191, "step": 127000}
{"episode_reward": 948.77025135475, "episode": 128.0, "batch_reward": 0.7041605370640754, "critic_loss": 3.1140677217245103, "actor_loss": -87.53124775695801, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.568105220794678, "step": 128000}
{"episode_reward": 901.9710382431123, "episode": 129.0, "batch_reward": 0.7054952580332756, "critic_loss": 3.0990259907245634, "actor_loss": -88.07116793823242, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.47786855697632, "step": 129000}
{"episode_reward": 900.9478882658003, "episode": 130.0, "batch_reward": 0.7071993715167045, "critic_loss": 2.9615886360406876, "actor_loss": -88.50215287780762, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.498504877090454, "step": 130000}
{"episode_reward": 928.7335582354881, "episode": 131.0, "batch_reward": 0.7077838217616081, "critic_loss": 2.7911627823114395, "actor_loss": -87.35959130859375, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.343827962875366, "step": 131000}
{"episode_reward": 930.6562819696478, "episode": 132.0, "batch_reward": 0.7087868130207062, "critic_loss": 2.8449244302511216, "actor_loss": -88.80002967834473, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.99618148803711, "step": 132000}
{"episode_reward": 867.6188120816154, "episode": 133.0, "batch_reward": 0.7122546590566635, "critic_loss": 2.803308605313301, "actor_loss": -87.8754368133545, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.954277753829956, "step": 133000}
{"episode_reward": 915.8718531430554, "episode": 134.0, "batch_reward": 0.7130301729440689, "critic_loss": 2.8634294021129607, "actor_loss": -88.32511616516113, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.985284090042114, "step": 134000}
{"episode_reward": 941.1349994496791, "episode": 135.0, "batch_reward": 0.7141204122304916, "critic_loss": 2.8399372252225876, "actor_loss": -88.82201039123535, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.56051278114319, "step": 135000}
{"episode_reward": 911.6688901930555, "episode": 136.0, "batch_reward": 0.7160832686424256, "critic_loss": 2.879165720462799, "actor_loss": -88.34075628662109, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.481215953826904, "step": 136000}
{"episode_reward": 886.2537005537548, "episode": 137.0, "batch_reward": 0.7194063268303871, "critic_loss": 2.9495825543403624, "actor_loss": -88.87866386413575, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.750614881515503, "step": 137000}
{"episode_reward": 846.692542893814, "episode": 138.0, "batch_reward": 0.7192685807347298, "critic_loss": 2.9710717813968657, "actor_loss": -89.41239801025391, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 22.038029432296753, "step": 138000}
{"episode_reward": 897.0796361896206, "episode": 139.0, "batch_reward": 0.7198935039043427, "critic_loss": 2.9322119172811507, "actor_loss": -88.10421998596192, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.57865047454834, "step": 139000}
{"episode_reward": 839.4744422513687, "episode": 140.0, "batch_reward": 0.7183140435218811, "critic_loss": 2.8272100644111635, "actor_loss": -89.1821602935791, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.19201135635376, "step": 140000}
{"episode_reward": 900.6190671998147, "episode": 141.0, "batch_reward": 0.7235922335386277, "critic_loss": 2.7239620851278303, "actor_loss": -88.79981648254395, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 41.79542636871338, "step": 141000}
{"episode_reward": 871.1547739995441, "episode": 142.0, "batch_reward": 0.7240174497961998, "critic_loss": 2.784454280257225, "actor_loss": -88.76408116149902, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.154150009155273, "step": 142000}
{"episode_reward": 801.636545996662, "episode": 143.0, "batch_reward": 0.7217428141236305, "critic_loss": 2.842602273106575, "actor_loss": -88.80163847351074, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.69591975212097, "step": 143000}
{"episode_reward": 839.9331311362481, "episode": 144.0, "batch_reward": 0.7245224385261536, "critic_loss": 2.7672621573209764, "actor_loss": -89.21287019348145, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.47836446762085, "step": 144000}
{"episode_reward": 882.8805114572252, "episode": 145.0, "batch_reward": 0.7267409112453461, "critic_loss": 2.772849270582199, "actor_loss": -89.18059590148926, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.117358207702637, "step": 145000}
{"episode_reward": 920.7365983532674, "episode": 146.0, "batch_reward": 0.7245742371082305, "critic_loss": 2.803395220041275, "actor_loss": -88.43185188293457, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.916285037994385, "step": 146000}
{"episode_reward": 893.2844462925473, "episode": 147.0, "batch_reward": 0.7259096372723579, "critic_loss": 2.844261921286583, "actor_loss": -88.96626864624024, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.15065884590149, "step": 147000}
{"episode_reward": 891.5047919582505, "episode": 148.0, "batch_reward": 0.7298866491317749, "critic_loss": 2.8563614526987076, "actor_loss": -88.91462133789062, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 20.884532690048218, "step": 148000}
{"episode_reward": 899.1001822416401, "episode": 149.0, "batch_reward": 0.7304761137366295, "critic_loss": 2.8013063287734985, "actor_loss": -89.27707858276368, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 21.663734912872314, "step": 149000}
{"episode_reward": 882.6988417178574, "episode": 150.0, "batch_reward": 0.7296948220133781, "critic_loss": 2.8415186351537702, "actor_loss": -89.53347924804687, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "step": 150000}
