{"episode": 1.0, "duration": 23.757244110107422, "episode_reward": 28.002640152663393, "step": 1000}
{"episode": 2.0, "duration": 2.1313726902008057, "episode_reward": 481.4321918933315, "step": 2000}
{"episode": 3.0, "batch_reward": 0.24020668762640066, "actor_loss": -85.92645360079227, "actor_target_entropy": -6.0, "alpha_value": 0.00244617320470393, "duration": 62.95797300338745, "episode_reward": 12.150722326607784, "step": 3000}
{"episode": 4.0, "batch_reward": 0.15183628133684396, "actor_loss": -79.65246058654785, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.326099395751953, "episode_reward": 6.415369498054089, "step": 4000}
{"episode": 5.0, "batch_reward": 0.1220051013417542, "actor_loss": -77.34126260375976, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.598856687545776, "episode_reward": 50.140770392895234, "step": 5000}
{"episode": 6.0, "batch_reward": 0.10908327843993902, "actor_loss": -76.71875163269043, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.78497076034546, "episode_reward": 39.178863925405594, "step": 6000}
{"episode": 7.0, "batch_reward": 0.09748130817711353, "actor_loss": -76.27622120666504, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.181556940078735, "episode_reward": 33.59646147924724, "step": 7000}
{"episode": 8.0, "batch_reward": 0.08965703835710884, "actor_loss": -76.8679077758789, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.0466570854187, "episode_reward": 32.83932048019098, "step": 8000}
{"episode": 9.0, "batch_reward": 0.08266805269569158, "actor_loss": -77.36310307312012, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.336894989013672, "episode_reward": 36.184357840987744, "step": 9000}
{"episode": 10.0, "batch_reward": 0.07762540997937321, "actor_loss": -74.4449382019043, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 3944.6828529834747, "episode_reward": 23.380760803836033, "step": 10000}
{"episode": 11.0, "batch_reward": 0.07747771747037768, "actor_loss": -73.95616329956054, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 36.64947485923767, "episode_reward": 99.84887952598152, "step": 11000}
{"episode": 12.0, "batch_reward": 0.07462604666501284, "actor_loss": -70.94633906555175, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 431.01833629608154, "episode_reward": 31.509612286353313, "step": 12000}
{"episode": 13.0, "batch_reward": 0.07078567409515381, "actor_loss": -71.46120468139648, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.116588354110718, "episode_reward": 29.386643797785265, "step": 13000}
{"episode": 14.0, "batch_reward": 0.07142278039455414, "actor_loss": -69.83386563110352, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 431.7911305427551, "episode_reward": 93.32814915636641, "step": 14000}
{"episode": 15.0, "batch_reward": 0.07246890584006906, "actor_loss": -69.79212983703613, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.000061988830566, "episode_reward": 109.52736484941857, "step": 15000}
{"episode": 16.0, "batch_reward": 0.07216597247123718, "actor_loss": -68.9725362854004, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 429.85438108444214, "episode_reward": 25.325039760201758, "step": 16000}
{"episode": 17.0, "batch_reward": 0.07168785646185279, "actor_loss": -69.15710177612304, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.7503023147583, "episode_reward": 116.2454317186664, "step": 17000}
{"episode": 18.0, "batch_reward": 0.07554944714158773, "actor_loss": -70.49354937744141, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 427.3256616592407, "episode_reward": 135.70689141907468, "step": 18000}
{"episode": 19.0, "batch_reward": 0.07537080185115337, "actor_loss": -70.55822619628906, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.445392370224, "episode_reward": 25.42195564496899, "step": 19000}
{"episode": 20.0, "batch_reward": 0.0725174186937511, "actor_loss": -69.70904846191407, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 424.9723131656647, "episode_reward": 18.1127370917872, "step": 20000}
{"episode": 21.0, "batch_reward": 0.07115568654984236, "actor_loss": -69.3439603729248, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 37.38384819030762, "episode_reward": 56.24735005612183, "step": 21000}
{"episode": 22.0, "batch_reward": 0.06934221541509032, "actor_loss": -68.80747004699707, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 427.0358371734619, "episode_reward": 13.926192836591497, "step": 22000}
{"episode": 23.0, "batch_reward": 0.06787035878002644, "actor_loss": -68.72537838745117, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.74663758277893, "episode_reward": 38.11518117529311, "step": 23000}
{"episode": 24.0, "batch_reward": 0.06705899086594581, "actor_loss": -69.08836512756348, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 427.3507630825043, "episode_reward": 53.99998896797611, "step": 24000}
{"episode": 25.0, "batch_reward": 0.06518543474003673, "actor_loss": -69.37089225769043, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.800764083862305, "episode_reward": 26.71002330668125, "step": 25000}
{"episode": 26.0, "batch_reward": 0.06340265695750713, "actor_loss": -69.66397846984863, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 426.00478863716125, "episode_reward": 25.51119442510913, "step": 26000}
{"episode": 27.0, "batch_reward": 0.06312473963573575, "actor_loss": -69.8310986175537, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.781750917434692, "episode_reward": 44.742531922514175, "step": 27000}
{"episode": 28.0, "batch_reward": 0.0612518577426672, "actor_loss": -70.60274137878417, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 429.6576232910156, "episode_reward": 25.821506288788747, "step": 28000}
{"episode": 29.0, "batch_reward": 0.06038065064698458, "actor_loss": -70.73277801513672, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.54321813583374, "episode_reward": 31.989586225441986, "step": 29000}
{"episode": 30.0, "batch_reward": 0.06097795458883047, "actor_loss": -69.78015744018555, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 430.9033179283142, "episode_reward": 60.6508134498763, "step": 30000}
{"episode": 31.0, "batch_reward": 0.06211726520955563, "actor_loss": -69.72026092529296, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 35.84001111984253, "episode_reward": 100.7247667081872, "step": 31000}
{"episode": 32.0, "batch_reward": 0.060883684393018486, "actor_loss": -68.04078123474122, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 430.0757761001587, "episode_reward": 25.918840569239357, "step": 32000}
{"episode": 33.0, "batch_reward": 0.05980392053723335, "actor_loss": -68.33438273620605, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.900102138519287, "episode_reward": 26.43368936390599, "step": 33000}
{"episode": 34.0, "batch_reward": 0.05912028670683503, "actor_loss": -69.02837850952149, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 429.115033864975, "episode_reward": 39.441012331730576, "step": 34000}
{"episode": 35.0, "batch_reward": 0.058197046060115096, "actor_loss": -68.89604364013672, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.606207847595215, "episode_reward": 19.23012253118805, "step": 35000}
{"episode": 36.0, "batch_reward": 0.058091371286660434, "actor_loss": -69.49189834594726, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 435.76892280578613, "episode_reward": 73.88721817464342, "step": 36000}
{"episode": 37.0, "batch_reward": 0.05799837901443243, "actor_loss": -69.34984555053711, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.068150520324707, "episode_reward": 32.205221465053874, "step": 37000}
{"episode": 38.0, "batch_reward": 0.0570267206132412, "actor_loss": -68.58178218078613, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 428.01583075523376, "episode_reward": 16.96352226745953, "step": 38000}
{"episode": 39.0, "batch_reward": 0.056091118222102526, "actor_loss": -68.09762889099122, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.088215112686157, "episode_reward": 53.57761304578815, "step": 39000}
{"episode": 40.0, "batch_reward": 0.057498570505529645, "actor_loss": -66.27140677642822, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 435.7911536693573, "episode_reward": 124.74631772754437, "step": 40000}
{"episode": 41.0, "batch_reward": 0.05763712390884757, "actor_loss": -66.0669842224121, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 36.889524698257446, "episode_reward": 19.599764109007754, "step": 41000}
{"episode": 42.0, "batch_reward": 0.05624998694099486, "actor_loss": -65.9130438156128, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 418.8731162548065, "episode_reward": 31.534620978234894, "step": 42000}
{"episode": 43.0, "batch_reward": 0.05616127920150757, "actor_loss": -66.03974297332763, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.8907687664032, "episode_reward": 38.69019593021788, "step": 43000}
{"episode": 44.0, "batch_reward": 0.056122291661798954, "actor_loss": -66.99786279296875, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 432.0363121032715, "episode_reward": 40.75802876194756, "step": 44000}
{"episode": 45.0, "batch_reward": 0.055556408956646916, "actor_loss": -67.15702694702148, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.774796724319458, "episode_reward": 24.420492127891617, "step": 45000}
{"episode": 46.0, "batch_reward": 0.05470394681766629, "actor_loss": -64.31095005035401, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 420.08424139022827, "episode_reward": 30.36669192927019, "step": 46000}
{"episode": 47.0, "batch_reward": 0.0538573184274137, "actor_loss": -64.1152857131958, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.09560537338257, "episode_reward": 18.36316267345162, "step": 47000}
{"episode": 48.0, "batch_reward": 0.0544444249086082, "actor_loss": -59.40460935211182, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 434.08515787124634, "episode_reward": 124.11659666215165, "step": 48000}
{"episode": 49.0, "batch_reward": 0.05499077370017767, "actor_loss": -59.32064862060547, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.301933765411377, "episode_reward": 24.488059603580812, "step": 49000}
{"episode": 50.0, "batch_reward": 0.05532194581255317, "actor_loss": -60.80446576690674, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 425.0065448284149, "episode_reward": 79.8060064625552, "step": 50000}
{"episode": 51.0, "batch_reward": 0.055213097739964724, "actor_loss": -61.23648445129395, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 38.71242618560791, "episode_reward": 43.71825915538527, "step": 51000}
{"episode": 52.0, "batch_reward": 0.054390965133905414, "actor_loss": -66.52085583496094, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 427.86805152893066, "episode_reward": 35.94813144017998, "step": 52000}
{"episode": 53.0, "batch_reward": 0.055032626643776894, "actor_loss": -66.71025415039063, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.92584800720215, "episode_reward": 91.33237448823932, "step": 53000}
{"episode": 54.0, "batch_reward": 0.05512664610520005, "actor_loss": -65.33191870117187, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 423.51011085510254, "episode_reward": 52.09733376963448, "step": 54000}
{"episode": 55.0, "batch_reward": 0.05493520554341376, "actor_loss": -65.39769478607178, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.607332468032837, "episode_reward": 34.008800012114634, "step": 55000}
{"episode": 56.0, "batch_reward": 0.055135208904743195, "actor_loss": -62.922670684814456, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 432.8858504295349, "episode_reward": 71.8537118548063, "step": 56000}
{"episode": 57.0, "batch_reward": 0.055517036855220796, "actor_loss": -63.10113233184814, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.91083264350891, "episode_reward": 81.00095018924901, "step": 57000}
{"episode": 58.0, "batch_reward": 0.055240858234465125, "actor_loss": -61.48909069061279, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 428.8415901660919, "episode_reward": 15.571247738706917, "step": 58000}
{"episode": 59.0, "batch_reward": 0.05647647885605693, "actor_loss": -61.855285446166995, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.858490467071533, "episode_reward": 251.09061467599864, "step": 59000}
{"episode": 60.0, "batch_reward": 0.060217472521588204, "actor_loss": -64.12519766235351, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 430.5799181461334, "episode_reward": 244.1100749627048, "step": 60000}
{"episode": 61.0, "batch_reward": 0.06169999534636736, "actor_loss": -64.27262347412109, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 36.2592613697052, "episode_reward": 76.99472888237719, "step": 61000}
{"episode": 62.0, "batch_reward": 0.06186065305396914, "actor_loss": -64.64894955444336, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 431.50750851631165, "episode_reward": 138.79061064781075, "step": 62000}
{"episode": 63.0, "batch_reward": 0.06370055768638849, "actor_loss": -64.91876942443848, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.706385612487793, "episode_reward": 112.40731051811608, "step": 63000}
{"episode": 64.0, "batch_reward": 0.06474815534055232, "actor_loss": -65.29771751403808, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 423.13791680336, "episode_reward": 182.3919915277721, "step": 64000}
{"episode": 65.0, "batch_reward": 0.0649088279120624, "actor_loss": -65.0884635925293, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.533565998077393, "episode_reward": 18.86116889676521, "step": 65000}
{"episode": 66.0, "batch_reward": 0.0657090292647481, "actor_loss": -63.80729586791992, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 433.1868040561676, "episode_reward": 194.5772018808028, "step": 66000}
{"episode": 67.0, "batch_reward": 0.0667716796733439, "actor_loss": -64.07616331481934, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.494205236434937, "episode_reward": 94.99566070048826, "step": 67000}
{"episode": 68.0, "batch_reward": 0.06744965470209718, "actor_loss": -64.62523518371582, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 426.37782073020935, "episode_reward": 136.13464716119816, "step": 68000}
{"episode": 69.0, "batch_reward": 0.06890956094488501, "actor_loss": -64.89809934997558, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.963812351226807, "episode_reward": 64.969140572966, "step": 69000}
{"episode": 70.0, "batch_reward": 0.06810525956377388, "actor_loss": -66.37339492034913, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 433.5399327278137, "episode_reward": 59.394936672329095, "step": 70000}
{"episode": 71.0, "batch_reward": 0.06770330183580518, "actor_loss": -66.29763438415527, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 37.09989309310913, "episode_reward": 19.68765224657157, "step": 71000}
{"episode": 72.0, "batch_reward": 0.06735402772203088, "actor_loss": -65.38993478393554, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 428.60170245170593, "episode_reward": 17.954060237968502, "step": 72000}
{"episode": 73.0, "batch_reward": 0.06726340747997164, "actor_loss": -65.3266058959961, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.12620973587036, "episode_reward": 94.2463379434422, "step": 73000}
{"episode": 74.0, "batch_reward": 0.0662793322019279, "actor_loss": -65.21943584442138, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 429.00818371772766, "episode_reward": 18.265009154217775, "step": 74000}
{"episode": 75.0, "batch_reward": 0.06591299948096276, "actor_loss": -65.0936982498169, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.031391382217407, "episode_reward": 37.29822359278983, "step": 75000}
{"episode": 76.0, "batch_reward": 0.0664095718152821, "actor_loss": -65.68437798309326, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 426.8245623111725, "episode_reward": 145.41547033627165, "step": 76000}
{"episode": 77.0, "batch_reward": 0.06712199215590954, "actor_loss": -65.5860235824585, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.97461771965027, "episode_reward": 32.58179600822649, "step": 77000}
{"episode": 78.0, "batch_reward": 0.06702884767577053, "actor_loss": -64.8543910522461, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 432.3901720046997, "episode_reward": 128.8257311241273, "step": 78000}
{"episode": 79.0, "batch_reward": 0.06723214786499739, "actor_loss": -65.02895418548584, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.07912802696228, "episode_reward": 85.16890400777874, "step": 79000}
{"episode": 80.0, "batch_reward": 0.06887486144900322, "actor_loss": -65.07916397094726, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 427.9455633163452, "episode_reward": 289.7602241847394, "step": 80000}
{"episode": 81.0, "batch_reward": 0.07194615084305406, "actor_loss": -65.41467021942138, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 40.93490982055664, "episode_reward": 232.7379626384565, "step": 81000}
{"episode": 82.0, "batch_reward": 0.0722275836840272, "actor_loss": -65.0389082107544, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 429.4316556453705, "episode_reward": 58.17080496097656, "step": 82000}
{"episode": 83.0, "batch_reward": 0.07425204291939735, "actor_loss": -65.12058196258545, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.744438409805298, "episode_reward": 359.5654067102313, "step": 83000}
{"episode": 84.0, "batch_reward": 0.07584757240861655, "actor_loss": -64.10050401306152, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 431.567223072052, "episode_reward": 83.63219167254604, "step": 84000}
{"episode": 85.0, "batch_reward": 0.0772124385163188, "actor_loss": -64.2185795211792, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.82147717475891, "episode_reward": 210.99343531065648, "step": 85000}
{"episode": 86.0, "batch_reward": 0.07785071662440896, "actor_loss": -63.105197341918945, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 426.95722794532776, "episode_reward": 162.55961390320383, "step": 86000}
{"episode": 87.0, "batch_reward": 0.07996754838898779, "actor_loss": -63.397582748413086, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.3734028339386, "episode_reward": 325.04904575867636, "step": 87000}
{"episode": 88.0, "batch_reward": 0.08155532257258892, "actor_loss": -63.74314910125732, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 430.5608744621277, "episode_reward": 98.42071922084351, "step": 88000}
{"episode": 89.0, "batch_reward": 0.08140410857275128, "actor_loss": -63.75998419189453, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.139966011047363, "episode_reward": 207.71101217371685, "step": 89000}
{"episode": 90.0, "batch_reward": 0.0823434787914157, "actor_loss": -63.0219178314209, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 423.51794838905334, "episode_reward": 17.74754501688225, "step": 90000}
{"episode": 91.0, "batch_reward": 0.08178483206406235, "actor_loss": -62.89437705230713, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 40.120872497558594, "episode_reward": 19.998880191932262, "step": 91000}
{"episode": 92.0, "batch_reward": 0.08201981483772397, "actor_loss": -61.30387005615234, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 422.4726312160492, "episode_reward": 359.4475888778922, "step": 92000}
{"episode": 93.0, "batch_reward": 0.08506484184414148, "actor_loss": -61.8071042175293, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.766083002090454, "episode_reward": 248.46341919614113, "step": 93000}
{"episode": 94.0, "batch_reward": 0.0864208422191441, "actor_loss": -61.98815214538574, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 426.3151307106018, "episode_reward": 133.7184453666865, "step": 94000}
{"episode": 95.0, "batch_reward": 0.08729845537245273, "actor_loss": -62.0605110244751, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.946052312850952, "episode_reward": 188.25454292256342, "step": 95000}
{"episode": 96.0, "batch_reward": 0.08800257070735097, "actor_loss": -62.67411067199707, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 432.4128849506378, "episode_reward": 77.91713319121442, "step": 96000}
{"episode": 97.0, "batch_reward": 0.08930556388944387, "actor_loss": -62.75981538391113, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.533268451690674, "episode_reward": 242.3534449218095, "step": 97000}
{"episode": 98.0, "batch_reward": 0.08932495405524969, "actor_loss": -62.382303825378415, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 427.67274141311646, "episode_reward": 85.04504808726946, "step": 98000}
{"episode": 99.0, "batch_reward": 0.090047835893929, "actor_loss": -62.42571092224121, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.510964155197144, "episode_reward": 246.18993718723175, "step": 99000}
{"episode": 100.0, "batch_reward": 0.0911751419827342, "actor_loss": -62.46721581268311, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 427.7904198169708, "episode_reward": 298.3049744314554, "step": 100000}
{"episode": 101.0, "batch_reward": 0.0928519823551178, "actor_loss": -62.504219604492185, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 36.03218340873718, "episode_reward": 85.7326252016886, "step": 101000}
{"episode": 102.0, "batch_reward": 0.09197519159317016, "actor_loss": -62.708434242248536, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 434.32404351234436, "episode_reward": 25.639024725052227, "step": 102000}
{"episode": 103.0, "batch_reward": 0.09269791052490473, "actor_loss": -62.68936326599121, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.121068954467773, "episode_reward": 202.07235717880076, "step": 103000}
{"episode": 104.0, "batch_reward": 0.09440111013874411, "actor_loss": -63.1093422164917, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 423.7874948978424, "episode_reward": 408.9662206646832, "step": 104000}
{"episode": 105.0, "batch_reward": 0.09695997593179345, "actor_loss": -63.280391777038574, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 15.863824367523193, "episode_reward": 338.6450803508228, "step": 105000}
{"episode": 106.0, "batch_reward": 0.09947736810892821, "actor_loss": -64.71294109344483, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 437.2335755825043, "episode_reward": 297.515497610769, "step": 106000}
{"episode": 107.0, "batch_reward": 0.10104605783522129, "actor_loss": -64.73934558868409, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.53759527206421, "episode_reward": 312.2713505453919, "step": 107000}
{"episode": 108.0, "batch_reward": 0.10268823403865099, "actor_loss": -64.61814776611328, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 425.078330039978, "episode_reward": 341.3473088964327, "step": 108000}
{"episode": 109.0, "batch_reward": 0.10449426340311765, "actor_loss": -64.75189822387695, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.444518089294434, "episode_reward": 136.83929381452492, "step": 109000}
{"episode": 110.0, "batch_reward": 0.10523832993209362, "actor_loss": -64.00261402130127, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 433.670147895813, "episode_reward": 302.26639699275245, "step": 110000}
{"episode": 111.0, "batch_reward": 0.10714864395558835, "actor_loss": -64.17901212310791, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 37.896270751953125, "episode_reward": 317.6878081782493, "step": 111000}
{"episode": 112.0, "batch_reward": 0.10896526212245226, "actor_loss": -63.89897959899902, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 425.9179081916809, "episode_reward": 348.0420425528532, "step": 112000}
{"episode": 113.0, "batch_reward": 0.11083752148225903, "actor_loss": -64.00292965698242, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.088653802871704, "episode_reward": 350.50975340498604, "step": 113000}
{"episode": 114.0, "batch_reward": 0.11386044049263, "actor_loss": -64.87681384277344, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 430.2052364349365, "episode_reward": 268.7399300876647, "step": 114000}
{"episode": 115.0, "batch_reward": 0.11510138294845819, "actor_loss": -64.97248333740234, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.162206888198853, "episode_reward": 354.7444127389513, "step": 115000}
{"episode": 116.0, "batch_reward": 0.11650962290912867, "actor_loss": -64.12658367919921, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 426.3258821964264, "episode_reward": 370.5664262263079, "step": 116000}
{"episode": 117.0, "batch_reward": 0.1186033035069704, "actor_loss": -64.31567874145507, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.01046085357666, "episode_reward": 416.9249836277223, "step": 117000}
{"episode": 118.0, "batch_reward": 0.12197889387607574, "actor_loss": -65.10464095306396, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 428.1676437854767, "episode_reward": 334.31460614026395, "step": 118000}
{"episode": 119.0, "batch_reward": 0.12315354473888875, "actor_loss": -65.19442646789551, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 15.89901852607727, "episode_reward": 268.00550007010236, "step": 119000}
{"episode": 120.0, "batch_reward": 0.12559775315225125, "actor_loss": -65.71078887176513, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 431.94196343421936, "episode_reward": 489.0930951660015, "step": 120000}
{"episode": 121.0, "batch_reward": 0.12664342653751373, "actor_loss": -65.77537338256836, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 38.112834453582764, "episode_reward": 14.646223433426314, "step": 121000}
{"episode": 122.0, "batch_reward": 0.1280506526529789, "actor_loss": -65.68195817565918, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 423.719379901886, "episode_reward": 440.2127503201171, "step": 122000}
{"episode": 123.0, "batch_reward": 0.12997097885608674, "actor_loss": -65.79469039154053, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.674026250839233, "episode_reward": 332.84174104636304, "step": 123000}
{"episode": 124.0, "batch_reward": 0.13046272352337837, "actor_loss": -66.55784609222412, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 429.2211172580719, "episode_reward": 14.57128058887912, "step": 124000}
{"episode": 125.0, "batch_reward": 0.13092498487979173, "actor_loss": -66.42731234741211, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.110979557037354, "episode_reward": 374.2922162812481, "step": 125000}
{"episode": 126.0, "batch_reward": 0.13327348648011683, "actor_loss": -66.49887593078613, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 424.0796513557434, "episode_reward": 443.0252178567964, "step": 126000}
{"episode": 127.0, "batch_reward": 0.13378165559470653, "actor_loss": -66.52849117279052, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.680219888687134, "episode_reward": 206.09284453674545, "step": 127000}
{"episode": 128.0, "batch_reward": 0.1342585964128375, "actor_loss": -66.90768865203857, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 431.7146146297455, "episode_reward": 18.401174993292205, "step": 128000}
{"episode": 129.0, "batch_reward": 0.13347407300770284, "actor_loss": -66.89027243041993, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.214518308639526, "episode_reward": 130.60757333361428, "step": 129000}
{"episode": 130.0, "batch_reward": 0.13381043506413698, "actor_loss": -67.25499104309083, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 424.119576215744, "episode_reward": 339.3941674438172, "step": 130000}
{"episode": 131.0, "batch_reward": 0.13446789288520813, "actor_loss": -67.20242153930664, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 40.07952809333801, "episode_reward": 13.783969175315665, "step": 131000}
{"episode": 132.0, "batch_reward": 0.13418834333866836, "actor_loss": -66.73166479492187, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 429.05358028411865, "episode_reward": 490.07260270647583, "step": 132000}
{"episode": 133.0, "batch_reward": 0.13906840462237596, "actor_loss": -66.88868139648437, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.96900749206543, "episode_reward": 487.249827176756, "step": 133000}
{"episode": 134.0, "batch_reward": 0.13891596457362174, "actor_loss": -66.77193045806885, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 426.93298506736755, "episode_reward": 16.22942847500959, "step": 134000}
{"episode": 135.0, "batch_reward": 0.13952116840332746, "actor_loss": -66.81941622924805, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.871097564697266, "episode_reward": 488.9356042385322, "step": 135000}
{"episode": 136.0, "batch_reward": 0.1403840123936534, "actor_loss": -66.27627203369141, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 431.0694317817688, "episode_reward": 21.998103329461028, "step": 136000}
{"episode": 137.0, "batch_reward": 0.1408540497869253, "actor_loss": -66.39910046386719, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.885291814804077, "episode_reward": 489.04235359717353, "step": 137000}
{"episode": 138.0, "batch_reward": 0.1442536948695779, "actor_loss": -66.1069327697754, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 427.5871469974518, "episode_reward": 530.7016793028241, "step": 138000}
{"episode": 139.0, "batch_reward": 0.14768594103306532, "actor_loss": -66.25149209594727, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 16.880653619766235, "episode_reward": 432.1369731179787, "step": 139000}
{"episode": 140.0, "batch_reward": 0.1495891099870205, "actor_loss": -66.339480758667, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 432.0019519329071, "episode_reward": 588.7184658407363, "step": 140000}
{"episode": 141.0, "batch_reward": 0.15130163563042878, "actor_loss": -66.42375082397461, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 36.23310589790344, "episode_reward": 434.4301154536911, "step": 141000}
{"episode": 142.0, "batch_reward": 0.15311876595765353, "actor_loss": -67.18210760498047, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 419.2243266105652, "episode_reward": 14.27223079491171, "step": 142000}
{"episode": 143.0, "batch_reward": 0.15183959168940783, "actor_loss": -67.01537154388427, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 19.008034467697144, "episode_reward": 237.38561618711842, "step": 143000}
{"episode": 144.0, "batch_reward": 0.15056707455217838, "actor_loss": -67.45866809082031, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 424.0604989528656, "episode_reward": 14.94741005645527, "step": 144000}
{"episode": 145.0, "batch_reward": 0.15083030821383, "actor_loss": -67.58676016235351, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 15.926546812057495, "episode_reward": 14.270803303801747, "step": 145000}
{"episode": 146.0, "batch_reward": 0.15107650768011807, "actor_loss": -66.14666567230225, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 431.90798783302307, "episode_reward": 498.1560170681442, "step": 146000}
{"episode": 147.0, "batch_reward": 0.1540748191922903, "actor_loss": -66.32739503479004, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 18.78801202774048, "episode_reward": 568.8940232440638, "step": 147000}
{"episode": 148.0, "batch_reward": 0.15716709185391664, "actor_loss": -64.88573259735108, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 426.4549489021301, "episode_reward": 490.87738794942857, "step": 148000}
{"episode": 149.0, "batch_reward": 0.15884740033745764, "actor_loss": -64.97265436553955, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "duration": 17.52897834777832, "episode_reward": 462.6447128585033, "step": 149000}
{"episode": 150.0, "batch_reward": 0.15998210754990577, "actor_loss": -64.69665710449219, "actor_target_entropy": -6.0, "alpha_value": 0.0024461732047040647, "step": 150000}
