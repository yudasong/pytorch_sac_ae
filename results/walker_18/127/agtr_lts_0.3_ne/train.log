{"episode_reward": 0.0, "episode": 1.0, "duration": 22.237387895584106, "step": 1000}
{"episode_reward": 28.002640152663393, "episode": 2.0, "duration": 1.9176232814788818, "step": 2000}
{"episode_reward": 481.4321918933315, "episode": 3.0, "batch_reward": 0.25981853553536494, "critic_loss": 0.6247071963711633, "actor_loss": -84.63405303832958, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 70.46945190429688, "step": 3000}
{"episode_reward": 385.8615125459003, "episode": 4.0, "batch_reward": 0.2962978252917528, "critic_loss": 0.8088848412334919, "actor_loss": -86.8575796508789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.439697265625, "step": 4000}
{"episode_reward": 241.25654846062372, "episode": 5.0, "batch_reward": 0.27825926527380945, "critic_loss": 0.6244320715367794, "actor_loss": -86.37641575622558, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.417877912521362, "step": 5000}
{"episode_reward": 176.68098409542876, "episode": 6.0, "batch_reward": 0.26441921590268613, "critic_loss": 0.6328833827972412, "actor_loss": -84.5772989807129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.417751789093018, "step": 6000}
{"episode_reward": 361.2001416620952, "episode": 7.0, "batch_reward": 0.2889575580060482, "critic_loss": 0.6428518364429474, "actor_loss": -83.28415216064454, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.412108421325684, "step": 7000}
{"episode_reward": 431.8409272593035, "episode": 8.0, "batch_reward": 0.31400017033517363, "critic_loss": 0.6407681329846382, "actor_loss": -82.57016319274902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.41104507446289, "step": 8000}
{"episode_reward": 396.58631953130975, "episode": 9.0, "batch_reward": 0.29735207435488703, "critic_loss": 0.5341103002429008, "actor_loss": -81.50597074890136, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.49384832382202, "step": 9000}
{"episode_reward": 35.96028588680415, "episode": 10.0, "batch_reward": 0.301017893910408, "critic_loss": 0.7976915160417557, "actor_loss": -80.84744288635254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.393139362335205, "step": 10000}
{"episode_reward": 656.810757394298, "episode": 11.0, "batch_reward": 0.3287781650722027, "critic_loss": 1.072144743204117, "actor_loss": -81.01093867492676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.24681353569031, "step": 11000}
{"episode_reward": 471.1080966493066, "episode": 12.0, "batch_reward": 0.3310019450485706, "critic_loss": 1.2006703010797501, "actor_loss": -81.04209426879883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.39189577102661, "step": 12000}
{"episode_reward": 381.1317031143068, "episode": 13.0, "batch_reward": 0.3302585299909115, "critic_loss": 1.430366924583912, "actor_loss": -80.37345127868652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.411829948425293, "step": 13000}
{"episode_reward": 293.8091624530307, "episode": 14.0, "batch_reward": 0.34442215502262113, "critic_loss": 1.6245576466321945, "actor_loss": -80.52708291625977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.41763401031494, "step": 14000}
{"episode_reward": 677.6012955693922, "episode": 15.0, "batch_reward": 0.3711565142869949, "critic_loss": 1.6739895907640456, "actor_loss": -80.77664375305176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.361527919769287, "step": 15000}
{"episode_reward": 731.7863202970028, "episode": 16.0, "batch_reward": 0.3906733286082745, "critic_loss": 1.6541458148956298, "actor_loss": -81.17246501159669, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.360599517822266, "step": 16000}
{"episode_reward": 669.9204851168375, "episode": 17.0, "batch_reward": 0.4127424749135971, "critic_loss": 1.5909546766281129, "actor_loss": -81.3842234802246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.37751078605652, "step": 17000}
{"episode_reward": 817.2436983263809, "episode": 18.0, "batch_reward": 0.4311959090828896, "critic_loss": 1.6112292239069939, "actor_loss": -81.47454248046876, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.412667751312256, "step": 18000}
{"episode_reward": 639.6151974919666, "episode": 19.0, "batch_reward": 0.4452320772707462, "critic_loss": 1.4836354926824569, "actor_loss": -81.51673825073242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.403826475143433, "step": 19000}
{"episode_reward": 764.0703187202795, "episode": 20.0, "batch_reward": 0.44229384952783585, "critic_loss": 1.319305292069912, "actor_loss": -81.27890948486328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.44339656829834, "step": 20000}
{"episode_reward": 17.163930347392917, "episode": 21.0, "batch_reward": 0.4413514721095562, "critic_loss": 1.3030202578306198, "actor_loss": -80.59153845214844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.1621618270874, "step": 21000}
{"episode_reward": 694.3247403322258, "episode": 22.0, "batch_reward": 0.4522413160204887, "critic_loss": 1.204406184732914, "actor_loss": -81.3127338256836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.392857789993286, "step": 22000}
{"episode_reward": 782.0767538740291, "episode": 23.0, "batch_reward": 0.46722414207458496, "critic_loss": 1.1588423606157303, "actor_loss": -80.89156423950195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.358570098876953, "step": 23000}
{"episode_reward": 658.7369845192818, "episode": 24.0, "batch_reward": 0.4753072833120823, "critic_loss": 1.0923853867650033, "actor_loss": -81.15053413391114, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.328752279281616, "step": 24000}
{"episode_reward": 782.3157242853583, "episode": 25.0, "batch_reward": 0.4858964328467846, "critic_loss": 1.0847299857735633, "actor_loss": -80.99232157897949, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.323126316070557, "step": 25000}
{"episode_reward": 742.8029636333857, "episode": 26.0, "batch_reward": 0.4988227851092815, "critic_loss": 1.072282941877842, "actor_loss": -81.00431471252442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.30530333518982, "step": 26000}
{"episode_reward": 813.29410315931, "episode": 27.0, "batch_reward": 0.5098397441208362, "critic_loss": 1.0527268670201302, "actor_loss": -81.16157223510743, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.3219997882843, "step": 27000}
{"episode_reward": 794.5406763297299, "episode": 28.0, "batch_reward": 0.5187173196971416, "critic_loss": 1.0511758012771606, "actor_loss": -81.88025346374512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.291149377822876, "step": 28000}
{"episode_reward": 804.9844242353041, "episode": 29.0, "batch_reward": 0.5312098947763443, "critic_loss": 1.0296486483812333, "actor_loss": -81.51216809082031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.279374837875366, "step": 29000}
{"episode_reward": 877.0351816743646, "episode": 30.0, "batch_reward": 0.5437980321347713, "critic_loss": 1.032405227303505, "actor_loss": -81.33721084594727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.92973566055298, "step": 30000}
{"episode_reward": 874.6139235424857, "episode": 31.0, "batch_reward": 0.5547438432574272, "critic_loss": 0.9994324023723602, "actor_loss": -81.72587838745117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.993335008621216, "step": 31000}
{"episode_reward": 827.7458926087311, "episode": 32.0, "batch_reward": 0.5634350434243679, "critic_loss": 1.0117212097644805, "actor_loss": -82.32878282165527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.459409475326538, "step": 32000}
{"episode_reward": 873.0206317763696, "episode": 33.0, "batch_reward": 0.5737763800024986, "critic_loss": 0.9556961842775344, "actor_loss": -82.69299052429199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.406931400299072, "step": 33000}
{"episode_reward": 932.7373890797812, "episode": 34.0, "batch_reward": 0.5799384225904941, "critic_loss": 0.9164025254249573, "actor_loss": -81.91437046813965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.40977454185486, "step": 34000}
{"episode_reward": 763.1568784205198, "episode": 35.0, "batch_reward": 0.5903112010657787, "critic_loss": 0.9033659144043923, "actor_loss": -82.88595498657227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.403156995773315, "step": 35000}
{"episode_reward": 906.0288551666657, "episode": 36.0, "batch_reward": 0.5979559992849827, "critic_loss": 0.8652512117922306, "actor_loss": -83.1614886932373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.42644166946411, "step": 36000}
{"episode_reward": 916.1662468369127, "episode": 37.0, "batch_reward": 0.6067160249352456, "critic_loss": 0.8521299582123757, "actor_loss": -83.08347749328614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.370934009552002, "step": 37000}
{"episode_reward": 886.8025470952584, "episode": 38.0, "batch_reward": 0.6138949020504951, "critic_loss": 0.8836058864295483, "actor_loss": -83.27922387695313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.44446849822998, "step": 38000}
{"episode_reward": 911.2601153939911, "episode": 39.0, "batch_reward": 0.6227632123231888, "critic_loss": 0.8720674215555191, "actor_loss": -83.64163665771484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.388091325759888, "step": 39000}
{"episode_reward": 940.2185681139488, "episode": 40.0, "batch_reward": 0.6293530173897743, "critic_loss": 0.8547899011671544, "actor_loss": -83.3121961517334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.451388597488403, "step": 40000}
{"episode_reward": 910.1706259591676, "episode": 41.0, "batch_reward": 0.6347510233521462, "critic_loss": 0.908567460000515, "actor_loss": -83.31673812866211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.157166481018066, "step": 41000}
{"episode_reward": 881.5860025814764, "episode": 42.0, "batch_reward": 0.6431856968998909, "critic_loss": 0.8953204256296158, "actor_loss": -84.12158140563965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.46075940132141, "step": 42000}
{"episode_reward": 932.6148649133368, "episode": 43.0, "batch_reward": 0.6499831843972206, "critic_loss": 0.8974630913436413, "actor_loss": -84.3423943786621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.42485737800598, "step": 43000}
{"episode_reward": 905.8361279085152, "episode": 44.0, "batch_reward": 0.6540637431144715, "critic_loss": 0.894271566271782, "actor_loss": -84.85120681762696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.348698377609253, "step": 44000}
{"episode_reward": 816.5498045718523, "episode": 45.0, "batch_reward": 0.6595608859062195, "critic_loss": 0.9189543894529343, "actor_loss": -84.93089402770997, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.431272983551025, "step": 45000}
{"episode_reward": 958.0203950047038, "episode": 46.0, "batch_reward": 0.6643335726261139, "critic_loss": 0.929191124022007, "actor_loss": -84.87228364562988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.38260316848755, "step": 46000}
{"episode_reward": 925.5958288052162, "episode": 47.0, "batch_reward": 0.6621873789429664, "critic_loss": 0.9154147532582283, "actor_loss": -84.83413722229004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.365273237228394, "step": 47000}
{"episode_reward": 184.17357058081163, "episode": 48.0, "batch_reward": 0.6612807984948158, "critic_loss": 0.908622677564621, "actor_loss": -84.74125262451172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.321632385253906, "step": 48000}
{"episode_reward": 904.5416122113978, "episode": 49.0, "batch_reward": 0.6681473926305771, "critic_loss": 0.8927302803993226, "actor_loss": -85.37579682922363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.38542366027832, "step": 49000}
{"episode_reward": 961.4194409573739, "episode": 50.0, "batch_reward": 0.6719512174129486, "critic_loss": 0.9172302172482014, "actor_loss": -85.34484536743165, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.403435468673706, "step": 50000}
{"episode_reward": 894.8174405996699, "episode": 51.0, "batch_reward": 0.6754865335822106, "critic_loss": 0.9004468137025833, "actor_loss": -85.44301239013672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.13537549972534, "step": 51000}
{"episode_reward": 884.2561876764944, "episode": 52.0, "batch_reward": 0.6817799328565598, "critic_loss": 0.8320084164738655, "actor_loss": -85.41645350646972, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.40756916999817, "step": 52000}
{"episode_reward": 962.3331321534686, "episode": 53.0, "batch_reward": 0.685190558731556, "critic_loss": 0.8227593947350978, "actor_loss": -86.2068669128418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.371749877929688, "step": 53000}
{"episode_reward": 948.3330616793841, "episode": 54.0, "batch_reward": 0.6914688073396683, "critic_loss": 0.7471114084124565, "actor_loss": -86.44258450317383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.360962867736816, "step": 54000}
{"episode_reward": 942.602004727265, "episode": 55.0, "batch_reward": 0.6952135965824128, "critic_loss": 0.7542048119604587, "actor_loss": -86.81059002685546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.329222679138184, "step": 55000}
{"episode_reward": 925.0771492572053, "episode": 56.0, "batch_reward": 0.7007329912185669, "critic_loss": 0.7364252068102359, "actor_loss": -86.83245120239258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.311787843704224, "step": 56000}
{"episode_reward": 962.2835997586974, "episode": 57.0, "batch_reward": 0.7042957829833031, "critic_loss": 0.7387419899106026, "actor_loss": -87.2500756225586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.325773239135742, "step": 57000}
{"episode_reward": 898.2352986078861, "episode": 58.0, "batch_reward": 0.7080781302452087, "critic_loss": 0.708608433842659, "actor_loss": -87.48616984558106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.270185470581055, "step": 58000}
{"episode_reward": 945.5848346120279, "episode": 59.0, "batch_reward": 0.7120449338555336, "critic_loss": 0.7049165353477002, "actor_loss": -87.42290019226074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.323843240737915, "step": 59000}
{"episode_reward": 982.2268617923168, "episode": 60.0, "batch_reward": 0.7170337790846825, "critic_loss": 0.6582900723814964, "actor_loss": -87.80128894042969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.292460680007935, "step": 60000}
{"episode_reward": 956.4614894310223, "episode": 61.0, "batch_reward": 0.7213636625409127, "critic_loss": 0.649844738215208, "actor_loss": -87.77814936828614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.60045886039734, "step": 61000}
{"episode_reward": 961.5522287292877, "episode": 62.0, "batch_reward": 0.7252729978561402, "critic_loss": 0.673119195997715, "actor_loss": -88.26216761779786, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.20175266265869, "step": 62000}
{"episode_reward": 956.364706240176, "episode": 63.0, "batch_reward": 0.7287685290575028, "critic_loss": 0.6349583946168422, "actor_loss": -88.04492929077148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.429457902908325, "step": 63000}
{"episode_reward": 969.949278928845, "episode": 64.0, "batch_reward": 0.7328293091058731, "critic_loss": 0.622644297003746, "actor_loss": -88.54306350708008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.434678077697754, "step": 64000}
{"episode_reward": 928.8143680153668, "episode": 65.0, "batch_reward": 0.7330917074680329, "critic_loss": 0.6188469405472279, "actor_loss": -88.56830952453613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.419000148773193, "step": 65000}
{"episode_reward": 878.8815933003316, "episode": 66.0, "batch_reward": 0.7364920732975007, "critic_loss": 0.6310513426959514, "actor_loss": -88.72668739318847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.444113969802856, "step": 66000}
{"episode_reward": 923.7450151095991, "episode": 67.0, "batch_reward": 0.7401942240595818, "critic_loss": 0.6658678100407124, "actor_loss": -89.14724685668945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.438563585281372, "step": 67000}
{"episode_reward": 914.8713301712526, "episode": 68.0, "batch_reward": 0.7443253474831582, "critic_loss": 0.6441564082801342, "actor_loss": -89.04526185607911, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.43826985359192, "step": 68000}
{"episode_reward": 963.4526418632031, "episode": 69.0, "batch_reward": 0.7431569706201553, "critic_loss": 0.6474166653752327, "actor_loss": -88.87367826843261, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.42516851425171, "step": 69000}
{"episode_reward": 934.1708021490866, "episode": 70.0, "batch_reward": 0.7484085829257965, "critic_loss": 0.6235519564449787, "actor_loss": -89.30220808410644, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.442325592041016, "step": 70000}
{"episode_reward": 963.7617405555048, "episode": 71.0, "batch_reward": 0.7487499812841415, "critic_loss": 0.653467827618122, "actor_loss": -89.41847631835938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.178948163986206, "step": 71000}
{"episode_reward": 884.4834000969906, "episode": 72.0, "batch_reward": 0.7523794976472855, "critic_loss": 0.649961531817913, "actor_loss": -89.3521586303711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.42549729347229, "step": 72000}
{"episode_reward": 892.3753142028941, "episode": 73.0, "batch_reward": 0.7554626623392106, "critic_loss": 0.6358320369124413, "actor_loss": -89.60782218933106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.414005279541016, "step": 73000}
{"episode_reward": 919.988995132732, "episode": 74.0, "batch_reward": 0.7566158887147904, "critic_loss": 0.6101171140372753, "actor_loss": -89.72026914978028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.45031762123108, "step": 74000}
{"episode_reward": 940.8095758857881, "episode": 75.0, "batch_reward": 0.7580312746763229, "critic_loss": 0.6197350868880749, "actor_loss": -89.68839065551758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.41265058517456, "step": 75000}
{"episode_reward": 853.4119204497765, "episode": 76.0, "batch_reward": 0.7605635870695114, "critic_loss": 0.6113227995336056, "actor_loss": -89.94811027526856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.39102029800415, "step": 76000}
{"episode_reward": 917.8291744550679, "episode": 77.0, "batch_reward": 0.7624914966225624, "critic_loss": 0.6383601447343826, "actor_loss": -90.19996516418458, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.457807302474976, "step": 77000}
{"episode_reward": 911.5979118493016, "episode": 78.0, "batch_reward": 0.7646286749839782, "critic_loss": 0.631286138266325, "actor_loss": -90.30206671142578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.37192440032959, "step": 78000}
{"episode_reward": 930.6436999690402, "episode": 79.0, "batch_reward": 0.7672945139408112, "critic_loss": 0.6568439401686191, "actor_loss": -90.50169763183594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.411851167678833, "step": 79000}
{"episode_reward": 955.7338494835744, "episode": 80.0, "batch_reward": 0.7694084950089455, "critic_loss": 0.6781153147518635, "actor_loss": -90.61038781738282, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.369030237197876, "step": 80000}
{"episode_reward": 952.736699043362, "episode": 81.0, "batch_reward": 0.772430201292038, "critic_loss": 0.6802836211025715, "actor_loss": -90.68226368713378, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.10152792930603, "step": 81000}
{"episode_reward": 864.3334479669887, "episode": 82.0, "batch_reward": 0.7724575824737548, "critic_loss": 0.6664523067176342, "actor_loss": -90.51620066833496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.40336799621582, "step": 82000}
{"episode_reward": 939.2475282201692, "episode": 83.0, "batch_reward": 0.776554535984993, "critic_loss": 0.6479166639149189, "actor_loss": -90.92230493164062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.42094349861145, "step": 83000}
{"episode_reward": 967.063226112358, "episode": 84.0, "batch_reward": 0.7769968351125717, "critic_loss": 0.6271992434859276, "actor_loss": -90.7967415008545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.394546270370483, "step": 84000}
{"episode_reward": 905.8690458410474, "episode": 85.0, "batch_reward": 0.7783032917976379, "critic_loss": 0.6293355891108513, "actor_loss": -90.98070184326171, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.369908571243286, "step": 85000}
{"episode_reward": 960.4638894387642, "episode": 86.0, "batch_reward": 0.7812544559836387, "critic_loss": 0.6230371586680412, "actor_loss": -91.06220045471191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.364418029785156, "step": 86000}
{"episode_reward": 968.6320708828761, "episode": 87.0, "batch_reward": 0.7841437873840332, "critic_loss": 0.5925932005643845, "actor_loss": -91.25412832641601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.38328742980957, "step": 87000}
{"episode_reward": 986.436766221247, "episode": 88.0, "batch_reward": 0.7856157538294792, "critic_loss": 0.6172571184933185, "actor_loss": -91.07881666564941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.375465869903564, "step": 88000}
{"episode_reward": 919.3778352822189, "episode": 89.0, "batch_reward": 0.7863875072002411, "critic_loss": 0.6295767519176007, "actor_loss": -91.15403601074219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.319574117660522, "step": 89000}
{"episode_reward": 866.9949120300242, "episode": 90.0, "batch_reward": 0.7892211626768112, "critic_loss": 0.6202460655868054, "actor_loss": -91.37357788085937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.33216404914856, "step": 90000}
{"episode_reward": 902.8967061703424, "episode": 91.0, "batch_reward": 0.7905578143596649, "critic_loss": 0.6214569952189922, "actor_loss": -91.34778257751465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.07601261138916, "step": 91000}
{"episode_reward": 979.6580471341323, "episode": 92.0, "batch_reward": 0.7916837542653083, "critic_loss": 0.5766466448903084, "actor_loss": -91.60756071472169, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.23346471786499, "step": 92000}
{"episode_reward": 929.6358065479579, "episode": 93.0, "batch_reward": 0.7922320997714997, "critic_loss": 0.62371070343256, "actor_loss": -91.57951988220215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.845510005950928, "step": 93000}
{"episode_reward": 891.5011669141882, "episode": 94.0, "batch_reward": 0.7946830634474754, "critic_loss": 0.624980778336525, "actor_loss": -91.75805325317383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.39579486846924, "step": 94000}
{"episode_reward": 947.1459381441038, "episode": 95.0, "batch_reward": 0.7971587136387825, "critic_loss": 0.6133285837769509, "actor_loss": -92.04915574645996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.419050216674805, "step": 95000}
{"episode_reward": 942.180455678291, "episode": 96.0, "batch_reward": 0.7961103308200836, "critic_loss": 0.6217784919738769, "actor_loss": -91.99065269470215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.431585788726807, "step": 96000}
{"episode_reward": 968.6949725097929, "episode": 97.0, "batch_reward": 0.7971485508680344, "critic_loss": 0.6315545869320631, "actor_loss": -92.09154832458496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.640565872192383, "step": 97000}
{"episode_reward": 936.3673947130278, "episode": 98.0, "batch_reward": 0.7999518785476685, "critic_loss": 0.6307000161260367, "actor_loss": -92.3220885772705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.567290782928467, "step": 98000}
{"episode_reward": 953.0868956889537, "episode": 99.0, "batch_reward": 0.8024903519749641, "critic_loss": 0.6284033490568399, "actor_loss": -92.24705892944336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.492743968963623, "step": 99000}
{"episode_reward": 985.3704285582781, "episode": 100.0, "batch_reward": 0.8044958036541939, "critic_loss": 0.5926950410157442, "actor_loss": -92.4186204071045, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.353032112121582, "step": 100000}
{"episode_reward": 949.6016776426953, "episode": 101.0, "batch_reward": 0.8037635133862495, "critic_loss": 0.6310965741425753, "actor_loss": -92.36246781921386, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.15261387825012, "step": 101000}
{"episode_reward": 928.8965181697051, "episode": 102.0, "batch_reward": 0.8026595286726952, "critic_loss": 0.7559994288384915, "actor_loss": -92.60717607116699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.42197012901306, "step": 102000}
{"episode_reward": 56.72354688852062, "episode": 103.0, "batch_reward": 0.7977015783190727, "critic_loss": 0.5915739262849092, "actor_loss": -92.78961436462403, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.457834482192993, "step": 103000}
{"episode_reward": 947.0708690783479, "episode": 104.0, "batch_reward": 0.8011488669514656, "critic_loss": 0.5851468479633332, "actor_loss": -92.71482647705078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.37581491470337, "step": 104000}
{"episode_reward": 959.9528574597418, "episode": 105.0, "batch_reward": 0.8018046740293503, "critic_loss": 0.5953637866079807, "actor_loss": -92.74190692138671, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.451088666915894, "step": 105000}
{"episode_reward": 947.6030235668115, "episode": 106.0, "batch_reward": 0.8027566653490067, "critic_loss": 0.5653721155375242, "actor_loss": -92.82906690979004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.42609739303589, "step": 106000}
{"episode_reward": 937.9023475534116, "episode": 107.0, "batch_reward": 0.803775032222271, "critic_loss": 0.5560055295825005, "actor_loss": -92.86486567687989, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.38457727432251, "step": 107000}
{"episode_reward": 927.769877191992, "episode": 108.0, "batch_reward": 0.8052842566370964, "critic_loss": 0.5718727719038725, "actor_loss": -92.98826945495605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.454007625579834, "step": 108000}
{"episode_reward": 869.2243436799705, "episode": 109.0, "batch_reward": 0.8073731889128685, "critic_loss": 0.5506919964998961, "actor_loss": -92.98727944946289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.390549182891846, "step": 109000}
{"episode_reward": 901.2727647225088, "episode": 110.0, "batch_reward": 0.807422569990158, "critic_loss": 0.544287304520607, "actor_loss": -93.17635752868652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.37782573699951, "step": 110000}
{"episode_reward": 933.0345141378261, "episode": 111.0, "batch_reward": 0.8079816380143165, "critic_loss": 0.5822944546639919, "actor_loss": -93.05929084777831, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.13852906227112, "step": 111000}
{"episode_reward": 892.4006291017437, "episode": 112.0, "batch_reward": 0.8078273727893829, "critic_loss": 0.5733674291521311, "actor_loss": -93.14918283081055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.397846221923828, "step": 112000}
{"episode_reward": 941.8347332347288, "episode": 113.0, "batch_reward": 0.8111553074121475, "critic_loss": 0.5565685215890408, "actor_loss": -93.16316291809082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.43998885154724, "step": 113000}
{"episode_reward": 959.557985205775, "episode": 114.0, "batch_reward": 0.8123319058418274, "critic_loss": 0.5417648116201162, "actor_loss": -93.2960182800293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.379408597946167, "step": 114000}
{"episode_reward": 962.976694762735, "episode": 115.0, "batch_reward": 0.8145763300657273, "critic_loss": 0.539972992002964, "actor_loss": -93.41711437988282, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.39631700515747, "step": 115000}
{"episode_reward": 939.0020488185892, "episode": 116.0, "batch_reward": 0.8139346823692322, "critic_loss": 0.556519833251834, "actor_loss": -93.36981587219238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.36575675010681, "step": 116000}
{"episode_reward": 960.1970520995034, "episode": 117.0, "batch_reward": 0.8160773628354072, "critic_loss": 0.5166551105827093, "actor_loss": -93.48015139770507, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.386897325515747, "step": 117000}
{"episode_reward": 942.0720351181853, "episode": 118.0, "batch_reward": 0.8165803914070129, "critic_loss": 0.5537388903349638, "actor_loss": -93.45153462219238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.345122575759888, "step": 118000}
{"episode_reward": 950.4252823513144, "episode": 119.0, "batch_reward": 0.8168601033687591, "critic_loss": 0.5452359243780375, "actor_loss": -93.423625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.36017918586731, "step": 119000}
{"episode_reward": 941.4524186327441, "episode": 120.0, "batch_reward": 0.818616212964058, "critic_loss": 0.508980158135295, "actor_loss": -93.53906573486329, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.325164079666138, "step": 120000}
{"episode_reward": 943.8304559764947, "episode": 121.0, "batch_reward": 0.820783029615879, "critic_loss": 0.5113476843684912, "actor_loss": -93.70016845703125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.045222759246826, "step": 121000}
{"episode_reward": 972.1171720228745, "episode": 122.0, "batch_reward": 0.8209924165010453, "critic_loss": 0.5292515968233347, "actor_loss": -93.74748519897462, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.305603981018066, "step": 122000}
{"episode_reward": 955.5798172958547, "episode": 123.0, "batch_reward": 0.8219783509373665, "critic_loss": 0.5133496559262276, "actor_loss": -93.77500910949708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.2729229927063, "step": 123000}
{"episode_reward": 909.0034599781799, "episode": 124.0, "batch_reward": 0.8216413568854332, "critic_loss": 0.5004796803444624, "actor_loss": -93.73723663330078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.460853099822998, "step": 124000}
{"episode_reward": 891.8897186634044, "episode": 125.0, "batch_reward": 0.8212986861467362, "critic_loss": 0.5302293153852224, "actor_loss": -93.76827836608886, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.409563779830933, "step": 125000}
{"episode_reward": 962.1473038346146, "episode": 126.0, "batch_reward": 0.8238524127006531, "critic_loss": 0.49839862692356107, "actor_loss": -93.84628540039063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.422724723815918, "step": 126000}
{"episode_reward": 973.0931206580074, "episode": 127.0, "batch_reward": 0.82510618942976, "critic_loss": 0.5087195872813464, "actor_loss": -93.91217378234863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.441258192062378, "step": 127000}
{"episode_reward": 963.6423722092109, "episode": 128.0, "batch_reward": 0.8258696995973587, "critic_loss": 0.5167471783906221, "actor_loss": -93.93278712463379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.415253162384033, "step": 128000}
{"episode_reward": 951.578477271196, "episode": 129.0, "batch_reward": 0.8271153717041015, "critic_loss": 0.5216277610361576, "actor_loss": -93.84501612854004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.418333768844604, "step": 129000}
{"episode_reward": 939.1141087063197, "episode": 130.0, "batch_reward": 0.8284675155282021, "critic_loss": 0.5159557707756758, "actor_loss": -93.98616857910156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.432136058807373, "step": 130000}
{"episode_reward": 939.5958471533166, "episode": 131.0, "batch_reward": 0.8293033122420311, "critic_loss": 0.5039318429380655, "actor_loss": -93.93647860717773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.15558362007141, "step": 131000}
{"episode_reward": 914.094807536868, "episode": 132.0, "batch_reward": 0.8295193195343018, "critic_loss": 0.5098823241740466, "actor_loss": -93.95582670593262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.39913296699524, "step": 132000}
{"episode_reward": 930.2708430556589, "episode": 133.0, "batch_reward": 0.8313519164919854, "critic_loss": 0.5125380018353463, "actor_loss": -94.0176683807373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.428441524505615, "step": 133000}
{"episode_reward": 944.4573643229911, "episode": 134.0, "batch_reward": 0.8302737193107605, "critic_loss": 0.506653984695673, "actor_loss": -94.04293322753907, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.46336817741394, "step": 134000}
{"episode_reward": 975.7947781078296, "episode": 135.0, "batch_reward": 0.8317142826318741, "critic_loss": 0.5173119434118271, "actor_loss": -94.10386553955078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.387737035751343, "step": 135000}
{"episode_reward": 901.3783406401203, "episode": 136.0, "batch_reward": 0.833752982378006, "critic_loss": 0.506899468883872, "actor_loss": -94.14814991760254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.438987255096436, "step": 136000}
{"episode_reward": 946.5989672894111, "episode": 137.0, "batch_reward": 0.8337481852769851, "critic_loss": 0.48293919494748117, "actor_loss": -94.1437762298584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.443816900253296, "step": 137000}
{"episode_reward": 919.6308603819745, "episode": 138.0, "batch_reward": 0.8343353456854821, "critic_loss": 0.4909163769930601, "actor_loss": -94.13828445434571, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.356387853622437, "step": 138000}
{"episode_reward": 958.4516683439413, "episode": 139.0, "batch_reward": 0.8351259120702743, "critic_loss": 0.4863091794550419, "actor_loss": -94.15429704284668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.44764733314514, "step": 139000}
{"episode_reward": 942.6577410139545, "episode": 140.0, "batch_reward": 0.8345470370650292, "critic_loss": 0.48787400326132774, "actor_loss": -94.05912265014648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.405478477478027, "step": 140000}
{"episode_reward": 957.5493491757088, "episode": 141.0, "batch_reward": 0.8382914296984673, "critic_loss": 0.4850159214287996, "actor_loss": -94.20162971496582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.04308581352234, "step": 141000}
{"episode_reward": 954.4418925194166, "episode": 142.0, "batch_reward": 0.8379321347475052, "critic_loss": 0.49635998453199864, "actor_loss": -94.1743533782959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.3719699382782, "step": 142000}
{"episode_reward": 880.9453006287227, "episode": 143.0, "batch_reward": 0.8380387144684791, "critic_loss": 0.5331665109395981, "actor_loss": -94.19088511657715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.394712686538696, "step": 143000}
{"episode_reward": 951.9897744640718, "episode": 144.0, "batch_reward": 0.8388078224062919, "critic_loss": 0.5064636703431606, "actor_loss": -94.22488078308105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.40569019317627, "step": 144000}
{"episode_reward": 967.1537726985704, "episode": 145.0, "batch_reward": 0.840266203224659, "critic_loss": 0.5126332089155913, "actor_loss": -94.197755859375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.394859790802002, "step": 145000}
{"episode_reward": 969.3011155445113, "episode": 146.0, "batch_reward": 0.8404036375880242, "critic_loss": 0.4826960510015488, "actor_loss": -94.12486027526856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.38336944580078, "step": 146000}
{"episode_reward": 920.7307167635389, "episode": 147.0, "batch_reward": 0.8399812978506088, "critic_loss": 0.5111994647830724, "actor_loss": -94.18460063171386, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.357353448867798, "step": 147000}
{"episode_reward": 965.9708958216572, "episode": 148.0, "batch_reward": 0.842346763074398, "critic_loss": 0.5327695764452219, "actor_loss": -94.25573013305664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.347444534301758, "step": 148000}
{"episode_reward": 952.5818212231675, "episode": 149.0, "batch_reward": 0.8427038457393646, "critic_loss": 0.4969764090180397, "actor_loss": -94.20103678894043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.374541759490967, "step": 149000}
{"episode_reward": 936.8850920059999, "episode": 150.0, "batch_reward": 0.842950618982315, "critic_loss": 0.5179440218806267, "actor_loss": -94.25798742675781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
