{"episode_reward": 0.0, "episode": 1.0, "duration": 22.076743125915527, "step": 1000}
{"episode_reward": 28.002640152663393, "episode": 2.0, "duration": 1.910353660583496, "step": 2000}
{"episode_reward": 481.4321918933315, "episode": 3.0, "batch_reward": 0.2533788797496835, "critic_loss": 0.6481221625460272, "actor_loss": -84.29787560776263, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 68.70880651473999, "step": 3000}
{"episode_reward": 283.0190463571517, "episode": 4.0, "batch_reward": 0.2717146442383528, "critic_loss": 1.0119235923886298, "actor_loss": -84.79615979003906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.150691986083984, "step": 4000}
{"episode_reward": 370.52692924329006, "episode": 5.0, "batch_reward": 0.30475135789811614, "critic_loss": 0.8571673266291618, "actor_loss": -85.02869184875489, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.968788623809814, "step": 5000}
{"episode_reward": 464.7927151475535, "episode": 6.0, "batch_reward": 0.33930012184381486, "critic_loss": 0.9061345034241677, "actor_loss": -84.824715133667, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.986366987228394, "step": 6000}
{"episode_reward": 499.9950316341498, "episode": 7.0, "batch_reward": 0.375283858448267, "critic_loss": 0.7880041762888431, "actor_loss": -84.34037300109863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.006922006607056, "step": 7000}
{"episode_reward": 598.1956336615583, "episode": 8.0, "batch_reward": 0.3849464855194092, "critic_loss": 0.8644645476341247, "actor_loss": -83.50102226257324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.978282690048218, "step": 8000}
{"episode_reward": 388.3746614449986, "episode": 9.0, "batch_reward": 0.3991721839308739, "critic_loss": 0.8972901330590248, "actor_loss": -82.91162112426758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.978987216949463, "step": 9000}
{"episode_reward": 562.8558099907158, "episode": 10.0, "batch_reward": 0.41239445039629935, "critic_loss": 0.9670028992891312, "actor_loss": -82.29940585327148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.989157915115356, "step": 10000}
{"episode_reward": 516.1032200233609, "episode": 11.0, "batch_reward": 0.43128326123952865, "critic_loss": 1.1648291260004044, "actor_loss": -82.01626113891602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.661643266677856, "step": 11000}
{"episode_reward": 644.6608434980527, "episode": 12.0, "batch_reward": 0.4435177157819271, "critic_loss": 1.2934811729192734, "actor_loss": -81.66849436950683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.975472688674927, "step": 12000}
{"episode_reward": 603.9420250251343, "episode": 13.0, "batch_reward": 0.44443157133460043, "critic_loss": 1.3178769733905793, "actor_loss": -80.68757876586913, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.95693325996399, "step": 13000}
{"episode_reward": 402.57378866626107, "episode": 14.0, "batch_reward": 0.4605092117190361, "critic_loss": 1.4629443648457527, "actor_loss": -80.88790310668945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.069658756256104, "step": 14000}
{"episode_reward": 746.3775069412493, "episode": 15.0, "batch_reward": 0.4718137703239918, "critic_loss": 1.547870823740959, "actor_loss": -81.20957139587402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.95052194595337, "step": 15000}
{"episode_reward": 615.3421247679222, "episode": 16.0, "batch_reward": 0.48542818358540535, "critic_loss": 1.525802186846733, "actor_loss": -80.73998185729981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.962947845458984, "step": 16000}
{"episode_reward": 628.605584420423, "episode": 17.0, "batch_reward": 0.49714724722504616, "critic_loss": 1.420872987627983, "actor_loss": -81.03044415283203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.03246259689331, "step": 17000}
{"episode_reward": 741.9087565995874, "episode": 18.0, "batch_reward": 0.5117478142976761, "critic_loss": 1.3477780110239983, "actor_loss": -81.06690162658691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.93985342979431, "step": 18000}
{"episode_reward": 843.6661552888482, "episode": 19.0, "batch_reward": 0.5291466580927372, "critic_loss": 1.2901870651841163, "actor_loss": -81.22040190124511, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.96459698677063, "step": 19000}
{"episode_reward": 833.1073835974436, "episode": 20.0, "batch_reward": 0.5426225670874119, "critic_loss": 1.2581064732074738, "actor_loss": -81.61245275878906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.976211071014404, "step": 20000}
{"episode_reward": 764.4207403776749, "episode": 21.0, "batch_reward": 0.5558032865226269, "critic_loss": 1.2666199269890785, "actor_loss": -81.21023802185059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.60977745056152, "step": 21000}
{"episode_reward": 736.8655463437686, "episode": 22.0, "batch_reward": 0.5643758977949619, "critic_loss": 1.2372126615047454, "actor_loss": -82.46631413269043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.911388874053955, "step": 22000}
{"episode_reward": 863.9765789173722, "episode": 23.0, "batch_reward": 0.5707028658092022, "critic_loss": 1.2285840843319893, "actor_loss": -81.97344854736328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.97340965270996, "step": 23000}
{"episode_reward": 481.69384727285495, "episode": 24.0, "batch_reward": 0.5729407677650452, "critic_loss": 1.232849389255047, "actor_loss": -81.99621380615234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.005138874053955, "step": 24000}
{"episode_reward": 736.6531997508773, "episode": 25.0, "batch_reward": 0.5817534544467926, "critic_loss": 1.1637857593297958, "actor_loss": -82.11124758911133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.965866804122925, "step": 25000}
{"episode_reward": 856.7379824409504, "episode": 26.0, "batch_reward": 0.5902086434662343, "critic_loss": 1.16528900963068, "actor_loss": -81.9200500793457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.93813180923462, "step": 26000}
{"episode_reward": 829.1555375816932, "episode": 27.0, "batch_reward": 0.6018220190107822, "critic_loss": 1.1050557619333268, "actor_loss": -81.76908198547363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.982178449630737, "step": 27000}
{"episode_reward": 902.8564328908335, "episode": 28.0, "batch_reward": 0.614614056289196, "critic_loss": 1.0836669626235962, "actor_loss": -82.90598080444336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.9236843585968, "step": 28000}
{"episode_reward": 882.3957293500109, "episode": 29.0, "batch_reward": 0.621193076968193, "critic_loss": 1.0863122963309289, "actor_loss": -82.78409132385254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.928775310516357, "step": 29000}
{"episode_reward": 881.1838254240377, "episode": 30.0, "batch_reward": 0.6309389275312424, "critic_loss": 1.0461545996665955, "actor_loss": -82.4338120880127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.90746521949768, "step": 30000}
{"episode_reward": 827.4716669964438, "episode": 31.0, "batch_reward": 0.6387617931962013, "critic_loss": 1.0444713559150696, "actor_loss": -83.33781509399414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.48477292060852, "step": 31000}
{"episode_reward": 913.1310566696595, "episode": 32.0, "batch_reward": 0.6470131129026413, "critic_loss": 0.9840361785888672, "actor_loss": -83.67776783752441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.86900758743286, "step": 32000}
{"episode_reward": 867.2030337429366, "episode": 33.0, "batch_reward": 0.6532566049695014, "critic_loss": 0.969317848175764, "actor_loss": -84.07372666931153, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.851906299591064, "step": 33000}
{"episode_reward": 867.5229935447428, "episode": 34.0, "batch_reward": 0.6600683996677399, "critic_loss": 0.9549396631121635, "actor_loss": -83.58541052246093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.90269422531128, "step": 34000}
{"episode_reward": 854.5292172008736, "episode": 35.0, "batch_reward": 0.6645187967419625, "critic_loss": 0.9814264788031578, "actor_loss": -84.35831854248048, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.81639575958252, "step": 35000}
{"episode_reward": 836.9300025129255, "episode": 36.0, "batch_reward": 0.6708072580099106, "critic_loss": 0.9533363250494004, "actor_loss": -84.70258349609375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.137088537216187, "step": 36000}
{"episode_reward": 892.497578150217, "episode": 37.0, "batch_reward": 0.677022881090641, "critic_loss": 0.9452187975943088, "actor_loss": -84.47762178039551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.98321533203125, "step": 37000}
{"episode_reward": 895.5279809344229, "episode": 38.0, "batch_reward": 0.6771082355380058, "critic_loss": 0.9472597528100014, "actor_loss": -84.69883575439454, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.996827125549316, "step": 38000}
{"episode_reward": 632.8785103584848, "episode": 39.0, "batch_reward": 0.6780182031989097, "critic_loss": 1.025008479833603, "actor_loss": -84.71010289001465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.99688220024109, "step": 39000}
{"episode_reward": 713.6469152021403, "episode": 40.0, "batch_reward": 0.6823370311260223, "critic_loss": 0.9753038884997368, "actor_loss": -84.69961824035644, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.9859356880188, "step": 40000}
{"episode_reward": 904.7151189257173, "episode": 41.0, "batch_reward": 0.6868275412917138, "critic_loss": 0.9675464580655098, "actor_loss": -84.06083036804199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.70953035354614, "step": 41000}
{"episode_reward": 929.0361871261197, "episode": 42.0, "batch_reward": 0.6933272393345833, "critic_loss": 0.9068966430425643, "actor_loss": -85.19790640258789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.966328144073486, "step": 42000}
{"episode_reward": 917.7817737514298, "episode": 43.0, "batch_reward": 0.6983547060489654, "critic_loss": 0.8703625614345074, "actor_loss": -85.56374668884277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.001299142837524, "step": 43000}
{"episode_reward": 967.2645022246882, "episode": 44.0, "batch_reward": 0.7031192489266396, "critic_loss": 0.9063048582077027, "actor_loss": -86.10011715698242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.98378825187683, "step": 44000}
{"episode_reward": 905.7801361029921, "episode": 45.0, "batch_reward": 0.7099355716109276, "critic_loss": 0.8833630689680576, "actor_loss": -86.32801106262207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.011390686035156, "step": 45000}
{"episode_reward": 952.4694246427048, "episode": 46.0, "batch_reward": 0.7140763347744942, "critic_loss": 0.8833233492970467, "actor_loss": -85.80268850708008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.002312183380127, "step": 46000}
{"episode_reward": 910.7138270447986, "episode": 47.0, "batch_reward": 0.7195145801305771, "critic_loss": 0.9197015052139759, "actor_loss": -86.11718200683593, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.95798420906067, "step": 47000}
{"episode_reward": 919.551835652987, "episode": 48.0, "batch_reward": 0.7233886176347732, "critic_loss": 0.9115578837394714, "actor_loss": -86.76846530151367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.98054075241089, "step": 48000}
{"episode_reward": 869.3981205990207, "episode": 49.0, "batch_reward": 0.7264546929597855, "critic_loss": 0.9612255086004734, "actor_loss": -87.02066464233398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.013975381851196, "step": 49000}
{"episode_reward": 884.2757445084932, "episode": 50.0, "batch_reward": 0.7288083452582359, "critic_loss": 0.9905419896245002, "actor_loss": -86.61943675231933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.911802530288696, "step": 50000}
{"episode_reward": 874.9056870223371, "episode": 51.0, "batch_reward": 0.7324727380275726, "critic_loss": 0.9471437832713128, "actor_loss": -86.59150659179687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.66772150993347, "step": 51000}
{"episode_reward": 950.9545468179659, "episode": 52.0, "batch_reward": 0.7368708811402321, "critic_loss": 0.9197707537710667, "actor_loss": -86.74912504577637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.903478622436523, "step": 52000}
{"episode_reward": 925.2584949819643, "episode": 53.0, "batch_reward": 0.7404588133692741, "critic_loss": 0.9127505797147751, "actor_loss": -87.6182386932373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.958556652069092, "step": 53000}
{"episode_reward": 937.9064317420423, "episode": 54.0, "batch_reward": 0.7431959429383278, "critic_loss": 0.8726040834784508, "actor_loss": -87.4834473876953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.92910933494568, "step": 54000}
{"episode_reward": 924.7830267936567, "episode": 55.0, "batch_reward": 0.7453839034438133, "critic_loss": 0.9010933191478252, "actor_loss": -87.69250573730469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.994266271591187, "step": 55000}
{"episode_reward": 929.7324388237633, "episode": 56.0, "batch_reward": 0.7512839847803116, "critic_loss": 0.8669671663343906, "actor_loss": -87.75303295898438, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.956446170806885, "step": 56000}
{"episode_reward": 918.6789740573863, "episode": 57.0, "batch_reward": 0.7541780925393105, "critic_loss": 0.8462688963711261, "actor_loss": -88.15750881958007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.981248140335083, "step": 57000}
{"episode_reward": 911.6399168459931, "episode": 58.0, "batch_reward": 0.7544024409651756, "critic_loss": 0.8766215204000473, "actor_loss": -88.42506230163575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.94580864906311, "step": 58000}
{"episode_reward": 876.2266438205953, "episode": 59.0, "batch_reward": 0.7599567077755928, "critic_loss": 0.8250774607956409, "actor_loss": -88.51811068725586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.96557927131653, "step": 59000}
{"episode_reward": 962.6007040402211, "episode": 60.0, "batch_reward": 0.7615176582336426, "critic_loss": 0.8319008114337921, "actor_loss": -88.75551713562012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.925239086151123, "step": 60000}
{"episode_reward": 955.792412767459, "episode": 61.0, "batch_reward": 0.7654398073554038, "critic_loss": 0.7983775447905064, "actor_loss": -88.65162928771973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.54288578033447, "step": 61000}
{"episode_reward": 926.4416783143472, "episode": 62.0, "batch_reward": 0.769002949476242, "critic_loss": 0.7763243448138237, "actor_loss": -89.19422616577148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.89445400238037, "step": 62000}
{"episode_reward": 940.1426864166435, "episode": 63.0, "batch_reward": 0.7706160026788712, "critic_loss": 0.7571590247452259, "actor_loss": -88.87132466125489, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.873836040496826, "step": 63000}
{"episode_reward": 959.4293830330323, "episode": 64.0, "batch_reward": 0.7746489192247391, "critic_loss": 0.7558443573713303, "actor_loss": -89.42906596374512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.872538566589355, "step": 64000}
{"episode_reward": 947.3771365998109, "episode": 65.0, "batch_reward": 0.775512676358223, "critic_loss": 0.7464712202250957, "actor_loss": -89.33377391052247, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.856448888778687, "step": 65000}
{"episode_reward": 911.4520111941277, "episode": 66.0, "batch_reward": 0.7775491586327553, "critic_loss": 0.7612389797270298, "actor_loss": -89.56059037780761, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.88418483734131, "step": 66000}
{"episode_reward": 943.4669708942947, "episode": 67.0, "batch_reward": 0.7795466431379319, "critic_loss": 0.7492488531172276, "actor_loss": -90.13299432373047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.75683569908142, "step": 67000}
{"episode_reward": 899.4618842713863, "episode": 68.0, "batch_reward": 0.7834026181697845, "critic_loss": 0.7853850154876709, "actor_loss": -90.12588290405273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.28093910217285, "step": 68000}
{"episode_reward": 905.5363435067303, "episode": 69.0, "batch_reward": 0.7818497738242149, "critic_loss": 0.7477148252725602, "actor_loss": -89.83843710327149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.970867156982422, "step": 69000}
{"episode_reward": 911.6145216636861, "episode": 70.0, "batch_reward": 0.7865040749907494, "critic_loss": 0.7268375955820083, "actor_loss": -90.25454217529297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.98529314994812, "step": 70000}
{"episode_reward": 944.3020261864638, "episode": 71.0, "batch_reward": 0.787030610203743, "critic_loss": 0.7239263543188572, "actor_loss": -90.19686824035645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.64337754249573, "step": 71000}
{"episode_reward": 924.878136883976, "episode": 72.0, "batch_reward": 0.7880976949334144, "critic_loss": 0.7683709222376347, "actor_loss": -90.20559576416015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.970306873321533, "step": 72000}
{"episode_reward": 902.936881363392, "episode": 73.0, "batch_reward": 0.7912999060153961, "critic_loss": 0.7245136024653912, "actor_loss": -90.41214460754395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.02138066291809, "step": 73000}
{"episode_reward": 891.5429560621443, "episode": 74.0, "batch_reward": 0.7930120550394059, "critic_loss": 0.7109929867088794, "actor_loss": -90.54491696166993, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.95427680015564, "step": 74000}
{"episode_reward": 918.8690233647005, "episode": 75.0, "batch_reward": 0.7945164875984192, "critic_loss": 0.7264853221476077, "actor_loss": -90.5168896484375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.0017147064209, "step": 75000}
{"episode_reward": 948.9073438606825, "episode": 76.0, "batch_reward": 0.7958657718896865, "critic_loss": 0.7446209015250206, "actor_loss": -90.55425112915039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.99600124359131, "step": 76000}
{"episode_reward": 925.6425781328905, "episode": 77.0, "batch_reward": 0.7972899532914162, "critic_loss": 0.7269111943542957, "actor_loss": -90.83529322814941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.987481594085693, "step": 77000}
{"episode_reward": 932.6873820985951, "episode": 78.0, "batch_reward": 0.799845933675766, "critic_loss": 0.7101240054666996, "actor_loss": -90.79517887878418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.01348090171814, "step": 78000}
{"episode_reward": 924.5984156777796, "episode": 79.0, "batch_reward": 0.8005565545558929, "critic_loss": 0.7244230828285217, "actor_loss": -91.06014225769043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.93735432624817, "step": 79000}
{"episode_reward": 869.3619881247774, "episode": 80.0, "batch_reward": 0.8033445146679878, "critic_loss": 0.7069838742911816, "actor_loss": -91.25182347106933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.991653442382812, "step": 80000}
{"episode_reward": 965.6996317115897, "episode": 81.0, "batch_reward": 0.8058323555588722, "critic_loss": 0.705489725381136, "actor_loss": -91.41748182678222, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.59283113479614, "step": 81000}
{"episode_reward": 904.2116707765399, "episode": 82.0, "batch_reward": 0.8042977300882339, "critic_loss": 0.7139788826107979, "actor_loss": -91.16589854431152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.999101877212524, "step": 82000}
{"episode_reward": 931.1162425836238, "episode": 83.0, "batch_reward": 0.8082202970981598, "critic_loss": 0.69781585881114, "actor_loss": -91.51778353881836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.986729621887207, "step": 83000}
{"episode_reward": 908.9370095350782, "episode": 84.0, "batch_reward": 0.807926613688469, "critic_loss": 0.6956431029438972, "actor_loss": -91.54209086608887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.90749716758728, "step": 84000}
{"episode_reward": 896.4143883492974, "episode": 85.0, "batch_reward": 0.809665642619133, "critic_loss": 0.7085452101230622, "actor_loss": -91.5445177154541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.92196035385132, "step": 85000}
{"episode_reward": 957.8709836261584, "episode": 86.0, "batch_reward": 0.8122905751466751, "critic_loss": 0.6884522276222705, "actor_loss": -91.71388720703125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.96732497215271, "step": 86000}
{"episode_reward": 961.3603156746591, "episode": 87.0, "batch_reward": 0.8130746746063232, "critic_loss": 0.7015175057947636, "actor_loss": -91.82884504699707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.96177339553833, "step": 87000}
{"episode_reward": 944.8888266600104, "episode": 88.0, "batch_reward": 0.8143599578738212, "critic_loss": 0.7033760951459408, "actor_loss": -91.88400114440918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.97087073326111, "step": 88000}
{"episode_reward": 871.5225968442962, "episode": 89.0, "batch_reward": 0.8157531587481499, "critic_loss": 0.7212029728591443, "actor_loss": -91.69137544250488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.949252367019653, "step": 89000}
{"episode_reward": 932.2149482324494, "episode": 90.0, "batch_reward": 0.8165774300694466, "critic_loss": 0.6965396579802037, "actor_loss": -91.82982914733887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.94954252243042, "step": 90000}
{"episode_reward": 879.0339052695232, "episode": 91.0, "batch_reward": 0.8163296185731888, "critic_loss": 0.7141042001843453, "actor_loss": -91.85137657165528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.54418587684631, "step": 91000}
{"episode_reward": 880.6157154379882, "episode": 92.0, "batch_reward": 0.8175680491924285, "critic_loss": 0.7071327563524247, "actor_loss": -92.07561712646485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.941209316253662, "step": 92000}
{"episode_reward": 937.7427021187842, "episode": 93.0, "batch_reward": 0.8189429038763046, "critic_loss": 0.6941489468216896, "actor_loss": -92.04950914001465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.163408517837524, "step": 93000}
{"episode_reward": 960.2654267182614, "episode": 94.0, "batch_reward": 0.8207294768095017, "critic_loss": 0.6786960924863815, "actor_loss": -92.21453327941894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.91034722328186, "step": 94000}
{"episode_reward": 949.3114680517434, "episode": 95.0, "batch_reward": 0.8211238477230072, "critic_loss": 0.6779940968155861, "actor_loss": -92.40352900695801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.8333957195282, "step": 95000}
{"episode_reward": 901.0925599325329, "episode": 96.0, "batch_reward": 0.8239465799927711, "critic_loss": 0.6811825453937054, "actor_loss": -92.2839644317627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.898614645004272, "step": 96000}
{"episode_reward": 961.5042067537978, "episode": 97.0, "batch_reward": 0.8232515410780906, "critic_loss": 0.6968957014083862, "actor_loss": -92.37983044433594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.855677604675293, "step": 97000}
{"episode_reward": 961.4607727697455, "episode": 98.0, "batch_reward": 0.8251403054594993, "critic_loss": 0.7076312674283981, "actor_loss": -92.69335145568847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.097355604171753, "step": 98000}
{"episode_reward": 864.0418872674786, "episode": 99.0, "batch_reward": 0.8267029190063476, "critic_loss": 0.7035809111297131, "actor_loss": -92.54803817749024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.668930530548096, "step": 99000}
{"episode_reward": 961.7071876791011, "episode": 100.0, "batch_reward": 0.8265045613646508, "critic_loss": 0.6894600634872914, "actor_loss": -92.68877835083008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.51301145553589, "step": 100000}
{"episode_reward": 954.5704796356987, "episode": 101.0, "batch_reward": 0.8287255545854568, "critic_loss": 0.6607391003966332, "actor_loss": -92.65805505371094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.62044358253479, "step": 101000}
{"episode_reward": 887.5521475797474, "episode": 102.0, "batch_reward": 0.8253431721329689, "critic_loss": 0.6813529152572155, "actor_loss": -92.73616900634765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.977476358413696, "step": 102000}
{"episode_reward": 59.29721861641452, "episode": 103.0, "batch_reward": 0.820170284152031, "critic_loss": 0.6990360086262226, "actor_loss": -92.6160066986084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.993584632873535, "step": 103000}
{"episode_reward": 957.0689929356067, "episode": 104.0, "batch_reward": 0.8232037953734398, "critic_loss": 0.6748101609349251, "actor_loss": -92.56770458984376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.9739351272583, "step": 104000}
{"episode_reward": 940.209303422371, "episode": 105.0, "batch_reward": 0.824437445282936, "critic_loss": 0.6813987747430802, "actor_loss": -92.6622575378418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.005112409591675, "step": 105000}
{"episode_reward": 946.5002287521904, "episode": 106.0, "batch_reward": 0.826174875319004, "critic_loss": 0.6781891594827175, "actor_loss": -92.7442094116211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.954086780548096, "step": 106000}
{"episode_reward": 961.2233495207612, "episode": 107.0, "batch_reward": 0.8267849944233895, "critic_loss": 0.6857391479611397, "actor_loss": -92.68714686584472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.014879941940308, "step": 107000}
{"episode_reward": 963.3055614859528, "episode": 108.0, "batch_reward": 0.8263065241575241, "critic_loss": 0.6713480308651925, "actor_loss": -92.95675544738769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.946280479431152, "step": 108000}
{"episode_reward": 934.1372895554452, "episode": 109.0, "batch_reward": 0.830228963792324, "critic_loss": 0.6742503344118596, "actor_loss": -92.88062992858887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.003976583480835, "step": 109000}
{"episode_reward": 948.9175863410212, "episode": 110.0, "batch_reward": 0.8282076141834259, "critic_loss": 0.6589024263620377, "actor_loss": -93.05536387634277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.972941637039185, "step": 110000}
{"episode_reward": 909.9902129877169, "episode": 111.0, "batch_reward": 0.8310082095265389, "critic_loss": 0.6549169519841671, "actor_loss": -93.04937739562989, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.60710430145264, "step": 111000}
{"episode_reward": 961.1069577858864, "episode": 112.0, "batch_reward": 0.8318848206400872, "critic_loss": 0.6620317088663578, "actor_loss": -93.21424156188965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.98583436012268, "step": 112000}
{"episode_reward": 907.1566534698253, "episode": 113.0, "batch_reward": 0.8337777979969978, "critic_loss": 0.6790555800199509, "actor_loss": -93.08195442199707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.920196294784546, "step": 113000}
{"episode_reward": 941.8190793358, "episode": 114.0, "batch_reward": 0.8336125932335854, "critic_loss": 0.6658278337717056, "actor_loss": -93.3053689880371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.993565797805786, "step": 114000}
{"episode_reward": 949.9895791374399, "episode": 115.0, "batch_reward": 0.8359906032681466, "critic_loss": 0.6727652362585068, "actor_loss": -93.34904461669922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.95381808280945, "step": 115000}
{"episode_reward": 947.6424328225487, "episode": 116.0, "batch_reward": 0.8354402490854264, "critic_loss": 0.6449226768612861, "actor_loss": -93.30551564025879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.908910274505615, "step": 116000}
{"episode_reward": 942.096248420702, "episode": 117.0, "batch_reward": 0.8372053320407867, "critic_loss": 0.6201538959443569, "actor_loss": -93.26534690856934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.918402910232544, "step": 117000}
{"episode_reward": 901.3000106528452, "episode": 118.0, "batch_reward": 0.838378756225109, "critic_loss": 0.6253586437106132, "actor_loss": -93.36027345275879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.926434755325317, "step": 118000}
{"episode_reward": 951.5652167046785, "episode": 119.0, "batch_reward": 0.8380666720867157, "critic_loss": 0.6401969465017319, "actor_loss": -93.41212174987793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.97206211090088, "step": 119000}
{"episode_reward": 886.5327359388211, "episode": 120.0, "batch_reward": 0.8389825854301453, "critic_loss": 0.6179771761000157, "actor_loss": -93.49974801635742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.94380521774292, "step": 120000}
{"episode_reward": 962.0713243666285, "episode": 121.0, "batch_reward": 0.8399186831712723, "critic_loss": 0.6378465706408024, "actor_loss": -93.48017391967774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.57374906539917, "step": 121000}
{"episode_reward": 883.705947891973, "episode": 122.0, "batch_reward": 0.8398958453536034, "critic_loss": 0.610262787848711, "actor_loss": -93.67425914001466, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.916205644607544, "step": 122000}
{"episode_reward": 896.3681164702247, "episode": 123.0, "batch_reward": 0.8413720840811729, "critic_loss": 0.6120530630648137, "actor_loss": -93.67095422363282, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.936497688293457, "step": 123000}
{"episode_reward": 903.278859397899, "episode": 124.0, "batch_reward": 0.839626421034336, "critic_loss": 0.6326592050790787, "actor_loss": -93.62296459960938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.929420232772827, "step": 124000}
{"episode_reward": 905.7565854483831, "episode": 125.0, "batch_reward": 0.8396296415925026, "critic_loss": 0.6361300263851881, "actor_loss": -93.6775601348877, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.908825397491455, "step": 125000}
{"episode_reward": 941.1088849034215, "episode": 126.0, "batch_reward": 0.8419217359423637, "critic_loss": 0.6036348413974046, "actor_loss": -93.75719686889649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.89041042327881, "step": 126000}
{"episode_reward": 955.236125346106, "episode": 127.0, "batch_reward": 0.8431838986873627, "critic_loss": 0.6031698796898126, "actor_loss": -93.83049293518066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.894423246383667, "step": 127000}
{"episode_reward": 963.7628653825212, "episode": 128.0, "batch_reward": 0.8429839698672295, "critic_loss": 0.6125624659508466, "actor_loss": -93.78866786193848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.88479995727539, "step": 128000}
{"episode_reward": 929.1240839562174, "episode": 129.0, "batch_reward": 0.8439823439121247, "critic_loss": 0.6350115482062101, "actor_loss": -93.78897161865234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.862950325012207, "step": 129000}
{"episode_reward": 961.5753001522911, "episode": 130.0, "batch_reward": 0.8454175098538399, "critic_loss": 0.6389238445162773, "actor_loss": -93.85293005371093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.841190814971924, "step": 130000}
{"episode_reward": 956.9109039341691, "episode": 131.0, "batch_reward": 0.8468459932208061, "critic_loss": 0.6235161815732717, "actor_loss": -93.83339260864258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.960736989974976, "step": 131000}
{"episode_reward": 951.6386965102232, "episode": 132.0, "batch_reward": 0.8466546146273612, "critic_loss": 0.6243721706569195, "actor_loss": -93.88332952880859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.971643447875977, "step": 132000}
{"episode_reward": 943.1611581175457, "episode": 133.0, "batch_reward": 0.8496883510947227, "critic_loss": 0.6244387109130621, "actor_loss": -93.8561297454834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.99850821495056, "step": 133000}
{"episode_reward": 972.2865768048662, "episode": 134.0, "batch_reward": 0.8487357995510101, "critic_loss": 0.6079213600903749, "actor_loss": -93.96686683654785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.00436234474182, "step": 134000}
{"episode_reward": 973.5567733864847, "episode": 135.0, "batch_reward": 0.848274950504303, "critic_loss": 0.6145623565912247, "actor_loss": -94.03457791137696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.99037742614746, "step": 135000}
{"episode_reward": 932.2705872911584, "episode": 136.0, "batch_reward": 0.8497657811045647, "critic_loss": 0.6090203511416912, "actor_loss": -94.07542906188965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.96423101425171, "step": 136000}
{"episode_reward": 921.5881686120456, "episode": 137.0, "batch_reward": 0.850307937681675, "critic_loss": 0.6125631749778986, "actor_loss": -94.12139329528809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.034807205200195, "step": 137000}
{"episode_reward": 926.7173824722089, "episode": 138.0, "batch_reward": 0.850437549173832, "critic_loss": 0.6245601883530617, "actor_loss": -94.05924601745606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.979517936706543, "step": 138000}
{"episode_reward": 937.5110394624606, "episode": 139.0, "batch_reward": 0.8516923155784607, "critic_loss": 0.6162884215861559, "actor_loss": -94.09877186584472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.01704168319702, "step": 139000}
{"episode_reward": 925.8761715382725, "episode": 140.0, "batch_reward": 0.8512594988942146, "critic_loss": 0.619302616417408, "actor_loss": -94.12082095336915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.964585065841675, "step": 140000}
{"episode_reward": 943.0403023019668, "episode": 141.0, "batch_reward": 0.8538734504580497, "critic_loss": 0.605802566409111, "actor_loss": -94.2705106201172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.67541527748108, "step": 141000}
{"episode_reward": 910.1395704744247, "episode": 142.0, "batch_reward": 0.8534237996339799, "critic_loss": 0.6157360504567623, "actor_loss": -94.20940167236328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.947811126708984, "step": 142000}
{"episode_reward": 912.7944391030416, "episode": 143.0, "batch_reward": 0.8530993667244912, "critic_loss": 0.6068892587423325, "actor_loss": -94.21368063354493, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.983721017837524, "step": 143000}
{"episode_reward": 917.8036961629969, "episode": 144.0, "batch_reward": 0.8539094243645668, "critic_loss": 0.600531363889575, "actor_loss": -94.30171348571777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.03870439529419, "step": 144000}
{"episode_reward": 926.1934236833112, "episode": 145.0, "batch_reward": 0.8555527478456497, "critic_loss": 0.6050596253573894, "actor_loss": -94.38957179260254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.929975032806396, "step": 145000}
{"episode_reward": 956.2693280487426, "episode": 146.0, "batch_reward": 0.8550529640316963, "critic_loss": 0.6080830906927586, "actor_loss": -94.22590678405761, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.984184503555298, "step": 146000}
{"episode_reward": 928.6850884317881, "episode": 147.0, "batch_reward": 0.854551227748394, "critic_loss": 0.6220137456059456, "actor_loss": -94.29875218200684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.988468170166016, "step": 147000}
{"episode_reward": 962.6829251692619, "episode": 148.0, "batch_reward": 0.8577279227375985, "critic_loss": 0.6098466267138719, "actor_loss": -94.40745979309082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.94906711578369, "step": 148000}
{"episode_reward": 943.470062436007, "episode": 149.0, "batch_reward": 0.8571419056653976, "critic_loss": 0.6001979019194842, "actor_loss": -94.46239170837403, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.955446243286133, "step": 149000}
{"episode_reward": 958.3932861583394, "episode": 150.0, "batch_reward": 0.8575845667719841, "critic_loss": 0.6020724596530199, "actor_loss": -94.50843699645996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
