{"episode_reward": 0.0, "episode": 1.0, "duration": 20.9611713886261, "step": 1000}
{"episode_reward": 27.46298806610516, "episode": 2.0, "duration": 1.8223369121551514, "step": 2000}
{"episode_reward": 489.1100087318934, "episode": 3.0, "batch_reward": 0.2497840530924417, "critic_loss": 0.9926307780190522, "actor_loss": -84.93108993170021, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.86151695251465, "step": 3000}
{"episode_reward": 121.87258044624099, "episode": 4.0, "batch_reward": 0.19577560000121594, "critic_loss": 1.64305700224638, "actor_loss": -86.52996846008301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.309271097183228, "step": 4000}
{"episode_reward": 74.39534390187085, "episode": 5.0, "batch_reward": 0.19695899952203036, "critic_loss": 2.7939814752936365, "actor_loss": -86.53559036254883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.369548559188843, "step": 5000}
{"episode_reward": 402.76533064291027, "episode": 6.0, "batch_reward": 0.238850659519434, "critic_loss": 3.347535326719284, "actor_loss": -88.34713369750976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.143298864364624, "step": 6000}
{"episode_reward": 351.2968578380435, "episode": 7.0, "batch_reward": 0.23793505957722663, "critic_loss": 3.242387068629265, "actor_loss": -89.06214987182616, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.160223245620728, "step": 7000}
{"episode_reward": 126.5962317921356, "episode": 8.0, "batch_reward": 0.23354504942893983, "critic_loss": 3.2344867923259737, "actor_loss": -88.43069607543946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.167001008987427, "step": 8000}
{"episode_reward": 364.0606660986304, "episode": 9.0, "batch_reward": 0.2590038014650345, "critic_loss": 2.8986491874456406, "actor_loss": -88.27873713684082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.19239115715027, "step": 9000}
{"episode_reward": 502.8387863309758, "episode": 10.0, "batch_reward": 0.28247473266720774, "critic_loss": 2.3376416496038437, "actor_loss": -87.8666223602295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.202954530715942, "step": 10000}
{"episode_reward": 287.01792846139, "episode": 11.0, "batch_reward": 0.2817704605013132, "critic_loss": 1.9311388864517212, "actor_loss": -86.95412225341796, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.916836738586426, "step": 11000}
{"episode_reward": 495.78072282443, "episode": 12.0, "batch_reward": 0.307356816932559, "critic_loss": 1.866255627810955, "actor_loss": -86.50390560913085, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.244591236114502, "step": 12000}
{"episode_reward": 561.635593487453, "episode": 13.0, "batch_reward": 0.32180886101722717, "critic_loss": 1.808329179406166, "actor_loss": -85.85509455871582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.244719743728638, "step": 13000}
{"episode_reward": 482.7438757833475, "episode": 14.0, "batch_reward": 0.33484519824385645, "critic_loss": 1.9100852645635604, "actor_loss": -85.36121253967285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.239118814468384, "step": 14000}
{"episode_reward": 501.2255484872917, "episode": 15.0, "batch_reward": 0.34651676142215726, "critic_loss": 1.8194767357110977, "actor_loss": -84.97593821716309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.237606048583984, "step": 15000}
{"episode_reward": 340.2903125215468, "episode": 16.0, "batch_reward": 0.33997785052657126, "critic_loss": 1.7733513581752778, "actor_loss": -83.97998622131348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.21879744529724, "step": 16000}
{"episode_reward": 204.59745165838675, "episode": 17.0, "batch_reward": 0.32679103627800943, "critic_loss": 1.7190319057703018, "actor_loss": -83.27614424133301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.196930646896362, "step": 17000}
{"episode_reward": 192.17196296167293, "episode": 18.0, "batch_reward": 0.3275054982900619, "critic_loss": 1.5105779968500137, "actor_loss": -83.17946305847168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.24334192276001, "step": 18000}
{"episode_reward": 467.58694943250646, "episode": 19.0, "batch_reward": 0.33265883186459544, "critic_loss": 1.5148342542052269, "actor_loss": -82.76137551879883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.23981285095215, "step": 19000}
{"episode_reward": 396.0689438363559, "episode": 20.0, "batch_reward": 0.3420323301851749, "critic_loss": 1.3225105652213096, "actor_loss": -82.43926455688477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.179030418395996, "step": 20000}
{"episode_reward": 575.1637077439063, "episode": 21.0, "batch_reward": 0.35396181130409243, "critic_loss": 1.2785466937422751, "actor_loss": -81.98829895019531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.775981426239014, "step": 21000}
{"episode_reward": 535.5018921387939, "episode": 22.0, "batch_reward": 0.36143024057149886, "critic_loss": 1.175691331267357, "actor_loss": -81.47060638427735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.178987741470337, "step": 22000}
{"episode_reward": 576.0275257239557, "episode": 23.0, "batch_reward": 0.3718923610150814, "critic_loss": 1.080235973596573, "actor_loss": -80.74504257202149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.171294927597046, "step": 23000}
{"episode_reward": 595.7086540963498, "episode": 24.0, "batch_reward": 0.38024087953567504, "critic_loss": 1.039018589735031, "actor_loss": -79.82698016357422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.175797700881958, "step": 24000}
{"episode_reward": 564.4471529386622, "episode": 25.0, "batch_reward": 0.3878990084528923, "critic_loss": 1.0095807646512984, "actor_loss": -79.82151194763183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.19725203514099, "step": 25000}
{"episode_reward": 585.1967257843054, "episode": 26.0, "batch_reward": 0.39767290771007535, "critic_loss": 1.0130431841015817, "actor_loss": -78.89898837280273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.192134380340576, "step": 26000}
{"episode_reward": 578.0340635709196, "episode": 27.0, "batch_reward": 0.40268837970495225, "critic_loss": 1.0693674566149711, "actor_loss": -78.2849617767334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.186143159866333, "step": 27000}
{"episode_reward": 514.892104022478, "episode": 28.0, "batch_reward": 0.40643726766109467, "critic_loss": 1.2006031243801116, "actor_loss": -78.31306330871583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.19884181022644, "step": 28000}
{"episode_reward": 593.6927681466441, "episode": 29.0, "batch_reward": 0.4133516599535942, "critic_loss": 1.2593898375034331, "actor_loss": -77.69309994506835, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.19566559791565, "step": 29000}
{"episode_reward": 603.644914882906, "episode": 30.0, "batch_reward": 0.4220218463242054, "critic_loss": 1.3420845413208007, "actor_loss": -77.36486375427246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.18355965614319, "step": 30000}
{"episode_reward": 711.4566529170174, "episode": 31.0, "batch_reward": 0.4233221462070942, "critic_loss": 1.2536885026693345, "actor_loss": -77.94016749572754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.76809048652649, "step": 31000}
{"episode_reward": 105.68336415490049, "episode": 32.0, "batch_reward": 0.42144826155900955, "critic_loss": 1.2278907918334008, "actor_loss": -77.01832963562012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.146716833114624, "step": 32000}
{"episode_reward": 688.10287722357, "episode": 33.0, "batch_reward": 0.43116257584095, "critic_loss": 1.1947174797058104, "actor_loss": -77.06477108764649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.170652627944946, "step": 33000}
{"episode_reward": 792.8918135131227, "episode": 34.0, "batch_reward": 0.4343635241985321, "critic_loss": 1.1331082243919373, "actor_loss": -77.36684864807128, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.173497200012207, "step": 34000}
{"episode_reward": 336.4421283316835, "episode": 35.0, "batch_reward": 0.43775654515624046, "critic_loss": 1.1324877548217773, "actor_loss": -76.83892501831055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.163692235946655, "step": 35000}
{"episode_reward": 754.3772641582073, "episode": 36.0, "batch_reward": 0.44604444500803947, "critic_loss": 1.1188770030736923, "actor_loss": -77.34979022216797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.145562887191772, "step": 36000}
{"episode_reward": 663.3825002303386, "episode": 37.0, "batch_reward": 0.4501228289604187, "critic_loss": 1.06966754925251, "actor_loss": -76.95144627380371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14973282814026, "step": 37000}
{"episode_reward": 624.3452324355233, "episode": 38.0, "batch_reward": 0.4532882342338562, "critic_loss": 0.993991996049881, "actor_loss": -76.85210731506348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.17778706550598, "step": 38000}
{"episode_reward": 405.5717921330742, "episode": 39.0, "batch_reward": 0.4543907101750374, "critic_loss": 0.952076906979084, "actor_loss": -76.9403359375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.195232629776, "step": 39000}
{"episode_reward": 387.8037973948363, "episode": 40.0, "batch_reward": 0.44948366621136665, "critic_loss": 0.9773021558523178, "actor_loss": -77.38482147216797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.215043783187866, "step": 40000}
{"episode_reward": 582.9945456117688, "episode": 41.0, "batch_reward": 0.4584163861870766, "critic_loss": 0.99866104221344, "actor_loss": -76.88787385559083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.8247766494751, "step": 41000}
{"episode_reward": 840.5951632981706, "episode": 42.0, "batch_reward": 0.4665556382536888, "critic_loss": 0.9815695798397064, "actor_loss": -76.91820051574707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.189323902130127, "step": 42000}
{"episode_reward": 699.52008732905, "episode": 43.0, "batch_reward": 0.47244878828525544, "critic_loss": 1.010396563887596, "actor_loss": -77.05713395690918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.174113512039185, "step": 43000}
{"episode_reward": 758.9802835002005, "episode": 44.0, "batch_reward": 0.47804923352599143, "critic_loss": 1.0241467779874802, "actor_loss": -76.69743099975587, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.17476773262024, "step": 44000}
{"episode_reward": 807.8904335763492, "episode": 45.0, "batch_reward": 0.48658904612064363, "critic_loss": 1.0388541630506516, "actor_loss": -76.1065305633545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.150211811065674, "step": 45000}
{"episode_reward": 762.8696094638307, "episode": 46.0, "batch_reward": 0.49176704227924345, "critic_loss": 1.132718407034874, "actor_loss": -75.94551098632813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.18602442741394, "step": 46000}
{"episode_reward": 735.8703161440701, "episode": 47.0, "batch_reward": 0.49721913480758667, "critic_loss": 1.1236129299402238, "actor_loss": -77.25198484802246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.165603399276733, "step": 47000}
{"episode_reward": 804.8968255849076, "episode": 48.0, "batch_reward": 0.5031929780542851, "critic_loss": 1.192128306388855, "actor_loss": -76.86208848571778, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.153361797332764, "step": 48000}
{"episode_reward": 797.4698189988394, "episode": 49.0, "batch_reward": 0.5108714311420918, "critic_loss": 1.149628699183464, "actor_loss": -77.32335131835937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.19548726081848, "step": 49000}
{"episode_reward": 837.7216767776828, "episode": 50.0, "batch_reward": 0.5173658913969994, "critic_loss": 1.1512769406437875, "actor_loss": -77.38089852905273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20796823501587, "step": 50000}
{"episode_reward": 860.6570642901843, "episode": 51.0, "batch_reward": 0.5221477750539779, "critic_loss": 1.1611164010763169, "actor_loss": -77.4265111541748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.83317494392395, "step": 51000}
{"episode_reward": 394.55171652905636, "episode": 52.0, "batch_reward": 0.5226290904283524, "critic_loss": 1.1544681004881858, "actor_loss": -77.29283334350586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.231196403503418, "step": 52000}
{"episode_reward": 736.5713626340286, "episode": 53.0, "batch_reward": 0.527265170365572, "critic_loss": 1.1468768472075461, "actor_loss": -78.2438094177246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.204519510269165, "step": 53000}
{"episode_reward": 912.9971097376662, "episode": 54.0, "batch_reward": 0.5331588991582393, "critic_loss": 1.1842817022800445, "actor_loss": -78.1909666595459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.17658543586731, "step": 54000}
{"episode_reward": 795.1845653700215, "episode": 55.0, "batch_reward": 0.5387894561588764, "critic_loss": 1.146233578979969, "actor_loss": -78.48796987915038, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.185688018798828, "step": 55000}
{"episode_reward": 822.2507139353431, "episode": 56.0, "batch_reward": 0.5396631610393524, "critic_loss": 1.1847950130701066, "actor_loss": -78.82028376770019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.205886840820312, "step": 56000}
{"episode_reward": 636.1907401163684, "episode": 57.0, "batch_reward": 0.5410335072278977, "critic_loss": 1.177675981104374, "actor_loss": -78.71496929931641, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.23273730278015, "step": 57000}
{"episode_reward": 248.8454889249335, "episode": 58.0, "batch_reward": 0.5407555780410767, "critic_loss": 1.1925542961955071, "actor_loss": -79.13412075805664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.21746587753296, "step": 58000}
{"episode_reward": 879.0518762252186, "episode": 59.0, "batch_reward": 0.5476392960250378, "critic_loss": 1.1932462354898452, "actor_loss": -79.2739514465332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.22285485267639, "step": 59000}
{"episode_reward": 882.9859688892573, "episode": 60.0, "batch_reward": 0.5498801644444465, "critic_loss": 1.1910719082355499, "actor_loss": -78.74169149780273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.234539270401, "step": 60000}
{"episode_reward": 904.3209520052767, "episode": 61.0, "batch_reward": 0.5558616356253624, "critic_loss": 1.153377278625965, "actor_loss": -79.31878021240234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.85352826118469, "step": 61000}
{"episode_reward": 867.381725551864, "episode": 62.0, "batch_reward": 0.5619264479577541, "critic_loss": 1.2106651152968406, "actor_loss": -78.80586936950684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.22541618347168, "step": 62000}
{"episode_reward": 819.0704948599708, "episode": 63.0, "batch_reward": 0.5652163688838482, "critic_loss": 1.1945502995848656, "actor_loss": -79.43831820678712, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.233373641967773, "step": 63000}
{"episode_reward": 817.3841555454053, "episode": 64.0, "batch_reward": 0.5715864625275136, "critic_loss": 1.2237637176513672, "actor_loss": -80.48068836975098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.241992712020874, "step": 64000}
{"episode_reward": 884.8448144871983, "episode": 65.0, "batch_reward": 0.5756912168264389, "critic_loss": 1.2106594030857085, "actor_loss": -79.82978240966797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.23555016517639, "step": 65000}
{"episode_reward": 881.1077625695967, "episode": 66.0, "batch_reward": 0.580523837685585, "critic_loss": 1.231743910729885, "actor_loss": -80.41792497253418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.22906756401062, "step": 66000}
{"episode_reward": 919.9772200923466, "episode": 67.0, "batch_reward": 0.5837212781310082, "critic_loss": 1.2216627378463745, "actor_loss": -80.49456059265137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.221403121948242, "step": 67000}
{"episode_reward": 828.1363565819165, "episode": 68.0, "batch_reward": 0.5907436294257641, "critic_loss": 1.1734455469846725, "actor_loss": -81.53005519104003, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.19212532043457, "step": 68000}
{"episode_reward": 921.3705033191173, "episode": 69.0, "batch_reward": 0.5952854278087616, "critic_loss": 1.1807391358017922, "actor_loss": -81.0307113494873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.2635440826416, "step": 69000}
{"episode_reward": 858.0953432500689, "episode": 70.0, "batch_reward": 0.59820219373703, "critic_loss": 1.1930876274704934, "actor_loss": -81.07210408020019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.50461769104004, "step": 70000}
{"episode_reward": 866.1255320467304, "episode": 71.0, "batch_reward": 0.6017793661355972, "critic_loss": 1.1973267931342124, "actor_loss": -81.32541903686523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.92277646064758, "step": 71000}
{"episode_reward": 912.2979093871232, "episode": 72.0, "batch_reward": 0.6044435955882073, "critic_loss": 1.1876498281359673, "actor_loss": -81.73892776489258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15764331817627, "step": 72000}
{"episode_reward": 935.9558212245261, "episode": 73.0, "batch_reward": 0.6100707464814186, "critic_loss": 1.1686099541187287, "actor_loss": -82.20827941894531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.18759298324585, "step": 73000}
{"episode_reward": 883.365878257388, "episode": 74.0, "batch_reward": 0.6116375166773796, "critic_loss": 1.1616540184020996, "actor_loss": -82.4670782623291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.185035705566406, "step": 74000}
{"episode_reward": 868.8991808863777, "episode": 75.0, "batch_reward": 0.6190036991238594, "critic_loss": 1.143963296532631, "actor_loss": -83.13772575378418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.195985078811646, "step": 75000}
{"episode_reward": 891.2576670868103, "episode": 76.0, "batch_reward": 0.6221765718460083, "critic_loss": 1.0996170642971992, "actor_loss": -83.55409275817871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15462350845337, "step": 76000}
{"episode_reward": 945.4348190095677, "episode": 77.0, "batch_reward": 0.6244550702571869, "critic_loss": 1.1362087251544, "actor_loss": -83.42240092468262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.182153940200806, "step": 77000}
{"episode_reward": 894.4847073229307, "episode": 78.0, "batch_reward": 0.6289440037608147, "critic_loss": 1.1009689380526542, "actor_loss": -83.44182200622559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.18940782546997, "step": 78000}
{"episode_reward": 967.3468359203256, "episode": 79.0, "batch_reward": 0.632347348690033, "critic_loss": 1.0912282238602637, "actor_loss": -83.93715306091309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.193062782287598, "step": 79000}
{"episode_reward": 726.2573917886199, "episode": 80.0, "batch_reward": 0.6270241884291172, "critic_loss": 1.0834282736182212, "actor_loss": -83.94822959899902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.192606925964355, "step": 80000}
{"episode_reward": 96.08517726888633, "episode": 81.0, "batch_reward": 0.6269657076001167, "critic_loss": 1.0582637247741222, "actor_loss": -84.06806753540039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.83180356025696, "step": 81000}
{"episode_reward": 928.0421265803268, "episode": 82.0, "batch_reward": 0.6303046932220459, "critic_loss": 1.0425665912032127, "actor_loss": -84.54194177246094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.200464725494385, "step": 82000}
{"episode_reward": 883.5333275103758, "episode": 83.0, "batch_reward": 0.6330260164737701, "critic_loss": 1.0471724113225938, "actor_loss": -84.00215174865723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.221357107162476, "step": 83000}
{"episode_reward": 856.78216576416, "episode": 84.0, "batch_reward": 0.6363330952525139, "critic_loss": 1.0649067928195, "actor_loss": -84.58810635375977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.23009490966797, "step": 84000}
{"episode_reward": 887.4376797696594, "episode": 85.0, "batch_reward": 0.6399808591604232, "critic_loss": 1.0732777014374733, "actor_loss": -84.82357870483398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.22677993774414, "step": 85000}
{"episode_reward": 901.1021554520873, "episode": 86.0, "batch_reward": 0.6434182369112968, "critic_loss": 1.0676112867593766, "actor_loss": -84.94708082580567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.218828678131104, "step": 86000}
{"episode_reward": 905.6437470440677, "episode": 87.0, "batch_reward": 0.6450268283486367, "critic_loss": 1.0603609511852263, "actor_loss": -85.11914576721192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.213879823684692, "step": 87000}
{"episode_reward": 904.3076698686084, "episode": 88.0, "batch_reward": 0.6490207680463791, "critic_loss": 1.0329623172879219, "actor_loss": -85.15126858520507, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.213054418563843, "step": 88000}
{"episode_reward": 931.0762467874239, "episode": 89.0, "batch_reward": 0.6517843952775002, "critic_loss": 1.0097291575968266, "actor_loss": -85.4920475769043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.22214436531067, "step": 89000}
{"episode_reward": 858.0012901125144, "episode": 90.0, "batch_reward": 0.6540993373394013, "critic_loss": 0.9949566112160683, "actor_loss": -85.81520120239257, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.213695764541626, "step": 90000}
{"episode_reward": 936.5953742747133, "episode": 91.0, "batch_reward": 0.6558524908423424, "critic_loss": 0.973743960082531, "actor_loss": -85.89802355957032, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.76118993759155, "step": 91000}
{"episode_reward": 901.9266969777877, "episode": 92.0, "batch_reward": 0.6594941636323929, "critic_loss": 0.9573567753732204, "actor_loss": -85.59957638549805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16261053085327, "step": 92000}
{"episode_reward": 963.25209046492, "episode": 93.0, "batch_reward": 0.6645587705373764, "critic_loss": 0.9563287149071693, "actor_loss": -86.2445149383545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.166764736175537, "step": 93000}
{"episode_reward": 865.0329392481309, "episode": 94.0, "batch_reward": 0.6666529875397682, "critic_loss": 0.9428831708431243, "actor_loss": -86.18431359863281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.168163299560547, "step": 94000}
{"episode_reward": 928.5568491749385, "episode": 95.0, "batch_reward": 0.667007784307003, "critic_loss": 0.9540085520148277, "actor_loss": -86.88503576660156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.172620058059692, "step": 95000}
{"episode_reward": 890.5902415116028, "episode": 96.0, "batch_reward": 0.6713782567381859, "critic_loss": 0.952524424046278, "actor_loss": -86.55086622619629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.176883220672607, "step": 96000}
{"episode_reward": 867.7686432241921, "episode": 97.0, "batch_reward": 0.6734200012087822, "critic_loss": 0.9313250522613525, "actor_loss": -87.2115750579834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.143630743026733, "step": 97000}
{"episode_reward": 931.4644297668522, "episode": 98.0, "batch_reward": 0.6764102213978768, "critic_loss": 0.9081704816222191, "actor_loss": -87.5180615234375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16777491569519, "step": 98000}
{"episode_reward": 926.5197453870602, "episode": 99.0, "batch_reward": 0.6778183138370514, "critic_loss": 0.9261826057136059, "actor_loss": -87.36727893066406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.221843719482422, "step": 99000}
{"episode_reward": 917.4542314649352, "episode": 100.0, "batch_reward": 0.680038846552372, "critic_loss": 0.9140818507373333, "actor_loss": -87.43518333435058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.22233009338379, "step": 100000}
{"episode_reward": 905.6699263161638, "episode": 101.0, "batch_reward": 0.6829544357061386, "critic_loss": 0.8905598530769349, "actor_loss": -87.56834999084472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.75946760177612, "step": 101000}
{"episode_reward": 908.2412367317564, "episode": 102.0, "batch_reward": 0.6856665684580803, "critic_loss": 0.8944951063096523, "actor_loss": -87.91682493591308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14444351196289, "step": 102000}
{"episode_reward": 922.5966525161103, "episode": 103.0, "batch_reward": 0.6863781433105469, "critic_loss": 0.8755880081355571, "actor_loss": -87.85052488708496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.193963050842285, "step": 103000}
{"episode_reward": 752.177852161841, "episode": 104.0, "batch_reward": 0.6894433607459068, "critic_loss": 0.8703478437364102, "actor_loss": -88.31704983520508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1705060005188, "step": 104000}
{"episode_reward": 883.6705349250226, "episode": 105.0, "batch_reward": 0.6888325980305672, "critic_loss": 0.8720137794315815, "actor_loss": -88.08926992797852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14631724357605, "step": 105000}
{"episode_reward": 959.2511317687129, "episode": 106.0, "batch_reward": 0.6921880769133568, "critic_loss": 0.8614344642460346, "actor_loss": -88.29561798095703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.161937952041626, "step": 106000}
{"episode_reward": 934.98929692483, "episode": 107.0, "batch_reward": 0.6922875248789787, "critic_loss": 0.8221557667553425, "actor_loss": -88.60689532470703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20212411880493, "step": 107000}
{"episode_reward": 936.0529816778094, "episode": 108.0, "batch_reward": 0.6962986397743225, "critic_loss": 0.8025940211713314, "actor_loss": -88.62788667297363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15893054008484, "step": 108000}
{"episode_reward": 967.6172750788996, "episode": 109.0, "batch_reward": 0.6990929006338119, "critic_loss": 0.8369184512495994, "actor_loss": -88.92959371948243, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.204657077789307, "step": 109000}
{"episode_reward": 821.7231157656219, "episode": 110.0, "batch_reward": 0.7004849458932877, "critic_loss": 0.8140264791548252, "actor_loss": -88.96216899108887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15716576576233, "step": 110000}
{"episode_reward": 948.1459207797051, "episode": 111.0, "batch_reward": 0.7025527244210243, "critic_loss": 0.8144800608158111, "actor_loss": -88.73720095825195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.76915645599365, "step": 111000}
{"episode_reward": 936.9421292992101, "episode": 112.0, "batch_reward": 0.7047179650068283, "critic_loss": 0.8045503968596458, "actor_loss": -88.85568074035645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.225812911987305, "step": 112000}
{"episode_reward": 887.0094478055973, "episode": 113.0, "batch_reward": 0.7066312646269798, "critic_loss": 0.8169868625998497, "actor_loss": -88.73139009094238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.216200351715088, "step": 113000}
{"episode_reward": 915.6265391245432, "episode": 114.0, "batch_reward": 0.7098156940937043, "critic_loss": 0.8058601158261299, "actor_loss": -89.09500947570801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.180440187454224, "step": 114000}
{"episode_reward": 954.1982493882231, "episode": 115.0, "batch_reward": 0.7116610100269317, "critic_loss": 0.84294739818573, "actor_loss": -89.44826409912109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.242051124572754, "step": 115000}
{"episode_reward": 972.0543150124645, "episode": 116.0, "batch_reward": 0.7124848155379295, "critic_loss": 0.8587076749205589, "actor_loss": -89.367749710083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20165205001831, "step": 116000}
{"episode_reward": 896.4683870746923, "episode": 117.0, "batch_reward": 0.7152031223773956, "critic_loss": 0.8442744895517826, "actor_loss": -89.37975016784668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.217241048812866, "step": 117000}
{"episode_reward": 924.036507716969, "episode": 118.0, "batch_reward": 0.7163906769156456, "critic_loss": 0.8625882185995579, "actor_loss": -89.31611996459961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.17769980430603, "step": 118000}
{"episode_reward": 912.3700798071999, "episode": 119.0, "batch_reward": 0.7183575088381767, "critic_loss": 0.8602866954505444, "actor_loss": -89.41941065979005, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.183667182922363, "step": 119000}
{"episode_reward": 942.5092126591948, "episode": 120.0, "batch_reward": 0.7199471079707146, "critic_loss": 0.8287999210059642, "actor_loss": -89.84086001586914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.176735877990723, "step": 120000}
{"episode_reward": 936.6155557477255, "episode": 121.0, "batch_reward": 0.7215693936347961, "critic_loss": 0.8283538140952588, "actor_loss": -89.77244737243652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.785844802856445, "step": 121000}
{"episode_reward": 916.3941885182868, "episode": 122.0, "batch_reward": 0.7235324735045433, "critic_loss": 0.832195895075798, "actor_loss": -90.16376620483399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.170107126235962, "step": 122000}
{"episode_reward": 927.2003743139788, "episode": 123.0, "batch_reward": 0.7227389862537384, "critic_loss": 0.8349167411327362, "actor_loss": -90.25680160522461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.161850214004517, "step": 123000}
{"episode_reward": 880.6839202273483, "episode": 124.0, "batch_reward": 0.7259303989410401, "critic_loss": 0.8580206388533116, "actor_loss": -90.15283625793457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.210742235183716, "step": 124000}
{"episode_reward": 975.0885859328841, "episode": 125.0, "batch_reward": 0.7288184879422188, "critic_loss": 0.8511600079536438, "actor_loss": -90.14392337036132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.223132371902466, "step": 125000}
{"episode_reward": 924.2199014107636, "episode": 126.0, "batch_reward": 0.7292019897699356, "critic_loss": 0.8520502383708954, "actor_loss": -90.16242575073242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.225616693496704, "step": 126000}
{"episode_reward": 949.4106304711823, "episode": 127.0, "batch_reward": 0.7306035218238831, "critic_loss": 0.8376609252095223, "actor_loss": -90.39131884765625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20657515525818, "step": 127000}
{"episode_reward": 898.3073148078091, "episode": 128.0, "batch_reward": 0.7319477064013481, "critic_loss": 0.845805133163929, "actor_loss": -90.27674028015137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.235626459121704, "step": 128000}
{"episode_reward": 961.0485315135377, "episode": 129.0, "batch_reward": 0.73432138723135, "critic_loss": 0.8504847674071789, "actor_loss": -90.37776762390136, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.23221516609192, "step": 129000}
{"episode_reward": 714.1493874439046, "episode": 130.0, "batch_reward": 0.7333482050299645, "critic_loss": 0.8332038564383983, "actor_loss": -90.49619830322266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.18022632598877, "step": 130000}
{"episode_reward": 920.451364680631, "episode": 131.0, "batch_reward": 0.733996907889843, "critic_loss": 0.8404668342769146, "actor_loss": -90.213689163208, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.8089599609375, "step": 131000}
{"episode_reward": 863.9615056379032, "episode": 132.0, "batch_reward": 0.7361540911793709, "critic_loss": 0.8063516950309276, "actor_loss": -90.4639427947998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.21209192276001, "step": 132000}
{"episode_reward": 935.6977111898807, "episode": 133.0, "batch_reward": 0.7354808669686318, "critic_loss": 0.7866529580950737, "actor_loss": -90.496607131958, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.23353600502014, "step": 133000}
{"episode_reward": 911.3118725121633, "episode": 134.0, "batch_reward": 0.7382518768310546, "critic_loss": 0.7788913709521293, "actor_loss": -90.61233569335937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.193609952926636, "step": 134000}
{"episode_reward": 894.9540367207842, "episode": 135.0, "batch_reward": 0.7386814769506455, "critic_loss": 0.8174407612681389, "actor_loss": -90.69395834350586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20807695388794, "step": 135000}
{"episode_reward": 936.8730236072165, "episode": 136.0, "batch_reward": 0.7408322517871857, "critic_loss": 0.8116620430648327, "actor_loss": -90.78281089782715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.2341091632843, "step": 136000}
{"episode_reward": 841.4774242504021, "episode": 137.0, "batch_reward": 0.7440089302659034, "critic_loss": 0.8038991275727749, "actor_loss": -90.81634614562988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.23979878425598, "step": 137000}
{"episode_reward": 977.0006160252166, "episode": 138.0, "batch_reward": 0.7444226896166801, "critic_loss": 0.8055092320740223, "actor_loss": -90.63967343139649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.226467609405518, "step": 138000}
{"episode_reward": 924.9550564236825, "episode": 139.0, "batch_reward": 0.7441387844085693, "critic_loss": 0.8235723278224468, "actor_loss": -90.66324960327148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.200215578079224, "step": 139000}
{"episode_reward": 724.8292132059829, "episode": 140.0, "batch_reward": 0.7452663334012032, "critic_loss": 0.8101189965605736, "actor_loss": -90.56720436096191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.236492156982422, "step": 140000}
{"episode_reward": 950.4458228352354, "episode": 141.0, "batch_reward": 0.7471458440423012, "critic_loss": 0.8256096760630608, "actor_loss": -90.9114091796875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.884724855422974, "step": 141000}
{"episode_reward": 937.0442425443104, "episode": 142.0, "batch_reward": 0.7473952234983444, "critic_loss": 0.8197172233760357, "actor_loss": -90.91208503723145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.238667249679565, "step": 142000}
{"episode_reward": 909.9481289304388, "episode": 143.0, "batch_reward": 0.7488370792865753, "critic_loss": 0.8516844373643399, "actor_loss": -91.00057272338867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.240126371383667, "step": 143000}
{"episode_reward": 932.8988284079518, "episode": 144.0, "batch_reward": 0.751907117486, "critic_loss": 0.8556310563981533, "actor_loss": -90.92449526977539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.209609508514404, "step": 144000}
{"episode_reward": 899.6480481905651, "episode": 145.0, "batch_reward": 0.7523454276919365, "critic_loss": 0.8519386664330959, "actor_loss": -91.2091662902832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.224621057510376, "step": 145000}
{"episode_reward": 928.0543732101186, "episode": 146.0, "batch_reward": 0.7524956758618355, "critic_loss": 0.8772191537618637, "actor_loss": -90.908755859375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.24899983406067, "step": 146000}
{"episode_reward": 920.6523025982406, "episode": 147.0, "batch_reward": 0.7528709933757782, "critic_loss": 0.8360625954568386, "actor_loss": -91.08380433654786, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.237988710403442, "step": 147000}
{"episode_reward": 926.8686770722443, "episode": 148.0, "batch_reward": 0.7553047730326653, "critic_loss": 0.8525980016887188, "actor_loss": -91.11049833679199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.241316080093384, "step": 148000}
{"episode_reward": 947.5437489577018, "episode": 149.0, "batch_reward": 0.7557288177013397, "critic_loss": 0.8444238573312759, "actor_loss": -91.06950863647461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.234349250793457, "step": 149000}
{"episode_reward": 923.6710761779663, "episode": 150.0, "batch_reward": 0.7581527848243713, "critic_loss": 0.7963382099568844, "actor_loss": -91.19741676330567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
