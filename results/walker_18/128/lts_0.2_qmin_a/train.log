{"episode_reward": 0.0, "episode": 1.0, "duration": 22.405395030975342, "step": 1000}
{"episode_reward": 27.46298806610516, "episode": 2.0, "duration": 1.8794207572937012, "step": 2000}
{"episode_reward": 489.1100087318934, "episode": 3.0, "batch_reward": 0.24390255162202346, "critic_loss": 0.16199348560835955, "actor_loss": -19.499143940330082, "actor_target_entropy": -6.0, "alpha_value": 0.002134017781850189, "duration": 62.76786971092224, "step": 3000}
{"episode_reward": 50.794505681672376, "episode": 4.0, "batch_reward": 0.1684537823200226, "critic_loss": 0.41679512916505335, "actor_loss": -26.535714506149294, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.674052238464355, "step": 4000}
{"episode_reward": 38.3044297555149, "episode": 5.0, "batch_reward": 0.1651454485654831, "critic_loss": 0.9782041045725346, "actor_loss": -29.139932777404784, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.207553386688232, "step": 5000}
{"episode_reward": 271.1132707537013, "episode": 6.0, "batch_reward": 0.1708643748164177, "critic_loss": 1.3727046622037888, "actor_loss": -31.955470859527587, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.447179794311523, "step": 6000}
{"episode_reward": 84.90508131629309, "episode": 7.0, "batch_reward": 0.170949073985219, "critic_loss": 1.31773522824049, "actor_loss": -32.93751507949829, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.425272941589355, "step": 7000}
{"episode_reward": 215.26655077839214, "episode": 8.0, "batch_reward": 0.17266314925253393, "critic_loss": 1.1301362701058388, "actor_loss": -37.85989888381958, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.356555938720703, "step": 8000}
{"episode_reward": 223.4189618565745, "episode": 9.0, "batch_reward": 0.1759682511240244, "critic_loss": 1.102772073864937, "actor_loss": -37.35938250732422, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.577805995941162, "step": 9000}
{"episode_reward": 238.89785415286298, "episode": 10.0, "batch_reward": 0.19600161319971085, "critic_loss": 1.0086878803372383, "actor_loss": -39.47120331954956, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.421146869659424, "step": 10000}
{"episode_reward": 414.57841654810346, "episode": 11.0, "batch_reward": 0.2064914501607418, "critic_loss": 1.0425286452174187, "actor_loss": -39.59659176254272, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.53001165390015, "step": 11000}
{"episode_reward": 201.8501986237225, "episode": 12.0, "batch_reward": 0.21631721183657646, "critic_loss": 1.0796415794491767, "actor_loss": -40.88610280609131, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.813542127609253, "step": 12000}
{"episode_reward": 423.24976950275715, "episode": 13.0, "batch_reward": 0.23234550853073596, "critic_loss": 1.1298813533186913, "actor_loss": -42.77498977279663, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.000433921813965, "step": 13000}
{"episode_reward": 528.7837649672887, "episode": 14.0, "batch_reward": 0.24420018567144872, "critic_loss": 0.9897871703505516, "actor_loss": -45.11497515869141, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.6277916431427, "step": 14000}
{"episode_reward": 131.64131705059887, "episode": 15.0, "batch_reward": 0.2350409094840288, "critic_loss": 1.003542351603508, "actor_loss": -45.2772774810791, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.47986102104187, "step": 15000}
{"episode_reward": 87.52544364241021, "episode": 16.0, "batch_reward": 0.22768103413283824, "critic_loss": 1.060902559041977, "actor_loss": -45.739930015563964, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.261054754257202, "step": 16000}
{"episode_reward": 159.62613008501913, "episode": 17.0, "batch_reward": 0.22411368525028227, "critic_loss": 1.1185535237789155, "actor_loss": -45.738239791870114, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.77519655227661, "step": 17000}
{"episode_reward": 171.13372328835175, "episode": 18.0, "batch_reward": 0.22338226932287217, "critic_loss": 1.1327818363904953, "actor_loss": -47.32507894897461, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.44561743736267, "step": 18000}
{"episode_reward": 198.04161695084542, "episode": 19.0, "batch_reward": 0.214743244856596, "critic_loss": 1.0415404950380325, "actor_loss": -48.25753118133545, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.953259229660034, "step": 19000}
{"episode_reward": 16.70849883249106, "episode": 20.0, "batch_reward": 0.20808441914618014, "critic_loss": 1.146950702726841, "actor_loss": -48.29469264984131, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.85166072845459, "step": 20000}
{"episode_reward": 123.6287469538483, "episode": 21.0, "batch_reward": 0.21176795169711113, "critic_loss": 1.2292873346209525, "actor_loss": -48.22579083251953, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.477169036865234, "step": 21000}
{"episode_reward": 419.37288637115284, "episode": 22.0, "batch_reward": 0.22030754931271077, "critic_loss": 1.303876686513424, "actor_loss": -50.50757376861572, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.82954168319702, "step": 22000}
{"episode_reward": 441.940881711104, "episode": 23.0, "batch_reward": 0.2331081957668066, "critic_loss": 1.234721256673336, "actor_loss": -49.54475733947754, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.468158721923828, "step": 23000}
{"episode_reward": 596.9129528406602, "episode": 24.0, "batch_reward": 0.2460457250624895, "critic_loss": 1.2308392825722694, "actor_loss": -51.22233682250977, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.503358364105225, "step": 24000}
{"episode_reward": 498.57977497402885, "episode": 25.0, "batch_reward": 0.2559147633165121, "critic_loss": 1.186114466071129, "actor_loss": -51.89081462097168, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.3396954536438, "step": 25000}
{"episode_reward": 498.3761950246276, "episode": 26.0, "batch_reward": 0.265499378785491, "critic_loss": 1.2410588660240174, "actor_loss": -51.94476212310791, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.439610958099365, "step": 26000}
{"episode_reward": 474.0574397474035, "episode": 27.0, "batch_reward": 0.2756322318315506, "critic_loss": 1.1987469090819358, "actor_loss": -52.738762214660646, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.24464464187622, "step": 27000}
{"episode_reward": 549.8097311659769, "episode": 28.0, "batch_reward": 0.28464569367468356, "critic_loss": 1.1637033571004867, "actor_loss": -53.2057829208374, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.60247564315796, "step": 28000}
{"episode_reward": 539.9721540073032, "episode": 29.0, "batch_reward": 0.2958484731167555, "critic_loss": 1.1827693808674813, "actor_loss": -53.27086114501953, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.44178557395935, "step": 29000}
{"episode_reward": 639.9993763597491, "episode": 30.0, "batch_reward": 0.3045590031445026, "critic_loss": 1.1771066938638688, "actor_loss": -54.161520240783695, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.695930004119873, "step": 30000}
{"episode_reward": 483.3164917660222, "episode": 31.0, "batch_reward": 0.3132845046669245, "critic_loss": 1.118444626778364, "actor_loss": -55.254325981140134, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.83878540992737, "step": 31000}
{"episode_reward": 599.1650944492754, "episode": 32.0, "batch_reward": 0.32310603152215484, "critic_loss": 1.1752018899917602, "actor_loss": -54.86946206665039, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.607433319091797, "step": 32000}
{"episode_reward": 654.1126862375576, "episode": 33.0, "batch_reward": 0.32852708905935285, "critic_loss": 1.0885581046938897, "actor_loss": -54.79414108276367, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.824738025665283, "step": 33000}
{"episode_reward": 241.86392201998316, "episode": 34.0, "batch_reward": 0.32931749123334886, "critic_loss": 1.1326759310364722, "actor_loss": -56.02368676757813, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.92484402656555, "step": 34000}
{"episode_reward": 594.6982088329229, "episode": 35.0, "batch_reward": 0.33803836107254026, "critic_loss": 1.0725124840736389, "actor_loss": -54.58659423828125, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.483050107955933, "step": 35000}
{"episode_reward": 577.2665573778262, "episode": 36.0, "batch_reward": 0.3447189057171345, "critic_loss": 1.1360693079829216, "actor_loss": -56.49364511871338, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.60771131515503, "step": 36000}
{"episode_reward": 566.4517131610605, "episode": 37.0, "batch_reward": 0.34864678072929384, "critic_loss": 1.2011838086843492, "actor_loss": -56.150663619995115, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.437211751937866, "step": 37000}
{"episode_reward": 559.1250553289831, "episode": 38.0, "batch_reward": 0.35050808039307596, "critic_loss": 1.2568123627901078, "actor_loss": -55.92705577087402, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.43952441215515, "step": 38000}
{"episode_reward": 287.5644995915622, "episode": 39.0, "batch_reward": 0.3546458580493927, "critic_loss": 1.2914886761903763, "actor_loss": -56.31494729614258, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.880918502807617, "step": 39000}
{"episode_reward": 698.5388333169559, "episode": 40.0, "batch_reward": 0.3625250452756882, "critic_loss": 1.2907835364341735, "actor_loss": -57.21314708709717, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.100305795669556, "step": 40000}
{"episode_reward": 696.259968103002, "episode": 41.0, "batch_reward": 0.37111463129520417, "critic_loss": 1.258969849705696, "actor_loss": -57.122852256774905, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.53751039505005, "step": 41000}
{"episode_reward": 677.706066058752, "episode": 42.0, "batch_reward": 0.37988133969902993, "critic_loss": 1.2787949383854866, "actor_loss": -57.92367774963379, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.727638244628906, "step": 42000}
{"episode_reward": 683.851588059572, "episode": 43.0, "batch_reward": 0.3862077155411243, "critic_loss": 1.2645895594358445, "actor_loss": -58.935575149536135, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.594975233078003, "step": 43000}
{"episode_reward": 692.9209077651577, "episode": 44.0, "batch_reward": 0.3909788528382778, "critic_loss": 1.349639133453369, "actor_loss": -58.92364789581299, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.912436962127686, "step": 44000}
{"episode_reward": 603.3961889525906, "episode": 45.0, "batch_reward": 0.39690198403596877, "critic_loss": 1.3408350506424904, "actor_loss": -58.8943243637085, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.789948225021362, "step": 45000}
{"episode_reward": 692.3395111701285, "episode": 46.0, "batch_reward": 0.40251580548286436, "critic_loss": 1.336343697488308, "actor_loss": -58.790808212280275, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.722569227218628, "step": 46000}
{"episode_reward": 585.1296434228431, "episode": 47.0, "batch_reward": 0.4068079615235329, "critic_loss": 1.3454814127683639, "actor_loss": -59.88243439483642, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.80969786643982, "step": 47000}
{"episode_reward": 711.1679645118068, "episode": 48.0, "batch_reward": 0.414592915982008, "critic_loss": 1.361060199201107, "actor_loss": -59.49585732269287, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.77637481689453, "step": 48000}
{"episode_reward": 711.9506354436497, "episode": 49.0, "batch_reward": 0.4230813239514828, "critic_loss": 1.342695474743843, "actor_loss": -61.45703824615479, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.76602840423584, "step": 49000}
{"episode_reward": 705.1610338362997, "episode": 50.0, "batch_reward": 0.4272521459162235, "critic_loss": 1.3811224642395974, "actor_loss": -61.63479724121094, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.74964165687561, "step": 50000}
{"episode_reward": 669.6716005244549, "episode": 51.0, "batch_reward": 0.4322578319907188, "critic_loss": 1.4006221569776536, "actor_loss": -61.53583547973633, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 40.66607713699341, "step": 51000}
{"episode_reward": 691.0649942162194, "episode": 52.0, "batch_reward": 0.4377039459049702, "critic_loss": 1.38083213442564, "actor_loss": -61.51526613616944, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.96863079071045, "step": 52000}
{"episode_reward": 834.7190355628641, "episode": 53.0, "batch_reward": 0.44657161033153536, "critic_loss": 1.4027776316404343, "actor_loss": -63.15356634521484, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.31158423423767, "step": 53000}
{"episode_reward": 793.4179934453864, "episode": 54.0, "batch_reward": 0.44980960568785666, "critic_loss": 1.4133840202093124, "actor_loss": -63.12479188537598, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.446338415145874, "step": 54000}
{"episode_reward": 628.1066670719925, "episode": 55.0, "batch_reward": 0.45609070724248885, "critic_loss": 1.416545775949955, "actor_loss": -63.8870710144043, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.782734870910645, "step": 55000}
{"episode_reward": 836.8655207650506, "episode": 56.0, "batch_reward": 0.46046307277679444, "critic_loss": 1.497488560438156, "actor_loss": -64.21410637664795, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.478941917419434, "step": 56000}
{"episode_reward": 846.9723787139669, "episode": 57.0, "batch_reward": 0.46753337675333023, "critic_loss": 1.4392500693798065, "actor_loss": -64.16795924377442, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.496649742126465, "step": 57000}
{"episode_reward": 808.6863424013188, "episode": 58.0, "batch_reward": 0.47465069270133975, "critic_loss": 1.4345152533054353, "actor_loss": -65.45300895690917, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.93460988998413, "step": 58000}
{"episode_reward": 783.8385216334226, "episode": 59.0, "batch_reward": 0.4811654167771339, "critic_loss": 1.4399992021918298, "actor_loss": -65.12070098876953, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.62372064590454, "step": 59000}
{"episode_reward": 861.8720490479933, "episode": 60.0, "batch_reward": 0.4835140089392662, "critic_loss": 1.4757514244914054, "actor_loss": -65.35521448516846, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.53524351119995, "step": 60000}
{"episode_reward": 747.7798661331699, "episode": 61.0, "batch_reward": 0.4888681951165199, "critic_loss": 1.456773265361786, "actor_loss": -66.78511331939697, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.221111536026, "step": 61000}
{"episode_reward": 853.7655844484262, "episode": 62.0, "batch_reward": 0.4975546383857727, "critic_loss": 1.405665576338768, "actor_loss": -66.77691088867188, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.427751302719116, "step": 62000}
{"episode_reward": 924.0581093940809, "episode": 63.0, "batch_reward": 0.503453292965889, "critic_loss": 1.3749150787591935, "actor_loss": -67.57811801910401, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.61684012413025, "step": 63000}
{"episode_reward": 486.2279826922439, "episode": 64.0, "batch_reward": 0.5039508509933949, "critic_loss": 1.4018834642767906, "actor_loss": -68.34413935089111, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.737072229385376, "step": 64000}
{"episode_reward": 860.4287099009289, "episode": 65.0, "batch_reward": 0.5082314618825913, "critic_loss": 1.4876599047183992, "actor_loss": -68.71267312622071, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.55090618133545, "step": 65000}
{"episode_reward": 880.9424996223844, "episode": 66.0, "batch_reward": 0.5163502788245677, "critic_loss": 1.4466723187565804, "actor_loss": -68.97795376586915, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.534391403198242, "step": 66000}
{"episode_reward": 872.9513162275648, "episode": 67.0, "batch_reward": 0.521291358590126, "critic_loss": 1.4313117415905, "actor_loss": -69.15355242919922, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.492695093154907, "step": 67000}
{"episode_reward": 844.2268636882058, "episode": 68.0, "batch_reward": 0.5263159949183464, "critic_loss": 1.5152616423368455, "actor_loss": -70.0555767288208, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.41210961341858, "step": 68000}
{"episode_reward": 908.549591456805, "episode": 69.0, "batch_reward": 0.5316647582054138, "critic_loss": 1.4170389759540558, "actor_loss": -70.31015602111816, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.62024712562561, "step": 69000}
{"episode_reward": 892.9042713272643, "episode": 70.0, "batch_reward": 0.5347227301299572, "critic_loss": 1.443531589269638, "actor_loss": -70.62258451843262, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.532674074172974, "step": 70000}
{"episode_reward": 739.8249048768054, "episode": 71.0, "batch_reward": 0.5398409379124641, "critic_loss": 1.395127983570099, "actor_loss": -71.69954598236085, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 40.68721556663513, "step": 71000}
{"episode_reward": 894.2236138225043, "episode": 72.0, "batch_reward": 0.5426076888144016, "critic_loss": 1.3848245686888694, "actor_loss": -71.48228141784668, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.834771394729614, "step": 72000}
{"episode_reward": 774.7274865182993, "episode": 73.0, "batch_reward": 0.5467420517206192, "critic_loss": 1.4100850801467895, "actor_loss": -72.56993896484374, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.762137174606323, "step": 73000}
{"episode_reward": 912.7991397146111, "episode": 74.0, "batch_reward": 0.5506335328519344, "critic_loss": 1.4044131900668144, "actor_loss": -73.2363458404541, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.768088579177856, "step": 74000}
{"episode_reward": 891.8810051493393, "episode": 75.0, "batch_reward": 0.5570409581363202, "critic_loss": 1.45931305539608, "actor_loss": -73.7236653137207, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.70908546447754, "step": 75000}
{"episode_reward": 900.876763025122, "episode": 76.0, "batch_reward": 0.5622384576797486, "critic_loss": 1.3922609153985976, "actor_loss": -74.28090921020508, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.1763596534729, "step": 76000}
{"episode_reward": 929.2986084566202, "episode": 77.0, "batch_reward": 0.5658778094947338, "critic_loss": 1.3476467039585114, "actor_loss": -74.55891534423829, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.43057608604431, "step": 77000}
{"episode_reward": 937.3352485718368, "episode": 78.0, "batch_reward": 0.5708455154895783, "critic_loss": 1.369309074997902, "actor_loss": -74.26833193969726, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.505542039871216, "step": 78000}
{"episode_reward": 865.5549990814263, "episode": 79.0, "batch_reward": 0.5756506531536579, "critic_loss": 1.4100346457362174, "actor_loss": -75.31537088012695, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.394608974456787, "step": 79000}
{"episode_reward": 931.3098229247973, "episode": 80.0, "batch_reward": 0.579609185218811, "critic_loss": 1.357249815285206, "actor_loss": -75.77423793029786, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.408666133880615, "step": 80000}
{"episode_reward": 935.498083112009, "episode": 81.0, "batch_reward": 0.5837657203674317, "critic_loss": 1.3602250992655753, "actor_loss": -76.25071157836913, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.359269857406616, "step": 81000}
{"episode_reward": 898.7689589181397, "episode": 82.0, "batch_reward": 0.5880033812820912, "critic_loss": 1.3585214523673057, "actor_loss": -76.60657568359375, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.60460090637207, "step": 82000}
{"episode_reward": 918.4395589743248, "episode": 83.0, "batch_reward": 0.5905640927255154, "critic_loss": 1.3187686315774918, "actor_loss": -76.75074183654785, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.31587862968445, "step": 83000}
{"episode_reward": 898.7613882335881, "episode": 84.0, "batch_reward": 0.593916885226965, "critic_loss": 1.3337542536854743, "actor_loss": -77.57757905578613, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.8577778339386, "step": 84000}
{"episode_reward": 906.9164503869104, "episode": 85.0, "batch_reward": 0.5985632084608078, "critic_loss": 1.3520179656147957, "actor_loss": -77.52044372558593, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.467657327651978, "step": 85000}
{"episode_reward": 925.2134162172764, "episode": 86.0, "batch_reward": 0.6008001398444176, "critic_loss": 1.3360351682305336, "actor_loss": -78.23816400146484, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.238032817840576, "step": 86000}
{"episode_reward": 911.1298254176788, "episode": 87.0, "batch_reward": 0.6039067662060261, "critic_loss": 1.2893986482024193, "actor_loss": -78.51306202697754, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.91677188873291, "step": 87000}
{"episode_reward": 872.7571716676591, "episode": 88.0, "batch_reward": 0.6099555402398109, "critic_loss": 1.2806228675246238, "actor_loss": -78.73841226196289, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.56788396835327, "step": 88000}
{"episode_reward": 942.7810288886529, "episode": 89.0, "batch_reward": 0.6129972771704197, "critic_loss": 1.2411554960012436, "actor_loss": -79.37855731201172, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.09634041786194, "step": 89000}
{"episode_reward": 906.3558812883012, "episode": 90.0, "batch_reward": 0.6153758093714714, "critic_loss": 1.2550108119845391, "actor_loss": -79.92782298278809, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.790374279022217, "step": 90000}
{"episode_reward": 884.287386111048, "episode": 91.0, "batch_reward": 0.6181434182524681, "critic_loss": 1.1916937748789787, "actor_loss": -79.9691137084961, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 40.62618279457092, "step": 91000}
{"episode_reward": 929.461094953033, "episode": 92.0, "batch_reward": 0.6204160368442535, "critic_loss": 1.222957855284214, "actor_loss": -80.05973249816894, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.95198154449463, "step": 92000}
{"episode_reward": 852.9499290066713, "episode": 93.0, "batch_reward": 0.6262668700814247, "critic_loss": 1.2595148950219155, "actor_loss": -80.18049964904785, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.201454639434814, "step": 93000}
{"episode_reward": 931.6769658716622, "episode": 94.0, "batch_reward": 0.6297248314023018, "critic_loss": 1.213020058453083, "actor_loss": -80.46070541381836, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.735998153686523, "step": 94000}
{"episode_reward": 953.9994786800512, "episode": 95.0, "batch_reward": 0.6303420240283012, "critic_loss": 1.2172005091309548, "actor_loss": -81.12282255554199, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.92874503135681, "step": 95000}
{"episode_reward": 912.8717656940009, "episode": 96.0, "batch_reward": 0.6366075200438499, "critic_loss": 1.240170777320862, "actor_loss": -80.9799754486084, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.51388669013977, "step": 96000}
{"episode_reward": 930.9988159894114, "episode": 97.0, "batch_reward": 0.6381015456318855, "critic_loss": 1.2279054634571076, "actor_loss": -81.67842391967774, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.413196563720703, "step": 97000}
{"episode_reward": 929.0836431550562, "episode": 98.0, "batch_reward": 0.6420428772568703, "critic_loss": 1.1636736230254174, "actor_loss": -82.37541700744629, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.5208523273468, "step": 98000}
{"episode_reward": 932.2802847786282, "episode": 99.0, "batch_reward": 0.6433647931814194, "critic_loss": 1.2042375743389129, "actor_loss": -82.17606492614746, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.440505743026733, "step": 99000}
{"episode_reward": 927.4212598047511, "episode": 100.0, "batch_reward": 0.6473546746969223, "critic_loss": 1.1795330245494842, "actor_loss": -81.9333659362793, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.525774478912354, "step": 100000}
{"episode_reward": 949.9589801477392, "episode": 101.0, "batch_reward": 0.6496723762750626, "critic_loss": 1.1648116744160653, "actor_loss": -82.30418176269531, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 40.93679857254028, "step": 101000}
{"episode_reward": 944.5201609848594, "episode": 102.0, "batch_reward": 0.6518644233345985, "critic_loss": 1.1921794067621232, "actor_loss": -82.8189329071045, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.719255447387695, "step": 102000}
{"episode_reward": 890.1344656029669, "episode": 103.0, "batch_reward": 0.6556557067036629, "critic_loss": 1.1451879541277885, "actor_loss": -82.63040441894532, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.867330074310303, "step": 103000}
{"episode_reward": 978.130803301397, "episode": 104.0, "batch_reward": 0.659361259162426, "critic_loss": 1.1068212423026562, "actor_loss": -83.12014428710937, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.622734546661377, "step": 104000}
{"episode_reward": 936.451653609716, "episode": 105.0, "batch_reward": 0.6610139154195785, "critic_loss": 1.1228909487724303, "actor_loss": -83.08861218261718, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.892460584640503, "step": 105000}
{"episode_reward": 967.4041120185323, "episode": 106.0, "batch_reward": 0.6640966041088104, "critic_loss": 1.1001163389682769, "actor_loss": -83.5669097442627, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.99927806854248, "step": 106000}
{"episode_reward": 969.1918879921524, "episode": 107.0, "batch_reward": 0.6666810460090637, "critic_loss": 1.0786143031716346, "actor_loss": -83.79180645751953, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.465962886810303, "step": 107000}
{"episode_reward": 947.3059861376381, "episode": 108.0, "batch_reward": 0.6681663882732392, "critic_loss": 1.0607475979328156, "actor_loss": -83.91703614807129, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.903916597366333, "step": 108000}
{"episode_reward": 981.0604541637675, "episode": 109.0, "batch_reward": 0.6730295562744141, "critic_loss": 1.0493360751867293, "actor_loss": -84.32309744262696, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.78854513168335, "step": 109000}
{"episode_reward": 978.9164273485962, "episode": 110.0, "batch_reward": 0.6750870708823205, "critic_loss": 1.015426446557045, "actor_loss": -84.54113319396973, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.688742637634277, "step": 110000}
{"episode_reward": 885.8538994369599, "episode": 111.0, "batch_reward": 0.676493923485279, "critic_loss": 1.0133109780550003, "actor_loss": -84.32934512329102, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.09515595436096, "step": 111000}
{"episode_reward": 957.5594935184122, "episode": 112.0, "batch_reward": 0.6795880247950554, "critic_loss": 1.0399309923648834, "actor_loss": -84.53968803405762, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.447158575057983, "step": 112000}
{"episode_reward": 930.2683922747069, "episode": 113.0, "batch_reward": 0.6818673259615898, "critic_loss": 1.0126742366552353, "actor_loss": -84.52224693298339, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.95927381515503, "step": 113000}
{"episode_reward": 878.7039495530707, "episode": 114.0, "batch_reward": 0.6840286602377892, "critic_loss": 0.981351271033287, "actor_loss": -85.1048501586914, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.776952743530273, "step": 114000}
{"episode_reward": 953.3176845780168, "episode": 115.0, "batch_reward": 0.6846838539242744, "critic_loss": 0.9869890881776809, "actor_loss": -85.06918521118165, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.423171997070312, "step": 115000}
{"episode_reward": 950.3715295092825, "episode": 116.0, "batch_reward": 0.6872140239477158, "critic_loss": 1.0292376900613307, "actor_loss": -85.39616116333008, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.9069721698761, "step": 116000}
{"episode_reward": 876.3933987525079, "episode": 117.0, "batch_reward": 0.6905581932663918, "critic_loss": 1.0665718712210654, "actor_loss": -85.51118873596191, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.121008157730103, "step": 117000}
{"episode_reward": 915.7182353380175, "episode": 118.0, "batch_reward": 0.6910427773594856, "critic_loss": 0.996372795522213, "actor_loss": -85.27584742736816, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.437185049057007, "step": 118000}
{"episode_reward": 952.4619952673424, "episode": 119.0, "batch_reward": 0.6929576733112335, "critic_loss": 1.0305751550495625, "actor_loss": -85.48427850341797, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.71452522277832, "step": 119000}
{"episode_reward": 943.2325716407131, "episode": 120.0, "batch_reward": 0.6966726016402245, "critic_loss": 1.0394116132855415, "actor_loss": -85.92432667541505, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.349852085113525, "step": 120000}
{"episode_reward": 977.7810887404576, "episode": 121.0, "batch_reward": 0.6993923895955085, "critic_loss": 0.994173172622919, "actor_loss": -85.66731401062012, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.16424822807312, "step": 121000}
{"episode_reward": 905.8322340241438, "episode": 122.0, "batch_reward": 0.7017547156214714, "critic_loss": 0.9980508962273598, "actor_loss": -86.03913151550293, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.183168411254883, "step": 122000}
{"episode_reward": 943.068438331398, "episode": 123.0, "batch_reward": 0.701427911400795, "critic_loss": 0.9891441598534584, "actor_loss": -86.3784051361084, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.506040334701538, "step": 123000}
{"episode_reward": 944.9125978247494, "episode": 124.0, "batch_reward": 0.7041690226793289, "critic_loss": 1.0092365969717503, "actor_loss": -86.512724899292, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.71795129776001, "step": 124000}
{"episode_reward": 986.9812712261172, "episode": 125.0, "batch_reward": 0.707437082529068, "critic_loss": 1.0420845686793327, "actor_loss": -86.36230207824707, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.982675313949585, "step": 125000}
{"episode_reward": 962.3321669791579, "episode": 126.0, "batch_reward": 0.7067616518735885, "critic_loss": 0.9803336078524589, "actor_loss": -86.6363600616455, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.944054126739502, "step": 126000}
{"episode_reward": 952.9739291971034, "episode": 127.0, "batch_reward": 0.7101496183276177, "critic_loss": 0.9920006732940674, "actor_loss": -86.95937280273438, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.809433698654175, "step": 127000}
{"episode_reward": 949.8515581923008, "episode": 128.0, "batch_reward": 0.7121613324284554, "critic_loss": 0.9684028942883015, "actor_loss": -86.78074504089355, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.8866605758667, "step": 128000}
{"episode_reward": 985.4016459535353, "episode": 129.0, "batch_reward": 0.7142610013484955, "critic_loss": 1.0120670538544654, "actor_loss": -86.95989483642578, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.637718200683594, "step": 129000}
{"episode_reward": 956.197229445425, "episode": 130.0, "batch_reward": 0.7154590665698052, "critic_loss": 0.9761761107444763, "actor_loss": -87.23456089782715, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.604630947113037, "step": 130000}
{"episode_reward": 909.5875203269275, "episode": 131.0, "batch_reward": 0.716838525891304, "critic_loss": 0.974659843981266, "actor_loss": -86.85688204956055, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.10456323623657, "step": 131000}
{"episode_reward": 909.1945608308877, "episode": 132.0, "batch_reward": 0.7179557303190232, "critic_loss": 0.997298881649971, "actor_loss": -87.48148986816406, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.44321370124817, "step": 132000}
{"episode_reward": 952.1876095680228, "episode": 133.0, "batch_reward": 0.7180598630905152, "critic_loss": 0.9697477397620677, "actor_loss": -87.19509579467774, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.911244869232178, "step": 133000}
{"episode_reward": 949.602780498896, "episode": 134.0, "batch_reward": 0.7218527991771698, "critic_loss": 0.9508628282845021, "actor_loss": -87.54037240600586, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.79346752166748, "step": 134000}
{"episode_reward": 961.5363473541393, "episode": 135.0, "batch_reward": 0.7226535969972611, "critic_loss": 0.9403506886661053, "actor_loss": -87.61983164978027, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.64270567893982, "step": 135000}
{"episode_reward": 942.6733634051279, "episode": 136.0, "batch_reward": 0.7253632698655128, "critic_loss": 0.9771244776546955, "actor_loss": -87.78315592956542, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.990152835845947, "step": 136000}
{"episode_reward": 851.5431199446161, "episode": 137.0, "batch_reward": 0.7271495679616928, "critic_loss": 0.9820164000988006, "actor_loss": -88.09058224487305, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.59916639328003, "step": 137000}
{"episode_reward": 975.7785362298487, "episode": 138.0, "batch_reward": 0.7281189520359039, "critic_loss": 0.9435903871953487, "actor_loss": -87.90192724609375, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.84694814682007, "step": 138000}
{"episode_reward": 953.2504767335013, "episode": 139.0, "batch_reward": 0.7302193213105201, "critic_loss": 0.9544065978825093, "actor_loss": -87.99046673583985, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.915879249572754, "step": 139000}
{"episode_reward": 963.1935631618916, "episode": 140.0, "batch_reward": 0.7302055993676185, "critic_loss": 0.916207880526781, "actor_loss": -88.09083142089844, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.17301058769226, "step": 140000}
{"episode_reward": 966.3687408523278, "episode": 141.0, "batch_reward": 0.7329243999123574, "critic_loss": 0.9074190914928913, "actor_loss": -88.20254238891602, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.788732290267944, "step": 141000}
{"episode_reward": 964.3064938747389, "episode": 142.0, "batch_reward": 0.7345290343761444, "critic_loss": 0.8964917736053467, "actor_loss": -88.33270115661621, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.323787212371826, "step": 142000}
{"episode_reward": 946.2323924914001, "episode": 143.0, "batch_reward": 0.7358062117099762, "critic_loss": 0.9336351806819438, "actor_loss": -88.4033464050293, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.667457342147827, "step": 143000}
{"episode_reward": 929.8820744840272, "episode": 144.0, "batch_reward": 0.7389571454524994, "critic_loss": 0.9268091673254967, "actor_loss": -88.48555310058593, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.091607809066772, "step": 144000}
{"episode_reward": 925.445217868755, "episode": 145.0, "batch_reward": 0.7395176125764846, "critic_loss": 0.9342903937995434, "actor_loss": -88.5904970703125, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.328619718551636, "step": 145000}
{"episode_reward": 946.4270543884135, "episode": 146.0, "batch_reward": 0.7399936000108719, "critic_loss": 0.9074754550755024, "actor_loss": -88.64942889404297, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.81142520904541, "step": 146000}
{"episode_reward": 970.6524115187442, "episode": 147.0, "batch_reward": 0.7422910100221634, "critic_loss": 0.8939462339282036, "actor_loss": -88.69096725463868, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.976166486740112, "step": 147000}
{"episode_reward": 931.833172777227, "episode": 148.0, "batch_reward": 0.7438998119235039, "critic_loss": 0.9002252984046936, "actor_loss": -88.8407975769043, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.395630836486816, "step": 148000}
{"episode_reward": 967.0997892762509, "episode": 149.0, "batch_reward": 0.7429785106778145, "critic_loss": 0.9084213691055775, "actor_loss": -88.91640466308594, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.360071659088135, "step": 149000}
{"episode_reward": 945.1858385407975, "episode": 150.0, "batch_reward": 0.7474702844023704, "critic_loss": 0.9156949684023857, "actor_loss": -88.9294775390625, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "step": 150000}
