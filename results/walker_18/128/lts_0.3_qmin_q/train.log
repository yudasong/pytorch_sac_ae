{"episode_reward": 0.0, "episode": 1.0, "duration": 21.992039918899536, "step": 1000}
{"episode_reward": 27.46298806610516, "episode": 2.0, "duration": 1.857621431350708, "step": 2000}
{"episode_reward": 489.1100087318934, "episode": 3.0, "batch_reward": 0.2455955289699269, "critic_loss": 0.557861892799013, "actor_loss": -82.55128664319732, "actor_target_entropy": -6.0, "alpha_value": 0.002134017781850189, "duration": 65.55634593963623, "step": 3000}
{"episode_reward": 68.09291230179691, "episode": 4.0, "batch_reward": 0.17207735493034124, "critic_loss": 0.6873009657263756, "actor_loss": -82.55603839111328, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.174593925476074, "step": 4000}
{"episode_reward": 22.413621099304294, "episode": 5.0, "batch_reward": 0.14541510842740535, "critic_loss": 1.1296167938113213, "actor_loss": -81.30500297546386, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.865192890167236, "step": 5000}
{"episode_reward": 92.198162532623, "episode": 6.0, "batch_reward": 0.13406803558021785, "critic_loss": 1.2714282398223877, "actor_loss": -81.38075450134278, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.625208377838135, "step": 6000}
{"episode_reward": 54.40198725000505, "episode": 7.0, "batch_reward": 0.12238922584056854, "critic_loss": 1.1044626353383065, "actor_loss": -81.69817813110352, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.94013547897339, "step": 7000}
{"episode_reward": 98.44439944498471, "episode": 8.0, "batch_reward": 0.12166488466411829, "critic_loss": 1.0840860471129417, "actor_loss": -81.26503506469727, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.372289180755615, "step": 8000}
{"episode_reward": 121.206078098558, "episode": 9.0, "batch_reward": 0.13474281427264215, "critic_loss": 1.4386353996396064, "actor_loss": -81.31461070251464, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.838518857955933, "step": 9000}
{"episode_reward": 365.19300644936845, "episode": 10.0, "batch_reward": 0.15524420423805713, "critic_loss": 1.0939408945441247, "actor_loss": -81.30917259216308, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.30635976791382, "step": 10000}
{"episode_reward": 258.60187198816175, "episode": 11.0, "batch_reward": 0.16367620304226876, "critic_loss": 0.865985830783844, "actor_loss": -80.71925819396972, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 43.96362924575806, "step": 11000}
{"episode_reward": 327.2636591017556, "episode": 12.0, "batch_reward": 0.1836833550632, "critic_loss": 0.8100526621639729, "actor_loss": -80.63673014831544, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.879840850830078, "step": 12000}
{"episode_reward": 409.3352970802178, "episode": 13.0, "batch_reward": 0.20269071231782437, "critic_loss": 0.9322854206264019, "actor_loss": -80.3546089630127, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.026466131210327, "step": 13000}
{"episode_reward": 367.3001953108345, "episode": 14.0, "batch_reward": 0.21704231533408164, "critic_loss": 0.8646201518774033, "actor_loss": -80.07497682189941, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.67256808280945, "step": 14000}
{"episode_reward": 464.38011399463454, "episode": 15.0, "batch_reward": 0.22974817551672458, "critic_loss": 0.724249368429184, "actor_loss": -79.2543692626953, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.938289403915405, "step": 15000}
{"episode_reward": 225.00903961449075, "episode": 16.0, "batch_reward": 0.2348213972002268, "critic_loss": 0.6400267839431762, "actor_loss": -78.22240126037597, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.430341005325317, "step": 16000}
{"episode_reward": 507.0609399781982, "episode": 17.0, "batch_reward": 0.25029844300448895, "critic_loss": 0.6121122205257415, "actor_loss": -77.29711474609375, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.154513835906982, "step": 17000}
{"episode_reward": 471.3945630724566, "episode": 18.0, "batch_reward": 0.26344956147670745, "critic_loss": 0.6137248056232929, "actor_loss": -76.85263995361328, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.259979963302612, "step": 18000}
{"episode_reward": 474.58383829069237, "episode": 19.0, "batch_reward": 0.269837687805295, "critic_loss": 0.8201049177646637, "actor_loss": -75.96484567260742, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.6761372089386, "step": 19000}
{"episode_reward": 297.6724579045739, "episode": 20.0, "batch_reward": 0.2727177385985851, "critic_loss": 0.7804128994941711, "actor_loss": -75.51144580078125, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.578777074813843, "step": 20000}
{"episode_reward": 309.90784861125104, "episode": 21.0, "batch_reward": 0.27658050221204755, "critic_loss": 0.8044696329534053, "actor_loss": -74.75137249755859, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.945677042007446, "step": 21000}
{"episode_reward": 457.2887098408847, "episode": 22.0, "batch_reward": 0.27598941215872763, "critic_loss": 0.8837731017172337, "actor_loss": -74.75633996582032, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.509187936782837, "step": 22000}
{"episode_reward": 37.28746700977326, "episode": 23.0, "batch_reward": 0.27616352002322675, "critic_loss": 0.886225041359663, "actor_loss": -74.61772354125976, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.15736985206604, "step": 23000}
{"episode_reward": 429.8384675172732, "episode": 24.0, "batch_reward": 0.2749459518790245, "critic_loss": 0.8908081790208816, "actor_loss": -74.98074197387696, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.20321011543274, "step": 24000}
{"episode_reward": 120.26116611492725, "episode": 25.0, "batch_reward": 0.26482081523537637, "critic_loss": 0.863007348626852, "actor_loss": -75.89543971252441, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 25.386566400527954, "step": 25000}
{"episode_reward": 37.837532977913696, "episode": 26.0, "batch_reward": 0.25687641111016274, "critic_loss": 0.9273380576372147, "actor_loss": -76.20665687561035, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.35897922515869, "step": 26000}
{"episode_reward": 32.461685140299245, "episode": 27.0, "batch_reward": 0.24886985996365546, "critic_loss": 0.9578489403426648, "actor_loss": -76.67213549804687, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.284520626068115, "step": 27000}
{"episode_reward": 55.42559582969187, "episode": 28.0, "batch_reward": 0.24130294592678547, "critic_loss": 0.9873127064108849, "actor_loss": -77.09415339660644, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.832471132278442, "step": 28000}
{"episode_reward": 50.89491783060183, "episode": 29.0, "batch_reward": 0.23513948702812196, "critic_loss": 1.0120573806762696, "actor_loss": -77.13013069152832, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.77553677558899, "step": 29000}
{"episode_reward": 52.60355640759979, "episode": 30.0, "batch_reward": 0.2275553172081709, "critic_loss": 0.9903639040589333, "actor_loss": -77.39982316589355, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.840679168701172, "step": 30000}
{"episode_reward": 35.973769421689894, "episode": 31.0, "batch_reward": 0.22265411393344403, "critic_loss": 1.0196025856733322, "actor_loss": -77.5117027130127, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.133052825927734, "step": 31000}
{"episode_reward": 39.746472675083226, "episode": 32.0, "batch_reward": 0.2156532338708639, "critic_loss": 1.0445628920793533, "actor_loss": -77.18321324157715, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.97761845588684, "step": 32000}
{"episode_reward": 44.14762412240438, "episode": 33.0, "batch_reward": 0.2114705071002245, "critic_loss": 1.0019571849703788, "actor_loss": -77.03830448913574, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.99934458732605, "step": 33000}
{"episode_reward": 73.06158135175656, "episode": 34.0, "batch_reward": 0.20788304083049297, "critic_loss": 1.0379630206227302, "actor_loss": -76.84225366210937, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.280463695526123, "step": 34000}
{"episode_reward": 47.84782739962967, "episode": 35.0, "batch_reward": 0.202452195674181, "critic_loss": 0.9924848754107952, "actor_loss": -75.93842401123047, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.243109226226807, "step": 35000}
{"episode_reward": 37.181259015221926, "episode": 36.0, "batch_reward": 0.19830306068062784, "critic_loss": 0.9253288725316524, "actor_loss": -75.54765042114258, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.93821668624878, "step": 36000}
{"episode_reward": 54.43815355160129, "episode": 37.0, "batch_reward": 0.19423963309824466, "critic_loss": 0.8702752358615399, "actor_loss": -74.30549407958985, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.50081706047058, "step": 37000}
{"episode_reward": 87.35650564409404, "episode": 38.0, "batch_reward": 0.1912241385281086, "critic_loss": 0.8391309726536273, "actor_loss": -73.12568159484863, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.913339376449585, "step": 38000}
{"episode_reward": 38.326442770669104, "episode": 39.0, "batch_reward": 0.18904015484452247, "critic_loss": 0.9583166355192662, "actor_loss": -72.79219998168945, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.20341181755066, "step": 39000}
{"episode_reward": 167.80786531513795, "episode": 40.0, "batch_reward": 0.1871989481598139, "critic_loss": 1.0921652927994727, "actor_loss": -72.50468984985352, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.19023370742798, "step": 40000}
{"episode_reward": 128.5496122059171, "episode": 41.0, "batch_reward": 0.18868775400519372, "critic_loss": 1.2927306351065635, "actor_loss": -71.74720085144043, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 46.121795415878296, "step": 41000}
{"episode_reward": 184.45128672770417, "episode": 42.0, "batch_reward": 0.18644528482109307, "critic_loss": 1.3763164596557618, "actor_loss": -71.48559632110596, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.79966974258423, "step": 42000}
{"episode_reward": 234.15541520059384, "episode": 43.0, "batch_reward": 0.1908672521337867, "critic_loss": 1.334465665578842, "actor_loss": -71.411950881958, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.33514380455017, "step": 43000}
{"episode_reward": 345.5620196831652, "episode": 44.0, "batch_reward": 0.19115984039008618, "critic_loss": 1.1936836483478546, "actor_loss": -71.34782379150391, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.325273752212524, "step": 44000}
{"episode_reward": 161.18842028327924, "episode": 45.0, "batch_reward": 0.19066034677624702, "critic_loss": 1.0662505768537522, "actor_loss": -70.93995036315918, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.811237573623657, "step": 45000}
{"episode_reward": 105.68059570275113, "episode": 46.0, "batch_reward": 0.18853037065267564, "critic_loss": 0.933613921314478, "actor_loss": -70.95750378417969, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.68563485145569, "step": 46000}
{"episode_reward": 99.16913817468684, "episode": 47.0, "batch_reward": 0.18877207180857658, "critic_loss": 0.8367462164461613, "actor_loss": -71.65914907836914, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.547044038772583, "step": 47000}
{"episode_reward": 194.87226191398372, "episode": 48.0, "batch_reward": 0.19247441597282886, "critic_loss": 0.720051058024168, "actor_loss": -71.02464057159423, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.683587074279785, "step": 48000}
{"episode_reward": 632.1095374263763, "episode": 49.0, "batch_reward": 0.20116255223751067, "critic_loss": 0.6550552558600903, "actor_loss": -70.67919709014893, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.694701194763184, "step": 49000}
{"episode_reward": 552.2892922172767, "episode": 50.0, "batch_reward": 0.206682985663414, "critic_loss": 0.6313834674060345, "actor_loss": -70.01621472167969, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.883601903915405, "step": 50000}
{"episode_reward": 552.5477700936947, "episode": 51.0, "batch_reward": 0.21465764072537422, "critic_loss": 0.615022581577301, "actor_loss": -68.93255255889892, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.15661692619324, "step": 51000}
{"episode_reward": 475.8096715595722, "episode": 52.0, "batch_reward": 0.2204285020083189, "critic_loss": 0.5890536679029464, "actor_loss": -68.23640728759766, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.432289361953735, "step": 52000}
{"episode_reward": 593.8732651895562, "episode": 53.0, "batch_reward": 0.22539172910153865, "critic_loss": 0.5835198858082294, "actor_loss": -68.30059503936768, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.78772759437561, "step": 53000}
{"episode_reward": 402.44287584051784, "episode": 54.0, "batch_reward": 0.23043538337945937, "critic_loss": 0.5883585504591465, "actor_loss": -67.36888929748535, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.915974378585815, "step": 54000}
{"episode_reward": 595.1092841997569, "episode": 55.0, "batch_reward": 0.2364853444993496, "critic_loss": 0.6160134334862232, "actor_loss": -66.99569724273681, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.548518180847168, "step": 55000}
{"episode_reward": 597.388567074318, "episode": 56.0, "batch_reward": 0.24189660599827767, "critic_loss": 0.6210125097036362, "actor_loss": -66.7804811782837, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.58529567718506, "step": 56000}
{"episode_reward": 500.7191640830345, "episode": 57.0, "batch_reward": 0.2465365472882986, "critic_loss": 0.611531102180481, "actor_loss": -66.09017182159424, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.626068353652954, "step": 57000}
{"episode_reward": 622.775073623904, "episode": 58.0, "batch_reward": 0.2537491217404604, "critic_loss": 0.6366677833795548, "actor_loss": -66.44273612976075, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.255725622177124, "step": 58000}
{"episode_reward": 643.6197193277306, "episode": 59.0, "batch_reward": 0.26011772301793096, "critic_loss": 0.6905984397828578, "actor_loss": -66.11807902526856, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.467273712158203, "step": 59000}
{"episode_reward": 603.4628742648757, "episode": 60.0, "batch_reward": 0.26527075926959515, "critic_loss": 0.6952350167036057, "actor_loss": -64.88835668945312, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.820072889328003, "step": 60000}
{"episode_reward": 644.0058976341983, "episode": 61.0, "batch_reward": 0.27140897400677205, "critic_loss": 0.7531988417208195, "actor_loss": -65.49663388061524, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.4088020324707, "step": 61000}
{"episode_reward": 619.0216653920007, "episode": 62.0, "batch_reward": 0.27968323189020156, "critic_loss": 0.7400556311607361, "actor_loss": -64.66467224884033, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.640849590301514, "step": 62000}
{"episode_reward": 675.2766938017418, "episode": 63.0, "batch_reward": 0.28537355798482894, "critic_loss": 0.7234535788595676, "actor_loss": -65.7660493774414, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.04097604751587, "step": 63000}
{"episode_reward": 670.2228466124025, "episode": 64.0, "batch_reward": 0.2915935694873333, "critic_loss": 0.7262471297979355, "actor_loss": -66.57657397460937, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.581570863723755, "step": 64000}
{"episode_reward": 665.6069381841303, "episode": 65.0, "batch_reward": 0.2947890417724848, "critic_loss": 0.7608263457417488, "actor_loss": -65.71176766204835, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.07351040840149, "step": 65000}
{"episode_reward": 541.4162849338504, "episode": 66.0, "batch_reward": 0.29883980377018454, "critic_loss": 0.7589320499300957, "actor_loss": -64.8952120437622, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.413753747940063, "step": 66000}
{"episode_reward": 722.3311259487086, "episode": 67.0, "batch_reward": 0.30721851930022237, "critic_loss": 0.7455915463864803, "actor_loss": -64.95889911651611, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.512557983398438, "step": 67000}
{"episode_reward": 695.6689665371281, "episode": 68.0, "batch_reward": 0.31316918216645717, "critic_loss": 0.7553446705639363, "actor_loss": -64.94933597564697, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.858612537384033, "step": 68000}
{"episode_reward": 694.0167911132895, "episode": 69.0, "batch_reward": 0.3189914599061012, "critic_loss": 0.7853442821800709, "actor_loss": -64.49309283447266, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.208374977111816, "step": 69000}
{"episode_reward": 665.9302223638263, "episode": 70.0, "batch_reward": 0.32386110235750676, "critic_loss": 0.8239500119090081, "actor_loss": -63.56188599395752, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.47151017189026, "step": 70000}
{"episode_reward": 639.3112221178029, "episode": 71.0, "batch_reward": 0.32862266834080217, "critic_loss": 0.8961696856617928, "actor_loss": -64.00689585113525, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 45.98066735267639, "step": 71000}
{"episode_reward": 632.3867011116905, "episode": 72.0, "batch_reward": 0.3325298478603363, "critic_loss": 0.9396076780557633, "actor_loss": -63.1553014831543, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.036171674728394, "step": 72000}
{"episode_reward": 680.9189960135207, "episode": 73.0, "batch_reward": 0.33725284576416015, "critic_loss": 0.9204976491928101, "actor_loss": -64.58218851470947, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.970131397247314, "step": 73000}
{"episode_reward": 738.0320261519948, "episode": 74.0, "batch_reward": 0.3408673786520958, "critic_loss": 0.9532722090184689, "actor_loss": -64.19375204467774, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.035879850387573, "step": 74000}
{"episode_reward": 554.376587974703, "episode": 75.0, "batch_reward": 0.3465781166553497, "critic_loss": 0.9381549297571182, "actor_loss": -64.92317756652832, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.698323488235474, "step": 75000}
{"episode_reward": 702.2873528928363, "episode": 76.0, "batch_reward": 0.3498841658234596, "critic_loss": 0.9250016383230686, "actor_loss": -65.45386923217774, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.6840877532959, "step": 76000}
{"episode_reward": 725.4307446284612, "episode": 77.0, "batch_reward": 0.35577464088797567, "critic_loss": 0.9340840664505958, "actor_loss": -65.28806922912598, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.704467058181763, "step": 77000}
{"episode_reward": 582.9598050425691, "episode": 78.0, "batch_reward": 0.3583137822449207, "critic_loss": 0.938914580464363, "actor_loss": -64.49889057159425, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.691667079925537, "step": 78000}
{"episode_reward": 756.2207053795175, "episode": 79.0, "batch_reward": 0.36581518480181696, "critic_loss": 0.9327623476684094, "actor_loss": -65.65529585266113, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.692354679107666, "step": 79000}
{"episode_reward": 722.7218977391079, "episode": 80.0, "batch_reward": 0.36790286272764205, "critic_loss": 0.9511839788556099, "actor_loss": -65.64281517791748, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.540642738342285, "step": 80000}
{"episode_reward": 583.5699320765484, "episode": 81.0, "batch_reward": 0.3709723160266876, "critic_loss": 0.9990796506404876, "actor_loss": -65.51999401092529, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 46.33171057701111, "step": 81000}
{"episode_reward": 745.2936808704065, "episode": 82.0, "batch_reward": 0.37531236445903776, "critic_loss": 0.9530861644148827, "actor_loss": -66.5560687713623, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.934390783309937, "step": 82000}
{"episode_reward": 736.1829605744116, "episode": 83.0, "batch_reward": 0.380860798150301, "critic_loss": 0.9693144015967846, "actor_loss": -64.71590451812745, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.963979482650757, "step": 83000}
{"episode_reward": 559.7670816536745, "episode": 84.0, "batch_reward": 0.3800371261835098, "critic_loss": 0.961269908875227, "actor_loss": -65.8372043762207, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.352307558059692, "step": 84000}
{"episode_reward": 725.7635423269522, "episode": 85.0, "batch_reward": 0.38709391161799434, "critic_loss": 0.9491716759502887, "actor_loss": -65.83482987213135, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.523029088974, "step": 85000}
{"episode_reward": 792.0969078135454, "episode": 86.0, "batch_reward": 0.3895001075565815, "critic_loss": 0.937806005448103, "actor_loss": -66.46946670532226, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.142518520355225, "step": 86000}
{"episode_reward": 786.5398062789493, "episode": 87.0, "batch_reward": 0.39434142750501633, "critic_loss": 0.939210463732481, "actor_loss": -65.75847229003907, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.335013151168823, "step": 87000}
{"episode_reward": 631.5981239576697, "episode": 88.0, "batch_reward": 0.3971747072339058, "critic_loss": 0.9546042855978012, "actor_loss": -65.88776979827881, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.472407579421997, "step": 88000}
{"episode_reward": 735.4383726949429, "episode": 89.0, "batch_reward": 0.40193821090459825, "critic_loss": 0.9688210866451263, "actor_loss": -66.21304796600342, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.9225811958313, "step": 89000}
{"episode_reward": 769.5038315227772, "episode": 90.0, "batch_reward": 0.40542987355589866, "critic_loss": 1.0051784269213677, "actor_loss": -67.10859660339355, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.94384503364563, "step": 90000}
{"episode_reward": 736.8445093741212, "episode": 91.0, "batch_reward": 0.41034794092178345, "critic_loss": 0.9574288034439087, "actor_loss": -67.20943434906006, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 43.73720932006836, "step": 91000}
{"episode_reward": 825.6845584248758, "episode": 92.0, "batch_reward": 0.4128031799197197, "critic_loss": 0.9743832856416702, "actor_loss": -66.1801915512085, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.187572479248047, "step": 92000}
{"episode_reward": 782.7966106896081, "episode": 93.0, "batch_reward": 0.4178764152228832, "critic_loss": 1.0135220332443715, "actor_loss": -67.16117177581788, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.918302059173584, "step": 93000}
{"episode_reward": 683.2575316051527, "episode": 94.0, "batch_reward": 0.42338627475500107, "critic_loss": 1.005593331694603, "actor_loss": -66.78034618377686, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.54179620742798, "step": 94000}
{"episode_reward": 771.4023569507794, "episode": 95.0, "batch_reward": 0.4226395194232464, "critic_loss": 1.0068465436697007, "actor_loss": -68.13329000091552, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.770135402679443, "step": 95000}
{"episode_reward": 414.6739512235136, "episode": 96.0, "batch_reward": 0.4254679026901722, "critic_loss": 0.9865508153736592, "actor_loss": -67.94378485870361, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.16077160835266, "step": 96000}
{"episode_reward": 796.5940018570847, "episode": 97.0, "batch_reward": 0.4284033630490303, "critic_loss": 0.9798916270732879, "actor_loss": -69.38194540405273, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.40927743911743, "step": 97000}
{"episode_reward": 773.3679506186081, "episode": 98.0, "batch_reward": 0.433246179163456, "critic_loss": 0.9660432435274124, "actor_loss": -70.14739582824707, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.456775426864624, "step": 98000}
{"episode_reward": 679.4713023390428, "episode": 99.0, "batch_reward": 0.4348670125901699, "critic_loss": 0.9754578386545181, "actor_loss": -69.16234734344482, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.571590423583984, "step": 99000}
{"episode_reward": 790.4548646380434, "episode": 100.0, "batch_reward": 0.4361473562717438, "critic_loss": 0.9613164420723915, "actor_loss": -68.94565007781982, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.925068616867065, "step": 100000}
{"episode_reward": 402.1124081811571, "episode": 101.0, "batch_reward": 0.43729311257600784, "critic_loss": 0.9228769736886024, "actor_loss": -69.52515164184571, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 43.11887216567993, "step": 101000}
{"episode_reward": 751.887362316097, "episode": 102.0, "batch_reward": 0.4418426094353199, "critic_loss": 0.9169519343674183, "actor_loss": -70.01707497406007, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.684021472930908, "step": 102000}
{"episode_reward": 762.0144753058943, "episode": 103.0, "batch_reward": 0.44302539744973185, "critic_loss": 0.9126272948384285, "actor_loss": -69.62658141326904, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.633268117904663, "step": 103000}
{"episode_reward": 783.2245031783305, "episode": 104.0, "batch_reward": 0.44835704275965693, "critic_loss": 0.9230557515621185, "actor_loss": -70.94260355377197, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.49957823753357, "step": 104000}
{"episode_reward": 815.2891096031599, "episode": 105.0, "batch_reward": 0.4502643995583057, "critic_loss": 0.9028804860115052, "actor_loss": -69.78830373382569, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.81889533996582, "step": 105000}
{"episode_reward": 857.8853357405111, "episode": 106.0, "batch_reward": 0.45450398755073546, "critic_loss": 0.9284248902201653, "actor_loss": -70.75012665557861, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.147076845169067, "step": 106000}
{"episode_reward": 809.5921289867371, "episode": 107.0, "batch_reward": 0.4571437866687775, "critic_loss": 0.8942375189960002, "actor_loss": -71.08772773742676, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.112072944641113, "step": 107000}
{"episode_reward": 860.3630021567106, "episode": 108.0, "batch_reward": 0.46038744094967843, "critic_loss": 0.8779175764322281, "actor_loss": -71.32403943634033, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.396570682525635, "step": 108000}
{"episode_reward": 876.8645500857943, "episode": 109.0, "batch_reward": 0.4653722785115242, "critic_loss": 0.8886062902212143, "actor_loss": -72.52983668518067, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.24231195449829, "step": 109000}
{"episode_reward": 886.0507788459396, "episode": 110.0, "batch_reward": 0.4693932005763054, "critic_loss": 0.8895580744147301, "actor_loss": -72.42352689361573, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.35896921157837, "step": 110000}
{"episode_reward": 814.0409545158175, "episode": 111.0, "batch_reward": 0.47217196083068846, "critic_loss": 0.8674488922953606, "actor_loss": -71.72503383636474, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 44.20932602882385, "step": 111000}
{"episode_reward": 841.8770712617263, "episode": 112.0, "batch_reward": 0.4766680172979832, "critic_loss": 0.8930294851958752, "actor_loss": -71.79408934783936, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.242449522018433, "step": 112000}
{"episode_reward": 755.4127185197053, "episode": 113.0, "batch_reward": 0.4804942435026169, "critic_loss": 0.916211443066597, "actor_loss": -71.44929873657226, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.008589267730713, "step": 113000}
{"episode_reward": 826.8851716777434, "episode": 114.0, "batch_reward": 0.4822339701354504, "critic_loss": 0.8919407080113888, "actor_loss": -73.20351452636719, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.074812412261963, "step": 114000}
{"episode_reward": 887.8805974104399, "episode": 115.0, "batch_reward": 0.4833565467298031, "critic_loss": 0.9029846352040768, "actor_loss": -73.22936064147949, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.309245586395264, "step": 115000}
{"episode_reward": 798.28682051579, "episode": 116.0, "batch_reward": 0.4865934611558914, "critic_loss": 0.8768892980217934, "actor_loss": -73.63129551696777, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.349998235702515, "step": 116000}
{"episode_reward": 856.4843295159482, "episode": 117.0, "batch_reward": 0.4922453276515007, "critic_loss": 0.8711893283724785, "actor_loss": -73.9946081237793, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.79018259048462, "step": 117000}
{"episode_reward": 881.1652453473513, "episode": 118.0, "batch_reward": 0.4949544877409935, "critic_loss": 0.8744435342848301, "actor_loss": -73.2935341796875, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.65264868736267, "step": 118000}
{"episode_reward": 883.8326885766346, "episode": 119.0, "batch_reward": 0.4977461053133011, "critic_loss": 0.8936216559410095, "actor_loss": -74.17176597595216, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.624494552612305, "step": 119000}
{"episode_reward": 643.2599482503315, "episode": 120.0, "batch_reward": 0.49947325894236566, "critic_loss": 0.8934324323534966, "actor_loss": -74.80427320861817, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 25.500669479370117, "step": 120000}
{"episode_reward": 908.1830309678576, "episode": 121.0, "batch_reward": 0.5030735410749912, "critic_loss": 0.8595886363387107, "actor_loss": -74.47517808532714, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.99953866004944, "step": 121000}
{"episode_reward": 913.2722223874393, "episode": 122.0, "batch_reward": 0.5066918767094613, "critic_loss": 0.8733330189883709, "actor_loss": -75.93104585266113, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.5344021320343, "step": 122000}
{"episode_reward": 850.5944541032442, "episode": 123.0, "batch_reward": 0.5071686550974845, "critic_loss": 0.9123949132561684, "actor_loss": -76.87639721679687, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.08287787437439, "step": 123000}
{"episode_reward": 857.2012113483858, "episode": 124.0, "batch_reward": 0.5115354636609555, "critic_loss": 0.9269893881380558, "actor_loss": -76.62418501281738, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.97859239578247, "step": 124000}
{"episode_reward": 914.8529660618848, "episode": 125.0, "batch_reward": 0.5144022437036038, "critic_loss": 0.9198050902783871, "actor_loss": -75.38278271484376, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.484646320343018, "step": 125000}
{"episode_reward": 916.669031134597, "episode": 126.0, "batch_reward": 0.5180383994281292, "critic_loss": 0.9121060107946396, "actor_loss": -75.96890837097168, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.48729109764099, "step": 126000}
{"episode_reward": 905.5341454209371, "episode": 127.0, "batch_reward": 0.5202910811007023, "critic_loss": 0.9421398717761039, "actor_loss": -77.02053053283691, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.627368450164795, "step": 127000}
{"episode_reward": 897.9369909009599, "episode": 128.0, "batch_reward": 0.5246545464098453, "critic_loss": 0.9413204997181892, "actor_loss": -76.28391889953613, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.566177129745483, "step": 128000}
{"episode_reward": 913.8257294808725, "episode": 129.0, "batch_reward": 0.5281329101324082, "critic_loss": 0.9221615899503232, "actor_loss": -77.17905885314941, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.092182874679565, "step": 129000}
{"episode_reward": 929.3153153828027, "episode": 130.0, "batch_reward": 0.5303164402246475, "critic_loss": 0.8982996988892555, "actor_loss": -77.78120487976074, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.67278790473938, "step": 130000}
{"episode_reward": 850.5033506446041, "episode": 131.0, "batch_reward": 0.5327042341530323, "critic_loss": 0.9300202014148236, "actor_loss": -76.81611674499511, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.4699604511261, "step": 131000}
{"episode_reward": 873.6242260961777, "episode": 132.0, "batch_reward": 0.5349172419011593, "critic_loss": 0.9437209519147873, "actor_loss": -77.90507067871094, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.664612770080566, "step": 132000}
{"episode_reward": 927.163955870615, "episode": 133.0, "batch_reward": 0.5370552382171154, "critic_loss": 0.916486053943634, "actor_loss": -77.85952571105958, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.246859073638916, "step": 133000}
{"episode_reward": 860.4219505910692, "episode": 134.0, "batch_reward": 0.5406312855482102, "critic_loss": 0.9109276953935623, "actor_loss": -78.53664837646484, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.136876344680786, "step": 134000}
{"episode_reward": 930.4123519148241, "episode": 135.0, "batch_reward": 0.5431129612326622, "critic_loss": 0.8940645243823528, "actor_loss": -79.00798118591308, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.25776481628418, "step": 135000}
{"episode_reward": 883.2464894972828, "episode": 136.0, "batch_reward": 0.545148966729641, "critic_loss": 0.8771368563473224, "actor_loss": -78.86314860534668, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.15177845954895, "step": 136000}
{"episode_reward": 855.386333814667, "episode": 137.0, "batch_reward": 0.5496537954807281, "critic_loss": 0.8669056208729744, "actor_loss": -79.54016139221191, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.7316255569458, "step": 137000}
{"episode_reward": 949.3027417665514, "episode": 138.0, "batch_reward": 0.551108799368143, "critic_loss": 0.8619650759100914, "actor_loss": -79.19183966064453, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.197943687438965, "step": 138000}
{"episode_reward": 895.2089563793046, "episode": 139.0, "batch_reward": 0.554437610000372, "critic_loss": 0.8751202055513859, "actor_loss": -79.3765333404541, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.748851537704468, "step": 139000}
{"episode_reward": 858.9580680851263, "episode": 140.0, "batch_reward": 0.5552457750141621, "critic_loss": 0.8776165396869182, "actor_loss": -79.84034727478027, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.576847076416016, "step": 140000}
{"episode_reward": 912.0613806387228, "episode": 141.0, "batch_reward": 0.5581014595627785, "critic_loss": 0.8806577956080437, "actor_loss": -80.35940455627441, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.228336334228516, "step": 141000}
{"episode_reward": 921.4189408317441, "episode": 142.0, "batch_reward": 0.5614642334282398, "critic_loss": 0.8685781507492065, "actor_loss": -80.37211682128907, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.61041831970215, "step": 142000}
{"episode_reward": 893.1767095684222, "episode": 143.0, "batch_reward": 0.5637282590270043, "critic_loss": 0.9040687784850597, "actor_loss": -80.5690691986084, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.419790744781494, "step": 143000}
{"episode_reward": 921.4552121391056, "episode": 144.0, "batch_reward": 0.5671377275288105, "critic_loss": 0.8825400534570217, "actor_loss": -80.66196412658691, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.69619917869568, "step": 144000}
{"episode_reward": 896.1953170188793, "episode": 145.0, "batch_reward": 0.569588884562254, "critic_loss": 0.902693523466587, "actor_loss": -81.11772750854492, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.136508464813232, "step": 145000}
{"episode_reward": 882.2703144379599, "episode": 146.0, "batch_reward": 0.5700162796676159, "critic_loss": 0.8608294687569141, "actor_loss": -81.01561766052247, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.573198556900024, "step": 146000}
{"episode_reward": 939.9304846003123, "episode": 147.0, "batch_reward": 0.5728037790954112, "critic_loss": 0.8858772273659706, "actor_loss": -81.19935429382325, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.328853845596313, "step": 147000}
{"episode_reward": 922.9955259369721, "episode": 148.0, "batch_reward": 0.5747746218442917, "critic_loss": 0.9060785993933678, "actor_loss": -81.26657777404785, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.81558394432068, "step": 148000}
{"episode_reward": 938.3242537363672, "episode": 149.0, "batch_reward": 0.5775682256221771, "critic_loss": 0.9131734105348587, "actor_loss": -81.27393566894531, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.92806363105774, "step": 149000}
{"episode_reward": 893.8787457322431, "episode": 150.0, "batch_reward": 0.5797924588918686, "critic_loss": 0.867045737862587, "actor_loss": -81.27729948425294, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "step": 150000}
