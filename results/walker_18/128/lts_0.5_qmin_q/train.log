{"episode_reward": 0.0, "episode": 1.0, "duration": 21.852447986602783, "step": 1000}
{"episode_reward": 27.46298806610516, "episode": 2.0, "duration": 1.9494540691375732, "step": 2000}
{"episode_reward": 489.1100087318934, "episode": 3.0, "batch_reward": 0.24403197271858068, "critic_loss": 0.465805194643427, "actor_loss": -81.92220904169774, "actor_target_entropy": -6.0, "alpha_value": 0.002134017781850189, "duration": 66.54142546653748, "step": 3000}
{"episode_reward": 37.395866762599766, "episode": 4.0, "batch_reward": 0.1664095949009061, "critic_loss": 0.6943572361469269, "actor_loss": -79.52445986938477, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.496665239334106, "step": 4000}
{"episode_reward": 59.03580167883331, "episode": 5.0, "batch_reward": 0.14257939394563438, "critic_loss": 0.6664589053690434, "actor_loss": -78.97339869689941, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.90908670425415, "step": 5000}
{"episode_reward": 41.001370941718505, "episode": 6.0, "batch_reward": 0.12146802593022585, "critic_loss": 0.6091601538658142, "actor_loss": -79.57779124450684, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.090856313705444, "step": 6000}
{"episode_reward": 24.283151900293905, "episode": 7.0, "batch_reward": 0.1146181810349226, "critic_loss": 0.8136509976387024, "actor_loss": -79.41276129150391, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.887325763702393, "step": 7000}
{"episode_reward": 103.66639496378156, "episode": 8.0, "batch_reward": 0.11593035165965557, "critic_loss": 0.7707733046412468, "actor_loss": -79.01491996765137, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.536715030670166, "step": 8000}
{"episode_reward": 120.13699276087993, "episode": 9.0, "batch_reward": 0.12779246509075165, "critic_loss": 1.0462067584097385, "actor_loss": -79.00415307617187, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.45384907722473, "step": 9000}
{"episode_reward": 338.12838909255754, "episode": 10.0, "batch_reward": 0.1557657521441579, "critic_loss": 0.969157404601574, "actor_loss": -79.17702456665039, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.825732707977295, "step": 10000}
{"episode_reward": 395.6596783358611, "episode": 11.0, "batch_reward": 0.1675248504653573, "critic_loss": 0.8103121223449707, "actor_loss": -77.9286964263916, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 43.23902106285095, "step": 11000}
{"episode_reward": 197.84456722271221, "episode": 12.0, "batch_reward": 0.1733129049614072, "critic_loss": 0.9478261407911778, "actor_loss": -77.56662998962402, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.716073274612427, "step": 12000}
{"episode_reward": 332.1417113177279, "episode": 13.0, "batch_reward": 0.18794928774237632, "critic_loss": 1.0763285602927208, "actor_loss": -76.96602821350098, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.643301725387573, "step": 13000}
{"episode_reward": 412.0995022591595, "episode": 14.0, "batch_reward": 0.1933161821961403, "critic_loss": 1.2999188644886017, "actor_loss": -76.84155172729493, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.00523281097412, "step": 14000}
{"episode_reward": 74.67676953698677, "episode": 15.0, "batch_reward": 0.18886859242618084, "critic_loss": 1.2267412451505662, "actor_loss": -76.81145715332032, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.049657821655273, "step": 15000}
{"episode_reward": 109.85628171641926, "episode": 16.0, "batch_reward": 0.17896854459494352, "critic_loss": 1.196658746600151, "actor_loss": -77.56614476013183, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.286609172821045, "step": 16000}
{"episode_reward": 45.941446180278945, "episode": 17.0, "batch_reward": 0.1845124790072441, "critic_loss": 1.089824275970459, "actor_loss": -77.4629886932373, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.18736982345581, "step": 17000}
{"episode_reward": 485.39572804058525, "episode": 18.0, "batch_reward": 0.20223918874561786, "critic_loss": 1.024368763923645, "actor_loss": -76.92702508544922, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.998030424118042, "step": 18000}
{"episode_reward": 526.6538510454628, "episode": 19.0, "batch_reward": 0.20683990056812762, "critic_loss": 1.0730460077822208, "actor_loss": -75.87776638793946, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.230454921722412, "step": 19000}
{"episode_reward": 25.903735325401993, "episode": 20.0, "batch_reward": 0.20542074947059155, "critic_loss": 1.268362246632576, "actor_loss": -75.71097802734376, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.489888191223145, "step": 20000}
{"episode_reward": 213.9005390321144, "episode": 21.0, "batch_reward": 0.20212344974279403, "critic_loss": 1.35162548494339, "actor_loss": -74.15559316253662, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.44729709625244, "step": 21000}
{"episode_reward": 106.25746618842152, "episode": 22.0, "batch_reward": 0.19413128370791674, "critic_loss": 1.6993315717577935, "actor_loss": -74.53805899810791, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.35619306564331, "step": 22000}
{"episode_reward": 23.73906039611167, "episode": 23.0, "batch_reward": 0.1876755998134613, "critic_loss": 2.0233481090664864, "actor_loss": -74.46131331634521, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.219061613082886, "step": 23000}
{"episode_reward": 53.16582499974202, "episode": 24.0, "batch_reward": 0.17979853353649378, "critic_loss": 2.515174937725067, "actor_loss": -74.87807804107666, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.510653972625732, "step": 24000}
{"episode_reward": 19.911399122800223, "episode": 25.0, "batch_reward": 0.17478446231037378, "critic_loss": 2.3830029501914978, "actor_loss": -75.89947564697266, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.546741724014282, "step": 25000}
{"episode_reward": 18.908998043995734, "episode": 26.0, "batch_reward": 0.16742474741488694, "critic_loss": 2.214924560546875, "actor_loss": -75.57949641418458, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.757261514663696, "step": 26000}
{"episode_reward": 15.948244149872693, "episode": 27.0, "batch_reward": 0.16773080074042082, "critic_loss": 2.8509840075969697, "actor_loss": -75.55976905822754, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.04847288131714, "step": 27000}
{"episode_reward": 259.0114904065227, "episode": 28.0, "batch_reward": 0.16624191612750291, "critic_loss": 2.7245410635471345, "actor_loss": -75.62372117614746, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.688926935195923, "step": 28000}
{"episode_reward": 21.903207306741496, "episode": 29.0, "batch_reward": 0.1614132408350706, "critic_loss": 2.920130095720291, "actor_loss": -75.55393753051757, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.82671046257019, "step": 29000}
{"episode_reward": 23.446003403019912, "episode": 30.0, "batch_reward": 0.15603655204176903, "critic_loss": 3.4776021054983137, "actor_loss": -75.51703282165528, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.105647563934326, "step": 30000}
{"episode_reward": 28.88441532763889, "episode": 31.0, "batch_reward": 0.1531585275232792, "critic_loss": 4.059947884678841, "actor_loss": -76.25494842529297, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 44.26583743095398, "step": 31000}
{"episode_reward": 85.00219180523065, "episode": 32.0, "batch_reward": 0.15138702090829612, "critic_loss": 4.38492397904396, "actor_loss": -75.56399465942383, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.642369747161865, "step": 32000}
{"episode_reward": 134.24940811611705, "episode": 33.0, "batch_reward": 0.1504015259295702, "critic_loss": 4.5204990785121915, "actor_loss": -75.73350367736816, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.19171380996704, "step": 33000}
{"episode_reward": 94.11584818521976, "episode": 34.0, "batch_reward": 0.14878633294254542, "critic_loss": 4.166806179523468, "actor_loss": -75.5407339630127, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.17085099220276, "step": 34000}
{"episode_reward": 93.90974220101302, "episode": 35.0, "batch_reward": 0.14750539485365152, "critic_loss": 3.4995949931144716, "actor_loss": -75.30241529846191, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.930498123168945, "step": 35000}
{"episode_reward": 66.7814914410634, "episode": 36.0, "batch_reward": 0.144461542673409, "critic_loss": 3.110166100025177, "actor_loss": -75.68125358581543, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.802184104919434, "step": 36000}
{"episode_reward": 55.43012094614748, "episode": 37.0, "batch_reward": 0.14257705799490214, "critic_loss": 2.856897490501404, "actor_loss": -75.50577532958984, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.179340600967407, "step": 37000}
{"episode_reward": 52.431794799720514, "episode": 38.0, "batch_reward": 0.1397031711861491, "critic_loss": 2.6221512439250945, "actor_loss": -75.43752624511718, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.17857336997986, "step": 38000}
{"episode_reward": 56.51981154539843, "episode": 39.0, "batch_reward": 0.1381533775627613, "critic_loss": 2.8217315193414687, "actor_loss": -75.82131669616699, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.65129327774048, "step": 39000}
{"episode_reward": 70.42794960571118, "episode": 40.0, "batch_reward": 0.1380714816376567, "critic_loss": 3.715187894463539, "actor_loss": -76.15289849853515, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.22281503677368, "step": 40000}
{"episode_reward": 133.5889148322612, "episode": 41.0, "batch_reward": 0.13708442378789187, "critic_loss": 4.822563532710076, "actor_loss": -76.46441697692872, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.68011426925659, "step": 41000}
{"episode_reward": 122.85737162094615, "episode": 42.0, "batch_reward": 0.13970948963612317, "critic_loss": 5.2941678359508515, "actor_loss": -77.08381118774415, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.76170778274536, "step": 42000}
{"episode_reward": 362.3231462568757, "episode": 43.0, "batch_reward": 0.14278914408385754, "critic_loss": 5.3839080543518065, "actor_loss": -77.91762455749512, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.7858407497406, "step": 43000}
{"episode_reward": 247.419742401212, "episode": 44.0, "batch_reward": 0.14697670921683312, "critic_loss": 5.736025598049164, "actor_loss": -78.71390184020996, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.730677366256714, "step": 44000}
{"episode_reward": 255.91736285301744, "episode": 45.0, "batch_reward": 0.145897453635931, "critic_loss": 5.74864312505722, "actor_loss": -79.85557139587402, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.467077255249023, "step": 45000}
{"episode_reward": 69.139159643275, "episode": 46.0, "batch_reward": 0.14518884890526534, "critic_loss": 6.132477117061615, "actor_loss": -81.29535684204102, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.576003074645996, "step": 46000}
{"episode_reward": 136.88225650890436, "episode": 47.0, "batch_reward": 0.14510169648379087, "critic_loss": 7.553378209352493, "actor_loss": -83.17618287658692, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.82987070083618, "step": 47000}
{"episode_reward": 84.1700243019395, "episode": 48.0, "batch_reward": 0.14388795950263739, "critic_loss": 8.495487587690354, "actor_loss": -85.96205274963378, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.609139680862427, "step": 48000}
{"episode_reward": 88.39152708790361, "episode": 49.0, "batch_reward": 0.14171163433790207, "critic_loss": 8.419867993831634, "actor_loss": -88.4185425567627, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.531184196472168, "step": 49000}
{"episode_reward": 80.74006198204803, "episode": 50.0, "batch_reward": 0.1403822171986103, "critic_loss": 8.386980364561081, "actor_loss": -89.90186973571777, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.92943501472473, "step": 50000}
{"episode_reward": 68.57553537731336, "episode": 51.0, "batch_reward": 0.13953298792243005, "critic_loss": 7.931254885673523, "actor_loss": -90.6322243347168, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 49.49851369857788, "step": 51000}
{"episode_reward": 75.47644629967546, "episode": 52.0, "batch_reward": 0.13872510965168477, "critic_loss": 7.853166136264801, "actor_loss": -92.05256643676758, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.628943920135498, "step": 52000}
{"episode_reward": 67.49353300339969, "episode": 53.0, "batch_reward": 0.13733485981822013, "critic_loss": 7.927749639987946, "actor_loss": -92.59026104736328, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.27221441268921, "step": 53000}
{"episode_reward": 117.42137655626053, "episode": 54.0, "batch_reward": 0.13600208570063113, "critic_loss": 7.931616806030274, "actor_loss": -94.01703428649903, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.414273262023926, "step": 54000}
{"episode_reward": 64.37413057097922, "episode": 55.0, "batch_reward": 0.13565464374423028, "critic_loss": 7.545368823289871, "actor_loss": -94.62434329223633, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.839362144470215, "step": 55000}
{"episode_reward": 85.12721564483446, "episode": 56.0, "batch_reward": 0.13523419051617383, "critic_loss": 7.292628470897674, "actor_loss": -93.87332267761231, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.286588191986084, "step": 56000}
{"episode_reward": 200.65682932310708, "episode": 57.0, "batch_reward": 0.13597355357557536, "critic_loss": 6.959203105211258, "actor_loss": -94.20788966369629, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.2524995803833, "step": 57000}
{"episode_reward": 244.26041241774817, "episode": 58.0, "batch_reward": 0.13890157716721296, "critic_loss": 6.581546832323074, "actor_loss": -93.76685110473633, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.6395320892334, "step": 58000}
{"episode_reward": 320.48647550762644, "episode": 59.0, "batch_reward": 0.13993568946421148, "critic_loss": 5.503796135425568, "actor_loss": -92.82861740112304, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.555429458618164, "step": 59000}
{"episode_reward": 83.37466607317025, "episode": 60.0, "batch_reward": 0.1385238516330719, "critic_loss": 4.3975645844936375, "actor_loss": -92.16823748779296, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.909165859222412, "step": 60000}
{"episode_reward": 112.96847956315911, "episode": 61.0, "batch_reward": 0.13935477567464113, "critic_loss": 3.819855163216591, "actor_loss": -91.49244673156738, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.25362730026245, "step": 61000}
{"episode_reward": 102.77909197866008, "episode": 62.0, "batch_reward": 0.13917277765274047, "critic_loss": 3.0649967317581175, "actor_loss": -90.74510859680176, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.569116830825806, "step": 62000}
{"episode_reward": 99.43378349471132, "episode": 63.0, "batch_reward": 0.13703833838552237, "critic_loss": 2.4452145730257033, "actor_loss": -88.96209683227539, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.558873653411865, "step": 63000}
{"episode_reward": 27.938334491612498, "episode": 64.0, "batch_reward": 0.13609107596427203, "critic_loss": 2.0294337280392645, "actor_loss": -87.36721794128418, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.43963098526001, "step": 64000}
{"episode_reward": 173.08726438416508, "episode": 65.0, "batch_reward": 0.13515993423759937, "critic_loss": 1.8002132731080056, "actor_loss": -86.30064172363281, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.58468508720398, "step": 65000}
{"episode_reward": 27.094640199464827, "episode": 66.0, "batch_reward": 0.13466350787878037, "critic_loss": 1.5466885775923729, "actor_loss": -85.14638438415527, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.286259412765503, "step": 66000}
{"episode_reward": 23.826681727896766, "episode": 67.0, "batch_reward": 0.1336260688379407, "critic_loss": 1.362911467552185, "actor_loss": -84.07321765136719, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.293083906173706, "step": 67000}
{"episode_reward": 95.21759173667775, "episode": 68.0, "batch_reward": 0.13268737481534482, "critic_loss": 1.167540531218052, "actor_loss": -82.71538539123536, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.8515408039093, "step": 68000}
{"episode_reward": 129.05101746711978, "episode": 69.0, "batch_reward": 0.1312647704333067, "critic_loss": 0.9691585204601287, "actor_loss": -81.36643572998047, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.135477781295776, "step": 69000}
{"episode_reward": 24.618679569010148, "episode": 70.0, "batch_reward": 0.13192652340233327, "critic_loss": 0.9046302568614483, "actor_loss": -79.904833694458, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.078661680221558, "step": 70000}
{"episode_reward": 130.1437832721735, "episode": 71.0, "batch_reward": 0.13312217292934655, "critic_loss": 0.8531674133241176, "actor_loss": -78.55511454772949, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.8467001914978, "step": 71000}
{"episode_reward": 533.2145583964266, "episode": 72.0, "batch_reward": 0.1387970686778426, "critic_loss": 0.782508710026741, "actor_loss": -77.50021382141114, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.248440980911255, "step": 72000}
{"episode_reward": 464.8169281907342, "episode": 73.0, "batch_reward": 0.14423540184646844, "critic_loss": 0.7373669459223747, "actor_loss": -76.21485049438476, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.42200255393982, "step": 73000}
{"episode_reward": 581.5986697190527, "episode": 74.0, "batch_reward": 0.15004856061935426, "critic_loss": 0.6808341211080551, "actor_loss": -75.50864440917968, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.606643676757812, "step": 74000}
{"episode_reward": 555.5020907125001, "episode": 75.0, "batch_reward": 0.15581874700635673, "critic_loss": 0.6425391307473183, "actor_loss": -74.97890745544433, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.437750339508057, "step": 75000}
{"episode_reward": 414.76192800356125, "episode": 76.0, "batch_reward": 0.15895704665780067, "critic_loss": 0.6516486328542233, "actor_loss": -74.08662396240234, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.030529022216797, "step": 76000}
{"episode_reward": 279.0119798867391, "episode": 77.0, "batch_reward": 0.16106438352167607, "critic_loss": 0.6022436827123165, "actor_loss": -72.82348998260498, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.462604522705078, "step": 77000}
{"episode_reward": 569.9287985475502, "episode": 78.0, "batch_reward": 0.16679708690941333, "critic_loss": 0.6074518693089486, "actor_loss": -72.03282275390625, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.42756938934326, "step": 78000}
{"episode_reward": 533.719984641654, "episode": 79.0, "batch_reward": 0.1705765983685851, "critic_loss": 0.6117915819883346, "actor_loss": -72.10928817749023, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.829248189926147, "step": 79000}
{"episode_reward": 531.5351845493672, "episode": 80.0, "batch_reward": 0.1764006356075406, "critic_loss": 0.6117837318181991, "actor_loss": -71.36398703765869, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.5991473197937, "step": 80000}
{"episode_reward": 641.7688311934484, "episode": 81.0, "batch_reward": 0.1810803039968014, "critic_loss": 0.6432942359745503, "actor_loss": -70.74347536468505, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.76588845252991, "step": 81000}
{"episode_reward": 598.8695650620824, "episode": 82.0, "batch_reward": 0.18608776967227458, "critic_loss": 0.6393497766554356, "actor_loss": -70.31605197906494, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.891875743865967, "step": 82000}
{"episode_reward": 614.6125992352019, "episode": 83.0, "batch_reward": 0.19139307697117328, "critic_loss": 0.6842963461577892, "actor_loss": -69.18753176116944, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.603100061416626, "step": 83000}
{"episode_reward": 611.2637258300484, "episode": 84.0, "batch_reward": 0.19576517127454282, "critic_loss": 0.7163953346908093, "actor_loss": -69.13360848236084, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.854101181030273, "step": 84000}
{"episode_reward": 513.1426806153789, "episode": 85.0, "batch_reward": 0.20137274587154388, "critic_loss": 0.76994350284338, "actor_loss": -68.89060065460205, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.720247745513916, "step": 85000}
{"episode_reward": 607.1871775207445, "episode": 86.0, "batch_reward": 0.2026218103170395, "critic_loss": 0.7862642619609833, "actor_loss": -67.62189978027344, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.713512659072876, "step": 86000}
{"episode_reward": 451.61024806112533, "episode": 87.0, "batch_reward": 0.2088299839794636, "critic_loss": 0.8157721977829934, "actor_loss": -67.74918271636963, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.1948504447937, "step": 87000}
{"episode_reward": 629.4360512329, "episode": 88.0, "batch_reward": 0.21239652143418788, "critic_loss": 0.8602253495752812, "actor_loss": -66.96463976287842, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.3350887298584, "step": 88000}
{"episode_reward": 531.2446861362465, "episode": 89.0, "batch_reward": 0.21632932528853416, "critic_loss": 0.8969246399104596, "actor_loss": -67.28976554107666, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.61037039756775, "step": 89000}
{"episode_reward": 642.0257720344085, "episode": 90.0, "batch_reward": 0.22096854797005652, "critic_loss": 0.9207534288465977, "actor_loss": -67.38871382141113, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.85246777534485, "step": 90000}
{"episode_reward": 636.4487928414478, "episode": 91.0, "batch_reward": 0.22624552410840987, "critic_loss": 0.9586499865949154, "actor_loss": -66.99660433197022, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 43.881412744522095, "step": 91000}
{"episode_reward": 629.1821111834568, "episode": 92.0, "batch_reward": 0.2282443244755268, "critic_loss": 0.9872937095165253, "actor_loss": -65.14087283325195, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.64362096786499, "step": 92000}
{"episode_reward": 608.7206697102781, "episode": 93.0, "batch_reward": 0.2349025130867958, "critic_loss": 1.0035848850011826, "actor_loss": -66.46750751495361, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.083390474319458, "step": 93000}
{"episode_reward": 712.4549329090838, "episode": 94.0, "batch_reward": 0.24182727999985218, "critic_loss": 0.9900043450295926, "actor_loss": -65.3783669204712, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.473338842391968, "step": 94000}
{"episode_reward": 733.7953988655341, "episode": 95.0, "batch_reward": 0.2442142488658428, "critic_loss": 1.0345362082719802, "actor_loss": -67.16859719085693, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.540814876556396, "step": 95000}
{"episode_reward": 679.533070807618, "episode": 96.0, "batch_reward": 0.2509706390798092, "critic_loss": 1.0804022014141084, "actor_loss": -64.76126155853271, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.069864988327026, "step": 96000}
{"episode_reward": 751.1091163411965, "episode": 97.0, "batch_reward": 0.255157740265131, "critic_loss": 1.1271701840758324, "actor_loss": -66.66858827209472, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.620668172836304, "step": 97000}
{"episode_reward": 746.66633678871, "episode": 98.0, "batch_reward": 0.26024862986803055, "critic_loss": 1.1311405263543128, "actor_loss": -67.49850144195557, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.456668853759766, "step": 98000}
{"episode_reward": 760.0049876024162, "episode": 99.0, "batch_reward": 0.26453008487820623, "critic_loss": 1.153984827697277, "actor_loss": -66.55352725982667, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.208942890167236, "step": 99000}
{"episode_reward": 797.8767147415625, "episode": 100.0, "batch_reward": 0.2699477360695601, "critic_loss": 1.1474295414090157, "actor_loss": -66.31155136108399, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.78682279586792, "step": 100000}
{"episode_reward": 703.2348406048812, "episode": 101.0, "batch_reward": 0.2755565885305405, "critic_loss": 1.1535788988471032, "actor_loss": -65.22099714660645, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.29383683204651, "step": 101000}
{"episode_reward": 737.2683005779097, "episode": 102.0, "batch_reward": 0.27800187534093856, "critic_loss": 1.1936411685347557, "actor_loss": -66.60444723510741, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.384057998657227, "step": 102000}
{"episode_reward": 755.3632074636473, "episode": 103.0, "batch_reward": 0.28318117029964923, "critic_loss": 1.1868644028306008, "actor_loss": -65.39145068359375, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.951354026794434, "step": 103000}
{"episode_reward": 724.4543698181742, "episode": 104.0, "batch_reward": 0.28910822862386704, "critic_loss": 1.2248804160058497, "actor_loss": -67.20080834197998, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.828612089157104, "step": 104000}
{"episode_reward": 800.8180229366637, "episode": 105.0, "batch_reward": 0.2934601337015629, "critic_loss": 1.2242194751501083, "actor_loss": -65.79817170715332, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.192185163497925, "step": 105000}
{"episode_reward": 850.3582692469015, "episode": 106.0, "batch_reward": 0.2985970735102892, "critic_loss": 1.3080422924160957, "actor_loss": -67.33178085327148, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.631428956985474, "step": 106000}
{"episode_reward": 844.9505962493275, "episode": 107.0, "batch_reward": 0.3045596865415573, "critic_loss": 1.2900822286605835, "actor_loss": -68.54432299041748, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.295705556869507, "step": 107000}
{"episode_reward": 864.0791562402704, "episode": 108.0, "batch_reward": 0.3091834767460823, "critic_loss": 1.3071216760277748, "actor_loss": -67.69816414642334, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.048516273498535, "step": 108000}
{"episode_reward": 877.8123245812685, "episode": 109.0, "batch_reward": 0.3141697499901056, "critic_loss": 1.3252362488508225, "actor_loss": -68.33444931030273, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.281522035598755, "step": 109000}
{"episode_reward": 868.4442620095911, "episode": 110.0, "batch_reward": 0.32040156914293766, "critic_loss": 1.379772113442421, "actor_loss": -68.81049147796631, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.627268075942993, "step": 110000}
{"episode_reward": 863.7034197819243, "episode": 111.0, "batch_reward": 0.32460620291531084, "critic_loss": 1.3881766363978385, "actor_loss": -68.06147271728516, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 43.73870325088501, "step": 111000}
{"episode_reward": 862.0734072465668, "episode": 112.0, "batch_reward": 0.32809485161304475, "critic_loss": 1.4463755756020547, "actor_loss": -68.80243991088867, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.999199628829956, "step": 112000}
{"episode_reward": 872.911751863351, "episode": 113.0, "batch_reward": 0.3357289102673531, "critic_loss": 1.439138470709324, "actor_loss": -68.32551986694335, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.623377799987793, "step": 113000}
{"episode_reward": 831.3547345104292, "episode": 114.0, "batch_reward": 0.3396453491151333, "critic_loss": 1.4579718447327614, "actor_loss": -69.54201467132569, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.610462427139282, "step": 114000}
{"episode_reward": 887.4497580666251, "episode": 115.0, "batch_reward": 0.34301040875911715, "critic_loss": 1.4399953953623772, "actor_loss": -71.4338963394165, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.23387837409973, "step": 115000}
{"episode_reward": 894.5904614582328, "episode": 116.0, "batch_reward": 0.3467895640730858, "critic_loss": 1.4253411944508552, "actor_loss": -70.76157119750977, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.97842288017273, "step": 116000}
{"episode_reward": 841.8144686101627, "episode": 117.0, "batch_reward": 0.3536127382516861, "critic_loss": 1.3697110713124274, "actor_loss": -71.23276013183593, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.485790729522705, "step": 117000}
{"episode_reward": 841.9349324076143, "episode": 118.0, "batch_reward": 0.3561190573871136, "critic_loss": 1.4175945308208466, "actor_loss": -70.83714337921143, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.27480673789978, "step": 118000}
{"episode_reward": 866.0546357311808, "episode": 119.0, "batch_reward": 0.36149380895495414, "critic_loss": 1.4458620633482933, "actor_loss": -71.57911587524414, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.89818263053894, "step": 119000}
{"episode_reward": 867.123745001583, "episode": 120.0, "batch_reward": 0.366391633272171, "critic_loss": 1.4391700701713561, "actor_loss": -72.39992430877686, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.422971963882446, "step": 120000}
{"episode_reward": 906.6894656257215, "episode": 121.0, "batch_reward": 0.3718463823795319, "critic_loss": 1.4768845221996307, "actor_loss": -72.38327680969238, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 40.94001746177673, "step": 121000}
{"episode_reward": 861.5909832635631, "episode": 122.0, "batch_reward": 0.37463816127181054, "critic_loss": 1.4807981868982316, "actor_loss": -73.75767944335938, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.916763067245483, "step": 122000}
{"episode_reward": 832.7662304736307, "episode": 123.0, "batch_reward": 0.3759752523303032, "critic_loss": 1.4451807473301888, "actor_loss": -74.00063800048828, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.648105144500732, "step": 123000}
{"episode_reward": 869.8829853640425, "episode": 124.0, "batch_reward": 0.38264688897132876, "critic_loss": 1.441208839416504, "actor_loss": -73.78763830566406, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.440387964248657, "step": 124000}
{"episode_reward": 913.1918087493791, "episode": 125.0, "batch_reward": 0.38611399456858636, "critic_loss": 1.396269679903984, "actor_loss": -73.99320761871338, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.2620632648468, "step": 125000}
{"episode_reward": 898.1561240839402, "episode": 126.0, "batch_reward": 0.3897692747414112, "critic_loss": 1.4210616025328635, "actor_loss": -74.26204885864257, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.02583885192871, "step": 126000}
{"episode_reward": 899.0098368214007, "episode": 127.0, "batch_reward": 0.39269343012571334, "critic_loss": 1.3730112769007683, "actor_loss": -74.41840842437745, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.804208755493164, "step": 127000}
{"episode_reward": 893.5684770320777, "episode": 128.0, "batch_reward": 0.3973392783999443, "critic_loss": 1.3578650268912316, "actor_loss": -73.92113388824463, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.51737928390503, "step": 128000}
{"episode_reward": 914.0264095596423, "episode": 129.0, "batch_reward": 0.4006633013188839, "critic_loss": 1.3947882546186448, "actor_loss": -74.33646031188965, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.83980369567871, "step": 129000}
{"episode_reward": 852.9823771116917, "episode": 130.0, "batch_reward": 0.40534039279818534, "critic_loss": 1.4300068151950835, "actor_loss": -75.2610855331421, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.04515814781189, "step": 130000}
{"episode_reward": 872.9972628777324, "episode": 131.0, "batch_reward": 0.4077446520924568, "critic_loss": 1.4167163357138635, "actor_loss": -74.05703668212891, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 43.13414549827576, "step": 131000}
{"episode_reward": 811.7509563390608, "episode": 132.0, "batch_reward": 0.41152410662174227, "critic_loss": 1.380459431886673, "actor_loss": -75.20948138427734, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.62006139755249, "step": 132000}
{"episode_reward": 892.9256667094545, "episode": 133.0, "batch_reward": 0.41286527475714685, "critic_loss": 1.3771295059323312, "actor_loss": -75.5813888015747, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.556356191635132, "step": 133000}
{"episode_reward": 861.6368074209372, "episode": 134.0, "batch_reward": 0.41975974369049074, "critic_loss": 1.362358415722847, "actor_loss": -75.96553542327881, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.595774173736572, "step": 134000}
{"episode_reward": 843.8067215910726, "episode": 135.0, "batch_reward": 0.4216868436038494, "critic_loss": 1.3432064554691314, "actor_loss": -76.70181267547608, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.866275787353516, "step": 135000}
{"episode_reward": 882.3124610142027, "episode": 136.0, "batch_reward": 0.4247807329595089, "critic_loss": 1.399478806078434, "actor_loss": -76.99827172088624, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.540860891342163, "step": 136000}
{"episode_reward": 891.7698055738806, "episode": 137.0, "batch_reward": 0.42909340670704843, "critic_loss": 1.3915543665885926, "actor_loss": -76.27626530456543, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.61575675010681, "step": 137000}
{"episode_reward": 888.1018348516038, "episode": 138.0, "batch_reward": 0.4322280425727367, "critic_loss": 1.3483653163313867, "actor_loss": -76.24127236175538, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.651459217071533, "step": 138000}
{"episode_reward": 885.14489516136, "episode": 139.0, "batch_reward": 0.4361611751317978, "critic_loss": 1.3212479900717735, "actor_loss": -76.23264209747315, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.90007448196411, "step": 139000}
{"episode_reward": 812.7409464776838, "episode": 140.0, "batch_reward": 0.43772596728801727, "critic_loss": 1.3748981625437737, "actor_loss": -76.67604135894776, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.230334281921387, "step": 140000}
{"episode_reward": 881.7110117413421, "episode": 141.0, "batch_reward": 0.4418432067930698, "critic_loss": 1.3716441748142243, "actor_loss": -78.04118019866944, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.82875394821167, "step": 141000}
{"episode_reward": 891.8272596639271, "episode": 142.0, "batch_reward": 0.4430006386935711, "critic_loss": 1.3298860369324683, "actor_loss": -77.18310585784913, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.272825956344604, "step": 142000}
{"episode_reward": 863.8631535819403, "episode": 143.0, "batch_reward": 0.4483763398528099, "critic_loss": 1.3089729843735696, "actor_loss": -78.52689347839356, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.98480224609375, "step": 143000}
{"episode_reward": 899.1585331190598, "episode": 144.0, "batch_reward": 0.4526485285460949, "critic_loss": 1.3098375892043115, "actor_loss": -78.04872076416015, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.40322470664978, "step": 144000}
{"episode_reward": 866.0679209183027, "episode": 145.0, "batch_reward": 0.45426194512844087, "critic_loss": 1.3318205826878549, "actor_loss": -78.88940866088868, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.717232704162598, "step": 145000}
{"episode_reward": 916.21133447797, "episode": 146.0, "batch_reward": 0.45647702330350876, "critic_loss": 1.3377980552315711, "actor_loss": -78.18181649780273, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.544575214385986, "step": 146000}
{"episode_reward": 933.6983470348229, "episode": 147.0, "batch_reward": 0.46032256254553794, "critic_loss": 1.349618755042553, "actor_loss": -78.91442469024658, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.65347695350647, "step": 147000}
{"episode_reward": 917.5209181753237, "episode": 148.0, "batch_reward": 0.46311073026061056, "critic_loss": 1.3529452359080314, "actor_loss": -78.96641213989258, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.86597180366516, "step": 148000}
{"episode_reward": 869.6303336840339, "episode": 149.0, "batch_reward": 0.46416984817385676, "critic_loss": 1.3494945970773697, "actor_loss": -78.56104714965821, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.576772689819336, "step": 149000}
{"episode_reward": 836.8025755928122, "episode": 150.0, "batch_reward": 0.4685063554942608, "critic_loss": 1.3567249736189841, "actor_loss": -78.97820240783692, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "step": 150000}
