{"episode_reward": 0.0, "episode": 1.0, "duration": 21.949734687805176, "step": 1000}
{"episode_reward": 27.46298806610516, "episode": 2.0, "duration": 1.947185754776001, "step": 2000}
{"episode_reward": 489.1100087318934, "episode": 3.0, "batch_reward": 0.2428228723213807, "critic_loss": 0.13557071458404216, "actor_loss": -52.165413503981185, "actor_target_entropy": -6.0, "alpha_value": 0.002134017781850189, "duration": 63.060248374938965, "step": 3000}
{"episode_reward": 10.268948377806394, "episode": 4.0, "batch_reward": 0.15651217229664327, "critic_loss": 0.45080146262049675, "actor_loss": -50.16866528606415, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.812199115753174, "step": 4000}
{"episode_reward": 28.899074160095687, "episode": 5.0, "batch_reward": 0.13626166395097972, "critic_loss": 1.0978127575814725, "actor_loss": -50.43309806060791, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.524016618728638, "step": 5000}
{"episode_reward": 114.48030062641335, "episode": 6.0, "batch_reward": 0.12721734226495027, "critic_loss": 1.1686005312800407, "actor_loss": -51.49192542266846, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.182823419570923, "step": 6000}
{"episode_reward": 46.52355363165837, "episode": 7.0, "batch_reward": 0.11232918882742524, "critic_loss": 0.6127735328972339, "actor_loss": -52.69072249412537, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.934670448303223, "step": 7000}
{"episode_reward": 24.463863839915472, "episode": 8.0, "batch_reward": 0.1006792502515018, "critic_loss": 0.6711422160416841, "actor_loss": -51.9472546672821, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.699796199798584, "step": 8000}
{"episode_reward": 20.036646078700336, "episode": 9.0, "batch_reward": 0.0919929040633142, "critic_loss": 0.5347432207316161, "actor_loss": -50.747730686187744, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.494386911392212, "step": 9000}
{"episode_reward": 32.87374775352341, "episode": 10.0, "batch_reward": 0.08672987497597932, "critic_loss": 0.3499754936248064, "actor_loss": -53.0079602432251, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.026334524154663, "step": 10000}
{"episode_reward": 41.78947839416238, "episode": 11.0, "batch_reward": 0.07986661322414874, "critic_loss": 0.258989209279418, "actor_loss": -50.21183225631714, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.155898332595825, "step": 11000}
{"episode_reward": 23.936802314203916, "episode": 12.0, "batch_reward": 0.07767586489766837, "critic_loss": 0.22185097865015269, "actor_loss": -53.51997484016418, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.710182189941406, "step": 12000}
{"episode_reward": 45.06666468681267, "episode": 13.0, "batch_reward": 0.07311732218787075, "critic_loss": 0.19433128590881824, "actor_loss": -54.26081309890747, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.930561542510986, "step": 13000}
{"episode_reward": 24.23081322027689, "episode": 14.0, "batch_reward": 0.06977158188074827, "critic_loss": 0.15996016124263407, "actor_loss": -52.614215137481686, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.465028524398804, "step": 14000}
{"episode_reward": 23.54092799121858, "episode": 15.0, "batch_reward": 0.06883761866018176, "critic_loss": 0.16576721061766148, "actor_loss": -50.177875674247744, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.49853801727295, "step": 15000}
{"episode_reward": 67.43573688688556, "episode": 16.0, "batch_reward": 0.07396348899975419, "critic_loss": 0.2161859343610704, "actor_loss": -51.73587753963471, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.843573570251465, "step": 16000}
{"episode_reward": 162.943295220849, "episode": 17.0, "batch_reward": 0.07278405300527811, "critic_loss": 0.2201111249104142, "actor_loss": -53.462582573890685, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.540133237838745, "step": 17000}
{"episode_reward": 24.46048992259059, "episode": 18.0, "batch_reward": 0.07098631615191699, "critic_loss": 0.24600221077352763, "actor_loss": -51.86454594326019, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.355249881744385, "step": 18000}
{"episode_reward": 64.58119610333831, "episode": 19.0, "batch_reward": 0.07074642107076944, "critic_loss": 0.2549037306457758, "actor_loss": -52.21794625854492, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.139023303985596, "step": 19000}
{"episode_reward": 69.26070084914053, "episode": 20.0, "batch_reward": 0.07468825902417302, "critic_loss": 0.33214071495085956, "actor_loss": -53.40759319496155, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.23935580253601, "step": 20000}
{"episode_reward": 157.71991726319214, "episode": 21.0, "batch_reward": 0.0804251604899764, "critic_loss": 0.40587215389311315, "actor_loss": -49.67864454364776, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.97245693206787, "step": 21000}
{"episode_reward": 312.30046322918884, "episode": 22.0, "batch_reward": 0.08597828337177635, "critic_loss": 0.42591600807756186, "actor_loss": -54.37292960262299, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.895777225494385, "step": 22000}
{"episode_reward": 65.92334007341061, "episode": 23.0, "batch_reward": 0.09165354900434614, "critic_loss": 0.47096020804345606, "actor_loss": -53.062995881080624, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.48875904083252, "step": 23000}
{"episode_reward": 361.497672506061, "episode": 24.0, "batch_reward": 0.10238257511705161, "critic_loss": 0.5524484169483185, "actor_loss": -49.88694451236725, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.574217557907104, "step": 24000}
{"episode_reward": 239.26182641099376, "episode": 25.0, "batch_reward": 0.10565841300785542, "critic_loss": 0.5441870776563883, "actor_loss": -53.194474420547486, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.999303817749023, "step": 25000}
{"episode_reward": 176.7003205938416, "episode": 26.0, "batch_reward": 0.11289091093838215, "critic_loss": 0.5879204641133546, "actor_loss": -51.68579704856872, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.45615863800049, "step": 26000}
{"episode_reward": 347.25762985290265, "episode": 27.0, "batch_reward": 0.11973513421416283, "critic_loss": 0.5589270742237568, "actor_loss": -52.443510488510135, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.67272925376892, "step": 27000}
{"episode_reward": 419.0684877429583, "episode": 28.0, "batch_reward": 0.1289677674397826, "critic_loss": 0.6074679295569658, "actor_loss": -54.30673875045776, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.30191993713379, "step": 28000}
{"episode_reward": 197.34442489532086, "episode": 29.0, "batch_reward": 0.13247465094178915, "critic_loss": 0.637958245754242, "actor_loss": -53.99213968849182, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.4727783203125, "step": 29000}
{"episode_reward": 379.60899816973904, "episode": 30.0, "batch_reward": 0.14167275530844928, "critic_loss": 0.7082585553228855, "actor_loss": -52.6915385761261, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.40358328819275, "step": 30000}
{"episode_reward": 450.21911354699114, "episode": 31.0, "batch_reward": 0.15251639128476382, "critic_loss": 0.7921572752892971, "actor_loss": -55.601369680404666, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.131240367889404, "step": 31000}
{"episode_reward": 387.048165509493, "episode": 32.0, "batch_reward": 0.1587732945457101, "critic_loss": 0.7809593934118748, "actor_loss": -54.74936110496521, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.225160837173462, "step": 32000}
{"episode_reward": 343.330009280154, "episode": 33.0, "batch_reward": 0.16534044371545314, "critic_loss": 0.7653483720123768, "actor_loss": -57.042688009262086, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.928290605545044, "step": 33000}
{"episode_reward": 372.0298305322586, "episode": 34.0, "batch_reward": 0.16909531131386757, "critic_loss": 0.7417450182139873, "actor_loss": -56.904231687545774, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.54106879234314, "step": 34000}
{"episode_reward": 178.49536950293245, "episode": 35.0, "batch_reward": 0.16765781170874833, "critic_loss": 0.6812338582277297, "actor_loss": -52.3786432056427, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.213274478912354, "step": 35000}
{"episode_reward": 96.8321415756163, "episode": 36.0, "batch_reward": 0.16929295480251313, "critic_loss": 0.7020482669472694, "actor_loss": -57.40435389518738, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.888492107391357, "step": 36000}
{"episode_reward": 392.3263404749914, "episode": 37.0, "batch_reward": 0.17585812287032604, "critic_loss": 0.732380089044571, "actor_loss": -55.520556228637695, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.628664016723633, "step": 37000}
{"episode_reward": 358.67791066517736, "episode": 38.0, "batch_reward": 0.18079044811427594, "critic_loss": 0.7612119609117508, "actor_loss": -54.71695409202576, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.395308017730713, "step": 38000}
{"episode_reward": 481.88576486359216, "episode": 39.0, "batch_reward": 0.18962418019026517, "critic_loss": 0.7905827932357788, "actor_loss": -58.53172379684448, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.49442458152771, "step": 39000}
{"episode_reward": 494.709156362198, "episode": 40.0, "batch_reward": 0.19262337048351766, "critic_loss": 0.740388983130455, "actor_loss": -60.89639947509766, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.51833701133728, "step": 40000}
{"episode_reward": 138.21306253651258, "episode": 41.0, "batch_reward": 0.19368368349969386, "critic_loss": 0.7959703316688538, "actor_loss": -59.71332160949707, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.23218870162964, "step": 41000}
{"episode_reward": 334.8848262743309, "episode": 42.0, "batch_reward": 0.197206393443048, "critic_loss": 0.7911015405356884, "actor_loss": -58.87781156158447, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.462112188339233, "step": 42000}
{"episode_reward": 409.8998605387721, "episode": 43.0, "batch_reward": 0.2037438284754753, "critic_loss": 0.7879080269634724, "actor_loss": -60.11967119979858, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.584816217422485, "step": 43000}
{"episode_reward": 536.5414663283765, "episode": 44.0, "batch_reward": 0.21095663607120513, "critic_loss": 0.7891622961461544, "actor_loss": -56.42218994522095, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.792909622192383, "step": 44000}
{"episode_reward": 400.959636298704, "episode": 45.0, "batch_reward": 0.2169066971242428, "critic_loss": 0.7778254397213459, "actor_loss": -56.14145500946045, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.473064661026, "step": 45000}
{"episode_reward": 557.0843692579722, "episode": 46.0, "batch_reward": 0.22507842920720578, "critic_loss": 0.8526820805668831, "actor_loss": -58.12275824737549, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.387779474258423, "step": 46000}
{"episode_reward": 575.8426620193553, "episode": 47.0, "batch_reward": 0.23128062058985233, "critic_loss": 0.8565269117951393, "actor_loss": -57.841630073547364, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.569918632507324, "step": 47000}
{"episode_reward": 602.7641726376354, "episode": 48.0, "batch_reward": 0.2392526796013117, "critic_loss": 0.9151937552988529, "actor_loss": -57.726883934021, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.474109888076782, "step": 48000}
{"episode_reward": 557.9301946820257, "episode": 49.0, "batch_reward": 0.24649164594709874, "critic_loss": 0.8971248221099377, "actor_loss": -58.78615064239502, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.551356554031372, "step": 49000}
{"episode_reward": 365.2714564355592, "episode": 50.0, "batch_reward": 0.2482844762057066, "critic_loss": 0.8852439687848092, "actor_loss": -58.64453227615356, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.791565895080566, "step": 50000}
{"episode_reward": 532.493847091908, "episode": 51.0, "batch_reward": 0.2503224834650755, "critic_loss": 0.9149973131120205, "actor_loss": -59.33735478591919, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.67902684211731, "step": 51000}
{"episode_reward": 255.729977600185, "episode": 52.0, "batch_reward": 0.2551847025156021, "critic_loss": 0.9301270409226418, "actor_loss": -58.29334516525269, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.083695888519287, "step": 52000}
{"episode_reward": 587.4204616400731, "episode": 53.0, "batch_reward": 0.2617557431608438, "critic_loss": 0.9561928681135178, "actor_loss": -59.248657112121585, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.494692087173462, "step": 53000}
{"episode_reward": 590.4429100795137, "episode": 54.0, "batch_reward": 0.26664084498584273, "critic_loss": 0.9628110894560814, "actor_loss": -59.69888916015625, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.674575567245483, "step": 54000}
{"episode_reward": 534.6067889222136, "episode": 55.0, "batch_reward": 0.27161071871221065, "critic_loss": 1.0090741764605045, "actor_loss": -60.19584614944458, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.427809953689575, "step": 55000}
{"episode_reward": 548.1787800664978, "episode": 56.0, "batch_reward": 0.2756158675998449, "critic_loss": 1.0046348224580288, "actor_loss": -62.130609481811526, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.463590621948242, "step": 56000}
{"episode_reward": 488.62720318553755, "episode": 57.0, "batch_reward": 0.2805130304545164, "critic_loss": 1.0084343544244767, "actor_loss": -61.38492978286743, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.637882709503174, "step": 57000}
{"episode_reward": 592.3464554194641, "episode": 58.0, "batch_reward": 0.28633631923794745, "critic_loss": 1.0892966752648354, "actor_loss": -62.23724035644531, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.754417657852173, "step": 58000}
{"episode_reward": 573.2288270934513, "episode": 59.0, "batch_reward": 0.2908087431788445, "critic_loss": 1.072143140375614, "actor_loss": -62.9818984413147, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.5827157497406, "step": 59000}
{"episode_reward": 574.796146139306, "episode": 60.0, "batch_reward": 0.2950534837692976, "critic_loss": 1.0531001153588295, "actor_loss": -61.84144603347778, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.605913400650024, "step": 60000}
{"episode_reward": 580.2354959484633, "episode": 61.0, "batch_reward": 0.2991099092066288, "critic_loss": 1.0816843791604043, "actor_loss": -60.33206506729126, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.91520929336548, "step": 61000}
{"episode_reward": 615.1187608473489, "episode": 62.0, "batch_reward": 0.3061168140470982, "critic_loss": 1.0831159227490426, "actor_loss": -61.00489270019531, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.46237325668335, "step": 62000}
{"episode_reward": 678.4640893216283, "episode": 63.0, "batch_reward": 0.31282547461986543, "critic_loss": 1.068070560336113, "actor_loss": -61.85758130264282, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.89496350288391, "step": 63000}
{"episode_reward": 598.7090363811444, "episode": 64.0, "batch_reward": 0.3159205377548933, "critic_loss": 1.0947772197723389, "actor_loss": -64.37858044815063, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.35819435119629, "step": 64000}
{"episode_reward": 562.7952942404735, "episode": 65.0, "batch_reward": 0.320272965669632, "critic_loss": 1.0487480927705766, "actor_loss": -64.40082968139649, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.426598072052002, "step": 65000}
{"episode_reward": 608.1304948875161, "episode": 66.0, "batch_reward": 0.3239833736717701, "critic_loss": 1.0252675592303275, "actor_loss": -64.25207556533813, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.656940460205078, "step": 66000}
{"episode_reward": 507.82723023751527, "episode": 67.0, "batch_reward": 0.32850399316847323, "critic_loss": 1.0440002627670766, "actor_loss": -61.59595626449585, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.068368196487427, "step": 67000}
{"episode_reward": 623.258323728761, "episode": 68.0, "batch_reward": 0.33372726698219773, "critic_loss": 1.0536976189613343, "actor_loss": -64.35941257476807, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.440005779266357, "step": 68000}
{"episode_reward": 615.5160930524476, "episode": 69.0, "batch_reward": 0.33634439635276797, "critic_loss": 1.0909924730062486, "actor_loss": -63.18318185424805, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.639005661010742, "step": 69000}
{"episode_reward": 566.1470952154665, "episode": 70.0, "batch_reward": 0.3390804623216391, "critic_loss": 1.122699629485607, "actor_loss": -62.83328242492676, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.874442100524902, "step": 70000}
{"episode_reward": 664.565549601579, "episode": 71.0, "batch_reward": 0.345459424495697, "critic_loss": 1.1170777044296265, "actor_loss": -63.447082138061525, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.5315523147583, "step": 71000}
{"episode_reward": 632.0877229789136, "episode": 72.0, "batch_reward": 0.3466391965448856, "critic_loss": 1.1870791833996772, "actor_loss": -64.3649405670166, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.63338327407837, "step": 72000}
{"episode_reward": 554.5517318581883, "episode": 73.0, "batch_reward": 0.3514225608408451, "critic_loss": 1.153575798034668, "actor_loss": -65.00352946472168, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.458902835845947, "step": 73000}
{"episode_reward": 597.1621250382533, "episode": 74.0, "batch_reward": 0.35406287261843683, "critic_loss": 1.1369312456250191, "actor_loss": -65.37747769165038, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.350606441497803, "step": 74000}
{"episode_reward": 701.4880933120355, "episode": 75.0, "batch_reward": 0.3571670975983143, "critic_loss": 1.1540069417357446, "actor_loss": -67.69605381774902, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.794657707214355, "step": 75000}
{"episode_reward": 433.40150468119873, "episode": 76.0, "batch_reward": 0.35971564677357676, "critic_loss": 1.1999962544441223, "actor_loss": -66.04438749694825, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.554677486419678, "step": 76000}
{"episode_reward": 706.6162742194568, "episode": 77.0, "batch_reward": 0.3652292601466179, "critic_loss": 1.2598838430643082, "actor_loss": -66.47801206207275, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.104077100753784, "step": 77000}
{"episode_reward": 629.4262565416668, "episode": 78.0, "batch_reward": 0.3665880757570267, "critic_loss": 1.3212874146997928, "actor_loss": -66.17416974639893, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.881802320480347, "step": 78000}
{"episode_reward": 250.03629051310006, "episode": 79.0, "batch_reward": 0.36510132578015325, "critic_loss": 1.261312586724758, "actor_loss": -67.71780424499512, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.690032958984375, "step": 79000}
{"episode_reward": 300.74983220649995, "episode": 80.0, "batch_reward": 0.36393032974004746, "critic_loss": 1.344942449092865, "actor_loss": -67.2795592956543, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.212564706802368, "step": 80000}
{"episode_reward": 411.08627193821167, "episode": 81.0, "batch_reward": 0.36570304855704305, "critic_loss": 1.3526913039684296, "actor_loss": -66.46555073547363, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.59805750846863, "step": 81000}
{"episode_reward": 651.0724477024438, "episode": 82.0, "batch_reward": 0.36889665988087655, "critic_loss": 1.4028082231879235, "actor_loss": -67.16877044677734, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.517549991607666, "step": 82000}
{"episode_reward": 284.55142969326147, "episode": 83.0, "batch_reward": 0.3674315369576216, "critic_loss": 1.5101455624699593, "actor_loss": -66.23819316101074, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.602951526641846, "step": 83000}
{"episode_reward": 206.4610080953603, "episode": 84.0, "batch_reward": 0.3661454658508301, "critic_loss": 1.487199770987034, "actor_loss": -66.55706880187988, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.78036332130432, "step": 84000}
{"episode_reward": 533.118901020338, "episode": 85.0, "batch_reward": 0.36788279211521147, "critic_loss": 1.5207848305106162, "actor_loss": -67.35959612274169, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.49399495124817, "step": 85000}
{"episode_reward": 675.8855736303719, "episode": 86.0, "batch_reward": 0.37057012233138087, "critic_loss": 1.5006122848391532, "actor_loss": -66.33819887542725, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.60774540901184, "step": 86000}
{"episode_reward": 580.2355067973973, "episode": 87.0, "batch_reward": 0.3746409220695496, "critic_loss": 1.654291726410389, "actor_loss": -65.74385790252686, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.23577117919922, "step": 87000}
{"episode_reward": 730.7506930029186, "episode": 88.0, "batch_reward": 0.37914105561375616, "critic_loss": 1.649108327448368, "actor_loss": -66.53379327392578, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.51727795600891, "step": 88000}
{"episode_reward": 784.2041495735012, "episode": 89.0, "batch_reward": 0.3832546662092209, "critic_loss": 1.6471249106526376, "actor_loss": -67.68587298583985, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.773653984069824, "step": 89000}
{"episode_reward": 701.4961603812276, "episode": 90.0, "batch_reward": 0.3862161198556423, "critic_loss": 1.5933542103171348, "actor_loss": -67.05371817016602, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.22033166885376, "step": 90000}
{"episode_reward": 626.7052226043972, "episode": 91.0, "batch_reward": 0.38835862907767293, "critic_loss": 1.5599613669514656, "actor_loss": -68.4510865020752, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.219929695129395, "step": 91000}
{"episode_reward": 636.3772607938712, "episode": 92.0, "batch_reward": 0.39204086539149285, "critic_loss": 1.59497461605072, "actor_loss": -65.55019858551026, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.782697677612305, "step": 92000}
{"episode_reward": 752.4016636579237, "episode": 93.0, "batch_reward": 0.3977579983174801, "critic_loss": 1.5872347774505615, "actor_loss": -67.7699638671875, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.171607732772827, "step": 93000}
{"episode_reward": 779.9517620547056, "episode": 94.0, "batch_reward": 0.4006104974746704, "critic_loss": 1.6732115305066109, "actor_loss": -66.57256969451905, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.563929319381714, "step": 94000}
{"episode_reward": 571.0052203339765, "episode": 95.0, "batch_reward": 0.40054792988300325, "critic_loss": 1.6434464522600174, "actor_loss": -68.36402208709717, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.000762224197388, "step": 95000}
{"episode_reward": 730.1026770933157, "episode": 96.0, "batch_reward": 0.4067090614438057, "critic_loss": 1.6626777195334435, "actor_loss": -67.4102640914917, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.4412624835968, "step": 96000}
{"episode_reward": 745.2868555810699, "episode": 97.0, "batch_reward": 0.4085964473485947, "critic_loss": 1.5629858890771866, "actor_loss": -68.57632723236084, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.504897117614746, "step": 97000}
{"episode_reward": 748.5242921297902, "episode": 98.0, "batch_reward": 0.41458837988972663, "critic_loss": 1.6458534185290337, "actor_loss": -70.17117871856689, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.899735689163208, "step": 98000}
{"episode_reward": 828.2633553895568, "episode": 99.0, "batch_reward": 0.415858753234148, "critic_loss": 1.599712891638279, "actor_loss": -68.8408642654419, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.013709545135498, "step": 99000}
{"episode_reward": 349.7455036077565, "episode": 100.0, "batch_reward": 0.41537969595193863, "critic_loss": 1.682284162580967, "actor_loss": -69.59011331939698, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.520260334014893, "step": 100000}
{"episode_reward": 767.7828892011388, "episode": 101.0, "batch_reward": 0.41929881143569947, "critic_loss": 1.7636380546092987, "actor_loss": -68.18289961242675, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.25004029273987, "step": 101000}
{"episode_reward": 705.4923825810642, "episode": 102.0, "batch_reward": 0.4250152045190334, "critic_loss": 1.7585365804433823, "actor_loss": -70.1358710784912, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.48596215248108, "step": 102000}
{"episode_reward": 790.0266930848935, "episode": 103.0, "batch_reward": 0.42614924094080925, "critic_loss": 1.7736590024232863, "actor_loss": -69.07554154968261, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.556702136993408, "step": 103000}
{"episode_reward": 770.9623795935912, "episode": 104.0, "batch_reward": 0.4304171196222305, "critic_loss": 1.7607475225925446, "actor_loss": -71.70313089752197, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.58826994895935, "step": 104000}
{"episode_reward": 777.3726118752622, "episode": 105.0, "batch_reward": 0.4315569158494473, "critic_loss": 1.7647141800522805, "actor_loss": -69.30129914093017, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.48762822151184, "step": 105000}
{"episode_reward": 810.3470228834602, "episode": 106.0, "batch_reward": 0.4379868252277374, "critic_loss": 1.6509596703648568, "actor_loss": -70.43291859436034, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.448442459106445, "step": 106000}
{"episode_reward": 832.6285813098148, "episode": 107.0, "batch_reward": 0.43884289836883544, "critic_loss": 1.7596346129775047, "actor_loss": -71.21893947601319, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.821662425994873, "step": 107000}
{"episode_reward": 836.54500092995, "episode": 108.0, "batch_reward": 0.44347328147292137, "critic_loss": 1.7101997655630112, "actor_loss": -71.17838210296631, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.53910207748413, "step": 108000}
{"episode_reward": 833.4837768859857, "episode": 109.0, "batch_reward": 0.44867399021983145, "critic_loss": 1.7524193866848945, "actor_loss": -71.70431875610352, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.321250438690186, "step": 109000}
{"episode_reward": 847.7338230649763, "episode": 110.0, "batch_reward": 0.45111212038993836, "critic_loss": 1.718843902885914, "actor_loss": -72.60537744140625, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.802008152008057, "step": 110000}
{"episode_reward": 873.2471921521342, "episode": 111.0, "batch_reward": 0.45601683366298673, "critic_loss": 1.7328194893598556, "actor_loss": -71.44631405639649, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 40.639193058013916, "step": 111000}
{"episode_reward": 859.3383679971082, "episode": 112.0, "batch_reward": 0.4587084693908691, "critic_loss": 1.701798518896103, "actor_loss": -72.60520503997803, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.056559562683105, "step": 112000}
{"episode_reward": 784.105853668201, "episode": 113.0, "batch_reward": 0.46229112979769704, "critic_loss": 1.8436068943738937, "actor_loss": -71.18118961334228, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.445038080215454, "step": 113000}
{"episode_reward": 748.8023046303533, "episode": 114.0, "batch_reward": 0.46357452362775803, "critic_loss": 1.7448319723010064, "actor_loss": -72.93478063964844, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.508981227874756, "step": 114000}
{"episode_reward": 831.5353075105526, "episode": 115.0, "batch_reward": 0.46705918648838995, "critic_loss": 1.8328744761943818, "actor_loss": -74.79147603607177, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.833983898162842, "step": 115000}
{"episode_reward": 795.6529910376806, "episode": 116.0, "batch_reward": 0.4708378228843212, "critic_loss": 1.8789937782287598, "actor_loss": -73.67321309661865, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.758347034454346, "step": 116000}
{"episode_reward": 842.9939739910812, "episode": 117.0, "batch_reward": 0.4745607906281948, "critic_loss": 1.8641729588508607, "actor_loss": -74.44268025207519, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.53745722770691, "step": 117000}
{"episode_reward": 843.2336164824067, "episode": 118.0, "batch_reward": 0.47634357810020445, "critic_loss": 1.8938917499184609, "actor_loss": -74.21358299255371, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.24384617805481, "step": 118000}
{"episode_reward": 833.5228963361513, "episode": 119.0, "batch_reward": 0.4775242491066456, "critic_loss": 1.9993142575025558, "actor_loss": -75.11602884674072, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.05295705795288, "step": 119000}
{"episode_reward": 332.3521549515526, "episode": 120.0, "batch_reward": 0.4796590312719345, "critic_loss": 1.9533899446725846, "actor_loss": -75.60912274932862, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.50517201423645, "step": 120000}
{"episode_reward": 885.0223032826849, "episode": 121.0, "batch_reward": 0.48349451464414595, "critic_loss": 1.990982899725437, "actor_loss": -75.85411994171143, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.614163875579834, "step": 121000}
{"episode_reward": 874.040389370767, "episode": 122.0, "batch_reward": 0.48635130128264425, "critic_loss": 1.987378827214241, "actor_loss": -76.75088848114014, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.440402507781982, "step": 122000}
{"episode_reward": 799.348076627438, "episode": 123.0, "batch_reward": 0.4874574608504772, "critic_loss": 2.0184354667067526, "actor_loss": -77.25236781311035, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.47010350227356, "step": 123000}
{"episode_reward": 802.1535286677799, "episode": 124.0, "batch_reward": 0.4884505599737167, "critic_loss": 1.9946956325769425, "actor_loss": -76.87084217071533, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.92475461959839, "step": 124000}
{"episode_reward": 820.8954129220939, "episode": 125.0, "batch_reward": 0.49408129581809046, "critic_loss": 1.983273473739624, "actor_loss": -77.33655361175538, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.393459796905518, "step": 125000}
{"episode_reward": 879.7377591974465, "episode": 126.0, "batch_reward": 0.4956664991378784, "critic_loss": 1.9732130053043366, "actor_loss": -77.87285620117187, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.45037579536438, "step": 126000}
{"episode_reward": 845.265100750953, "episode": 127.0, "batch_reward": 0.498704804956913, "critic_loss": 2.1111197397708894, "actor_loss": -77.27459255218506, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.77991509437561, "step": 127000}
{"episode_reward": 867.4835951932265, "episode": 128.0, "batch_reward": 0.5016103881001472, "critic_loss": 2.111769566178322, "actor_loss": -76.97389655303955, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.89694595336914, "step": 128000}
{"episode_reward": 878.3092235175375, "episode": 129.0, "batch_reward": 0.5048324411511421, "critic_loss": 2.135109864473343, "actor_loss": -77.87179252624512, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.796629190444946, "step": 129000}
{"episode_reward": 872.599898846275, "episode": 130.0, "batch_reward": 0.508421345949173, "critic_loss": 2.0870863082408904, "actor_loss": -77.76540162658691, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.68891191482544, "step": 130000}
{"episode_reward": 789.7318987424572, "episode": 131.0, "batch_reward": 0.5086810114085675, "critic_loss": 2.0226813188195227, "actor_loss": -76.70917903900147, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.82773041725159, "step": 131000}
{"episode_reward": 809.8330576471213, "episode": 132.0, "batch_reward": 0.5116864450573921, "critic_loss": 1.9878818942308425, "actor_loss": -78.04015479278564, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.431381464004517, "step": 132000}
{"episode_reward": 871.1449678364094, "episode": 133.0, "batch_reward": 0.5132005722224713, "critic_loss": 1.9882790507078172, "actor_loss": -78.6303867340088, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.674134731292725, "step": 133000}
{"episode_reward": 821.2198132412709, "episode": 134.0, "batch_reward": 0.5172812054157258, "critic_loss": 1.9387813192605972, "actor_loss": -79.00552977752686, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.215956449508667, "step": 134000}
{"episode_reward": 844.831526830865, "episode": 135.0, "batch_reward": 0.518022764146328, "critic_loss": 1.899738226234913, "actor_loss": -79.6340014038086, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.471694231033325, "step": 135000}
{"episode_reward": 874.4653210476633, "episode": 136.0, "batch_reward": 0.520717794239521, "critic_loss": 1.9383605871796608, "actor_loss": -80.13816068267822, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.380418300628662, "step": 136000}
{"episode_reward": 773.6718838251039, "episode": 137.0, "batch_reward": 0.5253233284950256, "critic_loss": 1.9071082473397254, "actor_loss": -80.06388094329834, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.525855779647827, "step": 137000}
{"episode_reward": 898.9095119122485, "episode": 138.0, "batch_reward": 0.5275167519450188, "critic_loss": 1.8945895011425018, "actor_loss": -78.63883295440674, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.45909333229065, "step": 138000}
{"episode_reward": 895.4163489846596, "episode": 139.0, "batch_reward": 0.5296842649579048, "critic_loss": 1.9502107659578323, "actor_loss": -78.53071296691894, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.98568558692932, "step": 139000}
{"episode_reward": 817.8267426400357, "episode": 140.0, "batch_reward": 0.5303503440320492, "critic_loss": 1.9468860026597976, "actor_loss": -79.3525340423584, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.324819326400757, "step": 140000}
{"episode_reward": 892.6937077953539, "episode": 141.0, "batch_reward": 0.5329466772973538, "critic_loss": 1.8882683488726615, "actor_loss": -80.6323755722046, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 40.67898106575012, "step": 141000}
{"episode_reward": 824.7473080057849, "episode": 142.0, "batch_reward": 0.5351279938817024, "critic_loss": 1.889686252295971, "actor_loss": -80.01663128662109, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.531580686569214, "step": 142000}
{"episode_reward": 867.8277695834823, "episode": 143.0, "batch_reward": 0.5384243104457855, "critic_loss": 1.9415903568863868, "actor_loss": -81.0797511138916, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.50200080871582, "step": 143000}
{"episode_reward": 915.113105959921, "episode": 144.0, "batch_reward": 0.5419843287467957, "critic_loss": 2.001141909837723, "actor_loss": -80.50474751281739, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.515453577041626, "step": 144000}
{"episode_reward": 867.9938538969335, "episode": 145.0, "batch_reward": 0.5447739912569523, "critic_loss": 1.9676902409791945, "actor_loss": -82.00491375732422, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.48264217376709, "step": 145000}
{"episode_reward": 870.4137907439571, "episode": 146.0, "batch_reward": 0.5449769615530967, "critic_loss": 2.038580471873283, "actor_loss": -80.14888259887695, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.113476991653442, "step": 146000}
{"episode_reward": 946.7017903330209, "episode": 147.0, "batch_reward": 0.5480655378997326, "critic_loss": 2.0115008238554, "actor_loss": -81.14840243530273, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.08501672744751, "step": 147000}
{"episode_reward": 883.0926923125419, "episode": 148.0, "batch_reward": 0.5509782804548741, "critic_loss": 1.9040309387445449, "actor_loss": -81.58024787902832, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.772859811782837, "step": 148000}
{"episode_reward": 898.750672970639, "episode": 149.0, "batch_reward": 0.5512278436720371, "critic_loss": 1.8944314023852349, "actor_loss": -81.27247792053222, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.847251415252686, "step": 149000}
{"episode_reward": 864.5405367966779, "episode": 150.0, "batch_reward": 0.5563608511984348, "critic_loss": 1.8526526666283607, "actor_loss": -81.40075108337402, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "step": 150000}
