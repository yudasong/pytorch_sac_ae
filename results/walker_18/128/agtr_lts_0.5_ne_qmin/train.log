{"episode_reward": 0.0, "episode": 1.0, "duration": 21.035815238952637, "step": 1000}
{"episode_reward": 27.46298806610516, "episode": 2.0, "duration": 1.825819492340088, "step": 2000}
{"episode_reward": 489.1100087318934, "episode": 3.0, "batch_reward": 0.26662245644216104, "critic_loss": 0.5997950496843315, "actor_loss": -83.76728804314695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 60.309725284576416, "step": 3000}
{"episode_reward": 430.3606864360367, "episode": 4.0, "batch_reward": 0.291161332026124, "critic_loss": 0.9038381533026695, "actor_loss": -84.47217778015137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.139073848724365, "step": 4000}
{"episode_reward": 118.29714524065706, "episode": 5.0, "batch_reward": 0.28691309940814974, "critic_loss": 0.8658501757085323, "actor_loss": -83.39930438232422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.179080724716187, "step": 5000}
{"episode_reward": 480.35679557326876, "episode": 6.0, "batch_reward": 0.3271230115145445, "critic_loss": 0.9588291618824005, "actor_loss": -83.45357527160644, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17130184173584, "step": 6000}
{"episode_reward": 525.5851220930489, "episode": 7.0, "batch_reward": 0.35196190559864043, "critic_loss": 0.8890216097235679, "actor_loss": -83.50124186706543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19676160812378, "step": 7000}
{"episode_reward": 305.71864203722504, "episode": 8.0, "batch_reward": 0.3511087483167648, "critic_loss": 0.8050258577764035, "actor_loss": -83.0268129119873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.177433729171753, "step": 8000}
{"episode_reward": 539.2166428246186, "episode": 9.0, "batch_reward": 0.3752984627485275, "critic_loss": 0.7914957538247108, "actor_loss": -82.5437865447998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.191239833831787, "step": 9000}
{"episode_reward": 593.8390539695225, "episode": 10.0, "batch_reward": 0.4038062823116779, "critic_loss": 0.7201374993920326, "actor_loss": -82.41619792175293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.184316873550415, "step": 10000}
{"episode_reward": 637.9241633539044, "episode": 11.0, "batch_reward": 0.41982275268435476, "critic_loss": 0.8054757863283157, "actor_loss": -81.5345405883789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.90578866004944, "step": 11000}
{"episode_reward": 553.7645418576006, "episode": 12.0, "batch_reward": 0.4172740321159363, "critic_loss": 0.7898913749158383, "actor_loss": -81.14422264099122, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.136563777923584, "step": 12000}
{"episode_reward": 127.75806132493383, "episode": 13.0, "batch_reward": 0.40534495308995244, "critic_loss": 0.7644955772459507, "actor_loss": -79.68099467468262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.153997898101807, "step": 13000}
{"episode_reward": 513.5490131177, "episode": 14.0, "batch_reward": 0.41241189047694204, "critic_loss": 0.9594671284556389, "actor_loss": -79.2392120513916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15506148338318, "step": 14000}
{"episode_reward": 442.6921454390521, "episode": 15.0, "batch_reward": 0.4175445768237114, "critic_loss": 1.037373127758503, "actor_loss": -78.6393130493164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.162024974822998, "step": 15000}
{"episode_reward": 515.352113855113, "episode": 16.0, "batch_reward": 0.4143360968530178, "critic_loss": 1.196852253317833, "actor_loss": -78.81220736694335, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16305899620056, "step": 16000}
{"episode_reward": 191.6077000169781, "episode": 17.0, "batch_reward": 0.4096971568465233, "critic_loss": 1.2994971585273742, "actor_loss": -77.89677117919922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19907784461975, "step": 17000}
{"episode_reward": 534.6327270726542, "episode": 18.0, "batch_reward": 0.4152973023056984, "critic_loss": 1.4593893919587135, "actor_loss": -78.20162602233887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.168185710906982, "step": 18000}
{"episode_reward": 376.89050838224284, "episode": 19.0, "batch_reward": 0.40899624252319333, "critic_loss": 1.4451928569674493, "actor_loss": -76.98704402160645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19896101951599, "step": 19000}
{"episode_reward": 276.31473194050875, "episode": 20.0, "batch_reward": 0.403167476862669, "critic_loss": 1.524530607044697, "actor_loss": -77.01163600158691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.173337936401367, "step": 20000}
{"episode_reward": 249.26508160910765, "episode": 21.0, "batch_reward": 0.3967301106750965, "critic_loss": 1.572774167895317, "actor_loss": -75.67145022583007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.8814537525177, "step": 21000}
{"episode_reward": 337.5054197738412, "episode": 22.0, "batch_reward": 0.3990372759699822, "critic_loss": 1.606706150829792, "actor_loss": -76.23395244598389, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.167449474334717, "step": 22000}
{"episode_reward": 642.795438176982, "episode": 23.0, "batch_reward": 0.40574212101101875, "critic_loss": 1.6786071130633353, "actor_loss": -75.15841679382324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16045641899109, "step": 23000}
{"episode_reward": 524.6921577269084, "episode": 24.0, "batch_reward": 0.4119614033997059, "critic_loss": 1.8052597327828408, "actor_loss": -74.50177670288086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.129101991653442, "step": 24000}
{"episode_reward": 589.3674229424639, "episode": 25.0, "batch_reward": 0.42362758484482765, "critic_loss": 1.7593292795419693, "actor_loss": -75.89707774353028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.11893081665039, "step": 25000}
{"episode_reward": 662.8456638277535, "episode": 26.0, "batch_reward": 0.4268214247226715, "critic_loss": 1.8691220473051071, "actor_loss": -74.7412269821167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.152942180633545, "step": 26000}
{"episode_reward": 524.8105245292915, "episode": 27.0, "batch_reward": 0.43538881251215933, "critic_loss": 1.9018741927146912, "actor_loss": -74.97756728363036, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15790581703186, "step": 27000}
{"episode_reward": 642.9077498509117, "episode": 28.0, "batch_reward": 0.442935202986002, "critic_loss": 1.789420456826687, "actor_loss": -75.68053674316407, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20764183998108, "step": 28000}
{"episode_reward": 601.1869302671279, "episode": 29.0, "batch_reward": 0.4494604979455471, "critic_loss": 1.8849887578487396, "actor_loss": -75.3804582824707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17554020881653, "step": 29000}
{"episode_reward": 696.491946206132, "episode": 30.0, "batch_reward": 0.4574950235188007, "critic_loss": 1.7125794125199318, "actor_loss": -74.9888550491333, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18389582633972, "step": 30000}
{"episode_reward": 765.9002352503666, "episode": 31.0, "batch_reward": 0.46563283079862594, "critic_loss": 1.6488064178824424, "actor_loss": -76.60717256164551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.97645568847656, "step": 31000}
{"episode_reward": 612.6082721985205, "episode": 32.0, "batch_reward": 0.4741339187026024, "critic_loss": 1.607571917116642, "actor_loss": -75.732431098938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.165750741958618, "step": 32000}
{"episode_reward": 721.700713026014, "episode": 33.0, "batch_reward": 0.4806472364962101, "critic_loss": 1.5365839365124703, "actor_loss": -76.18722001647949, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.137524843215942, "step": 33000}
{"episode_reward": 791.3591323010908, "episode": 34.0, "batch_reward": 0.4905738714337349, "critic_loss": 1.5843654842376709, "actor_loss": -76.34686875152588, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.136364221572876, "step": 34000}
{"episode_reward": 698.1698883190319, "episode": 35.0, "batch_reward": 0.4951158983707428, "critic_loss": 1.6519547019600869, "actor_loss": -75.47188214874268, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.200364112854004, "step": 35000}
{"episode_reward": 724.048549012077, "episode": 36.0, "batch_reward": 0.5003290270864964, "critic_loss": 1.6326558651328087, "actor_loss": -76.66013917541504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.137662410736084, "step": 36000}
{"episode_reward": 565.5925191907052, "episode": 37.0, "batch_reward": 0.5053559419512749, "critic_loss": 1.7001681671738624, "actor_loss": -76.10505944824219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.14862823486328, "step": 37000}
{"episode_reward": 725.6865415726777, "episode": 38.0, "batch_reward": 0.5083777499198914, "critic_loss": 1.7621589230298995, "actor_loss": -75.69082703399658, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.129005670547485, "step": 38000}
{"episode_reward": 712.5566941328804, "episode": 39.0, "batch_reward": 0.514062073647976, "critic_loss": 1.8478876991271973, "actor_loss": -76.51279276275635, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.448006868362427, "step": 39000}
{"episode_reward": 632.232427015893, "episode": 40.0, "batch_reward": 0.517715164065361, "critic_loss": 1.9063797032833099, "actor_loss": -77.59555238342286, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.160433530807495, "step": 40000}
{"episode_reward": 809.1510046586415, "episode": 41.0, "batch_reward": 0.5245439402759076, "critic_loss": 1.89846850502491, "actor_loss": -77.1862819442749, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.888861894607544, "step": 41000}
{"episode_reward": 769.8100763346034, "episode": 42.0, "batch_reward": 0.5319389150142669, "critic_loss": 1.9203297308683396, "actor_loss": -76.76529899597168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.14462900161743, "step": 42000}
{"episode_reward": 888.4424248763827, "episode": 43.0, "batch_reward": 0.5387113654911518, "critic_loss": 1.9775693340301514, "actor_loss": -77.43383183288574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.131930112838745, "step": 43000}
{"episode_reward": 852.3295205330378, "episode": 44.0, "batch_reward": 0.5458544939756393, "critic_loss": 2.0441288093328476, "actor_loss": -76.85240631103515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.1436185836792, "step": 44000}
{"episode_reward": 512.5393264962704, "episode": 45.0, "batch_reward": 0.5418343523442746, "critic_loss": 2.046754989385605, "actor_loss": -76.30823747253417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.14232635498047, "step": 45000}
{"episode_reward": 260.97432298219144, "episode": 46.0, "batch_reward": 0.5377416374981403, "critic_loss": 2.1436372759342195, "actor_loss": -76.4834818725586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.12256360054016, "step": 46000}
{"episode_reward": 763.0333154013466, "episode": 47.0, "batch_reward": 0.5453232094049454, "critic_loss": 2.22501812851429, "actor_loss": -76.83512212371826, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.163596153259277, "step": 47000}
{"episode_reward": 673.5723606723008, "episode": 48.0, "batch_reward": 0.5449220122992993, "critic_loss": 2.3291081256866457, "actor_loss": -76.35454243469238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19989252090454, "step": 48000}
{"episode_reward": 759.7203964270902, "episode": 49.0, "batch_reward": 0.5506006154417992, "critic_loss": 2.4307017629146577, "actor_loss": -76.71201965332031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17369818687439, "step": 49000}
{"episode_reward": 622.86241065467, "episode": 50.0, "batch_reward": 0.5546974773406983, "critic_loss": 2.670286192893982, "actor_loss": -77.11504095458984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.171102285385132, "step": 50000}
{"episode_reward": 908.7584705583535, "episode": 51.0, "batch_reward": 0.5629981985390187, "critic_loss": 3.3374785717725755, "actor_loss": -78.18702008056641, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.89317727088928, "step": 51000}
{"episode_reward": 927.8824842930798, "episode": 52.0, "batch_reward": 0.5678988279402256, "critic_loss": 4.022808942317963, "actor_loss": -78.60530683898926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.165542364120483, "step": 52000}
{"episode_reward": 852.2115786443911, "episode": 53.0, "batch_reward": 0.5739326671659947, "critic_loss": 4.669532114744187, "actor_loss": -79.94383554077149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.1806538105011, "step": 53000}
{"episode_reward": 904.1146459454287, "episode": 54.0, "batch_reward": 0.5796127327382564, "critic_loss": 5.0524515426158905, "actor_loss": -80.50197045898437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.210727214813232, "step": 54000}
{"episode_reward": 817.7074205991221, "episode": 55.0, "batch_reward": 0.5835373139083385, "critic_loss": 4.946795102357864, "actor_loss": -81.54956684875488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.176669120788574, "step": 55000}
{"episode_reward": 670.1209798035309, "episode": 56.0, "batch_reward": 0.5827148281633854, "critic_loss": 3.9472544190883636, "actor_loss": -82.18309129333497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.1481990814209, "step": 56000}
{"episode_reward": 591.017296249564, "episode": 57.0, "batch_reward": 0.5842768414318562, "critic_loss": 3.3662944105863573, "actor_loss": -81.92123712158204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.143264532089233, "step": 57000}
{"episode_reward": 554.0367307930233, "episode": 58.0, "batch_reward": 0.5826481885015965, "critic_loss": 3.0901374435424804, "actor_loss": -82.14206497192383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.150083780288696, "step": 58000}
{"episode_reward": 592.3817973445681, "episode": 59.0, "batch_reward": 0.5848805824518204, "critic_loss": 2.9896803179979323, "actor_loss": -82.2974736328125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.158954858779907, "step": 59000}
{"episode_reward": 533.5607252101444, "episode": 60.0, "batch_reward": 0.5812149513363838, "critic_loss": 3.0416019814014437, "actor_loss": -82.13105108642579, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.168094396591187, "step": 60000}
{"episode_reward": 265.9242362799161, "episode": 61.0, "batch_reward": 0.5735315780937672, "critic_loss": 3.0205061271190643, "actor_loss": -81.79948643493653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.99106979370117, "step": 61000}
{"episode_reward": 353.4874142243872, "episode": 62.0, "batch_reward": 0.5740400050580502, "critic_loss": 3.107843045711517, "actor_loss": -81.40053361511231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.190690279006958, "step": 62000}
{"episode_reward": 565.0392626650998, "episode": 63.0, "batch_reward": 0.5742316301763057, "critic_loss": 3.168027922987938, "actor_loss": -82.215306930542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15663504600525, "step": 63000}
{"episode_reward": 705.1912096841145, "episode": 64.0, "batch_reward": 0.5756364372372628, "critic_loss": 3.2127579990625383, "actor_loss": -82.84918969726563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.147282123565674, "step": 64000}
{"episode_reward": 800.323040118147, "episode": 65.0, "batch_reward": 0.5813687829375267, "critic_loss": 3.279772152900696, "actor_loss": -82.59046026611328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.461217403411865, "step": 65000}
{"episode_reward": 880.138438912471, "episode": 66.0, "batch_reward": 0.5866862299144268, "critic_loss": 3.27777832365036, "actor_loss": -82.89976879882812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.182127237319946, "step": 66000}
{"episode_reward": 891.3443682098034, "episode": 67.0, "batch_reward": 0.5872617458403111, "critic_loss": 3.3356425876617433, "actor_loss": -82.80621383666993, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17512059211731, "step": 67000}
{"episode_reward": 844.7515105160145, "episode": 68.0, "batch_reward": 0.5941315133571625, "critic_loss": 3.267206743478775, "actor_loss": -83.96254444885254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.156018018722534, "step": 68000}
{"episode_reward": 956.8316733883639, "episode": 69.0, "batch_reward": 0.6006736999154091, "critic_loss": 3.267367014169693, "actor_loss": -83.81055491638183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.14002227783203, "step": 69000}
{"episode_reward": 864.8959291264181, "episode": 70.0, "batch_reward": 0.6041414991617203, "critic_loss": 2.9496215127706527, "actor_loss": -83.99308183288574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.138925552368164, "step": 70000}
{"episode_reward": 941.6061882411773, "episode": 71.0, "batch_reward": 0.6098569375872612, "critic_loss": 2.6912399154901503, "actor_loss": -84.45762725830077, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.90309929847717, "step": 71000}
{"episode_reward": 934.0189891256584, "episode": 72.0, "batch_reward": 0.6110404531359672, "critic_loss": 2.4756183062791823, "actor_loss": -84.92868699645996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.14058828353882, "step": 72000}
{"episode_reward": 812.067895961358, "episode": 73.0, "batch_reward": 0.6153500992655754, "critic_loss": 2.2517642123699186, "actor_loss": -85.03883787536621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.159356594085693, "step": 73000}
{"episode_reward": 925.4845972490895, "episode": 74.0, "batch_reward": 0.6193802509903907, "critic_loss": 2.034972005844116, "actor_loss": -85.46282963562011, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.162556171417236, "step": 74000}
{"episode_reward": 915.4237127293462, "episode": 75.0, "batch_reward": 0.6244515553712845, "critic_loss": 1.9297241864800454, "actor_loss": -85.90539309692383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15258550643921, "step": 75000}
{"episode_reward": 887.0026603546397, "episode": 76.0, "batch_reward": 0.627196758210659, "critic_loss": 1.9005967149734497, "actor_loss": -85.91793885803223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.139974117279053, "step": 76000}
{"episode_reward": 870.2983563005517, "episode": 77.0, "batch_reward": 0.6297159301638603, "critic_loss": 1.9226466925740242, "actor_loss": -85.78775450134277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.143093585968018, "step": 77000}
{"episode_reward": 903.8024943738147, "episode": 78.0, "batch_reward": 0.6344428498148919, "critic_loss": 2.012679298520088, "actor_loss": -86.00137490844726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18216061592102, "step": 78000}
{"episode_reward": 949.7284153405755, "episode": 79.0, "batch_reward": 0.6377180398702621, "critic_loss": 2.054682637095451, "actor_loss": -86.49734233093261, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.144159078598022, "step": 79000}
{"episode_reward": 921.8776136136704, "episode": 80.0, "batch_reward": 0.6417437120079994, "critic_loss": 2.04264581489563, "actor_loss": -86.50350868225098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.147329807281494, "step": 80000}
{"episode_reward": 915.5648795323787, "episode": 81.0, "batch_reward": 0.6451783387064933, "critic_loss": 2.054741603136063, "actor_loss": -86.63549420166015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.95348787307739, "step": 81000}
{"episode_reward": 898.7858239446161, "episode": 82.0, "batch_reward": 0.6478422766327858, "critic_loss": 2.149261922836304, "actor_loss": -86.87684799194336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.14543080329895, "step": 82000}
{"episode_reward": 874.2351197307684, "episode": 83.0, "batch_reward": 0.6509609621167183, "critic_loss": 2.1880726588964463, "actor_loss": -86.72219993591308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.142380952835083, "step": 83000}
{"episode_reward": 859.5181616114127, "episode": 84.0, "batch_reward": 0.6528579983711242, "critic_loss": 2.275163046956062, "actor_loss": -87.05044592285157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17401671409607, "step": 84000}
{"episode_reward": 888.1115447963314, "episode": 85.0, "batch_reward": 0.6569861015081405, "critic_loss": 2.2776388459801673, "actor_loss": -87.24485325622558, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.199135780334473, "step": 85000}
{"episode_reward": 892.4323411905551, "episode": 86.0, "batch_reward": 0.656591472685337, "critic_loss": 2.4541494371891024, "actor_loss": -87.05537921142579, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.189515352249146, "step": 86000}
{"episode_reward": 914.8233167856633, "episode": 87.0, "batch_reward": 0.6619486021995544, "critic_loss": 2.6456516890525816, "actor_loss": -87.38601419067383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18287944793701, "step": 87000}
{"episode_reward": 838.503372302895, "episode": 88.0, "batch_reward": 0.6633288041949272, "critic_loss": 2.563786477923393, "actor_loss": -87.29505046081543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17430877685547, "step": 88000}
{"episode_reward": 746.4194953794633, "episode": 89.0, "batch_reward": 0.663292715728283, "critic_loss": 2.2630360360145567, "actor_loss": -87.43563766479492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.1517596244812, "step": 89000}
{"episode_reward": 727.9345009675304, "episode": 90.0, "batch_reward": 0.6659828636646271, "critic_loss": 2.0105928107500075, "actor_loss": -87.46472627258301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.152488470077515, "step": 90000}
{"episode_reward": 809.1752650135462, "episode": 91.0, "batch_reward": 0.664827576816082, "critic_loss": 2.0403168209791183, "actor_loss": -87.30088092041015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.93121695518494, "step": 91000}
{"episode_reward": 838.537716536917, "episode": 92.0, "batch_reward": 0.6690443209409713, "critic_loss": 1.9345723273158073, "actor_loss": -86.91803848266602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.138468265533447, "step": 92000}
{"episode_reward": 958.5109252522748, "episode": 93.0, "batch_reward": 0.6713249981403351, "critic_loss": 1.7892895820736885, "actor_loss": -87.36801292419433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.131585121154785, "step": 93000}
{"episode_reward": 919.6485804997003, "episode": 94.0, "batch_reward": 0.6752045638561249, "critic_loss": 1.7674499464631082, "actor_loss": -87.22841166687012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.152726650238037, "step": 94000}
{"episode_reward": 925.6598908179456, "episode": 95.0, "batch_reward": 0.6761879718899727, "critic_loss": 1.710819049179554, "actor_loss": -87.83296536254883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.154991149902344, "step": 95000}
{"episode_reward": 919.965477783115, "episode": 96.0, "batch_reward": 0.6805724402070046, "critic_loss": 1.652195034146309, "actor_loss": -87.26934037780762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15220284461975, "step": 96000}
{"episode_reward": 941.4980539465965, "episode": 97.0, "batch_reward": 0.6813544788956643, "critic_loss": 1.6433014728426933, "actor_loss": -87.86554048156738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.127965688705444, "step": 97000}
{"episode_reward": 894.7374282180249, "episode": 98.0, "batch_reward": 0.6868592277765274, "critic_loss": 1.5956917722821236, "actor_loss": -88.0958197631836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.140571117401123, "step": 98000}
{"episode_reward": 909.0953435838712, "episode": 99.0, "batch_reward": 0.6860216009616852, "critic_loss": 1.6303624738454818, "actor_loss": -88.0134486694336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.186447620391846, "step": 99000}
{"episode_reward": 957.2791834148596, "episode": 100.0, "batch_reward": 0.6882083174586296, "critic_loss": 1.6460464588403703, "actor_loss": -87.9654940185547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.167545080184937, "step": 100000}
{"episode_reward": 939.2108021096217, "episode": 101.0, "batch_reward": 0.6923333973288536, "critic_loss": 1.5999628794193268, "actor_loss": -87.91356918334961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.91375946998596, "step": 101000}
{"episode_reward": 937.1122234929962, "episode": 102.0, "batch_reward": 0.6948924040794373, "critic_loss": 1.6232575173974038, "actor_loss": -88.32304586791992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.142934799194336, "step": 102000}
{"episode_reward": 906.2698463360801, "episode": 103.0, "batch_reward": 0.6963946679234505, "critic_loss": 1.6225058325529098, "actor_loss": -88.1885178527832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.145740032196045, "step": 103000}
{"episode_reward": 959.292757821784, "episode": 104.0, "batch_reward": 0.6999751572012901, "critic_loss": 1.5831593366265297, "actor_loss": -88.77115185546874, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17924952507019, "step": 104000}
{"episode_reward": 950.2262027946889, "episode": 105.0, "batch_reward": 0.7010576489567757, "critic_loss": 1.5165433628559113, "actor_loss": -88.49315057373047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.205628395080566, "step": 105000}
{"episode_reward": 952.6914063671611, "episode": 106.0, "batch_reward": 0.7047157482504844, "critic_loss": 1.4636126720309257, "actor_loss": -88.94993287658691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.137190580368042, "step": 106000}
{"episode_reward": 968.098329603194, "episode": 107.0, "batch_reward": 0.7059708784222603, "critic_loss": 1.4258128455281258, "actor_loss": -89.22808641052247, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.14120864868164, "step": 107000}
{"episode_reward": 934.7612175250991, "episode": 108.0, "batch_reward": 0.7089170305728912, "critic_loss": 1.4364962977170945, "actor_loss": -89.12040327453613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15450406074524, "step": 108000}
{"episode_reward": 973.2540215189892, "episode": 109.0, "batch_reward": 0.7129338137507438, "critic_loss": 1.4444319415092468, "actor_loss": -89.31449974060058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.164633750915527, "step": 109000}
{"episode_reward": 920.1642764205764, "episode": 110.0, "batch_reward": 0.7145207847952842, "critic_loss": 1.443446035385132, "actor_loss": -89.41304286193848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.144529104232788, "step": 110000}
{"episode_reward": 954.5007333680122, "episode": 111.0, "batch_reward": 0.7148452921509743, "critic_loss": 1.4395304321050644, "actor_loss": -89.20249723815918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.90855431556702, "step": 111000}
{"episode_reward": 866.1204258162206, "episode": 112.0, "batch_reward": 0.7157313235402107, "critic_loss": 1.379068479180336, "actor_loss": -89.39648497009277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.194955825805664, "step": 112000}
{"episode_reward": 919.6474048382465, "episode": 113.0, "batch_reward": 0.7180776855945588, "critic_loss": 1.3404761870503425, "actor_loss": -89.29630352783204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.22243309020996, "step": 113000}
{"episode_reward": 918.1293195697823, "episode": 114.0, "batch_reward": 0.7207043234109879, "critic_loss": 1.2932497951984405, "actor_loss": -89.533310836792, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.192164182662964, "step": 114000}
{"episode_reward": 945.5577161714851, "episode": 115.0, "batch_reward": 0.7230492646098137, "critic_loss": 1.3179685752987862, "actor_loss": -89.98613189697265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.1705961227417, "step": 115000}
{"episode_reward": 956.2135636636485, "episode": 116.0, "batch_reward": 0.7239225463867187, "critic_loss": 1.3286629906892777, "actor_loss": -89.80360606384278, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17561960220337, "step": 116000}
{"episode_reward": 896.0856021413942, "episode": 117.0, "batch_reward": 0.7244137402176857, "critic_loss": 1.35402606767416, "actor_loss": -89.94992805480958, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.174937963485718, "step": 117000}
{"episode_reward": 847.4141985793407, "episode": 118.0, "batch_reward": 0.7265222229957581, "critic_loss": 1.343060556292534, "actor_loss": -89.77948532104492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19371795654297, "step": 118000}
{"episode_reward": 907.7922562871188, "episode": 119.0, "batch_reward": 0.727800099670887, "critic_loss": 1.3477701520323753, "actor_loss": -89.89645600891113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.183598041534424, "step": 119000}
{"episode_reward": 941.017394078868, "episode": 120.0, "batch_reward": 0.729170741379261, "critic_loss": 1.2542785460352897, "actor_loss": -90.12965420532227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18383502960205, "step": 120000}
{"episode_reward": 957.919017864094, "episode": 121.0, "batch_reward": 0.7325046536326408, "critic_loss": 1.2310201032161712, "actor_loss": -90.08578616333008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.9782829284668, "step": 121000}
{"episode_reward": 949.138468967612, "episode": 122.0, "batch_reward": 0.7343783513307571, "critic_loss": 1.270457329750061, "actor_loss": -90.3844501953125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.195111989974976, "step": 122000}
{"episode_reward": 924.6583311546568, "episode": 123.0, "batch_reward": 0.7351720430850983, "critic_loss": 1.255282564997673, "actor_loss": -90.38287495422364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17818570137024, "step": 123000}
{"episode_reward": 874.3659014492179, "episode": 124.0, "batch_reward": 0.7355592853426933, "critic_loss": 1.3028162803649903, "actor_loss": -90.24488459777832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.194020986557007, "step": 124000}
{"episode_reward": 966.8268585356052, "episode": 125.0, "batch_reward": 0.7384351459741593, "critic_loss": 1.2759437145590782, "actor_loss": -90.28296836853028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.202462196350098, "step": 125000}
{"episode_reward": 925.2618807132926, "episode": 126.0, "batch_reward": 0.7390323539376259, "critic_loss": 1.2359785938858985, "actor_loss": -90.3756060333252, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.178980350494385, "step": 126000}
{"episode_reward": 935.0879826460921, "episode": 127.0, "batch_reward": 0.74069258248806, "critic_loss": 1.2056675235629082, "actor_loss": -90.3814994354248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.205175399780273, "step": 127000}
{"episode_reward": 954.593673688229, "episode": 128.0, "batch_reward": 0.7429301607012748, "critic_loss": 1.258829361796379, "actor_loss": -90.19627317810058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.215274572372437, "step": 128000}
{"episode_reward": 976.0479340606751, "episode": 129.0, "batch_reward": 0.7450576983690261, "critic_loss": 1.205375960469246, "actor_loss": -90.31584776306153, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.220175981521606, "step": 129000}
{"episode_reward": 919.1165570221652, "episode": 130.0, "batch_reward": 0.7452026781439781, "critic_loss": 1.2718163275122643, "actor_loss": -90.41685034179687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.176199674606323, "step": 130000}
{"episode_reward": 826.6282703894539, "episode": 131.0, "batch_reward": 0.7465718669891357, "critic_loss": 1.2554223630428314, "actor_loss": -90.01967335510254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.95866656303406, "step": 131000}
{"episode_reward": 876.6232349229275, "episode": 132.0, "batch_reward": 0.7465515609383583, "critic_loss": 1.235169152021408, "actor_loss": -90.2967501373291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.212935209274292, "step": 132000}
{"episode_reward": 919.402797000111, "episode": 133.0, "batch_reward": 0.7458515318632126, "critic_loss": 1.252813794016838, "actor_loss": -90.28174029541016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.209805250167847, "step": 133000}
{"episode_reward": 868.5712395679326, "episode": 134.0, "batch_reward": 0.7482233836054802, "critic_loss": 1.2453068330287933, "actor_loss": -90.40666519165039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.196328163146973, "step": 134000}
{"episode_reward": 807.0247455824253, "episode": 135.0, "batch_reward": 0.7495899381041526, "critic_loss": 1.3010233387947083, "actor_loss": -90.62689207458496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.174968004226685, "step": 135000}
{"episode_reward": 946.8681634625437, "episode": 136.0, "batch_reward": 0.7508021426796914, "critic_loss": 1.2918889709711074, "actor_loss": -90.6529162902832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.194756746292114, "step": 136000}
{"episode_reward": 851.3117259140964, "episode": 137.0, "batch_reward": 0.7528840364217758, "critic_loss": 1.281312069952488, "actor_loss": -90.34871623229981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21912169456482, "step": 137000}
{"episode_reward": 927.7980340784569, "episode": 138.0, "batch_reward": 0.7541850769519806, "critic_loss": 1.2971040893793107, "actor_loss": -90.34524374389649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.214176893234253, "step": 138000}
{"episode_reward": 952.3536186688518, "episode": 139.0, "batch_reward": 0.7548682972192764, "critic_loss": 1.2934183120727538, "actor_loss": -90.30279194641113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21725583076477, "step": 139000}
{"episode_reward": 876.0114277998109, "episode": 140.0, "batch_reward": 0.7553206282258034, "critic_loss": 1.2775398158431053, "actor_loss": -90.40318165588378, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.212719678878784, "step": 140000}
{"episode_reward": 947.1004071869146, "episode": 141.0, "batch_reward": 0.7563806616067886, "critic_loss": 1.2691340994238853, "actor_loss": -90.81449745178223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.94412183761597, "step": 141000}
{"episode_reward": 968.937247419587, "episode": 142.0, "batch_reward": 0.7578175846338272, "critic_loss": 1.2920711064338684, "actor_loss": -90.57090396118164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21649408340454, "step": 142000}
{"episode_reward": 902.1845950941745, "episode": 143.0, "batch_reward": 0.7605464492440224, "critic_loss": 1.312307707309723, "actor_loss": -90.98715441894531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.201321363449097, "step": 143000}
{"episode_reward": 943.429777187244, "episode": 144.0, "batch_reward": 0.7622638406157494, "critic_loss": 1.309473236143589, "actor_loss": -90.84109300231934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.182074785232544, "step": 144000}
{"episode_reward": 914.4735665597665, "episode": 145.0, "batch_reward": 0.7626245849728585, "critic_loss": 1.2756110746264457, "actor_loss": -91.036580078125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18303394317627, "step": 145000}
{"episode_reward": 937.8601991354944, "episode": 146.0, "batch_reward": 0.76342582321167, "critic_loss": 1.2503472666740418, "actor_loss": -90.75522918701172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.165509700775146, "step": 146000}
{"episode_reward": 963.8909102667349, "episode": 147.0, "batch_reward": 0.7660295331478119, "critic_loss": 1.2419908156991004, "actor_loss": -91.05497329711915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.154828786849976, "step": 147000}
{"episode_reward": 935.5542681842569, "episode": 148.0, "batch_reward": 0.764614589869976, "critic_loss": 1.2020383873283864, "actor_loss": -90.9992546081543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19040012359619, "step": 148000}
{"episode_reward": 948.2610005896676, "episode": 149.0, "batch_reward": 0.7658927570581436, "critic_loss": 1.1927505575418473, "actor_loss": -90.90722898864746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20694661140442, "step": 149000}
{"episode_reward": 927.6153153428068, "episode": 150.0, "batch_reward": 0.7681614375114441, "critic_loss": 1.1811647390127182, "actor_loss": -91.04039985656738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
