{"episode_reward": 0.0, "episode": 1.0, "duration": 22.727177619934082, "step": 1000}
{"episode_reward": 27.46298806610516, "episode": 2.0, "duration": 1.941570520401001, "step": 2000}
{"episode_reward": 489.1100087318934, "episode": 3.0, "batch_reward": 0.2480135483467885, "critic_loss": 0.45260949307141524, "actor_loss": -81.74369998243438, "actor_target_entropy": -6.0, "alpha_value": 0.002134017781850189, "duration": 66.35243272781372, "step": 3000}
{"episode_reward": 96.76100604368172, "episode": 4.0, "batch_reward": 0.1829230587631464, "critic_loss": 0.46427015627920626, "actor_loss": -78.9380740814209, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.676558256149292, "step": 4000}
{"episode_reward": 56.82831408082069, "episode": 5.0, "batch_reward": 0.1524390305429697, "critic_loss": 0.41769704991579054, "actor_loss": -78.857736328125, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.05556058883667, "step": 5000}
{"episode_reward": 26.69237841186149, "episode": 6.0, "batch_reward": 0.13665710305422543, "critic_loss": 0.48222429248690607, "actor_loss": -78.60640850830079, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.681608200073242, "step": 6000}
{"episode_reward": 133.74015835488277, "episode": 7.0, "batch_reward": 0.13179065569490195, "critic_loss": 0.4528715214282274, "actor_loss": -77.60427561950684, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.513598918914795, "step": 7000}
{"episode_reward": 52.935861764078524, "episode": 8.0, "batch_reward": 0.12302627214044333, "critic_loss": 0.3871791578233242, "actor_loss": -77.4181354675293, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.168102741241455, "step": 8000}
{"episode_reward": 65.29606354172641, "episode": 9.0, "batch_reward": 0.12993867052346467, "critic_loss": 0.5024610809087753, "actor_loss": -76.66264710998536, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.436593532562256, "step": 9000}
{"episode_reward": 290.275406862132, "episode": 10.0, "batch_reward": 0.14806085715442896, "critic_loss": 0.49772886937856675, "actor_loss": -76.42679333496093, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.3637433052063, "step": 10000}
{"episode_reward": 403.62863144546685, "episode": 11.0, "batch_reward": 0.15886813708394765, "critic_loss": 0.39330292464792727, "actor_loss": -75.50106399536133, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.63690805435181, "step": 11000}
{"episode_reward": 68.67911692534146, "episode": 12.0, "batch_reward": 0.1621716835126281, "critic_loss": 0.36166082057356835, "actor_loss": -74.7987801361084, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.45409369468689, "step": 12000}
{"episode_reward": 338.66188655191945, "episode": 13.0, "batch_reward": 0.17560230232775212, "critic_loss": 0.364427331879735, "actor_loss": -73.62309678649902, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.38204288482666, "step": 13000}
{"episode_reward": 268.5453351187954, "episode": 14.0, "batch_reward": 0.18343945939838885, "critic_loss": 0.43614303451776504, "actor_loss": -73.25567611694336, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.04535746574402, "step": 14000}
{"episode_reward": 370.83956854022625, "episode": 15.0, "batch_reward": 0.20321328252553938, "critic_loss": 0.4893507110029459, "actor_loss": -72.12007828521729, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.015342950820923, "step": 15000}
{"episode_reward": 501.6523678204621, "episode": 16.0, "batch_reward": 0.21393411575257779, "critic_loss": 0.5584255090355873, "actor_loss": -71.55007305908204, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.860854864120483, "step": 16000}
{"episode_reward": 355.940619418828, "episode": 17.0, "batch_reward": 0.225518021941185, "critic_loss": 0.5681690236032009, "actor_loss": -71.31525820159912, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.798028469085693, "step": 17000}
{"episode_reward": 438.59303124177364, "episode": 18.0, "batch_reward": 0.23927430422604085, "critic_loss": 0.5965327754318714, "actor_loss": -71.58684127044678, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.83280372619629, "step": 18000}
{"episode_reward": 298.48225374407934, "episode": 19.0, "batch_reward": 0.24438398541510106, "critic_loss": 0.6175010556876659, "actor_loss": -70.34091138458253, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.175408601760864, "step": 19000}
{"episode_reward": 533.0724578453128, "episode": 20.0, "batch_reward": 0.2596106221675873, "critic_loss": 0.6290336012244224, "actor_loss": -70.46146654510498, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.362653970718384, "step": 20000}
{"episode_reward": 523.9496649010725, "episode": 21.0, "batch_reward": 0.2747191017717123, "critic_loss": 0.6269354670643806, "actor_loss": -70.06123763275147, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 47.419106006622314, "step": 21000}
{"episode_reward": 538.7620553025185, "episode": 22.0, "batch_reward": 0.2835360097885132, "critic_loss": 0.5932628481090069, "actor_loss": -69.90405142974853, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 25.67338514328003, "step": 22000}
{"episode_reward": 515.6287636606708, "episode": 23.0, "batch_reward": 0.29462666882574556, "critic_loss": 0.617849074870348, "actor_loss": -69.21973081207275, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.879020929336548, "step": 23000}
{"episode_reward": 521.3784561898588, "episode": 24.0, "batch_reward": 0.30664805944263934, "critic_loss": 0.6268039176166058, "actor_loss": -68.33422839355468, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.8912935256958, "step": 24000}
{"episode_reward": 510.06410911794717, "episode": 25.0, "batch_reward": 0.31052053317427636, "critic_loss": 0.6603056038618088, "actor_loss": -69.36619146728516, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.782376050949097, "step": 25000}
{"episode_reward": 291.1555075345925, "episode": 26.0, "batch_reward": 0.31078416502475736, "critic_loss": 0.6619199596941471, "actor_loss": -68.17699539184571, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.23473024368286, "step": 26000}
{"episode_reward": 304.339246126067, "episode": 27.0, "batch_reward": 0.3085754418373108, "critic_loss": 0.7003111488819123, "actor_loss": -67.4620096282959, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.874481678009033, "step": 27000}
{"episode_reward": 271.4916924748537, "episode": 28.0, "batch_reward": 0.30782065811753273, "critic_loss": 0.7460246879458428, "actor_loss": -67.96752897644043, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.693888187408447, "step": 28000}
{"episode_reward": 348.7019310448278, "episode": 29.0, "batch_reward": 0.3096810283362865, "critic_loss": 0.8317744673788547, "actor_loss": -66.82652069854737, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.03649377822876, "step": 29000}
{"episode_reward": 418.437188133099, "episode": 30.0, "batch_reward": 0.3147393855750561, "critic_loss": 0.9048020821809769, "actor_loss": -66.38288844299316, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.51380944252014, "step": 30000}
{"episode_reward": 375.9014417255255, "episode": 31.0, "batch_reward": 0.315435984402895, "critic_loss": 0.89292777633667, "actor_loss": -67.7103482208252, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.43983268737793, "step": 31000}
{"episode_reward": 406.18728424834154, "episode": 32.0, "batch_reward": 0.32195145608484743, "critic_loss": 0.9369242953360081, "actor_loss": -66.14228582000733, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.99895715713501, "step": 32000}
{"episode_reward": 624.8949963142546, "episode": 33.0, "batch_reward": 0.3317125045955181, "critic_loss": 0.9652494552135468, "actor_loss": -66.22765399169921, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.608535528182983, "step": 33000}
{"episode_reward": 643.1504802834588, "episode": 34.0, "batch_reward": 0.3404063488543034, "critic_loss": 0.9468408477902412, "actor_loss": -66.855482421875, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.957926988601685, "step": 34000}
{"episode_reward": 632.391970115805, "episode": 35.0, "batch_reward": 0.3497454195022583, "critic_loss": 0.946374164879322, "actor_loss": -66.07917780303956, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.123647928237915, "step": 35000}
{"episode_reward": 622.8901699889965, "episode": 36.0, "batch_reward": 0.35812595933675767, "critic_loss": 0.9540862533152104, "actor_loss": -66.85969757843017, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.0304274559021, "step": 36000}
{"episode_reward": 656.4768262443065, "episode": 37.0, "batch_reward": 0.36466790598630905, "critic_loss": 0.9898313956260681, "actor_loss": -66.08304850769044, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.852949857711792, "step": 37000}
{"episode_reward": 329.9891611141514, "episode": 38.0, "batch_reward": 0.360928535670042, "critic_loss": 0.9992513082027435, "actor_loss": -66.0144609527588, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 26.24440026283264, "step": 38000}
{"episode_reward": 440.8069576148201, "episode": 39.0, "batch_reward": 0.36500911888480186, "critic_loss": 1.0232492788434029, "actor_loss": -66.6386861038208, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 25.27279305458069, "step": 39000}
{"episode_reward": 555.7391186802732, "episode": 40.0, "batch_reward": 0.37056901344656945, "critic_loss": 1.043308369755745, "actor_loss": -67.85585266876221, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.797580242156982, "step": 40000}
{"episode_reward": 569.0839781436864, "episode": 41.0, "batch_reward": 0.3747425291240215, "critic_loss": 1.1180438914895057, "actor_loss": -67.05915878295899, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 44.13078474998474, "step": 41000}
{"episode_reward": 619.5061057280093, "episode": 42.0, "batch_reward": 0.38254711094498633, "critic_loss": 1.1557835099697114, "actor_loss": -67.20962461090087, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 25.16510558128357, "step": 42000}
{"episode_reward": 660.3581120824217, "episode": 43.0, "batch_reward": 0.3879404642879963, "critic_loss": 1.139906027853489, "actor_loss": -67.54619190216064, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.50032329559326, "step": 43000}
{"episode_reward": 634.2680817275331, "episode": 44.0, "batch_reward": 0.3945429126620293, "critic_loss": 1.1284387520551682, "actor_loss": -66.97571518707275, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.5205500125885, "step": 44000}
{"episode_reward": 646.2113788273588, "episode": 45.0, "batch_reward": 0.40038498646020887, "critic_loss": 1.102121155142784, "actor_loss": -66.04122525024414, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.407103538513184, "step": 45000}
{"episode_reward": 648.2337589812813, "episode": 46.0, "batch_reward": 0.40483542227745056, "critic_loss": 1.0710767655968667, "actor_loss": -65.89551945495606, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.4392249584198, "step": 46000}
{"episode_reward": 599.0352066032165, "episode": 47.0, "batch_reward": 0.40830742952227594, "critic_loss": 1.0813486224412918, "actor_loss": -67.79011516571045, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.94804096221924, "step": 47000}
{"episode_reward": 569.7424661474647, "episode": 48.0, "batch_reward": 0.41134384968876836, "critic_loss": 1.0788708083629608, "actor_loss": -67.15459089660645, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.20930790901184, "step": 48000}
{"episode_reward": 512.4136171548768, "episode": 49.0, "batch_reward": 0.41514399588108064, "critic_loss": 1.0764391471147536, "actor_loss": -67.68609224700927, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.35052514076233, "step": 49000}
{"episode_reward": 654.1461204052314, "episode": 50.0, "batch_reward": 0.41974334874749186, "critic_loss": 1.06280504655838, "actor_loss": -67.47255307006836, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.04419732093811, "step": 50000}
{"episode_reward": 718.6317509679876, "episode": 51.0, "batch_reward": 0.4256381990909576, "critic_loss": 1.0323654450774193, "actor_loss": -67.64005870819092, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 47.25006985664368, "step": 51000}
{"episode_reward": 734.9855987018258, "episode": 52.0, "batch_reward": 0.4344797563254833, "critic_loss": 1.0829971329569816, "actor_loss": -67.45370193481445, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.661428928375244, "step": 52000}
{"episode_reward": 770.6233303142686, "episode": 53.0, "batch_reward": 0.4384420683681965, "critic_loss": 1.0405498862862588, "actor_loss": -68.97991268920899, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.295783758163452, "step": 53000}
{"episode_reward": 773.1351625757003, "episode": 54.0, "batch_reward": 0.44481749430298806, "critic_loss": 1.043778840303421, "actor_loss": -68.6459386138916, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.843209743499756, "step": 54000}
{"episode_reward": 721.536529524595, "episode": 55.0, "batch_reward": 0.4506633488237858, "critic_loss": 1.0506193271279336, "actor_loss": -68.87835451507569, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.173396587371826, "step": 55000}
{"episode_reward": 759.5189936626813, "episode": 56.0, "batch_reward": 0.45628423935174944, "critic_loss": 1.0531091998815536, "actor_loss": -69.51249015808105, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.2157084941864, "step": 56000}
{"episode_reward": 757.2877817145429, "episode": 57.0, "batch_reward": 0.4604125580489635, "critic_loss": 1.095704697906971, "actor_loss": -69.29734462738037, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.068480014801025, "step": 57000}
{"episode_reward": 766.8884778992183, "episode": 58.0, "batch_reward": 0.4655818099677563, "critic_loss": 1.1114323464632034, "actor_loss": -70.0553549118042, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.7167387008667, "step": 58000}
{"episode_reward": 704.8958088866007, "episode": 59.0, "batch_reward": 0.47140892547369, "critic_loss": 1.1402397564053535, "actor_loss": -70.18901468658447, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.871992588043213, "step": 59000}
{"episode_reward": 800.472164037145, "episode": 60.0, "batch_reward": 0.4776210258603096, "critic_loss": 1.1386113035678864, "actor_loss": -69.3336037979126, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.136649131774902, "step": 60000}
{"episode_reward": 885.3082974102161, "episode": 61.0, "batch_reward": 0.4815800701081753, "critic_loss": 1.1250656372904777, "actor_loss": -70.17759590148925, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.25452017784119, "step": 61000}
{"episode_reward": 809.1506567612562, "episode": 62.0, "batch_reward": 0.4890491336286068, "critic_loss": 1.1520356904268265, "actor_loss": -69.14717665100098, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.808887720108032, "step": 62000}
{"episode_reward": 841.8102247587718, "episode": 63.0, "batch_reward": 0.494802693516016, "critic_loss": 1.1728740857243538, "actor_loss": -70.30575308990478, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.73748207092285, "step": 63000}
{"episode_reward": 775.004337605509, "episode": 64.0, "batch_reward": 0.4989066886007786, "critic_loss": 1.1977834082841874, "actor_loss": -71.80490016937256, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.049481868743896, "step": 64000}
{"episode_reward": 751.6121528418238, "episode": 65.0, "batch_reward": 0.5022333157360553, "critic_loss": 1.2401569074392318, "actor_loss": -70.70629776763916, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.615864753723145, "step": 65000}
{"episode_reward": 865.4222117390722, "episode": 66.0, "batch_reward": 0.5087936147153378, "critic_loss": 1.2652231006026269, "actor_loss": -71.52426051330566, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.855304479599, "step": 66000}
{"episode_reward": 844.1315748053113, "episode": 67.0, "batch_reward": 0.5122963247597218, "critic_loss": 1.239903124988079, "actor_loss": -71.54963974761962, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.083889961242676, "step": 67000}
{"episode_reward": 853.0277259595543, "episode": 68.0, "batch_reward": 0.5185655323266983, "critic_loss": 1.2434342777729035, "actor_loss": -73.22813537597656, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.329633235931396, "step": 68000}
{"episode_reward": 865.717995123619, "episode": 69.0, "batch_reward": 0.5254158320128918, "critic_loss": 1.2418514411449433, "actor_loss": -72.42103868103027, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.841415405273438, "step": 69000}
{"episode_reward": 843.7741679440633, "episode": 70.0, "batch_reward": 0.5285370002388954, "critic_loss": 1.2455201446413995, "actor_loss": -72.36555615234376, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.001623153686523, "step": 70000}
{"episode_reward": 804.112959853261, "episode": 71.0, "batch_reward": 0.5339672611653805, "critic_loss": 1.2637848529219626, "actor_loss": -72.67791387176514, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 43.398059129714966, "step": 71000}
{"episode_reward": 844.4045144190686, "episode": 72.0, "batch_reward": 0.5355500522851944, "critic_loss": 1.2653130441904068, "actor_loss": -73.3141333770752, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.973249435424805, "step": 72000}
{"episode_reward": 822.7646200490167, "episode": 73.0, "batch_reward": 0.5425574991703034, "critic_loss": 1.2994651302099227, "actor_loss": -74.10880577087403, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.10910439491272, "step": 73000}
{"episode_reward": 856.5990199784388, "episode": 74.0, "batch_reward": 0.544147723376751, "critic_loss": 1.2848672304749489, "actor_loss": -74.30166454315186, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.61113405227661, "step": 74000}
{"episode_reward": 818.5772170969791, "episode": 75.0, "batch_reward": 0.5486895170807838, "critic_loss": 1.3392157258987427, "actor_loss": -75.41834775543212, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.09546136856079, "step": 75000}
{"episode_reward": 858.822753098304, "episode": 76.0, "batch_reward": 0.5542420663535595, "critic_loss": 1.27869170075655, "actor_loss": -76.15900338745118, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.809528827667236, "step": 76000}
{"episode_reward": 868.9155645260389, "episode": 77.0, "batch_reward": 0.5571449591815472, "critic_loss": 1.2929108991622924, "actor_loss": -75.9155791015625, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.49557852745056, "step": 77000}
{"episode_reward": 824.8582384773761, "episode": 78.0, "batch_reward": 0.5600282935202122, "critic_loss": 1.300495561659336, "actor_loss": -75.8523380432129, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.318873167037964, "step": 78000}
{"episode_reward": 732.8808391325341, "episode": 79.0, "batch_reward": 0.5635018376111984, "critic_loss": 1.3208759189844133, "actor_loss": -76.46742445373535, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.13145661354065, "step": 79000}
{"episode_reward": 789.4347065632046, "episode": 80.0, "batch_reward": 0.5655300903618335, "critic_loss": 1.3080926492214202, "actor_loss": -76.57226713562012, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.26519513130188, "step": 80000}
{"episode_reward": 910.6953425938013, "episode": 81.0, "batch_reward": 0.5705452181100845, "critic_loss": 1.2994293925762177, "actor_loss": -77.03744612121582, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 43.58710241317749, "step": 81000}
{"episode_reward": 897.7564239679755, "episode": 82.0, "batch_reward": 0.5731270470023155, "critic_loss": 1.3189560642242433, "actor_loss": -77.86411477661133, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.37822127342224, "step": 82000}
{"episode_reward": 854.6406391649393, "episode": 83.0, "batch_reward": 0.5772686048746108, "critic_loss": 1.322765327990055, "actor_loss": -76.91238438415527, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.35722279548645, "step": 83000}
{"episode_reward": 776.1956916735852, "episode": 84.0, "batch_reward": 0.5792406252622604, "critic_loss": 1.377582979440689, "actor_loss": -77.89221769714355, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.627328872680664, "step": 84000}
{"episode_reward": 891.0318558201607, "episode": 85.0, "batch_reward": 0.5824869551956654, "critic_loss": 1.3847624757289887, "actor_loss": -78.14492811584472, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.33107089996338, "step": 85000}
{"episode_reward": 860.9766981447152, "episode": 86.0, "batch_reward": 0.5868214581906795, "critic_loss": 1.3813054285049438, "actor_loss": -78.34921182250977, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.133578300476074, "step": 86000}
{"episode_reward": 823.6378894332161, "episode": 87.0, "batch_reward": 0.5888650238513946, "critic_loss": 1.4154485629796982, "actor_loss": -78.63583395385743, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.032265663146973, "step": 87000}
{"episode_reward": 767.4614932774006, "episode": 88.0, "batch_reward": 0.5903015624880791, "critic_loss": 1.368594934463501, "actor_loss": -78.6368440246582, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.883469581604004, "step": 88000}
{"episode_reward": 869.4514999642518, "episode": 89.0, "batch_reward": 0.5930614959001541, "critic_loss": 1.3735324077606201, "actor_loss": -79.16542964172363, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.40285348892212, "step": 89000}
{"episode_reward": 788.9012893497123, "episode": 90.0, "batch_reward": 0.595603504896164, "critic_loss": 1.383335181593895, "actor_loss": -79.69124014282227, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.88923478126526, "step": 90000}
{"episode_reward": 848.9638402026133, "episode": 91.0, "batch_reward": 0.5987792484164238, "critic_loss": 1.3656889196038247, "actor_loss": -79.83179327392578, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 44.234633922576904, "step": 91000}
{"episode_reward": 872.2304698780723, "episode": 92.0, "batch_reward": 0.6002044702172279, "critic_loss": 1.3692558142542839, "actor_loss": -79.30114727783203, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.11596393585205, "step": 92000}
{"episode_reward": 777.7455642827812, "episode": 93.0, "batch_reward": 0.604265391945839, "critic_loss": 1.3805860069394111, "actor_loss": -80.33572229003906, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.423515558242798, "step": 93000}
{"episode_reward": 836.2945517927574, "episode": 94.0, "batch_reward": 0.6072950191497802, "critic_loss": 1.312270319223404, "actor_loss": -80.22464305114747, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.00778865814209, "step": 94000}
{"episode_reward": 868.2203547450416, "episode": 95.0, "batch_reward": 0.6066520544886589, "critic_loss": 1.3126911704540252, "actor_loss": -81.46403367614747, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.63362741470337, "step": 95000}
{"episode_reward": 796.1550413865594, "episode": 96.0, "batch_reward": 0.6124263333082199, "critic_loss": 1.2467207480669023, "actor_loss": -80.8167320098877, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.46373224258423, "step": 96000}
{"episode_reward": 887.1138640372226, "episode": 97.0, "batch_reward": 0.6130063446164131, "critic_loss": 1.2777097012996674, "actor_loss": -81.89903860473633, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.613788843154907, "step": 97000}
{"episode_reward": 804.2959779287523, "episode": 98.0, "batch_reward": 0.617581361591816, "critic_loss": 1.2759985620379448, "actor_loss": -82.42023193359375, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.98465895652771, "step": 98000}
{"episode_reward": 805.0977086043288, "episode": 99.0, "batch_reward": 0.6166368988156319, "critic_loss": 1.2612209920287132, "actor_loss": -81.89090307617188, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.40104031562805, "step": 99000}
{"episode_reward": 851.9475983843947, "episode": 100.0, "batch_reward": 0.6204900468587875, "critic_loss": 1.2200053265690805, "actor_loss": -81.96587103271484, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.328627109527588, "step": 100000}
{"episode_reward": 885.8546401353922, "episode": 101.0, "batch_reward": 0.6222161052823066, "critic_loss": 1.2152818422317504, "actor_loss": -82.13398983764648, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.916027307510376, "step": 101000}
{"episode_reward": 405.7521919784599, "episode": 102.0, "batch_reward": 0.6207503477334976, "critic_loss": 1.1947579809427262, "actor_loss": -82.60530049133301, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.78484058380127, "step": 102000}
{"episode_reward": 895.5376560723332, "episode": 103.0, "batch_reward": 0.6246436589956283, "critic_loss": 1.206694709956646, "actor_loss": -82.32946009826661, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.373358488082886, "step": 103000}
{"episode_reward": 878.2482301786606, "episode": 104.0, "batch_reward": 0.6261372898221016, "critic_loss": 1.2071824768781663, "actor_loss": -83.05119779968261, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.663905382156372, "step": 104000}
{"episode_reward": 519.6388653643791, "episode": 105.0, "batch_reward": 0.625086367726326, "critic_loss": 1.1872405406832696, "actor_loss": -82.52136689758301, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.532832860946655, "step": 105000}
{"episode_reward": 947.3445841405015, "episode": 106.0, "batch_reward": 0.6289734105467797, "critic_loss": 1.2151834415197373, "actor_loss": -82.76230563354493, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.116766214370728, "step": 106000}
{"episode_reward": 887.6977600077695, "episode": 107.0, "batch_reward": 0.6304719517230988, "critic_loss": 1.227559831380844, "actor_loss": -83.09771865844726, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.271698713302612, "step": 107000}
{"episode_reward": 846.6748087800765, "episode": 108.0, "batch_reward": 0.6317106935977935, "critic_loss": 1.1950186753869056, "actor_loss": -83.18489169311523, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.74016499519348, "step": 108000}
{"episode_reward": 894.7964212416397, "episode": 109.0, "batch_reward": 0.635619008898735, "critic_loss": 1.1959739326238632, "actor_loss": -83.64606425476074, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.450337171554565, "step": 109000}
{"episode_reward": 899.9445748611176, "episode": 110.0, "batch_reward": 0.6374676885604859, "critic_loss": 1.1858357034921647, "actor_loss": -83.74116296386718, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.227943420410156, "step": 110000}
{"episode_reward": 881.6329848757478, "episode": 111.0, "batch_reward": 0.6404816948771477, "critic_loss": 1.1815361798107624, "actor_loss": -83.36919288635254, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 43.53013253211975, "step": 111000}
{"episode_reward": 883.2879640387077, "episode": 112.0, "batch_reward": 0.6418374738097191, "critic_loss": 1.188249805867672, "actor_loss": -83.55245097351074, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.110281705856323, "step": 112000}
{"episode_reward": 897.1772577304101, "episode": 113.0, "batch_reward": 0.644694017469883, "critic_loss": 1.193231544673443, "actor_loss": -83.36042002868652, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.303510427474976, "step": 113000}
{"episode_reward": 792.7022229089002, "episode": 114.0, "batch_reward": 0.6458422400951386, "critic_loss": 1.1920449050068855, "actor_loss": -84.0422453918457, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.2682101726532, "step": 114000}
{"episode_reward": 873.4970203160256, "episode": 115.0, "batch_reward": 0.6470619350075721, "critic_loss": 1.1665352732241154, "actor_loss": -84.66105561828613, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.565370082855225, "step": 115000}
{"episode_reward": 824.770045999782, "episode": 116.0, "batch_reward": 0.6481166272163391, "critic_loss": 1.2160682365298272, "actor_loss": -84.41247528076173, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.28321146965027, "step": 116000}
{"episode_reward": 789.6438973910574, "episode": 117.0, "batch_reward": 0.6501217672228813, "critic_loss": 1.210928749203682, "actor_loss": -84.23360479736328, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.428864002227783, "step": 117000}
{"episode_reward": 787.0852229645649, "episode": 118.0, "batch_reward": 0.6526572450399398, "critic_loss": 1.2715416093468666, "actor_loss": -84.0364861755371, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.073451280593872, "step": 118000}
{"episode_reward": 865.1103631034058, "episode": 119.0, "batch_reward": 0.6529632883667946, "critic_loss": 1.2763483272194862, "actor_loss": -84.07056936645508, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.505572080612183, "step": 119000}
{"episode_reward": 898.155713456678, "episode": 120.0, "batch_reward": 0.6555403102636337, "critic_loss": 1.3053123782277107, "actor_loss": -84.73408689880371, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.296684980392456, "step": 120000}
{"episode_reward": 899.326009677622, "episode": 121.0, "batch_reward": 0.6581346551775933, "critic_loss": 1.2939584862589837, "actor_loss": -84.47094131469727, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 46.427797079086304, "step": 121000}
{"episode_reward": 900.3786525466662, "episode": 122.0, "batch_reward": 0.6594047943353653, "critic_loss": 1.3132115687727928, "actor_loss": -85.17228807067872, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.86091661453247, "step": 122000}
{"episode_reward": 883.3766005686751, "episode": 123.0, "batch_reward": 0.6605362192988395, "critic_loss": 1.3297000308036804, "actor_loss": -85.38384288024902, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.363104820251465, "step": 123000}
{"episode_reward": 826.953869134194, "episode": 124.0, "batch_reward": 0.6618985838294029, "critic_loss": 1.3829021388888358, "actor_loss": -85.0706707611084, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.12419033050537, "step": 124000}
{"episode_reward": 926.2861978000738, "episode": 125.0, "batch_reward": 0.6655907229185104, "critic_loss": 1.343542663872242, "actor_loss": -85.01177383422852, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.383246898651123, "step": 125000}
{"episode_reward": 839.6519011892656, "episode": 126.0, "batch_reward": 0.6651373371481896, "critic_loss": 1.3682449890971184, "actor_loss": -84.94821556091308, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.795552730560303, "step": 126000}
{"episode_reward": 894.769524942631, "episode": 127.0, "batch_reward": 0.6684624795913696, "critic_loss": 1.344753413259983, "actor_loss": -85.27105944824218, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.662253856658936, "step": 127000}
{"episode_reward": 882.4484429544888, "episode": 128.0, "batch_reward": 0.6692706850767136, "critic_loss": 1.3195776997804642, "actor_loss": -85.01813998413085, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.800562143325806, "step": 128000}
{"episode_reward": 933.1722002781797, "episode": 129.0, "batch_reward": 0.6719776943325997, "critic_loss": 1.304363239645958, "actor_loss": -85.19125935363769, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.54074740409851, "step": 129000}
{"episode_reward": 883.6438707896755, "episode": 130.0, "batch_reward": 0.6741608743667602, "critic_loss": 1.2918702629208565, "actor_loss": -85.61334132385254, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.725440502166748, "step": 130000}
{"episode_reward": 813.3175136452361, "episode": 131.0, "batch_reward": 0.6742989581823349, "critic_loss": 1.2599205605387687, "actor_loss": -84.93853839111328, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.11920738220215, "step": 131000}
{"episode_reward": 842.2086634385898, "episode": 132.0, "batch_reward": 0.6740512981414795, "critic_loss": 1.221591977417469, "actor_loss": -85.38745974731445, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.28779363632202, "step": 132000}
{"episode_reward": 891.8371304067058, "episode": 133.0, "batch_reward": 0.6748299746513367, "critic_loss": 1.2588582825660706, "actor_loss": -85.65848526000977, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.560882091522217, "step": 133000}
{"episode_reward": 762.5237684266216, "episode": 134.0, "batch_reward": 0.6773039402961731, "critic_loss": 1.2576040180921555, "actor_loss": -85.84698750305176, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.188557624816895, "step": 134000}
{"episode_reward": 786.7107400674477, "episode": 135.0, "batch_reward": 0.6778905263543129, "critic_loss": 1.2299822781682015, "actor_loss": -86.0780517578125, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.059065103530884, "step": 135000}
{"episode_reward": 913.352398789961, "episode": 136.0, "batch_reward": 0.6797892986536026, "critic_loss": 1.2166577528715135, "actor_loss": -86.22100891113281, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.055792808532715, "step": 136000}
{"episode_reward": 788.1366367480307, "episode": 137.0, "batch_reward": 0.6816126857995987, "critic_loss": 1.1822164649367333, "actor_loss": -86.24632899475098, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.45402455329895, "step": 137000}
{"episode_reward": 943.2397146733833, "episode": 138.0, "batch_reward": 0.683825430393219, "critic_loss": 1.1342484650611877, "actor_loss": -86.00513375854493, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.891802549362183, "step": 138000}
{"episode_reward": 913.1149685758139, "episode": 139.0, "batch_reward": 0.6841806482672691, "critic_loss": 1.0935547152459622, "actor_loss": -85.93646617126466, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.277628183364868, "step": 139000}
{"episode_reward": 832.8204245007731, "episode": 140.0, "batch_reward": 0.6852671469449997, "critic_loss": 1.0662983109354973, "actor_loss": -85.84253656005859, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.81414222717285, "step": 140000}
{"episode_reward": 913.6337636633875, "episode": 141.0, "batch_reward": 0.6870179709792137, "critic_loss": 1.0471468446552754, "actor_loss": -86.51234837341309, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 45.85173749923706, "step": 141000}
{"episode_reward": 925.2621219454519, "episode": 142.0, "batch_reward": 0.6887915537357331, "critic_loss": 1.0493326355814934, "actor_loss": -86.54706414794921, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.148524284362793, "step": 142000}
{"episode_reward": 862.203500511845, "episode": 143.0, "batch_reward": 0.6904824131131172, "critic_loss": 1.0466762932240963, "actor_loss": -86.82158961486816, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.61735200881958, "step": 143000}
{"episode_reward": 925.7562651405875, "episode": 144.0, "batch_reward": 0.6920038413405418, "critic_loss": 1.0747582574784755, "actor_loss": -86.42328221130371, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.4216148853302, "step": 144000}
{"episode_reward": 837.4954717551375, "episode": 145.0, "batch_reward": 0.6934055072069168, "critic_loss": 1.07215739646554, "actor_loss": -87.01463737487794, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.004205226898193, "step": 145000}
{"episode_reward": 913.3823836552114, "episode": 146.0, "batch_reward": 0.6955028440356255, "critic_loss": 1.0760428504049777, "actor_loss": -86.45550856018066, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.126312255859375, "step": 146000}
{"episode_reward": 916.8079091993362, "episode": 147.0, "batch_reward": 0.6962529075145721, "critic_loss": 1.064026484489441, "actor_loss": -86.8150877532959, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.869208335876465, "step": 147000}
{"episode_reward": 859.2496020936911, "episode": 148.0, "batch_reward": 0.6968706072568893, "critic_loss": 1.07103829652071, "actor_loss": -86.72039276123047, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.908239364624023, "step": 148000}
{"episode_reward": 934.9785647089352, "episode": 149.0, "batch_reward": 0.696659081697464, "critic_loss": 1.1092855029106141, "actor_loss": -86.64103163146973, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.752898931503296, "step": 149000}
{"episode_reward": 786.311140540499, "episode": 150.0, "batch_reward": 0.6992889859080315, "critic_loss": 1.0637585415244102, "actor_loss": -86.86176887512207, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "step": 150000}
