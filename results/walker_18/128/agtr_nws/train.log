{"episode": 1.0, "duration": 21.180031776428223, "episode_reward": 27.46298806610516, "step": 1000}
{"episode": 2.0, "duration": 1.8872382640838623, "episode_reward": 489.1100087318934, "step": 2000}
{"episode": 3.0, "batch_reward": 0.24357975236810656, "actor_loss": -85.35889531536644, "actor_target_entropy": -6.0, "alpha_value": 0.002134017781850189, "duration": 48.38164567947388, "episode_reward": 38.39444110278543, "step": 3000}
{"episode": 4.0, "batch_reward": 0.16631142012774944, "actor_loss": -81.55780633544921, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.092897176742554, "episode_reward": 36.093919874758434, "step": 4000}
{"episode": 5.0, "batch_reward": 0.14250867926329375, "actor_loss": -80.7378600769043, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.293195009231567, "episode_reward": 94.47907493555523, "step": 5000}
{"episode": 6.0, "batch_reward": 0.12794378700852393, "actor_loss": -79.80848788452148, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.675220727920532, "episode_reward": 32.96912842515303, "step": 6000}
{"episode": 7.0, "batch_reward": 0.11320357159525156, "actor_loss": -79.681505859375, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.859755516052246, "episode_reward": 26.546891652217642, "step": 7000}
{"episode": 8.0, "batch_reward": 0.10021693475916982, "actor_loss": -79.4220849456787, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.314037084579468, "episode_reward": 13.7435688931146, "step": 8000}
{"episode": 9.0, "batch_reward": 0.09414242830127478, "actor_loss": -78.89380229187012, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.403092861175537, "episode_reward": 60.666700680944196, "step": 9000}
{"episode": 10.0, "batch_reward": 0.08778008854389191, "actor_loss": -73.44335536193847, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 3923.8130435943604, "episode_reward": 25.57773723115887, "step": 10000}
{"episode": 11.0, "batch_reward": 0.08116925502941012, "actor_loss": -72.84315756225585, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 36.92015504837036, "episode_reward": 14.55083299658717, "step": 11000}
{"episode": 12.0, "batch_reward": 0.07738166284188629, "actor_loss": -70.91591697692871, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 431.2214283943176, "episode_reward": 24.403033019896515, "step": 12000}
{"episode": 13.0, "batch_reward": 0.07227198277786374, "actor_loss": -71.50146015930176, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.753379821777344, "episode_reward": 24.49512746622358, "step": 13000}
{"episode": 14.0, "batch_reward": 0.06752344894409179, "actor_loss": -70.94636701965332, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 425.8592281341553, "episode_reward": 24.47533567509297, "step": 14000}
{"episode": 15.0, "batch_reward": 0.06565111298114061, "actor_loss": -71.60610731506348, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.801782846450806, "episode_reward": 25.11566541059757, "step": 15000}
{"episode": 16.0, "batch_reward": 0.06237838792800903, "actor_loss": -71.66015531921387, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 432.7004590034485, "episode_reward": 24.71642356758277, "step": 16000}
{"episode": 17.0, "batch_reward": 0.06019589098356664, "actor_loss": -72.12073858642579, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.82807993888855, "episode_reward": 24.425091643641277, "step": 17000}
{"episode": 18.0, "batch_reward": 0.05818313289433718, "actor_loss": -71.64176599121093, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 422.5382454395294, "episode_reward": 24.70611435166297, "step": 18000}
{"episode": 19.0, "batch_reward": 0.05661665870063007, "actor_loss": -71.9485604095459, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.902592182159424, "episode_reward": 25.104117911789782, "step": 19000}
{"episode": 20.0, "batch_reward": 0.055550743617117405, "actor_loss": -71.39991011047363, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 429.8885147571564, "episode_reward": 26.4304383222086, "step": 20000}
{"episode": 21.0, "batch_reward": 0.05379979003965855, "actor_loss": -71.51546336364746, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 35.77554726600647, "episode_reward": 39.77232383181289, "step": 21000}
{"episode": 22.0, "batch_reward": 0.05269517081603408, "actor_loss": -70.82737574768066, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 424.6138253211975, "episode_reward": 23.588399516306787, "step": 22000}
{"episode": 23.0, "batch_reward": 0.05348820990324021, "actor_loss": -71.12340449523926, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.85701894760132, "episode_reward": 79.58829505739826, "step": 23000}
{"episode": 24.0, "batch_reward": 0.052746492696925995, "actor_loss": -70.67381539916992, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 429.8045325279236, "episode_reward": 24.161794360070076, "step": 24000}
{"episode": 25.0, "batch_reward": 0.05169982695952058, "actor_loss": -71.30428587341308, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 15.804947137832642, "episode_reward": 24.61282631395904, "step": 25000}
{"episode": 26.0, "batch_reward": 0.04990472690947354, "actor_loss": -71.31881309509278, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 430.1370499134064, "episode_reward": 31.06733480170081, "step": 26000}
{"episode": 27.0, "batch_reward": 0.05030063130520284, "actor_loss": -72.04261070251465, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.218234300613403, "episode_reward": 56.667113887737735, "step": 27000}
{"episode": 28.0, "batch_reward": 0.0508040322791785, "actor_loss": -71.40019076538086, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 424.09192276000977, "episode_reward": 99.09210226382267, "step": 28000}
{"episode": 29.0, "batch_reward": 0.05319391987286508, "actor_loss": -71.43513926696777, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.10844850540161, "episode_reward": 134.514961370295, "step": 29000}
{"episode": 30.0, "batch_reward": 0.056589599853381516, "actor_loss": -72.08257656860351, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 427.90440225601196, "episode_reward": 137.66038025874155, "step": 30000}
{"episode": 31.0, "batch_reward": 0.05875319868326187, "actor_loss": -72.22145877075195, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 40.785611152648926, "episode_reward": 107.91571265817173, "step": 31000}
{"episode": 32.0, "batch_reward": 0.059864333182573316, "actor_loss": -72.52193698120116, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 428.0284309387207, "episode_reward": 78.29076074372263, "step": 32000}
{"episode": 33.0, "batch_reward": 0.06147455167025328, "actor_loss": -72.45922424316406, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.871245622634888, "episode_reward": 114.26152479564313, "step": 33000}
{"episode": 34.0, "batch_reward": 0.06204027088731527, "actor_loss": -72.00985484313965, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 432.71535062789917, "episode_reward": 75.07739192064162, "step": 34000}
{"episode": 35.0, "batch_reward": 0.06221059109643102, "actor_loss": -71.76930334472657, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.96775197982788, "episode_reward": 75.77434692031078, "step": 35000}
{"episode": 36.0, "batch_reward": 0.06297388500347734, "actor_loss": -71.53924133300781, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 431.05777049064636, "episode_reward": 64.88064847501977, "step": 36000}
{"episode": 37.0, "batch_reward": 0.06413841603696346, "actor_loss": -71.50024407958985, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.961762189865112, "episode_reward": 159.7149847877531, "step": 37000}
{"episode": 38.0, "batch_reward": 0.06608472652733326, "actor_loss": -71.64121244812011, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 428.13012170791626, "episode_reward": 145.14162661445232, "step": 38000}
{"episode": 39.0, "batch_reward": 0.06712307078763842, "actor_loss": -71.55659654235839, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.136051177978516, "episode_reward": 70.9034388718033, "step": 39000}
{"episode": 40.0, "batch_reward": 0.06794681966304779, "actor_loss": -71.84230099487304, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 431.16117000579834, "episode_reward": 69.32127470824364, "step": 40000}
{"episode": 41.0, "batch_reward": 0.06717894169315695, "actor_loss": -71.77666404724121, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 37.40494251251221, "episode_reward": 59.84349977887024, "step": 41000}
{"episode": 42.0, "batch_reward": 0.06872646974399686, "actor_loss": -72.15568878173828, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 417.2518253326416, "episode_reward": 135.10247118953328, "step": 42000}
{"episode": 43.0, "batch_reward": 0.06950811253860593, "actor_loss": -72.19029850769043, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.11792826652527, "episode_reward": 130.89244957349175, "step": 43000}
{"episode": 44.0, "batch_reward": 0.07195366607233881, "actor_loss": -72.1532811126709, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 431.5812659263611, "episode_reward": 199.2487615031592, "step": 44000}
{"episode": 45.0, "batch_reward": 0.07419294657185674, "actor_loss": -72.23146237182617, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.294912576675415, "episode_reward": 150.61441040188868, "step": 45000}
{"episode": 46.0, "batch_reward": 0.0745963727273047, "actor_loss": -72.11679913330079, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 426.2492473125458, "episode_reward": 72.28049839120635, "step": 46000}
{"episode": 47.0, "batch_reward": 0.07490547434985638, "actor_loss": -72.15580499267578, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.02465844154358, "episode_reward": 69.38386234577105, "step": 47000}
{"episode": 48.0, "batch_reward": 0.07476273932680487, "actor_loss": -71.1485701751709, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 432.40860056877136, "episode_reward": 70.67201955541886, "step": 48000}
{"episode": 49.0, "batch_reward": 0.07661376614868641, "actor_loss": -71.15425770568848, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.994264841079712, "episode_reward": 232.90081301636224, "step": 49000}
{"episode": 50.0, "batch_reward": 0.07946187668666244, "actor_loss": -70.95304904174805, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 423.8189980983734, "episode_reward": 239.86354754338714, "step": 50000}
{"episode": 51.0, "batch_reward": 0.08082351667433978, "actor_loss": -70.98349186706542, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 39.75229787826538, "episode_reward": 72.98614594035807, "step": 51000}
{"episode": 52.0, "batch_reward": 0.08234228633716703, "actor_loss": -71.1046446685791, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 427.0985987186432, "episode_reward": 253.72458031170106, "step": 52000}
{"episode": 53.0, "batch_reward": 0.08341448127478361, "actor_loss": -71.16899311828614, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.560433864593506, "episode_reward": 63.07136729161298, "step": 53000}
{"episode": 54.0, "batch_reward": 0.08390920525789261, "actor_loss": -70.53635981750489, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 427.4709539413452, "episode_reward": 65.76140798572898, "step": 54000}
{"episode": 55.0, "batch_reward": 0.08453521076962352, "actor_loss": -70.67900053405762, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.658316612243652, "episode_reward": 156.39484681032036, "step": 55000}
{"episode": 56.0, "batch_reward": 0.0857014475800097, "actor_loss": -71.42034214782714, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 425.38093280792236, "episode_reward": 135.81273356921585, "step": 56000}
{"episode": 57.0, "batch_reward": 0.08678941169008612, "actor_loss": -71.47214482116699, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.104516983032227, "episode_reward": 126.81101447276706, "step": 57000}
{"episode": 58.0, "batch_reward": 0.08681887144595385, "actor_loss": -71.08577214050293, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 430.12262296676636, "episode_reward": 154.61297530352383, "step": 58000}
{"episode": 59.0, "batch_reward": 0.0886201174519956, "actor_loss": -71.02854321289063, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.056525945663452, "episode_reward": 180.3651863903842, "step": 59000}
{"episode": 60.0, "batch_reward": 0.08891291113570332, "actor_loss": -70.94958087158203, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 429.3705003261566, "episode_reward": 75.69490677378583, "step": 60000}
{"episode": 61.0, "batch_reward": 0.08936046179756522, "actor_loss": -70.89321472167968, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 37.72998809814453, "episode_reward": 64.45132665907501, "step": 61000}
{"episode": 62.0, "batch_reward": 0.0889614312686026, "actor_loss": -70.81604551696778, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 430.69031739234924, "episode_reward": 80.73495937305464, "step": 62000}
{"episode": 63.0, "batch_reward": 0.08895832759141922, "actor_loss": -70.71524438476563, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.01888871192932, "episode_reward": 67.62688984366766, "step": 63000}
{"episode": 64.0, "batch_reward": 0.08790857450664044, "actor_loss": -70.18896252441407, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 429.32672357559204, "episode_reward": 69.64839199190152, "step": 64000}
{"episode": 65.0, "batch_reward": 0.0876144024245441, "actor_loss": -70.12343644714356, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.265373468399048, "episode_reward": 68.74932859038118, "step": 65000}
{"episode": 66.0, "batch_reward": 0.08675252949073911, "actor_loss": -70.26237149047851, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 427.1280896663666, "episode_reward": 65.22963225480834, "step": 66000}
{"episode": 67.0, "batch_reward": 0.08739980294927954, "actor_loss": -70.30144166564942, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.999810934066772, "episode_reward": 74.619651904492, "step": 67000}
{"episode": 68.0, "batch_reward": 0.08771165530756116, "actor_loss": -70.85995510864258, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 429.0757019519806, "episode_reward": 89.46650630714714, "step": 68000}
{"episode": 69.0, "batch_reward": 0.08727181910723447, "actor_loss": -70.849191696167, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.087402820587158, "episode_reward": 87.09554301598396, "step": 69000}
{"episode": 70.0, "batch_reward": 0.08753130072355271, "actor_loss": -71.01955722045898, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 422.5935845375061, "episode_reward": 114.07580266249977, "step": 70000}
{"episode": 71.0, "batch_reward": 0.08788639218732715, "actor_loss": -71.15636529541015, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 37.53103423118591, "episode_reward": 91.09556215763195, "step": 71000}
{"episode": 72.0, "batch_reward": 0.08722587383538484, "actor_loss": -71.11246560668945, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 433.5763201713562, "episode_reward": 99.00700776487892, "step": 72000}
{"episode": 73.0, "batch_reward": 0.08920677886530758, "actor_loss": -71.22151989746094, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.384966611862183, "episode_reward": 252.04582098152326, "step": 73000}
{"episode": 74.0, "batch_reward": 0.09005267693474889, "actor_loss": -71.0368143157959, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 420.1621482372284, "episode_reward": 72.86488562505767, "step": 74000}
{"episode": 75.0, "batch_reward": 0.08976836395263672, "actor_loss": -71.05789463806153, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.7535240650177, "episode_reward": 70.39545751566136, "step": 75000}
{"episode": 76.0, "batch_reward": 0.08970002413541078, "actor_loss": -71.00071179199219, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 430.1971802711487, "episode_reward": 68.12172351186794, "step": 76000}
{"episode": 77.0, "batch_reward": 0.08919335040077567, "actor_loss": -71.0510290222168, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.600416660308838, "episode_reward": 98.56718077922798, "step": 77000}
{"episode": 78.0, "batch_reward": 0.09010396027937531, "actor_loss": -70.38703517150878, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 425.04939317703247, "episode_reward": 139.87943470693355, "step": 78000}
{"episode": 79.0, "batch_reward": 0.09072591388598085, "actor_loss": -70.41509646606445, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.047217845916748, "episode_reward": 87.89254464680845, "step": 79000}
{"episode": 80.0, "batch_reward": 0.09127961182221771, "actor_loss": -70.543310546875, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 429.16405177116394, "episode_reward": 137.9108451908108, "step": 80000}
{"episode": 81.0, "batch_reward": 0.09108432172611355, "actor_loss": -70.61141711425782, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 35.90237069129944, "episode_reward": 74.56895522201619, "step": 81000}
{"episode": 82.0, "batch_reward": 0.08878700545057655, "actor_loss": -70.55082736206055, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 427.7770571708679, "episode_reward": 4.238118420851416, "step": 82000}
{"episode": 83.0, "batch_reward": 0.08992833860963582, "actor_loss": -70.49942329406738, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.96088981628418, "episode_reward": 122.09002337139923, "step": 83000}
{"episode": 84.0, "batch_reward": 0.09062286698073149, "actor_loss": -70.47860256958008, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 425.596312046051, "episode_reward": 177.83927054041675, "step": 84000}
{"episode": 85.0, "batch_reward": 0.09055123868584633, "actor_loss": -70.50681098937989, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.498374938964844, "episode_reward": 75.19442743530259, "step": 85000}
{"episode": 86.0, "batch_reward": 0.09003316158801317, "actor_loss": -70.55743566894532, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 433.95869183540344, "episode_reward": 81.85281327695584, "step": 86000}
{"episode": 87.0, "batch_reward": 0.08996021939441562, "actor_loss": -70.6318281097412, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.263365268707275, "episode_reward": 85.02730466292088, "step": 87000}
{"episode": 88.0, "batch_reward": 0.09111982355639338, "actor_loss": -70.55847634887695, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 427.72752594947815, "episode_reward": 92.70581004383868, "step": 88000}
{"episode": 89.0, "batch_reward": 0.09013281730189919, "actor_loss": -70.62677021789551, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.866385459899902, "episode_reward": 76.5643400479947, "step": 89000}
{"episode": 90.0, "batch_reward": 0.09020839322730899, "actor_loss": -71.67537088012695, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 430.480263710022, "episode_reward": 82.6622119798234, "step": 90000}
{"episode": 91.0, "batch_reward": 0.09002844075486063, "actor_loss": -71.7132794342041, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 38.03304362297058, "episode_reward": 84.76531139011716, "step": 91000}
{"episode": 92.0, "batch_reward": 0.08918280658870935, "actor_loss": -70.47577836608886, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 420.60826897621155, "episode_reward": 78.0038900032666, "step": 92000}
{"episode": 93.0, "batch_reward": 0.08983009913563729, "actor_loss": -70.56083444213867, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.938618659973145, "episode_reward": 79.03055169186584, "step": 93000}
{"episode": 94.0, "batch_reward": 0.08983723170682788, "actor_loss": -71.22612886047364, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 432.983407497406, "episode_reward": 103.59750026152521, "step": 94000}
{"episode": 95.0, "batch_reward": 0.09079828571528197, "actor_loss": -71.21565225219726, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.241853952407837, "episode_reward": 251.66238492947534, "step": 95000}
{"episode": 96.0, "batch_reward": 0.09238257917761802, "actor_loss": -70.67865461730958, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 428.95559310913086, "episode_reward": 226.3250771614937, "step": 96000}
{"episode": 97.0, "batch_reward": 0.09301972986757755, "actor_loss": -70.73528793334961, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.458765506744385, "episode_reward": 239.9593973439888, "step": 97000}
{"episode": 98.0, "batch_reward": 0.0959484042711556, "actor_loss": -70.22851571655274, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 428.08183002471924, "episode_reward": 262.2077263831915, "step": 98000}
{"episode": 99.0, "batch_reward": 0.09747748693823814, "actor_loss": -70.27001434326172, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.08712935447693, "episode_reward": 185.85394023021502, "step": 99000}
{"episode": 100.0, "batch_reward": 0.09708501284569501, "actor_loss": -70.21646467590332, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 421.640469789505, "episode_reward": 97.69398402957222, "step": 100000}
{"episode": 101.0, "batch_reward": 0.09732192293927074, "actor_loss": -70.29080683898925, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.088178396224976, "episode_reward": 118.41835215758682, "step": 101000}
{"episode": 102.0, "batch_reward": 0.09726475986838341, "actor_loss": -70.85834884643555, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 426.57294607162476, "episode_reward": 90.90016922405684, "step": 102000}
{"episode": 103.0, "batch_reward": 0.09696351992338896, "actor_loss": -70.97725505065918, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 15.876057624816895, "episode_reward": 83.54524944256782, "step": 103000}
{"episode": 104.0, "batch_reward": 0.09693412996083497, "actor_loss": -71.30335189819336, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 430.6852948665619, "episode_reward": 82.53468676150464, "step": 104000}
{"episode": 105.0, "batch_reward": 0.09715588965266943, "actor_loss": -71.27680213928222, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.5817928314209, "episode_reward": 77.81891330765022, "step": 105000}
{"episode": 106.0, "batch_reward": 0.0976953983977437, "actor_loss": -71.25818209838867, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 430.0985507965088, "episode_reward": 140.8389325723427, "step": 106000}
{"episode": 107.0, "batch_reward": 0.09719454625621438, "actor_loss": -71.2886483001709, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.76977276802063, "episode_reward": 75.23684856657701, "step": 107000}
{"episode": 108.0, "batch_reward": 0.09611579217761755, "actor_loss": -70.87951091003418, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 429.12045097351074, "episode_reward": 72.07452941809463, "step": 108000}
{"episode": 109.0, "batch_reward": 0.09591036221385002, "actor_loss": -70.99082273864747, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.449977159500122, "episode_reward": 68.40293341477128, "step": 109000}
{"episode": 110.0, "batch_reward": 0.09636434578895568, "actor_loss": -70.94957656860352, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 428.1421797275543, "episode_reward": 66.46268072502396, "step": 110000}
{"episode": 111.0, "batch_reward": 0.09656529083847999, "actor_loss": -70.98603131103516, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 39.817339181900024, "episode_reward": 74.36738143112836, "step": 111000}
{"episode": 112.0, "batch_reward": 0.09625478684902192, "actor_loss": -70.96529710388184, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 431.6312267780304, "episode_reward": 104.74824414630037, "step": 112000}
{"episode": 113.0, "batch_reward": 0.09773369231075048, "actor_loss": -70.97994799804688, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.853460788726807, "episode_reward": 194.47552385794316, "step": 113000}
{"episode": 114.0, "batch_reward": 0.09745510244369507, "actor_loss": -70.43900273132324, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 427.82724261283875, "episode_reward": 92.41953050953046, "step": 114000}
{"episode": 115.0, "batch_reward": 0.09661678760498763, "actor_loss": -70.39154077148437, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.99250316619873, "episode_reward": 97.58440437264474, "step": 115000}
{"episode": 116.0, "batch_reward": 0.09802464241534471, "actor_loss": -70.55842372131347, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 426.86174869537354, "episode_reward": 366.3503476693692, "step": 116000}
{"episode": 117.0, "batch_reward": 0.09961439415812492, "actor_loss": -70.62212466430664, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.619446754455566, "episode_reward": 142.9633281872892, "step": 117000}
{"episode": 118.0, "batch_reward": 0.09998282054811716, "actor_loss": -68.65866893005371, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 429.4108724594116, "episode_reward": 89.30597143157095, "step": 118000}
{"episode": 119.0, "batch_reward": 0.09915944501757622, "actor_loss": -68.61121151733398, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.809226274490356, "episode_reward": 72.46597800032737, "step": 119000}
{"episode": 120.0, "batch_reward": 0.09900133619457484, "actor_loss": -68.56530863952636, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 426.8124165534973, "episode_reward": 74.49840450548166, "step": 120000}
{"episode": 121.0, "batch_reward": 0.09916321922838688, "actor_loss": -68.60949647521973, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 40.087382555007935, "episode_reward": 76.23109963853832, "step": 121000}
{"episode": 122.0, "batch_reward": 0.09890634873509407, "actor_loss": -67.69650326538085, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 431.76852321624756, "episode_reward": 75.61383128913435, "step": 122000}
{"episode": 123.0, "batch_reward": 0.10005124794691801, "actor_loss": -67.79950929260254, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.291382312774658, "episode_reward": 169.239019380912, "step": 123000}
{"episode": 124.0, "batch_reward": 0.09905742742866278, "actor_loss": -66.98652500915527, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 431.5396068096161, "episode_reward": 72.01111249676867, "step": 124000}
{"episode": 125.0, "batch_reward": 0.09930919567495584, "actor_loss": -66.94485597229004, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.944035291671753, "episode_reward": 67.76786404806639, "step": 125000}
{"episode": 126.0, "batch_reward": 0.09859316413849592, "actor_loss": -67.23489935302734, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 425.55207538604736, "episode_reward": 74.45895588559216, "step": 126000}
{"episode": 127.0, "batch_reward": 0.0987912929430604, "actor_loss": -67.30476385498046, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.05012273788452, "episode_reward": 111.68424430319673, "step": 127000}
{"episode": 128.0, "batch_reward": 0.09858193151652812, "actor_loss": -67.83093357849121, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 430.32006907463074, "episode_reward": 117.50964349817929, "step": 128000}
{"episode": 129.0, "batch_reward": 0.09871647822111845, "actor_loss": -67.83489793395997, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.963314533233643, "episode_reward": 93.21855241119746, "step": 129000}
{"episode": 130.0, "batch_reward": 0.09946040669083596, "actor_loss": -67.69242245483399, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 423.6595196723938, "episode_reward": 93.24186615285923, "step": 130000}
{"episode": 131.0, "batch_reward": 0.09925043703615666, "actor_loss": -67.71941348266601, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 37.420180559158325, "episode_reward": 72.84131503957614, "step": 131000}
{"episode": 132.0, "batch_reward": 0.09816003794968128, "actor_loss": -67.41673474121093, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 428.53826904296875, "episode_reward": 82.90470408752141, "step": 132000}
{"episode": 133.0, "batch_reward": 0.09914084427058696, "actor_loss": -67.43104608154297, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.61648440361023, "episode_reward": 156.158888434147, "step": 133000}
{"episode": 134.0, "batch_reward": 0.09953086701035499, "actor_loss": -67.60482968139648, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 426.26789355278015, "episode_reward": 92.51184031395769, "step": 134000}
{"episode": 135.0, "batch_reward": 0.09890846271812916, "actor_loss": -67.78944793701172, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.04249930381775, "episode_reward": 113.25575989789415, "step": 135000}
{"episode": 136.0, "batch_reward": 0.09918120761215687, "actor_loss": -68.46353840637207, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 426.1769104003906, "episode_reward": 115.73889611854399, "step": 136000}
{"episode": 137.0, "batch_reward": 0.09962819372862577, "actor_loss": -68.55081753540038, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 15.974527835845947, "episode_reward": 114.37772037206446, "step": 137000}
{"episode": 138.0, "batch_reward": 0.09920826467871666, "actor_loss": -69.26936047363282, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 424.8312587738037, "episode_reward": 96.22158023836873, "step": 138000}
{"episode": 139.0, "batch_reward": 0.09956560010462999, "actor_loss": -69.27110911560058, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.777775049209595, "episode_reward": 95.92662955153264, "step": 139000}
{"episode": 140.0, "batch_reward": 0.09945371407270431, "actor_loss": -69.69413150024414, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 423.9765202999115, "episode_reward": 117.49957356363548, "step": 140000}
{"episode": 141.0, "batch_reward": 0.09999312614649535, "actor_loss": -69.76000039672851, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 35.4588086605072, "episode_reward": 192.16837330222697, "step": 141000}
{"episode": 142.0, "batch_reward": 0.10076659815013408, "actor_loss": -69.19176364135743, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 419.45471119880676, "episode_reward": 188.51932343082018, "step": 142000}
{"episode": 143.0, "batch_reward": 0.10076309534162282, "actor_loss": -69.25667172241211, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.2796688079834, "episode_reward": 106.73436713325293, "step": 143000}
{"episode": 144.0, "batch_reward": 0.10111623462289572, "actor_loss": -69.66239295959473, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 419.9430696964264, "episode_reward": 122.76370648501235, "step": 144000}
{"episode": 145.0, "batch_reward": 0.10178745533525944, "actor_loss": -69.79182249450683, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.490498781204224, "episode_reward": 123.27187043380232, "step": 145000}
{"episode": 146.0, "batch_reward": 0.1007244962900877, "actor_loss": -70.57308428955078, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 430.19510769844055, "episode_reward": 143.00255976608187, "step": 146000}
{"episode": 147.0, "batch_reward": 0.10064924745261669, "actor_loss": -70.56744729614257, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.35947847366333, "episode_reward": 110.40210719417638, "step": 147000}
{"episode": 148.0, "batch_reward": 0.10143309877067805, "actor_loss": -70.30477542114258, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 416.82203674316406, "episode_reward": 115.3403840906987, "step": 148000}
{"episode": 149.0, "batch_reward": 0.10202241845428944, "actor_loss": -70.71158868408203, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.963240385055542, "episode_reward": 245.0826769462435, "step": 149000}
{"episode": 150.0, "batch_reward": 0.1036837309524417, "actor_loss": -70.47398674011231, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "step": 150000}
