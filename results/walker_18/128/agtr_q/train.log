{"episode": 1.0, "duration": 21.817933082580566, "episode_reward": 27.46298806610516, "step": 1000}
{"episode": 2.0, "duration": 1.9709153175354004, "episode_reward": 489.1100087318934, "step": 2000}
{"episode": 3.0, "batch_reward": 0.24270631831540548, "actor_loss": -83.93588560302051, "actor_target_entropy": -6.0, "alpha_value": 0.002134017781850189, "duration": 49.77886199951172, "episode_reward": 7.979925880509143, "step": 3000}
{"episode": 4.0, "batch_reward": 0.15596635100245476, "actor_loss": -81.48792611694336, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.88037610054016, "episode_reward": 51.251795145646426, "step": 4000}
{"episode": 5.0, "batch_reward": 0.1286683157682419, "actor_loss": -80.80117956542969, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.837268352508545, "episode_reward": 5.547415403534835, "step": 5000}
{"episode": 6.0, "batch_reward": 0.11069342606887221, "actor_loss": -79.92640046691895, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.94344139099121, "episode_reward": 131.42213777905746, "step": 6000}
{"episode": 7.0, "batch_reward": 0.1168190392702818, "actor_loss": -80.0490640411377, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.228774309158325, "episode_reward": 84.17111476574794, "step": 7000}
{"episode": 8.0, "batch_reward": 0.11218420652672649, "actor_loss": -80.16552569580078, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.436610221862793, "episode_reward": 79.08696343977658, "step": 8000}
{"episode": 9.0, "batch_reward": 0.11461966875195503, "actor_loss": -80.13068272399903, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 15.917564630508423, "episode_reward": 227.497701779785, "step": 9000}
{"episode": 10.0, "batch_reward": 0.12617610786110162, "actor_loss": -75.18990879821777, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 3932.0854704380035, "episode_reward": 233.00196785963553, "step": 10000}
{"episode": 11.0, "batch_reward": 0.14329855556041002, "actor_loss": -75.89287112426757, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 35.79066038131714, "episode_reward": 364.9095181275065, "step": 11000}
{"episode": 12.0, "batch_reward": 0.15693904282152651, "actor_loss": -73.76364183044434, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 433.0684463977814, "episode_reward": 181.02939091976012, "step": 12000}
{"episode": 13.0, "batch_reward": 0.16372175253927707, "actor_loss": -74.06451417541504, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.436213493347168, "episode_reward": 331.37089664792285, "step": 13000}
{"episode": 14.0, "batch_reward": 0.17575354164093732, "actor_loss": -73.27914071655273, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 426.1199097633362, "episode_reward": 342.87083295929864, "step": 14000}
{"episode": 15.0, "batch_reward": 0.18002019445598125, "actor_loss": -73.44222172546387, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.184510469436646, "episode_reward": 92.25383081537073, "step": 15000}
{"episode": 16.0, "batch_reward": 0.17753725180774926, "actor_loss": -72.37335670471191, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 434.689377784729, "episode_reward": 155.622117395768, "step": 16000}
{"episode": 17.0, "batch_reward": 0.17647917253524065, "actor_loss": -72.53074984741211, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.67220163345337, "episode_reward": 182.64446420369384, "step": 17000}
{"episode": 18.0, "batch_reward": 0.17928293116390706, "actor_loss": -73.17212223815918, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 421.85838770866394, "episode_reward": 287.94700930938643, "step": 18000}
{"episode": 19.0, "batch_reward": 0.18739943680167198, "actor_loss": -73.51586352539063, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.37657880783081, "episode_reward": 346.8369222939097, "step": 19000}
{"episode": 20.0, "batch_reward": 0.19806286841630935, "actor_loss": -73.9795235900879, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 426.1399140357971, "episode_reward": 413.8276961917807, "step": 20000}
{"episode": 21.0, "batch_reward": 0.20085782006382943, "actor_loss": -74.2298691253662, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 35.09619116783142, "episode_reward": 144.3138477278443, "step": 21000}
{"episode": 22.0, "batch_reward": 0.19916945812106132, "actor_loss": -73.79515254211425, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 429.10269379615784, "episode_reward": 186.58380525873673, "step": 22000}
{"episode": 23.0, "batch_reward": 0.19715666574239732, "actor_loss": -73.86367729187012, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.93847107887268, "episode_reward": 132.84755844521288, "step": 23000}
{"episode": 24.0, "batch_reward": 0.19462473344802855, "actor_loss": -73.13468255615234, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 422.8261742591858, "episode_reward": 156.95824961022004, "step": 24000}
{"episode": 25.0, "batch_reward": 0.1954801015406847, "actor_loss": -73.49972151184082, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 15.840177774429321, "episode_reward": 163.13168082273856, "step": 25000}
{"episode": 26.0, "batch_reward": 0.196003272280097, "actor_loss": -74.65387785339355, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 432.387583732605, "episode_reward": 319.76840645536663, "step": 26000}
{"episode": 27.0, "batch_reward": 0.1971377903074026, "actor_loss": -74.90921849060058, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.822404623031616, "episode_reward": 136.7160801320214, "step": 27000}
{"episode": 28.0, "batch_reward": 0.1959066359847784, "actor_loss": -75.25562677001953, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 424.72802782058716, "episode_reward": 253.1886710711885, "step": 28000}
{"episode": 29.0, "batch_reward": 0.1980906453281641, "actor_loss": -75.35935400390625, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.29418158531189, "episode_reward": 292.9153340066498, "step": 29000}
{"episode": 30.0, "batch_reward": 0.20043200343847276, "actor_loss": -77.19652516174317, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 432.0488328933716, "episode_reward": 170.4798663637035, "step": 30000}
{"episode": 31.0, "batch_reward": 0.20188896545767784, "actor_loss": -77.21149192810059, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 38.61958312988281, "episode_reward": 317.8158209059655, "step": 31000}
{"episode": 32.0, "batch_reward": 0.207103630438447, "actor_loss": -76.93488977050781, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 425.1296634674072, "episode_reward": 427.88302084073905, "step": 32000}
{"episode": 33.0, "batch_reward": 0.21583608774840832, "actor_loss": -77.07948263549805, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.205366849899292, "episode_reward": 550.8780403545113, "step": 33000}
{"episode": 34.0, "batch_reward": 0.22158299076557159, "actor_loss": -75.67963389587402, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 429.2290692329407, "episode_reward": 171.19806007547766, "step": 34000}
{"episode": 35.0, "batch_reward": 0.22153640370070934, "actor_loss": -75.71081454467773, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.578295707702637, "episode_reward": 424.03988221490295, "step": 35000}
{"episode": 36.0, "batch_reward": 0.22921077363193035, "actor_loss": -74.84019833374023, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 428.2266049385071, "episode_reward": 488.5505813251945, "step": 36000}
{"episode": 37.0, "batch_reward": 0.23514682763814926, "actor_loss": -74.88719009399414, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.90015983581543, "episode_reward": 453.8459060144301, "step": 37000}
{"episode": 38.0, "batch_reward": 0.24216220101714134, "actor_loss": -75.53427742004395, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 426.4763128757477, "episode_reward": 440.94160054375493, "step": 38000}
{"episode": 39.0, "batch_reward": 0.2449458981603384, "actor_loss": -75.64513208007813, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.9743230342865, "episode_reward": 406.7072299184037, "step": 39000}
{"episode": 40.0, "batch_reward": 0.24966691276431083, "actor_loss": -75.8241806640625, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 424.9744598865509, "episode_reward": 328.0327822852341, "step": 40000}
{"episode": 41.0, "batch_reward": 0.2500753178447485, "actor_loss": -75.78354470825195, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 37.22858929634094, "episode_reward": 266.38776942458463, "step": 41000}
{"episode": 42.0, "batch_reward": 0.25161484982073307, "actor_loss": -75.35784259033203, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 422.97479581832886, "episode_reward": 405.37816009525284, "step": 42000}
{"episode": 43.0, "batch_reward": 0.2559599312841892, "actor_loss": -75.41899298095703, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.108659505844116, "episode_reward": 403.26749674523546, "step": 43000}
{"episode": 44.0, "batch_reward": 0.2613869120925665, "actor_loss": -75.68934588623047, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 427.28795766830444, "episode_reward": 494.0351197669083, "step": 44000}
{"episode": 45.0, "batch_reward": 0.2608909481912851, "actor_loss": -75.73533351135254, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.818887948989868, "episode_reward": 140.01216829861715, "step": 45000}
{"episode": 46.0, "batch_reward": 0.26096540424227715, "actor_loss": -76.29017039489746, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 432.65676641464233, "episode_reward": 450.8508565632708, "step": 46000}
{"episode": 47.0, "batch_reward": 0.26775779701769353, "actor_loss": -76.49207470703125, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.359800100326538, "episode_reward": 495.68181092785926, "step": 47000}
{"episode": 48.0, "batch_reward": 0.2716832592636347, "actor_loss": -76.38141667175293, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 436.42094111442566, "episode_reward": 494.1032980640011, "step": 48000}
{"episode": 49.0, "batch_reward": 0.27575944462418556, "actor_loss": -76.47794178771973, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.65681791305542, "episode_reward": 400.2417819360856, "step": 49000}
{"episode": 50.0, "batch_reward": 0.2788672720938921, "actor_loss": -75.93481797790527, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 426.5744106769562, "episode_reward": 526.0725567167235, "step": 50000}
{"episode": 51.0, "batch_reward": 0.28381071393191815, "actor_loss": -76.02382977294921, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.233354568481445, "episode_reward": 468.38361480762427, "step": 51000}
{"episode": 52.0, "batch_reward": 0.28745029005408285, "actor_loss": -76.07502410888672, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 425.0058045387268, "episode_reward": 542.9961806330455, "step": 52000}
{"episode": 53.0, "batch_reward": 0.29038899721205236, "actor_loss": -76.20387739562989, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.974672317504883, "episode_reward": 460.5103378738266, "step": 53000}
{"episode": 54.0, "batch_reward": 0.29580449414253235, "actor_loss": -76.03187225341797, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 424.0313150882721, "episode_reward": 489.5325322053559, "step": 54000}
{"episode": 55.0, "batch_reward": 0.29959127645194533, "actor_loss": -76.2576441192627, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.76919388771057, "episode_reward": 602.280529302509, "step": 55000}
{"episode": 56.0, "batch_reward": 0.3031342963129282, "actor_loss": -76.06652618408204, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 426.24531412124634, "episode_reward": 394.4065414844363, "step": 56000}
{"episode": 57.0, "batch_reward": 0.3043230602890253, "actor_loss": -76.12165106201172, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.174387454986572, "episode_reward": 396.0825883496499, "step": 57000}
{"episode": 58.0, "batch_reward": 0.30812924391031266, "actor_loss": -76.28701864624023, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 424.05532240867615, "episode_reward": 518.2660782285284, "step": 58000}
{"episode": 59.0, "batch_reward": 0.311907735273242, "actor_loss": -76.31450230407715, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.74786353111267, "episode_reward": 583.8178604476172, "step": 59000}
{"episode": 60.0, "batch_reward": 0.3150567652583122, "actor_loss": -76.77216032409667, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 428.3998589515686, "episode_reward": 512.7061369424896, "step": 60000}
{"episode": 61.0, "batch_reward": 0.3181314750313759, "actor_loss": -76.91649485778808, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 38.31589317321777, "episode_reward": 352.31240127122066, "step": 61000}
{"episode": 62.0, "batch_reward": 0.3222948403060436, "actor_loss": -77.18483772277833, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 426.24699783325195, "episode_reward": 553.1506361048814, "step": 62000}
{"episode": 63.0, "batch_reward": 0.3241453570127487, "actor_loss": -77.25063636779785, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.961190462112427, "episode_reward": 546.1595135672219, "step": 63000}
{"episode": 64.0, "batch_reward": 0.32666634213924406, "actor_loss": -77.82885595703125, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 431.773074388504, "episode_reward": 494.71185711876603, "step": 64000}
{"episode": 65.0, "batch_reward": 0.327932487025857, "actor_loss": -77.95064683532715, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 15.966941833496094, "episode_reward": 445.1175633016235, "step": 65000}
{"episode": 66.0, "batch_reward": 0.3310026137381792, "actor_loss": -76.85834953308105, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 436.41799306869507, "episode_reward": 606.9112167105432, "step": 66000}
{"episode": 67.0, "batch_reward": 0.3352073026895523, "actor_loss": -76.98209666442871, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.98224902153015, "episode_reward": 642.3714047398034, "step": 67000}
{"episode": 68.0, "batch_reward": 0.34095502710342407, "actor_loss": -76.51931512451172, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 433.9107885360718, "episode_reward": 587.8176083708131, "step": 68000}
{"episode": 69.0, "batch_reward": 0.3421067431271076, "actor_loss": -76.48591738891602, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.131181955337524, "episode_reward": 582.8377578781191, "step": 69000}
{"episode": 70.0, "batch_reward": 0.34770802116394045, "actor_loss": -76.25136627197266, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 438.6476261615753, "episode_reward": 582.1202097817483, "step": 70000}
{"episode": 71.0, "batch_reward": 0.3511330175697803, "actor_loss": -76.3758130645752, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 38.865204095840454, "episode_reward": 501.2988060712048, "step": 71000}
{"episode": 72.0, "batch_reward": 0.3492372188270092, "actor_loss": -76.20175776672363, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 425.4436490535736, "episode_reward": 202.5678137713115, "step": 72000}
{"episode": 73.0, "batch_reward": 0.350642991155386, "actor_loss": -76.18599850463868, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.944504261016846, "episode_reward": 567.8059882376643, "step": 73000}
{"episode": 74.0, "batch_reward": 0.3535225225687027, "actor_loss": -77.2249370727539, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 431.0091392993927, "episode_reward": 617.2713907340411, "step": 74000}
{"episode": 75.0, "batch_reward": 0.35582322150468826, "actor_loss": -77.40735604858398, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.26052212715149, "episode_reward": 519.1392786893751, "step": 75000}
{"episode": 76.0, "batch_reward": 0.3602086811959743, "actor_loss": -76.66322463989258, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 422.9222276210785, "episode_reward": 614.0051330938646, "step": 76000}
{"episode": 77.0, "batch_reward": 0.3639083725512028, "actor_loss": -76.80705627441407, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.843490839004517, "episode_reward": 621.3254559548744, "step": 77000}
{"episode": 78.0, "batch_reward": 0.36672574740648267, "actor_loss": -77.08456146240235, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 431.46869373321533, "episode_reward": 662.571756561602, "step": 78000}
{"episode": 79.0, "batch_reward": 0.369478311508894, "actor_loss": -77.10780784606933, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.9930202960968, "episode_reward": 588.563989737195, "step": 79000}
{"episode": 80.0, "batch_reward": 0.3736030560135841, "actor_loss": -77.31724925231934, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 433.4976394176483, "episode_reward": 680.5061465150038, "step": 80000}
{"episode": 81.0, "batch_reward": 0.3765690090954304, "actor_loss": -77.42225749206543, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 40.003989696502686, "episode_reward": 651.921373722899, "step": 81000}
{"episode": 82.0, "batch_reward": 0.3785309555232525, "actor_loss": -77.81239315795898, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 437.67342948913574, "episode_reward": 608.4209839197498, "step": 82000}
{"episode": 83.0, "batch_reward": 0.3827395253777504, "actor_loss": -78.04715104675293, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.213825225830078, "episode_reward": 629.511626415139, "step": 83000}
{"episode": 84.0, "batch_reward": 0.3859557514190674, "actor_loss": -77.36054376220703, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 434.35934710502625, "episode_reward": 675.7788344428892, "step": 84000}
{"episode": 85.0, "batch_reward": 0.38889162668585775, "actor_loss": -77.46441969299316, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.925687551498413, "episode_reward": 632.5049911692058, "step": 85000}
{"episode": 86.0, "batch_reward": 0.3927960400283337, "actor_loss": -77.56328366088867, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 429.6675293445587, "episode_reward": 634.3107450394939, "step": 86000}
{"episode": 87.0, "batch_reward": 0.39267411065101626, "actor_loss": -77.57303062438965, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.759747743606567, "episode_reward": 565.4930606202746, "step": 87000}
{"episode": 88.0, "batch_reward": 0.3996019529402256, "actor_loss": -77.75792811584472, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 437.7511863708496, "episode_reward": 682.4167901468599, "step": 88000}
{"episode": 89.0, "batch_reward": 0.3998953137397766, "actor_loss": -77.78958377075195, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.99902606010437, "episode_reward": 692.5599933734505, "step": 89000}
{"episode": 90.0, "batch_reward": 0.40367220556735994, "actor_loss": -77.37200691223144, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 423.8011155128479, "episode_reward": 668.9670377070423, "step": 90000}
{"episode": 91.0, "batch_reward": 0.40475751423835754, "actor_loss": -77.49898847961425, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 37.93022537231445, "episode_reward": 530.3331957418636, "step": 91000}
{"episode": 92.0, "batch_reward": 0.40723632502555845, "actor_loss": -76.92656341552734, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 423.6891460418701, "episode_reward": 630.9272021517331, "step": 92000}
{"episode": 93.0, "batch_reward": 0.4090503679513931, "actor_loss": -76.99790325927735, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.56309175491333, "episode_reward": 575.1652468865635, "step": 93000}
{"episode": 94.0, "batch_reward": 0.4129513187110424, "actor_loss": -76.56629116821289, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 427.72764134407043, "episode_reward": 633.7522046821928, "step": 94000}
{"episode": 95.0, "batch_reward": 0.4121032429933548, "actor_loss": -76.51230213928223, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.98997449874878, "episode_reward": 542.9858648988577, "step": 95000}
{"episode": 96.0, "batch_reward": 0.4161121614873409, "actor_loss": -76.84031925964355, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 430.9944155216217, "episode_reward": 731.1567502149509, "step": 96000}
{"episode": 97.0, "batch_reward": 0.41960513946413996, "actor_loss": -76.92801863098144, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 15.881683588027954, "episode_reward": 656.8788659407858, "step": 97000}
{"episode": 98.0, "batch_reward": 0.4213585884273052, "actor_loss": -77.24066659545899, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 427.22285175323486, "episode_reward": 657.7526344427429, "step": 98000}
{"episode": 99.0, "batch_reward": 0.42210911586880684, "actor_loss": -77.29833345031739, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.273309469223022, "episode_reward": 646.2478067836611, "step": 99000}
{"episode": 100.0, "batch_reward": 0.42679431480169294, "actor_loss": -76.97495191955566, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 421.7620258331299, "episode_reward": 642.1995745569197, "step": 100000}
{"episode": 101.0, "batch_reward": 0.4268777024447918, "actor_loss": -76.97321032714844, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 37.60897445678711, "episode_reward": 570.9630978360361, "step": 101000}
{"episode": 102.0, "batch_reward": 0.42960951364040373, "actor_loss": -77.20791929626465, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 433.56138253211975, "episode_reward": 674.5494315939493, "step": 102000}
{"episode": 103.0, "batch_reward": 0.4333128542304039, "actor_loss": -77.48776321411133, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.038471937179565, "episode_reward": 755.4489553347896, "step": 103000}
{"episode": 104.0, "batch_reward": 0.4353970220386982, "actor_loss": -77.45816938781738, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 429.68417501449585, "episode_reward": 725.179074952349, "step": 104000}
{"episode": 105.0, "batch_reward": 0.4398430379629135, "actor_loss": -77.67785525512696, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.966479063034058, "episode_reward": 655.3408777448287, "step": 105000}
{"episode": 106.0, "batch_reward": 0.43951466313004495, "actor_loss": -76.85002159118652, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 436.38150358200073, "episode_reward": 708.5629564713092, "step": 106000}
{"episode": 107.0, "batch_reward": 0.4420757946074009, "actor_loss": -77.04203256225586, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.134984016418457, "episode_reward": 725.8564497653999, "step": 107000}
{"episode": 108.0, "batch_reward": 0.4440688069462776, "actor_loss": -77.75381155395507, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 430.33791494369507, "episode_reward": 465.91069526629155, "step": 108000}
{"episode": 109.0, "batch_reward": 0.44486031010746957, "actor_loss": -77.77746589660644, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.235952615737915, "episode_reward": 643.6516244872646, "step": 109000}
{"episode": 110.0, "batch_reward": 0.44786862802505495, "actor_loss": -77.22867695617676, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 435.3405718803406, "episode_reward": 605.0860795168902, "step": 110000}
{"episode": 111.0, "batch_reward": 0.4478488882780075, "actor_loss": -77.40581420898438, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 40.34065270423889, "episode_reward": 294.9759692947345, "step": 111000}
{"episode": 112.0, "batch_reward": 0.4464606221020222, "actor_loss": -76.70010507202149, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 435.13454031944275, "episode_reward": 548.2093618973092, "step": 112000}
{"episode": 113.0, "batch_reward": 0.4462693367898464, "actor_loss": -76.81881948852539, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.074528455734253, "episode_reward": 730.0889098789653, "step": 113000}
{"episode": 114.0, "batch_reward": 0.44975138583779334, "actor_loss": -76.81183055114747, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 422.9619278907776, "episode_reward": 683.18264768567, "step": 114000}
{"episode": 115.0, "batch_reward": 0.45240210351347926, "actor_loss": -76.92162631225585, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.05876588821411, "episode_reward": 693.97158368826, "step": 115000}
{"episode": 116.0, "batch_reward": 0.45416583913564684, "actor_loss": -77.20511389160156, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 426.2205958366394, "episode_reward": 683.8588452909531, "step": 116000}
{"episode": 117.0, "batch_reward": 0.4570474185347557, "actor_loss": -77.39443769836426, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.003098726272583, "episode_reward": 618.3008656457785, "step": 117000}
{"episode": 118.0, "batch_reward": 0.458138741761446, "actor_loss": -78.18972033691406, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 426.7023811340332, "episode_reward": 528.9188643727884, "step": 118000}
{"episode": 119.0, "batch_reward": 0.4566679133474827, "actor_loss": -78.19256367492676, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.262349367141724, "episode_reward": 98.99853154409638, "step": 119000}
{"episode": 120.0, "batch_reward": 0.4563694736361504, "actor_loss": -78.15351649475097, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 427.7649145126343, "episode_reward": 665.9887263111153, "step": 120000}
{"episode": 121.0, "batch_reward": 0.45731052967906, "actor_loss": -78.13062614440918, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 37.04936861991882, "episode_reward": 656.9598261618879, "step": 121000}
{"episode": 122.0, "batch_reward": 0.45842061313986776, "actor_loss": -77.85573487854003, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 427.76496839523315, "episode_reward": 595.5715122488085, "step": 122000}
{"episode": 123.0, "batch_reward": 0.4588943967819214, "actor_loss": -77.92315269470215, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.768126726150513, "episode_reward": 488.51570211599585, "step": 123000}
{"episode": 124.0, "batch_reward": 0.45887553137540815, "actor_loss": -77.59736067199707, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 420.08670353889465, "episode_reward": 629.9787288795496, "step": 124000}
{"episode": 125.0, "batch_reward": 0.4617724820077419, "actor_loss": -77.75644400024414, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.032652616500854, "episode_reward": 659.1701859339149, "step": 125000}
{"episode": 126.0, "batch_reward": 0.4627313408255577, "actor_loss": -77.56579804992676, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 429.894198179245, "episode_reward": 541.1833818893233, "step": 126000}
{"episode": 127.0, "batch_reward": 0.4645998540222645, "actor_loss": -77.59128646850586, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.755700826644897, "episode_reward": 752.0707290007257, "step": 127000}
{"episode": 128.0, "batch_reward": 0.4662642192542553, "actor_loss": -77.94976506042481, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 428.7514765262604, "episode_reward": 486.8051531940665, "step": 128000}
{"episode": 129.0, "batch_reward": 0.4665605416595936, "actor_loss": -78.0552924041748, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.30086922645569, "episode_reward": 734.4921196211429, "step": 129000}
{"episode": 130.0, "batch_reward": 0.4679842157661915, "actor_loss": -78.50119078063965, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 427.6194407939911, "episode_reward": 627.7956592104044, "step": 130000}
{"episode": 131.0, "batch_reward": 0.47026020401716234, "actor_loss": -78.60847193908691, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 36.07608461380005, "episode_reward": 712.6268884282824, "step": 131000}
{"episode": 132.0, "batch_reward": 0.4707827731072903, "actor_loss": -78.63057011413574, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 435.7837624549866, "episode_reward": 614.0394804678801, "step": 132000}
{"episode": 133.0, "batch_reward": 0.4725932028889656, "actor_loss": -78.67729028320312, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.109607934951782, "episode_reward": 657.4436266850059, "step": 133000}
{"episode": 134.0, "batch_reward": 0.47446673148870466, "actor_loss": -78.89497087097168, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 433.8253262042999, "episode_reward": 587.9924607816881, "step": 134000}
{"episode": 135.0, "batch_reward": 0.4754592828154564, "actor_loss": -78.91584085083008, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.423664808273315, "episode_reward": 659.0058231675841, "step": 135000}
{"episode": 136.0, "batch_reward": 0.4758294014930725, "actor_loss": -78.72749328613281, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 436.31427121162415, "episode_reward": 668.3073026907192, "step": 136000}
{"episode": 137.0, "batch_reward": 0.47778234601020814, "actor_loss": -78.81205888366699, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.355244874954224, "episode_reward": 635.9625442538417, "step": 137000}
{"episode": 138.0, "batch_reward": 0.4794323268532753, "actor_loss": -79.1237449798584, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 431.3072667121887, "episode_reward": 672.5549454135007, "step": 138000}
{"episode": 139.0, "batch_reward": 0.4798615657091141, "actor_loss": -79.22009326171874, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.144404888153076, "episode_reward": 219.47592657182736, "step": 139000}
{"episode": 140.0, "batch_reward": 0.477812676936388, "actor_loss": -78.80025811767578, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 443.2347185611725, "episode_reward": 659.445213586626, "step": 140000}
{"episode": 141.0, "batch_reward": 0.47999094346165655, "actor_loss": -78.86850090026856, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 37.87873888015747, "episode_reward": 675.6338480682666, "step": 141000}
{"episode": 142.0, "batch_reward": 0.479853295058012, "actor_loss": -78.96481999206543, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 427.4073441028595, "episode_reward": 531.0615408182766, "step": 142000}
{"episode": 143.0, "batch_reward": 0.4806566038429737, "actor_loss": -79.0670372619629, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.7232723236084, "episode_reward": 561.6752951753128, "step": 143000}
{"episode": 144.0, "batch_reward": 0.48167654675245286, "actor_loss": -78.02718269348145, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 431.0902979373932, "episode_reward": 508.9266918242524, "step": 144000}
{"episode": 145.0, "batch_reward": 0.48130088311433794, "actor_loss": -77.96394789123535, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.91763401031494, "episode_reward": 580.0455259203234, "step": 145000}
{"episode": 146.0, "batch_reward": 0.4828059196472168, "actor_loss": -78.32390928649902, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 459.12152123451233, "episode_reward": 597.5786940468668, "step": 146000}
{"episode": 147.0, "batch_reward": 0.4834059568941593, "actor_loss": -78.38356205749511, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.287221431732178, "episode_reward": 617.2141281076485, "step": 147000}
{"episode": 148.0, "batch_reward": 0.4834765218794346, "actor_loss": -77.75200799560547, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 476.7134268283844, "episode_reward": 591.3156852752354, "step": 148000}
{"episode": 149.0, "batch_reward": 0.4851428320109844, "actor_loss": -77.86952111816406, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.286564350128174, "episode_reward": 619.8582177169974, "step": 149000}
{"episode": 150.0, "batch_reward": 0.4865642148852348, "actor_loss": -78.56066969299316, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "step": 150000}
