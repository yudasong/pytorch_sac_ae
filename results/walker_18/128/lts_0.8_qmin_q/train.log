{"episode_reward": 0.0, "episode": 1.0, "duration": 22.448282718658447, "step": 1000}
{"episode_reward": 27.46298806610516, "episode": 2.0, "duration": 1.9342210292816162, "step": 2000}
{"episode_reward": 489.1100087318934, "episode": 3.0, "batch_reward": 0.2460258107516876, "critic_loss": 0.6125016852234474, "actor_loss": -82.5433726072216, "actor_target_entropy": -6.0, "alpha_value": 0.002134017781850189, "duration": 65.45218205451965, "step": 3000}
{"episode_reward": 70.82915339118308, "episode": 4.0, "batch_reward": 0.18073246432840825, "critic_loss": 0.5370355196297169, "actor_loss": -78.48739141845704, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.432520866394043, "step": 4000}
{"episode_reward": 76.38315014714637, "episode": 5.0, "batch_reward": 0.17288915568590163, "critic_loss": 0.735477203041315, "actor_loss": -78.05561563873292, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.725446462631226, "step": 5000}
{"episode_reward": 217.3603840988038, "episode": 6.0, "batch_reward": 0.1926457040682435, "critic_loss": 0.8117145674228669, "actor_loss": -77.61844731140137, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.22297477722168, "step": 6000}
{"episode_reward": 364.6606030314207, "episode": 7.0, "batch_reward": 0.21040114584565162, "critic_loss": 0.8159469386935234, "actor_loss": -77.93250601959228, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.590222358703613, "step": 7000}
{"episode_reward": 314.91669414209775, "episode": 8.0, "batch_reward": 0.22895503243803977, "critic_loss": 0.6933383030593395, "actor_loss": -78.56389891052245, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.18992018699646, "step": 8000}
{"episode_reward": 350.5397399868072, "episode": 9.0, "batch_reward": 0.24746311189234257, "critic_loss": 0.646293578505516, "actor_loss": -77.0161570892334, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.818934202194214, "step": 9000}
{"episode_reward": 384.93085885472743, "episode": 10.0, "batch_reward": 0.2637661928981543, "critic_loss": 0.6214100031256675, "actor_loss": -78.25467613983155, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.471341133117676, "step": 10000}
{"episode_reward": 430.9359660324637, "episode": 11.0, "batch_reward": 0.2783353832066059, "critic_loss": 0.6221796241402626, "actor_loss": -77.19529521942138, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 43.31036591529846, "step": 11000}
{"episode_reward": 423.24185359624613, "episode": 12.0, "batch_reward": 0.29472465959191324, "critic_loss": 0.6421328307688237, "actor_loss": -77.79516529083251, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.927889347076416, "step": 12000}
{"episode_reward": 491.1417163010168, "episode": 13.0, "batch_reward": 0.3056155554950237, "critic_loss": 0.6451823940575123, "actor_loss": -78.12145728302002, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.75003409385681, "step": 13000}
{"episode_reward": 271.50002009544045, "episode": 14.0, "batch_reward": 0.306904749289155, "critic_loss": 0.6096159830391407, "actor_loss": -77.9409907836914, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.413332223892212, "step": 14000}
{"episode_reward": 470.22480328275685, "episode": 15.0, "batch_reward": 0.31718704944849013, "critic_loss": 0.6665345200300217, "actor_loss": -76.50908369445801, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.987327098846436, "step": 15000}
{"episode_reward": 457.2247978825568, "episode": 16.0, "batch_reward": 0.3180212772488594, "critic_loss": 0.6912321951091289, "actor_loss": -76.90162630462646, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.84365677833557, "step": 16000}
{"episode_reward": 125.59853913506808, "episode": 17.0, "batch_reward": 0.3123243688642979, "critic_loss": 0.7173086025714874, "actor_loss": -76.90171244049073, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.249420404434204, "step": 17000}
{"episode_reward": 401.27651017895755, "episode": 18.0, "batch_reward": 0.319630942940712, "critic_loss": 0.7983383131027222, "actor_loss": -76.82804480743408, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.228593587875366, "step": 18000}
{"episode_reward": 484.41014807296824, "episode": 19.0, "batch_reward": 0.32182415449619295, "critic_loss": 0.8951527454257011, "actor_loss": -76.09357336425781, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.93143057823181, "step": 19000}
{"episode_reward": 167.2322460834857, "episode": 20.0, "batch_reward": 0.31518773540854456, "critic_loss": 0.9289252440929413, "actor_loss": -76.48948822784423, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.211026191711426, "step": 20000}
{"episode_reward": 323.50208555341635, "episode": 21.0, "batch_reward": 0.3154838146865368, "critic_loss": 0.9672458041906357, "actor_loss": -73.4344356994629, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 45.73468041419983, "step": 21000}
{"episode_reward": 265.822556791616, "episode": 22.0, "batch_reward": 0.31925938147306443, "critic_loss": 1.0549399539828301, "actor_loss": -76.03673111724854, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.935449838638306, "step": 22000}
{"episode_reward": 534.9657785446244, "episode": 23.0, "batch_reward": 0.3280556963980198, "critic_loss": 1.2117608745098114, "actor_loss": -75.81822508239746, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.464301586151123, "step": 23000}
{"episode_reward": 445.11972487446224, "episode": 24.0, "batch_reward": 0.33248715835809706, "critic_loss": 1.2952331347465516, "actor_loss": -74.11793126678467, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.356944799423218, "step": 24000}
{"episode_reward": 493.37842981648424, "episode": 25.0, "batch_reward": 0.33639851939678195, "critic_loss": 1.168362745642662, "actor_loss": -76.41651594543457, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.791089296340942, "step": 25000}
{"episode_reward": 329.1879523539461, "episode": 26.0, "batch_reward": 0.3375737623870373, "critic_loss": 1.1917029141783715, "actor_loss": -74.80306100463868, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.27054762840271, "step": 26000}
{"episode_reward": 372.81955064440075, "episode": 27.0, "batch_reward": 0.33906276905536653, "critic_loss": 1.2381472643613816, "actor_loss": -74.38840586853027, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.929664611816406, "step": 27000}
{"episode_reward": 433.2204464359261, "episode": 28.0, "batch_reward": 0.3383444129824638, "critic_loss": 1.2517044543027878, "actor_loss": -73.81164165878296, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.321301698684692, "step": 28000}
{"episode_reward": 219.84239248712967, "episode": 29.0, "batch_reward": 0.33706642016768457, "critic_loss": 1.2734853286743164, "actor_loss": -74.94534833145141, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.614232540130615, "step": 29000}
{"episode_reward": 358.88621967710094, "episode": 30.0, "batch_reward": 0.3397320555746555, "critic_loss": 1.2572933077216149, "actor_loss": -74.50022476577759, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.328975677490234, "step": 30000}
{"episode_reward": 496.43217649980954, "episode": 31.0, "batch_reward": 0.3466413874030113, "critic_loss": 1.2357465006113053, "actor_loss": -74.20321063232421, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.18641114234924, "step": 31000}
{"episode_reward": 536.3658527082622, "episode": 32.0, "batch_reward": 0.35129914781451227, "critic_loss": 1.2497229809165, "actor_loss": -74.15540746307373, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.81687045097351, "step": 32000}
{"episode_reward": 391.9525759933641, "episode": 33.0, "batch_reward": 0.35081970447301863, "critic_loss": 1.312241581261158, "actor_loss": -74.51287244415283, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.531168222427368, "step": 33000}
{"episode_reward": 354.4904128975869, "episode": 34.0, "batch_reward": 0.3530931522250175, "critic_loss": 1.3184138141274453, "actor_loss": -74.09453433227539, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.777946949005127, "step": 34000}
{"episode_reward": 532.8071505967118, "episode": 35.0, "batch_reward": 0.3549541561305523, "critic_loss": 1.3016643446683884, "actor_loss": -73.62059223175049, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.33791422843933, "step": 35000}
{"episode_reward": 350.31498735926124, "episode": 36.0, "batch_reward": 0.35766830971837044, "critic_loss": 1.3078308178186417, "actor_loss": -74.63621353149414, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.395499229431152, "step": 36000}
{"episode_reward": 369.9918134285952, "episode": 37.0, "batch_reward": 0.3595385510325432, "critic_loss": 1.3194093003869056, "actor_loss": -74.15966059112549, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.40380024909973, "step": 37000}
{"episode_reward": 461.40843404766326, "episode": 38.0, "batch_reward": 0.3597380601465702, "critic_loss": 1.2924771173000336, "actor_loss": -75.73583693313599, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.80491280555725, "step": 38000}
{"episode_reward": 356.67905931726443, "episode": 39.0, "batch_reward": 0.3573881774246693, "critic_loss": 1.309170190513134, "actor_loss": -76.18451805496215, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.16340184211731, "step": 39000}
{"episode_reward": 343.912659367728, "episode": 40.0, "batch_reward": 0.35805157533288, "critic_loss": 1.4064846194982528, "actor_loss": -76.90544498825074, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.966482639312744, "step": 40000}
{"episode_reward": 249.55961501151515, "episode": 41.0, "batch_reward": 0.3575424840450287, "critic_loss": 1.4788005793690682, "actor_loss": -74.44742100906372, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 39.24230408668518, "step": 41000}
{"episode_reward": 604.450170315453, "episode": 42.0, "batch_reward": 0.3635455754995346, "critic_loss": 1.6532312129139901, "actor_loss": -74.8865005455017, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.416118383407593, "step": 42000}
{"episode_reward": 511.2240713711925, "episode": 43.0, "batch_reward": 0.36645068606734277, "critic_loss": 2.155380079686642, "actor_loss": -75.8465509300232, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.05405330657959, "step": 43000}
{"episode_reward": 393.43587185622897, "episode": 44.0, "batch_reward": 0.3662701162695885, "critic_loss": 2.396380097806454, "actor_loss": -74.09938505554199, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.379626274108887, "step": 44000}
{"episode_reward": 356.55232955687137, "episode": 45.0, "batch_reward": 0.36666318887472155, "critic_loss": 3.6667309311032295, "actor_loss": -74.12159358978272, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.334744215011597, "step": 45000}
{"episode_reward": 482.3628720872713, "episode": 46.0, "batch_reward": 0.3707383808791637, "critic_loss": 3.322175020456314, "actor_loss": -74.51586706542969, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.42928671836853, "step": 46000}
{"episode_reward": 580.1068559238084, "episode": 47.0, "batch_reward": 0.3724936905503273, "critic_loss": 3.4545773229598997, "actor_loss": -72.75305697631836, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.001551389694214, "step": 47000}
{"episode_reward": 421.86053970913144, "episode": 48.0, "batch_reward": 0.3765882279872894, "critic_loss": 3.20319462954998, "actor_loss": -74.39804055786132, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.595963716506958, "step": 48000}
{"episode_reward": 582.5740698911744, "episode": 49.0, "batch_reward": 0.37928984028100965, "critic_loss": 2.68924147605896, "actor_loss": -74.61963346862792, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.001819133758545, "step": 49000}
{"episode_reward": 549.81210995433, "episode": 50.0, "batch_reward": 0.38339452248811723, "critic_loss": 2.0855922924876213, "actor_loss": -72.87715126419067, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.23891544342041, "step": 50000}
{"episode_reward": 587.765656483664, "episode": 51.0, "batch_reward": 0.387069247841835, "critic_loss": 1.9482937393784523, "actor_loss": -75.22561513137818, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 39.5889573097229, "step": 51000}
{"episode_reward": 666.251668085242, "episode": 52.0, "batch_reward": 0.39361385571956636, "critic_loss": 1.9298692687153816, "actor_loss": -73.5423872833252, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 25.260454177856445, "step": 52000}
{"episode_reward": 504.7935109698698, "episode": 53.0, "batch_reward": 0.3952029647529125, "critic_loss": 1.894671382009983, "actor_loss": -74.26772745132446, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.372552633285522, "step": 53000}
{"episode_reward": 562.5817171575394, "episode": 54.0, "batch_reward": 0.3990999564528465, "critic_loss": 1.8882313377857207, "actor_loss": -75.37572554397583, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.83096742630005, "step": 54000}
{"episode_reward": 590.4161093750033, "episode": 55.0, "batch_reward": 0.40280306923389436, "critic_loss": 1.9077497771978378, "actor_loss": -76.07443475341798, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.509685516357422, "step": 55000}
{"episode_reward": 560.7869696066292, "episode": 56.0, "batch_reward": 0.4025992819964886, "critic_loss": 1.863526639699936, "actor_loss": -75.56377750396729, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.053025245666504, "step": 56000}
{"episode_reward": 225.4603350343732, "episode": 57.0, "batch_reward": 0.4007115646004677, "critic_loss": 1.8801561428904534, "actor_loss": -75.08069256210327, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 26.264575719833374, "step": 57000}
{"episode_reward": 544.9656335404303, "episode": 58.0, "batch_reward": 0.4013019754886627, "critic_loss": 1.868615860939026, "actor_loss": -75.6179553565979, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.96843957901001, "step": 58000}
{"episode_reward": 216.78632948188485, "episode": 59.0, "batch_reward": 0.40121157747507097, "critic_loss": 1.8306026453971862, "actor_loss": -77.35978538131714, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.892943143844604, "step": 59000}
{"episode_reward": 446.75554861391635, "episode": 60.0, "batch_reward": 0.39991709613800047, "critic_loss": 1.8618946802616119, "actor_loss": -75.20658911132813, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.011847972869873, "step": 60000}
{"episode_reward": 560.3910142260595, "episode": 61.0, "batch_reward": 0.40486908090114593, "critic_loss": 1.898126721739769, "actor_loss": -74.34167739868164, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 44.518630027770996, "step": 61000}
{"episode_reward": 598.5450740562452, "episode": 62.0, "batch_reward": 0.4068746227622032, "critic_loss": 1.913302521944046, "actor_loss": -74.68896828079224, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.277993202209473, "step": 62000}
{"episode_reward": 606.5967295032912, "episode": 63.0, "batch_reward": 0.4109617185592651, "critic_loss": 1.8744808032512665, "actor_loss": -75.172729763031, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.690011501312256, "step": 63000}
{"episode_reward": 681.5409803965262, "episode": 64.0, "batch_reward": 0.4156078240275383, "critic_loss": 1.8914457758665084, "actor_loss": -75.61107902145386, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.319826126098633, "step": 64000}
{"episode_reward": 605.3696685030652, "episode": 65.0, "batch_reward": 0.41927313444018366, "critic_loss": 1.892334421634674, "actor_loss": -75.76497776794433, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.99360704421997, "step": 65000}
{"episode_reward": 651.3641899579592, "episode": 66.0, "batch_reward": 0.42168654564023017, "critic_loss": 1.9192542960643768, "actor_loss": -76.47145447540284, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.81276798248291, "step": 66000}
{"episode_reward": 574.635428887656, "episode": 67.0, "batch_reward": 0.4238794992864132, "critic_loss": 2.014975591778755, "actor_loss": -75.84122758865357, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.50749397277832, "step": 67000}
{"episode_reward": 609.5236081766222, "episode": 68.0, "batch_reward": 0.42762019419670105, "critic_loss": 2.1006804686784744, "actor_loss": -76.3693583831787, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.594210147857666, "step": 68000}
{"episode_reward": 414.72414821074324, "episode": 69.0, "batch_reward": 0.42659105616807935, "critic_loss": 2.114088139295578, "actor_loss": -74.99730801773072, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.398001670837402, "step": 69000}
{"episode_reward": 557.6075361270211, "episode": 70.0, "batch_reward": 0.4303092997968197, "critic_loss": 2.117416080713272, "actor_loss": -75.9906895828247, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.193206071853638, "step": 70000}
{"episode_reward": 610.3188468302413, "episode": 71.0, "batch_reward": 0.43051091381907464, "critic_loss": 2.132327675938606, "actor_loss": -75.75296879196166, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 46.31764006614685, "step": 71000}
{"episode_reward": 742.6493664821542, "episode": 72.0, "batch_reward": 0.4355692194104195, "critic_loss": 2.262118332862854, "actor_loss": -76.70056261444091, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.945651054382324, "step": 72000}
{"episode_reward": 638.8478789003047, "episode": 73.0, "batch_reward": 0.44033096182346343, "critic_loss": 2.374574654340744, "actor_loss": -75.30531858062744, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.208816289901733, "step": 73000}
{"episode_reward": 701.1341764209708, "episode": 74.0, "batch_reward": 0.4404905099272728, "critic_loss": 2.4074345289468764, "actor_loss": -74.8808371887207, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.180111169815063, "step": 74000}
{"episode_reward": 616.1756113698743, "episode": 75.0, "batch_reward": 0.44513588765263556, "critic_loss": 2.4190936918258665, "actor_loss": -78.4701823272705, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 26.086588621139526, "step": 75000}
{"episode_reward": 637.266441003351, "episode": 76.0, "batch_reward": 0.44784490540623667, "critic_loss": 2.443498677611351, "actor_loss": -77.0497618637085, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.850903511047363, "step": 76000}
{"episode_reward": 706.3745317541564, "episode": 77.0, "batch_reward": 0.4490437252819538, "critic_loss": 2.5459839547872543, "actor_loss": -76.52427373504639, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.969863891601562, "step": 77000}
{"episode_reward": 446.8124361917655, "episode": 78.0, "batch_reward": 0.45056672859191893, "critic_loss": 2.609693442940712, "actor_loss": -76.09776014709473, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.73050546646118, "step": 78000}
{"episode_reward": 730.3386822143041, "episode": 79.0, "batch_reward": 0.4533158914446831, "critic_loss": 2.5865426758527756, "actor_loss": -77.29828270721436, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.92914128303528, "step": 79000}
{"episode_reward": 670.1658794330729, "episode": 80.0, "batch_reward": 0.45848038351535797, "critic_loss": 2.6221332601308824, "actor_loss": -78.01134656524658, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.778938055038452, "step": 80000}
{"episode_reward": 806.7041248507018, "episode": 81.0, "batch_reward": 0.4619205726981163, "critic_loss": 2.6136550908088685, "actor_loss": -77.72033107757568, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.565661668777466, "step": 81000}
{"episode_reward": 672.9014599525657, "episode": 82.0, "batch_reward": 0.46413779494166374, "critic_loss": 2.6755252898931503, "actor_loss": -76.84520267486572, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.418256521224976, "step": 82000}
{"episode_reward": 757.9062678302726, "episode": 83.0, "batch_reward": 0.46689334261417387, "critic_loss": 2.8220098497867583, "actor_loss": -78.2142003250122, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.006418704986572, "step": 83000}
{"episode_reward": 650.8923092005824, "episode": 84.0, "batch_reward": 0.4687800580561161, "critic_loss": 2.8240613000392916, "actor_loss": -77.39528329467774, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.411153316497803, "step": 84000}
{"episode_reward": 755.5484807327061, "episode": 85.0, "batch_reward": 0.47151595175266264, "critic_loss": 2.860032196044922, "actor_loss": -79.0452752532959, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.799152612686157, "step": 85000}
{"episode_reward": 582.3935244648886, "episode": 86.0, "batch_reward": 0.4740896193385124, "critic_loss": 2.95626697742939, "actor_loss": -78.47274363708496, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.31178379058838, "step": 86000}
{"episode_reward": 712.426699958642, "episode": 87.0, "batch_reward": 0.47748247808218003, "critic_loss": 3.071862353205681, "actor_loss": -78.41445315551758, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.144746780395508, "step": 87000}
{"episode_reward": 691.7336959768447, "episode": 88.0, "batch_reward": 0.4790993451476097, "critic_loss": 3.025094561100006, "actor_loss": -78.4416802444458, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.42535400390625, "step": 88000}
{"episode_reward": 710.5679448586815, "episode": 89.0, "batch_reward": 0.4832814633846283, "critic_loss": 3.125082266688347, "actor_loss": -79.15260747528076, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 25.692348957061768, "step": 89000}
{"episode_reward": 698.378384957097, "episode": 90.0, "batch_reward": 0.4847310476899147, "critic_loss": 3.118272154331207, "actor_loss": -77.10360395050049, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.529634475708008, "step": 90000}
{"episode_reward": 783.7952449591962, "episode": 91.0, "batch_reward": 0.4869093272089958, "critic_loss": 3.215608515024185, "actor_loss": -79.10197889709472, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 40.5252730846405, "step": 91000}
{"episode_reward": 695.0102388247652, "episode": 92.0, "batch_reward": 0.48885810941457747, "critic_loss": 3.327102612018585, "actor_loss": -78.2179662322998, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.392836570739746, "step": 92000}
{"episode_reward": 692.2647224817368, "episode": 93.0, "batch_reward": 0.491053951472044, "critic_loss": 3.295136995792389, "actor_loss": -79.38239858245849, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.798649787902832, "step": 93000}
{"episode_reward": 644.716591989323, "episode": 94.0, "batch_reward": 0.4956942837536335, "critic_loss": 3.2035900126695633, "actor_loss": -78.12743518829346, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.271065950393677, "step": 94000}
{"episode_reward": 827.5857883186131, "episode": 95.0, "batch_reward": 0.4961468771994114, "critic_loss": 3.1953091521263124, "actor_loss": -79.35971589660645, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.508809328079224, "step": 95000}
{"episode_reward": 766.412149255848, "episode": 96.0, "batch_reward": 0.5025285181701183, "critic_loss": 3.1145013611316683, "actor_loss": -79.55490347290039, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.1266667842865, "step": 96000}
{"episode_reward": 788.3442184511093, "episode": 97.0, "batch_reward": 0.5042417738735676, "critic_loss": 3.1962650117874145, "actor_loss": -79.4092049484253, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.576716899871826, "step": 97000}
{"episode_reward": 814.2687338342398, "episode": 98.0, "batch_reward": 0.5061876548826695, "critic_loss": 3.2439006098508836, "actor_loss": -79.37974758148194, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.048627614974976, "step": 98000}
{"episode_reward": 801.3497643126456, "episode": 99.0, "batch_reward": 0.5060684302449227, "critic_loss": 3.1553677099943163, "actor_loss": -79.61752738952637, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 25.1378333568573, "step": 99000}
{"episode_reward": 86.43020023492201, "episode": 100.0, "batch_reward": 0.5064496041834354, "critic_loss": 3.074971909761429, "actor_loss": -79.90745468902588, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.619689226150513, "step": 100000}
{"episode_reward": 827.1184025429626, "episode": 101.0, "batch_reward": 0.5081450444757938, "critic_loss": 3.1787127583026886, "actor_loss": -78.92541818237305, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 40.57699799537659, "step": 101000}
{"episode_reward": 665.9277787811177, "episode": 102.0, "batch_reward": 0.5113865208923817, "critic_loss": 3.2692259434461595, "actor_loss": -80.48611861419678, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.394158363342285, "step": 102000}
{"episode_reward": 821.2828726283873, "episode": 103.0, "batch_reward": 0.5143105229437351, "critic_loss": 3.306358323454857, "actor_loss": -79.5378525466919, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.683359622955322, "step": 103000}
{"episode_reward": 803.995668950449, "episode": 104.0, "batch_reward": 0.5172700732052327, "critic_loss": 3.285267869114876, "actor_loss": -80.84056846618653, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.11298155784607, "step": 104000}
{"episode_reward": 799.5737378760736, "episode": 105.0, "batch_reward": 0.5181058458685875, "critic_loss": 3.2666032015085222, "actor_loss": -80.27740819549561, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.918246507644653, "step": 105000}
{"episode_reward": 871.9252201856503, "episode": 106.0, "batch_reward": 0.5208333474099636, "critic_loss": 3.4296812044382095, "actor_loss": -81.56051977539063, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.359979391098022, "step": 106000}
{"episode_reward": 774.5005545822114, "episode": 107.0, "batch_reward": 0.5231717735528946, "critic_loss": 3.407831250667572, "actor_loss": -81.17760124969483, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.330535888671875, "step": 107000}
{"episode_reward": 740.3577774924231, "episode": 108.0, "batch_reward": 0.5257043704390526, "critic_loss": 3.4374668779373168, "actor_loss": -81.0330824508667, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.20170283317566, "step": 108000}
{"episode_reward": 845.7855933725742, "episode": 109.0, "batch_reward": 0.5303498422503471, "critic_loss": 3.5379878613948823, "actor_loss": -81.53801616668702, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.141815662384033, "step": 109000}
{"episode_reward": 860.3589998823071, "episode": 110.0, "batch_reward": 0.532813575476408, "critic_loss": 3.4772761130332945, "actor_loss": -81.31626641082764, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.12000823020935, "step": 110000}
{"episode_reward": 783.4917235378934, "episode": 111.0, "batch_reward": 0.5340062336623669, "critic_loss": 3.5509922506809235, "actor_loss": -81.30815213775635, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.111836671829224, "step": 111000}
{"episode_reward": 867.1321250833483, "episode": 112.0, "batch_reward": 0.5375202859044075, "critic_loss": 3.5268576118946076, "actor_loss": -82.25457498931885, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.411699533462524, "step": 112000}
{"episode_reward": 703.4068774874404, "episode": 113.0, "batch_reward": 0.5400248005092144, "critic_loss": 3.6380906894207, "actor_loss": -81.0492864074707, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.311119079589844, "step": 113000}
{"episode_reward": 624.415546355498, "episode": 114.0, "batch_reward": 0.5422264884114265, "critic_loss": 3.7781861860752106, "actor_loss": -82.6274617767334, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.933756828308105, "step": 114000}
{"episode_reward": 869.9728070959231, "episode": 115.0, "batch_reward": 0.5397630229890347, "critic_loss": 3.9564844936132433, "actor_loss": -82.67736582183838, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 27.35947871208191, "step": 115000}
{"episode_reward": 112.31995962298097, "episode": 116.0, "batch_reward": 0.5391002404093742, "critic_loss": 4.080568300962448, "actor_loss": -82.53722316741943, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.67733597755432, "step": 116000}
{"episode_reward": 822.3273037713193, "episode": 117.0, "batch_reward": 0.5418247217833996, "critic_loss": 4.069072144269943, "actor_loss": -82.44117685699463, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.403361797332764, "step": 117000}
{"episode_reward": 816.1965818233308, "episode": 118.0, "batch_reward": 0.5449354727864265, "critic_loss": 4.087283580064773, "actor_loss": -82.47884829711914, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.585041522979736, "step": 118000}
{"episode_reward": 779.8937683303008, "episode": 119.0, "batch_reward": 0.5455778445601464, "critic_loss": 4.196304407119751, "actor_loss": -82.30627940368652, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.071855068206787, "step": 119000}
{"episode_reward": 756.6791973000619, "episode": 120.0, "batch_reward": 0.5476110584139824, "critic_loss": 4.223202603340149, "actor_loss": -83.79274559783936, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.84050416946411, "step": 120000}
{"episode_reward": 826.4694399712419, "episode": 121.0, "batch_reward": 0.5494457574188709, "critic_loss": 4.227813538074494, "actor_loss": -83.01556965637207, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.66910696029663, "step": 121000}
{"episode_reward": 779.5446386214956, "episode": 122.0, "batch_reward": 0.5543817344903946, "critic_loss": 4.2486533308029175, "actor_loss": -83.49144924926757, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.68955373764038, "step": 122000}
{"episode_reward": 834.140617423396, "episode": 123.0, "batch_reward": 0.5551953306496143, "critic_loss": 4.1865980758667, "actor_loss": -83.73879941558837, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.89165425300598, "step": 123000}
{"episode_reward": 735.608804621589, "episode": 124.0, "batch_reward": 0.5550854631960392, "critic_loss": 4.231134829759598, "actor_loss": -83.23022159576416, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.264890909194946, "step": 124000}
{"episode_reward": 724.3707960801835, "episode": 125.0, "batch_reward": 0.5574000052511692, "critic_loss": 4.181687222242355, "actor_loss": -84.54561908721924, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.266860723495483, "step": 125000}
{"episode_reward": 858.6986729958786, "episode": 126.0, "batch_reward": 0.558154493957758, "critic_loss": 4.129814563274383, "actor_loss": -83.94531231689453, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.015130043029785, "step": 126000}
{"episode_reward": 884.5536844259193, "episode": 127.0, "batch_reward": 0.5624356598556042, "critic_loss": 4.2051990766525265, "actor_loss": -83.63977694702149, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.199052333831787, "step": 127000}
{"episode_reward": 840.7203068279964, "episode": 128.0, "batch_reward": 0.5639579411745071, "critic_loss": 4.173267586708069, "actor_loss": -83.83923931884766, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.22892165184021, "step": 128000}
{"episode_reward": 849.5883968108341, "episode": 129.0, "batch_reward": 0.5665703625679016, "critic_loss": 4.153881326913834, "actor_loss": -84.23943075561523, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 25.625413179397583, "step": 129000}
{"episode_reward": 494.92802194424723, "episode": 130.0, "batch_reward": 0.566036356240511, "critic_loss": 4.323644300460815, "actor_loss": -83.62667276763916, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.52856135368347, "step": 130000}
{"episode_reward": 833.3576686135985, "episode": 131.0, "batch_reward": 0.5663974166810513, "critic_loss": 4.282351311206818, "actor_loss": -82.47296363830566, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 39.531227111816406, "step": 131000}
{"episode_reward": 776.8017638779095, "episode": 132.0, "batch_reward": 0.5693495627343654, "critic_loss": 4.107662761926651, "actor_loss": -83.15866372680664, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.843635320663452, "step": 132000}
{"episode_reward": 863.3826237109845, "episode": 133.0, "batch_reward": 0.5693830407559871, "critic_loss": 4.031467254400253, "actor_loss": -84.72676790618897, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.086061239242554, "step": 133000}
{"episode_reward": 817.3817887052727, "episode": 134.0, "batch_reward": 0.573100101351738, "critic_loss": 3.953132479429245, "actor_loss": -84.65634813690185, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.59306025505066, "step": 134000}
{"episode_reward": 814.4473022670791, "episode": 135.0, "batch_reward": 0.5743621654510498, "critic_loss": 4.09290603351593, "actor_loss": -84.93533939361572, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.918777227401733, "step": 135000}
{"episode_reward": 836.7559193045878, "episode": 136.0, "batch_reward": 0.5761678699851036, "critic_loss": 4.138430616021156, "actor_loss": -84.93401046752929, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.04809594154358, "step": 136000}
{"episode_reward": 759.0381727286953, "episode": 137.0, "batch_reward": 0.5788054592311382, "critic_loss": 4.152709117770195, "actor_loss": -84.78426260375977, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.850805521011353, "step": 137000}
{"episode_reward": 827.8430147137892, "episode": 138.0, "batch_reward": 0.5803476448059082, "critic_loss": 4.089969654321671, "actor_loss": -83.44355407714843, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.39483380317688, "step": 138000}
{"episode_reward": 870.12028609532, "episode": 139.0, "batch_reward": 0.582032168507576, "critic_loss": 4.043141650438309, "actor_loss": -83.37721192932129, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.369066953659058, "step": 139000}
{"episode_reward": 756.9740602068052, "episode": 140.0, "batch_reward": 0.5836952958703041, "critic_loss": 3.9887325053215026, "actor_loss": -84.04416374969482, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.447087049484253, "step": 140000}
{"episode_reward": 843.143979544062, "episode": 141.0, "batch_reward": 0.585202691078186, "critic_loss": 3.8464004468917845, "actor_loss": -84.31272653961182, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.72614312171936, "step": 141000}
{"episode_reward": 836.7199327769808, "episode": 142.0, "batch_reward": 0.5878537326455117, "critic_loss": 3.7504546536207197, "actor_loss": -84.61442349243164, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.81428599357605, "step": 142000}
{"episode_reward": 869.0305446085792, "episode": 143.0, "batch_reward": 0.5893714837431908, "critic_loss": 3.5759846761226655, "actor_loss": -85.75747267913819, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.468333959579468, "step": 143000}
{"episode_reward": 816.3558360368522, "episode": 144.0, "batch_reward": 0.5914589520096779, "critic_loss": 3.609661383032799, "actor_loss": -85.44504628753663, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.825590133666992, "step": 144000}
{"episode_reward": 811.2599773778378, "episode": 145.0, "batch_reward": 0.5931931747198105, "critic_loss": 3.5369513714313507, "actor_loss": -86.63413801574707, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.95616102218628, "step": 145000}
{"episode_reward": 849.8784752405534, "episode": 146.0, "batch_reward": 0.5937411540150642, "critic_loss": 3.4195839616060257, "actor_loss": -84.97056398773194, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 25.075319051742554, "step": 146000}
{"episode_reward": 868.7090366669383, "episode": 147.0, "batch_reward": 0.5973029672801494, "critic_loss": 3.4723084408044813, "actor_loss": -85.02067746734619, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.72464871406555, "step": 147000}
{"episode_reward": 805.9743153081755, "episode": 148.0, "batch_reward": 0.5978684247136116, "critic_loss": 3.362211881160736, "actor_loss": -85.42145030212403, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.598199605941772, "step": 148000}
{"episode_reward": 879.911932940643, "episode": 149.0, "batch_reward": 0.5983128171265125, "critic_loss": 3.4339664068222047, "actor_loss": -85.3139340209961, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.212538242340088, "step": 149000}
{"episode_reward": 805.0968230586157, "episode": 150.0, "batch_reward": 0.6015829847455024, "critic_loss": 3.4469658946990966, "actor_loss": -85.53379156494141, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "step": 150000}
