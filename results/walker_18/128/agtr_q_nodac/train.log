{"episode": 1.0, "duration": 24.151621103286743, "episode_reward": 27.46298806610516, "step": 1000}
{"episode": 2.0, "duration": 2.145998239517212, "episode_reward": 489.1100087318934, "step": 2000}
{"episode": 3.0, "batch_reward": 0.2429566255516909, "actor_loss": -83.96021609022027, "actor_target_entropy": -6.0, "alpha_value": 0.002134017781850189, "duration": 65.99385404586792, "episode_reward": 13.521289735767127, "step": 3000}
{"episode": 4.0, "batch_reward": 0.1607736220434308, "actor_loss": -81.37711502075196, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.831164360046387, "episode_reward": 71.08387277793057, "step": 4000}
{"episode": 5.0, "batch_reward": 0.13441261506080626, "actor_loss": -80.54259854125976, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.779049158096313, "episode_reward": 5.2954232031057185, "step": 5000}
{"episode": 6.0, "batch_reward": 0.12169689721614123, "actor_loss": -79.80904577636718, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.439239978790283, "episode_reward": 103.25123048256499, "step": 6000}
{"episode": 7.0, "batch_reward": 0.12706506327539682, "actor_loss": -80.06519094848633, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.34893822669983, "episode_reward": 193.6301364947818, "step": 7000}
{"episode": 8.0, "batch_reward": 0.126884819611907, "actor_loss": -80.39836149597168, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.667011499404907, "episode_reward": 79.93879359489449, "step": 8000}
{"episode": 9.0, "batch_reward": 0.1390718858912587, "actor_loss": -80.7946930847168, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.197863340377808, "episode_reward": 393.4162995280449, "step": 9000}
{"episode": 10.0, "batch_reward": 0.15682924193143843, "actor_loss": -81.21791247558593, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.424656867980957, "episode_reward": 151.47175160035934, "step": 10000}
{"episode": 11.0, "batch_reward": 0.14824002964794636, "actor_loss": -81.3472444152832, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.240849018096924, "episode_reward": 72.96222580132452, "step": 11000}
{"episode": 12.0, "batch_reward": 0.15433519873023033, "actor_loss": -81.64234921264648, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.55430030822754, "episode_reward": 341.68357646209233, "step": 12000}
{"episode": 13.0, "batch_reward": 0.15963543913513423, "actor_loss": -81.70270220947266, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.821696519851685, "episode_reward": 77.56769361027506, "step": 13000}
{"episode": 14.0, "batch_reward": 0.15735863400250674, "actor_loss": -81.50598858642579, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.9544198513031, "episode_reward": 289.5641182162394, "step": 14000}
{"episode": 15.0, "batch_reward": 0.17483856846392154, "actor_loss": -81.9516929321289, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.504708528518677, "episode_reward": 443.8079295407998, "step": 15000}
{"episode": 16.0, "batch_reward": 0.19218362091481686, "actor_loss": -82.28394190979004, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.178436756134033, "episode_reward": 447.2452843324023, "step": 16000}
{"episode": 17.0, "batch_reward": 0.20632575845718384, "actor_loss": -82.53122857666015, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.275644779205322, "episode_reward": 422.78358817098626, "step": 17000}
{"episode": 18.0, "batch_reward": 0.2189548846334219, "actor_loss": -82.79505596923828, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.304407358169556, "episode_reward": 432.2187987068345, "step": 18000}
{"episode": 19.0, "batch_reward": 0.22845096176862717, "actor_loss": -82.91965290832519, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.87329077720642, "episode_reward": 379.8093413828382, "step": 19000}
{"episode": 20.0, "batch_reward": 0.23528849929571152, "actor_loss": -82.99509941101074, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.211730003356934, "episode_reward": 368.8129627463317, "step": 20000}
{"episode": 21.0, "batch_reward": 0.244561750754714, "actor_loss": -83.18148735046387, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.69768190383911, "episode_reward": 394.4308742495205, "step": 21000}
{"episode": 22.0, "batch_reward": 0.24871283516287804, "actor_loss": -83.26952430725098, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.26043128967285, "episode_reward": 341.9223089012189, "step": 22000}
{"episode": 23.0, "batch_reward": 0.25673606161773205, "actor_loss": -83.43900456237793, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.15253734588623, "episode_reward": 509.2717281914226, "step": 23000}
{"episode": 24.0, "batch_reward": 0.2657311901003122, "actor_loss": -83.61344384765626, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.40138077735901, "episode_reward": 422.3676255980364, "step": 24000}
{"episode": 25.0, "batch_reward": 0.2708199021965265, "actor_loss": -83.75298352050781, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.17602014541626, "episode_reward": 380.0696230079275, "step": 25000}
{"episode": 26.0, "batch_reward": 0.27669715782999993, "actor_loss": -83.83644055175782, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.366883516311646, "episode_reward": 380.56774509671664, "step": 26000}
{"episode": 27.0, "batch_reward": 0.27989672076702116, "actor_loss": -83.83969052124023, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.52565622329712, "episode_reward": 397.9293802266473, "step": 27000}
{"episode": 28.0, "batch_reward": 0.2788654058277607, "actor_loss": -83.81032553100586, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.22647786140442, "episode_reward": 67.0785200704659, "step": 28000}
{"episode": 29.0, "batch_reward": 0.27602271400392053, "actor_loss": -83.73521347045899, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.670284748077393, "episode_reward": 226.44546928883815, "step": 29000}
{"episode": 30.0, "batch_reward": 0.2757312766611576, "actor_loss": -83.6546085357666, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.383018970489502, "episode_reward": 454.1740023461694, "step": 30000}
{"episode": 31.0, "batch_reward": 0.28261072967946527, "actor_loss": -83.76550349426269, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.32743430137634, "episode_reward": 486.772597173889, "step": 31000}
{"episode": 32.0, "batch_reward": 0.2880674755424261, "actor_loss": -83.85915884399414, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.43297052383423, "episode_reward": 438.3184847317558, "step": 32000}
{"episode": 33.0, "batch_reward": 0.29140609654784205, "actor_loss": -83.89357928466796, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.65933060646057, "episode_reward": 469.7446829236736, "step": 33000}
{"episode": 34.0, "batch_reward": 0.29747336603701113, "actor_loss": -83.97085243225098, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.33391785621643, "episode_reward": 290.36127231111635, "step": 34000}
{"episode": 35.0, "batch_reward": 0.2975694783627987, "actor_loss": -83.99976756286621, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.933746814727783, "episode_reward": 462.77316372697584, "step": 35000}
{"episode": 36.0, "batch_reward": 0.3021749691069126, "actor_loss": -84.08139707946778, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.490307569503784, "episode_reward": 475.45077311593366, "step": 36000}
{"episode": 37.0, "batch_reward": 0.3091026121675968, "actor_loss": -84.20303941345215, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.334567070007324, "episode_reward": 529.4048447603029, "step": 37000}
{"episode": 38.0, "batch_reward": 0.3132255697995424, "actor_loss": -84.3494324798584, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.618158102035522, "episode_reward": 453.81099771203316, "step": 38000}
{"episode": 39.0, "batch_reward": 0.31486302784085274, "actor_loss": -84.40753959655761, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.661840200424194, "episode_reward": 398.90965101515707, "step": 39000}
{"episode": 40.0, "batch_reward": 0.31798410654067993, "actor_loss": -84.4558040008545, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.578647136688232, "episode_reward": 345.37013805068585, "step": 40000}
{"episode": 41.0, "batch_reward": 0.31710573522746566, "actor_loss": -84.44356756591797, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.958873987197876, "episode_reward": 325.7685881295919, "step": 41000}
{"episode": 42.0, "batch_reward": 0.3197460099607706, "actor_loss": -84.50125428771973, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.705808401107788, "episode_reward": 471.39715322287367, "step": 42000}
{"episode": 43.0, "batch_reward": 0.3237756870388985, "actor_loss": -84.55985246276856, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.90328359603882, "episode_reward": 375.36094708126456, "step": 43000}
{"episode": 44.0, "batch_reward": 0.32252051819860933, "actor_loss": -84.52367147827148, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.06916308403015, "episode_reward": 355.84442956939665, "step": 44000}
{"episode": 45.0, "batch_reward": 0.3257225291132927, "actor_loss": -84.56494480895996, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.324340343475342, "episode_reward": 482.0006421751402, "step": 45000}
{"episode": 46.0, "batch_reward": 0.32596575704216957, "actor_loss": -84.63012181091308, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.328350067138672, "episode_reward": 154.74496369204846, "step": 46000}
{"episode": 47.0, "batch_reward": 0.32178163838386536, "actor_loss": -84.55414604187011, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.139543533325195, "episode_reward": 306.00707700026123, "step": 47000}
{"episode": 48.0, "batch_reward": 0.32430999314785003, "actor_loss": -84.57026641845704, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.061319589614868, "episode_reward": 357.06802535059467, "step": 48000}
{"episode": 49.0, "batch_reward": 0.3255176876485348, "actor_loss": -84.58201889038087, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.742420434951782, "episode_reward": 434.3691704453404, "step": 49000}
{"episode": 50.0, "batch_reward": 0.32478415513038633, "actor_loss": -84.55490209960938, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.83565044403076, "episode_reward": 203.3057723966751, "step": 50000}
{"episode": 51.0, "batch_reward": 0.325042337089777, "actor_loss": -84.55983782958984, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 43.388850927352905, "episode_reward": 500.90045129578766, "step": 51000}
{"episode": 52.0, "batch_reward": 0.3253221455514431, "actor_loss": -84.50656608581544, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.463254690170288, "episode_reward": 83.06605080197706, "step": 52000}
{"episode": 53.0, "batch_reward": 0.3222563618123531, "actor_loss": -84.47938511657715, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.93720769882202, "episode_reward": 343.4001150876188, "step": 53000}
{"episode": 54.0, "batch_reward": 0.3233319457769394, "actor_loss": -84.51123890686036, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.362076997756958, "episode_reward": 410.7586959664027, "step": 54000}
{"episode": 55.0, "batch_reward": 0.32344776824116706, "actor_loss": -84.46806607055665, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.45278835296631, "episode_reward": 202.32785593494, "step": 55000}
{"episode": 56.0, "batch_reward": 0.32346152383089066, "actor_loss": -84.48696220397949, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.67444896697998, "episode_reward": 555.6634865872405, "step": 56000}
{"episode": 57.0, "batch_reward": 0.3281577962636948, "actor_loss": -84.56557568359375, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.358424425125122, "episode_reward": 477.56900084585953, "step": 57000}
{"episode": 58.0, "batch_reward": 0.3293354322612286, "actor_loss": -84.59177519226074, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.262372255325317, "episode_reward": 427.4976891238275, "step": 58000}
{"episode": 59.0, "batch_reward": 0.3301139121055603, "actor_loss": -84.6188095703125, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.96290159225464, "episode_reward": 273.02434185211143, "step": 59000}
{"episode": 60.0, "batch_reward": 0.33024723437428477, "actor_loss": -84.5976630859375, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.019155502319336, "episode_reward": 279.743944925387, "step": 60000}
{"episode": 61.0, "batch_reward": 0.32842059606313706, "actor_loss": -84.56043865966797, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 43.969642162323, "episode_reward": 315.45749590171846, "step": 61000}
{"episode": 62.0, "batch_reward": 0.3293851100951433, "actor_loss": -84.60798919677734, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.76723885536194, "episode_reward": 436.2429685557674, "step": 62000}
{"episode": 63.0, "batch_reward": 0.33162834361195564, "actor_loss": -84.61559057617187, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.20389699935913, "episode_reward": 435.2930203089622, "step": 63000}
{"episode": 64.0, "batch_reward": 0.33342454412579536, "actor_loss": -84.65177444458008, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.075061798095703, "episode_reward": 462.28459891257967, "step": 64000}
{"episode": 65.0, "batch_reward": 0.33618061885237693, "actor_loss": -84.77140483093261, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.35588312149048, "episode_reward": 504.08739156975577, "step": 65000}
{"episode": 66.0, "batch_reward": 0.3380938004851341, "actor_loss": -84.72219488525391, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.06345295906067, "episode_reward": 447.54925011542116, "step": 66000}
{"episode": 67.0, "batch_reward": 0.33981367549300195, "actor_loss": -84.7543359375, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.575557947158813, "episode_reward": 399.275324197221, "step": 67000}
{"episode": 68.0, "batch_reward": 0.3394602113366127, "actor_loss": -84.75312754821778, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.492275714874268, "episode_reward": 431.82631201665833, "step": 68000}
{"episode": 69.0, "batch_reward": 0.34319569966197017, "actor_loss": -84.80254220581055, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.39915370941162, "episode_reward": 549.0264921112603, "step": 69000}
{"episode": 70.0, "batch_reward": 0.3455727377831936, "actor_loss": -84.8823498840332, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.935291290283203, "episode_reward": 521.5020550202861, "step": 70000}
{"episode": 71.0, "batch_reward": 0.34878198558092116, "actor_loss": -84.92736209106445, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.92472815513611, "episode_reward": 543.9313014727867, "step": 71000}
{"episode": 72.0, "batch_reward": 0.347510896474123, "actor_loss": -84.95603176879882, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.32608413696289, "episode_reward": 129.04773055792785, "step": 72000}
{"episode": 73.0, "batch_reward": 0.34711290779709814, "actor_loss": -84.85537260437012, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.348116636276245, "episode_reward": 502.8393462721292, "step": 73000}
{"episode": 74.0, "batch_reward": 0.34918592020869255, "actor_loss": -84.94859350585938, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.47863745689392, "episode_reward": 537.7550422622523, "step": 74000}
{"episode": 75.0, "batch_reward": 0.3511654847562313, "actor_loss": -85.02456889343262, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.325679063796997, "episode_reward": 527.1669986000778, "step": 75000}
{"episode": 76.0, "batch_reward": 0.35513973352313044, "actor_loss": -85.07758917236328, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.431425094604492, "episode_reward": 513.0084177186375, "step": 76000}
{"episode": 77.0, "batch_reward": 0.3566599963605404, "actor_loss": -85.12314233398438, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.53852939605713, "episode_reward": 484.80856503245764, "step": 77000}
{"episode": 78.0, "batch_reward": 0.3579207895696163, "actor_loss": -85.13376239013672, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.559966325759888, "episode_reward": 560.0356705342653, "step": 78000}
{"episode": 79.0, "batch_reward": 0.3614323312342167, "actor_loss": -85.20569161987305, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.89768648147583, "episode_reward": 548.0908857199455, "step": 79000}
{"episode": 80.0, "batch_reward": 0.36427801856398584, "actor_loss": -85.26710227966309, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.04324769973755, "episode_reward": 625.0180678043075, "step": 80000}
{"episode": 81.0, "batch_reward": 0.36572696551680567, "actor_loss": -85.32371101379394, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.17428684234619, "episode_reward": 357.97746077905293, "step": 81000}
{"episode": 82.0, "batch_reward": 0.3651075354814529, "actor_loss": -85.29662022399903, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.237526655197144, "episode_reward": 498.71031030424535, "step": 82000}
{"episode": 83.0, "batch_reward": 0.36824648451805114, "actor_loss": -85.32765414428711, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.607242345809937, "episode_reward": 496.06021794795555, "step": 83000}
{"episode": 84.0, "batch_reward": 0.3694122547805309, "actor_loss": -85.42338008117676, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.536810874938965, "episode_reward": 386.5599037834286, "step": 84000}
{"episode": 85.0, "batch_reward": 0.36890569975972176, "actor_loss": -85.35310743713379, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.516905069351196, "episode_reward": 437.291626315219, "step": 85000}
{"episode": 86.0, "batch_reward": 0.36858593186736105, "actor_loss": -85.35729940795899, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.11305832862854, "episode_reward": 393.45781072075965, "step": 86000}
{"episode": 87.0, "batch_reward": 0.37000366365909576, "actor_loss": -85.38157081604004, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.43189287185669, "episode_reward": 521.6304867797481, "step": 87000}
{"episode": 88.0, "batch_reward": 0.37232985165715216, "actor_loss": -85.36453643798828, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.776413440704346, "episode_reward": 549.4284938632202, "step": 88000}
{"episode": 89.0, "batch_reward": 0.3736493889987469, "actor_loss": -85.46116036987304, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.372005701065063, "episode_reward": 426.53102300802567, "step": 89000}
{"episode": 90.0, "batch_reward": 0.37457058268785476, "actor_loss": -85.4226962890625, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.13855791091919, "episode_reward": 317.6297646476134, "step": 90000}
{"episode": 91.0, "batch_reward": 0.37374375158548356, "actor_loss": -85.45882513427735, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.047158002853394, "episode_reward": 404.8843582059518, "step": 91000}
{"episode": 92.0, "batch_reward": 0.3721974793970585, "actor_loss": -85.43123886108398, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.87557625770569, "episode_reward": 323.724259361087, "step": 92000}
{"episode": 93.0, "batch_reward": 0.3736659041047096, "actor_loss": -85.42488973999023, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.177321195602417, "episode_reward": 526.3436194431587, "step": 93000}
{"episode": 94.0, "batch_reward": 0.3769753877222538, "actor_loss": -85.48417802429199, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.255096673965454, "episode_reward": 461.59169844835463, "step": 94000}
{"episode": 95.0, "batch_reward": 0.3740287932753563, "actor_loss": -85.43302677917481, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.490702390670776, "episode_reward": 300.51584630419444, "step": 95000}
{"episode": 96.0, "batch_reward": 0.37492031762003897, "actor_loss": -85.47188734436035, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.473570346832275, "episode_reward": 416.6243424344266, "step": 96000}
{"episode": 97.0, "batch_reward": 0.37504100701212884, "actor_loss": -85.4704686126709, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.509771823883057, "episode_reward": 389.1193874235907, "step": 97000}
{"episode": 98.0, "batch_reward": 0.37511553505063056, "actor_loss": -85.4436124420166, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.039210557937622, "episode_reward": 504.8781301830091, "step": 98000}
{"episode": 99.0, "batch_reward": 0.3765117315351963, "actor_loss": -85.48281341552735, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.245647192001343, "episode_reward": 368.3934970044041, "step": 99000}
{"episode": 100.0, "batch_reward": 0.3769105408191681, "actor_loss": -85.50359457397461, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.397360801696777, "episode_reward": 540.1595242660482, "step": 100000}
{"episode": 101.0, "batch_reward": 0.38001458764076235, "actor_loss": -85.55795082092285, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.59533953666687, "episode_reward": 439.9365026759174, "step": 101000}
{"episode": 102.0, "batch_reward": 0.3785258895456791, "actor_loss": -85.55026550292969, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.708125352859497, "episode_reward": 266.26509441113495, "step": 102000}
{"episode": 103.0, "batch_reward": 0.37862664604187013, "actor_loss": -85.53861251831054, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.52232050895691, "episode_reward": 537.9804399740076, "step": 103000}
{"episode": 104.0, "batch_reward": 0.38166108694672585, "actor_loss": -85.59076907348633, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.52692461013794, "episode_reward": 571.9070916709315, "step": 104000}
{"episode": 105.0, "batch_reward": 0.3821676653623581, "actor_loss": -85.61577380371094, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.34153151512146, "episode_reward": 483.84075217756913, "step": 105000}
{"episode": 106.0, "batch_reward": 0.38341842755675315, "actor_loss": -85.61119303894043, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.435854196548462, "episode_reward": 462.6162887562802, "step": 106000}
{"episode": 107.0, "batch_reward": 0.3830626753270626, "actor_loss": -85.63315667724609, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.5083167552948, "episode_reward": 116.6750729947667, "step": 107000}
{"episode": 108.0, "batch_reward": 0.3798887432217598, "actor_loss": -85.5505613861084, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.10583186149597, "episode_reward": 493.77893585382344, "step": 108000}
{"episode": 109.0, "batch_reward": 0.38359891703724863, "actor_loss": -85.6863370513916, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.55854320526123, "episode_reward": 504.31405400950854, "step": 109000}
{"episode": 110.0, "batch_reward": 0.38481212773919105, "actor_loss": -85.68064285278321, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.863587141036987, "episode_reward": 480.80724862475336, "step": 110000}
{"episode": 111.0, "batch_reward": 0.38367036420106887, "actor_loss": -85.67727671813965, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 43.82256865501404, "episode_reward": 439.909419225517, "step": 111000}
{"episode": 112.0, "batch_reward": 0.38334778717160223, "actor_loss": -85.66018786621093, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.26002311706543, "episode_reward": 468.76727069129623, "step": 112000}
{"episode": 113.0, "batch_reward": 0.38448657688498494, "actor_loss": -85.6850011138916, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.979754209518433, "episode_reward": 459.31710802629095, "step": 113000}
{"episode": 114.0, "batch_reward": 0.38484436804056166, "actor_loss": -85.67434234619141, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.46680474281311, "episode_reward": 154.26597586775952, "step": 114000}
{"episode": 115.0, "batch_reward": 0.3842682664990425, "actor_loss": -85.64185226440429, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.318705797195435, "episode_reward": 603.2097340319892, "step": 115000}
{"episode": 116.0, "batch_reward": 0.3853120972216129, "actor_loss": -85.68533270263671, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.428309440612793, "episode_reward": 509.71575736349183, "step": 116000}
{"episode": 117.0, "batch_reward": 0.3873763946890831, "actor_loss": -85.74583247375489, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.467849254608154, "episode_reward": 590.652142813891, "step": 117000}
{"episode": 118.0, "batch_reward": 0.3882318100035191, "actor_loss": -85.7655021057129, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.169955253601074, "episode_reward": 525.073387330543, "step": 118000}
{"episode": 119.0, "batch_reward": 0.38840650898218154, "actor_loss": -85.72995738220214, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.809536457061768, "episode_reward": 362.0487926170399, "step": 119000}
{"episode": 120.0, "batch_reward": 0.389508504062891, "actor_loss": -85.77413478088378, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.62872886657715, "episode_reward": 607.0115364746415, "step": 120000}
{"episode": 121.0, "batch_reward": 0.39050248670578, "actor_loss": -85.80507089233399, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 36.3951370716095, "episode_reward": 596.8968198789744, "step": 121000}
{"episode": 122.0, "batch_reward": 0.39254600352048874, "actor_loss": -85.84995951843261, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.210878610610962, "episode_reward": 443.44299067608006, "step": 122000}
{"episode": 123.0, "batch_reward": 0.39365535071492197, "actor_loss": -85.82807817077637, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.475430727005005, "episode_reward": 542.9321949575259, "step": 123000}
{"episode": 124.0, "batch_reward": 0.39462769532203673, "actor_loss": -85.89180854797364, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.393256664276123, "episode_reward": 512.6705177413113, "step": 124000}
{"episode": 125.0, "batch_reward": 0.39553735890984537, "actor_loss": -85.92456857299804, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.351770877838135, "episode_reward": 500.12462550794197, "step": 125000}
{"episode": 126.0, "batch_reward": 0.3965764796435833, "actor_loss": -85.9193145904541, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.445810794830322, "episode_reward": 453.885578777366, "step": 126000}
{"episode": 127.0, "batch_reward": 0.3965153083205223, "actor_loss": -85.95022895812988, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.70461869239807, "episode_reward": 535.0226519274579, "step": 127000}
{"episode": 128.0, "batch_reward": 0.39891727617383005, "actor_loss": -86.01796897888184, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.69047212600708, "episode_reward": 553.3257623776946, "step": 128000}
{"episode": 129.0, "batch_reward": 0.39980405911803246, "actor_loss": -85.98516250610352, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.989271879196167, "episode_reward": 459.98066936146415, "step": 129000}
{"episode": 130.0, "batch_reward": 0.39930393916368484, "actor_loss": -85.9774038696289, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.26479172706604, "episode_reward": 409.21580623667717, "step": 130000}
{"episode": 131.0, "batch_reward": 0.4003897859156132, "actor_loss": -85.9924291229248, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 32.6160888671875, "episode_reward": 570.2503521409569, "step": 131000}
{"episode": 132.0, "batch_reward": 0.39968814730644225, "actor_loss": -86.0418815460205, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.595890998840332, "episode_reward": 379.0498436704341, "step": 132000}
{"episode": 133.0, "batch_reward": 0.40010218024253846, "actor_loss": -86.00642372131348, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.980819940567017, "episode_reward": 516.7279488612858, "step": 133000}
{"episode": 134.0, "batch_reward": 0.3993653891682625, "actor_loss": -85.99014219665527, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.96036195755005, "episode_reward": 434.7491848434399, "step": 134000}
{"episode": 135.0, "batch_reward": 0.4013461875021458, "actor_loss": -85.98902911376953, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.253458976745605, "episode_reward": 328.04527765776965, "step": 135000}
{"episode": 136.0, "batch_reward": 0.40284537345170973, "actor_loss": -86.06465908813476, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.874753952026367, "episode_reward": 600.8763308307279, "step": 136000}
{"episode": 137.0, "batch_reward": 0.4036890622973442, "actor_loss": -86.00478840637207, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.942394495010376, "episode_reward": 282.0522189596804, "step": 137000}
{"episode": 138.0, "batch_reward": 0.4019843565523624, "actor_loss": -86.04337098693847, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.952659368515015, "episode_reward": 498.83600636502007, "step": 138000}
{"episode": 139.0, "batch_reward": 0.40349494537711145, "actor_loss": -86.0721078491211, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.021251678466797, "episode_reward": 606.4588747637534, "step": 139000}
{"episode": 140.0, "batch_reward": 0.40327757206559184, "actor_loss": -86.04693659973144, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.761495351791382, "episode_reward": 202.89179887764038, "step": 140000}
{"episode": 141.0, "batch_reward": 0.403540585398674, "actor_loss": -86.07430503845215, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 32.40699315071106, "episode_reward": 559.012703771957, "step": 141000}
{"episode": 142.0, "batch_reward": 0.404361666738987, "actor_loss": -86.08524404907226, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.3357675075531, "episode_reward": 481.1284874108636, "step": 142000}
{"episode": 143.0, "batch_reward": 0.4055423431098461, "actor_loss": -86.08739044189453, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.8351411819458, "episode_reward": 519.1916399887726, "step": 143000}
{"episode": 144.0, "batch_reward": 0.40355941581726074, "actor_loss": -86.02922981262208, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.19779109954834, "episode_reward": 107.0648643725109, "step": 144000}
{"episode": 145.0, "batch_reward": 0.4024319553375244, "actor_loss": -85.9916199798584, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.854148626327515, "episode_reward": 384.1821229421428, "step": 145000}
{"episode": 146.0, "batch_reward": 0.4022433942854404, "actor_loss": -86.01721151733399, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.83939266204834, "episode_reward": 556.3719240720258, "step": 146000}
{"episode": 147.0, "batch_reward": 0.40419426438212397, "actor_loss": -86.06442974853516, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.00309681892395, "episode_reward": 588.6540869149838, "step": 147000}
{"episode": 148.0, "batch_reward": 0.406154621720314, "actor_loss": -86.13159959411621, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.73905920982361, "episode_reward": 402.0953558996203, "step": 148000}
{"episode": 149.0, "batch_reward": 0.4045276248157024, "actor_loss": -86.09112820434571, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.63326382637024, "episode_reward": 454.76735000087183, "step": 149000}
{"episode": 150.0, "batch_reward": 0.4048546932041645, "actor_loss": -86.0966212158203, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "step": 150000}
