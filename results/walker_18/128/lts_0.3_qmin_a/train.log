{"episode_reward": 0.0, "episode": 1.0, "duration": 22.012585878372192, "step": 1000}
{"episode_reward": 27.46298806610516, "episode": 2.0, "duration": 1.9626178741455078, "step": 2000}
{"episode_reward": 489.1100087318934, "episode": 3.0, "batch_reward": 0.24287391423423832, "critic_loss": 0.14399889572956745, "actor_loss": -27.43158818687983, "actor_target_entropy": -6.0, "alpha_value": 0.002134017781850189, "duration": 63.50174117088318, "step": 3000}
{"episode_reward": 12.525308562155706, "episode": 4.0, "batch_reward": 0.1613559198155999, "critic_loss": 0.5442749404907227, "actor_loss": -32.88829279899597, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.014716863632202, "step": 4000}
{"episode_reward": 62.58496993764653, "episode": 5.0, "batch_reward": 0.14128228620439767, "critic_loss": 0.829567711442709, "actor_loss": -33.67595099830628, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.43661332130432, "step": 5000}
{"episode_reward": 66.36325270115269, "episode": 6.0, "batch_reward": 0.13385761880874633, "critic_loss": 1.1091322614252568, "actor_loss": -34.82328645515442, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.48778986930847, "step": 6000}
{"episode_reward": 131.82053186951697, "episode": 7.0, "batch_reward": 0.12569269930571317, "critic_loss": 1.5429334546923636, "actor_loss": -34.016865003585814, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.9226496219635, "step": 7000}
{"episode_reward": 112.98816995099062, "episode": 8.0, "batch_reward": 0.13173251685500145, "critic_loss": 2.3093612080812456, "actor_loss": -39.17906466293335, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.652644157409668, "step": 8000}
{"episode_reward": 167.4383068031351, "episode": 9.0, "batch_reward": 0.1361827053502202, "critic_loss": 2.191431327223778, "actor_loss": -37.99287311935425, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.126505374908447, "step": 9000}
{"episode_reward": 143.99984428739882, "episode": 10.0, "batch_reward": 0.14597804311662912, "critic_loss": 2.6096365180015564, "actor_loss": -40.856306922912594, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.5754873752594, "step": 10000}
{"episode_reward": 338.0627352570664, "episode": 11.0, "batch_reward": 0.15841783134639262, "critic_loss": 3.476747182607651, "actor_loss": -40.74785972595215, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.51411724090576, "step": 11000}
{"episode_reward": 206.9393780682433, "episode": 12.0, "batch_reward": 0.1717177939787507, "critic_loss": 3.9780448377132416, "actor_loss": -46.303987033843995, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.5448637008667, "step": 12000}
{"episode_reward": 423.71807061651, "episode": 13.0, "batch_reward": 0.18540685435384513, "critic_loss": 3.884262427568436, "actor_loss": -48.48934823989868, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.415054321289062, "step": 13000}
{"episode_reward": 220.0613359638835, "episode": 14.0, "batch_reward": 0.19117189906537532, "critic_loss": 3.7225466923713686, "actor_loss": -51.995463516235354, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.314568042755127, "step": 14000}
{"episode_reward": 384.51463465760037, "episode": 15.0, "batch_reward": 0.1944681976735592, "critic_loss": 3.0881771258115767, "actor_loss": -53.084818038940426, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.476625442504883, "step": 15000}
{"episode_reward": 59.14588984222101, "episode": 16.0, "batch_reward": 0.1960978119522333, "critic_loss": 2.4890272791385653, "actor_loss": -54.08697147369385, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.42111825942993, "step": 16000}
{"episode_reward": 409.88600872938923, "episode": 17.0, "batch_reward": 0.20015685199201108, "critic_loss": 2.2659464613199236, "actor_loss": -54.07552501678467, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.257197618484497, "step": 17000}
{"episode_reward": 97.43651395733858, "episode": 18.0, "batch_reward": 0.19514904783666134, "critic_loss": 2.080015866518021, "actor_loss": -54.85074271392822, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.295503854751587, "step": 18000}
{"episode_reward": 91.91881860414708, "episode": 19.0, "batch_reward": 0.18909011182934046, "critic_loss": 1.8849172295928, "actor_loss": -53.87062702941895, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.38224697113037, "step": 19000}
{"episode_reward": 85.5715414157803, "episode": 20.0, "batch_reward": 0.183277432218194, "critic_loss": 1.479752612888813, "actor_loss": -53.82431797027588, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.581432580947876, "step": 20000}
{"episode_reward": 80.19593815533896, "episode": 21.0, "batch_reward": 0.1829167980402708, "critic_loss": 1.264092861175537, "actor_loss": -52.84777660369873, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.32456874847412, "step": 21000}
{"episode_reward": 365.2891504097147, "episode": 22.0, "batch_reward": 0.1891449395120144, "critic_loss": 1.187830981850624, "actor_loss": -52.995565055847166, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.41188144683838, "step": 22000}
{"episode_reward": 285.83278489582966, "episode": 23.0, "batch_reward": 0.19967553447186948, "critic_loss": 1.2555606278777123, "actor_loss": -51.89225244140625, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.6131649017334, "step": 23000}
{"episode_reward": 381.7593453991476, "episode": 24.0, "batch_reward": 0.20135406868159772, "critic_loss": 1.1813952988982201, "actor_loss": -52.03867240905762, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.444326162338257, "step": 24000}
{"episode_reward": 148.67380097834697, "episode": 25.0, "batch_reward": 0.1972450689524412, "critic_loss": 1.1334882761836051, "actor_loss": -52.60096457672119, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.551011562347412, "step": 25000}
{"episode_reward": 137.17833108375706, "episode": 26.0, "batch_reward": 0.20265990944206716, "critic_loss": 1.1428653840422631, "actor_loss": -51.613818481445314, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.413650035858154, "step": 26000}
{"episode_reward": 472.7286266820227, "episode": 27.0, "batch_reward": 0.21318762247264386, "critic_loss": 1.1367130467295647, "actor_loss": -52.34895331573486, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.425878286361694, "step": 27000}
{"episode_reward": 531.4625715136849, "episode": 28.0, "batch_reward": 0.2251853945106268, "critic_loss": 1.0745489548444749, "actor_loss": -53.62282166290283, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.36613631248474, "step": 28000}
{"episode_reward": 489.65234876543275, "episode": 29.0, "batch_reward": 0.23205963937938212, "critic_loss": 1.1133357660770415, "actor_loss": -52.74521649169922, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.71593451499939, "step": 29000}
{"episode_reward": 421.1574136490874, "episode": 30.0, "batch_reward": 0.23719987718760968, "critic_loss": 1.100063947379589, "actor_loss": -53.46810134887696, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.418850660324097, "step": 30000}
{"episode_reward": 397.34843062253134, "episode": 31.0, "batch_reward": 0.24710724353790284, "critic_loss": 1.0596927388906479, "actor_loss": -54.73315640258789, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.866963624954224, "step": 31000}
{"episode_reward": 583.0596047427772, "episode": 32.0, "batch_reward": 0.2581884915679693, "critic_loss": 0.990980360776186, "actor_loss": -53.81039695739746, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.395596265792847, "step": 32000}
{"episode_reward": 574.8565034376952, "episode": 33.0, "batch_reward": 0.2609025034457445, "critic_loss": 0.9583737841248512, "actor_loss": -54.787451156616214, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.402061223983765, "step": 33000}
{"episode_reward": 106.45774164431042, "episode": 34.0, "batch_reward": 0.2634697880744934, "critic_loss": 0.9184106903374195, "actor_loss": -55.652575332641604, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.54784059524536, "step": 34000}
{"episode_reward": 616.819190221264, "episode": 35.0, "batch_reward": 0.27344170477986335, "critic_loss": 0.9628613981604576, "actor_loss": -54.67805749511719, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.424573183059692, "step": 35000}
{"episode_reward": 615.2740493389699, "episode": 36.0, "batch_reward": 0.28122644445300105, "critic_loss": 0.9266567364037037, "actor_loss": -55.94600246429443, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.447323083877563, "step": 36000}
{"episode_reward": 567.3308031430971, "episode": 37.0, "batch_reward": 0.2858571847528219, "critic_loss": 0.9322928231358528, "actor_loss": -55.093482749938964, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.31483483314514, "step": 37000}
{"episode_reward": 447.95031877972434, "episode": 38.0, "batch_reward": 0.29464372104406356, "critic_loss": 0.972522175848484, "actor_loss": -54.3821947555542, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.429495334625244, "step": 38000}
{"episode_reward": 650.3504988121618, "episode": 39.0, "batch_reward": 0.3044498382806778, "critic_loss": 0.9755079383254052, "actor_loss": -55.92944060516358, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.22049856185913, "step": 39000}
{"episode_reward": 664.6075497160255, "episode": 40.0, "batch_reward": 0.3112924290299416, "critic_loss": 1.0428630308806897, "actor_loss": -57.241210968017576, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.844200372695923, "step": 40000}
{"episode_reward": 394.05510949139716, "episode": 41.0, "batch_reward": 0.3141800248473883, "critic_loss": 1.0756876081228257, "actor_loss": -56.91475834655762, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.18157958984375, "step": 41000}
{"episode_reward": 539.2790229413133, "episode": 42.0, "batch_reward": 0.3218199948221445, "critic_loss": 1.234804060280323, "actor_loss": -56.89078037261963, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.74565362930298, "step": 42000}
{"episode_reward": 618.1782846341792, "episode": 43.0, "batch_reward": 0.3278509073853493, "critic_loss": 1.253955363214016, "actor_loss": -57.209342575073244, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.491656064987183, "step": 43000}
{"episode_reward": 619.4162340480361, "episode": 44.0, "batch_reward": 0.334991395264864, "critic_loss": 1.373414111852646, "actor_loss": -57.49221576690674, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.737714767456055, "step": 44000}
{"episode_reward": 612.2130977999273, "episode": 45.0, "batch_reward": 0.33908146154880525, "critic_loss": 1.3908199962973595, "actor_loss": -56.402571815490724, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.835176944732666, "step": 45000}
{"episode_reward": 604.3960905994581, "episode": 46.0, "batch_reward": 0.3464875916838646, "critic_loss": 1.5143584024310113, "actor_loss": -56.190384895324705, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.727386713027954, "step": 46000}
{"episode_reward": 653.8300106025398, "episode": 47.0, "batch_reward": 0.3521293149590492, "critic_loss": 1.5723278363347053, "actor_loss": -58.32335440826416, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.60942840576172, "step": 47000}
{"episode_reward": 535.4712998729347, "episode": 48.0, "batch_reward": 0.3557073381245136, "critic_loss": 1.4711665048003197, "actor_loss": -58.312160682678225, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.92346429824829, "step": 48000}
{"episode_reward": 356.3635061500331, "episode": 49.0, "batch_reward": 0.3576778609752655, "critic_loss": 1.5043407961130142, "actor_loss": -58.86627456665039, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.515573263168335, "step": 49000}
{"episode_reward": 646.1417133551028, "episode": 50.0, "batch_reward": 0.3629983133375645, "critic_loss": 1.5320555191636085, "actor_loss": -59.38357074737549, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.127641439437866, "step": 50000}
{"episode_reward": 689.9135813030998, "episode": 51.0, "batch_reward": 0.36709949749708176, "critic_loss": 1.5438117653727532, "actor_loss": -58.961809448242185, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.248600244522095, "step": 51000}
{"episode_reward": 600.4365770254324, "episode": 52.0, "batch_reward": 0.37357899522781374, "critic_loss": 1.6514489887356758, "actor_loss": -59.56503017425537, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.902353048324585, "step": 52000}
{"episode_reward": 678.6943264179245, "episode": 53.0, "batch_reward": 0.37861317479610446, "critic_loss": 1.6578150869011878, "actor_loss": -61.2129415435791, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.900760889053345, "step": 53000}
{"episode_reward": 644.2429394779072, "episode": 54.0, "batch_reward": 0.3849825523197651, "critic_loss": 1.7045211485028267, "actor_loss": -61.37342376708985, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.90344786643982, "step": 54000}
{"episode_reward": 800.7540686321543, "episode": 55.0, "batch_reward": 0.39416959577798844, "critic_loss": 1.7147227419018745, "actor_loss": -62.66062436676025, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.966119050979614, "step": 55000}
{"episode_reward": 796.2655338713431, "episode": 56.0, "batch_reward": 0.3992483156323433, "critic_loss": 1.63583462113142, "actor_loss": -63.503031898498534, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.979461431503296, "step": 56000}
{"episode_reward": 697.8105120179147, "episode": 57.0, "batch_reward": 0.403904881387949, "critic_loss": 1.6177791887521744, "actor_loss": -63.44426229095459, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.52077031135559, "step": 57000}
{"episode_reward": 655.2144557011011, "episode": 58.0, "batch_reward": 0.4093688550591469, "critic_loss": 1.6284843836426734, "actor_loss": -64.59505563354492, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.17965340614319, "step": 58000}
{"episode_reward": 719.0156198912736, "episode": 59.0, "batch_reward": 0.41571958920359614, "critic_loss": 1.6256907333135604, "actor_loss": -64.63982427215576, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.803576707839966, "step": 59000}
{"episode_reward": 737.2069926715324, "episode": 60.0, "batch_reward": 0.41994476318359375, "critic_loss": 1.68999033588171, "actor_loss": -63.54812825012207, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.453056573867798, "step": 60000}
{"episode_reward": 735.4549469658008, "episode": 61.0, "batch_reward": 0.4245821630656719, "critic_loss": 1.7618402520418166, "actor_loss": -64.65942750549317, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.04055833816528, "step": 61000}
{"episode_reward": 775.2844904702212, "episode": 62.0, "batch_reward": 0.43223568120598793, "critic_loss": 1.8142294027805328, "actor_loss": -64.16094962310791, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.431617975234985, "step": 62000}
{"episode_reward": 732.2508896251925, "episode": 63.0, "batch_reward": 0.43604789820313455, "critic_loss": 1.9205756816267967, "actor_loss": -65.78095616912842, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.283934593200684, "step": 63000}
{"episode_reward": 761.3886546358829, "episode": 64.0, "batch_reward": 0.4408779280483723, "critic_loss": 1.8231469815969468, "actor_loss": -67.12883666992188, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.605092763900757, "step": 64000}
{"episode_reward": 820.171528287641, "episode": 65.0, "batch_reward": 0.4478955978453159, "critic_loss": 1.830977115392685, "actor_loss": -67.08523620605469, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.635026931762695, "step": 65000}
{"episode_reward": 838.5248301111961, "episode": 66.0, "batch_reward": 0.4533299576342106, "critic_loss": 1.80906274998188, "actor_loss": -67.2282432937622, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.946674346923828, "step": 66000}
{"episode_reward": 840.7114483355648, "episode": 67.0, "batch_reward": 0.46054706487059593, "critic_loss": 1.6975588373541832, "actor_loss": -68.16713707733155, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.742919206619263, "step": 67000}
{"episode_reward": 826.1875954515449, "episode": 68.0, "batch_reward": 0.4668131653368473, "critic_loss": 1.7182996159791946, "actor_loss": -68.94364301300048, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.79712748527527, "step": 68000}
{"episode_reward": 848.9357829074758, "episode": 69.0, "batch_reward": 0.47240355986356736, "critic_loss": 1.7012144683599473, "actor_loss": -69.14951348114013, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.882468223571777, "step": 69000}
{"episode_reward": 832.3077664253794, "episode": 70.0, "batch_reward": 0.4742495930790901, "critic_loss": 1.7109088965654373, "actor_loss": -69.07337575531005, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.97620677947998, "step": 70000}
{"episode_reward": 813.9702056764386, "episode": 71.0, "batch_reward": 0.48183558323979375, "critic_loss": 1.682293409883976, "actor_loss": -70.16104634094238, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 40.97110080718994, "step": 71000}
{"episode_reward": 836.2558001174101, "episode": 72.0, "batch_reward": 0.48462491524219514, "critic_loss": 1.582690111041069, "actor_loss": -70.03562264251708, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.91486430168152, "step": 72000}
{"episode_reward": 857.8289570617206, "episode": 73.0, "batch_reward": 0.49269421556591986, "critic_loss": 1.6706405860185622, "actor_loss": -71.79463335418701, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.982017755508423, "step": 73000}
{"episode_reward": 830.0809810735026, "episode": 74.0, "batch_reward": 0.4950919641256332, "critic_loss": 1.61342427611351, "actor_loss": -71.97834327697754, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.43675947189331, "step": 74000}
{"episode_reward": 897.9760870392106, "episode": 75.0, "batch_reward": 0.5014797165691852, "critic_loss": 1.5568844748735429, "actor_loss": -72.96110847473145, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.81539535522461, "step": 75000}
{"episode_reward": 878.0233080382359, "episode": 76.0, "batch_reward": 0.5069254660010338, "critic_loss": 1.5628807021975517, "actor_loss": -73.77486401367187, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.64179515838623, "step": 76000}
{"episode_reward": 906.349238787656, "episode": 77.0, "batch_reward": 0.5115214659273625, "critic_loss": 1.53704364746809, "actor_loss": -74.01335908508301, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.426328420639038, "step": 77000}
{"episode_reward": 923.1557225458089, "episode": 78.0, "batch_reward": 0.5178806063830852, "critic_loss": 1.4863067003488541, "actor_loss": -73.80477104187011, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.66566038131714, "step": 78000}
{"episode_reward": 948.5895007942935, "episode": 79.0, "batch_reward": 0.5228991717994214, "critic_loss": 1.457141674399376, "actor_loss": -74.75567001342773, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.628682851791382, "step": 79000}
{"episode_reward": 903.2557187120174, "episode": 80.0, "batch_reward": 0.5267682846486569, "critic_loss": 1.452456489443779, "actor_loss": -75.02674165344239, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.413467168807983, "step": 80000}
{"episode_reward": 918.9720749994382, "episode": 81.0, "batch_reward": 0.5326677314043045, "critic_loss": 1.487111996591091, "actor_loss": -75.26190776062012, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.252734422683716, "step": 81000}
{"episode_reward": 899.1920150219032, "episode": 82.0, "batch_reward": 0.5353674590885639, "critic_loss": 1.481486741900444, "actor_loss": -76.22800563049316, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.554386615753174, "step": 82000}
{"episode_reward": 874.797434874347, "episode": 83.0, "batch_reward": 0.5401418069601059, "critic_loss": 1.5129891112446785, "actor_loss": -75.38816314697266, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.404623985290527, "step": 83000}
{"episode_reward": 885.4928074817346, "episode": 84.0, "batch_reward": 0.5439382419884204, "critic_loss": 1.496596964120865, "actor_loss": -76.42226887512207, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.493747234344482, "step": 84000}
{"episode_reward": 950.0715194749835, "episode": 85.0, "batch_reward": 0.5492160555422306, "critic_loss": 1.524209969460964, "actor_loss": -76.82134176635742, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.40436553955078, "step": 85000}
{"episode_reward": 865.3392754481371, "episode": 86.0, "batch_reward": 0.5512090297937393, "critic_loss": 1.453928201854229, "actor_loss": -77.46126155090332, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.63306474685669, "step": 86000}
{"episode_reward": 875.68164648066, "episode": 87.0, "batch_reward": 0.5572863122224808, "critic_loss": 1.4187907699942588, "actor_loss": -77.39468539428711, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.344527006149292, "step": 87000}
{"episode_reward": 912.7328122115226, "episode": 88.0, "batch_reward": 0.5618179044127465, "critic_loss": 1.4394014443159104, "actor_loss": -77.7475265045166, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.442201614379883, "step": 88000}
{"episode_reward": 957.337387269427, "episode": 89.0, "batch_reward": 0.5665229478180408, "critic_loss": 1.3918505312800407, "actor_loss": -78.25523579406739, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.59235954284668, "step": 89000}
{"episode_reward": 919.8590262340979, "episode": 90.0, "batch_reward": 0.5695688585639, "critic_loss": 1.3912556769251823, "actor_loss": -78.99769062805176, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.590064764022827, "step": 90000}
{"episode_reward": 854.6745965957012, "episode": 91.0, "batch_reward": 0.5714372411072254, "critic_loss": 1.4343138647079468, "actor_loss": -79.16091969299316, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.326648473739624, "step": 91000}
{"episode_reward": 929.9356203168722, "episode": 92.0, "batch_reward": 0.5753462022244931, "critic_loss": 1.3254656962752343, "actor_loss": -78.85017767333984, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.503332138061523, "step": 92000}
{"episode_reward": 925.8673142878196, "episode": 93.0, "batch_reward": 0.5801776744127274, "critic_loss": 1.3724927369952202, "actor_loss": -79.53193482971191, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.42307949066162, "step": 93000}
{"episode_reward": 869.6882035665741, "episode": 94.0, "batch_reward": 0.5853055944740773, "critic_loss": 1.3516256446242332, "actor_loss": -79.53054824829101, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.659101247787476, "step": 94000}
{"episode_reward": 910.2121476762255, "episode": 95.0, "batch_reward": 0.58432695505023, "critic_loss": 1.3268414037823677, "actor_loss": -80.25262112426758, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.852352619171143, "step": 95000}
{"episode_reward": 890.9384657364742, "episode": 96.0, "batch_reward": 0.5898927519917488, "critic_loss": 1.3121450723409653, "actor_loss": -80.3282264099121, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.717015981674194, "step": 96000}
{"episode_reward": 890.5347215238747, "episode": 97.0, "batch_reward": 0.5923251044750214, "critic_loss": 1.2881742231249809, "actor_loss": -81.12678131103516, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.6415376663208, "step": 97000}
{"episode_reward": 902.889531472468, "episode": 98.0, "batch_reward": 0.5968238845765591, "critic_loss": 1.2763047209978104, "actor_loss": -81.62500074768066, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.918859720230103, "step": 98000}
{"episode_reward": 861.8548625721126, "episode": 99.0, "batch_reward": 0.5991863277554512, "critic_loss": 1.3214780416488647, "actor_loss": -81.3273226776123, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.545360565185547, "step": 99000}
{"episode_reward": 936.2095686905137, "episode": 100.0, "batch_reward": 0.6028801952302456, "critic_loss": 1.2219139656424522, "actor_loss": -81.35629731750488, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.43287467956543, "step": 100000}
{"episode_reward": 936.0876356261725, "episode": 101.0, "batch_reward": 0.6074722321927547, "critic_loss": 1.2334492963552475, "actor_loss": -81.7422816772461, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.10476851463318, "step": 101000}
{"episode_reward": 898.7777926140002, "episode": 102.0, "batch_reward": 0.6091371834278106, "critic_loss": 1.2982387560009956, "actor_loss": -81.9523630065918, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.444971799850464, "step": 102000}
{"episode_reward": 879.4507178093388, "episode": 103.0, "batch_reward": 0.611349758207798, "critic_loss": 1.2499805459976197, "actor_loss": -81.97792378234864, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.31926131248474, "step": 103000}
{"episode_reward": 933.5587154755004, "episode": 104.0, "batch_reward": 0.6161037405729294, "critic_loss": 1.2423514234423638, "actor_loss": -82.68636430358887, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.727683544158936, "step": 104000}
{"episode_reward": 892.976845835126, "episode": 105.0, "batch_reward": 0.6163772916197777, "critic_loss": 1.2359482909440995, "actor_loss": -82.2410299835205, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.053699254989624, "step": 105000}
{"episode_reward": 956.757463254054, "episode": 106.0, "batch_reward": 0.6204077059626579, "critic_loss": 1.228916573226452, "actor_loss": -82.78067330932618, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.691333055496216, "step": 106000}
{"episode_reward": 956.420068254518, "episode": 107.0, "batch_reward": 0.6223914085626602, "critic_loss": 1.2560334525704384, "actor_loss": -82.99733340454101, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.883391857147217, "step": 107000}
{"episode_reward": 923.8474116907058, "episode": 108.0, "batch_reward": 0.6257721273303032, "critic_loss": 1.1954685223698616, "actor_loss": -83.16308148193359, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.642767190933228, "step": 108000}
{"episode_reward": 935.5135350422389, "episode": 109.0, "batch_reward": 0.630340285718441, "critic_loss": 1.1751194665431977, "actor_loss": -83.70876153564453, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.826136827468872, "step": 109000}
{"episode_reward": 922.2243327376501, "episode": 110.0, "batch_reward": 0.6308425189256668, "critic_loss": 1.1630914739966391, "actor_loss": -83.71662451171875, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.917836666107178, "step": 110000}
{"episode_reward": 821.2827962604925, "episode": 111.0, "batch_reward": 0.6329497314095497, "critic_loss": 1.2543536847233772, "actor_loss": -83.42954133605957, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.1391224861145, "step": 111000}
{"episode_reward": 911.6908349782362, "episode": 112.0, "batch_reward": 0.6349839743971825, "critic_loss": 1.1685869042873382, "actor_loss": -83.4962438659668, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.846774339675903, "step": 112000}
{"episode_reward": 908.816700797806, "episode": 113.0, "batch_reward": 0.6399427094459533, "critic_loss": 1.167345430791378, "actor_loss": -83.48809393310547, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.986929655075073, "step": 113000}
{"episode_reward": 896.0650843908713, "episode": 114.0, "batch_reward": 0.6413276160359382, "critic_loss": 1.1331498962044715, "actor_loss": -84.27070455932618, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.42681097984314, "step": 114000}
{"episode_reward": 935.8604243590679, "episode": 115.0, "batch_reward": 0.6422691842317582, "critic_loss": 1.1463114233016969, "actor_loss": -84.16904461669922, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.69092059135437, "step": 115000}
{"episode_reward": 900.7342146206256, "episode": 116.0, "batch_reward": 0.6452489306330681, "critic_loss": 1.1222239754796028, "actor_loss": -84.45082427978515, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.450451850891113, "step": 116000}
{"episode_reward": 916.4192693428195, "episode": 117.0, "batch_reward": 0.648563930273056, "critic_loss": 1.147617905676365, "actor_loss": -84.70503575134278, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.430951833724976, "step": 117000}
{"episode_reward": 913.2509784071788, "episode": 118.0, "batch_reward": 0.6497940591573715, "critic_loss": 1.114412238806486, "actor_loss": -84.33562805175781, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.930659532546997, "step": 118000}
{"episode_reward": 879.7071401391694, "episode": 119.0, "batch_reward": 0.6520599095821381, "critic_loss": 1.0935924548506737, "actor_loss": -84.70484762573243, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.78569483757019, "step": 119000}
{"episode_reward": 912.344967192507, "episode": 120.0, "batch_reward": 0.6547955098748207, "critic_loss": 1.0878463509082794, "actor_loss": -85.06881364440918, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.853338479995728, "step": 120000}
{"episode_reward": 919.4745072724266, "episode": 121.0, "batch_reward": 0.6571816579699516, "critic_loss": 1.1042044495642185, "actor_loss": -84.86097750854492, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.29666781425476, "step": 121000}
{"episode_reward": 895.276943478372, "episode": 122.0, "batch_reward": 0.6597106482386589, "critic_loss": 1.1052672412395477, "actor_loss": -85.53971487426757, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.275391817092896, "step": 122000}
{"episode_reward": 919.2869221799232, "episode": 123.0, "batch_reward": 0.6587328575849533, "critic_loss": 1.1284417066574097, "actor_loss": -85.92218336486816, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.42071509361267, "step": 123000}
{"episode_reward": 927.436723012638, "episode": 124.0, "batch_reward": 0.6628460792303086, "critic_loss": 1.0981849240660668, "actor_loss": -85.83370764160156, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.586241960525513, "step": 124000}
{"episode_reward": 928.9626813877622, "episode": 125.0, "batch_reward": 0.6657527679800987, "critic_loss": 1.0609353298842907, "actor_loss": -85.43699899291992, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.46682381629944, "step": 125000}
{"episode_reward": 922.4946878251419, "episode": 126.0, "batch_reward": 0.6654564432501793, "critic_loss": 1.0916237241625786, "actor_loss": -85.60560891723632, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.41422963142395, "step": 126000}
{"episode_reward": 923.121889354104, "episode": 127.0, "batch_reward": 0.6689903359413147, "critic_loss": 1.0513892079889775, "actor_loss": -86.09268855285644, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.88580083847046, "step": 127000}
{"episode_reward": 946.1483807871205, "episode": 128.0, "batch_reward": 0.6707159075140953, "critic_loss": 1.0438528644442557, "actor_loss": -85.66891510009765, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.36817240715027, "step": 128000}
{"episode_reward": 969.1207695990978, "episode": 129.0, "batch_reward": 0.6739031510353088, "critic_loss": 1.0721672733128071, "actor_loss": -86.13446534729005, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.61074733734131, "step": 129000}
{"episode_reward": 914.3687141297261, "episode": 130.0, "batch_reward": 0.6757125343680381, "critic_loss": 1.013196710884571, "actor_loss": -86.35558413696289, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.03942036628723, "step": 130000}
{"episode_reward": 897.6730582262999, "episode": 131.0, "batch_reward": 0.6775945398807526, "critic_loss": 1.0558308516144752, "actor_loss": -85.79508441162109, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 40.98879837989807, "step": 131000}
{"episode_reward": 860.6729671092093, "episode": 132.0, "batch_reward": 0.6779087855815887, "critic_loss": 1.0788936291337012, "actor_loss": -86.19614738464355, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.520442485809326, "step": 132000}
{"episode_reward": 921.2376103590706, "episode": 133.0, "batch_reward": 0.6786687398552894, "critic_loss": 1.049462385237217, "actor_loss": -86.12052868652344, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.832433462142944, "step": 133000}
{"episode_reward": 902.9487671572087, "episode": 134.0, "batch_reward": 0.6814737045764923, "critic_loss": 1.0574530826210975, "actor_loss": -86.36812490844727, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.548877239227295, "step": 134000}
{"episode_reward": 920.7345128662555, "episode": 135.0, "batch_reward": 0.6826910230517388, "critic_loss": 1.0466047347784042, "actor_loss": -86.50255187988282, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.374175310134888, "step": 135000}
{"episode_reward": 930.8436395100558, "episode": 136.0, "batch_reward": 0.6850582444667817, "critic_loss": 1.039005736798048, "actor_loss": -86.48364151000976, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.394952535629272, "step": 136000}
{"episode_reward": 920.3138382156525, "episode": 137.0, "batch_reward": 0.6866275565624237, "critic_loss": 1.0461464949846269, "actor_loss": -86.71284674072265, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.415229082107544, "step": 137000}
{"episode_reward": 931.0011180007148, "episode": 138.0, "batch_reward": 0.6883350608944893, "critic_loss": 1.0821970902085305, "actor_loss": -86.49651245117188, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.680824279785156, "step": 138000}
{"episode_reward": 946.2445627613115, "episode": 139.0, "batch_reward": 0.6905796453356743, "critic_loss": 1.0400666423141955, "actor_loss": -86.58055195617676, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.93821954727173, "step": 139000}
{"episode_reward": 858.9057830370738, "episode": 140.0, "batch_reward": 0.6924422605037689, "critic_loss": 1.0581082819104195, "actor_loss": -86.77027738952637, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.143908500671387, "step": 140000}
{"episode_reward": 944.7070651495918, "episode": 141.0, "batch_reward": 0.6936818770170212, "critic_loss": 1.02678302693367, "actor_loss": -86.92879959106445, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.96968364715576, "step": 141000}
{"episode_reward": 947.038763533478, "episode": 142.0, "batch_reward": 0.694120595574379, "critic_loss": 1.0380946556329727, "actor_loss": -86.93212835693359, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.294893980026245, "step": 142000}
{"episode_reward": 920.966731143047, "episode": 143.0, "batch_reward": 0.6963474099040031, "critic_loss": 1.0447531154453755, "actor_loss": -86.99581192016602, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.43735146522522, "step": 143000}
{"episode_reward": 904.7767353854123, "episode": 144.0, "batch_reward": 0.6999006828665734, "critic_loss": 1.0811703540980815, "actor_loss": -87.09381336975098, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.80793809890747, "step": 144000}
{"episode_reward": 900.3255578922257, "episode": 145.0, "batch_reward": 0.7007696277499199, "critic_loss": 1.032994092464447, "actor_loss": -87.30617138671874, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.323822498321533, "step": 145000}
{"episode_reward": 950.2104181398429, "episode": 146.0, "batch_reward": 0.7018086037039757, "critic_loss": 1.0179420619904995, "actor_loss": -87.23317129516602, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.44916081428528, "step": 146000}
{"episode_reward": 951.7832571775767, "episode": 147.0, "batch_reward": 0.7033883102536201, "critic_loss": 0.996057136029005, "actor_loss": -87.32054402160645, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.42613959312439, "step": 147000}
{"episode_reward": 931.1228233392674, "episode": 148.0, "batch_reward": 0.7058051553368568, "critic_loss": 1.0012550611197948, "actor_loss": -87.38738800048829, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.54459834098816, "step": 148000}
{"episode_reward": 957.3888663069099, "episode": 149.0, "batch_reward": 0.7052816504240036, "critic_loss": 0.9929486909210682, "actor_loss": -87.43773170471191, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.73784351348877, "step": 149000}
{"episode_reward": 904.3857086830604, "episode": 150.0, "batch_reward": 0.7086632472276687, "critic_loss": 0.9744779873490333, "actor_loss": -87.39049766540528, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "step": 150000}
