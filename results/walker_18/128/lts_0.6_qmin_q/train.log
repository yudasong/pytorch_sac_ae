{"episode_reward": 0.0, "episode": 1.0, "duration": 23.966155529022217, "step": 1000}
{"episode_reward": 27.46298806610516, "episode": 2.0, "duration": 2.0351967811584473, "step": 2000}
{"episode_reward": 489.1100087318934, "episode": 3.0, "batch_reward": 0.24304905164118568, "critic_loss": 0.40380659617207854, "actor_loss": -81.79178894152876, "actor_target_entropy": -6.0, "alpha_value": 0.002134017781850189, "duration": 64.17677211761475, "step": 3000}
{"episode_reward": 10.597589385109732, "episode": 4.0, "batch_reward": 0.15626263871788978, "critic_loss": 0.36788150630891325, "actor_loss": -76.75944158935548, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 26.505048274993896, "step": 4000}
{"episode_reward": 35.2891424229595, "episode": 5.0, "batch_reward": 0.14409246214479207, "critic_loss": 0.5535709179639816, "actor_loss": -75.65018113708496, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.97971510887146, "step": 5000}
{"episode_reward": 165.00370596739032, "episode": 6.0, "batch_reward": 0.14613660200685263, "critic_loss": 0.6084710155725479, "actor_loss": -75.69439877319336, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.01686453819275, "step": 6000}
{"episode_reward": 116.28478244462114, "episode": 7.0, "batch_reward": 0.15727711726725102, "critic_loss": 0.8592523838877678, "actor_loss": -75.8274828491211, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.97394037246704, "step": 7000}
{"episode_reward": 295.4202176211694, "episode": 8.0, "batch_reward": 0.16674541641026736, "critic_loss": 0.8271488758325577, "actor_loss": -75.1310728149414, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.211561679840088, "step": 8000}
{"episode_reward": 168.31211695482938, "episode": 9.0, "batch_reward": 0.18282872311025858, "critic_loss": 0.7555264938771725, "actor_loss": -74.91005432128907, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.781034231185913, "step": 9000}
{"episode_reward": 464.86904431472203, "episode": 10.0, "batch_reward": 0.2022066609710455, "critic_loss": 0.7160459331870079, "actor_loss": -75.40643080139161, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.36080312728882, "step": 10000}
{"episode_reward": 347.44531409249964, "episode": 11.0, "batch_reward": 0.21438044227659703, "critic_loss": 0.6264223151504994, "actor_loss": -74.32459250640869, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.66384720802307, "step": 11000}
{"episode_reward": 255.147516302295, "episode": 12.0, "batch_reward": 0.2269275513291359, "critic_loss": 0.5659697949886322, "actor_loss": -74.62422465515137, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.026676416397095, "step": 12000}
{"episode_reward": 468.8149520240084, "episode": 13.0, "batch_reward": 0.24627318108081817, "critic_loss": 0.5467456415295601, "actor_loss": -74.63744927215576, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.95645833015442, "step": 13000}
{"episode_reward": 521.3472093780761, "episode": 14.0, "batch_reward": 0.2631242691576481, "critic_loss": 0.575483085244894, "actor_loss": -73.77179891967774, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.616098642349243, "step": 14000}
{"episode_reward": 312.71269685587646, "episode": 15.0, "batch_reward": 0.2717951388061047, "critic_loss": 0.616902397453785, "actor_loss": -72.5628436126709, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.769952297210693, "step": 15000}
{"episode_reward": 494.2595617856402, "episode": 16.0, "batch_reward": 0.2836411170661449, "critic_loss": 0.6235624995529652, "actor_loss": -72.8911954498291, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.823572397232056, "step": 16000}
{"episode_reward": 480.48679762558936, "episode": 17.0, "batch_reward": 0.29384400880336764, "critic_loss": 0.6613023582100869, "actor_loss": -73.39115718078614, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.8590669631958, "step": 17000}
{"episode_reward": 367.7560630302028, "episode": 18.0, "batch_reward": 0.30280530847609044, "critic_loss": 0.6328448915481567, "actor_loss": -72.51818333435058, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.88105797767639, "step": 18000}
{"episode_reward": 495.91603605329277, "episode": 19.0, "batch_reward": 0.30994334930181505, "critic_loss": 0.6558536649942398, "actor_loss": -72.49190962982178, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.106743335723877, "step": 19000}
{"episode_reward": 442.7347943429796, "episode": 20.0, "batch_reward": 0.31710630148649216, "critic_loss": 0.6497224998176098, "actor_loss": -72.67324963378907, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.003944396972656, "step": 20000}
{"episode_reward": 502.83257530934793, "episode": 21.0, "batch_reward": 0.32398649591207507, "critic_loss": 0.6933549972772598, "actor_loss": -70.92168399810791, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 45.735005140304565, "step": 21000}
{"episode_reward": 416.8058518268872, "episode": 22.0, "batch_reward": 0.32943327021598817, "critic_loss": 0.7448793990314007, "actor_loss": -72.67536226654053, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.44282054901123, "step": 22000}
{"episode_reward": 414.38688763774263, "episode": 23.0, "batch_reward": 0.33367498910427096, "critic_loss": 0.7745030488669872, "actor_loss": -71.92123079681396, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.859591007232666, "step": 23000}
{"episode_reward": 450.9627191974791, "episode": 24.0, "batch_reward": 0.33770459815859794, "critic_loss": 0.8107994641959667, "actor_loss": -69.94130979919433, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.278236389160156, "step": 24000}
{"episode_reward": 404.34741341349695, "episode": 25.0, "batch_reward": 0.34290733343362806, "critic_loss": 0.9189738629162312, "actor_loss": -71.2880665512085, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.099693059921265, "step": 25000}
{"episode_reward": 426.87906824141015, "episode": 26.0, "batch_reward": 0.3461320860981941, "critic_loss": 0.9975809844136239, "actor_loss": -70.15884007263183, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.13349747657776, "step": 26000}
{"episode_reward": 535.8653545355152, "episode": 27.0, "batch_reward": 0.35374723899364474, "critic_loss": 1.0371032574176788, "actor_loss": -70.3047784729004, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.351435661315918, "step": 27000}
{"episode_reward": 563.9788487039478, "episode": 28.0, "batch_reward": 0.3629022526443005, "critic_loss": 1.1290315941572189, "actor_loss": -71.08662351226806, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.334464073181152, "step": 28000}
{"episode_reward": 590.831333919278, "episode": 29.0, "batch_reward": 0.3668138330280781, "critic_loss": 1.1129429752230644, "actor_loss": -70.6440816116333, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.997925519943237, "step": 29000}
{"episode_reward": 393.61657247783114, "episode": 30.0, "batch_reward": 0.371465604275465, "critic_loss": 1.1294002782702446, "actor_loss": -69.67198217773438, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.435306787490845, "step": 30000}
{"episode_reward": 604.3587999858069, "episode": 31.0, "batch_reward": 0.3775827803313732, "critic_loss": 1.1528845255374909, "actor_loss": -71.06831015777588, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 45.89328360557556, "step": 31000}
{"episode_reward": 520.235399082288, "episode": 32.0, "batch_reward": 0.38436327692866323, "critic_loss": 1.147204000353813, "actor_loss": -70.46921002960205, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.375069618225098, "step": 32000}
{"episode_reward": 684.8536212870331, "episode": 33.0, "batch_reward": 0.393068041652441, "critic_loss": 1.1642485612630844, "actor_loss": -71.73041790771484, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.449724197387695, "step": 33000}
{"episode_reward": 647.8691151621792, "episode": 34.0, "batch_reward": 0.40229299715161326, "critic_loss": 1.1652684867978096, "actor_loss": -71.68407524871826, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.466075658798218, "step": 34000}
{"episode_reward": 692.8067600865465, "episode": 35.0, "batch_reward": 0.4090303611755371, "critic_loss": 1.1865788660645484, "actor_loss": -69.07318695068359, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.067894458770752, "step": 35000}
{"episode_reward": 612.7555868592486, "episode": 36.0, "batch_reward": 0.4176636949777603, "critic_loss": 1.1392134710550308, "actor_loss": -72.07936000823975, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.3508563041687, "step": 36000}
{"episode_reward": 727.9089553868185, "episode": 37.0, "batch_reward": 0.4246396541297436, "critic_loss": 1.216336422264576, "actor_loss": -70.8643330078125, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.68902611732483, "step": 37000}
{"episode_reward": 643.7275453497173, "episode": 38.0, "batch_reward": 0.4290047595798969, "critic_loss": 1.2562742894887924, "actor_loss": -70.23553645324706, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.986391305923462, "step": 38000}
{"episode_reward": 704.5724311998275, "episode": 39.0, "batch_reward": 0.43667907449603083, "critic_loss": 1.3044518038630486, "actor_loss": -72.52229819488525, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.42364764213562, "step": 39000}
{"episode_reward": 625.1154099846115, "episode": 40.0, "batch_reward": 0.43880419662594794, "critic_loss": 1.4012651965618133, "actor_loss": -73.91475045013428, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.28522276878357, "step": 40000}
{"episode_reward": 565.1239932150834, "episode": 41.0, "batch_reward": 0.44228161054849624, "critic_loss": 1.385817909538746, "actor_loss": -73.15286595916749, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.345969915390015, "step": 41000}
{"episode_reward": 553.1697704478771, "episode": 42.0, "batch_reward": 0.4421107048690319, "critic_loss": 1.4377989392876624, "actor_loss": -72.47134655761718, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.97687840461731, "step": 42000}
{"episode_reward": 362.90419423731504, "episode": 43.0, "batch_reward": 0.44377293407917023, "critic_loss": 1.562851161956787, "actor_loss": -73.20996027374268, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.53407382965088, "step": 43000}
{"episode_reward": 386.23991749297625, "episode": 44.0, "batch_reward": 0.44394391494989394, "critic_loss": 1.5891584658622742, "actor_loss": -70.74729971313477, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.297605991363525, "step": 44000}
{"episode_reward": 728.1195675006394, "episode": 45.0, "batch_reward": 0.4493625633716583, "critic_loss": 1.6599530940651894, "actor_loss": -70.67007939910889, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.30681872367859, "step": 45000}
{"episode_reward": 744.4332568612238, "episode": 46.0, "batch_reward": 0.4572779326736927, "critic_loss": 1.6757426366209984, "actor_loss": -72.14508150482177, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.432889699935913, "step": 46000}
{"episode_reward": 657.9727339107618, "episode": 47.0, "batch_reward": 0.4624624258875847, "critic_loss": 1.683478982925415, "actor_loss": -72.02304232788086, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.14259433746338, "step": 47000}
{"episode_reward": 728.0612930633049, "episode": 48.0, "batch_reward": 0.46596409621834756, "critic_loss": 1.7145679185390472, "actor_loss": -71.99697142791749, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.50536322593689, "step": 48000}
{"episode_reward": 732.1970844172191, "episode": 49.0, "batch_reward": 0.47357157737016675, "critic_loss": 1.7608765991926194, "actor_loss": -72.74896697235107, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.10111165046692, "step": 49000}
{"episode_reward": 698.4524569217833, "episode": 50.0, "batch_reward": 0.47609208914637563, "critic_loss": 1.8267567895650865, "actor_loss": -72.8746351928711, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.430439949035645, "step": 50000}
{"episode_reward": 730.4539246833913, "episode": 51.0, "batch_reward": 0.4814889235198498, "critic_loss": 1.8005199102163314, "actor_loss": -73.42345561218262, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 45.33154058456421, "step": 51000}
{"episode_reward": 765.4667156529787, "episode": 52.0, "batch_reward": 0.4905254980623722, "critic_loss": 1.8067593118548393, "actor_loss": -72.99951378631592, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.121663570404053, "step": 52000}
{"episode_reward": 833.7429913354403, "episode": 53.0, "batch_reward": 0.4946644980311394, "critic_loss": 1.7560948430895806, "actor_loss": -73.71259951782227, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.772385358810425, "step": 53000}
{"episode_reward": 852.9840496490083, "episode": 54.0, "batch_reward": 0.5018770969212055, "critic_loss": 1.77517948782444, "actor_loss": -74.21397448730468, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.77227520942688, "step": 54000}
{"episode_reward": 797.6911982915011, "episode": 55.0, "batch_reward": 0.5081453508138657, "critic_loss": 1.713867633640766, "actor_loss": -74.74072760009766, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.59529185295105, "step": 55000}
{"episode_reward": 891.7065219582651, "episode": 56.0, "batch_reward": 0.5124687803387642, "critic_loss": 1.790774570465088, "actor_loss": -75.98169415283203, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.40428352355957, "step": 56000}
{"episode_reward": 717.5106244215858, "episode": 57.0, "batch_reward": 0.5170616587400436, "critic_loss": 1.7798380581736564, "actor_loss": -75.66646278381347, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.77645754814148, "step": 57000}
{"episode_reward": 811.6438228585961, "episode": 58.0, "batch_reward": 0.5231233185827732, "critic_loss": 1.7797934683561325, "actor_loss": -76.37490229034424, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.39007019996643, "step": 58000}
{"episode_reward": 760.0163734951846, "episode": 59.0, "batch_reward": 0.5272088596522808, "critic_loss": 1.7952756923437119, "actor_loss": -76.95553911590576, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.82243251800537, "step": 59000}
{"episode_reward": 798.046561859858, "episode": 60.0, "batch_reward": 0.5311145835518837, "critic_loss": 1.7482061053514482, "actor_loss": -76.41007606506348, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.877689599990845, "step": 60000}
{"episode_reward": 819.7261576928801, "episode": 61.0, "batch_reward": 0.5353800495564938, "critic_loss": 1.8034230995178222, "actor_loss": -75.72322735595704, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 45.9563422203064, "step": 61000}
{"episode_reward": 847.8914465669516, "episode": 62.0, "batch_reward": 0.542804981470108, "critic_loss": 1.7657267554998397, "actor_loss": -76.31043252563477, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.741898775100708, "step": 62000}
{"episode_reward": 863.2418966970915, "episode": 63.0, "batch_reward": 0.546436966329813, "critic_loss": 1.777971515059471, "actor_loss": -76.93147518920898, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.843390941619873, "step": 63000}
{"episode_reward": 716.1835426961217, "episode": 64.0, "batch_reward": 0.5494119271636009, "critic_loss": 1.7842149388790132, "actor_loss": -78.49048789978028, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.077250003814697, "step": 64000}
{"episode_reward": 859.3484025943383, "episode": 65.0, "batch_reward": 0.5538992347121239, "critic_loss": 1.8456004814505578, "actor_loss": -78.65913776397706, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.77499294281006, "step": 65000}
{"episode_reward": 864.4173806505032, "episode": 66.0, "batch_reward": 0.5586290493309498, "critic_loss": 1.8880451346635818, "actor_loss": -78.70547728729248, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.6033034324646, "step": 66000}
{"episode_reward": 858.1410207443296, "episode": 67.0, "batch_reward": 0.563624051809311, "critic_loss": 1.879409323334694, "actor_loss": -77.55086576843262, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.483213186264038, "step": 67000}
{"episode_reward": 881.1348327355041, "episode": 68.0, "batch_reward": 0.5696814641952515, "critic_loss": 1.8657918579578399, "actor_loss": -79.22514295196534, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.887866020202637, "step": 68000}
{"episode_reward": 875.8205570461545, "episode": 69.0, "batch_reward": 0.5747833361625672, "critic_loss": 1.8632774230241775, "actor_loss": -78.77826666259766, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.107821464538574, "step": 69000}
{"episode_reward": 882.1384455592922, "episode": 70.0, "batch_reward": 0.5770079298019409, "critic_loss": 1.8377875059843063, "actor_loss": -78.80184366607666, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.377377033233643, "step": 70000}
{"episode_reward": 834.863685361253, "episode": 71.0, "batch_reward": 0.5807391323149205, "critic_loss": 1.8234405758976937, "actor_loss": -79.1516605758667, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.45294523239136, "step": 71000}
{"episode_reward": 805.8824039363326, "episode": 72.0, "batch_reward": 0.5833453923463822, "critic_loss": 1.7739424302577973, "actor_loss": -79.73932878112792, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.55474281311035, "step": 72000}
{"episode_reward": 631.5494576233405, "episode": 73.0, "batch_reward": 0.5861662770807743, "critic_loss": 1.7508809220194816, "actor_loss": -80.11663223266602, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.85179328918457, "step": 73000}
{"episode_reward": 883.388428209724, "episode": 74.0, "batch_reward": 0.5867906073629856, "critic_loss": 1.7349358339309693, "actor_loss": -80.3799895477295, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.23404049873352, "step": 74000}
{"episode_reward": 785.5941067491113, "episode": 75.0, "batch_reward": 0.5924966412186623, "critic_loss": 1.6974367646574975, "actor_loss": -81.71629167175293, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.82623553276062, "step": 75000}
{"episode_reward": 858.698075043074, "episode": 76.0, "batch_reward": 0.5943256862163544, "critic_loss": 1.7159393280148507, "actor_loss": -81.05395650482178, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.219726085662842, "step": 76000}
{"episode_reward": 874.7371140357249, "episode": 77.0, "batch_reward": 0.5992036601901054, "critic_loss": 1.7374524377584457, "actor_loss": -81.35911309814453, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.76938772201538, "step": 77000}
{"episode_reward": 816.1956148262427, "episode": 78.0, "batch_reward": 0.6015440266728401, "critic_loss": 1.680544705927372, "actor_loss": -81.39924034118653, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.485211610794067, "step": 78000}
{"episode_reward": 839.7775195799667, "episode": 79.0, "batch_reward": 0.6060287229418755, "critic_loss": 1.6982923508882524, "actor_loss": -82.33825918579102, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.67702293395996, "step": 79000}
{"episode_reward": 886.2196917578038, "episode": 80.0, "batch_reward": 0.6083526321053505, "critic_loss": 1.7562972314357757, "actor_loss": -82.33480049133301, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.904720544815063, "step": 80000}
{"episode_reward": 930.283618128348, "episode": 81.0, "batch_reward": 0.6135165199637413, "critic_loss": 1.7396487229466437, "actor_loss": -82.08679463195801, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 45.615034341812134, "step": 81000}
{"episode_reward": 871.5347012155588, "episode": 82.0, "batch_reward": 0.6148659138083458, "critic_loss": 1.7227780840992928, "actor_loss": -82.60688111877441, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.94917941093445, "step": 82000}
{"episode_reward": 897.1075844551908, "episode": 83.0, "batch_reward": 0.6190614585280418, "critic_loss": 1.7308355238437652, "actor_loss": -82.40038459777833, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.918330192565918, "step": 83000}
{"episode_reward": 867.1639946958379, "episode": 84.0, "batch_reward": 0.6203249642252922, "critic_loss": 1.7022590600252152, "actor_loss": -82.72503912353515, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.39383840560913, "step": 84000}
{"episode_reward": 907.4828090167026, "episode": 85.0, "batch_reward": 0.6247616018652916, "critic_loss": 1.7857188320159911, "actor_loss": -83.24983956909179, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.567270040512085, "step": 85000}
{"episode_reward": 850.1186699881443, "episode": 86.0, "batch_reward": 0.6267109054923058, "critic_loss": 1.7347886691689491, "actor_loss": -82.92475166320801, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.42198133468628, "step": 86000}
{"episode_reward": 807.7456273930237, "episode": 87.0, "batch_reward": 0.6295460712313652, "critic_loss": 1.727456911444664, "actor_loss": -82.83643312072753, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.89228868484497, "step": 87000}
{"episode_reward": 896.475080711981, "episode": 88.0, "batch_reward": 0.6324541135430336, "critic_loss": 1.6684570358395576, "actor_loss": -83.26979931640625, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.5436532497406, "step": 88000}
{"episode_reward": 889.3713169139959, "episode": 89.0, "batch_reward": 0.6322801049351692, "critic_loss": 1.6642980808019638, "actor_loss": -83.76821270751954, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.671339988708496, "step": 89000}
{"episode_reward": 422.7456884624899, "episode": 90.0, "batch_reward": 0.6323141933083535, "critic_loss": 1.6849093440771103, "actor_loss": -83.45579246520997, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.447130918502808, "step": 90000}
{"episode_reward": 869.7282103249634, "episode": 91.0, "batch_reward": 0.6350598434209823, "critic_loss": 1.6886173870563508, "actor_loss": -84.11913986206055, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 44.60545873641968, "step": 91000}
{"episode_reward": 827.178640767745, "episode": 92.0, "batch_reward": 0.6378542699813843, "critic_loss": 1.6412881686091423, "actor_loss": -83.06547164916992, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.086366891860962, "step": 92000}
{"episode_reward": 895.8422187394606, "episode": 93.0, "batch_reward": 0.6407707028985024, "critic_loss": 1.6237350052595139, "actor_loss": -84.07997807312012, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.696759462356567, "step": 93000}
{"episode_reward": 915.2167693554799, "episode": 94.0, "batch_reward": 0.6446059764027595, "critic_loss": 1.5485315613150596, "actor_loss": -83.71675117492676, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.262486457824707, "step": 94000}
{"episode_reward": 894.863829148893, "episode": 95.0, "batch_reward": 0.6440999283790588, "critic_loss": 1.5949357169270515, "actor_loss": -84.5692375793457, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.483807802200317, "step": 95000}
{"episode_reward": 814.4285161177138, "episode": 96.0, "batch_reward": 0.6491860798597335, "critic_loss": 1.5537109310030937, "actor_loss": -84.18549368286133, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.294789791107178, "step": 96000}
{"episode_reward": 588.3002933727959, "episode": 97.0, "batch_reward": 0.6471472179889679, "critic_loss": 1.5081124011278153, "actor_loss": -84.69142530822754, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.432074785232544, "step": 97000}
{"episode_reward": 871.3574471520465, "episode": 98.0, "batch_reward": 0.6507740072607994, "critic_loss": 1.473328544139862, "actor_loss": -85.4210276184082, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.305971384048462, "step": 98000}
{"episode_reward": 876.8300107980791, "episode": 99.0, "batch_reward": 0.6520540177822113, "critic_loss": 1.4425174061655999, "actor_loss": -84.93431536865235, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.613454818725586, "step": 99000}
{"episode_reward": 936.0078166735752, "episode": 100.0, "batch_reward": 0.655088551223278, "critic_loss": 1.4718479464650154, "actor_loss": -85.31399424743653, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.479522466659546, "step": 100000}
{"episode_reward": 901.6442395449199, "episode": 101.0, "batch_reward": 0.6588197591304779, "critic_loss": 1.4771986840367317, "actor_loss": -84.85161358642578, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.5697021484375, "step": 101000}
{"episode_reward": 790.1175572268231, "episode": 102.0, "batch_reward": 0.659615094602108, "critic_loss": 1.4448233569860458, "actor_loss": -85.54276747131348, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.496655702590942, "step": 102000}
{"episode_reward": 925.9942539000975, "episode": 103.0, "batch_reward": 0.661795199394226, "critic_loss": 1.4036193380951882, "actor_loss": -85.1921856994629, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.97966456413269, "step": 103000}
{"episode_reward": 909.1979620712721, "episode": 104.0, "batch_reward": 0.6646388142704963, "critic_loss": 1.3833172423839568, "actor_loss": -86.16441293334961, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.121726274490356, "step": 104000}
{"episode_reward": 821.1035402361023, "episode": 105.0, "batch_reward": 0.6649203166365624, "critic_loss": 1.3847600553035737, "actor_loss": -85.3165725402832, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.844475030899048, "step": 105000}
{"episode_reward": 914.8380424328049, "episode": 106.0, "batch_reward": 0.6671921846270561, "critic_loss": 1.3950678495764732, "actor_loss": -85.72991246032714, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.482945919036865, "step": 106000}
{"episode_reward": 931.185576953542, "episode": 107.0, "batch_reward": 0.6694102947711944, "critic_loss": 1.382240959405899, "actor_loss": -86.11065423583985, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.536511182785034, "step": 107000}
{"episode_reward": 831.9325919717686, "episode": 108.0, "batch_reward": 0.6705177276730537, "critic_loss": 1.3655910826325417, "actor_loss": -86.0431529083252, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.300067901611328, "step": 108000}
{"episode_reward": 909.6368913110864, "episode": 109.0, "batch_reward": 0.6748817811012268, "critic_loss": 1.3386400901675224, "actor_loss": -86.25741162109375, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.793907165527344, "step": 109000}
{"episode_reward": 915.8183534477015, "episode": 110.0, "batch_reward": 0.6756449707746506, "critic_loss": 1.3218453524708749, "actor_loss": -86.55112539672851, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.455551624298096, "step": 110000}
{"episode_reward": 883.2620448549172, "episode": 111.0, "batch_reward": 0.6769395594000817, "critic_loss": 1.3636646075844765, "actor_loss": -86.07920735168457, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 44.14592480659485, "step": 111000}
{"episode_reward": 880.7352372178686, "episode": 112.0, "batch_reward": 0.679163922548294, "critic_loss": 1.331200595498085, "actor_loss": -86.52790573120117, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.680137157440186, "step": 112000}
{"episode_reward": 892.331060006422, "episode": 113.0, "batch_reward": 0.6828024592399597, "critic_loss": 1.3151703116297722, "actor_loss": -85.95541899108886, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.111963987350464, "step": 113000}
{"episode_reward": 758.1894244808256, "episode": 114.0, "batch_reward": 0.6831556629538537, "critic_loss": 1.2552535080313683, "actor_loss": -86.57931463623046, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.915554761886597, "step": 114000}
{"episode_reward": 945.9517541417384, "episode": 115.0, "batch_reward": 0.6844247325658798, "critic_loss": 1.2729941011071204, "actor_loss": -87.25344017028809, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.001169443130493, "step": 115000}
{"episode_reward": 902.4882516665641, "episode": 116.0, "batch_reward": 0.6867124614715576, "critic_loss": 1.3088957968950272, "actor_loss": -86.76701528930664, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.309104442596436, "step": 116000}
{"episode_reward": 891.7964694561408, "episode": 117.0, "batch_reward": 0.6883972361087799, "critic_loss": 1.3273416959047317, "actor_loss": -87.03666314697266, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.760679960250854, "step": 117000}
{"episode_reward": 887.9876347879673, "episode": 118.0, "batch_reward": 0.6909466955065727, "critic_loss": 1.3318906285762786, "actor_loss": -86.93872268676758, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.78490138053894, "step": 118000}
{"episode_reward": 887.872152541469, "episode": 119.0, "batch_reward": 0.69109117436409, "critic_loss": 1.3665066746473313, "actor_loss": -87.17016693115234, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.073484420776367, "step": 119000}
{"episode_reward": 786.2873871870744, "episode": 120.0, "batch_reward": 0.6915939512252808, "critic_loss": 1.368626720249653, "actor_loss": -87.40923973083495, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.801522254943848, "step": 120000}
{"episode_reward": 912.8302730394978, "episode": 121.0, "batch_reward": 0.69457093167305, "critic_loss": 1.3610737611055375, "actor_loss": -87.47316380310059, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 45.056854009628296, "step": 121000}
{"episode_reward": 921.3281287844259, "episode": 122.0, "batch_reward": 0.6977080087065697, "critic_loss": 1.3000900930762291, "actor_loss": -87.8233321685791, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.88617515563965, "step": 122000}
{"episode_reward": 887.8819482941293, "episode": 123.0, "batch_reward": 0.697530832529068, "critic_loss": 1.313244372010231, "actor_loss": -87.95775170898438, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.648576259613037, "step": 123000}
{"episode_reward": 795.405564189204, "episode": 124.0, "batch_reward": 0.6979516807794571, "critic_loss": 1.3658562008738517, "actor_loss": -87.63355644226074, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.528050661087036, "step": 124000}
{"episode_reward": 953.6909938589686, "episode": 125.0, "batch_reward": 0.7008457029461861, "critic_loss": 1.3319755160808564, "actor_loss": -87.80798222351075, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.229992866516113, "step": 125000}
{"episode_reward": 872.9493925753944, "episode": 126.0, "batch_reward": 0.7020751747488976, "critic_loss": 1.3418825114369393, "actor_loss": -88.02940213012695, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.173776149749756, "step": 126000}
{"episode_reward": 936.9008689990551, "episode": 127.0, "batch_reward": 0.7040057617425919, "critic_loss": 1.362909376859665, "actor_loss": -87.6636099243164, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.874835729599, "step": 127000}
{"episode_reward": 866.4780528910826, "episode": 128.0, "batch_reward": 0.7044676675796508, "critic_loss": 1.3540074694752693, "actor_loss": -87.46969830322266, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.917869567871094, "step": 128000}
{"episode_reward": 946.2280174375466, "episode": 129.0, "batch_reward": 0.7074290357232094, "critic_loss": 1.3616671112179757, "actor_loss": -87.88479930114747, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.91366958618164, "step": 129000}
{"episode_reward": 935.4332763444907, "episode": 130.0, "batch_reward": 0.7077766109704972, "critic_loss": 1.363697479248047, "actor_loss": -87.69900039672852, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.87077045440674, "step": 130000}
{"episode_reward": 797.849033028105, "episode": 131.0, "batch_reward": 0.7082456000447274, "critic_loss": 1.363359382390976, "actor_loss": -87.18929753112793, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.50071120262146, "step": 131000}
{"episode_reward": 825.311353178583, "episode": 132.0, "batch_reward": 0.7094321657419205, "critic_loss": 1.3690962392687798, "actor_loss": -87.8073316040039, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.70904564857483, "step": 132000}
{"episode_reward": 892.9012960809592, "episode": 133.0, "batch_reward": 0.7100825601220131, "critic_loss": 1.3702308774590493, "actor_loss": -87.9866524963379, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.414438247680664, "step": 133000}
{"episode_reward": 878.0451686944205, "episode": 134.0, "batch_reward": 0.7119532771706581, "critic_loss": 1.3724167760014534, "actor_loss": -88.12362738037109, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.766040086746216, "step": 134000}
{"episode_reward": 878.9472179888475, "episode": 135.0, "batch_reward": 0.7136310555934906, "critic_loss": 1.3279223096370698, "actor_loss": -88.34588772583008, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.742455005645752, "step": 135000}
{"episode_reward": 926.1684193987344, "episode": 136.0, "batch_reward": 0.7153984320163727, "critic_loss": 1.3258230996727944, "actor_loss": -88.57899826049805, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.86850118637085, "step": 136000}
{"episode_reward": 824.7594273659548, "episode": 137.0, "batch_reward": 0.7164825523495674, "critic_loss": 1.3018044919371605, "actor_loss": -88.39970462036133, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 23.08596897125244, "step": 137000}
{"episode_reward": 927.5423646904144, "episode": 138.0, "batch_reward": 0.7183622015714646, "critic_loss": 1.2501128143072129, "actor_loss": -87.63302767944336, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 24.385056257247925, "step": 138000}
{"episode_reward": 913.5692822085213, "episode": 139.0, "batch_reward": 0.7193672178983689, "critic_loss": 1.2574755870699883, "actor_loss": -87.54997668457031, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.466623067855835, "step": 139000}
{"episode_reward": 871.4939668843176, "episode": 140.0, "batch_reward": 0.7196917048692704, "critic_loss": 1.2361704327464105, "actor_loss": -87.95538357543946, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.68935465812683, "step": 140000}
{"episode_reward": 922.9852611972179, "episode": 141.0, "batch_reward": 0.7217417038679123, "critic_loss": 1.2347553372383118, "actor_loss": -88.63684992980957, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 44.14084815979004, "step": 141000}
{"episode_reward": 925.337372327898, "episode": 142.0, "batch_reward": 0.7233578165173531, "critic_loss": 1.2249929389953613, "actor_loss": -88.29119943237305, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.865286827087402, "step": 142000}
{"episode_reward": 867.649585327557, "episode": 143.0, "batch_reward": 0.7243466952443123, "critic_loss": 1.2534305956959724, "actor_loss": -88.81205618286133, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.96297335624695, "step": 143000}
{"episode_reward": 937.2354362606937, "episode": 144.0, "batch_reward": 0.7270507428050041, "critic_loss": 1.2310400286018848, "actor_loss": -88.44351162719727, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.942047357559204, "step": 144000}
{"episode_reward": 871.9503974072768, "episode": 145.0, "batch_reward": 0.7269489147663116, "critic_loss": 1.2184488122463226, "actor_loss": -89.21617700195313, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.04304790496826, "step": 145000}
{"episode_reward": 825.4912184915811, "episode": 146.0, "batch_reward": 0.727830604493618, "critic_loss": 1.236912936449051, "actor_loss": -88.16284814453125, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.672489643096924, "step": 146000}
{"episode_reward": 950.19264214845, "episode": 147.0, "batch_reward": 0.7299202043414116, "critic_loss": 1.2335171455144882, "actor_loss": -88.66114311218261, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.431177854537964, "step": 147000}
{"episode_reward": 858.356785382659, "episode": 148.0, "batch_reward": 0.7290156724452972, "critic_loss": 1.2560433718562125, "actor_loss": -88.81083976745606, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.795422792434692, "step": 148000}
{"episode_reward": 915.7492219094876, "episode": 149.0, "batch_reward": 0.7313591805100441, "critic_loss": 1.2556298758387565, "actor_loss": -88.65899446105956, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.284932613372803, "step": 149000}
{"episode_reward": 901.0367195278754, "episode": 150.0, "batch_reward": 0.7323287084102631, "critic_loss": 1.2759872491955757, "actor_loss": -88.62253759765625, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "step": 150000}
