{"episode_reward": 0.0, "episode": 1.0, "duration": 20.990979433059692, "step": 1000}
{"episode_reward": 27.46298806610516, "episode": 2.0, "duration": 1.8302886486053467, "step": 2000}
{"episode_reward": 489.1100087318934, "episode": 3.0, "batch_reward": 0.24518921650342443, "critic_loss": 0.9056089600798447, "actor_loss": -87.40264009046001, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 59.7611722946167, "step": 3000}
{"episode_reward": 47.23602948317603, "episode": 4.0, "batch_reward": 0.18416264152526857, "critic_loss": 1.5050996396541596, "actor_loss": -96.8407467803955, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.952229738235474, "step": 4000}
{"episode_reward": 103.65678406395914, "episode": 5.0, "batch_reward": 0.16814124108850956, "critic_loss": 3.8549219628572464, "actor_loss": -100.94558258056641, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.969785451889038, "step": 5000}
{"episode_reward": 212.29704925454223, "episode": 6.0, "batch_reward": 0.18025330601632594, "critic_loss": 5.22823878622055, "actor_loss": -108.54286788940429, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.90291976928711, "step": 6000}
{"episode_reward": 301.5930500536666, "episode": 7.0, "batch_reward": 0.2044225447922945, "critic_loss": 4.629572117567062, "actor_loss": -109.34773493957519, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.944389820098877, "step": 7000}
{"episode_reward": 222.9652446448912, "episode": 8.0, "batch_reward": 0.2029882460087538, "critic_loss": 3.537011777639389, "actor_loss": -108.57401861572265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.924431562423706, "step": 8000}
{"episode_reward": 320.54627374306614, "episode": 9.0, "batch_reward": 0.2328806582838297, "critic_loss": 2.935158068537712, "actor_loss": -109.67569688415527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.925424814224243, "step": 9000}
{"episode_reward": 458.35985318924287, "episode": 10.0, "batch_reward": 0.2567520540505648, "critic_loss": 2.3786481438875198, "actor_loss": -107.81898425292968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.93692421913147, "step": 10000}
{"episode_reward": 501.2610580142569, "episode": 11.0, "batch_reward": 0.2610359095185995, "critic_loss": 1.733223004579544, "actor_loss": -106.38209492492676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.56628966331482, "step": 11000}
{"episode_reward": 133.33502000377848, "episode": 12.0, "batch_reward": 0.24922256802022458, "critic_loss": 1.1753597941398621, "actor_loss": -104.2302645111084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.92061471939087, "step": 12000}
{"episode_reward": 96.13500924956705, "episode": 13.0, "batch_reward": 0.24383267579972745, "critic_loss": 1.282727213859558, "actor_loss": -101.5005246887207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.90320062637329, "step": 13000}
{"episode_reward": 237.15567628421692, "episode": 14.0, "batch_reward": 0.2427520955502987, "critic_loss": 1.1159243369102478, "actor_loss": -98.71824794006348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.900875329971313, "step": 14000}
{"episode_reward": 289.5989044336506, "episode": 15.0, "batch_reward": 0.24529121604561804, "critic_loss": 0.9106573797464371, "actor_loss": -97.03862448120117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.907676219940186, "step": 15000}
{"episode_reward": 156.50715858119085, "episode": 16.0, "batch_reward": 0.24822332714498044, "critic_loss": 0.8645280304551125, "actor_loss": -95.13151679992676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.929571866989136, "step": 16000}
{"episode_reward": 477.8815538453982, "episode": 17.0, "batch_reward": 0.26085138840973376, "critic_loss": 0.9029645639061927, "actor_loss": -93.43577870178223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.92027997970581, "step": 17000}
{"episode_reward": 469.83552417793237, "episode": 18.0, "batch_reward": 0.2774380686730146, "critic_loss": 0.8259829593896866, "actor_loss": -91.53778671264648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.913283586502075, "step": 18000}
{"episode_reward": 618.7205402509276, "episode": 19.0, "batch_reward": 0.2917814401686192, "critic_loss": 0.8317323628664016, "actor_loss": -89.83652946472168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.894298791885376, "step": 19000}
{"episode_reward": 486.8851575252751, "episode": 20.0, "batch_reward": 0.3048445391356945, "critic_loss": 0.8731865975856781, "actor_loss": -88.33842979431152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.917349815368652, "step": 20000}
{"episode_reward": 567.1457997772992, "episode": 21.0, "batch_reward": 0.3143572859168053, "critic_loss": 0.9043594251275062, "actor_loss": -86.90847412109375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.639748334884644, "step": 21000}
{"episode_reward": 388.0245635565983, "episode": 22.0, "batch_reward": 0.3200150498151779, "critic_loss": 0.9280084497928619, "actor_loss": -85.43172686767578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.929389476776123, "step": 22000}
{"episode_reward": 550.1141973757425, "episode": 23.0, "batch_reward": 0.3305724301338196, "critic_loss": 0.9660330756306649, "actor_loss": -84.23789093017578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.918014764785767, "step": 23000}
{"episode_reward": 622.087979544726, "episode": 24.0, "batch_reward": 0.3410384140610695, "critic_loss": 1.0050174944996835, "actor_loss": -83.18649114990234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.921215772628784, "step": 24000}
{"episode_reward": 524.0298007322233, "episode": 25.0, "batch_reward": 0.3505404378473759, "critic_loss": 1.0478448849916457, "actor_loss": -82.34621673583985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.92341661453247, "step": 25000}
{"episode_reward": 514.178258162843, "episode": 26.0, "batch_reward": 0.35728868761658666, "critic_loss": 1.0933643788695335, "actor_loss": -81.40080239868163, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.92525005340576, "step": 26000}
{"episode_reward": 622.0324244867785, "episode": 27.0, "batch_reward": 0.36844186371564863, "critic_loss": 1.0104581248760223, "actor_loss": -80.63569551086425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.92089605331421, "step": 27000}
{"episode_reward": 645.0355698251635, "episode": 28.0, "batch_reward": 0.37482169923186304, "critic_loss": 1.0059286835193635, "actor_loss": -79.83092752075196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.93655490875244, "step": 28000}
{"episode_reward": 540.7811257038784, "episode": 29.0, "batch_reward": 0.3842104587256908, "critic_loss": 0.9904130679368973, "actor_loss": -79.05208795166016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.953693628311157, "step": 29000}
{"episode_reward": 668.8847599220106, "episode": 30.0, "batch_reward": 0.3962136762440205, "critic_loss": 0.9590574009418488, "actor_loss": -78.55361067199706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.9544415473938, "step": 30000}
{"episode_reward": 767.9952830017179, "episode": 31.0, "batch_reward": 0.40408513343334196, "critic_loss": 0.9318033409714699, "actor_loss": -78.21481465148926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.60244011878967, "step": 31000}
{"episode_reward": 545.3317136775823, "episode": 32.0, "batch_reward": 0.41063185542821884, "critic_loss": 0.9479544728994369, "actor_loss": -77.39144047546387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.907514095306396, "step": 32000}
{"episode_reward": 700.6633816707284, "episode": 33.0, "batch_reward": 0.4131041621267796, "critic_loss": 0.9253431459069252, "actor_loss": -76.54398481750488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.926289319992065, "step": 33000}
{"episode_reward": 384.2689129160422, "episode": 34.0, "batch_reward": 0.42084583374857903, "critic_loss": 0.9575960603952408, "actor_loss": -76.44042825317383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.89854097366333, "step": 34000}
{"episode_reward": 737.0614016176745, "episode": 35.0, "batch_reward": 0.4268256727159023, "critic_loss": 0.9957223638296128, "actor_loss": -75.2108747253418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.928202152252197, "step": 35000}
{"episode_reward": 444.3778189755657, "episode": 36.0, "batch_reward": 0.4290510857105255, "critic_loss": 1.0115985003113748, "actor_loss": -75.29341456604004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.903783321380615, "step": 36000}
{"episode_reward": 644.508760630591, "episode": 37.0, "batch_reward": 0.4339188812673092, "critic_loss": 1.0248423383235932, "actor_loss": -74.68140766906738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.926873683929443, "step": 37000}
{"episode_reward": 634.416921653845, "episode": 38.0, "batch_reward": 0.43785011556744574, "critic_loss": 1.0441886408925056, "actor_loss": -74.13222932434083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.91969656944275, "step": 38000}
{"episode_reward": 614.6473987406913, "episode": 39.0, "batch_reward": 0.44000701123476027, "critic_loss": 1.059240848094225, "actor_loss": -73.8603705291748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.930728673934937, "step": 39000}
{"episode_reward": 506.88502024144964, "episode": 40.0, "batch_reward": 0.44609694758057594, "critic_loss": 1.1023288410305976, "actor_loss": -73.79338761901856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.954407453536987, "step": 40000}
{"episode_reward": 640.2833424542827, "episode": 41.0, "batch_reward": 0.451296163469553, "critic_loss": 1.131921572983265, "actor_loss": -73.3155991821289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.62773633003235, "step": 41000}
{"episode_reward": 766.3676843544517, "episode": 42.0, "batch_reward": 0.4594765828847885, "critic_loss": 1.1635172953605653, "actor_loss": -73.3530487060547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.933268547058105, "step": 42000}
{"episode_reward": 806.5775860588009, "episode": 43.0, "batch_reward": 0.46668766647577287, "critic_loss": 1.2103372825980185, "actor_loss": -73.61019714355469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.91803765296936, "step": 43000}
{"episode_reward": 740.0415689462353, "episode": 44.0, "batch_reward": 0.4739128679037094, "critic_loss": 1.1712842335700988, "actor_loss": -73.52822686767578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.95180058479309, "step": 44000}
{"episode_reward": 708.6700282221113, "episode": 45.0, "batch_reward": 0.4772174002826214, "critic_loss": 1.2078866575360299, "actor_loss": -73.2231876373291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.953967809677124, "step": 45000}
{"episode_reward": 739.022477501461, "episode": 46.0, "batch_reward": 0.4847811700999737, "critic_loss": 1.1968475992679597, "actor_loss": -73.1687004699707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.261473894119263, "step": 46000}
{"episode_reward": 832.5548833340705, "episode": 47.0, "batch_reward": 0.49210674029588697, "critic_loss": 1.1659195476174355, "actor_loss": -73.75103660583495, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.933207273483276, "step": 47000}
{"episode_reward": 809.5980925483576, "episode": 48.0, "batch_reward": 0.49586024883389473, "critic_loss": 1.196857000887394, "actor_loss": -73.30140412902833, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.880959033966064, "step": 48000}
{"episode_reward": 719.3927737560325, "episode": 49.0, "batch_reward": 0.5050619037151337, "critic_loss": 1.1386612352728844, "actor_loss": -74.36527548217774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.899787425994873, "step": 49000}
{"episode_reward": 768.0896119447921, "episode": 50.0, "batch_reward": 0.5078242467045784, "critic_loss": 1.1412714849710464, "actor_loss": -74.45772163391113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.907756090164185, "step": 50000}
{"episode_reward": 801.5631642835218, "episode": 51.0, "batch_reward": 0.5151660355627536, "critic_loss": 1.1207677889466285, "actor_loss": -74.52588006591797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.57860350608826, "step": 51000}
{"episode_reward": 909.8657053579968, "episode": 52.0, "batch_reward": 0.5243044659793377, "critic_loss": 1.0975714433789254, "actor_loss": -74.60161212158204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.965476512908936, "step": 52000}
{"episode_reward": 885.5560072811381, "episode": 53.0, "batch_reward": 0.529634749352932, "critic_loss": 1.079681285560131, "actor_loss": -75.46737586975098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.96060276031494, "step": 53000}
{"episode_reward": 802.6844046919138, "episode": 54.0, "batch_reward": 0.5346171596348286, "critic_loss": 1.0868272094130516, "actor_loss": -75.46063706970214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.95971179008484, "step": 54000}
{"episode_reward": 823.9637507408131, "episode": 55.0, "batch_reward": 0.5417791185379028, "critic_loss": 1.0651671451330185, "actor_loss": -75.80489624023437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.930320262908936, "step": 55000}
{"episode_reward": 925.2217523091778, "episode": 56.0, "batch_reward": 0.5462454857826233, "critic_loss": 1.0560398384928704, "actor_loss": -75.9533780670166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.93274211883545, "step": 56000}
{"episode_reward": 824.6791727967566, "episode": 57.0, "batch_reward": 0.5535303436815738, "critic_loss": 1.04845209723711, "actor_loss": -75.99485804748535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.94038224220276, "step": 57000}
{"episode_reward": 894.6811556462818, "episode": 58.0, "batch_reward": 0.557842532068491, "critic_loss": 1.0654022452235221, "actor_loss": -76.74142723083496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.946848392486572, "step": 58000}
{"episode_reward": 859.3991464252978, "episode": 59.0, "batch_reward": 0.5626370794475078, "critic_loss": 1.0620676801800728, "actor_loss": -76.56486639404297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.00009846687317, "step": 59000}
{"episode_reward": 866.5807937149459, "episode": 60.0, "batch_reward": 0.5688810118734836, "critic_loss": 1.057029641211033, "actor_loss": -76.70467895507812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.240806579589844, "step": 60000}
{"episode_reward": 912.8968069330717, "episode": 61.0, "batch_reward": 0.5731970036923886, "critic_loss": 1.0220048913359643, "actor_loss": -77.60193348693848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.574918031692505, "step": 61000}
{"episode_reward": 855.0958505944744, "episode": 62.0, "batch_reward": 0.5787423554658889, "critic_loss": 1.0314083359241486, "actor_loss": -77.63925776672363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.928752660751343, "step": 62000}
{"episode_reward": 843.2942349782955, "episode": 63.0, "batch_reward": 0.5825320824980735, "critic_loss": 1.0356155881881715, "actor_loss": -78.189302734375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.93209719657898, "step": 63000}
{"episode_reward": 864.4250454507567, "episode": 64.0, "batch_reward": 0.5879128851294517, "critic_loss": 1.0200944312214852, "actor_loss": -78.87160968017578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.95894145965576, "step": 64000}
{"episode_reward": 920.4266693836029, "episode": 65.0, "batch_reward": 0.5927128041386605, "critic_loss": 1.0016243810653687, "actor_loss": -79.15519242858886, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.96875023841858, "step": 65000}
{"episode_reward": 932.8421324875987, "episode": 66.0, "batch_reward": 0.5974135164022446, "critic_loss": 0.9875898010730744, "actor_loss": -79.37619369506837, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.967768907546997, "step": 66000}
{"episode_reward": 931.7230758875831, "episode": 67.0, "batch_reward": 0.604963073015213, "critic_loss": 0.9649644021391869, "actor_loss": -79.60895297241211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.969250917434692, "step": 67000}
{"episode_reward": 932.1011470116282, "episode": 68.0, "batch_reward": 0.6105978897809983, "critic_loss": 0.9596461783349514, "actor_loss": -80.21818351745605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.976304292678833, "step": 68000}
{"episode_reward": 907.2682245333311, "episode": 69.0, "batch_reward": 0.6126693719029427, "critic_loss": 0.9265469102859497, "actor_loss": -80.26835740661622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.957975387573242, "step": 69000}
{"episode_reward": 916.7073245385983, "episode": 70.0, "batch_reward": 0.6162806165218353, "critic_loss": 0.9354723082780838, "actor_loss": -80.54849174499512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.963786363601685, "step": 70000}
{"episode_reward": 872.6173662182591, "episode": 71.0, "batch_reward": 0.6206024055480956, "critic_loss": 0.9389438315033912, "actor_loss": -81.28527954101563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.64079689979553, "step": 71000}
{"episode_reward": 919.0931634882354, "episode": 72.0, "batch_reward": 0.6234508130550385, "critic_loss": 0.9567856583595276, "actor_loss": -81.1767887878418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.974828958511353, "step": 72000}
{"episode_reward": 885.724609274113, "episode": 73.0, "batch_reward": 0.6300905795097351, "critic_loss": 0.926838024020195, "actor_loss": -81.96067166137695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27638840675354, "step": 73000}
{"episode_reward": 937.9497147459477, "episode": 74.0, "batch_reward": 0.6309073041677475, "critic_loss": 0.894101961672306, "actor_loss": -82.28078805541992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.912827253341675, "step": 74000}
{"episode_reward": 885.1382212153535, "episode": 75.0, "batch_reward": 0.6359194224476814, "critic_loss": 0.87463313215971, "actor_loss": -82.5754290008545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.88103675842285, "step": 75000}
{"episode_reward": 911.3267104709361, "episode": 76.0, "batch_reward": 0.6399267464876175, "critic_loss": 0.8537512620985508, "actor_loss": -82.87739315795899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.909871816635132, "step": 76000}
{"episode_reward": 905.6920860674105, "episode": 77.0, "batch_reward": 0.643425740301609, "critic_loss": 0.8598879485726356, "actor_loss": -83.01972494506836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.959839582443237, "step": 77000}
{"episode_reward": 939.2346855494891, "episode": 78.0, "batch_reward": 0.6480801928043366, "critic_loss": 0.8495772114396095, "actor_loss": -82.84626588439941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.948726177215576, "step": 78000}
{"episode_reward": 943.6516587749138, "episode": 79.0, "batch_reward": 0.6509157049655915, "critic_loss": 0.8260880381464958, "actor_loss": -83.43457766723633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.962599754333496, "step": 79000}
{"episode_reward": 954.8231160344412, "episode": 80.0, "batch_reward": 0.6533024861216545, "critic_loss": 0.8603250744342804, "actor_loss": -83.66794645690918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.98643207550049, "step": 80000}
{"episode_reward": 939.4530518586052, "episode": 81.0, "batch_reward": 0.6574921244382859, "critic_loss": 0.8333221398591996, "actor_loss": -83.99180406188965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.59282302856445, "step": 81000}
{"episode_reward": 927.8573807912707, "episode": 82.0, "batch_reward": 0.6609108179211617, "critic_loss": 0.8099217025637626, "actor_loss": -84.2175532989502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.94667935371399, "step": 82000}
{"episode_reward": 936.835142531562, "episode": 83.0, "batch_reward": 0.6660592146515846, "critic_loss": 0.8169512248635292, "actor_loss": -84.32640383911132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.941386938095093, "step": 83000}
{"episode_reward": 943.0938345719225, "episode": 84.0, "batch_reward": 0.6674045767784119, "critic_loss": 0.7910660152733326, "actor_loss": -84.79663388061523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.965856552124023, "step": 84000}
{"episode_reward": 858.468825351746, "episode": 85.0, "batch_reward": 0.6699236536622047, "critic_loss": 0.7950645375847817, "actor_loss": -84.69909298706055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.95131802558899, "step": 85000}
{"episode_reward": 920.7574620116577, "episode": 86.0, "batch_reward": 0.6722019323110581, "critic_loss": 0.8229750950932503, "actor_loss": -85.12963122558594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.953972578048706, "step": 86000}
{"episode_reward": 909.0489000625779, "episode": 87.0, "batch_reward": 0.6737982035875321, "critic_loss": 0.7785140974223613, "actor_loss": -85.20949250793457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.952811002731323, "step": 87000}
{"episode_reward": 952.5306405985177, "episode": 88.0, "batch_reward": 0.6788327867984771, "critic_loss": 0.8097598722577095, "actor_loss": -85.2792103881836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.97162938117981, "step": 88000}
{"episode_reward": 908.6205878072545, "episode": 89.0, "batch_reward": 0.6811486282348633, "critic_loss": 0.8270825406610965, "actor_loss": -85.67875672912598, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.95684814453125, "step": 89000}
{"episode_reward": 886.3671520598367, "episode": 90.0, "batch_reward": 0.6826707996726036, "critic_loss": 0.8310728721022606, "actor_loss": -85.96256114196777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.947784900665283, "step": 90000}
{"episode_reward": 912.0537870965039, "episode": 91.0, "batch_reward": 0.6856218075752258, "critic_loss": 0.8577368113994598, "actor_loss": -86.0386213684082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.57831692695618, "step": 91000}
{"episode_reward": 896.8235605083605, "episode": 92.0, "batch_reward": 0.6888054108023643, "critic_loss": 0.8357838330566884, "actor_loss": -86.11738577270508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.938462018966675, "step": 92000}
{"episode_reward": 941.2022713058435, "episode": 93.0, "batch_reward": 0.6916447122097016, "critic_loss": 0.8439441278278828, "actor_loss": -86.1512943572998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.941120862960815, "step": 93000}
{"episode_reward": 915.6466365886414, "episode": 94.0, "batch_reward": 0.6953089166283607, "critic_loss": 0.857916963994503, "actor_loss": -86.4016238861084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.94631576538086, "step": 94000}
{"episode_reward": 934.997000719723, "episode": 95.0, "batch_reward": 0.6953274251222611, "critic_loss": 0.827672215104103, "actor_loss": -86.83020678710938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.961806297302246, "step": 95000}
{"episode_reward": 937.2528146511798, "episode": 96.0, "batch_reward": 0.7000728260874748, "critic_loss": 0.8456946618854999, "actor_loss": -86.67507341003417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.955000400543213, "step": 96000}
{"episode_reward": 931.5322703081334, "episode": 97.0, "batch_reward": 0.7000368345379829, "critic_loss": 0.8568283472955227, "actor_loss": -87.11463920593262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.915019989013672, "step": 97000}
{"episode_reward": 915.8746192039563, "episode": 98.0, "batch_reward": 0.70520490026474, "critic_loss": 0.8606587721407414, "actor_loss": -87.48281929016113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.929784536361694, "step": 98000}
{"episode_reward": 892.3342334378568, "episode": 99.0, "batch_reward": 0.7047428055405617, "critic_loss": 0.8623175828456878, "actor_loss": -87.36842977905273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.967226028442383, "step": 99000}
{"episode_reward": 975.8505697935085, "episode": 100.0, "batch_reward": 0.7071077381372451, "critic_loss": 0.8520243861973286, "actor_loss": -87.20755503845214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.9768328666687, "step": 100000}
{"episode_reward": 921.3513864181634, "episode": 101.0, "batch_reward": 0.7105596400499344, "critic_loss": 0.8636480583250523, "actor_loss": -87.54328645324708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.54749131202698, "step": 101000}
{"episode_reward": 946.9078289474335, "episode": 102.0, "batch_reward": 0.7127378431558609, "critic_loss": 0.876708199262619, "actor_loss": -87.83910134887695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.9476056098938, "step": 102000}
{"episode_reward": 937.0537725469056, "episode": 103.0, "batch_reward": 0.715389620244503, "critic_loss": 0.8270555076301098, "actor_loss": -87.78730029296875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.943538188934326, "step": 103000}
{"episode_reward": 973.4500066455937, "episode": 104.0, "batch_reward": 0.7191366947293282, "critic_loss": 0.838333431661129, "actor_loss": -88.08192649841308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.959376573562622, "step": 104000}
{"episode_reward": 907.2913117170225, "episode": 105.0, "batch_reward": 0.7186035851240158, "critic_loss": 0.809733669012785, "actor_loss": -88.12529843139649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.95894694328308, "step": 105000}
{"episode_reward": 971.3940530621016, "episode": 106.0, "batch_reward": 0.7217568756341934, "critic_loss": 0.8026724047958851, "actor_loss": -88.48047366333007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.94417095184326, "step": 106000}
{"episode_reward": 982.0686996058231, "episode": 107.0, "batch_reward": 0.7230010135173798, "critic_loss": 0.7717049341499805, "actor_loss": -88.64895906066894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.930593729019165, "step": 107000}
{"episode_reward": 959.3505065916994, "episode": 108.0, "batch_reward": 0.7265345296859741, "critic_loss": 0.745892329365015, "actor_loss": -88.77770333862304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.94027876853943, "step": 108000}
{"episode_reward": 989.2385635805724, "episode": 109.0, "batch_reward": 0.7287241819500924, "critic_loss": 0.7229632422626019, "actor_loss": -89.07469415283204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.97559404373169, "step": 109000}
{"episode_reward": 990.7521623331828, "episode": 110.0, "batch_reward": 0.7318500935435295, "critic_loss": 0.7422942986786365, "actor_loss": -89.24705432128906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.96710777282715, "step": 110000}
{"episode_reward": 943.292543027978, "episode": 111.0, "batch_reward": 0.7324783126115799, "critic_loss": 0.7200161248147487, "actor_loss": -89.15072901916504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.62068319320679, "step": 111000}
{"episode_reward": 931.7296451272327, "episode": 112.0, "batch_reward": 0.7340430450439454, "critic_loss": 0.6937281343340874, "actor_loss": -89.28907420349121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.97866415977478, "step": 112000}
{"episode_reward": 921.2339389415428, "episode": 113.0, "batch_reward": 0.7372221119403839, "critic_loss": 0.7112150143384933, "actor_loss": -89.29633009338379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.968172788619995, "step": 113000}
{"episode_reward": 916.5884180244385, "episode": 114.0, "batch_reward": 0.737079504609108, "critic_loss": 0.7044160136282444, "actor_loss": -89.65775296020507, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.93040704727173, "step": 114000}
{"episode_reward": 939.3856316872973, "episode": 115.0, "batch_reward": 0.7397637512683869, "critic_loss": 0.6994087921082973, "actor_loss": -89.68466067504883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.940124034881592, "step": 115000}
{"episode_reward": 962.4462578876227, "episode": 116.0, "batch_reward": 0.7409526777863502, "critic_loss": 0.6929430700242519, "actor_loss": -89.85125035095214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.928348064422607, "step": 116000}
{"episode_reward": 923.8148342730764, "episode": 117.0, "batch_reward": 0.7436652724146843, "critic_loss": 0.6983320863246918, "actor_loss": -90.0160776977539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.954391717910767, "step": 117000}
{"episode_reward": 914.3292062850912, "episode": 118.0, "batch_reward": 0.7453502559661865, "critic_loss": 0.6694475710690021, "actor_loss": -89.86174076843261, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.962538242340088, "step": 118000}
{"episode_reward": 925.8851862527931, "episode": 119.0, "batch_reward": 0.7455856795907021, "critic_loss": 0.6746857160329819, "actor_loss": -89.9605746307373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.962897300720215, "step": 119000}
{"episode_reward": 792.7582986331267, "episode": 120.0, "batch_reward": 0.7457084875702858, "critic_loss": 0.6850000579059125, "actor_loss": -90.20595190429688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.953994512557983, "step": 120000}
{"episode_reward": 979.9074626998911, "episode": 121.0, "batch_reward": 0.748803623020649, "critic_loss": 0.7051315184831619, "actor_loss": -90.08259765625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.624809980392456, "step": 121000}
{"episode_reward": 922.1790366297174, "episode": 122.0, "batch_reward": 0.7508200353980065, "critic_loss": 0.6921396540105342, "actor_loss": -90.21703102111816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.985551595687866, "step": 122000}
{"episode_reward": 939.6461707762722, "episode": 123.0, "batch_reward": 0.751149175465107, "critic_loss": 0.7195196953117847, "actor_loss": -90.39408654785156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.960310220718384, "step": 123000}
{"episode_reward": 920.8435424976105, "episode": 124.0, "batch_reward": 0.7523291010260582, "critic_loss": 0.712366654753685, "actor_loss": -90.43126272583008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.95268678665161, "step": 124000}
{"episode_reward": 954.7676044508468, "episode": 125.0, "batch_reward": 0.7562118014097213, "critic_loss": 0.7209321253597737, "actor_loss": -90.36663040161133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.94779133796692, "step": 125000}
{"episode_reward": 966.7357897993667, "episode": 126.0, "batch_reward": 0.7566765302419662, "critic_loss": 0.7603056213557721, "actor_loss": -90.51286695861816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.92334532737732, "step": 126000}
{"episode_reward": 963.4007608987331, "episode": 127.0, "batch_reward": 0.7577890202999115, "critic_loss": 0.7491059109866619, "actor_loss": -90.65444299316407, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.94958758354187, "step": 127000}
{"episode_reward": 947.5495749884124, "episode": 128.0, "batch_reward": 0.760006321310997, "critic_loss": 0.7267379596531391, "actor_loss": -90.59966931152344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.966358423233032, "step": 128000}
{"episode_reward": 984.4364861210073, "episode": 129.0, "batch_reward": 0.7616492051482201, "critic_loss": 0.7277808238565922, "actor_loss": -90.68446533203125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.96558380126953, "step": 129000}
{"episode_reward": 949.2889156782674, "episode": 130.0, "batch_reward": 0.7637641097307205, "critic_loss": 0.7407282463014125, "actor_loss": -90.88552818298339, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.957261323928833, "step": 130000}
{"episode_reward": 890.3489511684525, "episode": 131.0, "batch_reward": 0.7633384767174721, "critic_loss": 0.7545216529369354, "actor_loss": -90.67852159118652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.60666298866272, "step": 131000}
{"episode_reward": 926.8242254025979, "episode": 132.0, "batch_reward": 0.7631736627817154, "critic_loss": 0.7474482372701168, "actor_loss": -91.04772933959961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.942007064819336, "step": 132000}
{"episode_reward": 960.3475356545634, "episode": 133.0, "batch_reward": 0.7643445245027543, "critic_loss": 0.709981889128685, "actor_loss": -90.95556132507325, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.948660850524902, "step": 133000}
{"episode_reward": 937.477813000932, "episode": 134.0, "batch_reward": 0.7663926411867141, "critic_loss": 0.7226231999397278, "actor_loss": -91.10326701354981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.950731992721558, "step": 134000}
{"episode_reward": 940.4430218547459, "episode": 135.0, "batch_reward": 0.7672874501347542, "critic_loss": 0.6938713611960411, "actor_loss": -91.20404357910157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.96590304374695, "step": 135000}
{"episode_reward": 957.5532508692002, "episode": 136.0, "batch_reward": 0.769106451511383, "critic_loss": 0.7020770882666111, "actor_loss": -91.25405891418457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.966828107833862, "step": 136000}
{"episode_reward": 936.4614253235577, "episode": 137.0, "batch_reward": 0.7722491254806518, "critic_loss": 0.6690728849768639, "actor_loss": -91.47138888549804, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.950842142105103, "step": 137000}
{"episode_reward": 974.6612178875189, "episode": 138.0, "batch_reward": 0.7725864072442055, "critic_loss": 0.6654374668598175, "actor_loss": -91.3524666595459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.973150491714478, "step": 138000}
{"episode_reward": 955.0452982117624, "episode": 139.0, "batch_reward": 0.774254375398159, "critic_loss": 0.6970999766588211, "actor_loss": -91.42869354248047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.975536823272705, "step": 139000}
{"episode_reward": 931.9566488494713, "episode": 140.0, "batch_reward": 0.7730052140951157, "critic_loss": 0.6643867039680481, "actor_loss": -91.43401510620117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.978182792663574, "step": 140000}
{"episode_reward": 967.0384504016669, "episode": 141.0, "batch_reward": 0.7769920778870583, "critic_loss": 0.6344222044348716, "actor_loss": -91.60489631652833, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.579001665115356, "step": 141000}
{"episode_reward": 970.3400645989921, "episode": 142.0, "batch_reward": 0.7771762108206749, "critic_loss": 0.6529682010412217, "actor_loss": -91.6448184967041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.928329706192017, "step": 142000}
{"episode_reward": 944.0863874876121, "episode": 143.0, "batch_reward": 0.7795570718050003, "critic_loss": 0.6543296665549279, "actor_loss": -91.72374655151367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.94490146636963, "step": 143000}
{"episode_reward": 940.830453525408, "episode": 144.0, "batch_reward": 0.780509905576706, "critic_loss": 0.6538335683047771, "actor_loss": -91.76940951538086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.931885719299316, "step": 144000}
{"episode_reward": 935.0942210749204, "episode": 145.0, "batch_reward": 0.7815019214749336, "critic_loss": 0.6461488197743893, "actor_loss": -91.83601467895508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.930663585662842, "step": 145000}
{"episode_reward": 917.4152613265088, "episode": 146.0, "batch_reward": 0.782125521838665, "critic_loss": 0.6682094452381134, "actor_loss": -91.87817240905761, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.94043731689453, "step": 146000}
{"episode_reward": 984.5095471111703, "episode": 147.0, "batch_reward": 0.7832802464962005, "critic_loss": 0.6478171866238117, "actor_loss": -91.96550677490234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.915045976638794, "step": 147000}
{"episode_reward": 946.3286969758407, "episode": 148.0, "batch_reward": 0.7845207625031472, "critic_loss": 0.6457095929682255, "actor_loss": -92.05633325195312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.957366943359375, "step": 148000}
{"episode_reward": 965.8948176131181, "episode": 149.0, "batch_reward": 0.7851088790893554, "critic_loss": 0.6610576740205288, "actor_loss": -92.15964465332031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.942171812057495, "step": 149000}
{"episode_reward": 900.307004118041, "episode": 150.0, "batch_reward": 0.7864946191310882, "critic_loss": 0.6378602427542209, "actor_loss": -92.14981893920898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
