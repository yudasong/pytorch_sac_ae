{"episode": 1.0, "duration": 21.70559811592102, "episode_reward": 27.46298806610516, "step": 1000}
{"episode": 2.0, "duration": 1.9399998188018799, "episode_reward": 489.1100087318934, "step": 2000}
{"episode": 3.0, "batch_reward": 0.26495997919742964, "actor_loss": -84.2863398014235, "actor_target_entropy": -6.0, "alpha_value": 0.002134017781850189, "duration": 48.38546800613403, "episode_reward": 370.9303304911014, "step": 3000}
{"episode": 4.0, "batch_reward": 0.2779727863818407, "actor_loss": -84.1140725402832, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.12556266784668, "episode_reward": 238.8859721104039, "step": 4000}
{"episode": 5.0, "batch_reward": 0.2843085236996412, "actor_loss": -83.92994194030761, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.103926420211792, "episode_reward": 326.4482160321872, "step": 5000}
{"episode": 6.0, "batch_reward": 0.28944116117060187, "actor_loss": -83.76536457824707, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.15618872642517, "episode_reward": 310.8336628430049, "step": 6000}
{"episode": 7.0, "batch_reward": 0.3059899183660746, "actor_loss": -83.94964007568359, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.32858443260193, "episode_reward": 417.5100139487964, "step": 7000}
{"episode": 8.0, "batch_reward": 0.31366050577163695, "actor_loss": -84.08419032287598, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.97471570968628, "episode_reward": 361.21565634504253, "step": 8000}
{"episode": 9.0, "batch_reward": 0.3243919220268726, "actor_loss": -84.26937980651856, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.009944915771484, "episode_reward": 388.63087022371207, "step": 9000}
{"episode": 10.0, "batch_reward": 0.32064576584100724, "actor_loss": -77.25006271362305, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 4081.5315675735474, "episode_reward": 197.07748288471987, "step": 10000}
{"episode": 11.0, "batch_reward": 0.31202087649703025, "actor_loss": -77.98210803222656, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 37.086347818374634, "episode_reward": 311.42933669403806, "step": 11000}
{"episode": 12.0, "batch_reward": 0.3064037679731846, "actor_loss": -74.56915435791015, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 435.88815093040466, "episode_reward": 125.34335800815643, "step": 12000}
{"episode": 13.0, "batch_reward": 0.28960266897082326, "actor_loss": -74.05068006896973, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.256325244903564, "episode_reward": 74.94028535810544, "step": 13000}
{"episode": 14.0, "batch_reward": 0.27344043412804603, "actor_loss": -70.99684780883788, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 426.4201440811157, "episode_reward": 111.82057702661274, "step": 14000}
{"episode": 15.0, "batch_reward": 0.26996296441555023, "actor_loss": -70.91042741394043, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.8973286151886, "episode_reward": 274.5370751077845, "step": 15000}
{"episode": 16.0, "batch_reward": 0.2670402007251978, "actor_loss": -68.64051501464844, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 431.69317150115967, "episode_reward": 168.2450402800029, "step": 16000}
{"episode": 17.0, "batch_reward": 0.2640180471241474, "actor_loss": -68.7382975921631, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.619493007659912, "episode_reward": 312.6390980608618, "step": 17000}
{"episode": 18.0, "batch_reward": 0.26538705925643447, "actor_loss": -67.91050299072266, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 428.51089334487915, "episode_reward": 177.2812261866287, "step": 18000}
{"episode": 19.0, "batch_reward": 0.26077038802206515, "actor_loss": -68.02743374633789, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.96476650238037, "episode_reward": 306.8605224339847, "step": 19000}
{"episode": 20.0, "batch_reward": 0.26457505384087565, "actor_loss": -67.55455702209473, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 443.1894862651825, "episode_reward": 210.03029430358774, "step": 20000}
{"episode": 21.0, "batch_reward": 0.2603152446299791, "actor_loss": -67.72339053344727, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 40.05313158035278, "episode_reward": 216.83308572067668, "step": 21000}
{"episode": 22.0, "batch_reward": 0.2574074260443449, "actor_loss": -66.27726243591309, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 462.5211572647095, "episode_reward": 154.20971820868613, "step": 22000}
{"episode": 23.0, "batch_reward": 0.2587668350338936, "actor_loss": -66.50477626037598, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.28119158744812, "episode_reward": 424.49753922817393, "step": 23000}
{"episode": 24.0, "batch_reward": 0.2592454251796007, "actor_loss": -66.40472113800048, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 442.4940550327301, "episode_reward": 160.1653421324451, "step": 24000}
{"episode": 25.0, "batch_reward": 0.2583266501277685, "actor_loss": -66.66746363067627, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.282161712646484, "episode_reward": 412.4628844396379, "step": 25000}
{"episode": 26.0, "batch_reward": 0.25933147171139714, "actor_loss": -65.94625921630859, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 424.58267426490784, "episode_reward": 85.66537258268333, "step": 26000}
{"episode": 27.0, "batch_reward": 0.2567854428738356, "actor_loss": -65.97629096221924, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.87192440032959, "episode_reward": 192.24549146512373, "step": 27000}
{"episode": 28.0, "batch_reward": 0.251351055637002, "actor_loss": -67.89988806152344, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 433.63124346733093, "episode_reward": 181.5542556218823, "step": 28000}
{"episode": 29.0, "batch_reward": 0.25323442643880845, "actor_loss": -68.37074604797364, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.623558521270752, "episode_reward": 344.1755060240881, "step": 29000}
{"episode": 30.0, "batch_reward": 0.2586386385262012, "actor_loss": -69.10888423156739, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 427.7258896827698, "episode_reward": 495.06937592083233, "step": 30000}
{"episode": 31.0, "batch_reward": 0.2613955207169056, "actor_loss": -69.30912794494628, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 36.967841148376465, "episode_reward": 139.76433938340446, "step": 31000}
{"episode": 32.0, "batch_reward": 0.2573167111724615, "actor_loss": -68.70914001464844, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 432.5326917171478, "episode_reward": 182.23667904638438, "step": 32000}
{"episode": 33.0, "batch_reward": 0.25645116589963435, "actor_loss": -68.75371392822265, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.23663854598999, "episode_reward": 276.91241832423015, "step": 33000}
{"episode": 34.0, "batch_reward": 0.26064275527000424, "actor_loss": -69.32731132507324, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 440.4304759502411, "episode_reward": 328.40892836884353, "step": 34000}
{"episode": 35.0, "batch_reward": 0.2575593631565571, "actor_loss": -69.10031243896485, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.91935706138611, "episode_reward": 207.3758984836157, "step": 35000}
{"episode": 36.0, "batch_reward": 0.2573873202353716, "actor_loss": -70.41963833618163, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 421.2675006389618, "episode_reward": 335.63618714387496, "step": 36000}
{"episode": 37.0, "batch_reward": 0.2642237073332071, "actor_loss": -70.65269686889648, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.560890197753906, "episode_reward": 575.8840904646971, "step": 37000}
{"episode": 38.0, "batch_reward": 0.26981598751246927, "actor_loss": -70.63999909973144, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 431.3290033340454, "episode_reward": 476.5660585727578, "step": 38000}
{"episode": 39.0, "batch_reward": 0.2741010930985212, "actor_loss": -70.831465133667, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.99731159210205, "episode_reward": 388.16176761488435, "step": 39000}
{"episode": 40.0, "batch_reward": 0.2738339156359434, "actor_loss": -70.4391671447754, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 424.81670665740967, "episode_reward": 109.52900992763848, "step": 40000}
{"episode": 41.0, "batch_reward": 0.2733256323039532, "actor_loss": -70.44701989746093, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 40.9432110786438, "episode_reward": 498.94501433042456, "step": 41000}
{"episode": 42.0, "batch_reward": 0.2792715980112553, "actor_loss": -70.10038175964355, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 451.74861192703247, "episode_reward": 368.34192884971014, "step": 42000}
{"episode": 43.0, "batch_reward": 0.2832278715372086, "actor_loss": -70.4059782409668, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.82349705696106, "episode_reward": 614.945311111415, "step": 43000}
{"episode": 44.0, "batch_reward": 0.29048537872731683, "actor_loss": -70.62385522460937, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 458.73416328430176, "episode_reward": 518.3843383708755, "step": 44000}
{"episode": 45.0, "batch_reward": 0.2954909971654415, "actor_loss": -70.90909259033204, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.36080574989319, "episode_reward": 542.3080079320783, "step": 45000}
{"episode": 46.0, "batch_reward": 0.29999635739624503, "actor_loss": -71.44526220703125, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 462.54102897644043, "episode_reward": 446.38563243742203, "step": 46000}
{"episode": 47.0, "batch_reward": 0.30386178773641587, "actor_loss": -71.49945486450196, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.298534631729126, "episode_reward": 534.4386912442691, "step": 47000}
{"episode": 48.0, "batch_reward": 0.3084736007750034, "actor_loss": -70.26565214538574, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 460.01155185699463, "episode_reward": 565.3063720538662, "step": 48000}
{"episode": 49.0, "batch_reward": 0.3135322827845812, "actor_loss": -70.37678692626953, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.093506813049316, "episode_reward": 496.12263111616085, "step": 49000}
{"episode": 50.0, "batch_reward": 0.31912393563985825, "actor_loss": -69.62398786926269, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 456.89798617362976, "episode_reward": 660.2457410869504, "step": 50000}
{"episode": 51.0, "batch_reward": 0.32359560254216196, "actor_loss": -69.78521426391602, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.01797604560852, "episode_reward": 494.1009351591396, "step": 51000}
{"episode": 52.0, "batch_reward": 0.32823726305365564, "actor_loss": -68.97753324890137, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 464.8611900806427, "episode_reward": 630.7429216564623, "step": 52000}
{"episode": 53.0, "batch_reward": 0.3348606986403465, "actor_loss": -69.36205197143555, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.09265637397766, "episode_reward": 690.0671856198891, "step": 53000}
{"episode": 54.0, "batch_reward": 0.33969248372316363, "actor_loss": -70.36270606994628, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 461.671245098114, "episode_reward": 618.6494513500296, "step": 54000}
{"episode": 55.0, "batch_reward": 0.34672647780179977, "actor_loss": -70.67027166748046, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.906731605529785, "episode_reward": 605.8636781982913, "step": 55000}
{"episode": 56.0, "batch_reward": 0.34997682574391364, "actor_loss": -72.14728927612305, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 459.7408242225647, "episode_reward": 522.7304962300435, "step": 56000}
{"episode": 57.0, "batch_reward": 0.3537585908174515, "actor_loss": -72.29980163574218, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.792470932006836, "episode_reward": 628.2471209112967, "step": 57000}
{"episode": 58.0, "batch_reward": 0.3570499119460583, "actor_loss": -73.46913362121582, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 461.2319452762604, "episode_reward": 540.4621530956682, "step": 58000}
{"episode": 59.0, "batch_reward": 0.361038311123848, "actor_loss": -73.62390965270995, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.266153573989868, "episode_reward": 490.8831258188382, "step": 59000}
{"episode": 60.0, "batch_reward": 0.3642357615530491, "actor_loss": -73.41640280151367, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 468.48588705062866, "episode_reward": 503.16670936132857, "step": 60000}
{"episode": 61.0, "batch_reward": 0.3623926093876362, "actor_loss": -73.36321987915039, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 39.831597566604614, "episode_reward": 101.75326662361216, "step": 61000}
{"episode": 62.0, "batch_reward": 0.36181999707221985, "actor_loss": -73.3630694885254, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 465.4349868297577, "episode_reward": 547.8809642297757, "step": 62000}
{"episode": 63.0, "batch_reward": 0.3619235149025917, "actor_loss": -73.32523013305664, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.919349193572998, "episode_reward": 168.03084525841618, "step": 63000}
{"episode": 64.0, "batch_reward": 0.35986408138275144, "actor_loss": -72.83813024902344, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 460.6273856163025, "episode_reward": 287.2032921631109, "step": 64000}
{"episode": 65.0, "batch_reward": 0.3614969339668751, "actor_loss": -73.06426205444336, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.65124249458313, "episode_reward": 574.4715577162083, "step": 65000}
{"episode": 66.0, "batch_reward": 0.3635514748990536, "actor_loss": -73.55144348144532, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 462.95368003845215, "episode_reward": 361.3714442173835, "step": 66000}
{"episode": 67.0, "batch_reward": 0.36449459654092786, "actor_loss": -73.59799627685547, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.434536933898926, "episode_reward": 424.25781597891944, "step": 67000}
{"episode": 68.0, "batch_reward": 0.3655005969107151, "actor_loss": -73.88560272216797, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 467.74815702438354, "episode_reward": 597.609338418044, "step": 68000}
{"episode": 69.0, "batch_reward": 0.3647379938364029, "actor_loss": -73.89156915283203, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.665465831756592, "episode_reward": 238.04451971213143, "step": 69000}
{"episode": 70.0, "batch_reward": 0.36526324653625486, "actor_loss": -73.22520812988282, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 464.84332394599915, "episode_reward": 257.32802337278474, "step": 70000}
{"episode": 71.0, "batch_reward": 0.3644844135940075, "actor_loss": -73.1883098602295, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.43511199951172, "episode_reward": 312.73959172028754, "step": 71000}
{"episode": 72.0, "batch_reward": 0.36170861971378326, "actor_loss": -73.46265692138672, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 456.06861996650696, "episode_reward": 260.7222522787689, "step": 72000}
{"episode": 73.0, "batch_reward": 0.3603650490641594, "actor_loss": -73.49041329956054, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.751936674118042, "episode_reward": 183.62176646386484, "step": 73000}
{"episode": 74.0, "batch_reward": 0.35902629235386846, "actor_loss": -73.2900711517334, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 461.0085697174072, "episode_reward": 394.38230377148244, "step": 74000}
{"episode": 75.0, "batch_reward": 0.3594802807569504, "actor_loss": -73.40134173583985, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.9931001663208, "episode_reward": 537.2487797775646, "step": 75000}
{"episode": 76.0, "batch_reward": 0.36336619210243226, "actor_loss": -73.26671142578125, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 468.76529240608215, "episode_reward": 533.517305521042, "step": 76000}
{"episode": 77.0, "batch_reward": 0.3660389327406883, "actor_loss": -73.22934620666504, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.78523087501526, "episode_reward": 576.4288535038663, "step": 77000}
{"episode": 78.0, "batch_reward": 0.3678316387534142, "actor_loss": -72.99781106567383, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 434.1265399456024, "episode_reward": 541.0814634506759, "step": 78000}
{"episode": 79.0, "batch_reward": 0.36910079169273374, "actor_loss": -73.06230838012695, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.9757661819458, "episode_reward": 456.69934102318035, "step": 79000}
{"episode": 80.0, "batch_reward": 0.3738186675310135, "actor_loss": -73.45476119995118, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 442.64089179039, "episode_reward": 622.4330534267182, "step": 80000}
{"episode": 81.0, "batch_reward": 0.3723546026349068, "actor_loss": -73.42252424621581, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 45.02089881896973, "episode_reward": 572.9635983974484, "step": 81000}
{"episode": 82.0, "batch_reward": 0.3756289027929306, "actor_loss": -73.69312742614746, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 465.76266074180603, "episode_reward": 627.8752324047856, "step": 82000}
{"episode": 83.0, "batch_reward": 0.38004342368245125, "actor_loss": -73.88424172973633, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.154996871948242, "episode_reward": 661.0036142755263, "step": 83000}
{"episode": 84.0, "batch_reward": 0.3827829339802265, "actor_loss": -73.42483433532715, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 467.07565927505493, "episode_reward": 660.5312218391269, "step": 84000}
{"episode": 85.0, "batch_reward": 0.3872790103852749, "actor_loss": -73.53237658691407, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.42252230644226, "episode_reward": 619.5697788643757, "step": 85000}
{"episode": 86.0, "batch_reward": 0.3888085546195507, "actor_loss": -73.84441487121582, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 461.20686531066895, "episode_reward": 601.3235303082223, "step": 86000}
{"episode": 87.0, "batch_reward": 0.3911580593287945, "actor_loss": -74.03973844909667, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.80058526992798, "episode_reward": 630.8574664300589, "step": 87000}
{"episode": 88.0, "batch_reward": 0.39563384851813316, "actor_loss": -73.93911042785645, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 463.0024678707123, "episode_reward": 705.1597643595617, "step": 88000}
{"episode": 89.0, "batch_reward": 0.39800738281011583, "actor_loss": -74.09853889465332, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.336763620376587, "episode_reward": 759.3544971605286, "step": 89000}
{"episode": 90.0, "batch_reward": 0.40031076008081434, "actor_loss": -74.42503625488281, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 459.3072645664215, "episode_reward": 300.10750206026927, "step": 90000}
{"episode": 91.0, "batch_reward": 0.40011032617092135, "actor_loss": -74.44679624938965, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 36.106752157211304, "episode_reward": 670.4234983059465, "step": 91000}
{"episode": 92.0, "batch_reward": 0.4030588525533676, "actor_loss": -74.04574780273437, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 420.2690055370331, "episode_reward": 680.1706316715952, "step": 92000}
{"episode": 93.0, "batch_reward": 0.4074971700012684, "actor_loss": -74.14784747314454, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.47469401359558, "episode_reward": 726.2346075109724, "step": 93000}
{"episode": 94.0, "batch_reward": 0.4108566944599152, "actor_loss": -73.43275230407716, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 423.09928703308105, "episode_reward": 646.5402601485617, "step": 94000}
{"episode": 95.0, "batch_reward": 0.4120172882974148, "actor_loss": -73.34827186584472, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.934282779693604, "episode_reward": 696.8545599808523, "step": 95000}
{"episode": 96.0, "batch_reward": 0.4157329523265362, "actor_loss": -74.789728225708, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 432.2353458404541, "episode_reward": 706.9379957005526, "step": 96000}
{"episode": 97.0, "batch_reward": 0.41753362768888475, "actor_loss": -74.878697265625, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.71163034439087, "episode_reward": 593.2114276615727, "step": 97000}
{"episode": 98.0, "batch_reward": 0.4210183416903019, "actor_loss": -75.33377786254883, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 423.28852939605713, "episode_reward": 600.516665013092, "step": 98000}
{"episode": 99.0, "batch_reward": 0.4193985538184643, "actor_loss": -75.22155242919922, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.95659828186035, "episode_reward": 134.12872163502823, "step": 99000}
{"episode": 100.0, "batch_reward": 0.42095082607865336, "actor_loss": -75.68365928649902, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 432.17663168907166, "episode_reward": 683.9519585556642, "step": 100000}
{"episode": 101.0, "batch_reward": 0.42146969550848007, "actor_loss": -75.71400798034668, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 35.350770235061646, "episode_reward": 664.0634241102891, "step": 101000}
{"episode": 102.0, "batch_reward": 0.4232415698468685, "actor_loss": -76.10778799438476, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 434.41377425193787, "episode_reward": 609.7016241660687, "step": 102000}
{"episode": 103.0, "batch_reward": 0.42619909399747846, "actor_loss": -76.17635815429688, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.887463808059692, "episode_reward": 731.6064424240164, "step": 103000}
{"episode": 104.0, "batch_reward": 0.4306127733886242, "actor_loss": -75.93993794250488, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 418.767431974411, "episode_reward": 609.4420840643628, "step": 104000}
{"episode": 105.0, "batch_reward": 0.42977711829543114, "actor_loss": -75.89434341430665, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.829232692718506, "episode_reward": 378.5574447260091, "step": 105000}
{"episode": 106.0, "batch_reward": 0.43114506688714027, "actor_loss": -75.15730918884277, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 439.764080286026, "episode_reward": 424.5501418500118, "step": 106000}
{"episode": 107.0, "batch_reward": 0.430929479598999, "actor_loss": -75.21889385986329, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.396075963974, "episode_reward": 640.7327624401112, "step": 107000}
{"episode": 108.0, "batch_reward": 0.43220985516905785, "actor_loss": -75.10451332092285, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 423.858775138855, "episode_reward": 616.2501031013559, "step": 108000}
{"episode": 109.0, "batch_reward": 0.43395447847247126, "actor_loss": -75.24238940429687, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.95278525352478, "episode_reward": 660.8647559479286, "step": 109000}
{"episode": 110.0, "batch_reward": 0.43566386768221854, "actor_loss": -74.96865907287598, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 428.695148229599, "episode_reward": 711.3443376505234, "step": 110000}
{"episode": 111.0, "batch_reward": 0.4388350690603256, "actor_loss": -75.06959788513184, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 35.174779176712036, "episode_reward": 601.3978675661814, "step": 111000}
{"episode": 112.0, "batch_reward": 0.4413928524851799, "actor_loss": -75.23512448120117, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 427.9627637863159, "episode_reward": 680.2841612539494, "step": 112000}
{"episode": 113.0, "batch_reward": 0.4417500839531422, "actor_loss": -75.33671942138672, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.85665535926819, "episode_reward": 665.7056511215573, "step": 113000}
{"episode": 114.0, "batch_reward": 0.4439587604701519, "actor_loss": -75.18504949951172, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 424.62928915023804, "episode_reward": 638.4109477822215, "step": 114000}
{"episode": 115.0, "batch_reward": 0.4458296879529953, "actor_loss": -75.22513732910156, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.298173904418945, "episode_reward": 688.5606553848097, "step": 115000}
{"episode": 116.0, "batch_reward": 0.44581480300426485, "actor_loss": -75.6021074371338, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 426.91582918167114, "episode_reward": 624.8567419723785, "step": 116000}
{"episode": 117.0, "batch_reward": 0.4493621734380722, "actor_loss": -75.7576110534668, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.58943796157837, "episode_reward": 639.1495515309056, "step": 117000}
{"episode": 118.0, "batch_reward": 0.45051298984885213, "actor_loss": -75.22517678833007, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 450.44181966781616, "episode_reward": 624.1948011056061, "step": 118000}
{"episode": 119.0, "batch_reward": 0.4538526250720024, "actor_loss": -75.44636593627929, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.83160638809204, "episode_reward": 686.7395129367465, "step": 119000}
{"episode": 120.0, "batch_reward": 0.45408479699492454, "actor_loss": -75.94569158935546, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 464.8581762313843, "episode_reward": 771.1806917633188, "step": 120000}
{"episode": 121.0, "batch_reward": 0.4554468902349472, "actor_loss": -75.94283142089844, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 37.307117223739624, "episode_reward": 592.0657621724046, "step": 121000}
{"episode": 122.0, "batch_reward": 0.45757322472333906, "actor_loss": -75.91451499938965, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 465.50512075424194, "episode_reward": 595.6022449814669, "step": 122000}
{"episode": 123.0, "batch_reward": 0.45838773700594904, "actor_loss": -76.00148165893555, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.549670934677124, "episode_reward": 655.1323559494728, "step": 123000}
{"episode": 124.0, "batch_reward": 0.4603755237162113, "actor_loss": -75.98617127990723, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 464.3747510910034, "episode_reward": 722.3704587769103, "step": 124000}
{"episode": 125.0, "batch_reward": 0.4640315111875534, "actor_loss": -76.07278704833985, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.52338457107544, "episode_reward": 670.9211278823863, "step": 125000}
{"episode": 126.0, "batch_reward": 0.46657215943932534, "actor_loss": -76.26366004943847, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 465.2493109703064, "episode_reward": 659.8562990371958, "step": 126000}
{"episode": 127.0, "batch_reward": 0.4655452465713024, "actor_loss": -76.2633282623291, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.685251474380493, "episode_reward": 691.0824579349805, "step": 127000}
{"episode": 128.0, "batch_reward": 0.46758269095420835, "actor_loss": -75.50256349182129, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 466.4966163635254, "episode_reward": 722.7926335263649, "step": 128000}
{"episode": 129.0, "batch_reward": 0.4713728013932705, "actor_loss": -75.68565063476562, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.896881341934204, "episode_reward": 525.3741792600764, "step": 129000}
{"episode": 130.0, "batch_reward": 0.4717796421945095, "actor_loss": -76.54913374328613, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 473.296932220459, "episode_reward": 745.9679952353779, "step": 130000}
{"episode": 131.0, "batch_reward": 0.4738333986401558, "actor_loss": -76.66203091430664, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 39.0846061706543, "episode_reward": 635.2389698743182, "step": 131000}
{"episode": 132.0, "batch_reward": 0.4739354439675808, "actor_loss": -76.4040366973877, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 466.2472848892212, "episode_reward": 698.6550534791959, "step": 132000}
{"episode": 133.0, "batch_reward": 0.4761009555757046, "actor_loss": -76.45252676391601, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.598917245864868, "episode_reward": 418.0491499019259, "step": 133000}
{"episode": 134.0, "batch_reward": 0.47494124311208724, "actor_loss": -77.1908755645752, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 468.4855980873108, "episode_reward": 633.0138015673169, "step": 134000}
{"episode": 135.0, "batch_reward": 0.4770376317203045, "actor_loss": -77.2743809967041, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.895681142807007, "episode_reward": 690.7946359850877, "step": 135000}
{"episode": 136.0, "batch_reward": 0.47799225026369097, "actor_loss": -77.66855253601074, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 463.7850923538208, "episode_reward": 447.4493508511802, "step": 136000}
{"episode": 137.0, "batch_reward": 0.4787917674779892, "actor_loss": -77.68712471008301, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.5411856174469, "episode_reward": 730.8141808198541, "step": 137000}
{"episode": 138.0, "batch_reward": 0.4788008863925934, "actor_loss": -76.82455769348145, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 474.49988532066345, "episode_reward": 760.5241276953349, "step": 138000}
{"episode": 139.0, "batch_reward": 0.4822206798195839, "actor_loss": -76.97960012817383, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 16.443622589111328, "episode_reward": 793.0424105391701, "step": 139000}
{"episode": 140.0, "batch_reward": 0.48511861214041707, "actor_loss": -77.47886883544922, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 476.0857810974121, "episode_reward": 594.3002478307525, "step": 140000}
{"episode": 141.0, "batch_reward": 0.48581875067949293, "actor_loss": -77.56790673828125, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.866806507110596, "episode_reward": 762.8952661645009, "step": 141000}
{"episode": 142.0, "batch_reward": 0.4863222045302391, "actor_loss": -77.10852070617676, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 472.67232275009155, "episode_reward": 752.3744134595551, "step": 142000}
{"episode": 143.0, "batch_reward": 0.48841929545998575, "actor_loss": -77.18581449890137, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 17.568131685256958, "episode_reward": 714.8639038458166, "step": 143000}
{"episode": 144.0, "batch_reward": 0.49099819123744964, "actor_loss": -77.98231593322754, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 475.21512246131897, "episode_reward": 809.1713738174002, "step": 144000}
{"episode": 145.0, "batch_reward": 0.4921730336844921, "actor_loss": -77.97615394592285, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.17725968360901, "episode_reward": 637.0239778492868, "step": 145000}
{"episode": 146.0, "batch_reward": 0.4929364285171032, "actor_loss": -77.7227600402832, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 475.7276964187622, "episode_reward": 714.1987473137812, "step": 146000}
{"episode": 147.0, "batch_reward": 0.4968074307739735, "actor_loss": -77.90357092285156, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 18.45134925842285, "episode_reward": 698.7527339648166, "step": 147000}
{"episode": 148.0, "batch_reward": 0.4948704113960266, "actor_loss": -77.63631451416016, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 481.4766845703125, "episode_reward": 727.6951538019705, "step": 148000}
{"episode": 149.0, "batch_reward": 0.49755539470911025, "actor_loss": -77.83545223999023, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 19.535501718521118, "episode_reward": 665.4351402985131, "step": 149000}
{"episode": 150.0, "batch_reward": 0.4983176083266735, "actor_loss": -78.21801419067383, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "step": 150000}
