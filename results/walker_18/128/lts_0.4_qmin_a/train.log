{"episode_reward": 0.0, "episode": 1.0, "duration": 21.359459161758423, "step": 1000}
{"episode_reward": 27.46298806610516, "episode": 2.0, "duration": 1.914407730102539, "step": 2000}
{"episode_reward": 489.1100087318934, "episode": 3.0, "batch_reward": 0.24279895607691362, "critic_loss": 0.14395475707061292, "actor_loss": -35.25414915801491, "actor_target_entropy": -6.0, "alpha_value": 0.002134017781850189, "duration": 63.83583736419678, "step": 3000}
{"episode_reward": 9.680840442001658, "episode": 4.0, "batch_reward": 0.16623976928740739, "critic_loss": 0.5553878097981214, "actor_loss": -38.51705405426026, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.407405376434326, "step": 4000}
{"episode_reward": 118.4469697856657, "episode": 5.0, "batch_reward": 0.16209019458293913, "critic_loss": 0.8626093136370182, "actor_loss": -39.81113114738464, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.856224536895752, "step": 5000}
{"episode_reward": 197.14582334537073, "episode": 6.0, "batch_reward": 0.16720253366976975, "critic_loss": 1.0087518178522588, "actor_loss": -41.480472034454344, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.51323366165161, "step": 6000}
{"episode_reward": 123.7010206087775, "episode": 7.0, "batch_reward": 0.15534463848173619, "critic_loss": 0.8630916912853718, "actor_loss": -40.82571904945374, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.90642786026001, "step": 7000}
{"episode_reward": 84.06324754647339, "episode": 8.0, "batch_reward": 0.14349492131918667, "critic_loss": 0.6701856283843517, "actor_loss": -44.33525284194946, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.957597494125366, "step": 8000}
{"episode_reward": 55.58345862410002, "episode": 9.0, "batch_reward": 0.13979982339590788, "critic_loss": 0.6428662575185299, "actor_loss": -43.42297094345093, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.96321392059326, "step": 9000}
{"episode_reward": 100.75854803727604, "episode": 10.0, "batch_reward": 0.1348450468033552, "critic_loss": 0.610270331710577, "actor_loss": -44.51049759292602, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.624730348587036, "step": 10000}
{"episode_reward": 111.4408724678967, "episode": 11.0, "batch_reward": 0.13063377814739943, "critic_loss": 0.6391504736244679, "actor_loss": -43.25345417404175, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.346577882766724, "step": 11000}
{"episode_reward": 208.15492072639927, "episode": 12.0, "batch_reward": 0.141025133959949, "critic_loss": 0.7335304019451141, "actor_loss": -44.985185832977294, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.514575481414795, "step": 12000}
{"episode_reward": 223.4633529727435, "episode": 13.0, "batch_reward": 0.1533966138586402, "critic_loss": 0.6988789344131947, "actor_loss": -44.72455335617065, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.666956186294556, "step": 13000}
{"episode_reward": 348.96893663063975, "episode": 14.0, "batch_reward": 0.15929903510212898, "critic_loss": 0.7191917540878058, "actor_loss": -46.90123690795898, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.228216648101807, "step": 14000}
{"episode_reward": 82.04207683265626, "episode": 15.0, "batch_reward": 0.15378771278262138, "critic_loss": 0.6689929508566856, "actor_loss": -44.850109577178955, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.536717414855957, "step": 15000}
{"episode_reward": 74.52716414822262, "episode": 16.0, "batch_reward": 0.14811604664474726, "critic_loss": 0.7099347604811191, "actor_loss": -44.8507865486145, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.440109491348267, "step": 16000}
{"episode_reward": 63.570671809454865, "episode": 17.0, "batch_reward": 0.14284382018446923, "critic_loss": 0.8359804846346378, "actor_loss": -45.79108197402954, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.757028579711914, "step": 17000}
{"episode_reward": 77.36948561184788, "episode": 18.0, "batch_reward": 0.1471537140086293, "critic_loss": 1.0442728270590305, "actor_loss": -47.8319786567688, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.922175407409668, "step": 18000}
{"episode_reward": 382.5150025966486, "episode": 19.0, "batch_reward": 0.1556851494535804, "critic_loss": 1.1225328524708749, "actor_loss": -46.440788135528564, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.51837944984436, "step": 19000}
{"episode_reward": 237.1513583045761, "episode": 20.0, "batch_reward": 0.16175417441129686, "critic_loss": 1.1351941587924956, "actor_loss": -47.53264262390137, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.976407527923584, "step": 20000}
{"episode_reward": 329.210617815096, "episode": 21.0, "batch_reward": 0.17079952888190747, "critic_loss": 1.1041658934950829, "actor_loss": -47.66789342880249, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 40.98377537727356, "step": 21000}
{"episode_reward": 234.30626763460089, "episode": 22.0, "batch_reward": 0.17698628033697605, "critic_loss": 1.130667720735073, "actor_loss": -48.3065710067749, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.50105881690979, "step": 22000}
{"episode_reward": 517.7953503074083, "episode": 23.0, "batch_reward": 0.18942611476778984, "critic_loss": 1.074108998835087, "actor_loss": -47.67108574295044, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.855659008026123, "step": 23000}
{"episode_reward": 362.3766077792921, "episode": 24.0, "batch_reward": 0.19986310264468193, "critic_loss": 1.0688378561735152, "actor_loss": -46.74920654296875, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.570047855377197, "step": 24000}
{"episode_reward": 518.8598939818953, "episode": 25.0, "batch_reward": 0.21103493039309978, "critic_loss": 1.0406222651600838, "actor_loss": -49.852943489074704, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.6507465839386, "step": 25000}
{"episode_reward": 356.96235580759486, "episode": 26.0, "batch_reward": 0.2156067251265049, "critic_loss": 0.9849071017801762, "actor_loss": -48.60203380584717, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.77100896835327, "step": 26000}
{"episode_reward": 183.2550081408623, "episode": 27.0, "batch_reward": 0.21805740489065648, "critic_loss": 0.9751673259437085, "actor_loss": -48.39971451187134, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.515740871429443, "step": 27000}
{"episode_reward": 549.2598860503459, "episode": 28.0, "batch_reward": 0.22243438448011876, "critic_loss": 0.9918860166668891, "actor_loss": -50.44324628067017, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.81409192085266, "step": 28000}
{"episode_reward": 178.8867856841279, "episode": 29.0, "batch_reward": 0.22409974893927573, "critic_loss": 1.0499325415492058, "actor_loss": -49.502507453918454, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.80305027961731, "step": 29000}
{"episode_reward": 227.81511223162957, "episode": 30.0, "batch_reward": 0.2284789125174284, "critic_loss": 1.0557920781672, "actor_loss": -49.829508865356445, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.764282941818237, "step": 30000}
{"episode_reward": 414.29444346091685, "episode": 31.0, "batch_reward": 0.2308864403963089, "critic_loss": 1.132752026319504, "actor_loss": -52.96156177902222, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.436387062072754, "step": 31000}
{"episode_reward": 321.2461055010405, "episode": 32.0, "batch_reward": 0.23607012832164764, "critic_loss": 1.1896750431656837, "actor_loss": -50.97592415618897, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.84533143043518, "step": 32000}
{"episode_reward": 402.3607984163468, "episode": 33.0, "batch_reward": 0.24238409312069417, "critic_loss": 1.2496456300020218, "actor_loss": -51.53379846572876, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.787039279937744, "step": 33000}
{"episode_reward": 558.1986665753369, "episode": 34.0, "batch_reward": 0.25135953682661055, "critic_loss": 1.3008633589148522, "actor_loss": -53.059189220428465, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.75317120552063, "step": 34000}
{"episode_reward": 608.7334298178915, "episode": 35.0, "batch_reward": 0.26111991569399834, "critic_loss": 1.323139976978302, "actor_loss": -52.52192468261719, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.46686625480652, "step": 35000}
{"episode_reward": 506.39458198765556, "episode": 36.0, "batch_reward": 0.26514949651062486, "critic_loss": 1.3713064715862273, "actor_loss": -54.224023906707764, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.5123507976532, "step": 36000}
{"episode_reward": 389.7671691291274, "episode": 37.0, "batch_reward": 0.27463470855355265, "critic_loss": 1.3630603041052818, "actor_loss": -53.765039344787596, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.947400331497192, "step": 37000}
{"episode_reward": 650.248399130294, "episode": 38.0, "batch_reward": 0.28208319583535196, "critic_loss": 1.3019189224243164, "actor_loss": -54.23538072967529, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.229564666748047, "step": 38000}
{"episode_reward": 559.0496866899532, "episode": 39.0, "batch_reward": 0.2910008402764797, "critic_loss": 1.2361488478183746, "actor_loss": -55.363905250549315, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.50725769996643, "step": 39000}
{"episode_reward": 649.519584360494, "episode": 40.0, "batch_reward": 0.2978759024888277, "critic_loss": 1.3047169127464295, "actor_loss": -57.44393395996094, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.997695684432983, "step": 40000}
{"episode_reward": 499.337320641505, "episode": 41.0, "batch_reward": 0.3031693477332592, "critic_loss": 1.3401103336811067, "actor_loss": -56.5266088180542, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.20770502090454, "step": 41000}
{"episode_reward": 591.1413100662534, "episode": 42.0, "batch_reward": 0.3107337384670973, "critic_loss": 1.3867816832065583, "actor_loss": -57.04079596710205, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.789482831954956, "step": 42000}
{"episode_reward": 588.6413286646242, "episode": 43.0, "batch_reward": 0.31715781159698964, "critic_loss": 1.413463441312313, "actor_loss": -57.72445537567139, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.77445077896118, "step": 43000}
{"episode_reward": 630.440495799798, "episode": 44.0, "batch_reward": 0.32678805984556675, "critic_loss": 1.522534193634987, "actor_loss": -57.30915326690674, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.52176332473755, "step": 44000}
{"episode_reward": 730.928600342969, "episode": 45.0, "batch_reward": 0.33339381487667563, "critic_loss": 1.4745526247024536, "actor_loss": -56.30646153259277, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.604840517044067, "step": 45000}
{"episode_reward": 566.11739115799, "episode": 46.0, "batch_reward": 0.3409826350957155, "critic_loss": 1.4893923013210297, "actor_loss": -56.46003569793701, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.98883557319641, "step": 46000}
{"episode_reward": 677.5338998619666, "episode": 47.0, "batch_reward": 0.34714415180683134, "critic_loss": 1.489295224070549, "actor_loss": -59.35466905975342, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.70572066307068, "step": 47000}
{"episode_reward": 721.2679912432563, "episode": 48.0, "batch_reward": 0.35032210206985476, "critic_loss": 1.5306892240047454, "actor_loss": -58.739198822021486, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.35365605354309, "step": 48000}
{"episode_reward": 169.55029480886648, "episode": 49.0, "batch_reward": 0.3487370820939541, "critic_loss": 1.506268329322338, "actor_loss": -59.55673230743408, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.804075717926025, "step": 49000}
{"episode_reward": 242.89511141926428, "episode": 50.0, "batch_reward": 0.34949656495451925, "critic_loss": 1.506002914607525, "actor_loss": -59.38456708526611, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.683324575424194, "step": 50000}
{"episode_reward": 611.9238336938542, "episode": 51.0, "batch_reward": 0.3533817201256752, "critic_loss": 1.5026267946958543, "actor_loss": -59.70424375152588, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.204296588897705, "step": 51000}
{"episode_reward": 641.3999685613472, "episode": 52.0, "batch_reward": 0.360817517966032, "critic_loss": 1.5551888937354088, "actor_loss": -59.60302174377441, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.67212963104248, "step": 52000}
{"episode_reward": 742.4763406571009, "episode": 53.0, "batch_reward": 0.36781582713127137, "critic_loss": 1.5212023566365243, "actor_loss": -61.75312341308594, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.503973960876465, "step": 53000}
{"episode_reward": 739.9889134156774, "episode": 54.0, "batch_reward": 0.3688361240327358, "critic_loss": 1.5701022719144822, "actor_loss": -61.32044472503662, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.732866764068604, "step": 54000}
{"episode_reward": 294.67626671182256, "episode": 55.0, "batch_reward": 0.37502546787261964, "critic_loss": 1.586421830713749, "actor_loss": -61.84257989501953, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.413434743881226, "step": 55000}
{"episode_reward": 790.8934037514412, "episode": 56.0, "batch_reward": 0.3794201040863991, "critic_loss": 1.6307537077665328, "actor_loss": -62.75495919036865, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.49311876296997, "step": 56000}
{"episode_reward": 465.26267179584613, "episode": 57.0, "batch_reward": 0.3818874563276768, "critic_loss": 1.6518989631533623, "actor_loss": -62.5021357345581, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.776926517486572, "step": 57000}
{"episode_reward": 764.8854345311412, "episode": 58.0, "batch_reward": 0.38721352416276933, "critic_loss": 1.5733659622073173, "actor_loss": -63.65601871490478, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.358596086502075, "step": 58000}
{"episode_reward": 690.6143819520829, "episode": 59.0, "batch_reward": 0.39434441247582436, "critic_loss": 1.6605718142986297, "actor_loss": -63.94239965057373, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.503185749053955, "step": 59000}
{"episode_reward": 706.6080130675646, "episode": 60.0, "batch_reward": 0.39842778995633127, "critic_loss": 1.7445108817219734, "actor_loss": -63.09961024475098, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.523762702941895, "step": 60000}
{"episode_reward": 692.8208495141834, "episode": 61.0, "batch_reward": 0.40162634029984473, "critic_loss": 1.8046121539473534, "actor_loss": -64.11834117889404, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.11594009399414, "step": 61000}
{"episode_reward": 644.4181390325524, "episode": 62.0, "batch_reward": 0.407145597666502, "critic_loss": 1.8900943200588227, "actor_loss": -63.06819229125976, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.560404062271118, "step": 62000}
{"episode_reward": 824.0173452001325, "episode": 63.0, "batch_reward": 0.41583997905254366, "critic_loss": 1.9050078300833702, "actor_loss": -64.65175563049317, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.369786500930786, "step": 63000}
{"episode_reward": 809.0679633886285, "episode": 64.0, "batch_reward": 0.4201329452395439, "critic_loss": 1.8732399539351463, "actor_loss": -66.66227634429931, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.533398389816284, "step": 64000}
{"episode_reward": 824.716323409137, "episode": 65.0, "batch_reward": 0.42516519606113434, "critic_loss": 1.9476177545785904, "actor_loss": -65.5394800491333, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.750545263290405, "step": 65000}
{"episode_reward": 807.7441325956968, "episode": 66.0, "batch_reward": 0.4351569886803627, "critic_loss": 1.9465941251516343, "actor_loss": -66.85850852966308, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.384536743164062, "step": 66000}
{"episode_reward": 865.024564278144, "episode": 67.0, "batch_reward": 0.44117403054237364, "critic_loss": 1.9719368666410446, "actor_loss": -67.0907536315918, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.53939938545227, "step": 67000}
{"episode_reward": 830.1584099139753, "episode": 68.0, "batch_reward": 0.4464027186632156, "critic_loss": 1.9111312968730927, "actor_loss": -69.16997175598145, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.671275854110718, "step": 68000}
{"episode_reward": 819.5501929089035, "episode": 69.0, "batch_reward": 0.4522602392733097, "critic_loss": 1.9592736731767655, "actor_loss": -68.33286334991455, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.299098014831543, "step": 69000}
{"episode_reward": 770.6690087947569, "episode": 70.0, "batch_reward": 0.4569560528099537, "critic_loss": 1.930794071793556, "actor_loss": -68.46886970520019, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.53430461883545, "step": 70000}
{"episode_reward": 787.2695842590376, "episode": 71.0, "batch_reward": 0.4621449557244778, "critic_loss": 1.8241642153263091, "actor_loss": -68.87916397094726, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.38529419898987, "step": 71000}
{"episode_reward": 794.6969607579765, "episode": 72.0, "batch_reward": 0.46336979961395264, "critic_loss": 1.748339414536953, "actor_loss": -69.64917122650147, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.560730934143066, "step": 72000}
{"episode_reward": 773.1609115969576, "episode": 73.0, "batch_reward": 0.47033431378006935, "critic_loss": 1.7199049287438393, "actor_loss": -70.41836880493165, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.94547939300537, "step": 73000}
{"episode_reward": 833.0719692517251, "episode": 74.0, "batch_reward": 0.47332054418325425, "critic_loss": 1.750254272222519, "actor_loss": -70.68721415710449, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.950627088546753, "step": 74000}
{"episode_reward": 844.5060231600812, "episode": 75.0, "batch_reward": 0.48023687517642977, "critic_loss": 1.766246198952198, "actor_loss": -71.8384363937378, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.6303129196167, "step": 75000}
{"episode_reward": 828.0691377054117, "episode": 76.0, "batch_reward": 0.48448793828487396, "critic_loss": 1.7016970638632773, "actor_loss": -72.6865025024414, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.312134504318237, "step": 76000}
{"episode_reward": 879.3494495639836, "episode": 77.0, "batch_reward": 0.4892691718637943, "critic_loss": 1.6996838588118552, "actor_loss": -72.49395111846924, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.743470907211304, "step": 77000}
{"episode_reward": 857.0146933789944, "episode": 78.0, "batch_reward": 0.49493416446447375, "critic_loss": 1.6713645216822623, "actor_loss": -72.5788755645752, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.557907581329346, "step": 78000}
{"episode_reward": 884.4276434182257, "episode": 79.0, "batch_reward": 0.4994264951944351, "critic_loss": 1.605086791396141, "actor_loss": -73.36293223571778, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.75167942047119, "step": 79000}
{"episode_reward": 845.7247640610926, "episode": 80.0, "batch_reward": 0.5030903163552284, "critic_loss": 1.6757640265226363, "actor_loss": -73.54857733917237, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.96234893798828, "step": 80000}
{"episode_reward": 845.8874781706047, "episode": 81.0, "batch_reward": 0.5069721038937569, "critic_loss": 1.631520680308342, "actor_loss": -74.13012213897706, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.27974009513855, "step": 81000}
{"episode_reward": 832.0674021735327, "episode": 82.0, "batch_reward": 0.510365332365036, "critic_loss": 1.574036508977413, "actor_loss": -75.08728008270263, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.828370332717896, "step": 82000}
{"episode_reward": 845.9418019413806, "episode": 83.0, "batch_reward": 0.5171814633011818, "critic_loss": 1.587761676311493, "actor_loss": -74.11937851715088, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.53605365753174, "step": 83000}
{"episode_reward": 844.6528919242812, "episode": 84.0, "batch_reward": 0.5183240229189396, "critic_loss": 1.6284502151608466, "actor_loss": -75.09523064422608, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.16547989845276, "step": 84000}
{"episode_reward": 825.174363406686, "episode": 85.0, "batch_reward": 0.5232081996798515, "critic_loss": 1.6074850413799286, "actor_loss": -75.44102168273926, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.793495655059814, "step": 85000}
{"episode_reward": 852.004433550669, "episode": 86.0, "batch_reward": 0.5252460371553898, "critic_loss": 1.6191150891780852, "actor_loss": -75.48520248413087, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.49976420402527, "step": 86000}
{"episode_reward": 829.889327084657, "episode": 87.0, "batch_reward": 0.5302494617402553, "critic_loss": 1.6245904532670974, "actor_loss": -75.92604033660889, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.475369930267334, "step": 87000}
{"episode_reward": 740.4621306068552, "episode": 88.0, "batch_reward": 0.533006250590086, "critic_loss": 1.645173241019249, "actor_loss": -75.98592774963379, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.783411741256714, "step": 88000}
{"episode_reward": 899.5481532321318, "episode": 89.0, "batch_reward": 0.5377407174408436, "critic_loss": 1.5882023831009864, "actor_loss": -76.50485017395019, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.518656730651855, "step": 89000}
{"episode_reward": 872.3956068291429, "episode": 90.0, "batch_reward": 0.540302039116621, "critic_loss": 1.5393450039029122, "actor_loss": -77.05558403015137, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.763887882232666, "step": 90000}
{"episode_reward": 845.9595551964301, "episode": 91.0, "batch_reward": 0.5426224362254143, "critic_loss": 1.576312959432602, "actor_loss": -77.21049284362793, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.47630834579468, "step": 91000}
{"episode_reward": 908.1600685020965, "episode": 92.0, "batch_reward": 0.5466069545149803, "critic_loss": 1.6141404587626458, "actor_loss": -76.52246992492675, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.23936891555786, "step": 92000}
{"episode_reward": 869.2759045295786, "episode": 93.0, "batch_reward": 0.5518586317598819, "critic_loss": 1.5415522505640984, "actor_loss": -77.69773123168946, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.8864963054657, "step": 93000}
{"episode_reward": 858.5586515095665, "episode": 94.0, "batch_reward": 0.5565670603811741, "critic_loss": 1.5411094997525214, "actor_loss": -77.51221101379394, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.727190494537354, "step": 94000}
{"episode_reward": 877.6605745134772, "episode": 95.0, "batch_reward": 0.555678854316473, "critic_loss": 1.5258641847372054, "actor_loss": -78.82254106140137, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.246518850326538, "step": 95000}
{"episode_reward": 893.1167942098374, "episode": 96.0, "batch_reward": 0.5634932661950588, "critic_loss": 1.4584410082101822, "actor_loss": -78.15084004211425, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.591888189315796, "step": 96000}
{"episode_reward": 882.0600811440718, "episode": 97.0, "batch_reward": 0.5637409682273865, "critic_loss": 1.4924623585939407, "actor_loss": -79.36690423583984, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.503674745559692, "step": 97000}
{"episode_reward": 778.9906267962839, "episode": 98.0, "batch_reward": 0.5679539806246757, "critic_loss": 1.4317239011526108, "actor_loss": -79.87357080078125, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.199072122573853, "step": 98000}
{"episode_reward": 899.9755186894624, "episode": 99.0, "batch_reward": 0.5707837782502174, "critic_loss": 1.404651873588562, "actor_loss": -79.3807724609375, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.610910415649414, "step": 99000}
{"episode_reward": 929.8396577949591, "episode": 100.0, "batch_reward": 0.5749856778681278, "critic_loss": 1.404906902372837, "actor_loss": -79.38465167236328, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.519618272781372, "step": 100000}
{"episode_reward": 891.8178412799352, "episode": 101.0, "batch_reward": 0.5769409348964691, "critic_loss": 1.4265678948760032, "actor_loss": -79.54815420532226, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.95191264152527, "step": 101000}
{"episode_reward": 845.6864838443645, "episode": 102.0, "batch_reward": 0.5788618243932724, "critic_loss": 1.4895402886867524, "actor_loss": -80.1525182800293, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.26130223274231, "step": 102000}
{"episode_reward": 868.4298140248233, "episode": 103.0, "batch_reward": 0.5836524071693421, "critic_loss": 1.5577789719700814, "actor_loss": -80.02594412231446, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.539674043655396, "step": 103000}
{"episode_reward": 902.2647451548271, "episode": 104.0, "batch_reward": 0.587074749648571, "critic_loss": 1.532405430316925, "actor_loss": -80.90040794372558, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.636327743530273, "step": 104000}
{"episode_reward": 872.6860544336827, "episode": 105.0, "batch_reward": 0.5881019712090493, "critic_loss": 1.6508844150304793, "actor_loss": -80.44726870727538, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.888355493545532, "step": 105000}
{"episode_reward": 879.8071796005063, "episode": 106.0, "batch_reward": 0.5929771390259266, "critic_loss": 2.005273880243301, "actor_loss": -80.8903323059082, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.534274578094482, "step": 106000}
{"episode_reward": 910.0765106051771, "episode": 107.0, "batch_reward": 0.5939154906868934, "critic_loss": 2.4691389622688296, "actor_loss": -81.59703120422363, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.066792011260986, "step": 107000}
{"episode_reward": 898.6251983601721, "episode": 108.0, "batch_reward": 0.5976076672673225, "critic_loss": 3.3510419788360597, "actor_loss": -82.655851272583, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.988414525985718, "step": 108000}
{"episode_reward": 904.7619364800831, "episode": 109.0, "batch_reward": 0.6005228208303451, "critic_loss": 6.13094869863987, "actor_loss": -84.93170553588867, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.737056970596313, "step": 109000}
{"episode_reward": 500.61953316808706, "episode": 110.0, "batch_reward": 0.5941722567379475, "critic_loss": 9.967211224079133, "actor_loss": -87.9757474975586, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.698813915252686, "step": 110000}
{"episode_reward": 62.19607238328089, "episode": 111.0, "batch_reward": 0.5901218422949314, "critic_loss": 17.226661429405212, "actor_loss": -95.39065229797363, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 42.26367473602295, "step": 111000}
{"episode_reward": 54.56934785753508, "episode": 112.0, "batch_reward": 0.5862944096624851, "critic_loss": 27.370856644630432, "actor_loss": -110.10833847045899, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.502797842025757, "step": 112000}
{"episode_reward": 71.41385681050224, "episode": 113.0, "batch_reward": 0.5824815555512906, "critic_loss": 36.22017820358276, "actor_loss": -124.26664096069337, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.879615783691406, "step": 113000}
{"episode_reward": 61.54701621240038, "episode": 114.0, "batch_reward": 0.5782169235944747, "critic_loss": 44.38222513771057, "actor_loss": -130.42959396362303, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.927716732025146, "step": 114000}
{"episode_reward": 72.70546791911023, "episode": 115.0, "batch_reward": 0.572521819293499, "critic_loss": 47.6419698638916, "actor_loss": -133.29649949645997, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.500831604003906, "step": 115000}
{"episode_reward": 71.59462822204023, "episode": 116.0, "batch_reward": 0.5681013750433922, "critic_loss": 46.79118715858459, "actor_loss": -138.74458833312988, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.757269620895386, "step": 116000}
{"episode_reward": 61.977813515509176, "episode": 117.0, "batch_reward": 0.5665676553845406, "critic_loss": 41.277724046707156, "actor_loss": -144.32877354431153, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.636866569519043, "step": 117000}
{"episode_reward": 214.69845866166403, "episode": 118.0, "batch_reward": 0.5615310333371163, "critic_loss": 34.983648755073546, "actor_loss": -146.73850938415526, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.484071016311646, "step": 118000}
{"episode_reward": 134.7712559180145, "episode": 119.0, "batch_reward": 0.5605968761742115, "critic_loss": 27.67559854412079, "actor_loss": -146.67519900512696, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.436467170715332, "step": 119000}
{"episode_reward": 628.9767521666216, "episode": 120.0, "batch_reward": 0.5604094938337802, "critic_loss": 22.913237135887147, "actor_loss": -142.2007573852539, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.46669030189514, "step": 120000}
{"episode_reward": 714.2340524095589, "episode": 121.0, "batch_reward": 0.5628526357412338, "critic_loss": 18.37062633037567, "actor_loss": -143.10870671081543, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.60217070579529, "step": 121000}
{"episode_reward": 810.3630409752343, "episode": 122.0, "batch_reward": 0.5660576605796814, "critic_loss": 15.136998776435853, "actor_loss": -136.34862475585936, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.615276098251343, "step": 122000}
{"episode_reward": 845.9671506048863, "episode": 123.0, "batch_reward": 0.5666159688234329, "critic_loss": 12.74343038892746, "actor_loss": -133.74512396240235, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.51495361328125, "step": 123000}
{"episode_reward": 858.7650457779899, "episode": 124.0, "batch_reward": 0.5686523703038693, "critic_loss": 10.603302501201629, "actor_loss": -134.38951614379883, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.016780138015747, "step": 124000}
{"episode_reward": 841.3611648600141, "episode": 125.0, "batch_reward": 0.5727463679015636, "critic_loss": 9.029691689252854, "actor_loss": -134.46613104248047, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.96044397354126, "step": 125000}
{"episode_reward": 746.6472881291246, "episode": 126.0, "batch_reward": 0.5698745897710323, "critic_loss": 7.712514600038529, "actor_loss": -133.0218097229004, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.859351634979248, "step": 126000}
{"episode_reward": 740.4092290187726, "episode": 127.0, "batch_reward": 0.5734570207595825, "critic_loss": 6.776564789533615, "actor_loss": -129.72099606323243, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.286260843276978, "step": 127000}
{"episode_reward": 820.4167247456654, "episode": 128.0, "batch_reward": 0.5760895325839519, "critic_loss": 5.792742319822311, "actor_loss": -129.84518295288086, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.626811981201172, "step": 128000}
{"episode_reward": 790.2402659339618, "episode": 129.0, "batch_reward": 0.5794528557956219, "critic_loss": 5.170077496051788, "actor_loss": -127.8693044128418, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.648030519485474, "step": 129000}
{"episode_reward": 792.5179702106456, "episode": 130.0, "batch_reward": 0.5793304501771926, "critic_loss": 4.504109034061432, "actor_loss": -124.34250581359863, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.133466005325317, "step": 130000}
{"episode_reward": 797.1996250281304, "episode": 131.0, "batch_reward": 0.5816416472196579, "critic_loss": 4.344599302053451, "actor_loss": -126.15860458374023, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.92371940612793, "step": 131000}
{"episode_reward": 863.5676029043096, "episode": 132.0, "batch_reward": 0.5822050613760948, "critic_loss": 4.099722346544266, "actor_loss": -122.59261700439453, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.542800903320312, "step": 132000}
{"episode_reward": 910.8350115186581, "episode": 133.0, "batch_reward": 0.5841559615135193, "critic_loss": 3.7283810180425645, "actor_loss": -120.36771855163575, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.903937816619873, "step": 133000}
{"episode_reward": 853.9612081157721, "episode": 134.0, "batch_reward": 0.587621587395668, "critic_loss": 3.5356594096422196, "actor_loss": -118.85127154541016, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.558643102645874, "step": 134000}
{"episode_reward": 882.2261656366004, "episode": 135.0, "batch_reward": 0.5888697412014008, "critic_loss": 3.2932404563426974, "actor_loss": -116.58405268859863, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.615302324295044, "step": 135000}
{"episode_reward": 917.6505968056282, "episode": 136.0, "batch_reward": 0.5921742959916592, "critic_loss": 3.272111429572105, "actor_loss": -114.98976791381835, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.949464559555054, "step": 136000}
{"episode_reward": 887.5861216314513, "episode": 137.0, "batch_reward": 0.5973010518550873, "critic_loss": 2.882354944586754, "actor_loss": -113.99892567443848, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.908862829208374, "step": 137000}
{"episode_reward": 934.941483947757, "episode": 138.0, "batch_reward": 0.5972163900732994, "critic_loss": 2.8670661611557007, "actor_loss": -113.84570387268066, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.611525058746338, "step": 138000}
{"episode_reward": 892.5873552321083, "episode": 139.0, "batch_reward": 0.5984925802350044, "critic_loss": 2.8425153439044952, "actor_loss": -112.94028759765625, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.1092848777771, "step": 139000}
{"episode_reward": 846.2418869726366, "episode": 140.0, "batch_reward": 0.6007630994319916, "critic_loss": 2.7045582358837126, "actor_loss": -112.16307386779785, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 22.05942416191101, "step": 140000}
{"episode_reward": 899.7886294347635, "episode": 141.0, "batch_reward": 0.6004278665184974, "critic_loss": 2.66279427921772, "actor_loss": -109.23061877441407, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 41.531304359436035, "step": 141000}
{"episode_reward": 906.6363836545272, "episode": 142.0, "batch_reward": 0.60392061278224, "critic_loss": 2.4908457272052766, "actor_loss": -108.25011315917969, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.934436559677124, "step": 142000}
{"episode_reward": 882.2376116452839, "episode": 143.0, "batch_reward": 0.6067148901224136, "critic_loss": 2.379795713067055, "actor_loss": -106.67703480529785, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.88183045387268, "step": 143000}
{"episode_reward": 929.2591218990465, "episode": 144.0, "batch_reward": 0.6100795900821686, "critic_loss": 2.4162930402755736, "actor_loss": -106.94890129089356, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.665177583694458, "step": 144000}
{"episode_reward": 910.3802163270175, "episode": 145.0, "batch_reward": 0.6103799599707127, "critic_loss": 2.2178539392352103, "actor_loss": -104.67479801940918, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.28135323524475, "step": 145000}
{"episode_reward": 848.7590739546115, "episode": 146.0, "batch_reward": 0.6130305046439171, "critic_loss": 2.220412428677082, "actor_loss": -105.12428923034668, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.666413068771362, "step": 146000}
{"episode_reward": 940.719743772317, "episode": 147.0, "batch_reward": 0.6167024717628956, "critic_loss": 2.1442135071754453, "actor_loss": -103.66934959411621, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.47623562812805, "step": 147000}
{"episode_reward": 894.8490792764944, "episode": 148.0, "batch_reward": 0.6171434264779091, "critic_loss": 2.0971969552636147, "actor_loss": -103.17829048156739, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 21.838545560836792, "step": 148000}
{"episode_reward": 939.8411618128388, "episode": 149.0, "batch_reward": 0.6184874100685119, "critic_loss": 2.0903180365562437, "actor_loss": -102.83188973999023, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "duration": 20.491841793060303, "step": 149000}
{"episode_reward": 904.1609096970824, "episode": 150.0, "batch_reward": 0.6219254821240902, "critic_loss": 1.9050955776572227, "actor_loss": -101.76816363525391, "actor_target_entropy": -6.0, "alpha_value": 0.0021340177818500975, "step": 150000}
