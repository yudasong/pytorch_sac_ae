{"episode_reward": 0.0, "episode": 1.0, "duration": 25.227505207061768, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 2.376424789428711, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.43651052672451995, "critic_loss": 0.11435954968614871, "actor_loss": -82.66585418041728, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 93.80620288848877, "step": 3000}
{"episode_reward": 28.860501432372246, "episode": 4.0, "batch_reward": 0.3326827147156, "critic_loss": 0.2802756551206112, "actor_loss": -76.76716314697265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.657150745391846, "step": 4000}
{"episode_reward": 281.8413877206251, "episode": 5.0, "batch_reward": 0.2796188226342201, "critic_loss": 0.15894289872795345, "actor_loss": -73.45656684875489, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.546169757843018, "step": 5000}
{"episode_reward": 23.296169991907124, "episode": 6.0, "batch_reward": 0.24392058473825454, "critic_loss": 0.20572913800925016, "actor_loss": -70.40854985046387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.00584053993225, "step": 6000}
{"episode_reward": 86.84519978408221, "episode": 7.0, "batch_reward": 0.21225745429098605, "critic_loss": 0.20423532602190972, "actor_loss": -67.12980799102783, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.794011116027832, "step": 7000}
{"episode_reward": 120.20059293561737, "episode": 8.0, "batch_reward": 0.22607885886728762, "critic_loss": 0.6010922208130359, "actor_loss": -67.92357991027832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.61973476409912, "step": 8000}
{"episode_reward": 451.7802141080268, "episode": 9.0, "batch_reward": 0.24325940054655076, "critic_loss": 0.9310144018828869, "actor_loss": -71.44690539550781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.75219178199768, "step": 9000}
{"episode_reward": 200.08050976558866, "episode": 10.0, "batch_reward": 0.2562323991060257, "critic_loss": 1.2074689780771732, "actor_loss": -72.497880859375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.660585165023804, "step": 10000}
{"episode_reward": 630.4123391926967, "episode": 11.0, "batch_reward": 0.27600197985768316, "critic_loss": 1.170077269345522, "actor_loss": -72.44264727783204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 55.514811992645264, "step": 11000}
{"episode_reward": 195.18971312430264, "episode": 12.0, "batch_reward": 0.27405207200348375, "critic_loss": 1.0879677051901817, "actor_loss": -72.20587951660156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.51817488670349, "step": 12000}
{"episode_reward": 553.3670288776166, "episode": 13.0, "batch_reward": 0.30571329572796824, "critic_loss": 1.4664162064790727, "actor_loss": -73.59330979919433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.474156379699707, "step": 13000}
{"episode_reward": 676.3394096601554, "episode": 14.0, "batch_reward": 0.3269161751121283, "critic_loss": 1.7272079115509986, "actor_loss": -74.44630784606933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.951589822769165, "step": 14000}
{"episode_reward": 539.7847274475074, "episode": 15.0, "batch_reward": 0.3509578157067299, "critic_loss": 1.7821849283576012, "actor_loss": -74.25849220275879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.27369737625122, "step": 15000}
{"episode_reward": 748.9432579899892, "episode": 16.0, "batch_reward": 0.37378600883483887, "critic_loss": 1.903516354739666, "actor_loss": -75.73522537231446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.763493299484253, "step": 16000}
{"episode_reward": 702.7625706981694, "episode": 17.0, "batch_reward": 0.3884458084106445, "critic_loss": 2.0111155327558516, "actor_loss": -76.06931196594238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.84575390815735, "step": 17000}
{"episode_reward": 617.0236263297115, "episode": 18.0, "batch_reward": 0.40962938794493675, "critic_loss": 1.831898084461689, "actor_loss": -75.73891836547851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.808179140090942, "step": 18000}
{"episode_reward": 831.0481584721073, "episode": 19.0, "batch_reward": 0.4314769175052643, "critic_loss": 1.7238828726410866, "actor_loss": -76.03242915344238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.96144151687622, "step": 19000}
{"episode_reward": 805.6367666262946, "episode": 20.0, "batch_reward": 0.4479174366891384, "critic_loss": 1.753009018778801, "actor_loss": -75.88668290710449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.51016902923584, "step": 20000}
{"episode_reward": 684.3849812522492, "episode": 21.0, "batch_reward": 0.46232296848297116, "critic_loss": 1.5761590629220008, "actor_loss": -76.44029696655274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 57.75947022438049, "step": 21000}
{"episode_reward": 820.9823924648226, "episode": 22.0, "batch_reward": 0.4784823071360588, "critic_loss": 1.4728035563230515, "actor_loss": -75.6982494354248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.440229177474976, "step": 22000}
{"episode_reward": 739.2126283222364, "episode": 23.0, "batch_reward": 0.4901198958158493, "critic_loss": 1.484186050415039, "actor_loss": -75.72703044128419, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.863043069839478, "step": 23000}
{"episode_reward": 790.1378030901749, "episode": 24.0, "batch_reward": 0.5041365378201008, "critic_loss": 1.5023818675875664, "actor_loss": -75.85037144470215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.42244815826416, "step": 24000}
{"episode_reward": 840.9825755551585, "episode": 25.0, "batch_reward": 0.5181880535781384, "critic_loss": 1.4121536275744437, "actor_loss": -76.18027481079102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.826679229736328, "step": 25000}
{"episode_reward": 841.9416710524666, "episode": 26.0, "batch_reward": 0.5319446626901626, "critic_loss": 1.3483574177622795, "actor_loss": -76.659960647583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.50075626373291, "step": 26000}
{"episode_reward": 841.6997545366111, "episode": 27.0, "batch_reward": 0.5416003571748733, "critic_loss": 1.318102177798748, "actor_loss": -76.45275256347657, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.50962543487549, "step": 27000}
{"episode_reward": 762.3518783322793, "episode": 28.0, "batch_reward": 0.5510276423692704, "critic_loss": 1.245445932686329, "actor_loss": -77.4453310546875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.778053283691406, "step": 28000}
{"episode_reward": 837.4554850929034, "episode": 29.0, "batch_reward": 0.5630980391204358, "critic_loss": 1.1673007974624634, "actor_loss": -76.91508891296387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.07080864906311, "step": 29000}
{"episode_reward": 914.1913681976907, "episode": 30.0, "batch_reward": 0.5730614896714687, "critic_loss": 1.1022501372098923, "actor_loss": -77.57479277038574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.211925983428955, "step": 30000}
{"episode_reward": 874.3383373191061, "episode": 31.0, "batch_reward": 0.5809463908970356, "critic_loss": 1.096640349328518, "actor_loss": -78.03197383117676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 59.584638595581055, "step": 31000}
{"episode_reward": 830.8343451716165, "episode": 32.0, "batch_reward": 0.5916320743560791, "critic_loss": 1.048889635682106, "actor_loss": -78.21711613464356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.589910984039307, "step": 32000}
{"episode_reward": 913.6298447088126, "episode": 33.0, "batch_reward": 0.600008794426918, "critic_loss": 1.0148305237293243, "actor_loss": -78.61787071228028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.565356969833374, "step": 33000}
{"episode_reward": 796.432771129806, "episode": 34.0, "batch_reward": 0.605944536626339, "critic_loss": 1.0127266653180123, "actor_loss": -79.20115679931641, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.763935089111328, "step": 34000}
{"episode_reward": 846.8147926777418, "episode": 35.0, "batch_reward": 0.6137309007048607, "critic_loss": 0.9842206713557243, "actor_loss": -79.38312913513184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.647002935409546, "step": 35000}
{"episode_reward": 873.8354597167943, "episode": 36.0, "batch_reward": 0.6219120683670044, "critic_loss": 0.9430677344501018, "actor_loss": -79.9444063873291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.690680980682373, "step": 36000}
{"episode_reward": 848.755758575199, "episode": 37.0, "batch_reward": 0.6284605464339257, "critic_loss": 0.8998909721076489, "actor_loss": -80.38853002929687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.01629900932312, "step": 37000}
{"episode_reward": 883.2305670327235, "episode": 38.0, "batch_reward": 0.6348429945111275, "critic_loss": 0.9182773176729679, "actor_loss": -79.98021900939942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.155625104904175, "step": 38000}
{"episode_reward": 849.4903240818114, "episode": 39.0, "batch_reward": 0.6405211253166199, "critic_loss": 0.9051280156075955, "actor_loss": -80.70913522338867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.146689414978027, "step": 39000}
{"episode_reward": 897.3916174507771, "episode": 40.0, "batch_reward": 0.6443530572652817, "critic_loss": 0.8866429494023323, "actor_loss": -80.92680104064941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.152902364730835, "step": 40000}
{"episode_reward": 845.9351457635835, "episode": 41.0, "batch_reward": 0.6511319835782051, "critic_loss": 0.8124065254628658, "actor_loss": -81.39458299255371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.41723418235779, "step": 41000}
{"episode_reward": 874.3091462684027, "episode": 42.0, "batch_reward": 0.6563829181790352, "critic_loss": 0.8056004200577735, "actor_loss": -81.69680537414551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.592106819152832, "step": 42000}
{"episode_reward": 894.2122374734879, "episode": 43.0, "batch_reward": 0.6641609772443772, "critic_loss": 0.7822553094923497, "actor_loss": -81.72919134521484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.90334415435791, "step": 43000}
{"episode_reward": 871.4307918469738, "episode": 44.0, "batch_reward": 0.6666944113373756, "critic_loss": 0.7700988396704197, "actor_loss": -82.26993376159668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.520995140075684, "step": 44000}
{"episode_reward": 897.6546099300754, "episode": 45.0, "batch_reward": 0.6722417334318161, "critic_loss": 0.7477252554297448, "actor_loss": -82.22818286132812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.520715713500977, "step": 45000}
{"episode_reward": 862.3513885172262, "episode": 46.0, "batch_reward": 0.6762210628986358, "critic_loss": 0.702789407402277, "actor_loss": -82.78176234436035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.505578994750977, "step": 46000}
{"episode_reward": 863.1550641753944, "episode": 47.0, "batch_reward": 0.6810263096690178, "critic_loss": 0.706359649002552, "actor_loss": -83.08350651550293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.00324535369873, "step": 47000}
{"episode_reward": 918.5806188541322, "episode": 48.0, "batch_reward": 0.6778583878874779, "critic_loss": 0.7138278487324715, "actor_loss": -82.40524690246582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.444851636886597, "step": 48000}
{"episode_reward": 63.72254296170942, "episode": 49.0, "batch_reward": 0.6733721497654915, "critic_loss": 0.6954583941996098, "actor_loss": -82.59820175170898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.822497367858887, "step": 49000}
{"episode_reward": 885.1706436933927, "episode": 50.0, "batch_reward": 0.677563012778759, "critic_loss": 0.7292171905040741, "actor_loss": -83.03464407348633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.4633686542511, "step": 50000}
{"episode_reward": 863.8314272693889, "episode": 51.0, "batch_reward": 0.6811760465502739, "critic_loss": 0.6625477954745292, "actor_loss": -82.94618997192383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.898165225982666, "step": 51000}
{"episode_reward": 895.9083819703205, "episode": 52.0, "batch_reward": 0.6842942789196969, "critic_loss": 0.6500976506471634, "actor_loss": -83.37445327758789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.59647250175476, "step": 52000}
{"episode_reward": 870.6455303905143, "episode": 53.0, "batch_reward": 0.6888080524802208, "critic_loss": 0.6292023828625679, "actor_loss": -83.41523068237305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.50713014602661, "step": 53000}
{"episode_reward": 892.8281764254033, "episode": 54.0, "batch_reward": 0.6929533718824387, "critic_loss": 0.6370918208658696, "actor_loss": -83.90731173706055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.775777578353882, "step": 54000}
{"episode_reward": 897.5774550544015, "episode": 55.0, "batch_reward": 0.6953275555968285, "critic_loss": 0.6404440651834011, "actor_loss": -84.12859452819825, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.858376264572144, "step": 55000}
{"episode_reward": 896.874473759768, "episode": 56.0, "batch_reward": 0.7010338932871819, "critic_loss": 0.6233555279672146, "actor_loss": -84.08411796569824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.847766637802124, "step": 56000}
{"episode_reward": 955.298820263134, "episode": 57.0, "batch_reward": 0.7050183138847351, "critic_loss": 0.6091557340621948, "actor_loss": -84.47049378967286, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.05404758453369, "step": 57000}
{"episode_reward": 885.5952029559198, "episode": 58.0, "batch_reward": 0.7071118057966232, "critic_loss": 0.5888967626094818, "actor_loss": -84.4955484008789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.937411785125732, "step": 58000}
{"episode_reward": 902.5698312631906, "episode": 59.0, "batch_reward": 0.7107744850516319, "critic_loss": 0.5816307310163975, "actor_loss": -84.90160705566406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.931725025177002, "step": 59000}
{"episode_reward": 921.738342597745, "episode": 60.0, "batch_reward": 0.7149405924081802, "critic_loss": 0.5628158676475287, "actor_loss": -85.0612483215332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.160592317581177, "step": 60000}
{"episode_reward": 898.7361093402487, "episode": 61.0, "batch_reward": 0.7178278104662895, "critic_loss": 0.5561325896680355, "actor_loss": -85.23566090393066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.465803146362305, "step": 61000}
{"episode_reward": 906.9084950038678, "episode": 62.0, "batch_reward": 0.7199275804162025, "critic_loss": 0.5561804781109094, "actor_loss": -85.3612889251709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.427523136138916, "step": 62000}
{"episode_reward": 906.0666530109082, "episode": 63.0, "batch_reward": 0.7204995006918907, "critic_loss": 0.5820594329237938, "actor_loss": -85.50833479309082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.802747011184692, "step": 63000}
{"episode_reward": 878.251443670835, "episode": 64.0, "batch_reward": 0.7242046947479248, "critic_loss": 0.5752453308105469, "actor_loss": -85.92541513061524, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.502117395401, "step": 64000}
{"episode_reward": 848.8355516694673, "episode": 65.0, "batch_reward": 0.7284059590697288, "critic_loss": 0.5637218789756298, "actor_loss": -85.94519488525391, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.517138719558716, "step": 65000}
{"episode_reward": 938.7938878351038, "episode": 66.0, "batch_reward": 0.7316799705028534, "critic_loss": 0.5668082087337971, "actor_loss": -86.36194952392579, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.332756757736206, "step": 66000}
{"episode_reward": 965.6311963629446, "episode": 67.0, "batch_reward": 0.7347668009996414, "critic_loss": 0.5700057573020458, "actor_loss": -86.44276776123047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.48803186416626, "step": 67000}
{"episode_reward": 889.2754561489228, "episode": 68.0, "batch_reward": 0.7381805465221405, "critic_loss": 0.5514353400766849, "actor_loss": -86.70717681884766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.800357580184937, "step": 68000}
{"episode_reward": 956.7859710710255, "episode": 69.0, "batch_reward": 0.7394176473021508, "critic_loss": 0.5715656802505255, "actor_loss": -86.88267672729492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.209664344787598, "step": 69000}
{"episode_reward": 862.4979775777903, "episode": 70.0, "batch_reward": 0.7415402168631554, "critic_loss": 0.5799187638163567, "actor_loss": -86.99840080261231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.811182498931885, "step": 70000}
{"episode_reward": 892.1062144263009, "episode": 71.0, "batch_reward": 0.7422719135284424, "critic_loss": 0.584665683299303, "actor_loss": -86.96280972290039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.78749108314514, "step": 71000}
{"episode_reward": 901.5646405949664, "episode": 72.0, "batch_reward": 0.7466454983949661, "critic_loss": 0.5653258770704269, "actor_loss": -87.23527740478515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.86750626564026, "step": 72000}
{"episode_reward": 931.7757939029705, "episode": 73.0, "batch_reward": 0.7473107325434685, "critic_loss": 0.5606597301065922, "actor_loss": -87.4238490600586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.20751690864563, "step": 73000}
{"episode_reward": 929.2721537301301, "episode": 74.0, "batch_reward": 0.7519979797005654, "critic_loss": 0.5511068820953369, "actor_loss": -87.43454176330566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.826568365097046, "step": 74000}
{"episode_reward": 920.0790785707853, "episode": 75.0, "batch_reward": 0.7556784474253655, "critic_loss": 0.5352710001468658, "actor_loss": -87.78043136596679, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.647921085357666, "step": 75000}
{"episode_reward": 926.9146433777979, "episode": 76.0, "batch_reward": 0.7562571429014205, "critic_loss": 0.5085685836821795, "actor_loss": -88.00983619689941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.17740225791931, "step": 76000}
{"episode_reward": 941.5731032969945, "episode": 77.0, "batch_reward": 0.7600620427131652, "critic_loss": 0.5165858156085015, "actor_loss": -88.06267901611328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.91890025138855, "step": 77000}
{"episode_reward": 955.4983413277117, "episode": 78.0, "batch_reward": 0.7601274191737175, "critic_loss": 0.5254666856527328, "actor_loss": -88.06359742736817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.899908781051636, "step": 78000}
{"episode_reward": 892.1763141718044, "episode": 79.0, "batch_reward": 0.7624140871167183, "critic_loss": 0.502630389675498, "actor_loss": -88.24543446350097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.659079790115356, "step": 79000}
{"episode_reward": 914.5425790688387, "episode": 80.0, "batch_reward": 0.7648545604348183, "critic_loss": 0.5027743775248528, "actor_loss": -88.6348113708496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.867234468460083, "step": 80000}
{"episode_reward": 932.840246117925, "episode": 81.0, "batch_reward": 0.7666747969388962, "critic_loss": 0.47611336785554886, "actor_loss": -88.69937316894531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.69421195983887, "step": 81000}
{"episode_reward": 901.0415904909264, "episode": 82.0, "batch_reward": 0.7668473112583161, "critic_loss": 0.5003342020660638, "actor_loss": -88.79667301940918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.542002201080322, "step": 82000}
{"episode_reward": 942.7222716539734, "episode": 83.0, "batch_reward": 0.769088325381279, "critic_loss": 0.48756455479562283, "actor_loss": -89.14571830749512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.044392347335815, "step": 83000}
{"episode_reward": 952.9628043890687, "episode": 84.0, "batch_reward": 0.7723338176608086, "critic_loss": 0.4842664448171854, "actor_loss": -89.1823349456787, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.081549882888794, "step": 84000}
{"episode_reward": 923.2257240313297, "episode": 85.0, "batch_reward": 0.772437660753727, "critic_loss": 0.5054669733047485, "actor_loss": -89.22887486267089, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.467034578323364, "step": 85000}
{"episode_reward": 820.6603054210213, "episode": 86.0, "batch_reward": 0.7745327106118203, "critic_loss": 0.5105351484715939, "actor_loss": -89.44696072387696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.234652042388916, "step": 86000}
{"episode_reward": 911.940576164724, "episode": 87.0, "batch_reward": 0.7765477091670037, "critic_loss": 0.5034457704722881, "actor_loss": -89.52922286987305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.707255125045776, "step": 87000}
{"episode_reward": 905.7808874329452, "episode": 88.0, "batch_reward": 0.7763966779112816, "critic_loss": 0.47281804363429547, "actor_loss": -89.66410731506348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.220558643341064, "step": 88000}
{"episode_reward": 925.1109952073524, "episode": 89.0, "batch_reward": 0.7784335482120514, "critic_loss": 0.478127901494503, "actor_loss": -89.56537619018555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.52044701576233, "step": 89000}
{"episode_reward": 908.8645308798004, "episode": 90.0, "batch_reward": 0.7795880686640739, "critic_loss": 0.4950320653617382, "actor_loss": -89.56326173400879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.49297523498535, "step": 90000}
{"episode_reward": 931.8436244426788, "episode": 91.0, "batch_reward": 0.7825314541459083, "critic_loss": 0.5020956898927689, "actor_loss": -89.83675787353516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.36067199707031, "step": 91000}
{"episode_reward": 903.4071533849657, "episode": 92.0, "batch_reward": 0.7848538573980332, "critic_loss": 0.48601055081188677, "actor_loss": -90.08524369812012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.51862096786499, "step": 92000}
{"episode_reward": 965.142435943217, "episode": 93.0, "batch_reward": 0.7877620684504509, "critic_loss": 0.4846581762433052, "actor_loss": -90.15255392456055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.648454666137695, "step": 93000}
{"episode_reward": 956.7148246671118, "episode": 94.0, "batch_reward": 0.7885728248953819, "critic_loss": 0.481105459317565, "actor_loss": -90.27212605285645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.49393320083618, "step": 94000}
{"episode_reward": 912.8960272397225, "episode": 95.0, "batch_reward": 0.7885625402331352, "critic_loss": 0.5073232310116291, "actor_loss": -90.20359704589843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.77328372001648, "step": 95000}
{"episode_reward": 900.1778181531618, "episode": 96.0, "batch_reward": 0.7895033464431763, "critic_loss": 0.4718917623311281, "actor_loss": -90.60940547180176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.73971199989319, "step": 96000}
{"episode_reward": 936.3800900666034, "episode": 97.0, "batch_reward": 0.7906354507803917, "critic_loss": 0.46874525570869446, "actor_loss": -90.58600050354003, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.97305965423584, "step": 97000}
{"episode_reward": 936.7403130524832, "episode": 98.0, "batch_reward": 0.7925863081216812, "critic_loss": 0.46888772809505463, "actor_loss": -90.59393656921387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.024211168289185, "step": 98000}
{"episode_reward": 935.0267484297575, "episode": 99.0, "batch_reward": 0.7930223382711411, "critic_loss": 0.4568767469376326, "actor_loss": -90.894251953125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.727580308914185, "step": 99000}
{"episode_reward": 800.4895765665631, "episode": 100.0, "batch_reward": 0.7932069809436798, "critic_loss": 0.4486372971683741, "actor_loss": -90.85176055908204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.36012053489685, "step": 100000}
{"episode_reward": 953.215872275842, "episode": 101.0, "batch_reward": 0.7971691266298294, "critic_loss": 0.4459145460277796, "actor_loss": -91.06976834106446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.3819260597229, "step": 101000}
{"episode_reward": 961.8646834951162, "episode": 102.0, "batch_reward": 0.7983381631374359, "critic_loss": 0.43112528033554554, "actor_loss": -90.94483659362793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.90722107887268, "step": 102000}
{"episode_reward": 948.7167836302996, "episode": 103.0, "batch_reward": 0.7994011013507843, "critic_loss": 0.44593456719815733, "actor_loss": -90.90882261657715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.811601638793945, "step": 103000}
{"episode_reward": 953.156529572487, "episode": 104.0, "batch_reward": 0.7990274013280868, "critic_loss": 0.44788224177062513, "actor_loss": -91.02178875732422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.681010246276855, "step": 104000}
{"episode_reward": 937.0531107849131, "episode": 105.0, "batch_reward": 0.8029653264284133, "critic_loss": 0.4546651911139488, "actor_loss": -91.20794424438476, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.080411434173584, "step": 105000}
{"episode_reward": 966.0221362472093, "episode": 106.0, "batch_reward": 0.8030304443836213, "critic_loss": 0.4442609612047672, "actor_loss": -91.2535651397705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.558141231536865, "step": 106000}
{"episode_reward": 883.911429884649, "episode": 107.0, "batch_reward": 0.804713162124157, "critic_loss": 0.44425493240356445, "actor_loss": -91.30343315124512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.578530073165894, "step": 107000}
{"episode_reward": 908.0066419842198, "episode": 108.0, "batch_reward": 0.8038397780656814, "critic_loss": 0.45171202713251113, "actor_loss": -91.18203691101074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.206221103668213, "step": 108000}
{"episode_reward": 848.1763702821477, "episode": 109.0, "batch_reward": 0.8047618442177773, "critic_loss": 0.45568857216835024, "actor_loss": -91.21581355285645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.783165454864502, "step": 109000}
{"episode_reward": 942.6846238242563, "episode": 110.0, "batch_reward": 0.807860368013382, "critic_loss": 0.4348745857924223, "actor_loss": -91.31975300598144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.595130443572998, "step": 110000}
{"episode_reward": 942.5667594401272, "episode": 111.0, "batch_reward": 0.8076941461563111, "critic_loss": 0.44970273445546627, "actor_loss": -91.28726200866699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.491716146469116, "step": 111000}
{"episode_reward": 931.2161053172299, "episode": 112.0, "batch_reward": 0.8089314846396446, "critic_loss": 0.44858806425333025, "actor_loss": -91.51976443481445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.540711402893066, "step": 112000}
{"episode_reward": 913.4905922985838, "episode": 113.0, "batch_reward": 0.8102274514436721, "critic_loss": 0.4604630239009857, "actor_loss": -91.53456076049805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.884459495544434, "step": 113000}
{"episode_reward": 936.8336241993229, "episode": 114.0, "batch_reward": 0.8100897013545036, "critic_loss": 0.4718506398946047, "actor_loss": -91.62460147094727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.878385305404663, "step": 114000}
{"episode_reward": 927.7858549221676, "episode": 115.0, "batch_reward": 0.8111294568181038, "critic_loss": 0.45470490626990795, "actor_loss": -91.6697558746338, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.02290964126587, "step": 115000}
{"episode_reward": 945.9331518472895, "episode": 116.0, "batch_reward": 0.8147986661195755, "critic_loss": 0.4768246565312147, "actor_loss": -91.73173860168457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.958881616592407, "step": 116000}
{"episode_reward": 917.5904259717868, "episode": 117.0, "batch_reward": 0.8138139892816544, "critic_loss": 0.47682589712738993, "actor_loss": -91.6904434967041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.84737253189087, "step": 117000}
{"episode_reward": 916.9250201882273, "episode": 118.0, "batch_reward": 0.8143250376582146, "critic_loss": 0.4702149627357721, "actor_loss": -91.807796875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.32179093360901, "step": 118000}
{"episode_reward": 857.1758835770489, "episode": 119.0, "batch_reward": 0.8169458581805229, "critic_loss": 0.48429136779904364, "actor_loss": -91.7853706817627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.612978219985962, "step": 119000}
{"episode_reward": 898.7786314135508, "episode": 120.0, "batch_reward": 0.8167129884958267, "critic_loss": 0.5159322480857372, "actor_loss": -91.80428273010254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.602566242218018, "step": 120000}
{"episode_reward": 955.6483959888847, "episode": 121.0, "batch_reward": 0.8169833983182907, "critic_loss": 0.4988120249956846, "actor_loss": -91.92134846496582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.493778228759766, "step": 121000}
{"episode_reward": 950.7015653677737, "episode": 122.0, "batch_reward": 0.818825999379158, "critic_loss": 0.5002817669659853, "actor_loss": -91.9447064666748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.217044591903687, "step": 122000}
{"episode_reward": 932.5707700392771, "episode": 123.0, "batch_reward": 0.8199140836000443, "critic_loss": 0.48580951984226706, "actor_loss": -92.04981059265137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.432846784591675, "step": 123000}
{"episode_reward": 913.9146755081872, "episode": 124.0, "batch_reward": 0.8204383701682091, "critic_loss": 0.5108348528146743, "actor_loss": -92.15587506103516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.619951009750366, "step": 124000}
{"episode_reward": 910.236106077057, "episode": 125.0, "batch_reward": 0.8206736172437668, "critic_loss": 0.48450877775251866, "actor_loss": -92.20437301635742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.90748906135559, "step": 125000}
{"episode_reward": 891.8487766276411, "episode": 126.0, "batch_reward": 0.823935006737709, "critic_loss": 0.49467731396853926, "actor_loss": -92.10587612915039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.311208248138428, "step": 126000}
{"episode_reward": 970.9453018056842, "episode": 127.0, "batch_reward": 0.8218220874667168, "critic_loss": 0.4852486909031868, "actor_loss": -92.21607670593262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.38803482055664, "step": 127000}
{"episode_reward": 930.8980923664196, "episode": 128.0, "batch_reward": 0.8233569791316986, "critic_loss": 0.48374059845507145, "actor_loss": -92.2902257385254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.42860221862793, "step": 128000}
{"episode_reward": 921.9711584663177, "episode": 129.0, "batch_reward": 0.823154699742794, "critic_loss": 0.4882041255235672, "actor_loss": -92.19901454162597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.579326629638672, "step": 129000}
{"episode_reward": 962.6480745404829, "episode": 130.0, "batch_reward": 0.8267188662290573, "critic_loss": 0.4602340367585421, "actor_loss": -92.43104391479493, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.2121639251709, "step": 130000}
{"episode_reward": 953.3741063274772, "episode": 131.0, "batch_reward": 0.8265011520981789, "critic_loss": 0.4318271113038063, "actor_loss": -92.45359597778321, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.72860598564148, "step": 131000}
{"episode_reward": 928.7456193429339, "episode": 132.0, "batch_reward": 0.8271139367818833, "critic_loss": 0.45481381870806215, "actor_loss": -92.53569093322754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.588308572769165, "step": 132000}
{"episode_reward": 923.3451483330892, "episode": 133.0, "batch_reward": 0.8283136722445488, "critic_loss": 0.46323948922753333, "actor_loss": -92.42232818603516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.318835735321045, "step": 133000}
{"episode_reward": 974.4275006282776, "episode": 134.0, "batch_reward": 0.8285916323065757, "critic_loss": 0.45595353960990903, "actor_loss": -92.47831120300293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.08139657974243, "step": 134000}
{"episode_reward": 924.0777643641471, "episode": 135.0, "batch_reward": 0.8307101684808731, "critic_loss": 0.46108363731205465, "actor_loss": -92.65680694580078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.41028642654419, "step": 135000}
{"episode_reward": 915.960883065424, "episode": 136.0, "batch_reward": 0.8307050252556801, "critic_loss": 0.4603370944857597, "actor_loss": -92.59468832397461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.08432173728943, "step": 136000}
{"episode_reward": 929.8614167425177, "episode": 137.0, "batch_reward": 0.8299979984760284, "critic_loss": 0.4531857631355524, "actor_loss": -92.65619807434082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.515848636627197, "step": 137000}
{"episode_reward": 957.6661101624837, "episode": 138.0, "batch_reward": 0.8333163056969642, "critic_loss": 0.450779209241271, "actor_loss": -92.87018865966797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.03823208808899, "step": 138000}
{"episode_reward": 904.1818050777513, "episode": 139.0, "batch_reward": 0.8329916641712188, "critic_loss": 0.4568948031514883, "actor_loss": -92.65451377868652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.524774312973022, "step": 139000}
{"episode_reward": 950.7561720114621, "episode": 140.0, "batch_reward": 0.8357110815644264, "critic_loss": 0.42339179952442646, "actor_loss": -92.93613040161132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.27749800682068, "step": 140000}
{"episode_reward": 937.7530337037921, "episode": 141.0, "batch_reward": 0.8327514984607697, "critic_loss": 0.4390666100680828, "actor_loss": -92.8955785369873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.678996324539185, "step": 141000}
{"episode_reward": 919.4602843326384, "episode": 142.0, "batch_reward": 0.8345391945242882, "critic_loss": 0.44581048791110517, "actor_loss": -92.88596762084961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.339429140090942, "step": 142000}
{"episode_reward": 932.117356335764, "episode": 143.0, "batch_reward": 0.8350139058232308, "critic_loss": 0.4465621646344662, "actor_loss": -92.91703741455078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.557312488555908, "step": 143000}
{"episode_reward": 913.2517411865269, "episode": 144.0, "batch_reward": 0.8365496593117714, "critic_loss": 0.44537985780835154, "actor_loss": -93.0104348449707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.300276517868042, "step": 144000}
{"episode_reward": 889.4113736389045, "episode": 145.0, "batch_reward": 0.8368495470285415, "critic_loss": 0.4556767216771841, "actor_loss": -93.06085523986816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.79544973373413, "step": 145000}
{"episode_reward": 892.0984847079922, "episode": 146.0, "batch_reward": 0.8368317233920097, "critic_loss": 0.4477243562936783, "actor_loss": -93.12449435424804, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.392914295196533, "step": 146000}
{"episode_reward": 917.0955586881724, "episode": 147.0, "batch_reward": 0.8371046805381774, "critic_loss": 0.4306715335994959, "actor_loss": -93.13690757751465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.74026894569397, "step": 147000}
{"episode_reward": 934.7180458511465, "episode": 148.0, "batch_reward": 0.8367842925190926, "critic_loss": 0.4271388996243477, "actor_loss": -93.12386129760742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.301563024520874, "step": 148000}
{"episode_reward": 933.5920645551759, "episode": 149.0, "batch_reward": 0.8385226061344146, "critic_loss": 0.4388069900274277, "actor_loss": -93.17787704467773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.446228504180908, "step": 149000}
{"episode_reward": 965.3428583952277, "episode": 150.0, "batch_reward": 0.8382970985770225, "critic_loss": 0.44095263044536115, "actor_loss": -93.25338357543946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
