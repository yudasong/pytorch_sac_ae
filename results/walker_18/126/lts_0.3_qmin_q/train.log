{"episode_reward": 0.0, "episode": 1.0, "duration": 21.9048810005188, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.876692771911621, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.43713162717679294, "critic_loss": 0.12354753842554358, "actor_loss": -81.16789941379383, "actor_target_entropy": -6.0, "alpha_value": 0.002642586817083679, "duration": 65.1329939365387, "step": 3000}
{"episode_reward": 73.00881065715197, "episode": 4.0, "batch_reward": 0.3215433457195759, "critic_loss": 0.411665231898427, "actor_loss": -78.41138851928712, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.23205041885376, "step": 4000}
{"episode_reward": 242.85592011012497, "episode": 5.0, "batch_reward": 0.30926936307549474, "critic_loss": 0.4768863350749016, "actor_loss": -78.5291323852539, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.326345682144165, "step": 5000}
{"episode_reward": 279.63732598528026, "episode": 6.0, "batch_reward": 0.31668175530433657, "critic_loss": 0.6969346186220646, "actor_loss": -78.40436157226563, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.358653783798218, "step": 6000}
{"episode_reward": 440.42105467494764, "episode": 7.0, "batch_reward": 0.3396851759403944, "critic_loss": 0.8044486173689366, "actor_loss": -79.08384196472169, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.21206521987915, "step": 7000}
{"episode_reward": 549.9955082335073, "episode": 8.0, "batch_reward": 0.359136697769165, "critic_loss": 0.8984256738722325, "actor_loss": -80.27744564819336, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.28645658493042, "step": 8000}
{"episode_reward": 270.3693819538155, "episode": 9.0, "batch_reward": 0.35832294446229934, "critic_loss": 1.0497827248573304, "actor_loss": -80.29809327697754, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.55767273902893, "step": 9000}
{"episode_reward": 590.7220775092151, "episode": 10.0, "batch_reward": 0.3873154810965061, "critic_loss": 1.3213658823370933, "actor_loss": -81.14912326049804, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.071024179458618, "step": 10000}
{"episode_reward": 577.7563029562581, "episode": 11.0, "batch_reward": 0.4090616452693939, "critic_loss": 1.4026717383861542, "actor_loss": -81.32742652893066, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.59460377693176, "step": 11000}
{"episode_reward": 705.4811454011478, "episode": 12.0, "batch_reward": 0.4337492133080959, "critic_loss": 1.5597773728966713, "actor_loss": -82.23552537536621, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.2738618850708, "step": 12000}
{"episode_reward": 709.0877433808289, "episode": 13.0, "batch_reward": 0.4559716903269291, "critic_loss": 1.6799165678620338, "actor_loss": -82.59765405273437, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.51616930961609, "step": 13000}
{"episode_reward": 702.0755644052005, "episode": 14.0, "batch_reward": 0.4747611492276192, "critic_loss": 1.688118775010109, "actor_loss": -83.20573068237304, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.269222021102905, "step": 14000}
{"episode_reward": 645.4015996551453, "episode": 15.0, "batch_reward": 0.4855116320848465, "critic_loss": 2.666082121729851, "actor_loss": -83.28546142578125, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.623219966888428, "step": 15000}
{"episode_reward": 681.0619273361806, "episode": 16.0, "batch_reward": 0.5016810251176357, "critic_loss": 1.9216893136501312, "actor_loss": -84.37882850646973, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.048011302947998, "step": 16000}
{"episode_reward": 777.4212165000239, "episode": 17.0, "batch_reward": 0.495665072709322, "critic_loss": 1.9742148267030717, "actor_loss": -84.50135928344727, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.509008169174194, "step": 17000}
{"episode_reward": 18.601544075411287, "episode": 18.0, "batch_reward": 0.49025225338339806, "critic_loss": 1.7769466173052788, "actor_loss": -84.4910087890625, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.196974992752075, "step": 18000}
{"episode_reward": 816.7083955327881, "episode": 19.0, "batch_reward": 0.506981746673584, "critic_loss": 1.9534737575650216, "actor_loss": -85.00527159118653, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.210545301437378, "step": 19000}
{"episode_reward": 806.6457005285686, "episode": 20.0, "batch_reward": 0.5033995419442654, "critic_loss": 2.6078170733451844, "actor_loss": -85.96681465148926, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.69042730331421, "step": 20000}
{"episode_reward": 38.898865783840655, "episode": 21.0, "batch_reward": 0.4816484630703926, "critic_loss": 2.784196797847748, "actor_loss": -88.37107897949218, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.348076581954956, "step": 21000}
{"episode_reward": 57.13439670719704, "episode": 22.0, "batch_reward": 0.4612558400630951, "critic_loss": 4.084184369802475, "actor_loss": -90.73670715332031, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.0760715007782, "step": 22000}
{"episode_reward": 15.912064280861873, "episode": 23.0, "batch_reward": 0.44175967103242875, "critic_loss": 6.44709200501442, "actor_loss": -97.20800540161133, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.926895141601562, "step": 23000}
{"episode_reward": 53.99942742268413, "episode": 24.0, "batch_reward": 0.42546566730737684, "critic_loss": 6.231823699712753, "actor_loss": -104.37880999755859, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.022313356399536, "step": 24000}
{"episode_reward": 57.93187607061389, "episode": 25.0, "batch_reward": 0.41179995599389074, "critic_loss": 5.322782631158828, "actor_loss": -106.43631233215332, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.228989362716675, "step": 25000}
{"episode_reward": 69.08450712272793, "episode": 26.0, "batch_reward": 0.3983306266665459, "critic_loss": 3.7722958476543424, "actor_loss": -107.57412634277344, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.381675481796265, "step": 26000}
{"episode_reward": 33.04101913379181, "episode": 27.0, "batch_reward": 0.38485122150182727, "critic_loss": 2.7420259215831755, "actor_loss": -108.61308195495606, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.436232328414917, "step": 27000}
{"episode_reward": 40.491351648222455, "episode": 28.0, "batch_reward": 0.3765230287015438, "critic_loss": 2.223541278243065, "actor_loss": -107.47501481628419, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.15376877784729, "step": 28000}
{"episode_reward": 307.58427817166296, "episode": 29.0, "batch_reward": 0.3676370178461075, "critic_loss": 1.7335537109375, "actor_loss": -108.59601370239258, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.496360778808594, "step": 29000}
{"episode_reward": 54.29519292656037, "episode": 30.0, "batch_reward": 0.36094543616473673, "critic_loss": 1.3952197886705398, "actor_loss": -105.69064538574219, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.36452603340149, "step": 30000}
{"episode_reward": 134.32930658401554, "episode": 31.0, "batch_reward": 0.35060445219278336, "critic_loss": 1.2290749490261077, "actor_loss": -103.9062413482666, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.51621198654175, "step": 31000}
{"episode_reward": 64.51810535863672, "episode": 32.0, "batch_reward": 0.3421746665090323, "critic_loss": 1.1633688182234765, "actor_loss": -103.06294657897949, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.675676822662354, "step": 32000}
{"episode_reward": 235.35127061101116, "episode": 33.0, "batch_reward": 0.34661781337857245, "critic_loss": 1.105951562166214, "actor_loss": -102.06783145141601, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.51849126815796, "step": 33000}
{"episode_reward": 553.0476151377947, "episode": 34.0, "batch_reward": 0.35448802590370176, "critic_loss": 1.0721922620534896, "actor_loss": -99.7056024017334, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.493738174438477, "step": 34000}
{"episode_reward": 737.2817935360918, "episode": 35.0, "batch_reward": 0.36840472763776777, "critic_loss": 1.1340682033896445, "actor_loss": -99.2048964691162, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.201847314834595, "step": 35000}
{"episode_reward": 811.4729671415123, "episode": 36.0, "batch_reward": 0.37711821180582045, "critic_loss": 1.1720239058732986, "actor_loss": -97.82626498413086, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.20688247680664, "step": 36000}
{"episode_reward": 737.9960278540466, "episode": 37.0, "batch_reward": 0.3901437458097935, "critic_loss": 1.1531146228313447, "actor_loss": -96.97288542175293, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.643630743026733, "step": 37000}
{"episode_reward": 860.548256182902, "episode": 38.0, "batch_reward": 0.40327962571382525, "critic_loss": 1.1093658546805383, "actor_loss": -97.25929328918457, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.232868909835815, "step": 38000}
{"episode_reward": 893.2901428645608, "episode": 39.0, "batch_reward": 0.4171602854132652, "critic_loss": 1.071778003036976, "actor_loss": -96.644103515625, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.922319650650024, "step": 39000}
{"episode_reward": 931.4520767159544, "episode": 40.0, "batch_reward": 0.4274028606414795, "critic_loss": 1.0112864685058593, "actor_loss": -96.09526737976074, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.894405126571655, "step": 40000}
{"episode_reward": 878.9321522235456, "episode": 41.0, "batch_reward": 0.43896917122602463, "critic_loss": 0.9396955790519714, "actor_loss": -95.45544668579102, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.53672933578491, "step": 41000}
{"episode_reward": 854.7462439113704, "episode": 42.0, "batch_reward": 0.4493254059553146, "critic_loss": 0.9043624885380268, "actor_loss": -95.18874018859863, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.117680072784424, "step": 42000}
{"episode_reward": 885.3840088961858, "episode": 43.0, "batch_reward": 0.46196158161759376, "critic_loss": 0.8388933820128441, "actor_loss": -94.79923710632325, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.765784740447998, "step": 43000}
{"episode_reward": 905.4054693391856, "episode": 44.0, "batch_reward": 0.47019050815701485, "critic_loss": 0.8003833377361298, "actor_loss": -94.47750103759766, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.229599714279175, "step": 44000}
{"episode_reward": 896.1013754820933, "episode": 45.0, "batch_reward": 0.4780332641005516, "critic_loss": 0.7896069014668464, "actor_loss": -94.25511213684082, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.429422616958618, "step": 45000}
{"episode_reward": 890.4670237435313, "episode": 46.0, "batch_reward": 0.4888517929911613, "critic_loss": 0.7080989472568036, "actor_loss": -93.74249353027344, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.1286358833313, "step": 46000}
{"episode_reward": 868.4542882677003, "episode": 47.0, "batch_reward": 0.49722279313206674, "critic_loss": 0.6803236874938011, "actor_loss": -93.24957620239257, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.335211753845215, "step": 47000}
{"episode_reward": 907.2053521855404, "episode": 48.0, "batch_reward": 0.5067085317373275, "critic_loss": 0.6464786469340325, "actor_loss": -93.32996577453613, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.1348397731781, "step": 48000}
{"episode_reward": 904.6389172582981, "episode": 49.0, "batch_reward": 0.514830454826355, "critic_loss": 0.6338881378173828, "actor_loss": -92.94989002990722, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.19665002822876, "step": 49000}
{"episode_reward": 873.4782584985348, "episode": 50.0, "batch_reward": 0.5213065659701824, "critic_loss": 0.645330487459898, "actor_loss": -92.62985813903809, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.667690992355347, "step": 50000}
{"episode_reward": 837.7806866806174, "episode": 51.0, "batch_reward": 0.5288137184977532, "critic_loss": 0.5805439722239971, "actor_loss": -92.6881670074463, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.683584451675415, "step": 51000}
{"episode_reward": 910.4816496247522, "episode": 52.0, "batch_reward": 0.5358665459156037, "critic_loss": 0.5541193656325341, "actor_loss": -92.13681764221191, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.98804235458374, "step": 52000}
{"episode_reward": 928.8105894275943, "episode": 53.0, "batch_reward": 0.5406018962860107, "critic_loss": 0.5572658888697625, "actor_loss": -91.91980242919922, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.381054639816284, "step": 53000}
{"episode_reward": 842.5642082965622, "episode": 54.0, "batch_reward": 0.5489237835407257, "critic_loss": 0.5554114246964454, "actor_loss": -91.61062748718261, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.1069974899292, "step": 54000}
{"episode_reward": 891.8679284773285, "episode": 55.0, "batch_reward": 0.5533026913404465, "critic_loss": 0.5273164533972741, "actor_loss": -91.30034809875488, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.648003339767456, "step": 55000}
{"episode_reward": 920.0682604439352, "episode": 56.0, "batch_reward": 0.5621986795961856, "critic_loss": 0.4873932510614395, "actor_loss": -91.22491493225098, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.901360750198364, "step": 56000}
{"episode_reward": 978.3176175795172, "episode": 57.0, "batch_reward": 0.5696783736050129, "critic_loss": 0.47207234808802606, "actor_loss": -91.03706730651855, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.53330135345459, "step": 57000}
{"episode_reward": 925.9375591315509, "episode": 58.0, "batch_reward": 0.5752322002351284, "critic_loss": 0.48186825612187384, "actor_loss": -90.86218852233887, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.75045156478882, "step": 58000}
{"episode_reward": 926.347298236755, "episode": 59.0, "batch_reward": 0.5811093713939189, "critic_loss": 0.45676412461698057, "actor_loss": -90.7535054321289, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.86507558822632, "step": 59000}
{"episode_reward": 942.9104281333482, "episode": 60.0, "batch_reward": 0.5861353070735932, "critic_loss": 0.46597729866206644, "actor_loss": -90.63288819885254, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.27858066558838, "step": 60000}
{"episode_reward": 869.7278181434928, "episode": 61.0, "batch_reward": 0.590919284582138, "critic_loss": 0.4797031229734421, "actor_loss": -90.46172718811034, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.464842557907104, "step": 61000}
{"episode_reward": 901.4844585883166, "episode": 62.0, "batch_reward": 0.5950296934247017, "critic_loss": 0.45886207655072214, "actor_loss": -90.38313702392578, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.746872663497925, "step": 62000}
{"episode_reward": 944.3329515294258, "episode": 63.0, "batch_reward": 0.6004601984620094, "critic_loss": 0.4564061751514673, "actor_loss": -90.2620322265625, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.72281837463379, "step": 63000}
{"episode_reward": 891.1364583269399, "episode": 64.0, "batch_reward": 0.6079076577723026, "critic_loss": 0.45273633995652196, "actor_loss": -90.31944493103028, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.579116344451904, "step": 64000}
{"episode_reward": 899.7554967218716, "episode": 65.0, "batch_reward": 0.6117338771224022, "critic_loss": 0.4658457668274641, "actor_loss": -90.12350708007813, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.70997428894043, "step": 65000}
{"episode_reward": 928.8093313159794, "episode": 66.0, "batch_reward": 0.6164624645113945, "critic_loss": 0.46103455206751826, "actor_loss": -90.11309724426269, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.31120204925537, "step": 66000}
{"episode_reward": 926.9216084582287, "episode": 67.0, "batch_reward": 0.620813097178936, "critic_loss": 0.4401000202447176, "actor_loss": -89.99170668029785, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.590314626693726, "step": 67000}
{"episode_reward": 915.0361241386681, "episode": 68.0, "batch_reward": 0.6249365012049675, "critic_loss": 0.4457093158811331, "actor_loss": -89.9333497467041, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.898751735687256, "step": 68000}
{"episode_reward": 957.2617342690605, "episode": 69.0, "batch_reward": 0.6317862643003463, "critic_loss": 0.4325183723717928, "actor_loss": -89.92182312011718, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.694189071655273, "step": 69000}
{"episode_reward": 942.1652967048492, "episode": 70.0, "batch_reward": 0.6338797923326492, "critic_loss": 0.4569662716239691, "actor_loss": -89.9592275238037, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.044330596923828, "step": 70000}
{"episode_reward": 889.1928351593007, "episode": 71.0, "batch_reward": 0.6359971458911896, "critic_loss": 0.44413440383970737, "actor_loss": -89.8706326751709, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.52060270309448, "step": 71000}
{"episode_reward": 913.6153282331644, "episode": 72.0, "batch_reward": 0.642887025475502, "critic_loss": 0.4279621053338051, "actor_loss": -89.95825500488282, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.05922245979309, "step": 72000}
{"episode_reward": 940.440993175349, "episode": 73.0, "batch_reward": 0.6440175857543945, "critic_loss": 0.43912441353499887, "actor_loss": -89.92509150695801, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.40708565711975, "step": 73000}
{"episode_reward": 890.2162954585143, "episode": 74.0, "batch_reward": 0.6483790687918664, "critic_loss": 0.42697022829949854, "actor_loss": -89.95841200256348, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.23787760734558, "step": 74000}
{"episode_reward": 924.3650165050542, "episode": 75.0, "batch_reward": 0.6559359403252601, "critic_loss": 0.42636520697176455, "actor_loss": -89.98132070922851, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.508114337921143, "step": 75000}
{"episode_reward": 927.2953218233547, "episode": 76.0, "batch_reward": 0.6570028470754623, "critic_loss": 0.44610542663931846, "actor_loss": -89.99230798339843, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.35909390449524, "step": 76000}
{"episode_reward": 933.441435941566, "episode": 77.0, "batch_reward": 0.6622098411917686, "critic_loss": 0.42609207424521445, "actor_loss": -89.86836026000977, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.752504110336304, "step": 77000}
{"episode_reward": 964.6081974611774, "episode": 78.0, "batch_reward": 0.6617913343310357, "critic_loss": 0.45089666163921355, "actor_loss": -89.78144166564941, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.868470907211304, "step": 78000}
{"episode_reward": 893.5505025684134, "episode": 79.0, "batch_reward": 0.6662567124962807, "critic_loss": 0.4121299988925457, "actor_loss": -89.82286166381836, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.058231592178345, "step": 79000}
{"episode_reward": 930.1107374950113, "episode": 80.0, "batch_reward": 0.6713548957705497, "critic_loss": 0.4136338419765234, "actor_loss": -90.00724198913574, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.385775566101074, "step": 80000}
{"episode_reward": 913.5584138834041, "episode": 81.0, "batch_reward": 0.674864944934845, "critic_loss": 0.407612873390317, "actor_loss": -89.90656965637207, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.968353509902954, "step": 81000}
{"episode_reward": 940.3448579822291, "episode": 82.0, "batch_reward": 0.6735467023849487, "critic_loss": 0.40109717661142347, "actor_loss": -89.77578262329102, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.06544280052185, "step": 82000}
{"episode_reward": 942.521877537172, "episode": 83.0, "batch_reward": 0.6776634758114815, "critic_loss": 0.4051039439886808, "actor_loss": -89.87992205810546, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.36011290550232, "step": 83000}
{"episode_reward": 832.785849091361, "episode": 84.0, "batch_reward": 0.6792720454335213, "critic_loss": 0.40885616624355314, "actor_loss": -89.84416259765625, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.0577495098114, "step": 84000}
{"episode_reward": 931.8688617172829, "episode": 85.0, "batch_reward": 0.6827583608627319, "critic_loss": 0.39121723529696467, "actor_loss": -89.68165921020508, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.78057026863098, "step": 85000}
{"episode_reward": 919.2835321515049, "episode": 86.0, "batch_reward": 0.6879811316132546, "critic_loss": 0.42162646894156935, "actor_loss": -89.99235682678223, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.522080183029175, "step": 86000}
{"episode_reward": 883.2956506359561, "episode": 87.0, "batch_reward": 0.6888064233660698, "critic_loss": 0.42133803510665896, "actor_loss": -89.97879231262208, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.380326747894287, "step": 87000}
{"episode_reward": 925.4890285334943, "episode": 88.0, "batch_reward": 0.6934455391764641, "critic_loss": 0.41440381489694117, "actor_loss": -90.02873622131348, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.54393172264099, "step": 88000}
{"episode_reward": 935.3447518930114, "episode": 89.0, "batch_reward": 0.696121456861496, "critic_loss": 0.411472174718976, "actor_loss": -90.01073657226563, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.30412459373474, "step": 89000}
{"episode_reward": 915.8692118678437, "episode": 90.0, "batch_reward": 0.697422442138195, "critic_loss": 0.41620551331341266, "actor_loss": -89.97973028564454, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.381805419921875, "step": 90000}
{"episode_reward": 961.8032533226457, "episode": 91.0, "batch_reward": 0.6994904129505157, "critic_loss": 0.41134502317011357, "actor_loss": -89.95481770324707, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.54667091369629, "step": 91000}
{"episode_reward": 891.8894938285526, "episode": 92.0, "batch_reward": 0.7032924202084542, "critic_loss": 0.42055884620547296, "actor_loss": -90.20563661193847, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.102332830429077, "step": 92000}
{"episode_reward": 939.6148497231238, "episode": 93.0, "batch_reward": 0.7064108726382256, "critic_loss": 0.4161768622994423, "actor_loss": -90.23986410522461, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.408940315246582, "step": 93000}
{"episode_reward": 974.8859003217718, "episode": 94.0, "batch_reward": 0.7073455033898354, "critic_loss": 0.39757997730374334, "actor_loss": -90.2044552307129, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.929649591445923, "step": 94000}
{"episode_reward": 931.8926469068123, "episode": 95.0, "batch_reward": 0.7103200583457947, "critic_loss": 0.3882215536683798, "actor_loss": -90.0575989074707, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.697047472000122, "step": 95000}
{"episode_reward": 919.038652721189, "episode": 96.0, "batch_reward": 0.7128014146089554, "critic_loss": 0.39500553366541863, "actor_loss": -90.42990586853027, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.389941215515137, "step": 96000}
{"episode_reward": 949.7362930646449, "episode": 97.0, "batch_reward": 0.7145512984395027, "critic_loss": 0.3838299737274647, "actor_loss": -90.3481678314209, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.422816038131714, "step": 97000}
{"episode_reward": 959.0607334509749, "episode": 98.0, "batch_reward": 0.718264799952507, "critic_loss": 0.38709689639508726, "actor_loss": -90.26391470336914, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.907298803329468, "step": 98000}
{"episode_reward": 936.8371560817839, "episode": 99.0, "batch_reward": 0.7204411432147027, "critic_loss": 0.3910746202170849, "actor_loss": -90.60813594055176, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.301295518875122, "step": 99000}
{"episode_reward": 932.7449042284982, "episode": 100.0, "batch_reward": 0.7194816908836364, "critic_loss": 0.38153852209448813, "actor_loss": -90.41240692138672, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.335174560546875, "step": 100000}
{"episode_reward": 888.011955204944, "episode": 101.0, "batch_reward": 0.7235028674602508, "critic_loss": 0.3847731337398291, "actor_loss": -90.58587028503418, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.451834201812744, "step": 101000}
{"episode_reward": 971.373241150399, "episode": 102.0, "batch_reward": 0.7266539213657379, "critic_loss": 0.40283082446455953, "actor_loss": -90.52297912597656, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.28212833404541, "step": 102000}
{"episode_reward": 943.2638039843353, "episode": 103.0, "batch_reward": 0.7281191285848617, "critic_loss": 0.3873220454752445, "actor_loss": -90.55572938537598, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.43526291847229, "step": 103000}
{"episode_reward": 956.8099770797932, "episode": 104.0, "batch_reward": 0.7307758324742317, "critic_loss": 0.37246142922341824, "actor_loss": -90.66412078857422, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.66477060317993, "step": 104000}
{"episode_reward": 922.2757970611752, "episode": 105.0, "batch_reward": 0.7307386212348937, "critic_loss": 0.36785935166478156, "actor_loss": -90.66090237426758, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.7572124004364, "step": 105000}
{"episode_reward": 924.7445567733217, "episode": 106.0, "batch_reward": 0.7329347608685494, "critic_loss": 0.3861265693753958, "actor_loss": -90.78365809631347, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.445118188858032, "step": 106000}
{"episode_reward": 920.7689226087641, "episode": 107.0, "batch_reward": 0.7350230462551117, "critic_loss": 0.3911574454754591, "actor_loss": -90.74573416137696, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.364246368408203, "step": 107000}
{"episode_reward": 924.5197425370245, "episode": 108.0, "batch_reward": 0.7369002777338028, "critic_loss": 0.3887571690678597, "actor_loss": -90.54765403747558, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.091388463974, "step": 108000}
{"episode_reward": 940.2918397472953, "episode": 109.0, "batch_reward": 0.7384561856389046, "critic_loss": 0.3747475526034832, "actor_loss": -90.75311991882324, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.454408884048462, "step": 109000}
{"episode_reward": 901.7846107364905, "episode": 110.0, "batch_reward": 0.7407173802256584, "critic_loss": 0.3756666617542505, "actor_loss": -90.82481803894044, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.41462755203247, "step": 110000}
{"episode_reward": 940.7720272319767, "episode": 111.0, "batch_reward": 0.7425119315385819, "critic_loss": 0.3709350461214781, "actor_loss": -90.62987867736817, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.64521312713623, "step": 111000}
{"episode_reward": 911.3514623077272, "episode": 112.0, "batch_reward": 0.7445428457260131, "critic_loss": 0.3895430314391851, "actor_loss": -90.94325483703614, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.943310260772705, "step": 112000}
{"episode_reward": 883.835733702098, "episode": 113.0, "batch_reward": 0.7467796872258187, "critic_loss": 0.3668231933414936, "actor_loss": -90.91910319519043, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.430854558944702, "step": 113000}
{"episode_reward": 939.38490700475, "episode": 114.0, "batch_reward": 0.7463863668441773, "critic_loss": 0.36054352374374865, "actor_loss": -90.94876190185546, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.79564619064331, "step": 114000}
{"episode_reward": 985.1520434315681, "episode": 115.0, "batch_reward": 0.7475665462613106, "critic_loss": 0.36754853278398514, "actor_loss": -90.93197639465332, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.087491035461426, "step": 115000}
{"episode_reward": 934.7355981409183, "episode": 116.0, "batch_reward": 0.7529242573976517, "critic_loss": 0.3699904404878616, "actor_loss": -91.02694883728027, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.499118328094482, "step": 116000}
{"episode_reward": 858.632366140795, "episode": 117.0, "batch_reward": 0.7514990314245223, "critic_loss": 0.3618519925028086, "actor_loss": -90.8853448791504, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.38855242729187, "step": 117000}
{"episode_reward": 919.6933882819047, "episode": 118.0, "batch_reward": 0.7525473862886429, "critic_loss": 0.3671061752438545, "actor_loss": -91.01862492370606, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.5344295501709, "step": 118000}
{"episode_reward": 917.4546628905264, "episode": 119.0, "batch_reward": 0.7566652999520301, "critic_loss": 0.38889009092748167, "actor_loss": -91.08119714355469, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.7285578250885, "step": 119000}
{"episode_reward": 908.3114665912067, "episode": 120.0, "batch_reward": 0.7569441323280335, "critic_loss": 0.36579451423883436, "actor_loss": -91.02661045837402, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.567147970199585, "step": 120000}
{"episode_reward": 940.1340736945427, "episode": 121.0, "batch_reward": 0.7555161957144737, "critic_loss": 0.3612821637243032, "actor_loss": -91.24268534851075, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.21930170059204, "step": 121000}
{"episode_reward": 924.645965252132, "episode": 122.0, "batch_reward": 0.7586165572404862, "critic_loss": 0.360093887552619, "actor_loss": -91.20406684875488, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.369025230407715, "step": 122000}
{"episode_reward": 927.0000926949065, "episode": 123.0, "batch_reward": 0.7596353711485863, "critic_loss": 0.3665535110235214, "actor_loss": -91.32204840087891, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.345340728759766, "step": 123000}
{"episode_reward": 949.3621719025645, "episode": 124.0, "batch_reward": 0.7627055950164795, "critic_loss": 0.3825228355824947, "actor_loss": -91.48116581726075, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.382253170013428, "step": 124000}
{"episode_reward": 928.4731538750164, "episode": 125.0, "batch_reward": 0.7643160632252693, "critic_loss": 0.37386816908419135, "actor_loss": -91.47348568725586, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.68450379371643, "step": 125000}
{"episode_reward": 938.5704441419789, "episode": 126.0, "batch_reward": 0.7644595374464989, "critic_loss": 0.35589707835763695, "actor_loss": -91.32526069641114, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.642322540283203, "step": 126000}
{"episode_reward": 923.193076113684, "episode": 127.0, "batch_reward": 0.7664154969453811, "critic_loss": 0.35728034099936484, "actor_loss": -91.51293878173828, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.416916131973267, "step": 127000}
{"episode_reward": 947.9300499473012, "episode": 128.0, "batch_reward": 0.7676756322383881, "critic_loss": 0.3498399996161461, "actor_loss": -91.5498439025879, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.420649766921997, "step": 128000}
{"episode_reward": 939.5982163426994, "episode": 129.0, "batch_reward": 0.7675636546611786, "critic_loss": 0.3514651094675064, "actor_loss": -91.38875561523437, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.705615282058716, "step": 129000}
{"episode_reward": 973.7631623294945, "episode": 130.0, "batch_reward": 0.7705327683091163, "critic_loss": 0.34610695783048867, "actor_loss": -91.5408388824463, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.07475781440735, "step": 130000}
{"episode_reward": 954.1754831399898, "episode": 131.0, "batch_reward": 0.7718081674575805, "critic_loss": 0.35200301590561867, "actor_loss": -91.48771112060547, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.450369358062744, "step": 131000}
{"episode_reward": 934.7048822837813, "episode": 132.0, "batch_reward": 0.7710379502773285, "critic_loss": 0.35282104659080504, "actor_loss": -91.58615530395508, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.778265476226807, "step": 132000}
{"episode_reward": 915.0602111388272, "episode": 133.0, "batch_reward": 0.7754407733082771, "critic_loss": 0.34623222237825396, "actor_loss": -91.51323063659667, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.5101375579834, "step": 133000}
{"episode_reward": 948.6093059635589, "episode": 134.0, "batch_reward": 0.7754640400409698, "critic_loss": 0.34831253117322925, "actor_loss": -91.54012341308594, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.548576593399048, "step": 134000}
{"episode_reward": 925.9292592170659, "episode": 135.0, "batch_reward": 0.7757275496721268, "critic_loss": 0.3531396640837193, "actor_loss": -91.68035476684571, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.76479458808899, "step": 135000}
{"episode_reward": 892.0511650862293, "episode": 136.0, "batch_reward": 0.7759016456604004, "critic_loss": 0.348924114882946, "actor_loss": -91.4898406829834, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.728564500808716, "step": 136000}
{"episode_reward": 911.7420377333914, "episode": 137.0, "batch_reward": 0.7767890697717666, "critic_loss": 0.3540938249230385, "actor_loss": -91.72868733215331, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.50870943069458, "step": 137000}
{"episode_reward": 956.8632042503432, "episode": 138.0, "batch_reward": 0.7809517301917076, "critic_loss": 0.32086090498417613, "actor_loss": -91.88582276916505, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.38351273536682, "step": 138000}
{"episode_reward": 961.2925046119112, "episode": 139.0, "batch_reward": 0.7812254076004028, "critic_loss": 0.32349622863531113, "actor_loss": -91.75985731506347, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.86407208442688, "step": 139000}
{"episode_reward": 944.4013724968131, "episode": 140.0, "batch_reward": 0.784365756034851, "critic_loss": 0.33183399750292303, "actor_loss": -91.91014535522461, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.753400802612305, "step": 140000}
{"episode_reward": 940.1226671676188, "episode": 141.0, "batch_reward": 0.7818168509602547, "critic_loss": 0.34503655160963537, "actor_loss": -91.81780134582519, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.26235604286194, "step": 141000}
{"episode_reward": 922.5847535323572, "episode": 142.0, "batch_reward": 0.782194383919239, "critic_loss": 0.3326185717880726, "actor_loss": -91.69890237426758, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.515465021133423, "step": 142000}
{"episode_reward": 939.2738494817747, "episode": 143.0, "batch_reward": 0.7819582342505454, "critic_loss": 0.3499653333723545, "actor_loss": -91.68167881774902, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.787388801574707, "step": 143000}
{"episode_reward": 937.2031867979658, "episode": 144.0, "batch_reward": 0.7868103283643723, "critic_loss": 0.3508145453184843, "actor_loss": -91.83079566955567, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.565788984298706, "step": 144000}
{"episode_reward": 900.149705508072, "episode": 145.0, "batch_reward": 0.7864610068798065, "critic_loss": 0.34971735836565493, "actor_loss": -91.93443821716309, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.389780521392822, "step": 145000}
{"episode_reward": 900.6788000807189, "episode": 146.0, "batch_reward": 0.7875509814620018, "critic_loss": 0.3475440121144056, "actor_loss": -92.02289009094238, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.704771518707275, "step": 146000}
{"episode_reward": 955.3585237517352, "episode": 147.0, "batch_reward": 0.7887463141679764, "critic_loss": 0.3446585426181555, "actor_loss": -91.94682292175293, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.260265588760376, "step": 147000}
{"episode_reward": 923.6945188520963, "episode": 148.0, "batch_reward": 0.7895119296908378, "critic_loss": 0.33994874608516695, "actor_loss": -91.97429969787598, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.449089765548706, "step": 148000}
{"episode_reward": 909.8343360320338, "episode": 149.0, "batch_reward": 0.7894787746071815, "critic_loss": 0.3341361247301102, "actor_loss": -91.9853370513916, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.74842071533203, "step": 149000}
{"episode_reward": 985.3365395234047, "episode": 150.0, "batch_reward": 0.7915362882018089, "critic_loss": 0.3228470993191004, "actor_loss": -91.99559007263184, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "step": 150000}
