{"episode": 1.0, "duration": 24.15853190422058, "episode_reward": 29.08591335645728, "step": 1000}
{"episode": 2.0, "duration": 2.1744282245635986, "episode_reward": 898.6342244091321, "step": 2000}
{"episode": 3.0, "batch_reward": 0.4363528330819374, "actor_loss": -83.7405548706299, "actor_target_entropy": -6.0, "alpha_value": 0.002642586817083679, "duration": 50.25229024887085, "episode_reward": 27.811039515407888, "step": 3000}
{"episode": 4.0, "batch_reward": 0.2798111531734467, "actor_loss": -75.95366168212891, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.860172033309937, "episode_reward": 28.234453938084805, "step": 4000}
{"episode": 5.0, "batch_reward": 0.22446040743589402, "actor_loss": -73.56333720397949, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.040995836257935, "episode_reward": 30.68687034544659, "step": 5000}
{"episode": 6.0, "batch_reward": 0.18889136512577534, "actor_loss": -72.2154666595459, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.56927752494812, "episode_reward": 30.914720217237694, "step": 6000}
{"episode": 7.0, "batch_reward": 0.16537880787998438, "actor_loss": -71.13726190185547, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.600603818893433, "episode_reward": 29.402444164546704, "step": 7000}
{"episode": 8.0, "batch_reward": 0.1459100186266005, "actor_loss": -70.33995465087891, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 15.964693069458008, "episode_reward": 30.260198425592737, "step": 8000}
{"episode": 9.0, "batch_reward": 0.13104499454423785, "actor_loss": -69.82945701599121, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.535102128982544, "episode_reward": 14.790059833825344, "step": 9000}
{"episode": 10.0, "batch_reward": 0.1200673082061112, "actor_loss": -64.58347908020019, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 3977.484136581421, "episode_reward": 33.320198038528375, "step": 10000}
{"episode": 11.0, "batch_reward": 0.11174801840633154, "actor_loss": -64.06903742980957, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 37.199723958969116, "episode_reward": 28.158930425413224, "step": 11000}
{"episode": 12.0, "batch_reward": 0.10369812058284879, "actor_loss": -61.745654190063476, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 443.6781315803528, "episode_reward": 13.876284035851262, "step": 12000}
{"episode": 13.0, "batch_reward": 0.09675621914118529, "actor_loss": -61.50287632751465, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.19831919670105, "episode_reward": 28.23436022882193, "step": 13000}
{"episode": 14.0, "batch_reward": 0.09160033278167248, "actor_loss": -60.86169683074951, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 436.26099371910095, "episode_reward": 31.6054021797294, "step": 14000}
{"episode": 15.0, "batch_reward": 0.08779646663367749, "actor_loss": -60.881958389282225, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.571901321411133, "episode_reward": 15.151585591761998, "step": 15000}
{"episode": 16.0, "batch_reward": 0.08341544653475284, "actor_loss": -60.97083390045166, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 433.82825446128845, "episode_reward": 14.259847360912149, "step": 16000}
{"episode": 17.0, "batch_reward": 0.078541230911389, "actor_loss": -61.27141899871826, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.04087495803833, "episode_reward": 15.470006920129832, "step": 17000}
{"episode": 18.0, "batch_reward": 0.07529102624766529, "actor_loss": -59.08105280303955, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 436.8531017303467, "episode_reward": 29.20889943558214, "step": 18000}
{"episode": 19.0, "batch_reward": 0.07191560319624841, "actor_loss": -59.5130378036499, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.909183979034424, "episode_reward": 25.99114839863284, "step": 19000}
{"episode": 20.0, "batch_reward": 0.07043403089977801, "actor_loss": -60.06521231079102, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 431.5767171382904, "episode_reward": 14.586130717509887, "step": 20000}
{"episode": 21.0, "batch_reward": 0.06703061123192311, "actor_loss": -60.14223471069336, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 39.585439920425415, "episode_reward": 14.178120565772614, "step": 21000}
{"episode": 22.0, "batch_reward": 0.06510996077023447, "actor_loss": -59.08858820343018, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 436.4244701862335, "episode_reward": 13.965054835473035, "step": 22000}
{"episode": 23.0, "batch_reward": 0.06265802312642337, "actor_loss": -58.999215606689454, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.10896062850952, "episode_reward": 22.028787950790907, "step": 23000}
{"episode": 24.0, "batch_reward": 0.06162372846715152, "actor_loss": -59.70970404052734, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 430.4220881462097, "episode_reward": 56.93033868625031, "step": 24000}
{"episode": 25.0, "batch_reward": 0.061444389583542945, "actor_loss": -62.43577834320068, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.073171615600586, "episode_reward": 59.1641881232601, "step": 25000}
{"episode": 26.0, "batch_reward": 0.06082600039802492, "actor_loss": -60.16695421600342, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 438.5216007232666, "episode_reward": 17.737631947130723, "step": 26000}
{"episode": 27.0, "batch_reward": 0.05773101581819356, "actor_loss": -59.72974075317383, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.272965669631958, "episode_reward": 31.532428255881406, "step": 27000}
{"episode": 28.0, "batch_reward": 0.058618598276749256, "actor_loss": -58.60310289001465, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 441.7301561832428, "episode_reward": 53.038395571417986, "step": 28000}
{"episode": 29.0, "batch_reward": 0.05836434038355946, "actor_loss": -58.461032508850096, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.925700426101685, "episode_reward": 15.148758975470583, "step": 29000}
{"episode": 30.0, "batch_reward": 0.05667098910920322, "actor_loss": -56.55111631011963, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 433.5417923927307, "episode_reward": 11.033962815662775, "step": 30000}
{"episode": 31.0, "batch_reward": 0.055407055521383884, "actor_loss": -56.62437237548828, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 39.974539041519165, "episode_reward": 46.57333555543795, "step": 31000}
{"episode": 32.0, "batch_reward": 0.05517365255765617, "actor_loss": -57.67223069000244, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 436.32731461524963, "episode_reward": 59.12759197087903, "step": 32000}
{"episode": 33.0, "batch_reward": 0.054619456129148605, "actor_loss": -58.15542902374268, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.158127784729004, "episode_reward": 23.75547694811971, "step": 33000}
{"episode": 34.0, "batch_reward": 0.05374928659386933, "actor_loss": -59.88274557495117, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 438.6720130443573, "episode_reward": 23.344334568375444, "step": 34000}
{"episode": 35.0, "batch_reward": 0.05308622610941529, "actor_loss": -60.340623947143555, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.653066873550415, "episode_reward": 24.185339289484407, "step": 35000}
{"episode": 36.0, "batch_reward": 0.051959397030994295, "actor_loss": -60.22127736663818, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 434.1722323894501, "episode_reward": 23.85062427812077, "step": 36000}
{"episode": 37.0, "batch_reward": 0.05110203267261386, "actor_loss": -60.648037544250485, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.601547956466675, "episode_reward": 24.10036854220915, "step": 37000}
{"episode": 38.0, "batch_reward": 0.050697167202830316, "actor_loss": -61.28171781158447, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 440.8125901222229, "episode_reward": 11.19005443432933, "step": 38000}
{"episode": 39.0, "batch_reward": 0.049821781378239394, "actor_loss": -61.419953483581544, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.256964921951294, "episode_reward": 24.341754895479575, "step": 39000}
{"episode": 40.0, "batch_reward": 0.04874124544858933, "actor_loss": -61.71904724121094, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 435.2075560092926, "episode_reward": 13.28982915377981, "step": 40000}
{"episode": 41.0, "batch_reward": 0.047323475267738106, "actor_loss": -61.565754867553714, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 38.57284092903137, "episode_reward": 11.130067318733202, "step": 41000}
{"episode": 42.0, "batch_reward": 0.04797475455328822, "actor_loss": -62.19563798522949, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 431.7982804775238, "episode_reward": 58.88443041664707, "step": 42000}
{"episode": 43.0, "batch_reward": 0.0475792729742825, "actor_loss": -62.550482810974124, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.254900455474854, "episode_reward": 11.388955214291292, "step": 43000}
{"episode": 44.0, "batch_reward": 0.045727606017142534, "actor_loss": -61.62264869689941, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 431.9247398376465, "episode_reward": 23.710050318872632, "step": 44000}
{"episode": 45.0, "batch_reward": 0.04625114718452096, "actor_loss": -61.97839422607422, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.217132329940796, "episode_reward": 24.237606177791566, "step": 45000}
{"episode": 46.0, "batch_reward": 0.04512122177891433, "actor_loss": -61.39346457672119, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 436.78880167007446, "episode_reward": 11.576674182672802, "step": 46000}
{"episode": 47.0, "batch_reward": 0.04503630323894322, "actor_loss": -61.486340103149416, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.074949741363525, "episode_reward": 24.460830341348398, "step": 47000}
{"episode": 48.0, "batch_reward": 0.044636956429108976, "actor_loss": -62.434978645324705, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 433.9879710674286, "episode_reward": 23.71755651945711, "step": 48000}
{"episode": 49.0, "batch_reward": 0.04400054043903947, "actor_loss": -62.470659606933594, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.075318574905396, "episode_reward": 13.352948851873126, "step": 49000}
{"episode": 50.0, "batch_reward": 0.04252517883293331, "actor_loss": -60.35304963684082, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 432.9394483566284, "episode_reward": 10.513944089269327, "step": 50000}
{"episode": 51.0, "batch_reward": 0.042679639687761665, "actor_loss": -60.311343879699706, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 37.603145360946655, "episode_reward": 11.300385659065611, "step": 51000}
{"episode": 52.0, "batch_reward": 0.04242984722554684, "actor_loss": -60.761199150085446, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 438.6898672580719, "episode_reward": 10.843902805659939, "step": 52000}
{"episode": 53.0, "batch_reward": 0.04170011904463172, "actor_loss": -60.811906463623046, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.419694423675537, "episode_reward": 24.262915075453986, "step": 53000}
{"episode": 54.0, "batch_reward": 0.042429848793894054, "actor_loss": -62.59863556671142, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 435.25043416023254, "episode_reward": 63.71242612851628, "step": 54000}
{"episode": 55.0, "batch_reward": 0.042889031533151864, "actor_loss": -62.44549005126953, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.553895711898804, "episode_reward": 101.31404958233705, "step": 55000}
{"episode": 56.0, "batch_reward": 0.042903284607455135, "actor_loss": -62.262708938598635, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 436.3886468410492, "episode_reward": 25.95466409387936, "step": 56000}
{"episode": 57.0, "batch_reward": 0.042625562028959396, "actor_loss": -62.63772927093506, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.868704319000244, "episode_reward": 23.479859299046574, "step": 57000}
{"episode": 58.0, "batch_reward": 0.04222500767558813, "actor_loss": -63.278371871948245, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 437.3834402561188, "episode_reward": 33.247181689143964, "step": 58000}
{"episode": 59.0, "batch_reward": 0.04247702320106327, "actor_loss": -63.49175064849854, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.305450201034546, "episode_reward": 69.9899488391542, "step": 59000}
{"episode": 60.0, "batch_reward": 0.042894974712282416, "actor_loss": -62.97174070739746, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 432.51895475387573, "episode_reward": 110.23978507586358, "step": 60000}
{"episode": 61.0, "batch_reward": 0.04463668349198997, "actor_loss": -63.01152509307861, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 37.61905121803284, "episode_reward": 103.5798861779404, "step": 61000}
{"episode": 62.0, "batch_reward": 0.04501410519517958, "actor_loss": -62.12499079895019, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 438.8869524002075, "episode_reward": 42.77512235554471, "step": 62000}
{"episode": 63.0, "batch_reward": 0.04539285408332944, "actor_loss": -62.263144271850585, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.9988214969635, "episode_reward": 113.33295382310719, "step": 63000}
{"episode": 64.0, "batch_reward": 0.04593585447594523, "actor_loss": -63.446774452209475, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 431.7880012989044, "episode_reward": 66.73860282402592, "step": 64000}
{"episode": 65.0, "batch_reward": 0.046417793938890096, "actor_loss": -63.71642179107666, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.256529569625854, "episode_reward": 24.622642324723536, "step": 65000}
{"episode": 66.0, "batch_reward": 0.04654380737617612, "actor_loss": -62.85494766998291, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 435.82388734817505, "episode_reward": 53.92604337366828, "step": 66000}
{"episode": 67.0, "batch_reward": 0.04566102119162679, "actor_loss": -63.16934127044678, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.759456634521484, "episode_reward": 24.496026168965194, "step": 67000}
{"episode": 68.0, "batch_reward": 0.045544807402417065, "actor_loss": -63.69979571533203, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 435.78844809532166, "episode_reward": 24.4503132393585, "step": 68000}
{"episode": 69.0, "batch_reward": 0.04589235425181687, "actor_loss": -63.89375482177734, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.988386631011963, "episode_reward": 149.82334222650903, "step": 69000}
{"episode": 70.0, "batch_reward": 0.046726983370259406, "actor_loss": -65.41866463470458, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 431.2381839752197, "episode_reward": 79.85340336751231, "step": 70000}
{"episode": 71.0, "batch_reward": 0.04759159180335701, "actor_loss": -65.61432566833496, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 36.27827072143555, "episode_reward": 89.40237938000855, "step": 71000}
{"episode": 72.0, "batch_reward": 0.04803687651082873, "actor_loss": -64.62579776763916, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 436.920437335968, "episode_reward": 60.86575410975579, "step": 72000}
{"episode": 73.0, "batch_reward": 0.04843884667381644, "actor_loss": -64.4929990234375, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.279560565948486, "episode_reward": 76.873806031847, "step": 73000}
{"episode": 74.0, "batch_reward": 0.04866187776811421, "actor_loss": -65.28861829376221, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 433.16594910621643, "episode_reward": 57.69160391067911, "step": 74000}
{"episode": 75.0, "batch_reward": 0.04915793594717979, "actor_loss": -65.45105933380127, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.04227304458618, "episode_reward": 100.21792226938511, "step": 75000}
{"episode": 76.0, "batch_reward": 0.04914186610467732, "actor_loss": -65.88660012817382, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 433.34796953201294, "episode_reward": 23.628327134239978, "step": 76000}
{"episode": 77.0, "batch_reward": 0.049268784673884514, "actor_loss": -66.08740182495117, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.1727135181427, "episode_reward": 53.535702116600596, "step": 77000}
{"episode": 78.0, "batch_reward": 0.04877203236147761, "actor_loss": -66.4674952545166, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 438.71514439582825, "episode_reward": 24.049517830635676, "step": 78000}
{"episode": 79.0, "batch_reward": 0.04866129848361015, "actor_loss": -66.82545767211914, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.033697605133057, "episode_reward": 23.438795399071697, "step": 79000}
{"episode": 80.0, "batch_reward": 0.04800929148495197, "actor_loss": -67.52310983276367, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 436.58799862861633, "episode_reward": 24.20922089764945, "step": 80000}
{"episode": 81.0, "batch_reward": 0.04809682353399694, "actor_loss": -67.69122941589356, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 38.39803385734558, "episode_reward": 92.44179353962288, "step": 81000}
{"episode": 82.0, "batch_reward": 0.04938544786348939, "actor_loss": -64.51552140045166, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 440.47696590423584, "episode_reward": 147.1615742217854, "step": 82000}
{"episode": 83.0, "batch_reward": 0.049472095619887115, "actor_loss": -64.5964626235962, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.325560331344604, "episode_reward": 24.380985327762023, "step": 83000}
{"episode": 84.0, "batch_reward": 0.04946255819872022, "actor_loss": -63.94612210083008, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 435.9965431690216, "episode_reward": 75.53906292929523, "step": 84000}
{"episode": 85.0, "batch_reward": 0.04986548288725316, "actor_loss": -64.16546208953858, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.796504497528076, "episode_reward": 24.41063249795568, "step": 85000}
{"episode": 86.0, "batch_reward": 0.048967074804008005, "actor_loss": -64.86108283996582, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 439.0262100696564, "episode_reward": 23.644855116310588, "step": 86000}
{"episode": 87.0, "batch_reward": 0.049692111926153304, "actor_loss": -65.1941775894165, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.832587718963623, "episode_reward": 23.021487619092056, "step": 87000}
{"episode": 88.0, "batch_reward": 0.04924973893724382, "actor_loss": -66.9896909942627, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 436.01490926742554, "episode_reward": 101.57725778524997, "step": 88000}
{"episode": 89.0, "batch_reward": 0.0489782805275172, "actor_loss": -67.16349408721923, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.11394691467285, "episode_reward": 23.713465047724945, "step": 89000}
{"episode": 90.0, "batch_reward": 0.04945236533135176, "actor_loss": -66.0282906112671, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 440.38042664527893, "episode_reward": 61.381555302294686, "step": 90000}
{"episode": 91.0, "batch_reward": 0.04943162186257541, "actor_loss": -66.19498036193848, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 37.57946801185608, "episode_reward": 123.89875604171728, "step": 91000}
{"episode": 92.0, "batch_reward": 0.05056855308078229, "actor_loss": -66.37895894622802, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 425.2784798145294, "episode_reward": 89.60198377618262, "step": 92000}
{"episode": 93.0, "batch_reward": 0.050241522055119274, "actor_loss": -66.46571766662598, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.36074423789978, "episode_reward": 36.306699278189484, "step": 93000}
{"episode": 94.0, "batch_reward": 0.05021379167959094, "actor_loss": -66.85748840332032, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 431.10358357429504, "episode_reward": 24.338251859650434, "step": 94000}
{"episode": 95.0, "batch_reward": 0.04985433212667704, "actor_loss": -66.98586134338379, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.716797828674316, "episode_reward": 23.81304265941965, "step": 95000}
{"episode": 96.0, "batch_reward": 0.050283602602779864, "actor_loss": -67.6440122833252, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 437.6612010002136, "episode_reward": 24.08348622290376, "step": 96000}
{"episode": 97.0, "batch_reward": 0.049243981532752515, "actor_loss": -67.75507223510742, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.715677738189697, "episode_reward": 24.217074999223236, "step": 97000}
{"episode": 98.0, "batch_reward": 0.04915338961035013, "actor_loss": -67.99956161499023, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 432.47894835472107, "episode_reward": 23.86754758831525, "step": 98000}
{"episode": 99.0, "batch_reward": 0.04937289182841778, "actor_loss": -68.06404193115235, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.42723798751831, "episode_reward": 131.91676667921448, "step": 99000}
{"episode": 100.0, "batch_reward": 0.049847154792398214, "actor_loss": -68.3678984375, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 441.73460960388184, "episode_reward": 24.71329306863317, "step": 100000}
{"episode": 101.0, "batch_reward": 0.050538548462092873, "actor_loss": -68.58503967285156, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 38.86871385574341, "episode_reward": 214.73546819525805, "step": 101000}
{"episode": 102.0, "batch_reward": 0.05119628419354558, "actor_loss": -69.2741053161621, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 431.8856554031372, "episode_reward": 24.224593026351826, "step": 102000}
{"episode": 103.0, "batch_reward": 0.050516545340418814, "actor_loss": -69.50049984741212, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.290120601654053, "episode_reward": 23.748450094052025, "step": 103000}
{"episode": 104.0, "batch_reward": 0.050414057046175006, "actor_loss": -67.98561936950684, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 437.3388750553131, "episode_reward": 23.395493669850758, "step": 104000}
{"episode": 105.0, "batch_reward": 0.05075824239850044, "actor_loss": -68.14454515075684, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.741642475128174, "episode_reward": 101.13519165878016, "step": 105000}
{"episode": 106.0, "batch_reward": 0.05088032938912511, "actor_loss": -69.17351692199708, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 437.7753643989563, "episode_reward": 60.28870521336425, "step": 106000}
{"episode": 107.0, "batch_reward": 0.05260110653564334, "actor_loss": -69.39549356079101, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.10733199119568, "episode_reward": 180.8058774505775, "step": 107000}
{"episode": 108.0, "batch_reward": 0.052319516597315666, "actor_loss": -68.46821228027343, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 435.97075939178467, "episode_reward": 22.96529516829346, "step": 108000}
{"episode": 109.0, "batch_reward": 0.05192656372115016, "actor_loss": -68.45057110595702, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.553046464920044, "episode_reward": 22.97831920015, "step": 109000}
{"episode": 110.0, "batch_reward": 0.0518210851252079, "actor_loss": -69.85182461547852, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 438.7912817001343, "episode_reward": 24.184784308114576, "step": 110000}
{"episode": 111.0, "batch_reward": 0.05121857335790992, "actor_loss": -69.87909577941895, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 36.48186993598938, "episode_reward": 68.62275034157814, "step": 111000}
{"episode": 112.0, "batch_reward": 0.052136820022016764, "actor_loss": -69.8413717956543, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 434.50772857666016, "episode_reward": 103.09234858053566, "step": 112000}
{"episode": 113.0, "batch_reward": 0.052842668171972036, "actor_loss": -69.98185359191895, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.98296594619751, "episode_reward": 199.22806037269882, "step": 113000}
{"episode": 114.0, "batch_reward": 0.052956673039123416, "actor_loss": -68.5713501739502, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 437.51697182655334, "episode_reward": 31.235024041823173, "step": 114000}
{"episode": 115.0, "batch_reward": 0.05307964302971959, "actor_loss": -68.57221759033203, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.076449871063232, "episode_reward": 23.82788729479416, "step": 115000}
{"episode": 116.0, "batch_reward": 0.05268176483735442, "actor_loss": -68.07952124023437, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 441.30321049690247, "episode_reward": 23.9674536524052, "step": 116000}
{"episode": 117.0, "batch_reward": 0.05263920828327537, "actor_loss": -67.95983375549316, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.011167764663696, "episode_reward": 23.79695692946528, "step": 117000}
{"episode": 118.0, "batch_reward": 0.052761953897774216, "actor_loss": -68.89927995300293, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 433.1151695251465, "episode_reward": 23.61599782145064, "step": 118000}
{"episode": 119.0, "batch_reward": 0.052013384379446505, "actor_loss": -68.86046292114258, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.94630455970764, "episode_reward": 28.996747695118074, "step": 119000}
{"episode": 120.0, "batch_reward": 0.052434801954776046, "actor_loss": -67.95504400634766, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 437.35849237442017, "episode_reward": 188.93842919062664, "step": 120000}
{"episode": 121.0, "batch_reward": 0.053393340356647966, "actor_loss": -68.05772415161132, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 35.57285833358765, "episode_reward": 24.161478719561842, "step": 121000}
{"episode": 122.0, "batch_reward": 0.05256922992691398, "actor_loss": -68.18720227050781, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 435.66554069519043, "episode_reward": 22.872260783933537, "step": 122000}
{"episode": 123.0, "batch_reward": 0.052944786965847014, "actor_loss": -68.1883402709961, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.35776710510254, "episode_reward": 119.08631191745525, "step": 123000}
{"episode": 124.0, "batch_reward": 0.053701099529862406, "actor_loss": -69.25112646484375, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 431.4949595928192, "episode_reward": 191.2117437202403, "step": 124000}
{"episode": 125.0, "batch_reward": 0.05394019133970141, "actor_loss": -69.39289393615722, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.20057463645935, "episode_reward": 27.94554579556646, "step": 125000}
{"episode": 126.0, "batch_reward": 0.054520233977586034, "actor_loss": -69.55293693542481, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 433.57218742370605, "episode_reward": 93.06815556459289, "step": 126000}
{"episode": 127.0, "batch_reward": 0.054251868322491646, "actor_loss": -69.3203607635498, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.764075994491577, "episode_reward": 37.441270890541134, "step": 127000}
{"episode": 128.0, "batch_reward": 0.05434051503241062, "actor_loss": -70.47843029785156, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 434.0087389945984, "episode_reward": 23.579176865702728, "step": 128000}
{"episode": 129.0, "batch_reward": 0.055082923199981454, "actor_loss": -70.6374243774414, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.74715304374695, "episode_reward": 215.01211013005386, "step": 129000}
{"episode": 130.0, "batch_reward": 0.05492422622814774, "actor_loss": -69.50417268371582, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 428.1671760082245, "episode_reward": 24.040569625508, "step": 130000}
{"episode": 131.0, "batch_reward": 0.05490855579078197, "actor_loss": -69.53951931762695, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 36.85101103782654, "episode_reward": 24.191838267597962, "step": 131000}
{"episode": 132.0, "batch_reward": 0.05495141215249896, "actor_loss": -69.3080337524414, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 437.6819348335266, "episode_reward": 113.93222607315971, "step": 132000}
{"episode": 133.0, "batch_reward": 0.055141865260899064, "actor_loss": -69.40319577026368, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.637297868728638, "episode_reward": 23.528217396290763, "step": 133000}
{"episode": 134.0, "batch_reward": 0.05512229273840785, "actor_loss": -68.85589961242675, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 424.9453799724579, "episode_reward": 23.709445399953655, "step": 134000}
{"episode": 135.0, "batch_reward": 0.05443393013626337, "actor_loss": -68.91133470153808, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.287787914276123, "episode_reward": 124.56687562182286, "step": 135000}
{"episode": 136.0, "batch_reward": 0.05504235695302486, "actor_loss": -69.49818141174316, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 433.78152298927307, "episode_reward": 52.72717528070827, "step": 136000}
{"episode": 137.0, "batch_reward": 0.056251037124544385, "actor_loss": -69.62512013244628, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.952558040618896, "episode_reward": 171.4068360967032, "step": 137000}
{"episode": 138.0, "batch_reward": 0.05631837387382984, "actor_loss": -69.28885325622558, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 432.0830020904541, "episode_reward": 117.81328392614238, "step": 138000}
{"episode": 139.0, "batch_reward": 0.05665198483690619, "actor_loss": -69.34093659973145, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.189409255981445, "episode_reward": 23.78935156152504, "step": 139000}
{"episode": 140.0, "batch_reward": 0.05686794085800648, "actor_loss": -69.20085627746582, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 428.2645447254181, "episode_reward": 141.1096162089999, "step": 140000}
{"episode": 141.0, "batch_reward": 0.057645301651209596, "actor_loss": -69.37140596008301, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 35.11602330207825, "episode_reward": 127.36202744251092, "step": 141000}
{"episode": 142.0, "batch_reward": 0.057556582532823086, "actor_loss": -69.61602403259278, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 427.8199031352997, "episode_reward": 29.901193065079557, "step": 142000}
{"episode": 143.0, "batch_reward": 0.05748472123220563, "actor_loss": -69.67023542785644, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.837093114852905, "episode_reward": 23.71798481342815, "step": 143000}
{"episode": 144.0, "batch_reward": 0.05675911220908165, "actor_loss": -69.41003254699707, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 437.19563388824463, "episode_reward": 34.11728065073976, "step": 144000}
{"episode": 145.0, "batch_reward": 0.056988863322883845, "actor_loss": -69.5215871887207, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.4524142742157, "episode_reward": 181.11579122833103, "step": 145000}
{"episode": 146.0, "batch_reward": 0.057451456785202026, "actor_loss": -69.7210119934082, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 433.70200777053833, "episode_reward": 24.819920266883855, "step": 146000}
{"episode": 147.0, "batch_reward": 0.05754168974235654, "actor_loss": -69.77717671203614, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.79124689102173, "episode_reward": 23.805869131059737, "step": 147000}
{"episode": 148.0, "batch_reward": 0.05664159358665347, "actor_loss": -69.19606158447266, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 432.7461025714874, "episode_reward": 23.487354663858508, "step": 148000}
{"episode": 149.0, "batch_reward": 0.05755346826836467, "actor_loss": -69.61789721679688, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.972121477127075, "episode_reward": 229.93463768652626, "step": 149000}
{"episode": 150.0, "batch_reward": 0.05788096415251493, "actor_loss": -69.72445252990723, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "step": 150000}
