{"episode_reward": 0.0, "episode": 1.0, "duration": 20.895939350128174, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.8170890808105469, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.458340879021664, "critic_loss": 0.14688528886250593, "actor_loss": -83.65422254106721, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 59.29097032546997, "step": 3000}
{"episode_reward": 257.9435323647985, "episode": 4.0, "batch_reward": 0.41567459484934804, "critic_loss": 0.37794148233532904, "actor_loss": -83.318148147583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.86437702178955, "step": 4000}
{"episode_reward": 575.4297763252428, "episode": 5.0, "batch_reward": 0.42031775692105294, "critic_loss": 0.38457285809516906, "actor_loss": -83.53513688659667, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.83525061607361, "step": 5000}
{"episode_reward": 150.78621919527114, "episode": 6.0, "batch_reward": 0.4049351937174797, "critic_loss": 0.6644677052646876, "actor_loss": -82.74715475463867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.826553344726562, "step": 6000}
{"episode_reward": 546.6574314783876, "episode": 7.0, "batch_reward": 0.39880253133177757, "critic_loss": 0.7022406135499477, "actor_loss": -82.38523017883301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.87119436264038, "step": 7000}
{"episode_reward": 167.33171641895626, "episode": 8.0, "batch_reward": 0.38562704238295553, "critic_loss": 1.2133419866859914, "actor_loss": -82.43405757141113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.856231689453125, "step": 8000}
{"episode_reward": 565.0595430534745, "episode": 9.0, "batch_reward": 0.3946622822880745, "critic_loss": 1.290265890598297, "actor_loss": -82.04443608093261, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.851202726364136, "step": 9000}
{"episode_reward": 217.4572098451821, "episode": 10.0, "batch_reward": 0.3999301177561283, "critic_loss": 1.366326359808445, "actor_loss": -82.03456480407715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.837287664413452, "step": 10000}
{"episode_reward": 804.7623713918539, "episode": 11.0, "batch_reward": 0.4329601821899414, "critic_loss": 1.5432496565580367, "actor_loss": -82.6681326599121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.38036847114563, "step": 11000}
{"episode_reward": 685.7614240498781, "episode": 12.0, "batch_reward": 0.4459253205060959, "critic_loss": 1.7250356305241585, "actor_loss": -83.00876707458497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.825743913650513, "step": 12000}
{"episode_reward": 582.3085299977765, "episode": 13.0, "batch_reward": 0.45122728508710863, "critic_loss": 1.7281625936627387, "actor_loss": -83.01362518310548, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.83243417739868, "step": 13000}
{"episode_reward": 500.8905730264166, "episode": 14.0, "batch_reward": 0.4705742253661156, "critic_loss": 1.720765618979931, "actor_loss": -83.44757736206054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.828957557678223, "step": 14000}
{"episode_reward": 782.2059501424505, "episode": 15.0, "batch_reward": 0.4978498101532459, "critic_loss": 1.8111838986873627, "actor_loss": -83.03578620147705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.81019639968872, "step": 15000}
{"episode_reward": 898.7278344265795, "episode": 16.0, "batch_reward": 0.5215718726813793, "critic_loss": 1.7361588525176048, "actor_loss": -84.68924057006836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.803463220596313, "step": 16000}
{"episode_reward": 874.4843946612094, "episode": 17.0, "batch_reward": 0.5404176741242409, "critic_loss": 1.7352567036151887, "actor_loss": -84.67344432067871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.793753623962402, "step": 17000}
{"episode_reward": 795.9367331993494, "episode": 18.0, "batch_reward": 0.5553201037347317, "critic_loss": 1.9663170861005783, "actor_loss": -85.18337799072266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.850127458572388, "step": 18000}
{"episode_reward": 820.3510238599935, "episode": 19.0, "batch_reward": 0.5696862525641918, "critic_loss": 1.853100058913231, "actor_loss": -85.62208155822753, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.855237245559692, "step": 19000}
{"episode_reward": 842.2715758391228, "episode": 20.0, "batch_reward": 0.5855696090757847, "critic_loss": 1.727486596107483, "actor_loss": -85.08140809631348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.8501033782959, "step": 20000}
{"episode_reward": 817.9537654706801, "episode": 21.0, "batch_reward": 0.5964003928005696, "critic_loss": 1.631107527732849, "actor_loss": -85.55005172729493, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.35889911651611, "step": 21000}
{"episode_reward": 888.3553601824387, "episode": 22.0, "batch_reward": 0.6111658523082734, "critic_loss": 1.5816949687600135, "actor_loss": -85.65229054260254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.849549055099487, "step": 22000}
{"episode_reward": 889.4974134041183, "episode": 23.0, "batch_reward": 0.622336419582367, "critic_loss": 1.5679607872366905, "actor_loss": -86.41288069152831, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.848565340042114, "step": 23000}
{"episode_reward": 864.5262069726841, "episode": 24.0, "batch_reward": 0.6341954910159111, "critic_loss": 1.5373989093899727, "actor_loss": -86.62167492675782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.94258427619934, "step": 24000}
{"episode_reward": 913.6274420612767, "episode": 25.0, "batch_reward": 0.6448646721243858, "critic_loss": 1.4487598747015, "actor_loss": -87.52325718688965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.099692821502686, "step": 25000}
{"episode_reward": 891.408943768356, "episode": 26.0, "batch_reward": 0.6534702904820442, "critic_loss": 1.4460587624311447, "actor_loss": -87.14653556823731, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.819296836853027, "step": 26000}
{"episode_reward": 847.0014188053433, "episode": 27.0, "batch_reward": 0.6619152099490165, "critic_loss": 1.4293285555243491, "actor_loss": -87.40737989807128, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.768627643585205, "step": 27000}
{"episode_reward": 914.2712217676257, "episode": 28.0, "batch_reward": 0.6710851619839668, "critic_loss": 1.3631275382041932, "actor_loss": -87.88831294250488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.785640478134155, "step": 28000}
{"episode_reward": 900.618101629912, "episode": 29.0, "batch_reward": 0.6794712479710578, "critic_loss": 1.2999265241622924, "actor_loss": -87.4215040435791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.826854467391968, "step": 29000}
{"episode_reward": 908.1149273351166, "episode": 30.0, "batch_reward": 0.6864945769906045, "critic_loss": 1.2730334312319755, "actor_loss": -87.62520317077637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.8277645111084, "step": 30000}
{"episode_reward": 910.1870864158575, "episode": 31.0, "batch_reward": 0.692484953224659, "critic_loss": 1.2734755189418794, "actor_loss": -88.573896774292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.316022872924805, "step": 31000}
{"episode_reward": 889.3674533402104, "episode": 32.0, "batch_reward": 0.7020198013782502, "critic_loss": 1.2327425931692124, "actor_loss": -88.59004342651367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.81910252571106, "step": 32000}
{"episode_reward": 930.0950006469886, "episode": 33.0, "batch_reward": 0.7063670124411583, "critic_loss": 1.178425481379032, "actor_loss": -88.73910386657715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.794167280197144, "step": 33000}
{"episode_reward": 841.053367519483, "episode": 34.0, "batch_reward": 0.7105771912336349, "critic_loss": 1.1635289531350135, "actor_loss": -88.94225382995606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.83354616165161, "step": 34000}
{"episode_reward": 908.8753835011252, "episode": 35.0, "batch_reward": 0.7182378769516945, "critic_loss": 1.117964305639267, "actor_loss": -88.7027686920166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.801286697387695, "step": 35000}
{"episode_reward": 913.5200901353792, "episode": 36.0, "batch_reward": 0.7234415889978408, "critic_loss": 1.1099097516536713, "actor_loss": -89.76401699829101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.812987327575684, "step": 36000}
{"episode_reward": 887.0615375212793, "episode": 37.0, "batch_reward": 0.728950037419796, "critic_loss": 1.0583724757432937, "actor_loss": -89.45687271118165, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.845358848571777, "step": 37000}
{"episode_reward": 921.4787950138926, "episode": 38.0, "batch_reward": 0.7307997975945473, "critic_loss": 1.076925564289093, "actor_loss": -88.93463150024414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.828355073928833, "step": 38000}
{"episode_reward": 916.0037054612718, "episode": 39.0, "batch_reward": 0.7383644192814827, "critic_loss": 1.0783810978531838, "actor_loss": -89.90956512451172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.791317224502563, "step": 39000}
{"episode_reward": 912.419208452, "episode": 40.0, "batch_reward": 0.7387284368276597, "critic_loss": 1.095041435956955, "actor_loss": -89.87572428894043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.803720235824585, "step": 40000}
{"episode_reward": 914.2273067863395, "episode": 41.0, "batch_reward": 0.7448177978992462, "critic_loss": 1.1146586418747901, "actor_loss": -90.42048425292968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.2906391620636, "step": 41000}
{"episode_reward": 891.417061331411, "episode": 42.0, "batch_reward": 0.7484696519970894, "critic_loss": 1.0795764741301537, "actor_loss": -89.39489332580567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.839215993881226, "step": 42000}
{"episode_reward": 916.8640223139438, "episode": 43.0, "batch_reward": 0.754311299264431, "critic_loss": 1.0574638168811799, "actor_loss": -90.31029821777344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.833038330078125, "step": 43000}
{"episode_reward": 894.7709513214098, "episode": 44.0, "batch_reward": 0.7571189107894898, "critic_loss": 1.0612734056711197, "actor_loss": -90.29735494995117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.829282999038696, "step": 44000}
{"episode_reward": 897.0702331568268, "episode": 45.0, "batch_reward": 0.7607748173475265, "critic_loss": 0.9851250067651272, "actor_loss": -90.18978317260742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.846587896347046, "step": 45000}
{"episode_reward": 909.9784720639727, "episode": 46.0, "batch_reward": 0.7630988245606423, "critic_loss": 1.000059309065342, "actor_loss": -90.25274607849121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.848485231399536, "step": 46000}
{"episode_reward": 885.6638122421792, "episode": 47.0, "batch_reward": 0.7652177839875222, "critic_loss": 0.9943430589437485, "actor_loss": -90.63077276611328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.79665446281433, "step": 47000}
{"episode_reward": 890.5741325902114, "episode": 48.0, "batch_reward": 0.7673063631653786, "critic_loss": 1.0670082999765873, "actor_loss": -90.60796766662598, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.841830015182495, "step": 48000}
{"episode_reward": 725.2905168838141, "episode": 49.0, "batch_reward": 0.7680166705846786, "critic_loss": 1.092831457167864, "actor_loss": -90.79926809692383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.843204021453857, "step": 49000}
{"episode_reward": 897.8623380253263, "episode": 50.0, "batch_reward": 0.769329175889492, "critic_loss": 1.2341679700613022, "actor_loss": -90.3841162109375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.809865713119507, "step": 50000}
{"episode_reward": 742.9538944077685, "episode": 51.0, "batch_reward": 0.7687963839769364, "critic_loss": 1.2706894434690474, "actor_loss": -90.4408672027588, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.351524353027344, "step": 51000}
{"episode_reward": 472.2184179464348, "episode": 52.0, "batch_reward": 0.7595065484642982, "critic_loss": 1.3274069709181786, "actor_loss": -90.55571002197266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.851885318756104, "step": 52000}
{"episode_reward": 348.0474832475482, "episode": 53.0, "batch_reward": 0.7564147514104843, "critic_loss": 1.402065540611744, "actor_loss": -89.60018344116212, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.83233618736267, "step": 53000}
{"episode_reward": 910.4352512184524, "episode": 54.0, "batch_reward": 0.7586120395064354, "critic_loss": 1.3631398825049401, "actor_loss": -90.69093157958984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.83784008026123, "step": 54000}
{"episode_reward": 897.9110475204076, "episode": 55.0, "batch_reward": 0.7607257194519043, "critic_loss": 1.3689633746147156, "actor_loss": -90.39547546386719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.819839239120483, "step": 55000}
{"episode_reward": 899.384146080625, "episode": 56.0, "batch_reward": 0.7636457540392876, "critic_loss": 1.3363240994811059, "actor_loss": -89.8451178741455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.836419820785522, "step": 56000}
{"episode_reward": 961.475635189099, "episode": 57.0, "batch_reward": 0.7674669644832611, "critic_loss": 1.304402925014496, "actor_loss": -90.67240466308594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.81608510017395, "step": 57000}
{"episode_reward": 933.9537495314407, "episode": 58.0, "batch_reward": 0.77044463545084, "critic_loss": 1.241126553952694, "actor_loss": -90.41608375549316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.816896438598633, "step": 58000}
{"episode_reward": 912.4876640877995, "episode": 59.0, "batch_reward": 0.77343475908041, "critic_loss": 1.2201234807372092, "actor_loss": -90.61056802368164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.796210050582886, "step": 59000}
{"episode_reward": 911.7169508003128, "episode": 60.0, "batch_reward": 0.775244944036007, "critic_loss": 1.2787683758735657, "actor_loss": -90.62550505065919, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.822571277618408, "step": 60000}
{"episode_reward": 877.2443095016356, "episode": 61.0, "batch_reward": 0.7777462473511696, "critic_loss": 1.2293419623970985, "actor_loss": -90.99039752197265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.340436935424805, "step": 61000}
{"episode_reward": 885.142045723185, "episode": 62.0, "batch_reward": 0.7777218861579895, "critic_loss": 1.204813201725483, "actor_loss": -90.54613470458985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.85094118118286, "step": 62000}
{"episode_reward": 928.4778185045576, "episode": 63.0, "batch_reward": 0.7786118974685668, "critic_loss": 1.2189413772821427, "actor_loss": -90.77687831115723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.83189558982849, "step": 63000}
{"episode_reward": 881.7199448766528, "episode": 64.0, "batch_reward": 0.7823296990394593, "critic_loss": 1.1852681985795497, "actor_loss": -90.95621846008301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.83545184135437, "step": 64000}
{"episode_reward": 888.3977268130712, "episode": 65.0, "batch_reward": 0.7783644492030144, "critic_loss": 1.2289090232253075, "actor_loss": -90.66442478942871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.855576276779175, "step": 65000}
{"episode_reward": 77.96588513110608, "episode": 66.0, "batch_reward": 0.7735063073039055, "critic_loss": 1.2038919141292572, "actor_loss": -90.55661584472657, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.857068061828613, "step": 66000}
{"episode_reward": 939.4885245051646, "episode": 67.0, "batch_reward": 0.7778801873922349, "critic_loss": 1.179602053463459, "actor_loss": -90.49440383911133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.8239483833313, "step": 67000}
{"episode_reward": 909.0633150975556, "episode": 68.0, "batch_reward": 0.7768585687875748, "critic_loss": 1.1635748599469662, "actor_loss": -90.99228959655761, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.8246009349823, "step": 68000}
{"episode_reward": 879.4824576791285, "episode": 69.0, "batch_reward": 0.7736002630591392, "critic_loss": 1.2406788585782051, "actor_loss": -90.85636166381836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.830127239227295, "step": 69000}
{"episode_reward": 81.00782302597851, "episode": 70.0, "batch_reward": 0.7696418361067772, "critic_loss": 1.2686873236596585, "actor_loss": -90.78294398498535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.832538604736328, "step": 70000}
{"episode_reward": 931.5005820212674, "episode": 71.0, "batch_reward": 0.770633083999157, "critic_loss": 1.2720096624195576, "actor_loss": -90.40559677124024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.38431000709534, "step": 71000}
{"episode_reward": 881.0110267952917, "episode": 72.0, "batch_reward": 0.7742846165895462, "critic_loss": 1.2742801188528539, "actor_loss": -91.03631575012207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.8595290184021, "step": 72000}
{"episode_reward": 894.4457773085013, "episode": 73.0, "batch_reward": 0.7737283146977425, "critic_loss": 1.3014111360311509, "actor_loss": -90.97399475097656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.824865102767944, "step": 73000}
{"episode_reward": 919.9765786276862, "episode": 74.0, "batch_reward": 0.7771310331821442, "critic_loss": 1.3683246235251427, "actor_loss": -90.77441679382324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.825056076049805, "step": 74000}
{"episode_reward": 934.269945085341, "episode": 75.0, "batch_reward": 0.7806874014735222, "critic_loss": 1.3207010320723056, "actor_loss": -91.19525523376466, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.817166566848755, "step": 75000}
{"episode_reward": 917.3884650661325, "episode": 76.0, "batch_reward": 0.7809641166925431, "critic_loss": 1.3316113444566726, "actor_loss": -91.00164277648926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.845380783081055, "step": 76000}
{"episode_reward": 935.7781839625368, "episode": 77.0, "batch_reward": 0.7821874336600304, "critic_loss": 1.2815999374985696, "actor_loss": -90.93884443664551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.83281397819519, "step": 77000}
{"episode_reward": 900.552625043299, "episode": 78.0, "batch_reward": 0.7826740558743477, "critic_loss": 1.2367085549831391, "actor_loss": -90.86660008239745, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.835306644439697, "step": 78000}
{"episode_reward": 911.2353217022207, "episode": 79.0, "batch_reward": 0.7867929876446724, "critic_loss": 1.1994772025942801, "actor_loss": -91.31696607971192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.846235990524292, "step": 79000}
{"episode_reward": 920.7964348669558, "episode": 80.0, "batch_reward": 0.7888105000853538, "critic_loss": 1.1889849338233471, "actor_loss": -91.39254745483399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.825740575790405, "step": 80000}
{"episode_reward": 921.9142337699874, "episode": 81.0, "batch_reward": 0.789163547039032, "critic_loss": 1.1628022227585315, "actor_loss": -91.34506259155273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.33885335922241, "step": 81000}
{"episode_reward": 910.9305575651862, "episode": 82.0, "batch_reward": 0.78949561470747, "critic_loss": 1.1988703977763653, "actor_loss": -91.30817701721192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.84649419784546, "step": 82000}
{"episode_reward": 922.0877716683656, "episode": 83.0, "batch_reward": 0.7905801237225533, "critic_loss": 1.1917682879567146, "actor_loss": -91.37314230346679, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.82776427268982, "step": 83000}
{"episode_reward": 915.3590012756331, "episode": 84.0, "batch_reward": 0.7937269059419632, "critic_loss": 1.126574971973896, "actor_loss": -91.90532376098633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.83426308631897, "step": 84000}
{"episode_reward": 888.9754900361996, "episode": 85.0, "batch_reward": 0.7936029016375542, "critic_loss": 1.1452381789386272, "actor_loss": -91.52810717773437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.841115951538086, "step": 85000}
{"episode_reward": 920.771884321874, "episode": 86.0, "batch_reward": 0.7965077087879181, "critic_loss": 1.1184344094693661, "actor_loss": -91.85492276000977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.84784960746765, "step": 86000}
{"episode_reward": 952.8875357549048, "episode": 87.0, "batch_reward": 0.7982974206805229, "critic_loss": 1.1029432178735734, "actor_loss": -91.87593936157226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.858011960983276, "step": 87000}
{"episode_reward": 899.896055983229, "episode": 88.0, "batch_reward": 0.7993195899724961, "critic_loss": 1.1274669319987296, "actor_loss": -91.9525093536377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.84594702720642, "step": 88000}
{"episode_reward": 946.1229013408756, "episode": 89.0, "batch_reward": 0.79925562530756, "critic_loss": 1.1024085762798785, "actor_loss": -91.70194987487793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.166871070861816, "step": 89000}
{"episode_reward": 918.2936350201171, "episode": 90.0, "batch_reward": 0.8013147603869438, "critic_loss": 1.114983477860689, "actor_loss": -91.78850317382812, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.830329179763794, "step": 90000}
{"episode_reward": 902.1046744252338, "episode": 91.0, "batch_reward": 0.8030052337646484, "critic_loss": 1.1133554210960865, "actor_loss": -91.64001634216308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.32169532775879, "step": 91000}
{"episode_reward": 869.9058479870296, "episode": 92.0, "batch_reward": 0.804965821325779, "critic_loss": 1.0558819909989834, "actor_loss": -91.8941865081787, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.828413248062134, "step": 92000}
{"episode_reward": 883.1339561112354, "episode": 93.0, "batch_reward": 0.8062475016713142, "critic_loss": 1.100906492382288, "actor_loss": -92.18741975402833, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.84256339073181, "step": 93000}
{"episode_reward": 930.1730508021565, "episode": 94.0, "batch_reward": 0.8072820778489113, "critic_loss": 1.1207244885265828, "actor_loss": -92.20820693969726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.84091091156006, "step": 94000}
{"episode_reward": 898.63597568108, "episode": 95.0, "batch_reward": 0.8060099132657051, "critic_loss": 1.170383033066988, "actor_loss": -92.17211575317383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.841176509857178, "step": 95000}
{"episode_reward": 874.7161868807458, "episode": 96.0, "batch_reward": 0.8078295422196389, "critic_loss": 1.1691118206381799, "actor_loss": -91.95742388916015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.84993839263916, "step": 96000}
{"episode_reward": 950.8396316505817, "episode": 97.0, "batch_reward": 0.8089357938170433, "critic_loss": 1.1605760250389576, "actor_loss": -92.19303800964356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.844934701919556, "step": 97000}
{"episode_reward": 948.525490219581, "episode": 98.0, "batch_reward": 0.8105653975009918, "critic_loss": 1.1268162983357906, "actor_loss": -92.2548177947998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.824567556381226, "step": 98000}
{"episode_reward": 898.7853005396155, "episode": 99.0, "batch_reward": 0.8113459925055504, "critic_loss": 1.1678412929177284, "actor_loss": -92.14064199829102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.8176748752594, "step": 99000}
{"episode_reward": 855.8713514387238, "episode": 100.0, "batch_reward": 0.8129692850708962, "critic_loss": 1.1710831917524338, "actor_loss": -92.4584451751709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.816591262817383, "step": 100000}
{"episode_reward": 919.6811593886533, "episode": 101.0, "batch_reward": 0.813793818116188, "critic_loss": 1.27268701171875, "actor_loss": -92.3716761932373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.419562101364136, "step": 101000}
{"episode_reward": 859.2903831135792, "episode": 102.0, "batch_reward": 0.8138806828856469, "critic_loss": 1.2728508860468863, "actor_loss": -92.65534616088867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.0880389213562, "step": 102000}
{"episode_reward": 923.3226214329936, "episode": 103.0, "batch_reward": 0.8146294026970863, "critic_loss": 1.226018483310938, "actor_loss": -92.01132330322265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.78855609893799, "step": 103000}
{"episode_reward": 928.1522201572916, "episode": 104.0, "batch_reward": 0.815397698879242, "critic_loss": 1.2251719058156014, "actor_loss": -92.30974172973633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.77501082420349, "step": 104000}
{"episode_reward": 940.129083970927, "episode": 105.0, "batch_reward": 0.8175252258181572, "critic_loss": 1.2526223921775819, "actor_loss": -92.20307551574707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.80946969985962, "step": 105000}
{"episode_reward": 931.9785730204667, "episode": 106.0, "batch_reward": 0.8180192142128945, "critic_loss": 1.2552868246138096, "actor_loss": -92.70508790588379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.82200860977173, "step": 106000}
{"episode_reward": 871.1778683941759, "episode": 107.0, "batch_reward": 0.8187502346038819, "critic_loss": 1.2695670181810856, "actor_loss": -92.73935325622558, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.84088897705078, "step": 107000}
{"episode_reward": 837.3529096816792, "episode": 108.0, "batch_reward": 0.8173954293727875, "critic_loss": 1.2989296586811543, "actor_loss": -92.24459323120116, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.844852209091187, "step": 108000}
{"episode_reward": 856.6455071128781, "episode": 109.0, "batch_reward": 0.818079703271389, "critic_loss": 1.3460529779195785, "actor_loss": -92.55704821777344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.845052242279053, "step": 109000}
{"episode_reward": 918.5341092849791, "episode": 110.0, "batch_reward": 0.8196926928162575, "critic_loss": 1.3155566507279872, "actor_loss": -92.44375163269044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.84583568572998, "step": 110000}
{"episode_reward": 901.9624989160255, "episode": 111.0, "batch_reward": 0.8202350735068321, "critic_loss": 1.3479460365772247, "actor_loss": -92.31041249084473, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.3002347946167, "step": 111000}
{"episode_reward": 891.329994379212, "episode": 112.0, "batch_reward": 0.8220865367650986, "critic_loss": 1.3414793537855147, "actor_loss": -92.65971765136719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.843390464782715, "step": 112000}
{"episode_reward": 900.2695743449314, "episode": 113.0, "batch_reward": 0.8226675828695297, "critic_loss": 1.4018937757313252, "actor_loss": -92.7352940979004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.81940245628357, "step": 113000}
{"episode_reward": 827.3644331824967, "episode": 114.0, "batch_reward": 0.8217161141633987, "critic_loss": 1.3608625802993775, "actor_loss": -92.70065051269532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.84090805053711, "step": 114000}
{"episode_reward": 953.8484279233835, "episode": 115.0, "batch_reward": 0.8224663563370704, "critic_loss": 1.3182791995108127, "actor_loss": -92.37465498352051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.849091291427612, "step": 115000}
{"episode_reward": 875.6331910811923, "episode": 116.0, "batch_reward": 0.8240968138575554, "critic_loss": 1.3210292564630508, "actor_loss": -92.53460696411133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.830141067504883, "step": 116000}
{"episode_reward": 863.8127360939893, "episode": 117.0, "batch_reward": 0.8238641712665558, "critic_loss": 1.3654816293120384, "actor_loss": -92.1059465789795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.84169363975525, "step": 117000}
{"episode_reward": 863.9058963197272, "episode": 118.0, "batch_reward": 0.8243718236684799, "critic_loss": 1.399469789892435, "actor_loss": -92.40294296264648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.816661596298218, "step": 118000}
{"episode_reward": 917.4868395383345, "episode": 119.0, "batch_reward": 0.8254879932999611, "critic_loss": 1.4354873275160789, "actor_loss": -92.34654913330078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.85056734085083, "step": 119000}
{"episode_reward": 915.1032356823818, "episode": 120.0, "batch_reward": 0.8258417212963104, "critic_loss": 1.5048429875075817, "actor_loss": -92.41040495300292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.844590663909912, "step": 120000}
{"episode_reward": 942.0644188455458, "episode": 121.0, "batch_reward": 0.8264929032921791, "critic_loss": 1.4064878691434861, "actor_loss": -92.4036759185791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.33648204803467, "step": 121000}
{"episode_reward": 928.095513606506, "episode": 122.0, "batch_reward": 0.8276556224822998, "critic_loss": 1.42522210380435, "actor_loss": -92.75334729003906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.822506427764893, "step": 122000}
{"episode_reward": 920.1590896269943, "episode": 123.0, "batch_reward": 0.8294049777388572, "critic_loss": 1.3965618934333324, "actor_loss": -92.96542765808105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.79382061958313, "step": 123000}
{"episode_reward": 878.2275763383446, "episode": 124.0, "batch_reward": 0.8297207489609718, "critic_loss": 1.3820986665189265, "actor_loss": -92.90843058776855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.828582525253296, "step": 124000}
{"episode_reward": 906.1457007734895, "episode": 125.0, "batch_reward": 0.8298165645003319, "critic_loss": 1.377856999605894, "actor_loss": -92.82583651733398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.84227967262268, "step": 125000}
{"episode_reward": 933.36399045589, "episode": 126.0, "batch_reward": 0.8329203888177872, "critic_loss": 1.408687163591385, "actor_loss": -92.66251460266113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.841683864593506, "step": 126000}
{"episode_reward": 942.5293938822156, "episode": 127.0, "batch_reward": 0.8312614295482635, "critic_loss": 1.4304709239900113, "actor_loss": -92.46781832885742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.831156253814697, "step": 127000}
{"episode_reward": 920.3772359590535, "episode": 128.0, "batch_reward": 0.8315747542381287, "critic_loss": 1.4282921154201031, "actor_loss": -92.62747537231445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.801580905914307, "step": 128000}
{"episode_reward": 920.3467667740933, "episode": 129.0, "batch_reward": 0.8295723420381546, "critic_loss": 1.3713129247128963, "actor_loss": -92.72734497070313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.823055744171143, "step": 129000}
{"episode_reward": 59.49943056145008, "episode": 130.0, "batch_reward": 0.8288668975830078, "critic_loss": 1.3638637342453004, "actor_loss": -92.52135940551757, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.81347131729126, "step": 130000}
{"episode_reward": 927.2478276107817, "episode": 131.0, "batch_reward": 0.8269149998426437, "critic_loss": 1.3743578785657882, "actor_loss": -92.74791477966309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.27921009063721, "step": 131000}
{"episode_reward": 906.1673885459707, "episode": 132.0, "batch_reward": 0.8277923309803009, "critic_loss": 1.3405525136888028, "actor_loss": -92.99775399780273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.814380407333374, "step": 132000}
{"episode_reward": 851.5362435235038, "episode": 133.0, "batch_reward": 0.8286472367048263, "critic_loss": 1.3731121675372124, "actor_loss": -92.82558663940429, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.825239658355713, "step": 133000}
{"episode_reward": 955.8113398213136, "episode": 134.0, "batch_reward": 0.8298736618161201, "critic_loss": 1.3501986003816129, "actor_loss": -92.77375814819337, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.81772756576538, "step": 134000}
{"episode_reward": 911.0607569056954, "episode": 135.0, "batch_reward": 0.8314776318669319, "critic_loss": 1.318968878865242, "actor_loss": -92.60494668579102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.847118854522705, "step": 135000}
{"episode_reward": 903.6144605098866, "episode": 136.0, "batch_reward": 0.8306431150436402, "critic_loss": 1.3229540665447712, "actor_loss": -92.50145524597168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.834425687789917, "step": 136000}
{"episode_reward": 863.3536650070384, "episode": 137.0, "batch_reward": 0.8292241786718368, "critic_loss": 1.2355483575165271, "actor_loss": -93.10234645080567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.834320068359375, "step": 137000}
{"episode_reward": 919.2430018924206, "episode": 138.0, "batch_reward": 0.8330597642660141, "critic_loss": 1.2129634286165238, "actor_loss": -92.94001214599609, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.832918882369995, "step": 138000}
{"episode_reward": 957.0614957687188, "episode": 139.0, "batch_reward": 0.8314641141295434, "critic_loss": 1.23509002161026, "actor_loss": -92.81291258239746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.847278118133545, "step": 139000}
{"episode_reward": 911.169488341409, "episode": 140.0, "batch_reward": 0.8342406819462777, "critic_loss": 1.2446297453641892, "actor_loss": -92.8757491760254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.832356691360474, "step": 140000}
{"episode_reward": 865.6461920030484, "episode": 141.0, "batch_reward": 0.8319139758944512, "critic_loss": 1.300468503832817, "actor_loss": -93.02207554626465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.31509590148926, "step": 141000}
{"episode_reward": 928.9757870596599, "episode": 142.0, "batch_reward": 0.8323182586431503, "critic_loss": 1.2218627581596375, "actor_loss": -92.50769038391114, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.839900493621826, "step": 142000}
{"episode_reward": 880.0198655404516, "episode": 143.0, "batch_reward": 0.8341114433407784, "critic_loss": 1.1739882350862025, "actor_loss": -92.67718138122558, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.827383518218994, "step": 143000}
{"episode_reward": 899.9941638924115, "episode": 144.0, "batch_reward": 0.834926559984684, "critic_loss": 1.106981673359871, "actor_loss": -92.97691058349609, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.822592973709106, "step": 144000}
{"episode_reward": 892.7362359037979, "episode": 145.0, "batch_reward": 0.8349574165940284, "critic_loss": 1.114029309630394, "actor_loss": -93.27450538635254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.80485510826111, "step": 145000}
{"episode_reward": 915.4153277289786, "episode": 146.0, "batch_reward": 0.8350514471530914, "critic_loss": 1.135816049963236, "actor_loss": -93.247484664917, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.838557481765747, "step": 146000}
{"episode_reward": 842.8177273798974, "episode": 147.0, "batch_reward": 0.8357982029318809, "critic_loss": 1.135937123298645, "actor_loss": -92.95422479248047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.8468017578125, "step": 147000}
{"episode_reward": 859.444614574601, "episode": 148.0, "batch_reward": 0.8346155315637589, "critic_loss": 1.1178566128909588, "actor_loss": -93.21136071777343, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.851855516433716, "step": 148000}
{"episode_reward": 895.1723842624277, "episode": 149.0, "batch_reward": 0.836751783132553, "critic_loss": 1.1472666398584843, "actor_loss": -92.90707832336426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.841732501983643, "step": 149000}
{"episode_reward": 937.2548077417828, "episode": 150.0, "batch_reward": 0.8357433620691299, "critic_loss": 1.136510997325182, "actor_loss": -93.18324169921875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
