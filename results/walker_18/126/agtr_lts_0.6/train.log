{"episode_reward": 0.0, "episode": 1.0, "duration": 20.914990663528442, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.8187363147735596, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.4629273271314221, "critic_loss": 0.19732779965907704, "actor_loss": -83.54844678960451, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.623209714889526, "step": 3000}
{"episode_reward": 544.9343941133228, "episode": 4.0, "batch_reward": 0.5021005931794643, "critic_loss": 0.601916911020875, "actor_loss": -84.40390411376953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.101825952529907, "step": 4000}
{"episode_reward": 611.6988698105524, "episode": 5.0, "batch_reward": 0.5287177332043648, "critic_loss": 0.7603515933156013, "actor_loss": -85.71431785583496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.094792127609253, "step": 5000}
{"episode_reward": 655.084351343942, "episode": 6.0, "batch_reward": 0.5507094886004925, "critic_loss": 0.8478969566524028, "actor_loss": -86.26776206970214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.083184480667114, "step": 6000}
{"episode_reward": 711.2300163134244, "episode": 7.0, "batch_reward": 0.5909446318745613, "critic_loss": 0.95234482973814, "actor_loss": -87.37761376953125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.091325521469116, "step": 7000}
{"episode_reward": 797.3141903974397, "episode": 8.0, "batch_reward": 0.6107498260140419, "critic_loss": 1.0493585198521613, "actor_loss": -88.27624467468262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09217381477356, "step": 8000}
{"episode_reward": 666.8401863670587, "episode": 9.0, "batch_reward": 0.6018302725255489, "critic_loss": 1.008670610845089, "actor_loss": -88.17508178710938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1005539894104, "step": 9000}
{"episode_reward": 245.7941734223322, "episode": 10.0, "batch_reward": 0.5817859834432602, "critic_loss": 0.9705506539344788, "actor_loss": -87.7276421661377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10792088508606, "step": 10000}
{"episode_reward": 783.5348083996886, "episode": 11.0, "batch_reward": 0.6019582218527794, "critic_loss": 1.0398585116267205, "actor_loss": -88.14673117065429, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.68121314048767, "step": 11000}
{"episode_reward": 776.4287977287773, "episode": 12.0, "batch_reward": 0.6187220708429814, "critic_loss": 1.026073147714138, "actor_loss": -88.48113986206054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.080289840698242, "step": 12000}
{"episode_reward": 815.3116543232856, "episode": 13.0, "batch_reward": 0.6326435860991478, "critic_loss": 1.0510680514574051, "actor_loss": -88.65510481262207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07911205291748, "step": 13000}
{"episode_reward": 817.1149099986077, "episode": 14.0, "batch_reward": 0.651094133079052, "critic_loss": 1.001570942401886, "actor_loss": -89.0391346130371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09763789176941, "step": 14000}
{"episode_reward": 940.449700812636, "episode": 15.0, "batch_reward": 0.664873022377491, "critic_loss": 0.9647381453812123, "actor_loss": -89.13623254394531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.315732955932617, "step": 15000}
{"episode_reward": 847.3838802607278, "episode": 16.0, "batch_reward": 0.6859121594429016, "critic_loss": 0.8628572359979153, "actor_loss": -89.91607870483398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.203558444976807, "step": 16000}
{"episode_reward": 952.9531497018461, "episode": 17.0, "batch_reward": 0.6993602116107941, "critic_loss": 0.7838135969638824, "actor_loss": -90.1813250579834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.082778692245483, "step": 17000}
{"episode_reward": 927.8662861991252, "episode": 18.0, "batch_reward": 0.7107007071971894, "critic_loss": 0.7396352334916592, "actor_loss": -90.49418914794921, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.070761680603027, "step": 18000}
{"episode_reward": 865.4930166323688, "episode": 19.0, "batch_reward": 0.7096043313145638, "critic_loss": 0.6270524557828904, "actor_loss": -90.473972946167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.092538118362427, "step": 19000}
{"episode_reward": 305.33453084059494, "episode": 20.0, "batch_reward": 0.6985148961544037, "critic_loss": 0.5871063766479492, "actor_loss": -89.73138534545899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.090667724609375, "step": 20000}
{"episode_reward": 894.5382792834243, "episode": 21.0, "batch_reward": 0.7094538328051567, "critic_loss": 0.564939041107893, "actor_loss": -90.17600877380372, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.61874556541443, "step": 21000}
{"episode_reward": 937.3587244356264, "episode": 22.0, "batch_reward": 0.7162015132904053, "critic_loss": 0.5975693014860153, "actor_loss": -90.2252451019287, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.093446969985962, "step": 22000}
{"episode_reward": 828.9132182649277, "episode": 23.0, "batch_reward": 0.7226730449795723, "critic_loss": 0.5872617022097111, "actor_loss": -90.49553182983398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10132908821106, "step": 23000}
{"episode_reward": 895.0763383424285, "episode": 24.0, "batch_reward": 0.7181179642677307, "critic_loss": 0.5928689585328102, "actor_loss": -90.39960350036621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11470317840576, "step": 24000}
{"episode_reward": 550.1136976879039, "episode": 25.0, "batch_reward": 0.7235119732022286, "critic_loss": 0.5745853390544653, "actor_loss": -90.46724168395995, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.101279497146606, "step": 25000}
{"episode_reward": 839.9400441905453, "episode": 26.0, "batch_reward": 0.7252360629439354, "critic_loss": 0.6394414591789246, "actor_loss": -90.66349810791016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.100008010864258, "step": 26000}
{"episode_reward": 581.4723199801851, "episode": 27.0, "batch_reward": 0.7240893170237541, "critic_loss": 0.6012570083737373, "actor_loss": -90.35269580078125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.087059020996094, "step": 27000}
{"episode_reward": 942.1666799090939, "episode": 28.0, "batch_reward": 0.7319945264458656, "critic_loss": 0.5716947087645531, "actor_loss": -90.49012283325196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.104984760284424, "step": 28000}
{"episode_reward": 917.610170217852, "episode": 29.0, "batch_reward": 0.7376567571163177, "critic_loss": 0.5468899143636227, "actor_loss": -90.41849925231934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.100608825683594, "step": 29000}
{"episode_reward": 903.9099335955406, "episode": 30.0, "batch_reward": 0.7412487332820892, "critic_loss": 0.5291357650756836, "actor_loss": -90.52178901672363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09686303138733, "step": 30000}
{"episode_reward": 924.5406552082111, "episode": 31.0, "batch_reward": 0.7458004133105278, "critic_loss": 0.513294111341238, "actor_loss": -90.63468572998048, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.634578704833984, "step": 31000}
{"episode_reward": 862.2286789945167, "episode": 32.0, "batch_reward": 0.7538406077623367, "critic_loss": 0.5090314497500658, "actor_loss": -90.79774359130859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.085585117340088, "step": 32000}
{"episode_reward": 945.9243891768056, "episode": 33.0, "batch_reward": 0.7497203575372696, "critic_loss": 0.5351037081629038, "actor_loss": -90.6466872253418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.088953495025635, "step": 33000}
{"episode_reward": 577.7311270659944, "episode": 34.0, "batch_reward": 0.7510700752139091, "critic_loss": 0.5351911904066801, "actor_loss": -90.85130059814453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.100968599319458, "step": 34000}
{"episode_reward": 821.2440809436134, "episode": 35.0, "batch_reward": 0.756599603176117, "critic_loss": 0.552806918591261, "actor_loss": -90.83355856323242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08991551399231, "step": 35000}
{"episode_reward": 927.0651095663197, "episode": 36.0, "batch_reward": 0.7602296167016029, "critic_loss": 0.5471673339903355, "actor_loss": -91.24245927429199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.110891342163086, "step": 36000}
{"episode_reward": 839.4319302650038, "episode": 37.0, "batch_reward": 0.7627066481113434, "critic_loss": 0.5551046389341354, "actor_loss": -91.08436235046386, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.112024784088135, "step": 37000}
{"episode_reward": 948.8567153965868, "episode": 38.0, "batch_reward": 0.7666212789416313, "critic_loss": 0.5225701822638512, "actor_loss": -90.95149325561523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09791612625122, "step": 38000}
{"episode_reward": 931.0819587784102, "episode": 39.0, "batch_reward": 0.7714633447527885, "critic_loss": 0.5204259650409222, "actor_loss": -91.29799458312988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.105069398880005, "step": 39000}
{"episode_reward": 908.3279498736921, "episode": 40.0, "batch_reward": 0.773949904024601, "critic_loss": 0.4985310519039631, "actor_loss": -91.51998645019532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.100883960723877, "step": 40000}
{"episode_reward": 946.5249441418107, "episode": 41.0, "batch_reward": 0.7781126899719238, "critic_loss": 0.593167670071125, "actor_loss": -91.70478991699218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.63323903083801, "step": 41000}
{"episode_reward": 817.226560962728, "episode": 42.0, "batch_reward": 0.7728244395852089, "critic_loss": 0.585107025936246, "actor_loss": -91.37796311950683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.095621585845947, "step": 42000}
{"episode_reward": 633.143208770428, "episode": 43.0, "batch_reward": 0.7779470842480659, "critic_loss": 0.5762851321101189, "actor_loss": -91.6875813293457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09478235244751, "step": 43000}
{"episode_reward": 945.6998383979086, "episode": 44.0, "batch_reward": 0.779141978263855, "critic_loss": 0.5977941275537014, "actor_loss": -91.4220816192627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09052801132202, "step": 44000}
{"episode_reward": 904.3061696915985, "episode": 45.0, "batch_reward": 0.7841113849878311, "critic_loss": 0.5806942486017942, "actor_loss": -91.50871760559082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08310317993164, "step": 45000}
{"episode_reward": 930.7650665281706, "episode": 46.0, "batch_reward": 0.7856004166007042, "critic_loss": 0.5764740376770496, "actor_loss": -91.80057872009277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.091723442077637, "step": 46000}
{"episode_reward": 914.2534727936456, "episode": 47.0, "batch_reward": 0.7889260079264641, "critic_loss": 0.5495433804392814, "actor_loss": -91.92070436096192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.096211433410645, "step": 47000}
{"episode_reward": 949.0543866448078, "episode": 48.0, "batch_reward": 0.7935619722008705, "critic_loss": 0.5295970280170441, "actor_loss": -92.09612425231934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.102038145065308, "step": 48000}
{"episode_reward": 924.1778607747704, "episode": 49.0, "batch_reward": 0.7955739710330963, "critic_loss": 0.530057123735547, "actor_loss": -92.19719064331055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.106339693069458, "step": 49000}
{"episode_reward": 905.6718373307542, "episode": 50.0, "batch_reward": 0.7976516497135162, "critic_loss": 0.5380914394855499, "actor_loss": -92.18031407165527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10627031326294, "step": 50000}
{"episode_reward": 910.9755095823677, "episode": 51.0, "batch_reward": 0.8017011762261391, "critic_loss": 0.5020069828182459, "actor_loss": -92.2624946899414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.6105797290802, "step": 51000}
{"episode_reward": 950.6652478639954, "episode": 52.0, "batch_reward": 0.802937725365162, "critic_loss": 0.5033682526946068, "actor_loss": -92.41951943969727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0949604511261, "step": 52000}
{"episode_reward": 926.919812107047, "episode": 53.0, "batch_reward": 0.8056660056114197, "critic_loss": 0.4846704465150833, "actor_loss": -92.1911650238037, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09765315055847, "step": 53000}
{"episode_reward": 914.8646797431724, "episode": 54.0, "batch_reward": 0.8090404450297356, "critic_loss": 0.48166958370804785, "actor_loss": -92.73933612060547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08205556869507, "step": 54000}
{"episode_reward": 934.0112762778111, "episode": 55.0, "batch_reward": 0.808576381444931, "critic_loss": 0.4725412780046463, "actor_loss": -92.6253740386963, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09990167617798, "step": 55000}
{"episode_reward": 845.0894166394403, "episode": 56.0, "batch_reward": 0.8101402404308319, "critic_loss": 0.4913854702562094, "actor_loss": -92.52201643371582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10645365715027, "step": 56000}
{"episode_reward": 963.6469236357785, "episode": 57.0, "batch_reward": 0.8122240611314774, "critic_loss": 0.4848360176831484, "actor_loss": -92.65495951843262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.108646392822266, "step": 57000}
{"episode_reward": 869.2691774809123, "episode": 58.0, "batch_reward": 0.8145944216251373, "critic_loss": 0.494393039137125, "actor_loss": -92.81315000915528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09560489654541, "step": 58000}
{"episode_reward": 925.3410087459241, "episode": 59.0, "batch_reward": 0.8154335888624191, "critic_loss": 0.48075783656537535, "actor_loss": -92.79155107116699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.089820861816406, "step": 59000}
{"episode_reward": 952.4306906326416, "episode": 60.0, "batch_reward": 0.8186527361273765, "critic_loss": 0.47372714088857176, "actor_loss": -92.96326927185059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.094141960144043, "step": 60000}
{"episode_reward": 904.8508921858163, "episode": 61.0, "batch_reward": 0.8197540194392204, "critic_loss": 0.49058089464902876, "actor_loss": -92.988779296875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.67506384849548, "step": 61000}
{"episode_reward": 861.8586344966374, "episode": 62.0, "batch_reward": 0.818634207367897, "critic_loss": 0.4869834664911032, "actor_loss": -92.83796098327636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.113589763641357, "step": 62000}
{"episode_reward": 945.7744677201619, "episode": 63.0, "batch_reward": 0.819605326116085, "critic_loss": 0.4697187846302986, "actor_loss": -92.9085365447998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.124340057373047, "step": 63000}
{"episode_reward": 900.8024146578722, "episode": 64.0, "batch_reward": 0.8230706104636192, "critic_loss": 0.4909443079531193, "actor_loss": -93.09561645507813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.097552061080933, "step": 64000}
{"episode_reward": 922.4904051090573, "episode": 65.0, "batch_reward": 0.8236770506501198, "critic_loss": 0.4843945955783129, "actor_loss": -93.00972785949708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.097331762313843, "step": 65000}
{"episode_reward": 931.0989166375365, "episode": 66.0, "batch_reward": 0.8265545132160187, "critic_loss": 0.4937870188355446, "actor_loss": -93.1552840576172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10351824760437, "step": 66000}
{"episode_reward": 954.399441636946, "episode": 67.0, "batch_reward": 0.8279448553919793, "critic_loss": 0.517216211900115, "actor_loss": -93.17289129638672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.090485334396362, "step": 67000}
{"episode_reward": 915.3248850836868, "episode": 68.0, "batch_reward": 0.8306361058950424, "critic_loss": 0.5045884382724762, "actor_loss": -93.41348159790039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.100572109222412, "step": 68000}
{"episode_reward": 935.0543655579412, "episode": 69.0, "batch_reward": 0.8316449514627456, "critic_loss": 0.4614619174450636, "actor_loss": -93.40528434753418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.093689441680908, "step": 69000}
{"episode_reward": 962.714676772663, "episode": 70.0, "batch_reward": 0.8323886622786522, "critic_loss": 0.4416470486074686, "actor_loss": -93.52288520812988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.120718240737915, "step": 70000}
{"episode_reward": 930.8203540798243, "episode": 71.0, "batch_reward": 0.8347432499527931, "critic_loss": 0.4567680231034756, "actor_loss": -93.41972727966309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.627434968948364, "step": 71000}
{"episode_reward": 929.7429964889549, "episode": 72.0, "batch_reward": 0.8370666810870171, "critic_loss": 0.43157664969563486, "actor_loss": -93.60310800170899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09023904800415, "step": 72000}
{"episode_reward": 948.671399270911, "episode": 73.0, "batch_reward": 0.8368849788308144, "critic_loss": 0.4397847127169371, "actor_loss": -93.51699223327637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09746527671814, "step": 73000}
{"episode_reward": 935.1834548007283, "episode": 74.0, "batch_reward": 0.8406907607913017, "critic_loss": 0.432044657856226, "actor_loss": -93.60927432250976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.106788396835327, "step": 74000}
{"episode_reward": 936.8189693382652, "episode": 75.0, "batch_reward": 0.8418322341442108, "critic_loss": 0.42164172261208294, "actor_loss": -93.69387725830079, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.111759662628174, "step": 75000}
{"episode_reward": 957.2052230330911, "episode": 76.0, "batch_reward": 0.8426515191793442, "critic_loss": 0.4400813705474138, "actor_loss": -93.74796195983886, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14161777496338, "step": 76000}
{"episode_reward": 883.2837480301635, "episode": 77.0, "batch_reward": 0.8422440569400788, "critic_loss": 0.42790577287971976, "actor_loss": -93.706875289917, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.18746590614319, "step": 77000}
{"episode_reward": 951.1467405768539, "episode": 78.0, "batch_reward": 0.8432681322097778, "critic_loss": 0.4330004589855671, "actor_loss": -93.66504148864746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.36379885673523, "step": 78000}
{"episode_reward": 931.3891925213845, "episode": 79.0, "batch_reward": 0.8450005077123642, "critic_loss": 0.4582080450206995, "actor_loss": -93.77685208129883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.105597734451294, "step": 79000}
{"episode_reward": 926.5633947819807, "episode": 80.0, "batch_reward": 0.8456589793562889, "critic_loss": 0.42226436488330366, "actor_loss": -93.81131341552734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09818196296692, "step": 80000}
{"episode_reward": 876.9836270028484, "episode": 81.0, "batch_reward": 0.8448933976888656, "critic_loss": 0.42402263203263285, "actor_loss": -93.76021118164063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.644442558288574, "step": 81000}
{"episode_reward": 828.5093354245907, "episode": 82.0, "batch_reward": 0.8430420664548874, "critic_loss": 0.4407311159595847, "actor_loss": -93.76673657226563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.102087020874023, "step": 82000}
{"episode_reward": 889.6463398393605, "episode": 83.0, "batch_reward": 0.8457235268354416, "critic_loss": 0.44416838651895524, "actor_loss": -93.91217349243163, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.421244382858276, "step": 83000}
{"episode_reward": 909.3463341814459, "episode": 84.0, "batch_reward": 0.8466570190191269, "critic_loss": 0.44808175683021545, "actor_loss": -94.0196665649414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09031057357788, "step": 84000}
{"episode_reward": 930.6086916975486, "episode": 85.0, "batch_reward": 0.8474697574973107, "critic_loss": 0.4558291183710098, "actor_loss": -93.88031420898437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.078784942626953, "step": 85000}
{"episode_reward": 915.7992903825739, "episode": 86.0, "batch_reward": 0.8486328145861626, "critic_loss": 0.41620767533779146, "actor_loss": -93.86258921813965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08533525466919, "step": 86000}
{"episode_reward": 951.9072947430329, "episode": 87.0, "batch_reward": 0.8499792264699936, "critic_loss": 0.45008406426012515, "actor_loss": -93.97216889953613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.093913555145264, "step": 87000}
{"episode_reward": 915.6762751175995, "episode": 88.0, "batch_reward": 0.8517867389917374, "critic_loss": 0.4269703549742699, "actor_loss": -94.06350929260253, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.090057849884033, "step": 88000}
{"episode_reward": 961.6839790131448, "episode": 89.0, "batch_reward": 0.8524973014593125, "critic_loss": 0.4556445916444063, "actor_loss": -93.98273558044434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09276032447815, "step": 89000}
{"episode_reward": 952.4583544699495, "episode": 90.0, "batch_reward": 0.8530485419631004, "critic_loss": 0.44538001307845115, "actor_loss": -94.05846908569336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09196949005127, "step": 90000}
{"episode_reward": 923.5677115047561, "episode": 91.0, "batch_reward": 0.8551945089101791, "critic_loss": 0.43514471454918385, "actor_loss": -94.04380520629883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.57552170753479, "step": 91000}
{"episode_reward": 905.5956207805851, "episode": 92.0, "batch_reward": 0.8559560329318047, "critic_loss": 0.43855913597345353, "actor_loss": -94.09420349121093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.099860429763794, "step": 92000}
{"episode_reward": 980.4302255458509, "episode": 93.0, "batch_reward": 0.8561268833875656, "critic_loss": 0.41674608997255563, "actor_loss": -94.12242260742188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.093247890472412, "step": 93000}
{"episode_reward": 984.0394921317798, "episode": 94.0, "batch_reward": 0.857453330039978, "critic_loss": 0.4447592925429344, "actor_loss": -94.18445014953613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09451937675476, "step": 94000}
{"episode_reward": 910.1178464372141, "episode": 95.0, "batch_reward": 0.8578665947914124, "critic_loss": 0.4325591056644916, "actor_loss": -94.26453038024903, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.101386308670044, "step": 95000}
{"episode_reward": 929.6555225791392, "episode": 96.0, "batch_reward": 0.8589269726276397, "critic_loss": 0.4344326653778553, "actor_loss": -94.24450598144531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10609722137451, "step": 96000}
{"episode_reward": 954.6737184958431, "episode": 97.0, "batch_reward": 0.8591049721240998, "critic_loss": 0.4250054321140051, "actor_loss": -94.25886192321778, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.112536668777466, "step": 97000}
{"episode_reward": 939.6265764570348, "episode": 98.0, "batch_reward": 0.8606719300150871, "critic_loss": 0.41849059280753137, "actor_loss": -94.23999238586426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.118449211120605, "step": 98000}
{"episode_reward": 943.3878655961094, "episode": 99.0, "batch_reward": 0.8615830169320107, "critic_loss": 0.38479394710063936, "actor_loss": -94.31661740112305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11275815963745, "step": 99000}
{"episode_reward": 912.376053415004, "episode": 100.0, "batch_reward": 0.8606971810460091, "critic_loss": 0.4283546494916081, "actor_loss": -94.25381864929199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.112020015716553, "step": 100000}
{"episode_reward": 925.9927215639581, "episode": 101.0, "batch_reward": 0.8634252979755401, "critic_loss": 0.4375411033928394, "actor_loss": -94.38868664550782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.63608980178833, "step": 101000}
{"episode_reward": 955.0739893296934, "episode": 102.0, "batch_reward": 0.8637074443101883, "critic_loss": 0.4229556080698967, "actor_loss": -94.3239341583252, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.108290672302246, "step": 102000}
{"episode_reward": 960.7573982257883, "episode": 103.0, "batch_reward": 0.8647751570343971, "critic_loss": 0.4098906331956387, "actor_loss": -94.31821459960938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.096468448638916, "step": 103000}
{"episode_reward": 942.4471519598015, "episode": 104.0, "batch_reward": 0.8648876180648803, "critic_loss": 0.4097863589823246, "actor_loss": -94.39879342651368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09585189819336, "step": 104000}
{"episode_reward": 926.2481928691294, "episode": 105.0, "batch_reward": 0.8653793960213662, "critic_loss": 0.41016904915869234, "actor_loss": -94.29883049011231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09568166732788, "step": 105000}
{"episode_reward": 946.1415129065787, "episode": 106.0, "batch_reward": 0.8661744843125343, "critic_loss": 0.42249561224877835, "actor_loss": -94.43014096069336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.098597288131714, "step": 106000}
{"episode_reward": 889.9183790779716, "episode": 107.0, "batch_reward": 0.8668741213083268, "critic_loss": 0.40455070085823536, "actor_loss": -94.38378573608398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.082950592041016, "step": 107000}
{"episode_reward": 926.6841055396134, "episode": 108.0, "batch_reward": 0.8660221610665322, "critic_loss": 0.4220957093387842, "actor_loss": -94.23697274780274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.094061851501465, "step": 108000}
{"episode_reward": 917.2888455304854, "episode": 109.0, "batch_reward": 0.8661315958499909, "critic_loss": 0.4129024848639965, "actor_loss": -94.42398918151855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.096938610076904, "step": 109000}
{"episode_reward": 921.6306213153638, "episode": 110.0, "batch_reward": 0.8677283708453178, "critic_loss": 0.42178362888097765, "actor_loss": -94.45780072021485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.093783378601074, "step": 110000}
{"episode_reward": 898.4483089707131, "episode": 111.0, "batch_reward": 0.8675461286902427, "critic_loss": 0.42578542000055314, "actor_loss": -94.30686544799805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.65075087547302, "step": 111000}
{"episode_reward": 913.2242398427046, "episode": 112.0, "batch_reward": 0.868371054828167, "critic_loss": 0.39993922390043735, "actor_loss": -94.49885173034669, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10313105583191, "step": 112000}
{"episode_reward": 925.46963193281, "episode": 113.0, "batch_reward": 0.869286511182785, "critic_loss": 0.413165492400527, "actor_loss": -94.39799327087403, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.111772537231445, "step": 113000}
{"episode_reward": 923.0031274959341, "episode": 114.0, "batch_reward": 0.8692542423009872, "critic_loss": 0.42117209869623184, "actor_loss": -94.46349092102051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.121337413787842, "step": 114000}
{"episode_reward": 965.6252012831873, "episode": 115.0, "batch_reward": 0.8709852392077446, "critic_loss": 0.4392397848963738, "actor_loss": -94.46450227355957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.116625785827637, "step": 115000}
{"episode_reward": 942.1219099590085, "episode": 116.0, "batch_reward": 0.8725298269987106, "critic_loss": 0.4432717074453831, "actor_loss": -94.51436727905273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.126775979995728, "step": 116000}
{"episode_reward": 918.0506506606555, "episode": 117.0, "batch_reward": 0.8721316929459572, "critic_loss": 0.4452506551742554, "actor_loss": -94.40259742736816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1190345287323, "step": 117000}
{"episode_reward": 913.5392421032569, "episode": 118.0, "batch_reward": 0.8716237771511078, "critic_loss": 0.4648396244496107, "actor_loss": -94.44182034301758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.092486143112183, "step": 118000}
{"episode_reward": 931.6582634744454, "episode": 119.0, "batch_reward": 0.8725082051753997, "critic_loss": 0.45151983737945556, "actor_loss": -94.45175758361816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.104910373687744, "step": 119000}
{"episode_reward": 919.3946991127144, "episode": 120.0, "batch_reward": 0.8719519613981247, "critic_loss": 0.4359803045243025, "actor_loss": -94.45154090881347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0906662940979, "step": 120000}
{"episode_reward": 935.9758340998094, "episode": 121.0, "batch_reward": 0.8736786118745804, "critic_loss": 0.43637823677808046, "actor_loss": -94.49268984985352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.580551624298096, "step": 121000}
{"episode_reward": 947.3315935958658, "episode": 122.0, "batch_reward": 0.8744661585092545, "critic_loss": 0.44744372682273387, "actor_loss": -94.5564104309082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09234929084778, "step": 122000}
{"episode_reward": 919.9271247303446, "episode": 123.0, "batch_reward": 0.8744979847073555, "critic_loss": 0.4325635861903429, "actor_loss": -94.64673233032227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.091588735580444, "step": 123000}
{"episode_reward": 961.9090812090955, "episode": 124.0, "batch_reward": 0.8755194730162621, "critic_loss": 0.4339327331334352, "actor_loss": -94.6361388092041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08564519882202, "step": 124000}
{"episode_reward": 930.0798020513186, "episode": 125.0, "batch_reward": 0.8755383636951447, "critic_loss": 0.4138382212817669, "actor_loss": -94.7006429901123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09521770477295, "step": 125000}
{"episode_reward": 928.6054936610083, "episode": 126.0, "batch_reward": 0.87691583776474, "critic_loss": 0.41848834121227263, "actor_loss": -94.6239584197998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.111889123916626, "step": 126000}
{"episode_reward": 970.8881308158374, "episode": 127.0, "batch_reward": 0.8762787559628487, "critic_loss": 0.3916531440615654, "actor_loss": -94.65404957580566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11659860610962, "step": 127000}
{"episode_reward": 949.6633641897462, "episode": 128.0, "batch_reward": 0.8767662934660911, "critic_loss": 0.39257261878997085, "actor_loss": -94.69446319580078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11692523956299, "step": 128000}
{"episode_reward": 905.3234085827186, "episode": 129.0, "batch_reward": 0.877667184472084, "critic_loss": 0.4199109177738428, "actor_loss": -94.67142878723145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.122154235839844, "step": 129000}
{"episode_reward": 981.4267897270735, "episode": 130.0, "batch_reward": 0.8791335179805756, "critic_loss": 0.41249852773547174, "actor_loss": -94.76639750671387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11748170852661, "step": 130000}
{"episode_reward": 815.7066298869152, "episode": 131.0, "batch_reward": 0.8772130302786827, "critic_loss": 0.48661531680077313, "actor_loss": -94.72016441345215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.62173914909363, "step": 131000}
{"episode_reward": 952.456708005844, "episode": 132.0, "batch_reward": 0.8769853815436364, "critic_loss": 0.4633777539283037, "actor_loss": -94.8673670349121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.110525369644165, "step": 132000}
{"episode_reward": 900.0859307425993, "episode": 133.0, "batch_reward": 0.8784329718351365, "critic_loss": 0.4854995080679655, "actor_loss": -94.76679014587403, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.124000310897827, "step": 133000}
{"episode_reward": 940.7321255017735, "episode": 134.0, "batch_reward": 0.8793786744475365, "critic_loss": 0.4558311450779438, "actor_loss": -94.692439453125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10360836982727, "step": 134000}
{"episode_reward": 941.174477569874, "episode": 135.0, "batch_reward": 0.8791935068964958, "critic_loss": 0.4367923750281334, "actor_loss": -94.84295657348633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.097652673721313, "step": 135000}
{"episode_reward": 929.9615761562395, "episode": 136.0, "batch_reward": 0.8802599733471871, "critic_loss": 0.43055744023621084, "actor_loss": -94.61602363586425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.100467681884766, "step": 136000}
{"episode_reward": 937.1228566740429, "episode": 137.0, "batch_reward": 0.8791880288124084, "critic_loss": 0.45185406066477296, "actor_loss": -94.81743923950195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.089165687561035, "step": 137000}
{"episode_reward": 888.7303219623449, "episode": 138.0, "batch_reward": 0.8816068357229233, "critic_loss": 0.4237802319601178, "actor_loss": -94.83298997497559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1035258769989, "step": 138000}
{"episode_reward": 951.0178449929981, "episode": 139.0, "batch_reward": 0.8808578099012375, "critic_loss": 0.43977786172926425, "actor_loss": -94.82150701904297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.089658737182617, "step": 139000}
{"episode_reward": 946.8547310956732, "episode": 140.0, "batch_reward": 0.8829688856005669, "critic_loss": 0.44038754914700984, "actor_loss": -94.88399038696289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.099527597427368, "step": 140000}
{"episode_reward": 951.4996226602727, "episode": 141.0, "batch_reward": 0.8803881548643112, "critic_loss": 0.47400331200659274, "actor_loss": -94.81001376342773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.63604497909546, "step": 141000}
{"episode_reward": 851.0306355787217, "episode": 142.0, "batch_reward": 0.8811621279716492, "critic_loss": 0.45643023936450483, "actor_loss": -94.77053050231933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.108415603637695, "step": 142000}
{"episode_reward": 925.6086624275802, "episode": 143.0, "batch_reward": 0.8815126326084137, "critic_loss": 0.4346133775860071, "actor_loss": -94.80781526184082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.081782341003418, "step": 143000}
{"episode_reward": 906.6076408169411, "episode": 144.0, "batch_reward": 0.8817602866888046, "critic_loss": 0.4339315067380667, "actor_loss": -94.91113827514648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.101576566696167, "step": 144000}
{"episode_reward": 900.3466051449325, "episode": 145.0, "batch_reward": 0.8818283253312111, "critic_loss": 0.4203186235204339, "actor_loss": -94.93398167419434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.099955320358276, "step": 145000}
{"episode_reward": 871.0463772662995, "episode": 146.0, "batch_reward": 0.8820332047343254, "critic_loss": 0.4403058673143387, "actor_loss": -94.98231825256347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.111311674118042, "step": 146000}
{"episode_reward": 958.1179548697936, "episode": 147.0, "batch_reward": 0.8832438091635704, "critic_loss": 0.4331272325664759, "actor_loss": -94.95023335266113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.111152172088623, "step": 147000}
{"episode_reward": 899.7079828230254, "episode": 148.0, "batch_reward": 0.8818313027620316, "critic_loss": 0.4241608853712678, "actor_loss": -94.91043496704101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.114049911499023, "step": 148000}
{"episode_reward": 915.4979513723991, "episode": 149.0, "batch_reward": 0.8816880400180817, "critic_loss": 0.43116006898134945, "actor_loss": -94.91542658996582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.111626863479614, "step": 149000}
{"episode_reward": 973.1350535691118, "episode": 150.0, "batch_reward": 0.8823879654407502, "critic_loss": 0.42200275230407713, "actor_loss": -94.94613230895996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
