{"episode_reward": 0.0, "episode": 1.0, "duration": 22.27294921875, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.903531551361084, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.4350755709425614, "critic_loss": 0.07594991454676976, "actor_loss": -28.19336030635537, "actor_target_entropy": -6.0, "alpha_value": 0.002642586817083679, "duration": 62.429187536239624, "step": 3000}
{"episode_reward": 7.8684059781843345, "episode": 4.0, "batch_reward": 0.2738777627050877, "critic_loss": 0.15341598253697156, "actor_loss": -26.68928849411011, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.58393144607544, "step": 4000}
{"episode_reward": 25.694344721675527, "episode": 5.0, "batch_reward": 0.21709131730347872, "critic_loss": 0.23839208807051182, "actor_loss": -28.64792819881439, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.86128306388855, "step": 5000}
{"episode_reward": 7.479300801569824, "episode": 6.0, "batch_reward": 0.17848989922553302, "critic_loss": 0.20788457100838423, "actor_loss": -26.296837313652038, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.19442844390869, "step": 6000}
{"episode_reward": 7.451957172221335, "episode": 7.0, "batch_reward": 0.1526217783242464, "critic_loss": 0.24317953097820283, "actor_loss": -26.584830039978026, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.01014494895935, "step": 7000}
{"episode_reward": 11.796088560986947, "episode": 8.0, "batch_reward": 0.13578407980501653, "critic_loss": 0.28849985744059087, "actor_loss": -28.968090744018554, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.46661877632141, "step": 8000}
{"episode_reward": 42.084057054537205, "episode": 9.0, "batch_reward": 0.12338164613768458, "critic_loss": 0.5217090756818652, "actor_loss": -28.266477159500123, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.370853662490845, "step": 9000}
{"episode_reward": 38.60647711087147, "episode": 10.0, "batch_reward": 0.1163800913579762, "critic_loss": 0.6687382773458957, "actor_loss": -29.913944241523744, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.542173147201538, "step": 10000}
{"episode_reward": 66.04478714105973, "episode": 11.0, "batch_reward": 0.11102281337976455, "critic_loss": 0.581442525882274, "actor_loss": -27.647665311813356, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.75983166694641, "step": 11000}
{"episode_reward": 79.62632293484212, "episode": 12.0, "batch_reward": 0.1081930937692523, "critic_loss": 1.7893675867393612, "actor_loss": -31.92979128742218, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.841878175735474, "step": 12000}
{"episode_reward": 31.61464113829823, "episode": 13.0, "batch_reward": 0.10349493936821819, "critic_loss": 2.1099159140884876, "actor_loss": -31.50838447189331, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.87688660621643, "step": 13000}
{"episode_reward": 101.26138214447478, "episode": 14.0, "batch_reward": 0.10346965854614973, "critic_loss": 1.9747505014836788, "actor_loss": -32.6265977230072, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.100169897079468, "step": 14000}
{"episode_reward": 111.03023325412897, "episode": 15.0, "batch_reward": 0.10449857204407453, "critic_loss": 2.547726105391979, "actor_loss": -32.63773592948914, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.607946395874023, "step": 15000}
{"episode_reward": 124.27385563950736, "episode": 16.0, "batch_reward": 0.10528166249766946, "critic_loss": 4.482847114443779, "actor_loss": -43.050260124206545, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.92633295059204, "step": 16000}
{"episode_reward": 67.80789682861115, "episode": 17.0, "batch_reward": 0.10392758007720113, "critic_loss": 5.457393238544464, "actor_loss": -48.86842632293701, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.17622470855713, "step": 17000}
{"episode_reward": 130.23460071244023, "episode": 18.0, "batch_reward": 0.1024306100346148, "critic_loss": 6.239728948831559, "actor_loss": -53.48912755584717, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.490344047546387, "step": 18000}
{"episode_reward": 65.78002116012033, "episode": 19.0, "batch_reward": 0.1071799162067473, "critic_loss": 7.050280977725983, "actor_loss": -58.83777908325195, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.394663095474243, "step": 19000}
{"episode_reward": 260.8617498745226, "episode": 20.0, "batch_reward": 0.11200634907186031, "critic_loss": 8.324308551073074, "actor_loss": -62.5203102645874, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.813668966293335, "step": 20000}
{"episode_reward": 166.86674126982743, "episode": 21.0, "batch_reward": 0.11747727208584548, "critic_loss": 9.22038808274269, "actor_loss": -67.51211893463135, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.12938714027405, "step": 21000}
{"episode_reward": 216.0455291848029, "episode": 22.0, "batch_reward": 0.12271183048188686, "critic_loss": 10.601499499082566, "actor_loss": -72.1034556503296, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.688618659973145, "step": 22000}
{"episode_reward": 238.4598370672403, "episode": 23.0, "batch_reward": 0.12390979737788439, "critic_loss": 11.466599992752075, "actor_loss": -77.84963244628906, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.38831067085266, "step": 23000}
{"episode_reward": 122.49380675872995, "episode": 24.0, "batch_reward": 0.13013698007166385, "critic_loss": 12.110513553142548, "actor_loss": -84.81121380615234, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.028870820999146, "step": 24000}
{"episode_reward": 453.7005259514392, "episode": 25.0, "batch_reward": 0.14003658540546893, "critic_loss": 12.180595626354217, "actor_loss": -91.22696379089355, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.29699158668518, "step": 25000}
{"episode_reward": 332.9609277160297, "episode": 26.0, "batch_reward": 0.15027402756363153, "critic_loss": 11.605892798423767, "actor_loss": -97.45714350891113, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.419257640838623, "step": 26000}
{"episode_reward": 454.95013343270944, "episode": 27.0, "batch_reward": 0.1559245431497693, "critic_loss": 10.659375573158265, "actor_loss": -102.56782051086425, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.834295511245728, "step": 27000}
{"episode_reward": 43.183695993469854, "episode": 28.0, "batch_reward": 0.1493584624454379, "critic_loss": 9.614781097888947, "actor_loss": -104.24230807495117, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.6175434589386, "step": 28000}
{"episode_reward": 51.23899403415536, "episode": 29.0, "batch_reward": 0.14794573432952166, "critic_loss": 8.188315078020096, "actor_loss": -107.90997924804688, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.631202220916748, "step": 29000}
{"episode_reward": 49.385397417018034, "episode": 30.0, "batch_reward": 0.1447999918460846, "critic_loss": 7.125879199504852, "actor_loss": -105.90644110107422, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.79190230369568, "step": 30000}
{"episode_reward": 47.85904739938465, "episode": 31.0, "batch_reward": 0.1423280655220151, "critic_loss": 6.757259796619415, "actor_loss": -105.33683976745606, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.45102858543396, "step": 31000}
{"episode_reward": 220.97190754722675, "episode": 32.0, "batch_reward": 0.14474165393412114, "critic_loss": 5.811575907945633, "actor_loss": -106.08883865356445, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.412672996520996, "step": 32000}
{"episode_reward": 190.16184057536006, "episode": 33.0, "batch_reward": 0.15113955260813236, "critic_loss": 5.247227655410766, "actor_loss": -106.18028454589843, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.788091897964478, "step": 33000}
{"episode_reward": 415.19675558734974, "episode": 34.0, "batch_reward": 0.15477559702843427, "critic_loss": 4.999767955541611, "actor_loss": -103.17646430969238, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.45384907722473, "step": 34000}
{"episode_reward": 271.62538434427955, "episode": 35.0, "batch_reward": 0.16423894137144088, "critic_loss": 4.369238931179047, "actor_loss": -103.31006797790528, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.78753924369812, "step": 35000}
{"episode_reward": 501.80209488334935, "episode": 36.0, "batch_reward": 0.16918906067311765, "critic_loss": 4.0406237577199935, "actor_loss": -101.12704777526855, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.92690134048462, "step": 36000}
{"episode_reward": 398.4047231864685, "episode": 37.0, "batch_reward": 0.18040431789308786, "critic_loss": 3.8160866522789, "actor_loss": -99.91759403991699, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.170045614242554, "step": 37000}
{"episode_reward": 561.4608153158666, "episode": 38.0, "batch_reward": 0.1928649361357093, "critic_loss": 3.415806722164154, "actor_loss": -100.50225755310059, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.425957202911377, "step": 38000}
{"episode_reward": 659.8679533358281, "episode": 39.0, "batch_reward": 0.20502521818876265, "critic_loss": 3.280850017786026, "actor_loss": -98.68904733276368, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.567380666732788, "step": 39000}
{"episode_reward": 802.6830686575346, "episode": 40.0, "batch_reward": 0.21689417742192746, "critic_loss": 2.72120426261425, "actor_loss": -97.27154931640625, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.844860792160034, "step": 40000}
{"episode_reward": 733.6699628321445, "episode": 41.0, "batch_reward": 0.2262862561047077, "critic_loss": 2.5344382400512697, "actor_loss": -96.10606130981445, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.050209522247314, "step": 41000}
{"episode_reward": 420.1026310387264, "episode": 42.0, "batch_reward": 0.23648762734234333, "critic_loss": 2.6746154009103775, "actor_loss": -95.6361789855957, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.92263650894165, "step": 42000}
{"episode_reward": 794.2038791595697, "episode": 43.0, "batch_reward": 0.25064409290254114, "critic_loss": 2.534579297184944, "actor_loss": -94.9112899017334, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.50727081298828, "step": 43000}
{"episode_reward": 820.4444501008455, "episode": 44.0, "batch_reward": 0.260552636295557, "critic_loss": 2.4244351358413696, "actor_loss": -94.34671867370605, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.93274164199829, "step": 44000}
{"episode_reward": 637.7378276818412, "episode": 45.0, "batch_reward": 0.26999022065103057, "critic_loss": 2.2974232013225557, "actor_loss": -94.34541191101074, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.60196614265442, "step": 45000}
{"episode_reward": 808.7487018801114, "episode": 46.0, "batch_reward": 0.28311020132899284, "critic_loss": 2.209733277916908, "actor_loss": -93.38913059997559, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.34931230545044, "step": 46000}
{"episode_reward": 770.9529898826928, "episode": 47.0, "batch_reward": 0.2928807063400745, "critic_loss": 2.170527347445488, "actor_loss": -92.32907614135742, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.596458435058594, "step": 47000}
{"episode_reward": 714.0970709008325, "episode": 48.0, "batch_reward": 0.30540127798914907, "critic_loss": 2.005776299893856, "actor_loss": -92.85067361450196, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.15947985649109, "step": 48000}
{"episode_reward": 892.0612825518116, "episode": 49.0, "batch_reward": 0.3171808596402407, "critic_loss": 1.9181671228408814, "actor_loss": -92.26267948913575, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.48505735397339, "step": 49000}
{"episode_reward": 820.3027392806038, "episode": 50.0, "batch_reward": 0.32686214135587216, "critic_loss": 1.8725300014019013, "actor_loss": -91.67011000061035, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.755837440490723, "step": 50000}
{"episode_reward": 835.0106413264035, "episode": 51.0, "batch_reward": 0.33612367902696133, "critic_loss": 1.9505276724100113, "actor_loss": -92.2915482635498, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.33199906349182, "step": 51000}
{"episode_reward": 765.287736475621, "episode": 52.0, "batch_reward": 0.34481951761245727, "critic_loss": 1.8566371892094613, "actor_loss": -91.24547045898437, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.454041957855225, "step": 52000}
{"episode_reward": 862.2175136672815, "episode": 53.0, "batch_reward": 0.3546344329416752, "critic_loss": 1.8533327905535697, "actor_loss": -91.57963409423829, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.37157893180847, "step": 53000}
{"episode_reward": 855.7561019786369, "episode": 54.0, "batch_reward": 0.3625833716392517, "critic_loss": 1.782541952908039, "actor_loss": -90.73975686645508, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.6437087059021, "step": 54000}
{"episode_reward": 841.2077423466596, "episode": 55.0, "batch_reward": 0.371784480497241, "critic_loss": 1.8848147131800652, "actor_loss": -90.1215613861084, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.715606451034546, "step": 55000}
{"episode_reward": 880.1338779913362, "episode": 56.0, "batch_reward": 0.3801569981276989, "critic_loss": 1.78682327991724, "actor_loss": -89.80166792297364, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.354700803756714, "step": 56000}
{"episode_reward": 847.6232560335093, "episode": 57.0, "batch_reward": 0.39133190661668776, "critic_loss": 1.7548876863718033, "actor_loss": -89.14201945495606, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.415374040603638, "step": 57000}
{"episode_reward": 900.1972685055324, "episode": 58.0, "batch_reward": 0.39950483909249307, "critic_loss": 1.7905947919487952, "actor_loss": -88.81101351928712, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.353018760681152, "step": 58000}
{"episode_reward": 861.5692930084464, "episode": 59.0, "batch_reward": 0.4044398149549961, "critic_loss": 1.938666019976139, "actor_loss": -88.19305267333985, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.441550731658936, "step": 59000}
{"episode_reward": 778.7022328231493, "episode": 60.0, "batch_reward": 0.41206215211749075, "critic_loss": 1.8376174492239952, "actor_loss": -87.71851190185546, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.369662523269653, "step": 60000}
{"episode_reward": 784.4446552091335, "episode": 61.0, "batch_reward": 0.418902960896492, "critic_loss": 1.8642801978588104, "actor_loss": -87.3915090789795, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.6013662815094, "step": 61000}
{"episode_reward": 851.6402685292676, "episode": 62.0, "batch_reward": 0.426417536854744, "critic_loss": 2.0126924225091933, "actor_loss": -87.35319673156738, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.22031331062317, "step": 62000}
{"episode_reward": 938.6381035728052, "episode": 63.0, "batch_reward": 0.4300437100529671, "critic_loss": 2.0605585200190544, "actor_loss": -86.96807427978516, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.82383108139038, "step": 63000}
{"episode_reward": 632.8468654229699, "episode": 64.0, "batch_reward": 0.4395520250797272, "critic_loss": 2.051782683491707, "actor_loss": -86.92178704833984, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.78977060317993, "step": 64000}
{"episode_reward": 887.5712259190386, "episode": 65.0, "batch_reward": 0.4453014373481274, "critic_loss": 2.481144287824631, "actor_loss": -86.84847700500488, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.437715530395508, "step": 65000}
{"episode_reward": 912.3063624045795, "episode": 66.0, "batch_reward": 0.45129609262943265, "critic_loss": 2.6475354488492013, "actor_loss": -86.84152565002441, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.753458499908447, "step": 66000}
{"episode_reward": 837.4527733010933, "episode": 67.0, "batch_reward": 0.45829874429106715, "critic_loss": 3.089937525510788, "actor_loss": -87.14759426879883, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.79671287536621, "step": 67000}
{"episode_reward": 784.9319545661483, "episode": 68.0, "batch_reward": 0.4571922624707222, "critic_loss": 3.101837838470936, "actor_loss": -87.5057946472168, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.682556867599487, "step": 68000}
{"episode_reward": 57.30005848137283, "episode": 69.0, "batch_reward": 0.4574537147581577, "critic_loss": 2.924363159894943, "actor_loss": -88.0491979522705, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.987199783325195, "step": 69000}
{"episode_reward": 869.8202447834244, "episode": 70.0, "batch_reward": 0.45626714038848876, "critic_loss": 2.8180672721862794, "actor_loss": -88.5503790435791, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.726606845855713, "step": 70000}
{"episode_reward": 48.23227711317098, "episode": 71.0, "batch_reward": 0.44826019468903544, "critic_loss": 2.572374710917473, "actor_loss": -89.42269586181641, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.07067370414734, "step": 71000}
{"episode_reward": 44.51896895500874, "episode": 72.0, "batch_reward": 0.4507585012614727, "critic_loss": 2.2245656114816668, "actor_loss": -89.8472871246338, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.712345600128174, "step": 72000}
{"episode_reward": 905.3122899209912, "episode": 73.0, "batch_reward": 0.455503755658865, "critic_loss": 2.2878069870471953, "actor_loss": -90.0268289794922, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.915950536727905, "step": 73000}
{"episode_reward": 945.8285494398602, "episode": 74.0, "batch_reward": 0.4585056878626347, "critic_loss": 2.06479918718338, "actor_loss": -90.02114329528808, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.76589560508728, "step": 74000}
{"episode_reward": 461.18668163089274, "episode": 75.0, "batch_reward": 0.4665415939092636, "critic_loss": 1.9346236119866371, "actor_loss": -90.07714671325684, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.398557662963867, "step": 75000}
{"episode_reward": 938.23637519065, "episode": 76.0, "batch_reward": 0.4686252214610577, "critic_loss": 2.0109669139981268, "actor_loss": -89.77704061889648, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.8403582572937, "step": 76000}
{"episode_reward": 848.8211659677653, "episode": 77.0, "batch_reward": 0.4753440732657909, "critic_loss": 1.875524845957756, "actor_loss": -89.85912289428711, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.31251049041748, "step": 77000}
{"episode_reward": 933.5586873503664, "episode": 78.0, "batch_reward": 0.47932089447975157, "critic_loss": 1.9797086572647096, "actor_loss": -89.62611642456055, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.77753233909607, "step": 78000}
{"episode_reward": 613.0237405033772, "episode": 79.0, "batch_reward": 0.48118650591373446, "critic_loss": 2.0213312718272207, "actor_loss": -89.57045739746094, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.921053409576416, "step": 79000}
{"episode_reward": 832.6449486360502, "episode": 80.0, "batch_reward": 0.4822376172542572, "critic_loss": 2.057909640610218, "actor_loss": -89.45038307189941, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.645694494247437, "step": 80000}
{"episode_reward": 69.5145406766759, "episode": 81.0, "batch_reward": 0.47595505064725874, "critic_loss": 2.086306462407112, "actor_loss": -89.47726806640625, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.61977815628052, "step": 81000}
{"episode_reward": 15.647415653040012, "episode": 82.0, "batch_reward": 0.46819466960430145, "critic_loss": 2.9856102731227874, "actor_loss": -89.42963270568848, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.379754066467285, "step": 82000}
{"episode_reward": 184.802100543523, "episode": 83.0, "batch_reward": 0.4675294969379902, "critic_loss": 5.175807527184486, "actor_loss": -91.21959411621094, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.85665464401245, "step": 83000}
{"episode_reward": 67.89228908231237, "episode": 84.0, "batch_reward": 0.4607296954989433, "critic_loss": 8.409002546310425, "actor_loss": -96.30180772399902, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.92076325416565, "step": 84000}
{"episode_reward": 66.18543993561023, "episode": 85.0, "batch_reward": 0.4551388293206692, "critic_loss": 10.814557225704194, "actor_loss": -105.7172943725586, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.089761972427368, "step": 85000}
{"episode_reward": 63.02847715830416, "episode": 86.0, "batch_reward": 0.45299639520049095, "critic_loss": 12.189170309066773, "actor_loss": -112.92789059448242, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.601300477981567, "step": 86000}
{"episode_reward": 72.44482820162824, "episode": 87.0, "batch_reward": 0.44880109670758245, "critic_loss": 12.708877903461456, "actor_loss": -119.06351220703125, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.380398750305176, "step": 87000}
{"episode_reward": 87.58672799084127, "episode": 88.0, "batch_reward": 0.44609760212898253, "critic_loss": 12.020071599960326, "actor_loss": -122.48776271057129, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.10358428955078, "step": 88000}
{"episode_reward": 96.42938271841385, "episode": 89.0, "batch_reward": 0.44284365755319594, "critic_loss": 11.947489696979522, "actor_loss": -124.56939157104492, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.62374472618103, "step": 89000}
{"episode_reward": 130.03375170142843, "episode": 90.0, "batch_reward": 0.4392021643817425, "critic_loss": 11.163262923717499, "actor_loss": -126.70467861938477, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.54559826850891, "step": 90000}
{"episode_reward": 409.9205075026392, "episode": 91.0, "batch_reward": 0.4390285410284996, "critic_loss": 9.79849364709854, "actor_loss": -126.02633746337891, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.84420824050903, "step": 91000}
{"episode_reward": 719.8369687391438, "episode": 92.0, "batch_reward": 0.4431576270461082, "critic_loss": 7.228929398298264, "actor_loss": -123.9189514465332, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.631423234939575, "step": 92000}
{"episode_reward": 597.3027904871205, "episode": 93.0, "batch_reward": 0.44458576452732085, "critic_loss": 6.16914386844635, "actor_loss": -123.09434275817871, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.095181226730347, "step": 93000}
{"episode_reward": 651.594323334091, "episode": 94.0, "batch_reward": 0.45156918609142305, "critic_loss": 5.219049761295318, "actor_loss": -121.83208657836914, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.32953643798828, "step": 94000}
{"episode_reward": 914.4947114997924, "episode": 95.0, "batch_reward": 0.4530183192789555, "critic_loss": 4.185073824763298, "actor_loss": -123.30908229064941, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.770423889160156, "step": 95000}
{"episode_reward": 796.5723724984201, "episode": 96.0, "batch_reward": 0.45657281422615054, "critic_loss": 3.573017288804054, "actor_loss": -117.34839532470703, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.899568557739258, "step": 96000}
{"episode_reward": 888.3276666402544, "episode": 97.0, "batch_reward": 0.4617990235090256, "critic_loss": 3.0738567819595337, "actor_loss": -118.1617117767334, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.869476079940796, "step": 97000}
{"episode_reward": 932.1147496331464, "episode": 98.0, "batch_reward": 0.46586262485384944, "critic_loss": 2.824509847640991, "actor_loss": -119.19429527282715, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.858452558517456, "step": 98000}
{"episode_reward": 900.2764381158286, "episode": 99.0, "batch_reward": 0.46830761340260507, "critic_loss": 2.4196705857515335, "actor_loss": -114.34275518798827, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.88624143600464, "step": 99000}
{"episode_reward": 521.5672192448885, "episode": 100.0, "batch_reward": 0.4662501792013645, "critic_loss": 2.2315912130475044, "actor_loss": -113.98085734558106, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.62744402885437, "step": 100000}
{"episode_reward": 64.39688314348473, "episode": 101.0, "batch_reward": 0.4695470413863659, "critic_loss": 2.046794515132904, "actor_loss": -111.76153857421875, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.06234550476074, "step": 101000}
{"episode_reward": 951.3322353956739, "episode": 102.0, "batch_reward": 0.4718666838109493, "critic_loss": 1.8761564328670501, "actor_loss": -111.24391876220703, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.35801601409912, "step": 102000}
{"episode_reward": 923.212353650638, "episode": 103.0, "batch_reward": 0.4769292615354061, "critic_loss": 1.7668944820165635, "actor_loss": -110.31831455993652, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.347747564315796, "step": 103000}
{"episode_reward": 938.379638923574, "episode": 104.0, "batch_reward": 0.4782908663749695, "critic_loss": 1.6882064622044564, "actor_loss": -108.76208793640137, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.45669412612915, "step": 104000}
{"episode_reward": 919.4094267824535, "episode": 105.0, "batch_reward": 0.48589735382795335, "critic_loss": 1.5233498811721802, "actor_loss": -107.80649327087403, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.537219524383545, "step": 105000}
{"episode_reward": 952.9440995183083, "episode": 106.0, "batch_reward": 0.4887328426241875, "critic_loss": 1.5564781236052514, "actor_loss": -106.12403858947754, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.713875770568848, "step": 106000}
{"episode_reward": 915.2810444525563, "episode": 107.0, "batch_reward": 0.4938433514535427, "critic_loss": 1.490207568347454, "actor_loss": -105.35897122192382, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.34681248664856, "step": 107000}
{"episode_reward": 896.681564364635, "episode": 108.0, "batch_reward": 0.4972474220097065, "critic_loss": 1.5492081488966942, "actor_loss": -106.04546099853516, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.784600019454956, "step": 108000}
{"episode_reward": 925.6004384786329, "episode": 109.0, "batch_reward": 0.4991570056080818, "critic_loss": 1.4609624145627023, "actor_loss": -104.25182412719727, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.96862506866455, "step": 109000}
{"episode_reward": 888.2097027035347, "episode": 110.0, "batch_reward": 0.5015603398382664, "critic_loss": 1.378700386106968, "actor_loss": -103.19424433898926, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.785494089126587, "step": 110000}
{"episode_reward": 66.7360072414081, "episode": 111.0, "batch_reward": 0.4998174880445003, "critic_loss": 1.3452039394378663, "actor_loss": -103.6642134552002, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.6994731426239, "step": 111000}
{"episode_reward": 898.3546927447344, "episode": 112.0, "batch_reward": 0.5064959752857685, "critic_loss": 1.374254310309887, "actor_loss": -101.40729843139648, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.808908700942993, "step": 112000}
{"episode_reward": 928.9318823014127, "episode": 113.0, "batch_reward": 0.5072825621068477, "critic_loss": 1.3069202365279198, "actor_loss": -101.40015422058106, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.71560049057007, "step": 113000}
{"episode_reward": 908.937594259461, "episode": 114.0, "batch_reward": 0.5096440992653369, "critic_loss": 1.206892481982708, "actor_loss": -100.66134567260742, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.671249866485596, "step": 114000}
{"episode_reward": 975.0235947590171, "episode": 115.0, "batch_reward": 0.5146733803153039, "critic_loss": 1.1750813100934028, "actor_loss": -100.24450759887695, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.120224952697754, "step": 115000}
{"episode_reward": 955.8668102642364, "episode": 116.0, "batch_reward": 0.5221936057806015, "critic_loss": 1.121735546886921, "actor_loss": -99.9777075805664, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.524548768997192, "step": 116000}
{"episode_reward": 935.7061972123512, "episode": 117.0, "batch_reward": 0.5216628416180611, "critic_loss": 1.0384985631406307, "actor_loss": -99.73484510803223, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.585063695907593, "step": 117000}
{"episode_reward": 932.1998231761659, "episode": 118.0, "batch_reward": 0.523371494680643, "critic_loss": 1.0339703044891357, "actor_loss": -98.81153736877441, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.50083827972412, "step": 118000}
{"episode_reward": 72.05452046102087, "episode": 119.0, "batch_reward": 0.5227529356181622, "critic_loss": 1.0173338086307049, "actor_loss": -97.85457513427734, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.233848333358765, "step": 119000}
{"episode_reward": 959.4692844664471, "episode": 120.0, "batch_reward": 0.5271799048781395, "critic_loss": 1.0377633136808873, "actor_loss": -97.74527801513672, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.909263134002686, "step": 120000}
{"episode_reward": 955.5605085436312, "episode": 121.0, "batch_reward": 0.5300107479989529, "critic_loss": 0.9354796783626079, "actor_loss": -96.3928083190918, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.2655885219574, "step": 121000}
{"episode_reward": 939.2505580710496, "episode": 122.0, "batch_reward": 0.5331118954718113, "critic_loss": 0.9755920245349408, "actor_loss": -95.86714904785157, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.616206407546997, "step": 122000}
{"episode_reward": 841.7121232043957, "episode": 123.0, "batch_reward": 0.5365912592709065, "critic_loss": 0.9937444621026515, "actor_loss": -95.12525045776367, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.63676142692566, "step": 123000}
{"episode_reward": 953.1824480775787, "episode": 124.0, "batch_reward": 0.5384354296326638, "critic_loss": 0.97054302495718, "actor_loss": -94.42859382629395, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.334836959838867, "step": 124000}
{"episode_reward": 944.2307189384715, "episode": 125.0, "batch_reward": 0.5394026772677898, "critic_loss": 1.0491143048107625, "actor_loss": -93.90307070922852, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.21755886077881, "step": 125000}
{"episode_reward": 57.49821487008036, "episode": 126.0, "batch_reward": 0.5390229265093803, "critic_loss": 1.1080461339652539, "actor_loss": -93.54785020446778, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.648371696472168, "step": 126000}
{"episode_reward": 959.5422614715429, "episode": 127.0, "batch_reward": 0.5411117218136787, "critic_loss": 0.9940581650137902, "actor_loss": -92.78427531433105, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.383965492248535, "step": 127000}
{"episode_reward": 959.629288603798, "episode": 128.0, "batch_reward": 0.54518959659338, "critic_loss": 1.0011689758002758, "actor_loss": -92.39247247314454, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.485443353652954, "step": 128000}
{"episode_reward": 942.8865481638699, "episode": 129.0, "batch_reward": 0.5466455878019333, "critic_loss": 1.061333816587925, "actor_loss": -92.15685134887696, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.528594255447388, "step": 129000}
{"episode_reward": 935.8726927869609, "episode": 130.0, "batch_reward": 0.5536523390710354, "critic_loss": 0.9067607651650905, "actor_loss": -91.9312195892334, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.455798864364624, "step": 130000}
{"episode_reward": 956.092546851804, "episode": 131.0, "batch_reward": 0.5553143480420113, "critic_loss": 0.9877905316650868, "actor_loss": -91.58181285095215, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.80666446685791, "step": 131000}
{"episode_reward": 942.4498538113955, "episode": 132.0, "batch_reward": 0.5557080308496952, "critic_loss": 0.9633349128067493, "actor_loss": -91.11147792053222, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.75415349006653, "step": 132000}
{"episode_reward": 937.0002994151122, "episode": 133.0, "batch_reward": 0.5575367572009563, "critic_loss": 0.941363932788372, "actor_loss": -90.83236599731445, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.753786087036133, "step": 133000}
{"episode_reward": 59.4101706190449, "episode": 134.0, "batch_reward": 0.5568152588009835, "critic_loss": 0.8874610158205032, "actor_loss": -90.2868857421875, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.64891791343689, "step": 134000}
{"episode_reward": 966.469713375038, "episode": 135.0, "batch_reward": 0.560835649996996, "critic_loss": 0.8619040698409081, "actor_loss": -89.95815577697753, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.229515075683594, "step": 135000}
{"episode_reward": 949.6741431591886, "episode": 136.0, "batch_reward": 0.5626631191074848, "critic_loss": 0.8921604053676129, "actor_loss": -89.87558239746093, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.526880264282227, "step": 136000}
{"episode_reward": 953.7420181620786, "episode": 137.0, "batch_reward": 0.564813389569521, "critic_loss": 0.8852638954818248, "actor_loss": -89.52010137939453, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.448264837265015, "step": 137000}
{"episode_reward": 957.317950238218, "episode": 138.0, "batch_reward": 0.5704200250506402, "critic_loss": 0.8582142440974713, "actor_loss": -89.28040966796875, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.713730812072754, "step": 138000}
{"episode_reward": 951.580693341236, "episode": 139.0, "batch_reward": 0.5714550596475602, "critic_loss": 0.8418377099335194, "actor_loss": -89.11018292236328, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.86664366722107, "step": 139000}
{"episode_reward": 953.2928648328729, "episode": 140.0, "batch_reward": 0.5777395651340484, "critic_loss": 0.833156143784523, "actor_loss": -89.01982681274414, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.761475563049316, "step": 140000}
{"episode_reward": 908.7712091718636, "episode": 141.0, "batch_reward": 0.5749835746586323, "critic_loss": 0.8009131727516651, "actor_loss": -88.65669018554688, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.79876661300659, "step": 141000}
{"episode_reward": 930.9348974630598, "episode": 142.0, "batch_reward": 0.5758998474180699, "critic_loss": 0.7749594346880913, "actor_loss": -88.53755856323242, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.264302015304565, "step": 142000}
{"episode_reward": 910.7511339724555, "episode": 143.0, "batch_reward": 0.5783309737443924, "critic_loss": 0.7872278243899345, "actor_loss": -88.41881016540528, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.042463302612305, "step": 143000}
{"episode_reward": 875.8754765520603, "episode": 144.0, "batch_reward": 0.5847813484668731, "critic_loss": 0.775324904948473, "actor_loss": -88.48286636352539, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.377594232559204, "step": 144000}
{"episode_reward": 901.0612361825292, "episode": 145.0, "batch_reward": 0.5848843728601932, "critic_loss": 0.8495203368663787, "actor_loss": -88.23341334533691, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.82217264175415, "step": 145000}
{"episode_reward": 940.1307446760038, "episode": 146.0, "batch_reward": 0.5867527281045913, "critic_loss": 0.8645612829625606, "actor_loss": -88.16929025268554, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.681607246398926, "step": 146000}
{"episode_reward": 961.9342497679953, "episode": 147.0, "batch_reward": 0.5880654627382755, "critic_loss": 0.8307715530097485, "actor_loss": -88.00388325500488, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.872199058532715, "step": 147000}
{"episode_reward": 904.4952315081463, "episode": 148.0, "batch_reward": 0.5939291397929192, "critic_loss": 0.7923452280759812, "actor_loss": -87.92548065185547, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.61329984664917, "step": 148000}
{"episode_reward": 913.7743565494733, "episode": 149.0, "batch_reward": 0.593723787099123, "critic_loss": 0.7592557262480258, "actor_loss": -87.75594519042968, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.582279682159424, "step": 149000}
{"episode_reward": 963.677362641382, "episode": 150.0, "batch_reward": 0.5970689264833927, "critic_loss": 0.7571182227730751, "actor_loss": -87.7331455078125, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "step": 150000}
