{"episode_reward": 0.0, "episode": 1.0, "duration": 20.97914218902588, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.8262338638305664, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.4484499178357266, "critic_loss": 0.20687367367114412, "actor_loss": -83.50642665818769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 59.063788175582886, "step": 3000}
{"episode_reward": 318.7887994097989, "episode": 4.0, "batch_reward": 0.38767122918367386, "critic_loss": 0.3737825486958027, "actor_loss": -82.27255676269532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.75791907310486, "step": 4000}
{"episode_reward": 143.2563303892279, "episode": 5.0, "batch_reward": 0.364061471387744, "critic_loss": 0.683611309170723, "actor_loss": -81.81769830322266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.78064513206482, "step": 5000}
{"episode_reward": 594.6762816686712, "episode": 6.0, "batch_reward": 0.41320114412903786, "critic_loss": 0.9131963359415531, "actor_loss": -82.7760399017334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.794618606567383, "step": 6000}
{"episode_reward": 640.6858953390173, "episode": 7.0, "batch_reward": 0.456600481569767, "critic_loss": 0.9732801889777184, "actor_loss": -83.72039378356934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.803257703781128, "step": 7000}
{"episode_reward": 724.5404318494351, "episode": 8.0, "batch_reward": 0.4981257663965225, "critic_loss": 1.122091921389103, "actor_loss": -85.14768170166016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.764302968978882, "step": 8000}
{"episode_reward": 790.140274733105, "episode": 9.0, "batch_reward": 0.5085450082421302, "critic_loss": 1.2757958472967148, "actor_loss": -85.12498323059081, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.797722578048706, "step": 9000}
{"episode_reward": 263.1206070131945, "episode": 10.0, "batch_reward": 0.5008368321955204, "critic_loss": 1.3162206571102142, "actor_loss": -84.77068942260742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.775514602661133, "step": 10000}
{"episode_reward": 721.1263573935067, "episode": 11.0, "batch_reward": 0.5232276315391063, "critic_loss": 1.4664117853045464, "actor_loss": -85.39249908447266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.44494390487671, "step": 11000}
{"episode_reward": 764.762661539065, "episode": 12.0, "batch_reward": 0.5430192449390888, "critic_loss": 1.6643655286431314, "actor_loss": -85.69590983581543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.779468536376953, "step": 12000}
{"episode_reward": 767.410828699889, "episode": 13.0, "batch_reward": 0.5534355835020542, "critic_loss": 1.7527671221494674, "actor_loss": -85.95829930114746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.783973455429077, "step": 13000}
{"episode_reward": 667.4893051922234, "episode": 14.0, "batch_reward": 0.5662032785713673, "critic_loss": 1.6737880557775497, "actor_loss": -86.0557021636963, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.793031215667725, "step": 14000}
{"episode_reward": 802.5552517022796, "episode": 15.0, "batch_reward": 0.5834096918702125, "critic_loss": 1.5732019113302231, "actor_loss": -85.85988409423828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.826504945755005, "step": 15000}
{"episode_reward": 793.6955411318188, "episode": 16.0, "batch_reward": 0.602147154301405, "critic_loss": 1.3591615190505981, "actor_loss": -87.16817807006836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.798043727874756, "step": 16000}
{"episode_reward": 923.4349761940739, "episode": 17.0, "batch_reward": 0.619404332458973, "critic_loss": 1.354826882123947, "actor_loss": -87.3050855102539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.79844880104065, "step": 17000}
{"episode_reward": 767.3975289392146, "episode": 18.0, "batch_reward": 0.6313422203063965, "critic_loss": 1.2400892168283462, "actor_loss": -87.60596324157714, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.803317070007324, "step": 18000}
{"episode_reward": 908.5070117947932, "episode": 19.0, "batch_reward": 0.642206986784935, "critic_loss": 1.2505620748400688, "actor_loss": -87.90699078369141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.799816370010376, "step": 19000}
{"episode_reward": 840.7968285095353, "episode": 20.0, "batch_reward": 0.6534565901756286, "critic_loss": 1.258135445177555, "actor_loss": -87.5758581237793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.814538955688477, "step": 20000}
{"episode_reward": 687.2352311707622, "episode": 21.0, "batch_reward": 0.6554410063624382, "critic_loss": 1.196959966301918, "actor_loss": -87.77472325134278, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.73416090011597, "step": 21000}
{"episode_reward": 625.2742477294133, "episode": 22.0, "batch_reward": 0.6571454826593399, "critic_loss": 1.2202187141776084, "actor_loss": -87.65612391662597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.785818338394165, "step": 22000}
{"episode_reward": 894.3246701681069, "episode": 23.0, "batch_reward": 0.664633654475212, "critic_loss": 1.1353453792333603, "actor_loss": -87.93820294189453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.766139030456543, "step": 23000}
{"episode_reward": 902.2546397752244, "episode": 24.0, "batch_reward": 0.6769368787407875, "critic_loss": 1.1486729855537414, "actor_loss": -88.42680032348633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.752955436706543, "step": 24000}
{"episode_reward": 949.395080435461, "episode": 25.0, "batch_reward": 0.686684387087822, "critic_loss": 1.119783863067627, "actor_loss": -88.4502455444336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.795267343521118, "step": 25000}
{"episode_reward": 861.5063558236166, "episode": 26.0, "batch_reward": 0.6930584033131599, "critic_loss": 1.1355009533166884, "actor_loss": -88.56969563293457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.791732788085938, "step": 26000}
{"episode_reward": 898.6790445393757, "episode": 27.0, "batch_reward": 0.6980358709096909, "critic_loss": 1.1648613711595535, "actor_loss": -88.39211006164551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.77101969718933, "step": 27000}
{"episode_reward": 390.7648003858374, "episode": 28.0, "batch_reward": 0.6895335233807564, "critic_loss": 1.1353137810230256, "actor_loss": -88.37676206970215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.786872148513794, "step": 28000}
{"episode_reward": 882.7359049740777, "episode": 29.0, "batch_reward": 0.6977497515678406, "critic_loss": 1.245039155304432, "actor_loss": -88.26024812316895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.78704285621643, "step": 29000}
{"episode_reward": 897.541527221868, "episode": 30.0, "batch_reward": 0.7019306541085243, "critic_loss": 1.1449030705094339, "actor_loss": -88.34433303833008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.79521942138672, "step": 30000}
{"episode_reward": 882.7104359205043, "episode": 31.0, "batch_reward": 0.7091752026081085, "critic_loss": 1.1582312663793564, "actor_loss": -88.84621052551269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.446343421936035, "step": 31000}
{"episode_reward": 873.3132773625415, "episode": 32.0, "batch_reward": 0.7154635584950447, "critic_loss": 1.1624870772361755, "actor_loss": -88.89202430725098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.819702863693237, "step": 32000}
{"episode_reward": 903.4784633941003, "episode": 33.0, "batch_reward": 0.721251947939396, "critic_loss": 1.12592889046669, "actor_loss": -88.90315696716308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.814924478530884, "step": 33000}
{"episode_reward": 884.1429010517512, "episode": 34.0, "batch_reward": 0.7253020115494728, "critic_loss": 1.1134741262793542, "actor_loss": -89.35869520568848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.77328133583069, "step": 34000}
{"episode_reward": 903.3243509034882, "episode": 35.0, "batch_reward": 0.7254930751919746, "critic_loss": 1.172215784907341, "actor_loss": -88.9409181060791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.80032992362976, "step": 35000}
{"episode_reward": 662.1698049940399, "episode": 36.0, "batch_reward": 0.7292968765497208, "critic_loss": 1.1395652698874474, "actor_loss": -89.71526869201661, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.787017107009888, "step": 36000}
{"episode_reward": 875.8302992094387, "episode": 37.0, "batch_reward": 0.7338722157478332, "critic_loss": 1.0740676255524158, "actor_loss": -89.5478126525879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.768433094024658, "step": 37000}
{"episode_reward": 896.7942513129599, "episode": 38.0, "batch_reward": 0.7375212081670761, "critic_loss": 1.0440539529919624, "actor_loss": -89.23432620239258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.79543900489807, "step": 38000}
{"episode_reward": 928.0243113979882, "episode": 39.0, "batch_reward": 0.7435674257278443, "critic_loss": 1.0040693043768405, "actor_loss": -89.79147245788575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.74917697906494, "step": 39000}
{"episode_reward": 942.1502144183078, "episode": 40.0, "batch_reward": 0.7452731263041497, "critic_loss": 0.9983228211700916, "actor_loss": -89.95529457092285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.76191782951355, "step": 40000}
{"episode_reward": 914.9313343491705, "episode": 41.0, "batch_reward": 0.7511788222193718, "critic_loss": 0.9840169847905635, "actor_loss": -90.32954554748535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.360329389572144, "step": 41000}
{"episode_reward": 910.9142385417772, "episode": 42.0, "batch_reward": 0.7521426702737808, "critic_loss": 1.0053401322066784, "actor_loss": -89.93847927856446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.794353723526, "step": 42000}
{"episode_reward": 487.3413728475221, "episode": 43.0, "batch_reward": 0.7521083211898804, "critic_loss": 0.9891002899110317, "actor_loss": -90.06588864135742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.77071762084961, "step": 43000}
{"episode_reward": 894.1522083952699, "episode": 44.0, "batch_reward": 0.7531532914042472, "critic_loss": 1.0709956353008747, "actor_loss": -89.74744602966308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.751465320587158, "step": 44000}
{"episode_reward": 873.1499881311647, "episode": 45.0, "batch_reward": 0.7563270716071129, "critic_loss": 1.1241174252331256, "actor_loss": -89.77101199340821, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.770307064056396, "step": 45000}
{"episode_reward": 920.9811737892028, "episode": 46.0, "batch_reward": 0.7600308447480202, "critic_loss": 1.1020299499630928, "actor_loss": -90.17128733825683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.756816625595093, "step": 46000}
{"episode_reward": 829.5931830880721, "episode": 47.0, "batch_reward": 0.7622619901299477, "critic_loss": 1.079299105256796, "actor_loss": -90.32417724609375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.77077865600586, "step": 47000}
{"episode_reward": 960.5096915555167, "episode": 48.0, "batch_reward": 0.7659764065742493, "critic_loss": 1.0828329630196094, "actor_loss": -90.4433205871582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.78810739517212, "step": 48000}
{"episode_reward": 937.5285815932232, "episode": 49.0, "batch_reward": 0.7692252940535546, "critic_loss": 1.088866556107998, "actor_loss": -90.6284733428955, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.781760931015015, "step": 49000}
{"episode_reward": 868.762879032941, "episode": 50.0, "batch_reward": 0.7722972021698952, "critic_loss": 1.100432974755764, "actor_loss": -90.51376382446288, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.793505668640137, "step": 50000}
{"episode_reward": 892.4289030944972, "episode": 51.0, "batch_reward": 0.7728486257791519, "critic_loss": 1.0852506421506405, "actor_loss": -90.86308345031738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.36791634559631, "step": 51000}
{"episode_reward": 867.643158158219, "episode": 52.0, "batch_reward": 0.7740992910265923, "critic_loss": 1.0441112973093987, "actor_loss": -91.00609744262695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.795605897903442, "step": 52000}
{"episode_reward": 876.7540902326415, "episode": 53.0, "batch_reward": 0.7772341505289078, "critic_loss": 1.0295344977974892, "actor_loss": -90.60144432067871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.804202795028687, "step": 53000}
{"episode_reward": 855.0281796156532, "episode": 54.0, "batch_reward": 0.779100749194622, "critic_loss": 1.0532796899080277, "actor_loss": -91.54812663269043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.783613920211792, "step": 54000}
{"episode_reward": 930.7919556107074, "episode": 55.0, "batch_reward": 0.7797856380939484, "critic_loss": 1.0177421241700648, "actor_loss": -91.29862979125977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.79643177986145, "step": 55000}
{"episode_reward": 889.1110077336969, "episode": 56.0, "batch_reward": 0.7819845445156097, "critic_loss": 1.049283578634262, "actor_loss": -90.99760472106934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.740619897842407, "step": 56000}
{"episode_reward": 974.9065415722231, "episode": 57.0, "batch_reward": 0.7861051622629166, "critic_loss": 1.0293584092259407, "actor_loss": -91.39540550231933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.752607345581055, "step": 57000}
{"episode_reward": 938.4079374637403, "episode": 58.0, "batch_reward": 0.7890978667140007, "critic_loss": 0.9538490200638771, "actor_loss": -91.48432736206054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.78775191307068, "step": 58000}
{"episode_reward": 896.3190810369365, "episode": 59.0, "batch_reward": 0.7919154605865478, "critic_loss": 0.9094434277415275, "actor_loss": -91.7189229888916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.779640436172485, "step": 59000}
{"episode_reward": 923.6977594976772, "episode": 60.0, "batch_reward": 0.7943783649206162, "critic_loss": 0.9048174787461758, "actor_loss": -91.55633822631836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.798558950424194, "step": 60000}
{"episode_reward": 874.4012741461637, "episode": 61.0, "batch_reward": 0.7949904490113259, "critic_loss": 0.9111126958727837, "actor_loss": -91.85015367126465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.32602643966675, "step": 61000}
{"episode_reward": 604.5705156620429, "episode": 62.0, "batch_reward": 0.7906821225881576, "critic_loss": 0.9265630255937576, "actor_loss": -91.32928582763672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.79823327064514, "step": 62000}
{"episode_reward": 936.1093110231534, "episode": 63.0, "batch_reward": 0.7919211568832397, "critic_loss": 0.9245738382339478, "actor_loss": -91.45006823730469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.825421810150146, "step": 63000}
{"episode_reward": 875.6149114409911, "episode": 64.0, "batch_reward": 0.794581645488739, "critic_loss": 0.9237456591427327, "actor_loss": -91.7103971710205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.79085683822632, "step": 64000}
{"episode_reward": 867.7247382947138, "episode": 65.0, "batch_reward": 0.7961624960303306, "critic_loss": 0.9325667785704136, "actor_loss": -91.41875190734864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.80155086517334, "step": 65000}
{"episode_reward": 895.1808661244587, "episode": 66.0, "batch_reward": 0.7972126479744911, "critic_loss": 0.9168543401062489, "actor_loss": -91.57996977233887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.791077375411987, "step": 66000}
{"episode_reward": 937.8699248979091, "episode": 67.0, "batch_reward": 0.8015679733157158, "critic_loss": 0.8936905698180199, "actor_loss": -91.58961080932617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.79002094268799, "step": 67000}
{"episode_reward": 915.6552698340917, "episode": 68.0, "batch_reward": 0.8014377517104149, "critic_loss": 0.9090286402404308, "actor_loss": -92.04456118774414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.777299642562866, "step": 68000}
{"episode_reward": 930.2891980855062, "episode": 69.0, "batch_reward": 0.803440610408783, "critic_loss": 0.8881551652550698, "actor_loss": -92.0053680267334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.77861499786377, "step": 69000}
{"episode_reward": 913.1202279592557, "episode": 70.0, "batch_reward": 0.8054657417535782, "critic_loss": 0.9473195635676384, "actor_loss": -92.23408406066895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.748873472213745, "step": 70000}
{"episode_reward": 911.2340392110367, "episode": 71.0, "batch_reward": 0.8049915687441825, "critic_loss": 0.9009741928875447, "actor_loss": -91.73580540466308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.38588762283325, "step": 71000}
{"episode_reward": 921.4931883348017, "episode": 72.0, "batch_reward": 0.8094655888676643, "critic_loss": 1.1365147272348404, "actor_loss": -92.21267475891113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.778515100479126, "step": 72000}
{"episode_reward": 903.3024406403143, "episode": 73.0, "batch_reward": 0.8090544942617416, "critic_loss": 1.4027070004045963, "actor_loss": -92.26935289001464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.786006212234497, "step": 73000}
{"episode_reward": 914.6838160118585, "episode": 74.0, "batch_reward": 0.8121216856837272, "critic_loss": 1.4267685386240483, "actor_loss": -92.28783125305176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.782474279403687, "step": 74000}
{"episode_reward": 859.6649891937599, "episode": 75.0, "batch_reward": 0.8125383688807487, "critic_loss": 1.4106192278862, "actor_loss": -92.42331413269044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.795742511749268, "step": 75000}
{"episode_reward": 915.6119354654506, "episode": 76.0, "batch_reward": 0.8076798955798149, "critic_loss": 2.4074572689533236, "actor_loss": -92.3682347869873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.797255039215088, "step": 76000}
{"episode_reward": 42.49500130445298, "episode": 77.0, "batch_reward": 0.8031590681672096, "critic_loss": 1.8367725527882577, "actor_loss": -92.44450076293946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.806711435317993, "step": 77000}
{"episode_reward": 923.5135902555907, "episode": 78.0, "batch_reward": 0.803875541806221, "critic_loss": 1.4386630880236626, "actor_loss": -92.48497555541992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.780018091201782, "step": 78000}
{"episode_reward": 917.2332771466473, "episode": 79.0, "batch_reward": 0.8044334416985511, "critic_loss": 1.3386885886192321, "actor_loss": -92.38919017028809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.746879816055298, "step": 79000}
{"episode_reward": 915.1656945916167, "episode": 80.0, "batch_reward": 0.8021461853981018, "critic_loss": 1.654308643400669, "actor_loss": -92.56066282653809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.7921199798584, "step": 80000}
{"episode_reward": 35.366554005477404, "episode": 81.0, "batch_reward": 0.7972344939112663, "critic_loss": 1.3236452395319938, "actor_loss": -92.42857006835938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.3714394569397, "step": 81000}
{"episode_reward": 919.5634465244575, "episode": 82.0, "batch_reward": 0.792037642300129, "critic_loss": 1.2742310042977334, "actor_loss": -92.4690419921875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.763160467147827, "step": 82000}
{"episode_reward": 35.84644356293307, "episode": 83.0, "batch_reward": 0.7889606090188026, "critic_loss": 1.2198060722649098, "actor_loss": -92.6862304534912, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.76350998878479, "step": 83000}
{"episode_reward": 932.1323138936261, "episode": 84.0, "batch_reward": 0.7910326627492905, "critic_loss": 1.1654471259713173, "actor_loss": -92.70669921875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.77349615097046, "step": 84000}
{"episode_reward": 918.049529377383, "episode": 85.0, "batch_reward": 0.7913916347026825, "critic_loss": 1.1397192184329032, "actor_loss": -92.23832368469239, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.790225982666016, "step": 85000}
{"episode_reward": 911.8927412525309, "episode": 86.0, "batch_reward": 0.7927921780347824, "critic_loss": 1.1523388038575648, "actor_loss": -92.33241537475585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.79984712600708, "step": 86000}
{"episode_reward": 830.6541396628393, "episode": 87.0, "batch_reward": 0.7934360714554787, "critic_loss": 1.098275024831295, "actor_loss": -92.33992263793945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.787259101867676, "step": 87000}
{"episode_reward": 905.308215197644, "episode": 88.0, "batch_reward": 0.7969396858215332, "critic_loss": 1.0410866611599923, "actor_loss": -92.47076968383789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.757870197296143, "step": 88000}
{"episode_reward": 949.413818572039, "episode": 89.0, "batch_reward": 0.7982558608651161, "critic_loss": 0.9890641174912452, "actor_loss": -92.24984252929687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.76916003227234, "step": 89000}
{"episode_reward": 928.5311321470431, "episode": 90.0, "batch_reward": 0.7999479370713234, "critic_loss": 0.9636361066699028, "actor_loss": -92.47062200927735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.77047562599182, "step": 90000}
{"episode_reward": 924.1809485657224, "episode": 91.0, "batch_reward": 0.7997014521360397, "critic_loss": 0.9675528564453125, "actor_loss": -92.27019149780273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.36201310157776, "step": 91000}
{"episode_reward": 898.7015689355336, "episode": 92.0, "batch_reward": 0.8022524382472038, "critic_loss": 0.9105156992971897, "actor_loss": -92.47239498901367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.77178406715393, "step": 92000}
{"episode_reward": 942.3049846209205, "episode": 93.0, "batch_reward": 0.8033923733234406, "critic_loss": 0.8968804604709149, "actor_loss": -92.56928323364258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.097015857696533, "step": 93000}
{"episode_reward": 967.6540458386695, "episode": 94.0, "batch_reward": 0.8035456023812294, "critic_loss": 0.882369841337204, "actor_loss": -92.80810313415527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.727147579193115, "step": 94000}
{"episode_reward": 910.8449823874247, "episode": 95.0, "batch_reward": 0.8061433562636375, "critic_loss": 0.9460866036713124, "actor_loss": -92.83084873962402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.73163414001465, "step": 95000}
{"episode_reward": 915.8266860179002, "episode": 96.0, "batch_reward": 0.8063282902240754, "critic_loss": 0.9407517302632332, "actor_loss": -92.66038333129883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.744643926620483, "step": 96000}
{"episode_reward": 919.7588961794046, "episode": 97.0, "batch_reward": 0.8086030017137528, "critic_loss": 0.9208968705534935, "actor_loss": -92.69861416625976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.802343130111694, "step": 97000}
{"episode_reward": 945.9961013256344, "episode": 98.0, "batch_reward": 0.810272483766079, "critic_loss": 0.8893943718373776, "actor_loss": -92.60480065917969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.76445484161377, "step": 98000}
{"episode_reward": 913.2887186723684, "episode": 99.0, "batch_reward": 0.8116621339917183, "critic_loss": 0.829599358677864, "actor_loss": -92.81796069335938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.78526759147644, "step": 99000}
{"episode_reward": 913.6856430075668, "episode": 100.0, "batch_reward": 0.8104207260608673, "critic_loss": 0.8364223519563675, "actor_loss": -92.80353930664063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.7878839969635, "step": 100000}
{"episode_reward": 919.9233985888922, "episode": 101.0, "batch_reward": 0.8136751286387444, "critic_loss": 0.8006222251355648, "actor_loss": -92.81004742431641, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.39138436317444, "step": 101000}
{"episode_reward": 960.34980307235, "episode": 102.0, "batch_reward": 0.8148993072509766, "critic_loss": 0.8215194469988346, "actor_loss": -93.09720573425292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.781190156936646, "step": 102000}
{"episode_reward": 903.5927219624965, "episode": 103.0, "batch_reward": 0.8147357082366944, "critic_loss": 0.7824016309678554, "actor_loss": -92.75044201660157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.788190603256226, "step": 103000}
{"episode_reward": 932.1954081637055, "episode": 104.0, "batch_reward": 0.8155071697831154, "critic_loss": 0.7910379610806704, "actor_loss": -93.00445356750488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.80127739906311, "step": 104000}
{"episode_reward": 917.755949344788, "episode": 105.0, "batch_reward": 0.8164250857234001, "critic_loss": 0.7658290436565875, "actor_loss": -92.74512069702149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.787670373916626, "step": 105000}
{"episode_reward": 925.531728521312, "episode": 106.0, "batch_reward": 0.8188939474821091, "critic_loss": 0.7763317014276981, "actor_loss": -93.16026892089843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.781946659088135, "step": 106000}
{"episode_reward": 882.4143708737113, "episode": 107.0, "batch_reward": 0.8179378204345703, "critic_loss": 0.7879809444546699, "actor_loss": -92.95833926391602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.101808547973633, "step": 107000}
{"episode_reward": 700.3646707469328, "episode": 108.0, "batch_reward": 0.8155926206707954, "critic_loss": 0.8240911617577076, "actor_loss": -92.61720281982421, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.795759201049805, "step": 108000}
{"episode_reward": 934.8326281625716, "episode": 109.0, "batch_reward": 0.8176995171904564, "critic_loss": 0.7796088958233595, "actor_loss": -93.02119422912598, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.743716955184937, "step": 109000}
{"episode_reward": 921.2592378084858, "episode": 110.0, "batch_reward": 0.8200555208325386, "critic_loss": 0.7608728038072586, "actor_loss": -92.93614109802246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.76886820793152, "step": 110000}
{"episode_reward": 919.2609789384402, "episode": 111.0, "batch_reward": 0.820534461081028, "critic_loss": 0.8329997717142105, "actor_loss": -92.85129005432128, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.29868197441101, "step": 111000}
{"episode_reward": 906.5355449183928, "episode": 112.0, "batch_reward": 0.8214930834174157, "critic_loss": 0.7899501174092293, "actor_loss": -93.15833006286621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.75982093811035, "step": 112000}
{"episode_reward": 906.8719424836412, "episode": 113.0, "batch_reward": 0.8220517508387566, "critic_loss": 0.7862521401494742, "actor_loss": -93.09934750366212, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.790574550628662, "step": 113000}
{"episode_reward": 784.4634583764622, "episode": 114.0, "batch_reward": 0.8201999507546425, "critic_loss": 0.8114972325861454, "actor_loss": -93.25891900634765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.782144784927368, "step": 114000}
{"episode_reward": 951.9957559307456, "episode": 115.0, "batch_reward": 0.824243276834488, "critic_loss": 0.831996344357729, "actor_loss": -93.09947662353515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.790782928466797, "step": 115000}
{"episode_reward": 921.0116417179557, "episode": 116.0, "batch_reward": 0.8245312405824661, "critic_loss": 0.8367958136498929, "actor_loss": -93.16879975891113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.781070709228516, "step": 116000}
{"episode_reward": 902.4895551007143, "episode": 117.0, "batch_reward": 0.8250229113101959, "critic_loss": 0.7723705280721188, "actor_loss": -92.98484750366211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.787941455841064, "step": 117000}
{"episode_reward": 934.6855438460002, "episode": 118.0, "batch_reward": 0.824405609369278, "critic_loss": 0.7748609354794025, "actor_loss": -93.10751136779785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.782368183135986, "step": 118000}
{"episode_reward": 942.2869427179692, "episode": 119.0, "batch_reward": 0.8257423059940339, "critic_loss": 0.7412138442695141, "actor_loss": -93.1985541381836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.78145170211792, "step": 119000}
{"episode_reward": 894.6455439867813, "episode": 120.0, "batch_reward": 0.827344571173191, "critic_loss": 0.758901082187891, "actor_loss": -93.10325891113281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.75849461555481, "step": 120000}
{"episode_reward": 940.6019575072744, "episode": 121.0, "batch_reward": 0.8277908569574356, "critic_loss": 0.7212006275057793, "actor_loss": -93.18514559936523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.38798379898071, "step": 121000}
{"episode_reward": 926.8141430839556, "episode": 122.0, "batch_reward": 0.8292126001119614, "critic_loss": 0.744332074046135, "actor_loss": -93.3267741394043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.787387371063232, "step": 122000}
{"episode_reward": 904.8850735747362, "episode": 123.0, "batch_reward": 0.8309232431650162, "critic_loss": 0.7220206900388002, "actor_loss": -93.54052299499511, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.761295318603516, "step": 123000}
{"episode_reward": 962.663205103837, "episode": 124.0, "batch_reward": 0.8304494999647141, "critic_loss": 0.7140264208614826, "actor_loss": -93.52895571899414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.78475069999695, "step": 124000}
{"episode_reward": 908.4448891422734, "episode": 125.0, "batch_reward": 0.8321310930848121, "critic_loss": 0.6744004534184933, "actor_loss": -93.59039720153808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.790915727615356, "step": 125000}
{"episode_reward": 928.4651151875642, "episode": 126.0, "batch_reward": 0.8338389002680778, "critic_loss": 0.655469576716423, "actor_loss": -93.42924661254882, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.77562928199768, "step": 126000}
{"episode_reward": 939.2212957090491, "episode": 127.0, "batch_reward": 0.8334839878678322, "critic_loss": 0.6728700667768717, "actor_loss": -93.42970747375489, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.78017020225525, "step": 127000}
{"episode_reward": 941.2767947355353, "episode": 128.0, "batch_reward": 0.832219268143177, "critic_loss": 0.6857783123850822, "actor_loss": -93.54399899291992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.797847032546997, "step": 128000}
{"episode_reward": 900.8928268804638, "episode": 129.0, "batch_reward": 0.8331369020938874, "critic_loss": 0.6634556290507316, "actor_loss": -93.4324194946289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.784584045410156, "step": 129000}
{"episode_reward": 959.7085034279511, "episode": 130.0, "batch_reward": 0.8365940005779267, "critic_loss": 0.6424126853942871, "actor_loss": -93.53527272033692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.793135404586792, "step": 130000}
{"episode_reward": 946.2968055366474, "episode": 131.0, "batch_reward": 0.8356315011382103, "critic_loss": 0.62384381313622, "actor_loss": -93.5542887878418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.371198892593384, "step": 131000}
{"episode_reward": 924.8504896439932, "episode": 132.0, "batch_reward": 0.8367269073724747, "critic_loss": 0.6085743024647235, "actor_loss": -93.69512557983398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.801584720611572, "step": 132000}
{"episode_reward": 910.4832512915773, "episode": 133.0, "batch_reward": 0.8368669515848159, "critic_loss": 0.6393139111101628, "actor_loss": -93.62353141784668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.778829336166382, "step": 133000}
{"episode_reward": 945.9306298429082, "episode": 134.0, "batch_reward": 0.838417074739933, "critic_loss": 0.6273128084987402, "actor_loss": -93.56205195617676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.782681941986084, "step": 134000}
{"episode_reward": 940.1463291741957, "episode": 135.0, "batch_reward": 0.8374868310689926, "critic_loss": 0.649583579108119, "actor_loss": -93.70168782043457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.7887864112854, "step": 135000}
{"episode_reward": 896.635780420385, "episode": 136.0, "batch_reward": 0.8404842251539231, "critic_loss": 0.6395638004541397, "actor_loss": -93.43598962402343, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.79751944541931, "step": 136000}
{"episode_reward": 897.4580951563406, "episode": 137.0, "batch_reward": 0.8386674367785454, "critic_loss": 0.666405508056283, "actor_loss": -93.74791334533691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.802279233932495, "step": 137000}
{"episode_reward": 957.5005716014483, "episode": 138.0, "batch_reward": 0.8415267468094826, "critic_loss": 0.6534909716546535, "actor_loss": -93.8938599395752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.783918857574463, "step": 138000}
{"episode_reward": 938.407030332242, "episode": 139.0, "batch_reward": 0.8422069373130798, "critic_loss": 0.6632800201177597, "actor_loss": -93.77797096252442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.774909496307373, "step": 139000}
{"episode_reward": 947.5240071316866, "episode": 140.0, "batch_reward": 0.8430575370192528, "critic_loss": 0.6648664712458849, "actor_loss": -93.75041307067872, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.77674102783203, "step": 140000}
{"episode_reward": 929.71934193442, "episode": 141.0, "batch_reward": 0.8419199754595756, "critic_loss": 0.6618437706530094, "actor_loss": -93.70069805908203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.38723564147949, "step": 141000}
{"episode_reward": 932.5193589038864, "episode": 142.0, "batch_reward": 0.8438731570839881, "critic_loss": 0.6645382378250361, "actor_loss": -93.56371508789063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.7731511592865, "step": 142000}
{"episode_reward": 934.4613884538393, "episode": 143.0, "batch_reward": 0.8436960970759392, "critic_loss": 0.656554836332798, "actor_loss": -93.72067546081543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.768107652664185, "step": 143000}
{"episode_reward": 927.1428944073008, "episode": 144.0, "batch_reward": 0.8453409015536308, "critic_loss": 0.6514286304414272, "actor_loss": -93.85468499755859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.779907703399658, "step": 144000}
{"episode_reward": 915.0908066601012, "episode": 145.0, "batch_reward": 0.8441873797774315, "critic_loss": 0.657952936694026, "actor_loss": -93.92334568786622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.78887391090393, "step": 145000}
{"episode_reward": 876.6203402008604, "episode": 146.0, "batch_reward": 0.8447569393515587, "critic_loss": 0.6633759840875864, "actor_loss": -93.99789552307129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.795954942703247, "step": 146000}
{"episode_reward": 942.6442193298759, "episode": 147.0, "batch_reward": 0.8452030032277107, "critic_loss": 0.7070172431766987, "actor_loss": -93.88029663085938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.786360502243042, "step": 147000}
{"episode_reward": 912.0905514067019, "episode": 148.0, "batch_reward": 0.8457406704425812, "critic_loss": 0.657477149233222, "actor_loss": -93.97868371582031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.77758240699768, "step": 148000}
{"episode_reward": 887.6582072348336, "episode": 149.0, "batch_reward": 0.84674327480793, "critic_loss": 0.654545051023364, "actor_loss": -93.81201878356934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.77275061607361, "step": 149000}
{"episode_reward": 969.3195145369477, "episode": 150.0, "batch_reward": 0.8451755471229553, "critic_loss": 0.6381643120795488, "actor_loss": -93.88351077270508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
