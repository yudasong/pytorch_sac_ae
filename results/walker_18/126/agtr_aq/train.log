{"episode": 1.0, "duration": 21.826523065567017, "episode_reward": 29.08591335645728, "step": 1000}
{"episode": 2.0, "duration": 1.9663360118865967, "episode_reward": 898.6342244091321, "step": 2000}
{"episode": 3.0, "batch_reward": 0.46092119032877926, "actor_loss": -83.87623085733317, "actor_target_entropy": -6.0, "alpha_value": 0.002642586817083679, "duration": 53.10273599624634, "episode_reward": 429.7181199294188, "step": 3000}
{"episode": 4.0, "batch_reward": 0.46769753357768057, "actor_loss": -85.29673783874512, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.57035255432129, "episode_reward": 563.7052580428738, "step": 4000}
{"episode": 5.0, "batch_reward": 0.4858434793353081, "actor_loss": -86.06102284240723, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.05242156982422, "episode_reward": 597.5233152306077, "step": 5000}
{"episode": 6.0, "batch_reward": 0.5130779131054878, "actor_loss": -87.1552742614746, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.67952871322632, "episode_reward": 630.0287647644774, "step": 6000}
{"episode": 7.0, "batch_reward": 0.5281769505143166, "actor_loss": -87.72882611083985, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.17018723487854, "episode_reward": 612.9261563800413, "step": 7000}
{"episode": 8.0, "batch_reward": 0.5443902078270912, "actor_loss": -88.34122291564941, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.96898078918457, "episode_reward": 611.6592585517728, "step": 8000}
{"episode": 9.0, "batch_reward": 0.5554789398908615, "actor_loss": -88.68955039978027, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.902731895446777, "episode_reward": 712.1655962167847, "step": 9000}
{"episode": 10.0, "batch_reward": 0.5637717916965485, "actor_loss": -85.6598783416748, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 4097.365931749344, "episode_reward": 470.7141133755691, "step": 10000}
{"episode": 11.0, "batch_reward": 0.553737394630909, "actor_loss": -85.61898210144042, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 39.31639814376831, "episode_reward": 550.4903939970915, "step": 11000}
{"episode": 12.0, "batch_reward": 0.5539721269011497, "actor_loss": -83.52960650634766, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 427.2137961387634, "episode_reward": 580.7908115444545, "step": 12000}
{"episode": 13.0, "batch_reward": 0.5564365414083003, "actor_loss": -83.94191226196288, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.2188503742218, "episode_reward": 584.190516905106, "step": 13000}
{"episode": 14.0, "batch_reward": 0.5623804022967815, "actor_loss": -82.71271434020996, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 437.82716846466064, "episode_reward": 659.0931573963071, "step": 14000}
{"episode": 15.0, "batch_reward": 0.5646837746798992, "actor_loss": -83.00678773498535, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.187360763549805, "episode_reward": 508.0306120133467, "step": 15000}
{"episode": 16.0, "batch_reward": 0.5577007049322128, "actor_loss": -81.29675804138184, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 424.15708661079407, "episode_reward": 343.45447745477844, "step": 16000}
{"episode": 17.0, "batch_reward": 0.545675737708807, "actor_loss": -81.11176699829102, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.637710571289062, "episode_reward": 495.4954023546302, "step": 17000}
{"episode": 18.0, "batch_reward": 0.5489357879161835, "actor_loss": -80.31529289245606, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 431.2315101623535, "episode_reward": 687.9027381726908, "step": 18000}
{"episode": 19.0, "batch_reward": 0.5485212263762951, "actor_loss": -80.42335612487793, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.25464391708374, "episode_reward": 472.70998786656077, "step": 19000}
{"episode": 20.0, "batch_reward": 0.5493318557143211, "actor_loss": -79.19972560119629, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 428.1429386138916, "episode_reward": 597.7627199425336, "step": 20000}
{"episode": 21.0, "batch_reward": 0.5491965992450714, "actor_loss": -79.18792778015137, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.21199584007263, "episode_reward": 276.45801304431524, "step": 21000}
{"episode": 22.0, "batch_reward": 0.5405341107547283, "actor_loss": -77.6793713684082, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 458.7149221897125, "episode_reward": 688.6942494820624, "step": 22000}
{"episode": 23.0, "batch_reward": 0.5474617122411728, "actor_loss": -77.91124188232422, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.506683826446533, "episode_reward": 641.4714987545236, "step": 23000}
{"episode": 24.0, "batch_reward": 0.5492480991482734, "actor_loss": -78.21921083068848, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 461.1039972305298, "episode_reward": 430.33047785085245, "step": 24000}
{"episode": 25.0, "batch_reward": 0.5426225174963474, "actor_loss": -78.01941651916503, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.69953942298889, "episode_reward": 440.40596256620165, "step": 25000}
{"episode": 26.0, "batch_reward": 0.5375904855132103, "actor_loss": -76.73495321655274, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 432.5190830230713, "episode_reward": 229.6581265337688, "step": 26000}
{"episode": 27.0, "batch_reward": 0.530444334089756, "actor_loss": -76.52065126037597, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.784709215164185, "episode_reward": 699.7292842429753, "step": 27000}
{"episode": 28.0, "batch_reward": 0.5347156620919704, "actor_loss": -75.98805760192872, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 425.1390731334686, "episode_reward": 489.1445621916028, "step": 28000}
{"episode": 29.0, "batch_reward": 0.5378267534971237, "actor_loss": -76.21758990478516, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.670181035995483, "episode_reward": 750.7747244740359, "step": 29000}
{"episode": 30.0, "batch_reward": 0.5442275182902813, "actor_loss": -77.00471035766601, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 428.2000379562378, "episode_reward": 697.1707881006273, "step": 30000}
{"episode": 31.0, "batch_reward": 0.5482968221306801, "actor_loss": -77.12743588256836, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.00125193595886, "episode_reward": 716.9188244047184, "step": 31000}
{"episode": 32.0, "batch_reward": 0.5488557009100914, "actor_loss": -76.17939544677735, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 424.1476731300354, "episode_reward": 382.54360229038423, "step": 32000}
{"episode": 33.0, "batch_reward": 0.5432456776499748, "actor_loss": -76.14503059387206, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.256214141845703, "episode_reward": 284.85454666149616, "step": 33000}
{"episode": 34.0, "batch_reward": 0.5398576836287975, "actor_loss": -74.99262344360352, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 436.05377316474915, "episode_reward": 774.8136352323565, "step": 34000}
{"episode": 35.0, "batch_reward": 0.5493054768443107, "actor_loss": -75.30547477722168, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.057544946670532, "episode_reward": 752.7735701320032, "step": 35000}
{"episode": 36.0, "batch_reward": 0.5483859582841396, "actor_loss": -74.97313415527344, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 437.15803027153015, "episode_reward": 373.11577095474036, "step": 36000}
{"episode": 37.0, "batch_reward": 0.5430846509039402, "actor_loss": -74.8671025390625, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.03959083557129, "episode_reward": 501.5371471301216, "step": 37000}
{"episode": 38.0, "batch_reward": 0.5483284698724746, "actor_loss": -74.65919287109375, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 426.696724653244, "episode_reward": 789.2466490075127, "step": 38000}
{"episode": 39.0, "batch_reward": 0.5519698547720909, "actor_loss": -74.80816799926758, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.389080047607422, "episode_reward": 646.176022477287, "step": 39000}
{"episode": 40.0, "batch_reward": 0.5545987242162228, "actor_loss": -74.84667691040039, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 435.9608051776886, "episode_reward": 670.8191439699995, "step": 40000}
{"episode": 41.0, "batch_reward": 0.5580089740753174, "actor_loss": -75.09940632629394, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 36.06927251815796, "episode_reward": 684.1863894818096, "step": 41000}
{"episode": 42.0, "batch_reward": 0.559060954272747, "actor_loss": -75.26193925476075, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 440.25399565696716, "episode_reward": 467.3114279875074, "step": 42000}
{"episode": 43.0, "batch_reward": 0.5573000858426094, "actor_loss": -75.15718336486816, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.930366277694702, "episode_reward": 599.5407245959306, "step": 43000}
{"episode": 44.0, "batch_reward": 0.5604184693992138, "actor_loss": -75.70191873168946, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 459.2586627006531, "episode_reward": 751.3331405477174, "step": 44000}
{"episode": 45.0, "batch_reward": 0.56572733771801, "actor_loss": -75.90129295349121, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.899118185043335, "episode_reward": 774.9645193718092, "step": 45000}
{"episode": 46.0, "batch_reward": 0.5698939077556133, "actor_loss": -76.7245573272705, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 460.28817439079285, "episode_reward": 822.1674397684666, "step": 46000}
{"episode": 47.0, "batch_reward": 0.5743715814352035, "actor_loss": -76.8726159362793, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.0119047164917, "episode_reward": 787.3161667601736, "step": 47000}
{"episode": 48.0, "batch_reward": 0.5796685440242291, "actor_loss": -76.45248416137696, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 469.4472198486328, "episode_reward": 748.3095356544153, "step": 48000}
{"episode": 49.0, "batch_reward": 0.5821909096240997, "actor_loss": -76.59490209960937, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.653309106826782, "episode_reward": 676.0808357971604, "step": 49000}
{"episode": 50.0, "batch_reward": 0.5837389617860317, "actor_loss": -76.79192004394531, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 455.34389638900757, "episode_reward": 728.8943066667341, "step": 50000}
{"episode": 51.0, "batch_reward": 0.5896192120611667, "actor_loss": -77.07263409423828, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.646114110946655, "episode_reward": 797.9106450323231, "step": 51000}
{"episode": 52.0, "batch_reward": 0.5909966960549354, "actor_loss": -77.0730825958252, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 464.10026931762695, "episode_reward": 698.3773753306135, "step": 52000}
{"episode": 53.0, "batch_reward": 0.5947506978511811, "actor_loss": -77.11579350280762, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.619742393493652, "episode_reward": 763.1304206379632, "step": 53000}
{"episode": 54.0, "batch_reward": 0.5986304910778999, "actor_loss": -77.18520048522949, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 465.9033088684082, "episode_reward": 766.560161206576, "step": 54000}
{"episode": 55.0, "batch_reward": 0.5994201753735542, "actor_loss": -77.2101626739502, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.865448713302612, "episode_reward": 793.4632946220729, "step": 55000}
{"episode": 56.0, "batch_reward": 0.6031245517730713, "actor_loss": -77.32040397644043, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 464.65276622772217, "episode_reward": 818.5733277236684, "step": 56000}
{"episode": 57.0, "batch_reward": 0.6066738579273224, "actor_loss": -77.4643776397705, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.23871946334839, "episode_reward": 719.6459578716346, "step": 57000}
{"episode": 58.0, "batch_reward": 0.6101745873093605, "actor_loss": -76.92013279724121, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 460.7853672504425, "episode_reward": 816.3878727265054, "step": 58000}
{"episode": 59.0, "batch_reward": 0.6137350862622261, "actor_loss": -76.97603848266601, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.052886962890625, "episode_reward": 856.4686170691257, "step": 59000}
{"episode": 60.0, "batch_reward": 0.6176166511774063, "actor_loss": -76.53365982055664, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 463.1927604675293, "episode_reward": 869.0739887237668, "step": 60000}
{"episode": 61.0, "batch_reward": 0.6210895632505417, "actor_loss": -76.66013394165039, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.356444358825684, "episode_reward": 792.9591230135554, "step": 61000}
{"episode": 62.0, "batch_reward": 0.6252890828251839, "actor_loss": -76.81258992004395, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 470.0957260131836, "episode_reward": 858.9057359605025, "step": 62000}
{"episode": 63.0, "batch_reward": 0.627374594271183, "actor_loss": -76.82285427856445, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.500001192092896, "episode_reward": 756.8442391177481, "step": 63000}
{"episode": 64.0, "batch_reward": 0.6291854529380798, "actor_loss": -76.35948641967774, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 465.72133564949036, "episode_reward": 785.7498193167658, "step": 64000}
{"episode": 65.0, "batch_reward": 0.6333316218852997, "actor_loss": -76.49394314575196, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.68476700782776, "episode_reward": 870.030582981637, "step": 65000}
{"episode": 66.0, "batch_reward": 0.636279011964798, "actor_loss": -76.30213949584962, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 461.8113615512848, "episode_reward": 872.9969988675729, "step": 66000}
{"episode": 67.0, "batch_reward": 0.6411747302412987, "actor_loss": -76.45814350891114, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.068291187286377, "episode_reward": 790.9181660310019, "step": 67000}
{"episode": 68.0, "batch_reward": 0.6416317659616471, "actor_loss": -75.86543252563476, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 460.94719195365906, "episode_reward": 814.9854552945254, "step": 68000}
{"episode": 69.0, "batch_reward": 0.6428722672462464, "actor_loss": -75.86545333862304, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.336191654205322, "episode_reward": 692.7439171779386, "step": 69000}
{"episode": 70.0, "batch_reward": 0.6455958946347237, "actor_loss": -75.01476861572266, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 467.56476068496704, "episode_reward": 867.4963180128125, "step": 70000}
{"episode": 71.0, "batch_reward": 0.6469548642039299, "actor_loss": -75.09004010009765, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 38.28715658187866, "episode_reward": 764.6537239497086, "step": 71000}
{"episode": 72.0, "batch_reward": 0.6500884062051773, "actor_loss": -75.21055137634278, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 466.6187918186188, "episode_reward": 847.1953828271563, "step": 72000}
{"episode": 73.0, "batch_reward": 0.6529978550076485, "actor_loss": -75.34513484191895, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.61234951019287, "episode_reward": 801.2534141474772, "step": 73000}
{"episode": 74.0, "batch_reward": 0.6542642303109169, "actor_loss": -74.30548941040038, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 459.33139967918396, "episode_reward": 811.9585490255521, "step": 74000}
{"episode": 75.0, "batch_reward": 0.6581716114282607, "actor_loss": -74.39161485290528, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.894227027893066, "episode_reward": 846.5479071579238, "step": 75000}
{"episode": 76.0, "batch_reward": 0.6578967316150666, "actor_loss": -74.39467523193359, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 464.89606833457947, "episode_reward": 796.2360216790184, "step": 76000}
{"episode": 77.0, "batch_reward": 0.6611738020777702, "actor_loss": -74.6128430480957, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.72514057159424, "episode_reward": 876.3982144993297, "step": 77000}
{"episode": 78.0, "batch_reward": 0.6649951850175857, "actor_loss": -74.57597265625, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 454.51781010627747, "episode_reward": 821.4198344961371, "step": 78000}
{"episode": 79.0, "batch_reward": 0.6651240399479866, "actor_loss": -74.67084060668945, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.465263843536377, "episode_reward": 824.4892947398436, "step": 79000}
{"episode": 80.0, "batch_reward": 0.667621837079525, "actor_loss": -74.49789596557618, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 436.0472502708435, "episode_reward": 775.2693459967691, "step": 80000}
{"episode": 81.0, "batch_reward": 0.6689440642595291, "actor_loss": -74.65003070068359, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.555805921554565, "episode_reward": 839.8914037478658, "step": 81000}
{"episode": 82.0, "batch_reward": 0.671390866458416, "actor_loss": -74.42766078186035, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 457.73589992523193, "episode_reward": 818.5117556827231, "step": 82000}
{"episode": 83.0, "batch_reward": 0.6729004907011986, "actor_loss": -74.44314578247071, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.864700078964233, "episode_reward": 840.6199989695225, "step": 83000}
{"episode": 84.0, "batch_reward": 0.6745163230895996, "actor_loss": -74.87216998291015, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 467.95323157310486, "episode_reward": 850.1916457697132, "step": 84000}
{"episode": 85.0, "batch_reward": 0.6788150039315224, "actor_loss": -75.03769862365722, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.46690607070923, "episode_reward": 815.8964468145475, "step": 85000}
{"episode": 86.0, "batch_reward": 0.6784770531654358, "actor_loss": -74.82997378540038, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 469.1601209640503, "episode_reward": 925.6072940830962, "step": 86000}
{"episode": 87.0, "batch_reward": 0.6819720023870468, "actor_loss": -74.92976187133789, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.05371332168579, "episode_reward": 896.4150970345579, "step": 87000}
{"episode": 88.0, "batch_reward": 0.686404881298542, "actor_loss": -75.34449140930175, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 461.98189067840576, "episode_reward": 929.8310948236224, "step": 88000}
{"episode": 89.0, "batch_reward": 0.6879081618189812, "actor_loss": -75.38965301513672, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.066184282302856, "episode_reward": 923.1233117268516, "step": 89000}
{"episode": 90.0, "batch_reward": 0.6913461408019066, "actor_loss": -76.3573158569336, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 470.9090521335602, "episode_reward": 914.7449779142681, "step": 90000}
{"episode": 91.0, "batch_reward": 0.6922416722774506, "actor_loss": -76.35542294311523, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.39047312736511, "episode_reward": 879.1929188990495, "step": 91000}
{"episode": 92.0, "batch_reward": 0.6949520633816719, "actor_loss": -76.35419801330566, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 418.9481086730957, "episode_reward": 907.7220602772514, "step": 92000}
{"episode": 93.0, "batch_reward": 0.6972864221334457, "actor_loss": -76.37373200988769, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.389621257781982, "episode_reward": 899.6665483123609, "step": 93000}
{"episode": 94.0, "batch_reward": 0.6979802364706993, "actor_loss": -76.5905909576416, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 430.9399688243866, "episode_reward": 819.2533424516847, "step": 94000}
{"episode": 95.0, "batch_reward": 0.6984762513041496, "actor_loss": -76.58552046203613, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.19235062599182, "episode_reward": 884.5201717680571, "step": 95000}
{"episode": 96.0, "batch_reward": 0.7019865571260452, "actor_loss": -77.26936647033692, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 426.21044278144836, "episode_reward": 846.8953395732373, "step": 96000}
{"episode": 97.0, "batch_reward": 0.7035897453427314, "actor_loss": -77.3880828857422, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.05365514755249, "episode_reward": 888.5356219451834, "step": 97000}
{"episode": 98.0, "batch_reward": 0.7046842818856239, "actor_loss": -77.22328262329101, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 428.17424845695496, "episode_reward": 832.6013924189821, "step": 98000}
{"episode": 99.0, "batch_reward": 0.7066130980849266, "actor_loss": -77.3901813659668, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.902117490768433, "episode_reward": 830.902049191103, "step": 99000}
{"episode": 100.0, "batch_reward": 0.7064223161935806, "actor_loss": -77.37494264221192, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 429.00709319114685, "episode_reward": 895.8408362825703, "step": 100000}
{"episode": 101.0, "batch_reward": 0.7117490594983101, "actor_loss": -77.57018817138672, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 38.1331353187561, "episode_reward": 822.411679964213, "step": 101000}
{"episode": 102.0, "batch_reward": 0.7110046454071999, "actor_loss": -77.40968183898926, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 431.4368989467621, "episode_reward": 861.700796694168, "step": 102000}
{"episode": 103.0, "batch_reward": 0.7100275046825409, "actor_loss": -77.39848983764648, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.90636658668518, "episode_reward": 799.1367719166841, "step": 103000}
{"episode": 104.0, "batch_reward": 0.7132731943726539, "actor_loss": -77.66412565612794, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 431.41111993789673, "episode_reward": 873.8379355496078, "step": 104000}
{"episode": 105.0, "batch_reward": 0.7144724232554436, "actor_loss": -77.74899606323243, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.286858558654785, "episode_reward": 888.7635344517414, "step": 105000}
{"episode": 106.0, "batch_reward": 0.7162225165367127, "actor_loss": -77.33358047485352, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 432.5521640777588, "episode_reward": 859.4030736260386, "step": 106000}
{"episode": 107.0, "batch_reward": 0.7183084417581558, "actor_loss": -77.3593466796875, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.826303243637085, "episode_reward": 862.9778123529948, "step": 107000}
{"episode": 108.0, "batch_reward": 0.7184762642979622, "actor_loss": -77.70022993469239, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 431.4186885356903, "episode_reward": 919.7593407883392, "step": 108000}
{"episode": 109.0, "batch_reward": 0.7209620614647865, "actor_loss": -77.84911032104492, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.99139404296875, "episode_reward": 893.7437634828175, "step": 109000}
{"episode": 110.0, "batch_reward": 0.720667826294899, "actor_loss": -78.00607334899902, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 425.92150712013245, "episode_reward": 809.3676641260008, "step": 110000}
{"episode": 111.0, "batch_reward": 0.7223199371695519, "actor_loss": -78.1381591796875, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 37.67980647087097, "episode_reward": 907.4621666147351, "step": 111000}
{"episode": 112.0, "batch_reward": 0.7257012364268303, "actor_loss": -77.98472689819336, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 425.93318223953247, "episode_reward": 839.9595866655465, "step": 112000}
{"episode": 113.0, "batch_reward": 0.7255974630117417, "actor_loss": -77.99996546936035, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.035062551498413, "episode_reward": 914.3931103836593, "step": 113000}
{"episode": 114.0, "batch_reward": 0.7272192882299423, "actor_loss": -78.266464553833, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 430.47508668899536, "episode_reward": 961.4114119031528, "step": 114000}
{"episode": 115.0, "batch_reward": 0.7299377366900444, "actor_loss": -78.36939828491211, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.188954830169678, "episode_reward": 869.9357915423584, "step": 115000}
{"episode": 116.0, "batch_reward": 0.7316412760615348, "actor_loss": -77.38613305664063, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 425.4390621185303, "episode_reward": 898.2389945615148, "step": 116000}
{"episode": 117.0, "batch_reward": 0.7330477283000946, "actor_loss": -77.31838661193848, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.368146419525146, "episode_reward": 894.2651712485219, "step": 117000}
{"episode": 118.0, "batch_reward": 0.736056443810463, "actor_loss": -77.46967614746094, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 442.26908588409424, "episode_reward": 892.6847649846981, "step": 118000}
{"episode": 119.0, "batch_reward": 0.7361300860643387, "actor_loss": -77.50616830444336, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.04716968536377, "episode_reward": 931.6076306053486, "step": 119000}
{"episode": 120.0, "batch_reward": 0.7360951702594757, "actor_loss": -77.626339553833, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 460.6742796897888, "episode_reward": 894.2464311252021, "step": 120000}
{"episode": 121.0, "batch_reward": 0.7388597003221512, "actor_loss": -77.69120924377441, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 44.11216759681702, "episode_reward": 841.955129106149, "step": 121000}
{"episode": 122.0, "batch_reward": 0.7389538034796714, "actor_loss": -77.63113645935059, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 459.8936131000519, "episode_reward": 878.9244298439557, "step": 122000}
{"episode": 123.0, "batch_reward": 0.7410475603938103, "actor_loss": -77.74705265808106, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.879749059677124, "episode_reward": 919.1190375464836, "step": 123000}
{"episode": 124.0, "batch_reward": 0.7416100100278854, "actor_loss": -77.51962699890137, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 469.5055830478668, "episode_reward": 941.3507604527665, "step": 124000}
{"episode": 125.0, "batch_reward": 0.7432668533921242, "actor_loss": -77.62201528930665, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.837337017059326, "episode_reward": 901.9173574768671, "step": 125000}
{"episode": 126.0, "batch_reward": 0.7457777364850044, "actor_loss": -77.2601722869873, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 468.30265951156616, "episode_reward": 936.9719172619145, "step": 126000}
{"episode": 127.0, "batch_reward": 0.7451331685185433, "actor_loss": -77.27323510742187, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.70485520362854, "episode_reward": 859.8636018838043, "step": 127000}
{"episode": 128.0, "batch_reward": 0.7467859338521957, "actor_loss": -76.74780792236328, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 466.5406744480133, "episode_reward": 869.8453665094326, "step": 128000}
{"episode": 129.0, "batch_reward": 0.747110548555851, "actor_loss": -76.77618235778809, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.133092164993286, "episode_reward": 936.1146403023961, "step": 129000}
{"episode": 130.0, "batch_reward": 0.7492273491024971, "actor_loss": -76.83976231384277, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 466.52863335609436, "episode_reward": 883.308662033186, "step": 130000}
{"episode": 131.0, "batch_reward": 0.7497211951613426, "actor_loss": -76.84835623168945, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.863966941833496, "episode_reward": 880.4286945947358, "step": 131000}
{"episode": 132.0, "batch_reward": 0.7508658252954483, "actor_loss": -76.17863795471192, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 464.47489619255066, "episode_reward": 890.3178850002291, "step": 132000}
{"episode": 133.0, "batch_reward": 0.7532445178627968, "actor_loss": -76.2788561706543, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.484647512435913, "episode_reward": 930.0371007318149, "step": 133000}
{"episode": 134.0, "batch_reward": 0.7538085678815841, "actor_loss": -75.69482971191407, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 474.44650745391846, "episode_reward": 885.5195353852347, "step": 134000}
{"episode": 135.0, "batch_reward": 0.7548844244480133, "actor_loss": -75.80573159790039, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.062671661376953, "episode_reward": 825.0554730610115, "step": 135000}
{"episode": 136.0, "batch_reward": 0.755052785038948, "actor_loss": -75.51822496032715, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 468.99687242507935, "episode_reward": 833.6615011807866, "step": 136000}
{"episode": 137.0, "batch_reward": 0.7569068534374237, "actor_loss": -75.58235813903809, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.537487268447876, "episode_reward": 901.9684519730582, "step": 137000}
{"episode": 138.0, "batch_reward": 0.7574469088315964, "actor_loss": -75.27963540649414, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 467.8711977005005, "episode_reward": 917.8880930234293, "step": 138000}
{"episode": 139.0, "batch_reward": 0.7581273389458656, "actor_loss": -75.27956665039062, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.10822558403015, "episode_reward": 916.9620260809191, "step": 139000}
{"episode": 140.0, "batch_reward": 0.7584535866975785, "actor_loss": -74.6474811706543, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 473.3290798664093, "episode_reward": 881.1507592341776, "step": 140000}
{"episode": 141.0, "batch_reward": 0.7600771463513374, "actor_loss": -74.66582518005372, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.943947076797485, "episode_reward": 775.7118377178048, "step": 141000}
{"episode": 142.0, "batch_reward": 0.7601622585058212, "actor_loss": -74.88081645202637, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 472.4400589466095, "episode_reward": 917.2453180077335, "step": 142000}
{"episode": 143.0, "batch_reward": 0.7601014609932899, "actor_loss": -74.91862406921386, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.375932693481445, "episode_reward": 891.7680691226501, "step": 143000}
{"episode": 144.0, "batch_reward": 0.7615620394945145, "actor_loss": -74.81940208435059, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 483.5695013999939, "episode_reward": 838.5700028168653, "step": 144000}
{"episode": 145.0, "batch_reward": 0.7635603722929954, "actor_loss": -74.96609996032714, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.073477506637573, "episode_reward": 808.6253138104097, "step": 145000}
{"episode": 146.0, "batch_reward": 0.763493333697319, "actor_loss": -74.501763961792, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 473.347781419754, "episode_reward": 732.2793094767046, "step": 146000}
{"episode": 147.0, "batch_reward": 0.7629879039525985, "actor_loss": -74.44551202392579, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.74341869354248, "episode_reward": 877.364987978209, "step": 147000}
{"episode": 148.0, "batch_reward": 0.7632582623958588, "actor_loss": -74.04919606018066, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 484.82505321502686, "episode_reward": 771.007010773471, "step": 148000}
{"episode": 149.0, "batch_reward": 0.7648348816633225, "actor_loss": -74.09756298828125, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.25985550880432, "episode_reward": 900.5100505255449, "step": 149000}
{"episode": 150.0, "batch_reward": 0.763749324798584, "actor_loss": -74.64723793029785, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "step": 150000}
