{"episode_reward": 0.0, "episode": 1.0, "duration": 20.946791887283325, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.8269917964935303, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.46221495456757566, "critic_loss": 0.20581009366654204, "actor_loss": -83.52771825282848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.473209619522095, "step": 3000}
{"episode_reward": 504.06826113651266, "episode": 4.0, "batch_reward": 0.5195112490057945, "critic_loss": 0.3884912932366133, "actor_loss": -84.85884037780762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07149314880371, "step": 4000}
{"episode_reward": 773.6137487500738, "episode": 5.0, "batch_reward": 0.5480526689589024, "critic_loss": 0.6946444835662842, "actor_loss": -85.6273924407959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.066116333007812, "step": 5000}
{"episode_reward": 577.7595994921976, "episode": 6.0, "batch_reward": 0.5624564352631569, "critic_loss": 0.9444685404598713, "actor_loss": -86.30437643432617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.056987762451172, "step": 6000}
{"episode_reward": 647.3418419615059, "episode": 7.0, "batch_reward": 0.5825777364671231, "critic_loss": 1.1047787187099456, "actor_loss": -86.96981265258789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.065242290496826, "step": 7000}
{"episode_reward": 811.1019202323043, "episode": 8.0, "batch_reward": 0.6215713909864425, "critic_loss": 1.123836572110653, "actor_loss": -88.3205362701416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.080395698547363, "step": 8000}
{"episode_reward": 783.4174900230919, "episode": 9.0, "batch_reward": 0.6409867444634437, "critic_loss": 1.1675821987390518, "actor_loss": -88.79457319641114, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.060285329818726, "step": 9000}
{"episode_reward": 897.2592304031874, "episode": 10.0, "batch_reward": 0.6694265144467354, "critic_loss": 1.1216219066381454, "actor_loss": -89.59532391357422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.060311317443848, "step": 10000}
{"episode_reward": 858.7604506857122, "episode": 11.0, "batch_reward": 0.6847020842432976, "critic_loss": 1.063064987719059, "actor_loss": -90.08592567443847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.635361671447754, "step": 11000}
{"episode_reward": 860.3485876645473, "episode": 12.0, "batch_reward": 0.6863206132650376, "critic_loss": 0.9772389852404595, "actor_loss": -90.0943741607666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07251787185669, "step": 12000}
{"episode_reward": 663.5974111631355, "episode": 13.0, "batch_reward": 0.6931686304211616, "critic_loss": 0.8706716836988926, "actor_loss": -90.31897218322754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.070650815963745, "step": 13000}
{"episode_reward": 793.2297017361799, "episode": 14.0, "batch_reward": 0.7046125189065934, "critic_loss": 0.8206334810853004, "actor_loss": -90.61216793823242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.106971740722656, "step": 14000}
{"episode_reward": 902.9989385206636, "episode": 15.0, "batch_reward": 0.7044008530974388, "critic_loss": 0.8029514472484589, "actor_loss": -90.3301745147705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.399142265319824, "step": 15000}
{"episode_reward": 622.4944333847058, "episode": 16.0, "batch_reward": 0.7150504384636879, "critic_loss": 0.7368761692941189, "actor_loss": -90.90130540466309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.069120407104492, "step": 16000}
{"episode_reward": 956.8482286574972, "episode": 17.0, "batch_reward": 0.7254664672613144, "critic_loss": 0.7780735953450203, "actor_loss": -91.01082484436036, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.066468238830566, "step": 17000}
{"episode_reward": 860.7516050594747, "episode": 18.0, "batch_reward": 0.7329751733541489, "critic_loss": 0.7511824240386487, "actor_loss": -91.13897344970704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.051188230514526, "step": 18000}
{"episode_reward": 901.3528895569096, "episode": 19.0, "batch_reward": 0.7443105854392051, "critic_loss": 0.7339437709450721, "actor_loss": -91.34296327209472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.072863817214966, "step": 19000}
{"episode_reward": 916.3055056743269, "episode": 20.0, "batch_reward": 0.7540130199193954, "critic_loss": 0.7635301792621613, "actor_loss": -91.2866607055664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.065662384033203, "step": 20000}
{"episode_reward": 928.5167035701462, "episode": 21.0, "batch_reward": 0.760304865181446, "critic_loss": 0.8072119622528553, "actor_loss": -91.46286450195312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.60203719139099, "step": 21000}
{"episode_reward": 850.4152344740517, "episode": 22.0, "batch_reward": 0.7630667746663093, "critic_loss": 0.9141046415269375, "actor_loss": -91.53842724609375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.081403732299805, "step": 22000}
{"episode_reward": 800.2405462933702, "episode": 23.0, "batch_reward": 0.7663885967731476, "critic_loss": 0.8896833466887474, "actor_loss": -91.64504232788086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.070390701293945, "step": 23000}
{"episode_reward": 926.2854925710487, "episode": 24.0, "batch_reward": 0.7740606251955032, "critic_loss": 0.8666004835665226, "actor_loss": -91.89785859680175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0673611164093, "step": 24000}
{"episode_reward": 886.7371252185064, "episode": 25.0, "batch_reward": 0.7783318506479263, "critic_loss": 0.8359633832275868, "actor_loss": -91.92233404541015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.05393934249878, "step": 25000}
{"episode_reward": 896.9683954507251, "episode": 26.0, "batch_reward": 0.7846395739912987, "critic_loss": 0.8006781623363495, "actor_loss": -92.05323616027832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.066205501556396, "step": 26000}
{"episode_reward": 957.4438542522921, "episode": 27.0, "batch_reward": 0.7851352540254593, "critic_loss": 0.7670054914057255, "actor_loss": -92.0197668762207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08156108856201, "step": 27000}
{"episode_reward": 396.6016558261573, "episode": 28.0, "batch_reward": 0.7763989816904068, "critic_loss": 0.7238132787942886, "actor_loss": -92.02307502746582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08669400215149, "step": 28000}
{"episode_reward": 945.2259576646073, "episode": 29.0, "batch_reward": 0.7818720691800117, "critic_loss": 0.6877008485198021, "actor_loss": -92.0100471496582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09006953239441, "step": 29000}
{"episode_reward": 947.9913001518846, "episode": 30.0, "batch_reward": 0.7854360967874527, "critic_loss": 0.6922398552000523, "actor_loss": -92.0832159576416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.077003955841064, "step": 30000}
{"episode_reward": 883.7103969663153, "episode": 31.0, "batch_reward": 0.7890900720953942, "critic_loss": 0.696146981805563, "actor_loss": -92.2193044128418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.62168788909912, "step": 31000}
{"episode_reward": 905.2452309558322, "episode": 32.0, "batch_reward": 0.7934624487757683, "critic_loss": 0.7753755613565445, "actor_loss": -92.29420402526856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.093206644058228, "step": 32000}
{"episode_reward": 892.2211887711288, "episode": 33.0, "batch_reward": 0.7932257249951362, "critic_loss": 0.7756526295244693, "actor_loss": -92.17355058288574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.065239667892456, "step": 33000}
{"episode_reward": 757.5773310465936, "episode": 34.0, "batch_reward": 0.7935118581056595, "critic_loss": 0.8333525667786599, "actor_loss": -92.35049073791504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09636116027832, "step": 34000}
{"episode_reward": 830.2110104124083, "episode": 35.0, "batch_reward": 0.7966766866445542, "critic_loss": 0.8867156797647476, "actor_loss": -92.23784341430664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.065496683120728, "step": 35000}
{"episode_reward": 906.3634085842273, "episode": 36.0, "batch_reward": 0.8004209388494492, "critic_loss": 0.8760006341338158, "actor_loss": -92.55088972473145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.091137170791626, "step": 36000}
{"episode_reward": 862.5066537013184, "episode": 37.0, "batch_reward": 0.80248495388031, "critic_loss": 0.86167129316926, "actor_loss": -92.53842073059081, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.059383153915405, "step": 37000}
{"episode_reward": 923.703086269008, "episode": 38.0, "batch_reward": 0.8060876117348671, "critic_loss": 0.8182554984390735, "actor_loss": -92.39480018615723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.077466249465942, "step": 38000}
{"episode_reward": 910.8173989373437, "episode": 39.0, "batch_reward": 0.8094360485076905, "critic_loss": 0.7963995053172112, "actor_loss": -92.70140933227539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.083921194076538, "step": 39000}
{"episode_reward": 967.2822617906357, "episode": 40.0, "batch_reward": 0.8107294815778733, "critic_loss": 0.7806717213392258, "actor_loss": -92.7415768585205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08438467979431, "step": 40000}
{"episode_reward": 935.6856179776324, "episode": 41.0, "batch_reward": 0.8145516255497932, "critic_loss": 0.7442129700779915, "actor_loss": -92.93051248168945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.60584735870361, "step": 41000}
{"episode_reward": 920.7461739745489, "episode": 42.0, "batch_reward": 0.8148904816508293, "critic_loss": 0.7755734778046608, "actor_loss": -92.84721304321289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08226466178894, "step": 42000}
{"episode_reward": 864.7188538957648, "episode": 43.0, "batch_reward": 0.8194311158061027, "critic_loss": 0.7336180780827999, "actor_loss": -93.01442080688477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.070518016815186, "step": 43000}
{"episode_reward": 932.9156038776757, "episode": 44.0, "batch_reward": 0.8220204563140869, "critic_loss": 0.6883704472482205, "actor_loss": -92.94182647705078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06723642349243, "step": 44000}
{"episode_reward": 916.3571945717528, "episode": 45.0, "batch_reward": 0.822442936360836, "critic_loss": 0.7238577895462514, "actor_loss": -92.90943884277344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.092232942581177, "step": 45000}
{"episode_reward": 906.2616641799754, "episode": 46.0, "batch_reward": 0.8249266284704209, "critic_loss": 0.6861640149354935, "actor_loss": -93.10052947998047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07567596435547, "step": 46000}
{"episode_reward": 912.470176140744, "episode": 47.0, "batch_reward": 0.8274589086174965, "critic_loss": 0.6620230395197868, "actor_loss": -93.21883894348144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.074277877807617, "step": 47000}
{"episode_reward": 930.2816100311211, "episode": 48.0, "batch_reward": 0.8312243520021438, "critic_loss": 0.6409648831486702, "actor_loss": -93.24592669677735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07986617088318, "step": 48000}
{"episode_reward": 950.7100989279985, "episode": 49.0, "batch_reward": 0.8326399246454239, "critic_loss": 0.6239861086606979, "actor_loss": -93.32994259643554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.048540830612183, "step": 49000}
{"episode_reward": 905.4455227474531, "episode": 50.0, "batch_reward": 0.8336955305337906, "critic_loss": 0.6714303324669599, "actor_loss": -93.20016441345214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.05541443824768, "step": 50000}
{"episode_reward": 870.5152211465178, "episode": 51.0, "batch_reward": 0.83540567111969, "critic_loss": 0.6661568934023381, "actor_loss": -93.41190968322753, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.57971453666687, "step": 51000}
{"episode_reward": 911.7752955372351, "episode": 52.0, "batch_reward": 0.8357869838476181, "critic_loss": 0.6585784301161766, "actor_loss": -93.3783734588623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.063413858413696, "step": 52000}
{"episode_reward": 936.0662561799911, "episode": 53.0, "batch_reward": 0.8374208219051361, "critic_loss": 0.6967949974089861, "actor_loss": -93.18787028503418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.076635599136353, "step": 53000}
{"episode_reward": 881.6765765936677, "episode": 54.0, "batch_reward": 0.8401838129162789, "critic_loss": 0.6765666095465421, "actor_loss": -93.69764147949219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.062461853027344, "step": 54000}
{"episode_reward": 917.7836000223501, "episode": 55.0, "batch_reward": 0.8394802032709122, "critic_loss": 0.6324155242145062, "actor_loss": -93.55294030761719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07929253578186, "step": 55000}
{"episode_reward": 939.4569532458589, "episode": 56.0, "batch_reward": 0.8416328527331353, "critic_loss": 0.6288061158359051, "actor_loss": -93.41690101623536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.091327905654907, "step": 56000}
{"episode_reward": 972.476249033074, "episode": 57.0, "batch_reward": 0.8437302483320236, "critic_loss": 0.6054076445251704, "actor_loss": -93.6342781677246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.077093839645386, "step": 57000}
{"episode_reward": 934.8071356275468, "episode": 58.0, "batch_reward": 0.8450726376771927, "critic_loss": 0.603561467140913, "actor_loss": -93.64535369873047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10237765312195, "step": 58000}
{"episode_reward": 903.8337225595433, "episode": 59.0, "batch_reward": 0.8460138173103332, "critic_loss": 0.5621433277279139, "actor_loss": -93.73890431213378, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08091163635254, "step": 59000}
{"episode_reward": 865.8937269001342, "episode": 60.0, "batch_reward": 0.8465602177977561, "critic_loss": 0.6013674207180738, "actor_loss": -93.57477185058593, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07867121696472, "step": 60000}
{"episode_reward": 828.2042096915737, "episode": 61.0, "batch_reward": 0.8464032184481621, "critic_loss": 0.6186417230069637, "actor_loss": -93.71422785949707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.60757803916931, "step": 61000}
{"episode_reward": 876.2904197978881, "episode": 62.0, "batch_reward": 0.8464699130654335, "critic_loss": 0.6110236763507128, "actor_loss": -93.53329257202148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.082130193710327, "step": 62000}
{"episode_reward": 929.1492964102162, "episode": 63.0, "batch_reward": 0.8464728751182556, "critic_loss": 0.6118770984709263, "actor_loss": -93.62231161499024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.077842473983765, "step": 63000}
{"episode_reward": 874.2019756375787, "episode": 64.0, "batch_reward": 0.8486997843384743, "critic_loss": 0.6099138629436492, "actor_loss": -93.7562027130127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07059407234192, "step": 64000}
{"episode_reward": 916.5455233440589, "episode": 65.0, "batch_reward": 0.8504353308677673, "critic_loss": 0.6076261955052614, "actor_loss": -93.61006010437012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.070437908172607, "step": 65000}
{"episode_reward": 930.0913763645383, "episode": 66.0, "batch_reward": 0.8502352535128593, "critic_loss": 0.622915223479271, "actor_loss": -93.68119320678711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.084158182144165, "step": 66000}
{"episode_reward": 898.4889151465923, "episode": 67.0, "batch_reward": 0.846448437333107, "critic_loss": 0.6460787458568812, "actor_loss": -93.54046417236329, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09700632095337, "step": 67000}
{"episode_reward": 64.169976107007, "episode": 68.0, "batch_reward": 0.8390154184103013, "critic_loss": 0.6686506630480289, "actor_loss": -93.5659552154541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09867525100708, "step": 68000}
{"episode_reward": 923.0192651765675, "episode": 69.0, "batch_reward": 0.8422084383368492, "critic_loss": 0.6582069657742977, "actor_loss": -93.58582302856445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.076411247253418, "step": 69000}
{"episode_reward": 953.9674349267598, "episode": 70.0, "batch_reward": 0.8422398213744163, "critic_loss": 0.6794034163057804, "actor_loss": -93.67852070617676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.073824167251587, "step": 70000}
{"episode_reward": 880.3360075485085, "episode": 71.0, "batch_reward": 0.8428091742396354, "critic_loss": 0.6956743857562542, "actor_loss": -93.45392839050292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.89947295188904, "step": 71000}
{"episode_reward": 948.5626158683295, "episode": 72.0, "batch_reward": 0.8454381944537163, "critic_loss": 0.640733931273222, "actor_loss": -93.74484640502929, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.086077451705933, "step": 72000}
{"episode_reward": 910.0727747911775, "episode": 73.0, "batch_reward": 0.8461019580364227, "critic_loss": 0.6066623484641314, "actor_loss": -93.73554158020019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.046979904174805, "step": 73000}
{"episode_reward": 930.931036866592, "episode": 74.0, "batch_reward": 0.8465340521931648, "critic_loss": 0.5986083808392286, "actor_loss": -93.68402548217773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.058348417282104, "step": 74000}
{"episode_reward": 900.4206415244311, "episode": 75.0, "batch_reward": 0.8496028813719749, "critic_loss": 0.5686970244646072, "actor_loss": -93.8116812133789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.074461460113525, "step": 75000}
{"episode_reward": 957.8869312383301, "episode": 76.0, "batch_reward": 0.849508246421814, "critic_loss": 0.535156637981534, "actor_loss": -93.78286668395997, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.082387924194336, "step": 76000}
{"episode_reward": 940.2755830318914, "episode": 77.0, "batch_reward": 0.8514455857872963, "critic_loss": 0.5315015621781349, "actor_loss": -93.79129382324219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.074268102645874, "step": 77000}
{"episode_reward": 959.4845448694653, "episode": 78.0, "batch_reward": 0.8512659673094749, "critic_loss": 0.5501768799871206, "actor_loss": -93.78860076904297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.082558393478394, "step": 78000}
{"episode_reward": 951.3688629845931, "episode": 79.0, "batch_reward": 0.8512398353815078, "critic_loss": 0.6010985428839922, "actor_loss": -93.78510827636718, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.413848161697388, "step": 79000}
{"episode_reward": 887.8119193250303, "episode": 80.0, "batch_reward": 0.8538246858716011, "critic_loss": 0.5158378448933363, "actor_loss": -93.90876344299316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.091392040252686, "step": 80000}
{"episode_reward": 906.5299834333163, "episode": 81.0, "batch_reward": 0.8544530352950096, "critic_loss": 0.5419039883166552, "actor_loss": -93.73421453857422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.6250901222229, "step": 81000}
{"episode_reward": 939.0773328188308, "episode": 82.0, "batch_reward": 0.8552813309431077, "critic_loss": 0.5717843309491872, "actor_loss": -93.81551795959473, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06715440750122, "step": 82000}
{"episode_reward": 924.7117805785999, "episode": 83.0, "batch_reward": 0.8557758867740631, "critic_loss": 0.5304929832965135, "actor_loss": -94.02528805541992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.095630168914795, "step": 83000}
{"episode_reward": 927.017448847456, "episode": 84.0, "batch_reward": 0.8563997725248337, "critic_loss": 0.588953726708889, "actor_loss": -94.09015238952637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.073145151138306, "step": 84000}
{"episode_reward": 922.6978208789999, "episode": 85.0, "batch_reward": 0.8564290702342987, "critic_loss": 0.5765003236681223, "actor_loss": -93.88251493835449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07294726371765, "step": 85000}
{"episode_reward": 900.2519801939746, "episode": 86.0, "batch_reward": 0.8579944148659706, "critic_loss": 0.5464920037984848, "actor_loss": -93.99585830688477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07188320159912, "step": 86000}
{"episode_reward": 953.9460184615161, "episode": 87.0, "batch_reward": 0.8596211490035057, "critic_loss": 0.5488318402767182, "actor_loss": -94.10461563110351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.064149856567383, "step": 87000}
{"episode_reward": 938.1145698472542, "episode": 88.0, "batch_reward": 0.8599863386154175, "critic_loss": 0.5613623998314142, "actor_loss": -94.13229266357422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.05830478668213, "step": 88000}
{"episode_reward": 974.4598244934868, "episode": 89.0, "batch_reward": 0.8614131922721863, "critic_loss": 0.5458767577409744, "actor_loss": -94.05415116882324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.069140672683716, "step": 89000}
{"episode_reward": 926.6831501671581, "episode": 90.0, "batch_reward": 0.8621175216436386, "critic_loss": 0.5550517009496689, "actor_loss": -94.13637355041504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.072702407836914, "step": 90000}
{"episode_reward": 929.7492233175931, "episode": 91.0, "batch_reward": 0.8628911429643631, "critic_loss": 0.5470530302822589, "actor_loss": -94.08955624389648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.62941575050354, "step": 91000}
{"episode_reward": 921.5687844439001, "episode": 92.0, "batch_reward": 0.8645799540281296, "critic_loss": 0.5261754475682974, "actor_loss": -94.20547981262207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.081738471984863, "step": 92000}
{"episode_reward": 957.6270016927575, "episode": 93.0, "batch_reward": 0.8650208774209023, "critic_loss": 0.534424468010664, "actor_loss": -94.24687951660157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.087871074676514, "step": 93000}
{"episode_reward": 944.9343934065089, "episode": 94.0, "batch_reward": 0.8644766477346421, "critic_loss": 0.5449573634713888, "actor_loss": -94.33907353210449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.095710039138794, "step": 94000}
{"episode_reward": 908.7821443009252, "episode": 95.0, "batch_reward": 0.8659538500905037, "critic_loss": 0.5669580639600754, "actor_loss": -94.37097206115723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.071186780929565, "step": 95000}
{"episode_reward": 853.9635157560491, "episode": 96.0, "batch_reward": 0.8646526905298233, "critic_loss": 0.5861809154748917, "actor_loss": -94.2960704650879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06869411468506, "step": 96000}
{"episode_reward": 943.9226276176626, "episode": 97.0, "batch_reward": 0.8653345236182213, "critic_loss": 0.5756408147364854, "actor_loss": -94.28737380981445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09314775466919, "step": 97000}
{"episode_reward": 947.937678689002, "episode": 98.0, "batch_reward": 0.8677270113229751, "critic_loss": 0.5290041799247265, "actor_loss": -94.31724430847169, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.075971126556396, "step": 98000}
{"episode_reward": 945.9804053132451, "episode": 99.0, "batch_reward": 0.8685422492623329, "critic_loss": 0.5303049207478762, "actor_loss": -94.36637062072754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.059759855270386, "step": 99000}
{"episode_reward": 932.1510010569154, "episode": 100.0, "batch_reward": 0.8682971429228783, "critic_loss": 0.5796444817632437, "actor_loss": -94.3682472076416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.064659118652344, "step": 100000}
{"episode_reward": 951.2705536048089, "episode": 101.0, "batch_reward": 0.8703015391230583, "critic_loss": 0.5894009425342083, "actor_loss": -94.3468115234375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.62887907028198, "step": 101000}
{"episode_reward": 949.4871818610117, "episode": 102.0, "batch_reward": 0.8706852315664292, "critic_loss": 0.6176908492296934, "actor_loss": -94.52811289978027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.073547840118408, "step": 102000}
{"episode_reward": 945.1936195561681, "episode": 103.0, "batch_reward": 0.8724420005083084, "critic_loss": 0.5982454572021961, "actor_loss": -94.39363873291016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.068715810775757, "step": 103000}
{"episode_reward": 938.2540394348013, "episode": 104.0, "batch_reward": 0.8723440257906914, "critic_loss": 0.6177965766638518, "actor_loss": -94.51790980529785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08802628517151, "step": 104000}
{"episode_reward": 932.3090208337487, "episode": 105.0, "batch_reward": 0.8725563886761666, "critic_loss": 0.54044947129488, "actor_loss": -94.3744799041748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08023500442505, "step": 105000}
{"episode_reward": 962.8616970806477, "episode": 106.0, "batch_reward": 0.8728004916906357, "critic_loss": 0.5283346451520919, "actor_loss": -94.62781338500976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.088029384613037, "step": 106000}
{"episode_reward": 913.7850832737759, "episode": 107.0, "batch_reward": 0.8734671823978424, "critic_loss": 0.5269397796541453, "actor_loss": -94.49200529479981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.071776866912842, "step": 107000}
{"episode_reward": 845.445113176709, "episode": 108.0, "batch_reward": 0.8729283175468445, "critic_loss": 0.5507109255641699, "actor_loss": -94.39061674499511, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07157588005066, "step": 108000}
{"episode_reward": 919.2651913383963, "episode": 109.0, "batch_reward": 0.8728063540458679, "critic_loss": 0.5497337989062071, "actor_loss": -94.51753117370606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06812047958374, "step": 109000}
{"episode_reward": 921.688531780765, "episode": 110.0, "batch_reward": 0.8742261641025543, "critic_loss": 0.5515553726255894, "actor_loss": -94.51598936462402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.080899953842163, "step": 110000}
{"episode_reward": 884.9256759361099, "episode": 111.0, "batch_reward": 0.8736938518881798, "critic_loss": 0.5730912348628044, "actor_loss": -94.44555123901367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.67183327674866, "step": 111000}
{"episode_reward": 929.669021956132, "episode": 112.0, "batch_reward": 0.874922120809555, "critic_loss": 0.5511766947805882, "actor_loss": -94.60026060485839, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10266399383545, "step": 112000}
{"episode_reward": 915.9724369871889, "episode": 113.0, "batch_reward": 0.8753503057956695, "critic_loss": 0.5520326417833566, "actor_loss": -94.58359785461425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.102750539779663, "step": 113000}
{"episode_reward": 919.9159448991612, "episode": 114.0, "batch_reward": 0.8735050051808357, "critic_loss": 0.5631417657285929, "actor_loss": -94.6155322265625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10652446746826, "step": 114000}
{"episode_reward": 969.0254799540052, "episode": 115.0, "batch_reward": 0.8768237102031707, "critic_loss": 0.5875585298240185, "actor_loss": -94.63247825622558, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.069681644439697, "step": 115000}
{"episode_reward": 952.5304207427432, "episode": 116.0, "batch_reward": 0.8769671138525009, "critic_loss": 0.6071935850679875, "actor_loss": -94.58668031311035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06775689125061, "step": 116000}
{"episode_reward": 870.7742194815838, "episode": 117.0, "batch_reward": 0.8759450767040252, "critic_loss": 0.5529599904567003, "actor_loss": -94.43098121643067, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.079012155532837, "step": 117000}
{"episode_reward": 933.472396563802, "episode": 118.0, "batch_reward": 0.8764703760147095, "critic_loss": 0.6123923683613539, "actor_loss": -94.49315585327149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08868718147278, "step": 118000}
{"episode_reward": 844.8315957556039, "episode": 119.0, "batch_reward": 0.8777405784726143, "critic_loss": 0.6261770125478506, "actor_loss": -94.5393473815918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.066975355148315, "step": 119000}
{"episode_reward": 945.9621713637861, "episode": 120.0, "batch_reward": 0.8786186203360558, "critic_loss": 0.5880824682712555, "actor_loss": -94.52234436035157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.082080602645874, "step": 120000}
{"episode_reward": 967.8064989583572, "episode": 121.0, "batch_reward": 0.8792524693012238, "critic_loss": 0.5765410298854112, "actor_loss": -94.57293661499024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.65416646003723, "step": 121000}
{"episode_reward": 946.0282214144333, "episode": 122.0, "batch_reward": 0.8780023241043091, "critic_loss": 0.6107419700622558, "actor_loss": -94.57656941223145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07122230529785, "step": 122000}
{"episode_reward": 881.6944370298637, "episode": 123.0, "batch_reward": 0.8796860803365707, "critic_loss": 0.6318618844896555, "actor_loss": -94.73291816711426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.082531929016113, "step": 123000}
{"episode_reward": 917.742027612445, "episode": 124.0, "batch_reward": 0.8796108388900756, "critic_loss": 0.6269619682133197, "actor_loss": -94.68854136657716, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07634210586548, "step": 124000}
{"episode_reward": 877.9099823332048, "episode": 125.0, "batch_reward": 0.880371059536934, "critic_loss": 0.6375370470583439, "actor_loss": -94.72867840576171, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.081032514572144, "step": 125000}
{"episode_reward": 947.7486619947305, "episode": 126.0, "batch_reward": 0.8805361374616623, "critic_loss": 0.6324680251628161, "actor_loss": -94.62952459716797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.082277536392212, "step": 126000}
{"episode_reward": 927.088839935378, "episode": 127.0, "batch_reward": 0.880534222483635, "critic_loss": 0.6650068976432085, "actor_loss": -94.61042678833007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07933521270752, "step": 127000}
{"episode_reward": 952.4547282307107, "episode": 128.0, "batch_reward": 0.8803980403542518, "critic_loss": 0.7843429588526487, "actor_loss": -94.71998918151856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.07660937309265, "step": 128000}
{"episode_reward": 888.9371192891762, "episode": 129.0, "batch_reward": 0.8800644286870957, "critic_loss": 0.9192836790531874, "actor_loss": -94.63607279968262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.087252616882324, "step": 129000}
{"episode_reward": 965.3759483385609, "episode": 130.0, "batch_reward": 0.8827783286571502, "critic_loss": 1.0178848153650761, "actor_loss": -94.74884175109864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.082594871520996, "step": 130000}
{"episode_reward": 940.4328966566909, "episode": 131.0, "batch_reward": 0.8811377404928208, "critic_loss": 1.1958915981501341, "actor_loss": -94.70086138916015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.68518543243408, "step": 131000}
{"episode_reward": 919.3402249767478, "episode": 132.0, "batch_reward": 0.8814872869849205, "critic_loss": 1.248618943721056, "actor_loss": -94.85240620422363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09064555168152, "step": 132000}
{"episode_reward": 935.6382186873551, "episode": 133.0, "batch_reward": 0.8828683328032494, "critic_loss": 1.5248557924330235, "actor_loss": -94.79940208435059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.101459503173828, "step": 133000}
{"episode_reward": 962.2097313176931, "episode": 134.0, "batch_reward": 0.8830302250385285, "critic_loss": 1.318050973623991, "actor_loss": -94.77487846374511, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.081238508224487, "step": 134000}
{"episode_reward": 884.873540000931, "episode": 135.0, "batch_reward": 0.8830215557813644, "critic_loss": 1.1323704266548156, "actor_loss": -94.86549102783204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09236741065979, "step": 135000}
{"episode_reward": 923.2249794545554, "episode": 136.0, "batch_reward": 0.8837896110415459, "critic_loss": 0.9738767567873001, "actor_loss": -94.6898151550293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.075809240341187, "step": 136000}
{"episode_reward": 939.4519981556583, "episode": 137.0, "batch_reward": 0.8822147418856621, "critic_loss": 0.8438838569074869, "actor_loss": -94.8647056427002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0776309967041, "step": 137000}
{"episode_reward": 922.9019414992576, "episode": 138.0, "batch_reward": 0.8853795157074928, "critic_loss": 0.7412347009032965, "actor_loss": -94.95479733276368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.075557470321655, "step": 138000}
{"episode_reward": 915.6842190406375, "episode": 139.0, "batch_reward": 0.8849852628707886, "critic_loss": 0.6924896798282861, "actor_loss": -94.86929899597168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.079792976379395, "step": 139000}
{"episode_reward": 937.4312927512204, "episode": 140.0, "batch_reward": 0.8865806844234466, "critic_loss": 0.6742507382929325, "actor_loss": -94.89927604675293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.066230297088623, "step": 140000}
{"episode_reward": 950.9184279186194, "episode": 141.0, "batch_reward": 0.8842611660957337, "critic_loss": 0.6694023052603006, "actor_loss": -94.79714889526367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.63744616508484, "step": 141000}
{"episode_reward": 964.7935462100038, "episode": 142.0, "batch_reward": 0.8856033114790917, "critic_loss": 0.6788402116894722, "actor_loss": -94.70624786376953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.06083583831787, "step": 142000}
{"episode_reward": 935.4682559355869, "episode": 143.0, "batch_reward": 0.8867079701423645, "critic_loss": 0.6624162129461765, "actor_loss": -94.81105680847168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.085734367370605, "step": 143000}
{"episode_reward": 906.754115535943, "episode": 144.0, "batch_reward": 0.8870204897522926, "critic_loss": 0.682665304362774, "actor_loss": -94.88326399230957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0754177570343, "step": 144000}
{"episode_reward": 905.1835869822274, "episode": 145.0, "batch_reward": 0.8861776214838027, "critic_loss": 0.6557931916713715, "actor_loss": -94.89145434570312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0912344455719, "step": 145000}
{"episode_reward": 912.5040442288657, "episode": 146.0, "batch_reward": 0.887086092531681, "critic_loss": 0.6508626522570848, "actor_loss": -94.96228204345704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.096904754638672, "step": 146000}
{"episode_reward": 959.1811001560346, "episode": 147.0, "batch_reward": 0.886941899240017, "critic_loss": 0.6491962065547705, "actor_loss": -94.89518063354492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.099910020828247, "step": 147000}
{"episode_reward": 876.3988922183969, "episode": 148.0, "batch_reward": 0.8866209778785705, "critic_loss": 0.6683603870719671, "actor_loss": -94.90587377929687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.082825183868408, "step": 148000}
{"episode_reward": 942.0730854189968, "episode": 149.0, "batch_reward": 0.8871813251972198, "critic_loss": 0.6499533351361751, "actor_loss": -94.81840408325195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.09214425086975, "step": 149000}
{"episode_reward": 956.5282858412879, "episode": 150.0, "batch_reward": 0.88672943431139, "critic_loss": 0.6525174521058797, "actor_loss": -94.84312701416016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
