{"episode_reward": 0.0, "episode": 1.0, "duration": 21.978312253952026, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.9061179161071777, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.4686615349710604, "critic_loss": 0.15141849439912894, "actor_loss": -83.90201121342092, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 69.12427282333374, "step": 3000}
{"episode_reward": 621.7926343589852, "episode": 4.0, "batch_reward": 0.5516951247751712, "critic_loss": 0.3152389674782753, "actor_loss": -86.98892692565919, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.106937885284424, "step": 4000}
{"episode_reward": 791.2356635825142, "episode": 5.0, "batch_reward": 0.5930806376338005, "critic_loss": 0.4957282142788172, "actor_loss": -88.10587763977051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.074409008026123, "step": 5000}
{"episode_reward": 739.434929294044, "episode": 6.0, "batch_reward": 0.5805664804279804, "critic_loss": 0.5477765954732895, "actor_loss": -87.94098315429687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.127365589141846, "step": 6000}
{"episode_reward": 140.59787297214527, "episode": 7.0, "batch_reward": 0.5437343305647373, "critic_loss": 0.6692974737286568, "actor_loss": -87.00948608398437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.098491430282593, "step": 7000}
{"episode_reward": 762.3619061486853, "episode": 8.0, "batch_reward": 0.5755163228809833, "critic_loss": 0.8304589135050774, "actor_loss": -87.85803343200683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.083564043045044, "step": 8000}
{"episode_reward": 713.6165949330608, "episode": 9.0, "batch_reward": 0.5864245783686638, "critic_loss": 0.9569326996803283, "actor_loss": -87.91865641784668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.042839765548706, "step": 9000}
{"episode_reward": 673.5780419239563, "episode": 10.0, "batch_reward": 0.6078226888179779, "critic_loss": 1.0081828429102897, "actor_loss": -88.42592807006837, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.03981328010559, "step": 10000}
{"episode_reward": 820.3050158080844, "episode": 11.0, "batch_reward": 0.6211983090043068, "critic_loss": 1.1302011744379998, "actor_loss": -88.74133251953126, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.49296569824219, "step": 11000}
{"episode_reward": 715.7765048175636, "episode": 12.0, "batch_reward": 0.6361310751438141, "critic_loss": 1.0941240763068198, "actor_loss": -88.99732745361328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.971495389938354, "step": 12000}
{"episode_reward": 862.863667234787, "episode": 13.0, "batch_reward": 0.6421082428097725, "critic_loss": 1.1627873495817185, "actor_loss": -89.12655422973633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.003066539764404, "step": 13000}
{"episode_reward": 688.9231629330608, "episode": 14.0, "batch_reward": 0.6553526510000229, "critic_loss": 1.2114077701568604, "actor_loss": -89.46601159667969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.987928867340088, "step": 14000}
{"episode_reward": 775.8138018280441, "episode": 15.0, "batch_reward": 0.661621438741684, "critic_loss": 1.3120622707605363, "actor_loss": -88.98498022460937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.97185206413269, "step": 15000}
{"episode_reward": 790.6278889794664, "episode": 16.0, "batch_reward": 0.6764158967137337, "critic_loss": 1.3007564635276794, "actor_loss": -89.87163485717774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.86324167251587, "step": 16000}
{"episode_reward": 925.417197534957, "episode": 17.0, "batch_reward": 0.6863396013975144, "critic_loss": 1.2283156108260154, "actor_loss": -89.86084840393066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.548646211624146, "step": 17000}
{"episode_reward": 848.208247853876, "episode": 18.0, "batch_reward": 0.6965754818320274, "critic_loss": 1.2065251656770706, "actor_loss": -90.18750888061524, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.095613479614258, "step": 18000}
{"episode_reward": 872.3153876078399, "episode": 19.0, "batch_reward": 0.7077875158190727, "critic_loss": 1.1671526339650153, "actor_loss": -90.48546524047852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.118247747421265, "step": 19000}
{"episode_reward": 924.505388255476, "episode": 20.0, "batch_reward": 0.7172060617804528, "critic_loss": 1.1150237434506416, "actor_loss": -90.37077690124512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.09393048286438, "step": 20000}
{"episode_reward": 861.6784360069265, "episode": 21.0, "batch_reward": 0.7278296059966087, "critic_loss": 1.072462984085083, "actor_loss": -90.68363374328614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.629711389541626, "step": 21000}
{"episode_reward": 910.1976468752945, "episode": 22.0, "batch_reward": 0.7346538617014885, "critic_loss": 1.0905200055241584, "actor_loss": -90.73521406555176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.122694730758667, "step": 22000}
{"episode_reward": 853.1902122281996, "episode": 23.0, "batch_reward": 0.7364168676137924, "critic_loss": 1.086417831480503, "actor_loss": -90.831494430542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.071158409118652, "step": 23000}
{"episode_reward": 835.1614204965472, "episode": 24.0, "batch_reward": 0.7442109415531158, "critic_loss": 1.054815110862255, "actor_loss": -90.92352806091309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.14346718788147, "step": 24000}
{"episode_reward": 892.2576588851732, "episode": 25.0, "batch_reward": 0.7501553873419762, "critic_loss": 1.0017255098819733, "actor_loss": -91.31864689636231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.082152843475342, "step": 25000}
{"episode_reward": 911.7883774757495, "episode": 26.0, "batch_reward": 0.7579837779402733, "critic_loss": 0.9902995212078094, "actor_loss": -91.20178175354003, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.129421949386597, "step": 26000}
{"episode_reward": 915.500909908143, "episode": 27.0, "batch_reward": 0.7640272664427757, "critic_loss": 0.9497324001193047, "actor_loss": -91.4590726776123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.115702867507935, "step": 27000}
{"episode_reward": 906.2453351448555, "episode": 28.0, "batch_reward": 0.7672498522996902, "critic_loss": 0.871256589949131, "actor_loss": -91.59625788879394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.088387966156006, "step": 28000}
{"episode_reward": 852.8818782283626, "episode": 29.0, "batch_reward": 0.7728949888944626, "critic_loss": 0.8497133374512196, "actor_loss": -91.39173072814941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.124130249023438, "step": 29000}
{"episode_reward": 959.524040006625, "episode": 30.0, "batch_reward": 0.7733041706681252, "critic_loss": 0.9482372242212296, "actor_loss": -91.42694281005859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.110955238342285, "step": 30000}
{"episode_reward": 811.3020911364429, "episode": 31.0, "batch_reward": 0.7758291330337524, "critic_loss": 0.9904230554103851, "actor_loss": -91.84290615844726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.65858197212219, "step": 31000}
{"episode_reward": 870.5050192902087, "episode": 32.0, "batch_reward": 0.7813276356458664, "critic_loss": 0.9646618301272393, "actor_loss": -91.92273933410644, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.097382068634033, "step": 32000}
{"episode_reward": 929.2858294075645, "episode": 33.0, "batch_reward": 0.782164916396141, "critic_loss": 1.0634461257457732, "actor_loss": -91.93450137329101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.044604539871216, "step": 33000}
{"episode_reward": 687.6599236109739, "episode": 34.0, "batch_reward": 0.7804954625964164, "critic_loss": 0.985791113436222, "actor_loss": -91.99075202941894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.054686784744263, "step": 34000}
{"episode_reward": 784.1832858369697, "episode": 35.0, "batch_reward": 0.7840101154446601, "critic_loss": 0.9998862309455872, "actor_loss": -91.87267059326172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.08762836456299, "step": 35000}
{"episode_reward": 897.2673493745499, "episode": 36.0, "batch_reward": 0.7847936382293701, "critic_loss": 1.0106753473579884, "actor_loss": -92.4011955871582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.093549728393555, "step": 36000}
{"episode_reward": 816.8962163710486, "episode": 37.0, "batch_reward": 0.7890569046735764, "critic_loss": 0.9682519360184669, "actor_loss": -92.28444165039062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.101985216140747, "step": 37000}
{"episode_reward": 915.4882869577807, "episode": 38.0, "batch_reward": 0.7918701077103615, "critic_loss": 1.0089989189505577, "actor_loss": -92.09251034545899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.111494302749634, "step": 38000}
{"episode_reward": 928.4101036139797, "episode": 39.0, "batch_reward": 0.794018775343895, "critic_loss": 0.9671976537406445, "actor_loss": -92.46726133728028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.082609176635742, "step": 39000}
{"episode_reward": 897.0997754828231, "episode": 40.0, "batch_reward": 0.7947785819172859, "critic_loss": 0.9358697205781936, "actor_loss": -92.48240946960449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.073085069656372, "step": 40000}
{"episode_reward": 897.7383973737783, "episode": 41.0, "batch_reward": 0.7976238312125206, "critic_loss": 0.9264594408273696, "actor_loss": -92.72469813537597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.59843158721924, "step": 41000}
{"episode_reward": 876.3441309291675, "episode": 42.0, "batch_reward": 0.8006656330823898, "critic_loss": 0.934533460766077, "actor_loss": -92.25997897338867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.026508808135986, "step": 42000}
{"episode_reward": 931.3925533931779, "episode": 43.0, "batch_reward": 0.8042992175817489, "critic_loss": 0.9142196518778801, "actor_loss": -92.64847914123536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.026958465576172, "step": 43000}
{"episode_reward": 815.2270479897775, "episode": 44.0, "batch_reward": 0.8031971964836121, "critic_loss": 0.9774643194079399, "actor_loss": -92.58526150512695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.982958793640137, "step": 44000}
{"episode_reward": 851.9384675778794, "episode": 45.0, "batch_reward": 0.8040355533361435, "critic_loss": 0.8985688786804676, "actor_loss": -92.538642578125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.012454986572266, "step": 45000}
{"episode_reward": 882.2708763301646, "episode": 46.0, "batch_reward": 0.8063141881227494, "critic_loss": 0.9281150059998036, "actor_loss": -92.51626174926758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.977558374404907, "step": 46000}
{"episode_reward": 917.9549368445743, "episode": 47.0, "batch_reward": 0.8095866172909737, "critic_loss": 0.9350694881677628, "actor_loss": -92.75717658996582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.94389009475708, "step": 47000}
{"episode_reward": 907.7360490551683, "episode": 48.0, "batch_reward": 0.8121610773801804, "critic_loss": 0.9561362306773663, "actor_loss": -92.79862141418457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.182339429855347, "step": 48000}
{"episode_reward": 923.6775273095857, "episode": 49.0, "batch_reward": 0.8128329657316208, "critic_loss": 0.9205600409507751, "actor_loss": -92.89168048095704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.949219465255737, "step": 49000}
{"episode_reward": 914.2962084074759, "episode": 50.0, "batch_reward": 0.8156474254727364, "critic_loss": 0.984692703038454, "actor_loss": -92.74805250549316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.11059546470642, "step": 50000}
{"episode_reward": 838.2375631478726, "episode": 51.0, "batch_reward": 0.8169250577092171, "critic_loss": 0.9847465468645096, "actor_loss": -92.88372868347167, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.625343799591064, "step": 51000}
{"episode_reward": 881.8843446787533, "episode": 52.0, "batch_reward": 0.8169897260069847, "critic_loss": 0.982405575633049, "actor_loss": -93.05687167358398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.101317644119263, "step": 52000}
{"episode_reward": 868.4870456805152, "episode": 53.0, "batch_reward": 0.8177572727799416, "critic_loss": 0.9872313803732395, "actor_loss": -92.73150730895996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.101698875427246, "step": 53000}
{"episode_reward": 850.1170103449995, "episode": 54.0, "batch_reward": 0.8193356766104698, "critic_loss": 0.8822799045443535, "actor_loss": -93.26428102111817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.108425617218018, "step": 54000}
{"episode_reward": 834.4476837303348, "episode": 55.0, "batch_reward": 0.8193988404273986, "critic_loss": 0.9109749102294445, "actor_loss": -93.07272120666504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.08334732055664, "step": 55000}
{"episode_reward": 832.2581888083521, "episode": 56.0, "batch_reward": 0.8200651406049728, "critic_loss": 0.9039289397746324, "actor_loss": -92.74794255065918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.110602378845215, "step": 56000}
{"episode_reward": 931.1948895425485, "episode": 57.0, "batch_reward": 0.8224121824502945, "critic_loss": 0.8710051820278167, "actor_loss": -93.19698803710938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.06554341316223, "step": 57000}
{"episode_reward": 928.2379987798633, "episode": 58.0, "batch_reward": 0.8226700285077095, "critic_loss": 0.901222042620182, "actor_loss": -93.043497756958, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.11748433113098, "step": 58000}
{"episode_reward": 827.1943240226839, "episode": 59.0, "batch_reward": 0.8227252452373505, "critic_loss": 0.9243349329233169, "actor_loss": -93.03735137939454, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.106890439987183, "step": 59000}
{"episode_reward": 689.0747946575243, "episode": 60.0, "batch_reward": 0.819794835627079, "critic_loss": 0.9724617546498775, "actor_loss": -92.96365495300293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.058098316192627, "step": 60000}
{"episode_reward": 731.7000676348473, "episode": 61.0, "batch_reward": 0.816997288942337, "critic_loss": 1.0375406660139561, "actor_loss": -93.02288957214355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.63485383987427, "step": 61000}
{"episode_reward": 583.5970105415556, "episode": 62.0, "batch_reward": 0.8145426217317581, "critic_loss": 1.0463567996621133, "actor_loss": -92.77034794616699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.03248119354248, "step": 62000}
{"episode_reward": 887.2643569518648, "episode": 63.0, "batch_reward": 0.8164321202635765, "critic_loss": 1.0309505535066128, "actor_loss": -92.87508180236816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.13935160636902, "step": 63000}
{"episode_reward": 875.3686448966197, "episode": 64.0, "batch_reward": 0.8180016478300095, "critic_loss": 1.0924645431041717, "actor_loss": -92.90667079162597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.076310873031616, "step": 64000}
{"episode_reward": 886.2659527407025, "episode": 65.0, "batch_reward": 0.8194224218726158, "critic_loss": 1.154917816400528, "actor_loss": -92.85914656066895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.065975666046143, "step": 65000}
{"episode_reward": 911.062757439385, "episode": 66.0, "batch_reward": 0.8195107348561287, "critic_loss": 1.236527024626732, "actor_loss": -92.91029759216309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.02383279800415, "step": 66000}
{"episode_reward": 684.8785095441613, "episode": 67.0, "batch_reward": 0.8196474965810776, "critic_loss": 1.3385456770062447, "actor_loss": -92.76655180358887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.073435306549072, "step": 67000}
{"episode_reward": 920.0563252194937, "episode": 68.0, "batch_reward": 0.8193644177913666, "critic_loss": 1.294104903638363, "actor_loss": -93.028837600708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.080739736557007, "step": 68000}
{"episode_reward": 940.3581777687584, "episode": 69.0, "batch_reward": 0.8211656190752983, "critic_loss": 1.3697007434368134, "actor_loss": -93.12114190673829, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.097254037857056, "step": 69000}
{"episode_reward": 874.4271762897358, "episode": 70.0, "batch_reward": 0.8222981824874878, "critic_loss": 1.619187357544899, "actor_loss": -93.12184274291992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.07436227798462, "step": 70000}
{"episode_reward": 815.8726324065176, "episode": 71.0, "batch_reward": 0.8216145939826965, "critic_loss": 1.752280615091324, "actor_loss": -92.84032981872559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.609750509262085, "step": 71000}
{"episode_reward": 866.0168084473814, "episode": 72.0, "batch_reward": 0.8222630996108055, "critic_loss": 2.1358124300837518, "actor_loss": -93.22640774536133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.051806211471558, "step": 72000}
{"episode_reward": 894.7258121746657, "episode": 73.0, "batch_reward": 0.8234218552112579, "critic_loss": 2.376301351428032, "actor_loss": -93.10785574340821, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.083033084869385, "step": 73000}
{"episode_reward": 894.7485163242111, "episode": 74.0, "batch_reward": 0.8245920584201812, "critic_loss": 2.8122007714509962, "actor_loss": -92.98315762329102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.0535089969635, "step": 74000}
{"episode_reward": 910.9862608813256, "episode": 75.0, "batch_reward": 0.8270382646918297, "critic_loss": 2.8046191185116767, "actor_loss": -93.2971346282959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.02987265586853, "step": 75000}
{"episode_reward": 915.0810251751948, "episode": 76.0, "batch_reward": 0.8268054676651955, "critic_loss": 4.2522539742589, "actor_loss": -93.17889111328125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.97272539138794, "step": 76000}
{"episode_reward": 940.3107483657675, "episode": 77.0, "batch_reward": 0.8288249896764756, "critic_loss": 5.2125535788536075, "actor_loss": -93.18300610351562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.998311519622803, "step": 77000}
{"episode_reward": 841.4869251140191, "episode": 78.0, "batch_reward": 0.8284883543848991, "critic_loss": 4.617403507232666, "actor_loss": -93.07250289916992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.97854781150818, "step": 78000}
{"episode_reward": 917.1978508758825, "episode": 79.0, "batch_reward": 0.8287007714509964, "critic_loss": 5.179921154618263, "actor_loss": -93.30786618041992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.96400213241577, "step": 79000}
{"episode_reward": 904.3610922141714, "episode": 80.0, "batch_reward": 0.8258250198364258, "critic_loss": 8.196140243887902, "actor_loss": -93.79825143432618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.55830669403076, "step": 80000}
{"episode_reward": 62.33269693378467, "episode": 81.0, "batch_reward": 0.8198371186852456, "critic_loss": 8.505396138906478, "actor_loss": -94.10784138488769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.49206733703613, "step": 81000}
{"episode_reward": 821.903984449512, "episode": 82.0, "batch_reward": 0.8193045795559883, "critic_loss": 10.881770829916, "actor_loss": -94.45697987365723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.11241841316223, "step": 82000}
{"episode_reward": 421.10431304166684, "episode": 83.0, "batch_reward": 0.8149362472891808, "critic_loss": 11.402062092781067, "actor_loss": -94.72851832580567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.128475427627563, "step": 83000}
{"episode_reward": 681.7353559370862, "episode": 84.0, "batch_reward": 0.8121623989939689, "critic_loss": 12.166494126081467, "actor_loss": -94.77271910095214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.13024401664734, "step": 84000}
{"episode_reward": 331.5089336736501, "episode": 85.0, "batch_reward": 0.8036139715909958, "critic_loss": 12.519164971113206, "actor_loss": -95.28955401611329, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.096899032592773, "step": 85000}
{"episode_reward": 65.44107673436763, "episode": 86.0, "batch_reward": 0.7998898009061813, "critic_loss": 13.210598743915558, "actor_loss": -95.88845869445801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.103447675704956, "step": 86000}
{"episode_reward": 825.3626073739641, "episode": 87.0, "batch_reward": 0.795534403026104, "critic_loss": 18.278342140436173, "actor_loss": -95.86206825256347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.07394242286682, "step": 87000}
{"episode_reward": 70.9332775175437, "episode": 88.0, "batch_reward": 0.7872218108177185, "critic_loss": 20.46317966604233, "actor_loss": -97.10485215759277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.111122846603394, "step": 88000}
{"episode_reward": 63.8977649075759, "episode": 89.0, "batch_reward": 0.7793937993645668, "critic_loss": 28.24219990539551, "actor_loss": -100.33034693908691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.07386088371277, "step": 89000}
{"episode_reward": 63.63363946109148, "episode": 90.0, "batch_reward": 0.7719195707440376, "critic_loss": 41.69119035720825, "actor_loss": -103.90019023132324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.14160704612732, "step": 90000}
{"episode_reward": 107.74177588376489, "episode": 91.0, "batch_reward": 0.7649121899008751, "critic_loss": 72.52477295303345, "actor_loss": -109.32128450012208, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.6155731678009, "step": 91000}
{"episode_reward": 63.00977954239018, "episode": 92.0, "batch_reward": 0.7567558977007866, "critic_loss": 141.17228324127197, "actor_loss": -115.30292852783204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.126607179641724, "step": 92000}
{"episode_reward": 91.33097234191995, "episode": 93.0, "batch_reward": 0.7510996621847152, "critic_loss": 240.65032209777831, "actor_loss": -120.56516018676759, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.134676694869995, "step": 93000}
{"episode_reward": 88.65992337931985, "episode": 94.0, "batch_reward": 0.7422367436289787, "critic_loss": 356.36003091430666, "actor_loss": -131.3813447570801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.06584072113037, "step": 94000}
{"episode_reward": 72.22335550837677, "episode": 95.0, "batch_reward": 0.7371206462979317, "critic_loss": 446.2063411712646, "actor_loss": -142.71071868896485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.11352801322937, "step": 95000}
{"episode_reward": 62.00692290492477, "episode": 96.0, "batch_reward": 0.7268139790296555, "critic_loss": 515.5030344848633, "actor_loss": -159.58484802246093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.074290990829468, "step": 96000}
{"episode_reward": 91.61654382181504, "episode": 97.0, "batch_reward": 0.7215341477394104, "critic_loss": 524.1861699829102, "actor_loss": -164.41854359436036, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.075717449188232, "step": 97000}
{"episode_reward": 149.52200757283254, "episode": 98.0, "batch_reward": 0.7167147693634033, "critic_loss": 519.5720618286133, "actor_loss": -169.1772490234375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.99979519844055, "step": 98000}
{"episode_reward": 106.33098290811581, "episode": 99.0, "batch_reward": 0.7088164151906967, "critic_loss": 511.22657342529294, "actor_loss": -178.22200007629394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.09376883506775, "step": 99000}
{"episode_reward": 24.102433626234347, "episode": 100.0, "batch_reward": 0.7044224681854248, "critic_loss": 497.03198875427245, "actor_loss": -168.87533721923828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.100213050842285, "step": 100000}
{"episode_reward": 343.6917637521977, "episode": 101.0, "batch_reward": 0.702306254684925, "critic_loss": 495.00531521606445, "actor_loss": -173.57382022094725, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.661423683166504, "step": 101000}
{"episode_reward": 693.5853587940824, "episode": 102.0, "batch_reward": 0.6998164122700691, "critic_loss": 460.60965003967283, "actor_loss": -165.06942971801757, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.087061166763306, "step": 102000}
{"episode_reward": 616.2237930262062, "episode": 103.0, "batch_reward": 0.7017258613705635, "critic_loss": 415.9843285827637, "actor_loss": -190.0178851776123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.28890562057495, "step": 103000}
{"episode_reward": 725.8298503712784, "episode": 104.0, "batch_reward": 0.7028054694533348, "critic_loss": 344.19111421203615, "actor_loss": -176.5109168548584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.32257080078125, "step": 104000}
{"episode_reward": 792.1895384943573, "episode": 105.0, "batch_reward": 0.7028367286920547, "critic_loss": 295.1091207046509, "actor_loss": -182.6976227416992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.01355528831482, "step": 105000}
{"episode_reward": 872.567856818213, "episode": 106.0, "batch_reward": 0.7063059258460999, "critic_loss": 245.1417802963257, "actor_loss": -162.73211593627929, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.97989845275879, "step": 106000}
{"episode_reward": 908.0323304509678, "episode": 107.0, "batch_reward": 0.7058962320685387, "critic_loss": 209.62746537017821, "actor_loss": -162.0895202484131, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.995137929916382, "step": 107000}
{"episode_reward": 785.6838204416002, "episode": 108.0, "batch_reward": 0.708400231540203, "critic_loss": 176.42264383697508, "actor_loss": -176.55729455566407, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.96598243713379, "step": 108000}
{"episode_reward": 849.7604936780663, "episode": 109.0, "batch_reward": 0.7079324950575828, "critic_loss": 151.00976070785524, "actor_loss": -163.59740074157716, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.980355262756348, "step": 109000}
{"episode_reward": 875.5768092396635, "episode": 110.0, "batch_reward": 0.7093449992537498, "critic_loss": 123.98815128326416, "actor_loss": -166.2494760131836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.989063024520874, "step": 110000}
{"episode_reward": 817.7064986653218, "episode": 111.0, "batch_reward": 0.7112351856827736, "critic_loss": 109.64942708206176, "actor_loss": -168.99521813964844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 42.81586480140686, "step": 111000}
{"episode_reward": 837.7239757137605, "episode": 112.0, "batch_reward": 0.7136858993768692, "critic_loss": 87.66661670303344, "actor_loss": -157.85274647521973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.105522871017456, "step": 112000}
{"episode_reward": 898.6581995019416, "episode": 113.0, "batch_reward": 0.7146638167500496, "critic_loss": 69.36798214149475, "actor_loss": -152.51905989074706, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.10881996154785, "step": 113000}
{"episode_reward": 884.0888400605616, "episode": 114.0, "batch_reward": 0.7154331920146942, "critic_loss": 59.02989479827881, "actor_loss": -148.5429836730957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.14369487762451, "step": 114000}
{"episode_reward": 901.5224406376449, "episode": 115.0, "batch_reward": 0.7175812686085701, "critic_loss": 47.395204427719115, "actor_loss": -155.3975987548828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.099794387817383, "step": 115000}
{"episode_reward": 857.9912247434391, "episode": 116.0, "batch_reward": 0.7156786813139916, "critic_loss": 38.24026378917694, "actor_loss": -148.6466043395996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.120482444763184, "step": 116000}
{"episode_reward": 45.194999397981164, "episode": 117.0, "batch_reward": 0.7130277101993561, "critic_loss": 31.421551392555237, "actor_loss": -157.65537644958496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.116907119750977, "step": 117000}
{"episode_reward": 890.827342437768, "episode": 118.0, "batch_reward": 0.7127664148807525, "critic_loss": 26.247656713485718, "actor_loss": -148.6362617492676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.10291886329651, "step": 118000}
{"episode_reward": 944.8611745499393, "episode": 119.0, "batch_reward": 0.7152822680473327, "critic_loss": 21.742967324733733, "actor_loss": -145.37446963500977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.083184480667114, "step": 119000}
{"episode_reward": 796.3228570522468, "episode": 120.0, "batch_reward": 0.7150651680231095, "critic_loss": 18.7768525724411, "actor_loss": -143.32471229553224, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.112220525741577, "step": 120000}
{"episode_reward": 403.4220412207344, "episode": 121.0, "batch_reward": 0.7143181096911431, "critic_loss": 15.388469501018523, "actor_loss": -140.60092510986328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.68750309944153, "step": 121000}
{"episode_reward": 901.7045283999005, "episode": 122.0, "batch_reward": 0.714224633038044, "critic_loss": 13.180684150218964, "actor_loss": -132.39373997497557, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.07722544670105, "step": 122000}
{"episode_reward": 889.9251252153995, "episode": 123.0, "batch_reward": 0.7178924936056137, "critic_loss": 11.260564574241638, "actor_loss": -127.11913830566407, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.07294011116028, "step": 123000}
{"episode_reward": 917.8607076797689, "episode": 124.0, "batch_reward": 0.7190001010894775, "critic_loss": 9.682955423593521, "actor_loss": -126.9233131866455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.150638341903687, "step": 124000}
{"episode_reward": 882.7662794022738, "episode": 125.0, "batch_reward": 0.7196792340874671, "critic_loss": 8.154858236074448, "actor_loss": -126.57462948608398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.07646083831787, "step": 125000}
{"episode_reward": 915.1422193174765, "episode": 126.0, "batch_reward": 0.7232198104858398, "critic_loss": 7.087362573623658, "actor_loss": -128.6897816467285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.06974172592163, "step": 126000}
{"episode_reward": 908.4304271551198, "episode": 127.0, "batch_reward": 0.7226243357658386, "critic_loss": 6.656317696094513, "actor_loss": -128.87925190734865, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.10522699356079, "step": 127000}
{"episode_reward": 935.4736618268261, "episode": 128.0, "batch_reward": 0.7249109761714936, "critic_loss": 5.633718375682831, "actor_loss": -125.85605575561523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.027838468551636, "step": 128000}
{"episode_reward": 898.3959934499629, "episode": 129.0, "batch_reward": 0.7242014235854148, "critic_loss": 5.105049393177032, "actor_loss": -122.01602864074707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.094629764556885, "step": 129000}
{"episode_reward": 949.0533598107679, "episode": 130.0, "batch_reward": 0.7280750280022621, "critic_loss": 4.7411467260122295, "actor_loss": -123.32723126220704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.021793842315674, "step": 130000}
{"episode_reward": 902.7350867603051, "episode": 131.0, "batch_reward": 0.7295982970595359, "critic_loss": 4.176727477908134, "actor_loss": -118.28137872314453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.70489239692688, "step": 131000}
{"episode_reward": 904.3176764607982, "episode": 132.0, "batch_reward": 0.7315278014540673, "critic_loss": 4.115931670308113, "actor_loss": -114.44102388000488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.059648990631104, "step": 132000}
{"episode_reward": 878.544078638336, "episode": 133.0, "batch_reward": 0.7310191177725792, "critic_loss": 3.729513462781906, "actor_loss": -115.42306979370117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.086044549942017, "step": 133000}
{"episode_reward": 953.7201851763195, "episode": 134.0, "batch_reward": 0.733683325946331, "critic_loss": 3.306277254462242, "actor_loss": -116.50456121826171, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.085312366485596, "step": 134000}
{"episode_reward": 859.9124046703556, "episode": 135.0, "batch_reward": 0.7323007302284241, "critic_loss": 3.3267795040607453, "actor_loss": -116.32093382263183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.046011686325073, "step": 135000}
{"episode_reward": 880.4544771085298, "episode": 136.0, "batch_reward": 0.7363754351139069, "critic_loss": 2.9508226915597917, "actor_loss": -117.13921566772461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.065621614456177, "step": 136000}
{"episode_reward": 916.5983044628074, "episode": 137.0, "batch_reward": 0.7373293268084526, "critic_loss": 3.0244258012771605, "actor_loss": -110.09722055053712, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.02278709411621, "step": 137000}
{"episode_reward": 943.9876990702996, "episode": 138.0, "batch_reward": 0.7394716273546219, "critic_loss": 2.6163193366527557, "actor_loss": -110.9666692199707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.017741680145264, "step": 138000}
{"episode_reward": 956.904563857885, "episode": 139.0, "batch_reward": 0.7401084803342819, "critic_loss": 2.7139095343351363, "actor_loss": -111.14905676269531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.984633207321167, "step": 139000}
{"episode_reward": 944.0833615051774, "episode": 140.0, "batch_reward": 0.7426583110690117, "critic_loss": 2.583019324541092, "actor_loss": -110.39292346191407, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.979520797729492, "step": 140000}
{"episode_reward": 913.5814734029914, "episode": 141.0, "batch_reward": 0.7414938578605652, "critic_loss": 2.546794419884682, "actor_loss": -107.66381587219239, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.51305270195007, "step": 141000}
{"episode_reward": 901.4963771047495, "episode": 142.0, "batch_reward": 0.743501023709774, "critic_loss": 2.414732429265976, "actor_loss": -111.3860513305664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.919533729553223, "step": 142000}
{"episode_reward": 936.0050715853421, "episode": 143.0, "batch_reward": 0.7443376673460007, "critic_loss": 2.3210226820111273, "actor_loss": -109.26605625915528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.29302406311035, "step": 143000}
{"episode_reward": 934.960200543807, "episode": 144.0, "batch_reward": 0.746144640982151, "critic_loss": 2.2179073646664618, "actor_loss": -106.78390191650391, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.1356201171875, "step": 144000}
{"episode_reward": 903.3016973986994, "episode": 145.0, "batch_reward": 0.7462868204116822, "critic_loss": 2.078526491343975, "actor_loss": -104.28354742431641, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.124124765396118, "step": 145000}
{"episode_reward": 890.1402214639556, "episode": 146.0, "batch_reward": 0.7461436209082604, "critic_loss": 2.0944170863628386, "actor_loss": -104.20459036254883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.146398782730103, "step": 146000}
{"episode_reward": 62.86983803796747, "episode": 147.0, "batch_reward": 0.7417224583029747, "critic_loss": 2.07452200704813, "actor_loss": -105.0506288909912, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.096146821975708, "step": 147000}
{"episode_reward": 780.1748739010666, "episode": 148.0, "batch_reward": 0.7429062163829804, "critic_loss": 2.043089930057526, "actor_loss": -102.38519447326661, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.09667158126831, "step": 148000}
{"episode_reward": 893.6949585597762, "episode": 149.0, "batch_reward": 0.743759572982788, "critic_loss": 2.0361309809684753, "actor_loss": -104.15270472717285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.136925220489502, "step": 149000}
{"episode_reward": 934.089238962456, "episode": 150.0, "batch_reward": 0.7451819415688514, "critic_loss": 1.9705584365129472, "actor_loss": -101.62288186645507, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
