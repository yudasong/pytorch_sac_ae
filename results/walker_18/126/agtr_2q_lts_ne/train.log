{"episode_reward": 0.0, "episode": 1.0, "duration": 36.358710050582886, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 3.351790428161621, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.470870152935659, "critic_loss": 0.13377739526964935, "actor_loss": -82.23751434778013, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 95.7137668132782, "step": 3000}
{"episode_reward": 639.024087197173, "episode": 4.0, "batch_reward": 0.5259123770594597, "critic_loss": 0.3845357889980078, "actor_loss": -84.46278695678711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.03466296195984, "step": 4000}
{"episode_reward": 563.0141220121153, "episode": 5.0, "batch_reward": 0.5423505131006241, "critic_loss": 0.5019996874779463, "actor_loss": -85.49658470153808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.44670343399048, "step": 5000}
{"episode_reward": 672.7954943843727, "episode": 6.0, "batch_reward": 0.5648949238657951, "critic_loss": 0.7213861482441425, "actor_loss": -86.4575811920166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.62814998626709, "step": 6000}
{"episode_reward": 632.4900975943248, "episode": 7.0, "batch_reward": 0.5844573077261448, "critic_loss": 0.8947063819169998, "actor_loss": -87.54665580749511, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.189556121826172, "step": 7000}
{"episode_reward": 778.3628400802532, "episode": 8.0, "batch_reward": 0.617352900505066, "critic_loss": 0.863361320912838, "actor_loss": -88.81513262939453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.850361824035645, "step": 8000}
{"episode_reward": 849.0584815013598, "episode": 9.0, "batch_reward": 0.6419685400724411, "critic_loss": 0.7914413161575794, "actor_loss": -89.66852801513672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.84049153327942, "step": 9000}
{"episode_reward": 841.5627097890581, "episode": 10.0, "batch_reward": 0.6690614849328995, "critic_loss": 0.7588961975574493, "actor_loss": -90.27359075927734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.171908378601074, "step": 10000}
{"episode_reward": 891.6546108098698, "episode": 11.0, "batch_reward": 0.6813436549305916, "critic_loss": 0.8203140529990196, "actor_loss": -90.52188323974609, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.8730776309967, "step": 11000}
{"episode_reward": 783.5678521397408, "episode": 12.0, "batch_reward": 0.6877208049297333, "critic_loss": 0.8160669223964214, "actor_loss": -90.51432182312011, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.66634488105774, "step": 12000}
{"episode_reward": 653.1868094793701, "episode": 13.0, "batch_reward": 0.6899996789693832, "critic_loss": 0.6679836821258068, "actor_loss": -90.46142602539062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.733586072921753, "step": 13000}
{"episode_reward": 839.7987592041015, "episode": 14.0, "batch_reward": 0.702977425813675, "critic_loss": 0.5930367912650109, "actor_loss": -90.58227920532227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.0779550075531, "step": 14000}
{"episode_reward": 839.6630678668095, "episode": 15.0, "batch_reward": 0.7052041243910789, "critic_loss": 0.6022533548176289, "actor_loss": -90.60492185974121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.48723340034485, "step": 15000}
{"episode_reward": 756.8058242825673, "episode": 16.0, "batch_reward": 0.7189445563554764, "critic_loss": 0.5274785878956318, "actor_loss": -90.59930908203125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.253418684005737, "step": 16000}
{"episode_reward": 941.5953231757647, "episode": 17.0, "batch_reward": 0.7125529508590698, "critic_loss": 0.5078832051306963, "actor_loss": -90.49946301269532, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.363913774490356, "step": 17000}
{"episode_reward": 182.5401838312724, "episode": 18.0, "batch_reward": 0.6935501039624214, "critic_loss": 0.5230008231699467, "actor_loss": -89.9207113494873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.346044063568115, "step": 18000}
{"episode_reward": 825.2849977011456, "episode": 19.0, "batch_reward": 0.7056809511184693, "critic_loss": 0.5308071831464768, "actor_loss": -90.02274188232421, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.75585126876831, "step": 19000}
{"episode_reward": 880.3010193005894, "episode": 20.0, "batch_reward": 0.7127105366587639, "critic_loss": 0.5485535989701747, "actor_loss": -90.22274249267578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.08891010284424, "step": 20000}
{"episode_reward": 853.5300071629132, "episode": 21.0, "batch_reward": 0.7218459122776986, "critic_loss": 0.5515521769821644, "actor_loss": -90.14731723022462, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.87293481826782, "step": 21000}
{"episode_reward": 877.0323942315663, "episode": 22.0, "batch_reward": 0.7239835264086724, "critic_loss": 0.5490741905122996, "actor_loss": -90.20601329040527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.397805213928223, "step": 22000}
{"episode_reward": 785.9763920488825, "episode": 23.0, "batch_reward": 0.7296747523546219, "critic_loss": 0.5674375271797181, "actor_loss": -90.23901829528809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.690765142440796, "step": 23000}
{"episode_reward": 856.1946028957057, "episode": 24.0, "batch_reward": 0.7216807742714881, "critic_loss": 0.5570148157775402, "actor_loss": -89.93005545043945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.475274085998535, "step": 24000}
{"episode_reward": 384.1195167858548, "episode": 25.0, "batch_reward": 0.7225988215208053, "critic_loss": 0.5224125973284245, "actor_loss": -89.91263763427735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.20889163017273, "step": 25000}
{"episode_reward": 899.7149096597431, "episode": 26.0, "batch_reward": 0.73057116574049, "critic_loss": 0.5446277934014797, "actor_loss": -89.93918690490723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.64001202583313, "step": 26000}
{"episode_reward": 926.6218860507149, "episode": 27.0, "batch_reward": 0.7373230349421501, "critic_loss": 0.536070298820734, "actor_loss": -90.32782702636719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.77673888206482, "step": 27000}
{"episode_reward": 913.7771186309834, "episode": 28.0, "batch_reward": 0.7408742036819458, "critic_loss": 0.4937887389659882, "actor_loss": -90.15921923828125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.4109468460083, "step": 28000}
{"episode_reward": 916.9599122651252, "episode": 29.0, "batch_reward": 0.7506218274235725, "critic_loss": 0.48823082248866556, "actor_loss": -90.59613922119141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.861565828323364, "step": 29000}
{"episode_reward": 963.0221519344421, "episode": 30.0, "batch_reward": 0.7548724672794342, "critic_loss": 0.47787188094854355, "actor_loss": -90.755787109375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.41822576522827, "step": 30000}
{"episode_reward": 896.0510083169158, "episode": 31.0, "batch_reward": 0.760964094877243, "critic_loss": 0.43443508304655554, "actor_loss": -90.67564779663086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.91284942626953, "step": 31000}
{"episode_reward": 916.8108137830322, "episode": 32.0, "batch_reward": 0.7648252973556519, "critic_loss": 0.4494392332136631, "actor_loss": -90.80641036987305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.011112451553345, "step": 32000}
{"episode_reward": 897.3122104826662, "episode": 33.0, "batch_reward": 0.7692916899323463, "critic_loss": 0.4517218895703554, "actor_loss": -91.13883277893066, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.400538682937622, "step": 33000}
{"episode_reward": 876.567346597755, "episode": 34.0, "batch_reward": 0.7709808368682861, "critic_loss": 0.4602205251902342, "actor_loss": -91.00388290405273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.63852882385254, "step": 34000}
{"episode_reward": 851.7085898784999, "episode": 35.0, "batch_reward": 0.7740751997828483, "critic_loss": 0.49960666662454606, "actor_loss": -91.04073649597169, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.05728268623352, "step": 35000}
{"episode_reward": 826.0712501449049, "episode": 36.0, "batch_reward": 0.7751414085626602, "critic_loss": 0.48209223040938376, "actor_loss": -90.9764243927002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.85201668739319, "step": 36000}
{"episode_reward": 865.2733383703896, "episode": 37.0, "batch_reward": 0.779118078827858, "critic_loss": 0.4786827480196953, "actor_loss": -91.20227209472657, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.47602915763855, "step": 37000}
{"episode_reward": 920.8221525536188, "episode": 38.0, "batch_reward": 0.7830626084804535, "critic_loss": 0.47016860365867613, "actor_loss": -91.47451161193848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.428343296051025, "step": 38000}
{"episode_reward": 951.6157556089468, "episode": 39.0, "batch_reward": 0.7882495844960212, "critic_loss": 0.46698840892314913, "actor_loss": -91.49199847412109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.721176862716675, "step": 39000}
{"episode_reward": 945.7149949089792, "episode": 40.0, "batch_reward": 0.7896225590109825, "critic_loss": 0.4375984874665737, "actor_loss": -91.49520434570313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.00337839126587, "step": 40000}
{"episode_reward": 935.7793950106995, "episode": 41.0, "batch_reward": 0.794967001259327, "critic_loss": 0.44809572032094, "actor_loss": -91.6006926727295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.29169011116028, "step": 41000}
{"episode_reward": 944.3974623413849, "episode": 42.0, "batch_reward": 0.7981688633561135, "critic_loss": 0.4384992485195398, "actor_loss": -91.88253790283203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.214600324630737, "step": 42000}
{"episode_reward": 932.2975461464672, "episode": 43.0, "batch_reward": 0.8038162760138512, "critic_loss": 0.41544843359291556, "actor_loss": -92.02277807617187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.761852502822876, "step": 43000}
{"episode_reward": 950.4922371254486, "episode": 44.0, "batch_reward": 0.8059305317401886, "critic_loss": 0.4114316993206739, "actor_loss": -92.1838349761963, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.67279553413391, "step": 44000}
{"episode_reward": 864.5278845023034, "episode": 45.0, "batch_reward": 0.8052972283363342, "critic_loss": 0.41909330397844313, "actor_loss": -92.27950959777831, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.22973918914795, "step": 45000}
{"episode_reward": 897.8149448043981, "episode": 46.0, "batch_reward": 0.8091636929512024, "critic_loss": 0.4063532360196114, "actor_loss": -92.24538987731934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.055478811264038, "step": 46000}
{"episode_reward": 904.6650437337332, "episode": 47.0, "batch_reward": 0.8106164932847023, "critic_loss": 0.42361903277039525, "actor_loss": -92.24667863464356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.20755648612976, "step": 47000}
{"episode_reward": 925.3559360790817, "episode": 48.0, "batch_reward": 0.8126489633321762, "critic_loss": 0.4300871183127165, "actor_loss": -92.35323724365234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.36786913871765, "step": 48000}
{"episode_reward": 891.2453643896629, "episode": 49.0, "batch_reward": 0.8156400368213653, "critic_loss": 0.4233330223560333, "actor_loss": -92.44214291381836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.4884250164032, "step": 49000}
{"episode_reward": 953.2191738417941, "episode": 50.0, "batch_reward": 0.8175252711772919, "critic_loss": 0.4096723026037216, "actor_loss": -92.56093051147461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.113131046295166, "step": 50000}
{"episode_reward": 899.31526794435, "episode": 51.0, "batch_reward": 0.8194330303668976, "critic_loss": 0.4151046092510223, "actor_loss": -92.79061909484864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.90989112854004, "step": 51000}
{"episode_reward": 954.3443358103333, "episode": 52.0, "batch_reward": 0.8218620232343674, "critic_loss": 0.39863280521333216, "actor_loss": -92.58851766967773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.96858286857605, "step": 52000}
{"episode_reward": 946.0747442817525, "episode": 53.0, "batch_reward": 0.8245395159125328, "critic_loss": 0.4062877413481474, "actor_loss": -92.93728269958496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.510743856430054, "step": 53000}
{"episode_reward": 938.4693758703237, "episode": 54.0, "batch_reward": 0.8280592623949051, "critic_loss": 0.40138984885811807, "actor_loss": -92.81369505310059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.35079264640808, "step": 54000}
{"episode_reward": 924.3314378230306, "episode": 55.0, "batch_reward": 0.8278096472024917, "critic_loss": 0.3884986036866903, "actor_loss": -92.903072555542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.248010635375977, "step": 55000}
{"episode_reward": 918.1531651292527, "episode": 56.0, "batch_reward": 0.8304258569478988, "critic_loss": 0.3830684712827206, "actor_loss": -93.12333851623535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.484930992126465, "step": 56000}
{"episode_reward": 972.1813500347057, "episode": 57.0, "batch_reward": 0.8294400712251663, "critic_loss": 0.42282381980121136, "actor_loss": -93.07993804931641, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.63667917251587, "step": 57000}
{"episode_reward": 361.54459950376975, "episode": 58.0, "batch_reward": 0.82400360506773, "critic_loss": 0.4113685452491045, "actor_loss": -92.98451292419433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.995332956314087, "step": 58000}
{"episode_reward": 931.6333339772419, "episode": 59.0, "batch_reward": 0.8271649721264839, "critic_loss": 0.3904664406180382, "actor_loss": -93.0168563232422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.939363718032837, "step": 59000}
{"episode_reward": 954.6013164392609, "episode": 60.0, "batch_reward": 0.8279273880124092, "critic_loss": 0.40333886678516867, "actor_loss": -92.93411756896973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.58331274986267, "step": 60000}
{"episode_reward": 947.4594604081449, "episode": 61.0, "batch_reward": 0.8309494754076004, "critic_loss": 0.38271854442358016, "actor_loss": -93.05876348876953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.7500102519989, "step": 61000}
{"episode_reward": 885.8845544749274, "episode": 62.0, "batch_reward": 0.8288237172365188, "critic_loss": 0.39322018741071224, "actor_loss": -93.1400542755127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.452919244766235, "step": 62000}
{"episode_reward": 921.5822635694982, "episode": 63.0, "batch_reward": 0.8248873007297516, "critic_loss": 0.4148042249977589, "actor_loss": -92.97297721862793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.190221071243286, "step": 63000}
{"episode_reward": 82.00456150675288, "episode": 64.0, "batch_reward": 0.8201459844112396, "critic_loss": 0.3998020396977663, "actor_loss": -92.70148439025878, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.48385787010193, "step": 64000}
{"episode_reward": 881.3088302539106, "episode": 65.0, "batch_reward": 0.8226483716964722, "critic_loss": 0.4142367817759514, "actor_loss": -92.71113697814941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.708842039108276, "step": 65000}
{"episode_reward": 949.5751707742562, "episode": 66.0, "batch_reward": 0.8239588814377785, "critic_loss": 0.41135454253852366, "actor_loss": -92.7504326171875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.590646743774414, "step": 66000}
{"episode_reward": 952.8357910055759, "episode": 67.0, "batch_reward": 0.8247106582522392, "critic_loss": 0.4248864562511444, "actor_loss": -92.80531161499023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.316575288772583, "step": 67000}
{"episode_reward": 912.365979122495, "episode": 68.0, "batch_reward": 0.8270129916071892, "critic_loss": 0.4381783570945263, "actor_loss": -92.70079737854005, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.668795347213745, "step": 68000}
{"episode_reward": 938.2473710788174, "episode": 69.0, "batch_reward": 0.828958685040474, "critic_loss": 0.4222113022655249, "actor_loss": -92.76547389221192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.03942322731018, "step": 69000}
{"episode_reward": 953.5051156017544, "episode": 70.0, "batch_reward": 0.8287428390979766, "critic_loss": 0.4055499289035797, "actor_loss": -92.66153871154785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.124836206436157, "step": 70000}
{"episode_reward": 923.7460309278903, "episode": 71.0, "batch_reward": 0.8308928297758102, "critic_loss": 0.4306994544118643, "actor_loss": -92.77296997070313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.74354577064514, "step": 71000}
{"episode_reward": 944.4944377230435, "episode": 72.0, "batch_reward": 0.833535679936409, "critic_loss": 0.4232002087235451, "actor_loss": -92.79413871765136, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.033186197280884, "step": 72000}
{"episode_reward": 920.6387779796519, "episode": 73.0, "batch_reward": 0.8340255221128464, "critic_loss": 0.4132125595062971, "actor_loss": -92.80211651611329, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.33405327796936, "step": 73000}
{"episode_reward": 950.4585996703674, "episode": 74.0, "batch_reward": 0.8345838492512703, "critic_loss": 0.46327437122166154, "actor_loss": -92.7530498046875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.975127458572388, "step": 74000}
{"episode_reward": 804.1284458785437, "episode": 75.0, "batch_reward": 0.8356370661258697, "critic_loss": 0.4479922538548708, "actor_loss": -92.78195095825195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.854461431503296, "step": 75000}
{"episode_reward": 938.3323172106022, "episode": 76.0, "batch_reward": 0.8369218303561211, "critic_loss": 0.4368014457076788, "actor_loss": -92.70797950744628, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.18759322166443, "step": 76000}
{"episode_reward": 938.0488674632809, "episode": 77.0, "batch_reward": 0.8384284729957581, "critic_loss": 0.4479166427701712, "actor_loss": -92.83141288757324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.615018606185913, "step": 77000}
{"episode_reward": 925.955430420095, "episode": 78.0, "batch_reward": 0.8332781662344932, "critic_loss": 0.44674514372646806, "actor_loss": -92.74141404724121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.268688917160034, "step": 78000}
{"episode_reward": 352.5351940573486, "episode": 79.0, "batch_reward": 0.8307335773706436, "critic_loss": 0.4571440912038088, "actor_loss": -92.71017834472656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.706448793411255, "step": 79000}
{"episode_reward": 949.5024421689328, "episode": 80.0, "batch_reward": 0.8355210827589035, "critic_loss": 0.4334621558189392, "actor_loss": -92.94660610961914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.199141025543213, "step": 80000}
{"episode_reward": 929.4672136060018, "episode": 81.0, "batch_reward": 0.8362249218821526, "critic_loss": 0.43586552180349825, "actor_loss": -92.94091351318359, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.44003415107727, "step": 81000}
{"episode_reward": 933.0964058026343, "episode": 82.0, "batch_reward": 0.835599818110466, "critic_loss": 0.4131731200963259, "actor_loss": -93.01944760131836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.375641345977783, "step": 82000}
{"episode_reward": 919.1301312392326, "episode": 83.0, "batch_reward": 0.8375122321844101, "critic_loss": 0.3930371998250484, "actor_loss": -93.0107124786377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.33480954170227, "step": 83000}
{"episode_reward": 944.438554708468, "episode": 84.0, "batch_reward": 0.8384882971048355, "critic_loss": 0.432075375854969, "actor_loss": -93.09566801452637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.77512216567993, "step": 84000}
{"episode_reward": 915.2350681380278, "episode": 85.0, "batch_reward": 0.8408966925740242, "critic_loss": 0.42252858759462836, "actor_loss": -93.2656720275879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.443201303482056, "step": 85000}
{"episode_reward": 948.6151354334187, "episode": 86.0, "batch_reward": 0.8407617812752723, "critic_loss": 0.42857801930606365, "actor_loss": -93.16285229492188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.507554054260254, "step": 86000}
{"episode_reward": 963.3591447290426, "episode": 87.0, "batch_reward": 0.8370326797962189, "critic_loss": 0.4673866740614176, "actor_loss": -92.96264846801758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.235148906707764, "step": 87000}
{"episode_reward": 94.52933459749563, "episode": 88.0, "batch_reward": 0.8336711165904999, "critic_loss": 0.43832117050886155, "actor_loss": -92.74971575927735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.13628339767456, "step": 88000}
{"episode_reward": 965.1197179393127, "episode": 89.0, "batch_reward": 0.8362966837882996, "critic_loss": 0.43323384633660317, "actor_loss": -92.97187173461914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.0881564617157, "step": 89000}
{"episode_reward": 962.6335393543435, "episode": 90.0, "batch_reward": 0.8359955788254738, "critic_loss": 0.40883788870275023, "actor_loss": -92.85634800720214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 32.08356213569641, "step": 90000}
{"episode_reward": 959.8346354230576, "episode": 91.0, "batch_reward": 0.8399790278077126, "critic_loss": 0.4255830331146717, "actor_loss": -93.00010116577148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.32884216308594, "step": 91000}
{"episode_reward": 909.2349775141377, "episode": 92.0, "batch_reward": 0.8395042147636413, "critic_loss": 0.3929438290297985, "actor_loss": -92.99761656188964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.485215663909912, "step": 92000}
{"episode_reward": 971.5807027071849, "episode": 93.0, "batch_reward": 0.8414751706719399, "critic_loss": 0.40399104051291945, "actor_loss": -93.05670445251465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.17297625541687, "step": 93000}
{"episode_reward": 989.9958093398009, "episode": 94.0, "batch_reward": 0.8403327805995942, "critic_loss": 0.3922295728176832, "actor_loss": -92.97634783935547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.94821548461914, "step": 94000}
{"episode_reward": 912.1213000674323, "episode": 95.0, "batch_reward": 0.8437790104746818, "critic_loss": 0.4157332182973623, "actor_loss": -93.06943649291992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.336098670959473, "step": 95000}
{"episode_reward": 920.9153526167995, "episode": 96.0, "batch_reward": 0.8423283559679985, "critic_loss": 0.413068321198225, "actor_loss": -93.04163215637207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.80074429512024, "step": 96000}
{"episode_reward": 873.4246778088122, "episode": 97.0, "batch_reward": 0.8428662966489792, "critic_loss": 0.40130769383907317, "actor_loss": -93.04795542907715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.869900703430176, "step": 97000}
{"episode_reward": 950.2204891906255, "episode": 98.0, "batch_reward": 0.8447712638378143, "critic_loss": 0.41988466660678386, "actor_loss": -93.2120243988037, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.241127967834473, "step": 98000}
{"episode_reward": 915.9634270465367, "episode": 99.0, "batch_reward": 0.8464686583876609, "critic_loss": 0.4366737771034241, "actor_loss": -93.15760011291503, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.6869695186615, "step": 99000}
{"episode_reward": 909.8097486338794, "episode": 100.0, "batch_reward": 0.8457742199897766, "critic_loss": 0.43918120278418066, "actor_loss": -93.25668794250488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.438207387924194, "step": 100000}
{"episode_reward": 946.8692244617816, "episode": 101.0, "batch_reward": 0.8497482625246048, "critic_loss": 0.45745784021914004, "actor_loss": -93.44101460266113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.69403862953186, "step": 101000}
{"episode_reward": 951.9507235953024, "episode": 102.0, "batch_reward": 0.8490334749221802, "critic_loss": 0.49334253147244456, "actor_loss": -93.43756938171387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.379432201385498, "step": 102000}
{"episode_reward": 956.6696624380614, "episode": 103.0, "batch_reward": 0.8497773391604424, "critic_loss": 0.5048161614835263, "actor_loss": -93.58116075134278, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.215318202972412, "step": 103000}
{"episode_reward": 954.1381226189343, "episode": 104.0, "batch_reward": 0.8517698319554329, "critic_loss": 0.470724623054266, "actor_loss": -93.74884133911132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.551391124725342, "step": 104000}
{"episode_reward": 939.8067053436323, "episode": 105.0, "batch_reward": 0.850820137321949, "critic_loss": 0.4945983023792505, "actor_loss": -93.83511686706542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.99972915649414, "step": 105000}
{"episode_reward": 949.375426845294, "episode": 106.0, "batch_reward": 0.8530244560241699, "critic_loss": 0.4749870255589485, "actor_loss": -93.99729301452636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.896753787994385, "step": 106000}
{"episode_reward": 921.5106576574757, "episode": 107.0, "batch_reward": 0.8535716160535812, "critic_loss": 0.4741386577039957, "actor_loss": -94.05765933227539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.774165630340576, "step": 107000}
{"episode_reward": 905.0676788572061, "episode": 108.0, "batch_reward": 0.8514896644949913, "critic_loss": 0.48436917892098424, "actor_loss": -94.095958694458, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.70666193962097, "step": 108000}
{"episode_reward": 917.9871516199676, "episode": 109.0, "batch_reward": 0.85285098695755, "critic_loss": 0.4619076780080795, "actor_loss": -94.10928659057618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.53795623779297, "step": 109000}
{"episode_reward": 966.1398132172818, "episode": 110.0, "batch_reward": 0.8552562634944916, "critic_loss": 0.4399470839202404, "actor_loss": -94.14303303527832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.364800214767456, "step": 110000}
{"episode_reward": 890.397698786245, "episode": 111.0, "batch_reward": 0.8549275152087211, "critic_loss": 0.41204542700201274, "actor_loss": -94.16829525756836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.98055458068848, "step": 111000}
{"episode_reward": 929.1109595188799, "episode": 112.0, "batch_reward": 0.8570664473176003, "critic_loss": 0.4044984017163515, "actor_loss": -94.13122662353516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.43382740020752, "step": 112000}
{"episode_reward": 934.3732914469684, "episode": 113.0, "batch_reward": 0.8585036277770997, "critic_loss": 0.3873468305468559, "actor_loss": -94.14626316833495, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.780534505844116, "step": 113000}
{"episode_reward": 950.9384382088383, "episode": 114.0, "batch_reward": 0.8561704884171486, "critic_loss": 0.43656854882836343, "actor_loss": -93.98879086303711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.961809396743774, "step": 114000}
{"episode_reward": 918.5387153642383, "episode": 115.0, "batch_reward": 0.8581983954906464, "critic_loss": 0.4260071091800928, "actor_loss": -94.00668884277344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.77496862411499, "step": 115000}
{"episode_reward": 958.1934402820104, "episode": 116.0, "batch_reward": 0.8600732268691063, "critic_loss": 0.41274234399199483, "actor_loss": -94.06053286743165, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.60619044303894, "step": 116000}
{"episode_reward": 938.3801719044335, "episode": 117.0, "batch_reward": 0.8594417099356652, "critic_loss": 0.40913594084978105, "actor_loss": -94.07956803894044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.12845754623413, "step": 117000}
{"episode_reward": 914.412808109451, "episode": 118.0, "batch_reward": 0.8591422381997108, "critic_loss": 0.4113975325524807, "actor_loss": -93.98408058166504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.71461582183838, "step": 118000}
{"episode_reward": 959.8185957667636, "episode": 119.0, "batch_reward": 0.8613586255311966, "critic_loss": 0.38362401707470417, "actor_loss": -93.98356401062011, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.284871816635132, "step": 119000}
{"episode_reward": 958.6555295348645, "episode": 120.0, "batch_reward": 0.8613912253379822, "critic_loss": 0.38605142161250117, "actor_loss": -94.03357701110839, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.34827709197998, "step": 120000}
{"episode_reward": 944.4389473521456, "episode": 121.0, "batch_reward": 0.862775912642479, "critic_loss": 0.3867124006152153, "actor_loss": -94.05442323303222, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.685861825943, "step": 121000}
{"episode_reward": 958.494911259987, "episode": 122.0, "batch_reward": 0.8630692309737206, "critic_loss": 0.39673435513675215, "actor_loss": -94.01578453063965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.04588031768799, "step": 122000}
{"episode_reward": 912.4972465359663, "episode": 123.0, "batch_reward": 0.8644458246827126, "critic_loss": 0.3763657703250647, "actor_loss": -94.0214914855957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.714173793792725, "step": 123000}
{"episode_reward": 972.1464688824444, "episode": 124.0, "batch_reward": 0.8654709510803222, "critic_loss": 0.3969878806620836, "actor_loss": -94.03952229309083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.561962366104126, "step": 124000}
{"episode_reward": 953.3507278127103, "episode": 125.0, "batch_reward": 0.8656343505978584, "critic_loss": 0.42733266852796076, "actor_loss": -94.15741429138184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.539809465408325, "step": 125000}
{"episode_reward": 938.9655830267227, "episode": 126.0, "batch_reward": 0.8668847724199295, "critic_loss": 0.3784599207937717, "actor_loss": -94.16996894836426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.932983875274658, "step": 126000}
{"episode_reward": 933.9618399856796, "episode": 127.0, "batch_reward": 0.8652736785411834, "critic_loss": 0.3708546585813165, "actor_loss": -93.94138082885742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.518198251724243, "step": 127000}
{"episode_reward": 941.827786504955, "episode": 128.0, "batch_reward": 0.8669128834605216, "critic_loss": 0.3909471580535173, "actor_loss": -94.06891798400879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.211673736572266, "step": 128000}
{"episode_reward": 953.998880890772, "episode": 129.0, "batch_reward": 0.8666221626996994, "critic_loss": 0.38416770623624324, "actor_loss": -94.05485514831543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.549785614013672, "step": 129000}
{"episode_reward": 984.5312125832278, "episode": 130.0, "batch_reward": 0.8699367300868034, "critic_loss": 0.3738764146119356, "actor_loss": -94.18415867614746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.569628477096558, "step": 130000}
{"episode_reward": 935.4153795356066, "episode": 131.0, "batch_reward": 0.8695238192081451, "critic_loss": 0.35083426563441755, "actor_loss": -94.13198503112793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.35197067260742, "step": 131000}
{"episode_reward": 939.5560805075901, "episode": 132.0, "batch_reward": 0.8687914439439773, "critic_loss": 0.35790055329352616, "actor_loss": -94.13258956909179, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.13954782485962, "step": 132000}
{"episode_reward": 924.5200067110778, "episode": 133.0, "batch_reward": 0.8704245969653129, "critic_loss": 0.3669519419074059, "actor_loss": -94.26499333190918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.178614377975464, "step": 133000}
{"episode_reward": 964.6649653398122, "episode": 134.0, "batch_reward": 0.8699460676312447, "critic_loss": 0.3594531211107969, "actor_loss": -94.21100382995606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.0498788356781, "step": 134000}
{"episode_reward": 945.0573218931296, "episode": 135.0, "batch_reward": 0.8710790634155273, "critic_loss": 0.38542225056886675, "actor_loss": -94.1736364440918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.56693172454834, "step": 135000}
{"episode_reward": 915.489661982666, "episode": 136.0, "batch_reward": 0.8725191599130631, "critic_loss": 0.36557349865883587, "actor_loss": -94.32420378112793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.66809916496277, "step": 136000}
{"episode_reward": 925.1582701932606, "episode": 137.0, "batch_reward": 0.8709203254580498, "critic_loss": 0.3716790885105729, "actor_loss": -94.24903523254395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.817785501480103, "step": 137000}
{"episode_reward": 938.4858699388428, "episode": 138.0, "batch_reward": 0.8733607360124588, "critic_loss": 0.3815356507897377, "actor_loss": -94.29799209594727, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.72650456428528, "step": 138000}
{"episode_reward": 965.0734334949673, "episode": 139.0, "batch_reward": 0.872882055580616, "critic_loss": 0.3703866599500179, "actor_loss": -94.34946997070313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.29559087753296, "step": 139000}
{"episode_reward": 898.5153917807673, "episode": 140.0, "batch_reward": 0.8743540714383126, "critic_loss": 0.3476792395189405, "actor_loss": -94.35555015563965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.169944286346436, "step": 140000}
{"episode_reward": 934.4805889077172, "episode": 141.0, "batch_reward": 0.8734729690551758, "critic_loss": 0.3556755399182439, "actor_loss": -94.35722357177734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 65.5599935054779, "step": 141000}
{"episode_reward": 925.5903161651548, "episode": 142.0, "batch_reward": 0.8742138817310333, "critic_loss": 0.3389298634901643, "actor_loss": -94.41304457092285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.180174589157104, "step": 142000}
{"episode_reward": 929.0117971102379, "episode": 143.0, "batch_reward": 0.8746255220770836, "critic_loss": 0.3365238663479686, "actor_loss": -94.424333984375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.07866597175598, "step": 143000}
{"episode_reward": 929.400400231113, "episode": 144.0, "batch_reward": 0.8745276932120323, "critic_loss": 0.33800429294258355, "actor_loss": -94.41959886169434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.07056999206543, "step": 144000}
{"episode_reward": 949.286096579984, "episode": 145.0, "batch_reward": 0.8751980461478234, "critic_loss": 0.33966671673953536, "actor_loss": -94.39922933959961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.573071002960205, "step": 145000}
{"episode_reward": 910.6966359103908, "episode": 146.0, "batch_reward": 0.874694902420044, "critic_loss": 0.3618250044509769, "actor_loss": -94.41544229125977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.85890817642212, "step": 146000}
{"episode_reward": 929.9917722656854, "episode": 147.0, "batch_reward": 0.8767102296948432, "critic_loss": 0.36087170837074517, "actor_loss": -94.42432540893554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.934658527374268, "step": 147000}
{"episode_reward": 943.9934195811788, "episode": 148.0, "batch_reward": 0.8764861110448837, "critic_loss": 0.3836949349492788, "actor_loss": -94.51139080810547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.143296241760254, "step": 148000}
{"episode_reward": 953.3486108682847, "episode": 149.0, "batch_reward": 0.8757034919857979, "critic_loss": 0.3647864209115505, "actor_loss": -94.53716787719726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.211631059646606, "step": 149000}
{"episode_reward": 988.5341657390762, "episode": 150.0, "batch_reward": 0.8773810380101204, "critic_loss": 0.34936395587027075, "actor_loss": -94.55655567932129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
