{"episode_reward": 0.0, "episode": 1.0, "duration": 21.472046375274658, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.8475556373596191, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.4404467965919362, "critic_loss": 0.2921881486971345, "actor_loss": -83.08445188072788, "actor_target_entropy": -6.0, "alpha_value": 0.002642586817083679, "duration": 67.74214696884155, "step": 3000}
{"episode_reward": 105.75995284810885, "episode": 4.0, "batch_reward": 0.31320530591905116, "critic_loss": 0.7508236285150051, "actor_loss": -80.21627336120605, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.385308980941772, "step": 4000}
{"episode_reward": 123.51100449806832, "episode": 5.0, "batch_reward": 0.2799515829235315, "critic_loss": 0.8591072581410408, "actor_loss": -79.29255525207519, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.856748342514038, "step": 5000}
{"episode_reward": 250.3255873160284, "episode": 6.0, "batch_reward": 0.289713527828455, "critic_loss": 0.9340079680979252, "actor_loss": -79.74532286071778, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.786107063293457, "step": 6000}
{"episode_reward": 445.46611292126187, "episode": 7.0, "batch_reward": 0.32055091996490953, "critic_loss": 1.2797934911251068, "actor_loss": -80.53298571777344, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.685118675231934, "step": 7000}
{"episode_reward": 427.66784623708844, "episode": 8.0, "batch_reward": 0.33726214468479154, "critic_loss": 1.6205807386636735, "actor_loss": -81.21804679870606, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.881882190704346, "step": 8000}
{"episode_reward": 531.3005468180393, "episode": 9.0, "batch_reward": 0.36307990410923957, "critic_loss": 1.9005268050432205, "actor_loss": -81.36036199951172, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.401790857315063, "step": 9000}
{"episode_reward": 609.8041180298738, "episode": 10.0, "batch_reward": 0.3864756861925125, "critic_loss": 2.025374253630638, "actor_loss": -82.15007733154297, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.55107569694519, "step": 10000}
{"episode_reward": 536.144736157382, "episode": 11.0, "batch_reward": 0.40866192707419396, "critic_loss": 2.331371155977249, "actor_loss": -82.72351348876953, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.700329065322876, "step": 11000}
{"episode_reward": 659.424933919666, "episode": 12.0, "batch_reward": 0.4275187108516693, "critic_loss": 2.6352842814922335, "actor_loss": -83.2660594329834, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.353439807891846, "step": 12000}
{"episode_reward": 676.4554864889653, "episode": 13.0, "batch_reward": 0.44411992517113685, "critic_loss": 2.5998086638450624, "actor_loss": -83.48394970703124, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.21561598777771, "step": 13000}
{"episode_reward": 571.455644218566, "episode": 14.0, "batch_reward": 0.46001554268598555, "critic_loss": 2.493582360625267, "actor_loss": -83.947021194458, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.00512933731079, "step": 14000}
{"episode_reward": 738.7568827114566, "episode": 15.0, "batch_reward": 0.4821385880112648, "critic_loss": 2.424133390188217, "actor_loss": -83.4981162109375, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.174732208251953, "step": 15000}
{"episode_reward": 786.8471050780472, "episode": 16.0, "batch_reward": 0.5014452874362468, "critic_loss": 2.3401028971672058, "actor_loss": -85.01039337158203, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.12847876548767, "step": 16000}
{"episode_reward": 777.7349702048144, "episode": 17.0, "batch_reward": 0.5172749512493611, "critic_loss": 2.3336473948955536, "actor_loss": -85.02193290710449, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.653167724609375, "step": 17000}
{"episode_reward": 764.5432982784616, "episode": 18.0, "batch_reward": 0.5326489847302437, "critic_loss": 2.3258803087472915, "actor_loss": -85.47198716735839, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.386640787124634, "step": 18000}
{"episode_reward": 801.4716684144144, "episode": 19.0, "batch_reward": 0.547635710388422, "critic_loss": 2.2855235090255737, "actor_loss": -85.89354530334472, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.04606819152832, "step": 19000}
{"episode_reward": 823.9256181184537, "episode": 20.0, "batch_reward": 0.561197663128376, "critic_loss": 2.214199790596962, "actor_loss": -85.44180824279785, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.8779935836792, "step": 20000}
{"episode_reward": 790.5380691411775, "episode": 21.0, "batch_reward": 0.5734174873828888, "critic_loss": 2.0993388332128524, "actor_loss": -85.91243960571289, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.01559400558472, "step": 21000}
{"episode_reward": 843.507863839419, "episode": 22.0, "batch_reward": 0.5879188466668129, "critic_loss": 2.038850233912468, "actor_loss": -86.03272651672363, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.35473871231079, "step": 22000}
{"episode_reward": 843.2390002902521, "episode": 23.0, "batch_reward": 0.5957248136401176, "critic_loss": 1.821471666932106, "actor_loss": -86.4897886505127, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.34532117843628, "step": 23000}
{"episode_reward": 855.7023948205396, "episode": 24.0, "batch_reward": 0.6031894037723541, "critic_loss": 1.7804622020721435, "actor_loss": -86.4991722869873, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.24510884284973, "step": 24000}
{"episode_reward": 759.1948985421924, "episode": 25.0, "batch_reward": 0.6111003497242927, "critic_loss": 1.688201155900955, "actor_loss": -87.2480461883545, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.272170543670654, "step": 25000}
{"episode_reward": 765.5238359355576, "episode": 26.0, "batch_reward": 0.6195045815110206, "critic_loss": 1.7761417157649995, "actor_loss": -86.78608869934082, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.709311723709106, "step": 26000}
{"episode_reward": 827.0835909535808, "episode": 27.0, "batch_reward": 0.6289500867724419, "critic_loss": 1.660080394744873, "actor_loss": -87.13001268005371, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.044281005859375, "step": 27000}
{"episode_reward": 843.8316158076617, "episode": 28.0, "batch_reward": 0.6340559906363488, "critic_loss": 1.62216723549366, "actor_loss": -87.425976852417, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.500789403915405, "step": 28000}
{"episode_reward": 818.581570641748, "episode": 29.0, "batch_reward": 0.6437383684515953, "critic_loss": 1.5059891917705537, "actor_loss": -86.9199828338623, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.887446880340576, "step": 29000}
{"episode_reward": 900.2700398840911, "episode": 30.0, "batch_reward": 0.6502074808478355, "critic_loss": 1.4702353356480597, "actor_loss": -87.12744192504883, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.952642679214478, "step": 30000}
{"episode_reward": 820.6071493207166, "episode": 31.0, "batch_reward": 0.6558736217021942, "critic_loss": 1.4196385202407837, "actor_loss": -88.05302032470703, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.877127170562744, "step": 31000}
{"episode_reward": 863.028967718028, "episode": 32.0, "batch_reward": 0.6542977926135063, "critic_loss": 1.5357780066132545, "actor_loss": -87.67176731872559, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.121361017227173, "step": 32000}
{"episode_reward": 98.9657395456739, "episode": 33.0, "batch_reward": 0.645840430855751, "critic_loss": 1.3193651019930839, "actor_loss": -87.42188304138183, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.261797428131104, "step": 33000}
{"episode_reward": 842.2216770304908, "episode": 34.0, "batch_reward": 0.6513917720317841, "critic_loss": 1.322676786661148, "actor_loss": -87.67360459899902, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.555620670318604, "step": 34000}
{"episode_reward": 873.9822032900959, "episode": 35.0, "batch_reward": 0.6576253919005394, "critic_loss": 1.3021276864409446, "actor_loss": -87.35170162963867, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.321447372436523, "step": 35000}
{"episode_reward": 642.0604397962959, "episode": 36.0, "batch_reward": 0.6558700192570687, "critic_loss": 1.361770856142044, "actor_loss": -88.37062602233887, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.572635889053345, "step": 36000}
{"episode_reward": 812.437927257757, "episode": 37.0, "batch_reward": 0.6633298398256302, "critic_loss": 1.3952930936217307, "actor_loss": -88.00442372131347, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.783164501190186, "step": 37000}
{"episode_reward": 850.823784976563, "episode": 38.0, "batch_reward": 0.6682229049801827, "critic_loss": 1.4022985377907753, "actor_loss": -87.56705903625489, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.2321834564209, "step": 38000}
{"episode_reward": 874.1857879146407, "episode": 39.0, "batch_reward": 0.6740045608282089, "critic_loss": 1.3779293132424355, "actor_loss": -88.47276475524902, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.02419137954712, "step": 39000}
{"episode_reward": 926.2677490594081, "episode": 40.0, "batch_reward": 0.6780631155967712, "critic_loss": 1.4006067147850991, "actor_loss": -88.45816693115235, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.46101689338684, "step": 40000}
{"episode_reward": 904.4532299083766, "episode": 41.0, "batch_reward": 0.6815072922110558, "critic_loss": 1.386981210052967, "actor_loss": -88.99157809448242, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.22639513015747, "step": 41000}
{"episode_reward": 425.64003041941197, "episode": 42.0, "batch_reward": 0.6765599195361137, "critic_loss": 1.4113285230994224, "actor_loss": -87.55361334228516, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.58439803123474, "step": 42000}
{"episode_reward": 905.5821385870612, "episode": 43.0, "batch_reward": 0.6862241489887237, "critic_loss": 1.4268103927373885, "actor_loss": -88.66592741394042, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.50005578994751, "step": 43000}
{"episode_reward": 848.3017163632522, "episode": 44.0, "batch_reward": 0.6879297416210175, "critic_loss": 1.3671998855471612, "actor_loss": -88.57121075439453, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.60672688484192, "step": 44000}
{"episode_reward": 843.3389573062499, "episode": 45.0, "batch_reward": 0.6927331128716469, "critic_loss": 1.3941230223178864, "actor_loss": -88.48739450073242, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.50856900215149, "step": 45000}
{"episode_reward": 892.3027532411734, "episode": 46.0, "batch_reward": 0.6955288858413696, "critic_loss": 1.3860085964202882, "actor_loss": -88.39544483947753, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.93371891975403, "step": 46000}
{"episode_reward": 834.4976394250338, "episode": 47.0, "batch_reward": 0.6985636020302772, "critic_loss": 1.4426321886181832, "actor_loss": -88.89546702575683, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.422517776489258, "step": 47000}
{"episode_reward": 877.4385862906353, "episode": 48.0, "batch_reward": 0.7023561670184135, "critic_loss": 1.420175302863121, "actor_loss": -88.89922651672363, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.63762354850769, "step": 48000}
{"episode_reward": 893.3522635400595, "episode": 49.0, "batch_reward": 0.7062408459186554, "critic_loss": 1.3458424738049508, "actor_loss": -89.19948220825195, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.346942901611328, "step": 49000}
{"episode_reward": 868.5168644588213, "episode": 50.0, "batch_reward": 0.7113606796860695, "critic_loss": 1.376159066438675, "actor_loss": -88.82576371765137, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.91563844680786, "step": 50000}
{"episode_reward": 841.3758055307846, "episode": 51.0, "batch_reward": 0.7109383598566056, "critic_loss": 1.4691051315665244, "actor_loss": -88.88188731384277, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.48576211929321, "step": 51000}
{"episode_reward": 718.4795003698375, "episode": 52.0, "batch_reward": 0.7116662885546684, "critic_loss": 1.48154514503479, "actor_loss": -89.36306805419922, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.214804887771606, "step": 52000}
{"episode_reward": 859.4228765730421, "episode": 53.0, "batch_reward": 0.7136210969090462, "critic_loss": 1.4595236858725549, "actor_loss": -88.4282314453125, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.96413540840149, "step": 53000}
{"episode_reward": 853.5276410666901, "episode": 54.0, "batch_reward": 0.7170240125656128, "critic_loss": 1.4274282503724098, "actor_loss": -89.82601594543458, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.200228929519653, "step": 54000}
{"episode_reward": 887.9233485591207, "episode": 55.0, "batch_reward": 0.7204343209266663, "critic_loss": 1.3805229410529136, "actor_loss": -89.49401765441894, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.754892349243164, "step": 55000}
{"episode_reward": 918.8498813752847, "episode": 56.0, "batch_reward": 0.7244306167364121, "critic_loss": 1.3651885976195335, "actor_loss": -88.8045536956787, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.558792114257812, "step": 56000}
{"episode_reward": 960.4027108733679, "episode": 57.0, "batch_reward": 0.7304643120169639, "critic_loss": 1.2955782555937767, "actor_loss": -89.81656747436523, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.909214973449707, "step": 57000}
{"episode_reward": 921.8883860338107, "episode": 58.0, "batch_reward": 0.7316819204092025, "critic_loss": 1.2755509717464446, "actor_loss": -89.4533465423584, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.300397872924805, "step": 58000}
{"episode_reward": 886.6336542477846, "episode": 59.0, "batch_reward": 0.7359884198307991, "critic_loss": 1.2619977595806122, "actor_loss": -89.67856712341309, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.374801874160767, "step": 59000}
{"episode_reward": 913.1927406413298, "episode": 60.0, "batch_reward": 0.7364437367916107, "critic_loss": 1.2545748570561408, "actor_loss": -89.68263507080079, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.767174243927002, "step": 60000}
{"episode_reward": 875.4896749329757, "episode": 61.0, "batch_reward": 0.740258493423462, "critic_loss": 1.2262189753055572, "actor_loss": -90.11498097229004, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.84940528869629, "step": 61000}
{"episode_reward": 864.6432740220312, "episode": 62.0, "batch_reward": 0.7403396429419518, "critic_loss": 1.2052681795358657, "actor_loss": -89.65767166137695, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.022249460220337, "step": 62000}
{"episode_reward": 940.698997484819, "episode": 63.0, "batch_reward": 0.7453618449568749, "critic_loss": 1.1947511172294616, "actor_loss": -89.99679450988769, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.30910873413086, "step": 63000}
{"episode_reward": 926.3021886242905, "episode": 64.0, "batch_reward": 0.7487455254793167, "critic_loss": 1.1468886553049087, "actor_loss": -90.17006991577148, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.888065576553345, "step": 64000}
{"episode_reward": 905.403287401185, "episode": 65.0, "batch_reward": 0.7511690948605537, "critic_loss": 1.1188461577892304, "actor_loss": -90.03058280944825, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.352688550949097, "step": 65000}
{"episode_reward": 920.6955350843128, "episode": 66.0, "batch_reward": 0.7531548447012901, "critic_loss": 1.1625674129128456, "actor_loss": -90.14765710449218, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.721153736114502, "step": 66000}
{"episode_reward": 899.5712033434453, "episode": 67.0, "batch_reward": 0.7547378984689712, "critic_loss": 1.1223133494257926, "actor_loss": -89.96858705139161, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.46833324432373, "step": 67000}
{"episode_reward": 885.767404254988, "episode": 68.0, "batch_reward": 0.7578082309365273, "critic_loss": 1.0497885271906853, "actor_loss": -90.59956326293945, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.979849576950073, "step": 68000}
{"episode_reward": 929.7350129825285, "episode": 69.0, "batch_reward": 0.7605629169344902, "critic_loss": 1.0747759049534797, "actor_loss": -90.66000103759765, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.93758273124695, "step": 69000}
{"episode_reward": 873.9661229782098, "episode": 70.0, "batch_reward": 0.7610049885511398, "critic_loss": 1.0590597189068793, "actor_loss": -90.72770738220215, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.80218267440796, "step": 70000}
{"episode_reward": 885.6012824271974, "episode": 71.0, "batch_reward": 0.7617882685065269, "critic_loss": 1.0780931891798973, "actor_loss": -90.30962164306641, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.5297417640686, "step": 71000}
{"episode_reward": 913.1233369191501, "episode": 72.0, "batch_reward": 0.7662030806541443, "critic_loss": 1.0288859701752662, "actor_loss": -91.07384854125976, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.979553699493408, "step": 72000}
{"episode_reward": 897.1214413139897, "episode": 73.0, "batch_reward": 0.7672163976430892, "critic_loss": 1.0399340119361877, "actor_loss": -90.98742831420898, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.42353081703186, "step": 73000}
{"episode_reward": 896.1730764564331, "episode": 74.0, "batch_reward": 0.7706147184967995, "critic_loss": 1.0671701415777206, "actor_loss": -90.76676052856445, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.34466314315796, "step": 74000}
{"episode_reward": 917.1849780046422, "episode": 75.0, "batch_reward": 0.7720398510694504, "critic_loss": 1.0266965890228748, "actor_loss": -91.23075770568848, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.780995845794678, "step": 75000}
{"episode_reward": 913.6274195223477, "episode": 76.0, "batch_reward": 0.7723776275515556, "critic_loss": 1.054796363711357, "actor_loss": -91.01748558044433, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.841185808181763, "step": 76000}
{"episode_reward": 930.2397618418861, "episode": 77.0, "batch_reward": 0.7756173064112664, "critic_loss": 0.9798971934318542, "actor_loss": -91.06371632385255, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.679470539093018, "step": 77000}
{"episode_reward": 908.7390960338402, "episode": 78.0, "batch_reward": 0.7744241868257522, "critic_loss": 0.9943979598283768, "actor_loss": -90.79224586486816, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.482420682907104, "step": 78000}
{"episode_reward": 864.8917858898932, "episode": 79.0, "batch_reward": 0.7778422093391418, "critic_loss": 0.9806169714927674, "actor_loss": -91.31179347229003, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.510567903518677, "step": 79000}
{"episode_reward": 897.6310113964751, "episode": 80.0, "batch_reward": 0.7789729964733124, "critic_loss": 0.9991515658199787, "actor_loss": -91.31858526611327, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.058080673217773, "step": 80000}
{"episode_reward": 914.3599623136536, "episode": 81.0, "batch_reward": 0.7811853151917457, "critic_loss": 0.9810469333529472, "actor_loss": -91.32499731445313, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 44.96487069129944, "step": 81000}
{"episode_reward": 917.3606734364738, "episode": 82.0, "batch_reward": 0.7809026414752006, "critic_loss": 1.0125164508223534, "actor_loss": -91.24647370910644, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.532367706298828, "step": 82000}
{"episode_reward": 879.357272945344, "episode": 83.0, "batch_reward": 0.7817110055685044, "critic_loss": 0.9690661978721619, "actor_loss": -91.30541961669923, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.82214045524597, "step": 83000}
{"episode_reward": 927.3157316806661, "episode": 84.0, "batch_reward": 0.7848471196293831, "critic_loss": 1.0014160911738872, "actor_loss": -91.84765730285645, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.704582691192627, "step": 84000}
{"episode_reward": 874.6949659612143, "episode": 85.0, "batch_reward": 0.785595254123211, "critic_loss": 0.9944831185042858, "actor_loss": -91.51657072448731, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.882204055786133, "step": 85000}
{"episode_reward": 916.8084414357472, "episode": 86.0, "batch_reward": 0.7872445452809333, "critic_loss": 0.9965725072026252, "actor_loss": -91.75310604858399, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.562476873397827, "step": 86000}
{"episode_reward": 916.5009031441194, "episode": 87.0, "batch_reward": 0.789606941640377, "critic_loss": 0.9902036675214767, "actor_loss": -91.8391667022705, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.478657960891724, "step": 87000}
{"episode_reward": 924.2895641726698, "episode": 88.0, "batch_reward": 0.7910049359202385, "critic_loss": 0.9731169861257076, "actor_loss": -91.9482424621582, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.375227689743042, "step": 88000}
{"episode_reward": 915.6090327151346, "episode": 89.0, "batch_reward": 0.7922400087118149, "critic_loss": 0.9697211065590382, "actor_loss": -91.6985301513672, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.2182776927948, "step": 89000}
{"episode_reward": 899.7539857991925, "episode": 90.0, "batch_reward": 0.7930028417110443, "critic_loss": 0.9653469808101655, "actor_loss": -91.7952791595459, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.212629795074463, "step": 90000}
{"episode_reward": 939.9596985596746, "episode": 91.0, "batch_reward": 0.794948062300682, "critic_loss": 0.9707669260203838, "actor_loss": -91.6158271484375, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.65191054344177, "step": 91000}
{"episode_reward": 893.1628974676672, "episode": 92.0, "batch_reward": 0.7969644073843956, "critic_loss": 0.9555623743832111, "actor_loss": -91.84272219848633, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.081782579421997, "step": 92000}
{"episode_reward": 909.4867266090176, "episode": 93.0, "batch_reward": 0.798479080080986, "critic_loss": 0.931539588958025, "actor_loss": -92.20984602355956, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.15825915336609, "step": 93000}
{"episode_reward": 935.0024084967732, "episode": 94.0, "batch_reward": 0.7994601191282272, "critic_loss": 0.9355333794653415, "actor_loss": -92.20875001525879, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.02802872657776, "step": 94000}
{"episode_reward": 886.0711451631536, "episode": 95.0, "batch_reward": 0.7994146190285683, "critic_loss": 0.950563749909401, "actor_loss": -92.23399353027344, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.391679048538208, "step": 95000}
{"episode_reward": 849.646222628107, "episode": 96.0, "batch_reward": 0.8003721105456352, "critic_loss": 0.9393311022222042, "actor_loss": -92.07827249145508, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.612776517868042, "step": 96000}
{"episode_reward": 922.0441643523073, "episode": 97.0, "batch_reward": 0.8012873057126999, "critic_loss": 0.9354489583969117, "actor_loss": -92.24504026794433, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.49210238456726, "step": 97000}
{"episode_reward": 885.578966316088, "episode": 98.0, "batch_reward": 0.8019787678122521, "critic_loss": 0.9354227407574653, "actor_loss": -92.28668717956543, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.26032018661499, "step": 98000}
{"episode_reward": 888.1933728833328, "episode": 99.0, "batch_reward": 0.8042527354955673, "critic_loss": 0.9583026085495949, "actor_loss": -92.21027581787109, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.67136311531067, "step": 99000}
{"episode_reward": 882.6999863724404, "episode": 100.0, "batch_reward": 0.8031828449368477, "critic_loss": 0.9753563756942749, "actor_loss": -92.49006596374512, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.014683485031128, "step": 100000}
{"episode_reward": 921.2077918772992, "episode": 101.0, "batch_reward": 0.8066053480505944, "critic_loss": 0.9422833008170128, "actor_loss": -92.49791632080078, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.213873624801636, "step": 101000}
{"episode_reward": 931.0781142072874, "episode": 102.0, "batch_reward": 0.8084047775864601, "critic_loss": 0.9390014846324921, "actor_loss": -92.76217910766601, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.791324853897095, "step": 102000}
{"episode_reward": 953.6604707876946, "episode": 103.0, "batch_reward": 0.8065832904577255, "critic_loss": 0.8844047794342041, "actor_loss": -92.07921838378907, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.32075834274292, "step": 103000}
{"episode_reward": 930.8439116508544, "episode": 104.0, "batch_reward": 0.8078664233088493, "critic_loss": 0.9243279938697815, "actor_loss": -92.46072698974609, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.860371351242065, "step": 104000}
{"episode_reward": 846.4300696492597, "episode": 105.0, "batch_reward": 0.8108500072956085, "critic_loss": 0.9203556761443615, "actor_loss": -92.32473173522949, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.766416788101196, "step": 105000}
{"episode_reward": 919.1823195334804, "episode": 106.0, "batch_reward": 0.8102250386476517, "critic_loss": 0.9830403912365436, "actor_loss": -92.84600088500977, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.392569065093994, "step": 106000}
{"episode_reward": 779.0557451196721, "episode": 107.0, "batch_reward": 0.8101913070678711, "critic_loss": 0.9998848852515221, "actor_loss": -92.7524666595459, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.01448965072632, "step": 107000}
{"episode_reward": 851.6852997230558, "episode": 108.0, "batch_reward": 0.8091265913248062, "critic_loss": 1.0437817241549492, "actor_loss": -92.33049052429199, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.561676025390625, "step": 108000}
{"episode_reward": 908.1135977195063, "episode": 109.0, "batch_reward": 0.8110718581080437, "critic_loss": 0.9931569413244724, "actor_loss": -92.65747198486328, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.35300350189209, "step": 109000}
{"episode_reward": 868.4098430213792, "episode": 110.0, "batch_reward": 0.8124241154789925, "critic_loss": 0.9327404809892178, "actor_loss": -92.60463453674316, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.41637349128723, "step": 110000}
{"episode_reward": 811.1082636292473, "episode": 111.0, "batch_reward": 0.8127980741858483, "critic_loss": 0.9823110519349575, "actor_loss": -92.44726499938965, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.19087505340576, "step": 111000}
{"episode_reward": 914.2924324026586, "episode": 112.0, "batch_reward": 0.8127796227931976, "critic_loss": 1.0317182055413723, "actor_loss": -92.69356532287598, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.0067880153656, "step": 112000}
{"episode_reward": 831.7252023600366, "episode": 113.0, "batch_reward": 0.8138050791025162, "critic_loss": 1.1233462079465388, "actor_loss": -92.78806413269044, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.485717296600342, "step": 113000}
{"episode_reward": 935.6823669287182, "episode": 114.0, "batch_reward": 0.813226791381836, "critic_loss": 1.1517769082486629, "actor_loss": -92.78207252502442, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.97538733482361, "step": 114000}
{"episode_reward": 932.6371089244077, "episode": 115.0, "batch_reward": 0.8160233666300774, "critic_loss": 1.0804513131082059, "actor_loss": -92.53162559509278, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.252317190170288, "step": 115000}
{"episode_reward": 932.9719954351012, "episode": 116.0, "batch_reward": 0.8176474496722221, "critic_loss": 1.1535021336376667, "actor_loss": -92.69557664489746, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.625662565231323, "step": 116000}
{"episode_reward": 890.7090329251101, "episode": 117.0, "batch_reward": 0.8164882523417473, "critic_loss": 1.0859311626553536, "actor_loss": -92.25203944396972, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.869965076446533, "step": 117000}
{"episode_reward": 907.2341179073577, "episode": 118.0, "batch_reward": 0.8173121557831764, "critic_loss": 1.0808730126917363, "actor_loss": -92.51120965576172, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.695398807525635, "step": 118000}
{"episode_reward": 903.7033451234946, "episode": 119.0, "batch_reward": 0.819004598557949, "critic_loss": 1.1063897087275982, "actor_loss": -92.55813737487793, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.615532398223877, "step": 119000}
{"episode_reward": 904.1687606447047, "episode": 120.0, "batch_reward": 0.819316002190113, "critic_loss": 1.107288212478161, "actor_loss": -92.57534487915039, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.51350426673889, "step": 120000}
{"episode_reward": 930.088723493732, "episode": 121.0, "batch_reward": 0.8201234239935875, "critic_loss": 1.081166451871395, "actor_loss": -92.60048806762696, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.00566291809082, "step": 121000}
{"episode_reward": 924.7087903724482, "episode": 122.0, "batch_reward": 0.8216033247113228, "critic_loss": 1.0859920392930507, "actor_loss": -92.86562071228028, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.62191605567932, "step": 122000}
{"episode_reward": 871.5428547964826, "episode": 123.0, "batch_reward": 0.8213857735991478, "critic_loss": 1.0538527772128583, "actor_loss": -93.09560633850097, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.826770067214966, "step": 123000}
{"episode_reward": 888.6323771299255, "episode": 124.0, "batch_reward": 0.8214947491884231, "critic_loss": 1.0906426517367362, "actor_loss": -92.9930108795166, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.80460548400879, "step": 124000}
{"episode_reward": 835.8753481572593, "episode": 125.0, "batch_reward": 0.8221110115647317, "critic_loss": 1.1169973972141742, "actor_loss": -92.99089161682129, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.566590309143066, "step": 125000}
{"episode_reward": 899.4202902126948, "episode": 126.0, "batch_reward": 0.8253829302191734, "critic_loss": 1.1215525557398796, "actor_loss": -92.78458613586426, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.305867671966553, "step": 126000}
{"episode_reward": 896.5256977617541, "episode": 127.0, "batch_reward": 0.8235274856090545, "critic_loss": 1.132952762901783, "actor_loss": -92.6144051361084, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.850879192352295, "step": 127000}
{"episode_reward": 923.0120241331531, "episode": 128.0, "batch_reward": 0.8233509369492531, "critic_loss": 1.1217182393372058, "actor_loss": -92.7589108581543, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.550056219100952, "step": 128000}
{"episode_reward": 872.7541217901019, "episode": 129.0, "batch_reward": 0.8239771882891656, "critic_loss": 1.124800587683916, "actor_loss": -92.89742761230468, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.286048412322998, "step": 129000}
{"episode_reward": 958.7808870888115, "episode": 130.0, "batch_reward": 0.8281240720748901, "critic_loss": 1.080368489176035, "actor_loss": -92.81899127197265, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.009411096572876, "step": 130000}
{"episode_reward": 914.8246049435157, "episode": 131.0, "batch_reward": 0.8264632388949394, "critic_loss": 1.0837898372411727, "actor_loss": -93.04986114501953, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.970776081085205, "step": 131000}
{"episode_reward": 904.1264450559671, "episode": 132.0, "batch_reward": 0.8270908060669899, "critic_loss": 1.0298880015313625, "actor_loss": -93.3148731994629, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.39975118637085, "step": 132000}
{"episode_reward": 887.0929346787827, "episode": 133.0, "batch_reward": 0.8264393244981766, "critic_loss": 1.0634533623158933, "actor_loss": -93.04125157165528, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.7463276386261, "step": 133000}
{"episode_reward": 914.769880032762, "episode": 134.0, "batch_reward": 0.8280646519064904, "critic_loss": 1.0315615905225277, "actor_loss": -92.93086553955078, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.002830982208252, "step": 134000}
{"episode_reward": 885.7355306934209, "episode": 135.0, "batch_reward": 0.8292222833037376, "critic_loss": 1.073946138650179, "actor_loss": -92.84943588256836, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.432883739471436, "step": 135000}
{"episode_reward": 904.2062908561547, "episode": 136.0, "batch_reward": 0.8292733149528504, "critic_loss": 0.9887803002297878, "actor_loss": -92.73376010131835, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.72077965736389, "step": 136000}
{"episode_reward": 894.6602799623457, "episode": 137.0, "batch_reward": 0.8280150907039643, "critic_loss": 0.9998708618581295, "actor_loss": -93.27653169250489, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.79476833343506, "step": 137000}
{"episode_reward": 922.9489339711682, "episode": 138.0, "batch_reward": 0.8308149790167808, "critic_loss": 0.9387840758860111, "actor_loss": -93.13430926513672, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.677971363067627, "step": 138000}
{"episode_reward": 924.920673185613, "episode": 139.0, "batch_reward": 0.8315639211535454, "critic_loss": 0.9441374015510082, "actor_loss": -93.09532543945312, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.00097417831421, "step": 139000}
{"episode_reward": 927.1467853609624, "episode": 140.0, "batch_reward": 0.8332537277340889, "critic_loss": 0.9051368927657604, "actor_loss": -93.1126587677002, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.512385368347168, "step": 140000}
{"episode_reward": 885.7999978328451, "episode": 141.0, "batch_reward": 0.8300406824350357, "critic_loss": 0.9787267205417156, "actor_loss": -93.20070918273926, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.49992632865906, "step": 141000}
{"episode_reward": 868.1426451107934, "episode": 142.0, "batch_reward": 0.8318652851581574, "critic_loss": 0.9672653588056564, "actor_loss": -92.70447805786132, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.454604625701904, "step": 142000}
{"episode_reward": 910.1193498107771, "episode": 143.0, "batch_reward": 0.8324986594319344, "critic_loss": 0.9592397063374519, "actor_loss": -92.86992506408691, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.55256485939026, "step": 143000}
{"episode_reward": 890.8993754462136, "episode": 144.0, "batch_reward": 0.8331235458254814, "critic_loss": 0.941037168443203, "actor_loss": -93.14787832641602, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.054142951965332, "step": 144000}
{"episode_reward": 907.2080975107884, "episode": 145.0, "batch_reward": 0.8335083681344986, "critic_loss": 0.9040923692882061, "actor_loss": -93.4148109741211, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.436012268066406, "step": 145000}
{"episode_reward": 903.8775373560695, "episode": 146.0, "batch_reward": 0.8351254498362541, "critic_loss": 0.9259821643233299, "actor_loss": -93.41594485473632, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.119553804397583, "step": 146000}
{"episode_reward": 940.0258413765015, "episode": 147.0, "batch_reward": 0.834027693271637, "critic_loss": 0.91791530418396, "actor_loss": -93.10417141723633, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.79409170150757, "step": 147000}
{"episode_reward": 893.2087633356177, "episode": 148.0, "batch_reward": 0.8356883658766746, "critic_loss": 0.9144290228784084, "actor_loss": -93.46132551574706, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.806498527526855, "step": 148000}
{"episode_reward": 894.667251647523, "episode": 149.0, "batch_reward": 0.835256305217743, "critic_loss": 0.9454183776378632, "actor_loss": -93.0889850769043, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.831687927246094, "step": 149000}
{"episode_reward": 960.4213610571117, "episode": 150.0, "batch_reward": 0.8355052075982093, "critic_loss": 0.95620109847188, "actor_loss": -93.407888961792, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "step": 150000}
