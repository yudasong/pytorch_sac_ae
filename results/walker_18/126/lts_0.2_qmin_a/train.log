{"episode_reward": 0.0, "episode": 1.0, "duration": 21.66375207901001, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.957298994064331, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.4366877073743177, "critic_loss": 0.06271455289886674, "actor_loss": -20.913199430473952, "actor_target_entropy": -6.0, "alpha_value": 0.002642586817083679, "duration": 64.26447677612305, "step": 3000}
{"episode_reward": 32.94546685282229, "episode": 4.0, "batch_reward": 0.28288881468772886, "critic_loss": 0.13465577837638557, "actor_loss": -21.34393643760681, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.001370668411255, "step": 4000}
{"episode_reward": 43.127618472684745, "episode": 5.0, "batch_reward": 0.23187910878658294, "critic_loss": 0.2203532701358199, "actor_loss": -22.747360796928405, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.837160110473633, "step": 5000}
{"episode_reward": 56.29516651822612, "episode": 6.0, "batch_reward": 0.19624844422936438, "critic_loss": 0.2696100511625409, "actor_loss": -21.74418328857422, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.16795015335083, "step": 6000}
{"episode_reward": 39.046296553635784, "episode": 7.0, "batch_reward": 0.17326828569173813, "critic_loss": 0.32924145099148155, "actor_loss": -20.48525180721283, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.7994122505188, "step": 7000}
{"episode_reward": 31.081096104941317, "episode": 8.0, "batch_reward": 0.15456918492913246, "critic_loss": 0.4462710706330836, "actor_loss": -25.669987776756287, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.573281049728394, "step": 8000}
{"episode_reward": 61.05960681866278, "episode": 9.0, "batch_reward": 0.14728318627923728, "critic_loss": 0.8775937501937151, "actor_loss": -26.610418257713317, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.785225868225098, "step": 9000}
{"episode_reward": 150.0222437355807, "episode": 10.0, "batch_reward": 0.1549091419354081, "critic_loss": 1.9132125124633312, "actor_loss": -28.960151422500612, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.93903636932373, "step": 10000}
{"episode_reward": 295.8887693818837, "episode": 11.0, "batch_reward": 0.1600602320805192, "critic_loss": 3.6346963341236114, "actor_loss": -32.92813159942627, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.163118839263916, "step": 11000}
{"episode_reward": 55.87881279785376, "episode": 12.0, "batch_reward": 0.15085543555021286, "critic_loss": 3.714383683681488, "actor_loss": -44.16087692642212, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.963671684265137, "step": 12000}
{"episode_reward": 62.6184158403278, "episode": 13.0, "batch_reward": 0.14393461338430644, "critic_loss": 4.883791315317154, "actor_loss": -50.85357922363281, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.068514585494995, "step": 13000}
{"episode_reward": 55.3531654922899, "episode": 14.0, "batch_reward": 0.13473769956827164, "critic_loss": 5.081307502627372, "actor_loss": -56.63103380584717, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.930622100830078, "step": 14000}
{"episode_reward": 32.53870556625639, "episode": 15.0, "batch_reward": 0.1281504849009216, "critic_loss": 5.763909292936325, "actor_loss": -64.11139431762696, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.43575882911682, "step": 15000}
{"episode_reward": 20.816243014881238, "episode": 16.0, "batch_reward": 0.12276121813058853, "critic_loss": 7.0583542351722715, "actor_loss": -72.4726322555542, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.72207498550415, "step": 16000}
{"episode_reward": 57.35010142366266, "episode": 17.0, "batch_reward": 0.11759732810780406, "critic_loss": 8.548495537281037, "actor_loss": -79.82567210388184, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.87647271156311, "step": 17000}
{"episode_reward": 64.77228939163768, "episode": 18.0, "batch_reward": 0.11349315194040537, "critic_loss": 8.846847243309021, "actor_loss": -86.41716369628907, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.91043472290039, "step": 18000}
{"episode_reward": 30.487566363996294, "episode": 19.0, "batch_reward": 0.11143311472237111, "critic_loss": 9.016155309200286, "actor_loss": -90.51628608703614, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.708678722381592, "step": 19000}
{"episode_reward": 87.6971760169696, "episode": 20.0, "batch_reward": 0.11086034484952688, "critic_loss": 6.7290162675380705, "actor_loss": -92.7550096130371, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.465726852416992, "step": 20000}
{"episode_reward": 72.37917737054696, "episode": 21.0, "batch_reward": 0.10680998443439603, "critic_loss": 5.350185047388077, "actor_loss": -92.92850367736817, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.657958030700684, "step": 21000}
{"episode_reward": 61.283268600613425, "episode": 22.0, "batch_reward": 0.10534652569890023, "critic_loss": 4.531555515289306, "actor_loss": -94.68625335693359, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.100409746170044, "step": 22000}
{"episode_reward": 63.21373609007213, "episode": 23.0, "batch_reward": 0.10508450204133987, "critic_loss": 3.962070781350136, "actor_loss": -95.67076414489746, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.51820731163025, "step": 23000}
{"episode_reward": 121.94992877252434, "episode": 24.0, "batch_reward": 0.10412884797155857, "critic_loss": 3.427549801468849, "actor_loss": -95.97323243713379, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.18406867980957, "step": 24000}
{"episode_reward": 15.448028604394098, "episode": 25.0, "batch_reward": 0.10250635807961225, "critic_loss": 3.1777208559513093, "actor_loss": -95.35275184631348, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.988930463790894, "step": 25000}
{"episode_reward": 94.6551802658635, "episode": 26.0, "batch_reward": 0.1013440882563591, "critic_loss": 3.002136219620705, "actor_loss": -95.68057888793945, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.677685976028442, "step": 26000}
{"episode_reward": 47.892399342587396, "episode": 27.0, "batch_reward": 0.09857400099188089, "critic_loss": 2.7501273783445357, "actor_loss": -97.01888894653321, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.804102897644043, "step": 27000}
{"episode_reward": 39.736571327600934, "episode": 28.0, "batch_reward": 0.09482518171146512, "critic_loss": 2.7055905723571776, "actor_loss": -95.59693032836914, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.54146385192871, "step": 28000}
{"episode_reward": 40.94735375018533, "episode": 29.0, "batch_reward": 0.09415429684892297, "critic_loss": 2.5610802565813064, "actor_loss": -96.83996151733399, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.718157529830933, "step": 29000}
{"episode_reward": 77.47816938383427, "episode": 30.0, "batch_reward": 0.09419310544803738, "critic_loss": 2.700518093585968, "actor_loss": -95.69080601501464, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.16075325012207, "step": 30000}
{"episode_reward": 37.10330799671901, "episode": 31.0, "batch_reward": 0.09149125427007675, "critic_loss": 2.3932685931921007, "actor_loss": -94.38056484985351, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.91987371444702, "step": 31000}
{"episode_reward": 29.399960706535243, "episode": 32.0, "batch_reward": 0.09132636461034417, "critic_loss": 2.6315286605358126, "actor_loss": -93.56218339538574, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.825504064559937, "step": 32000}
{"episode_reward": 89.15750272607552, "episode": 33.0, "batch_reward": 0.09118665114417672, "critic_loss": 2.8673949147462845, "actor_loss": -92.55801823425293, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.704731225967407, "step": 33000}
{"episode_reward": 136.5911873051167, "episode": 34.0, "batch_reward": 0.09248843878507614, "critic_loss": 3.1014201687574388, "actor_loss": -91.672380859375, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.81391978263855, "step": 34000}
{"episode_reward": 101.19046578553707, "episode": 35.0, "batch_reward": 0.0972374906502664, "critic_loss": 3.5659671771526336, "actor_loss": -91.16524954223632, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.306594371795654, "step": 35000}
{"episode_reward": 439.15685192104263, "episode": 36.0, "batch_reward": 0.10556558357551694, "critic_loss": 4.099119859457016, "actor_loss": -90.86745758056641, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.312982082366943, "step": 36000}
{"episode_reward": 309.4396004140753, "episode": 37.0, "batch_reward": 0.10810028616338968, "critic_loss": 4.48710494351387, "actor_loss": -91.02182946777344, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.02111053466797, "step": 37000}
{"episode_reward": 129.19313316512307, "episode": 38.0, "batch_reward": 0.1086412746682763, "critic_loss": 4.339872269630432, "actor_loss": -92.92910676574706, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.71863603591919, "step": 38000}
{"episode_reward": 137.51454478295994, "episode": 39.0, "batch_reward": 0.11063307210803032, "critic_loss": 4.3743147732019425, "actor_loss": -92.84922048950196, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.111680269241333, "step": 39000}
{"episode_reward": 165.9686655872631, "episode": 40.0, "batch_reward": 0.11356310978531838, "critic_loss": 4.62982365822792, "actor_loss": -92.87745268249512, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.37068223953247, "step": 40000}
{"episode_reward": 430.74117168683136, "episode": 41.0, "batch_reward": 0.12111172941327095, "critic_loss": 4.62795155119896, "actor_loss": -92.80463125610352, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.44780135154724, "step": 41000}
{"episode_reward": 189.40870822117435, "episode": 42.0, "batch_reward": 0.12310181897133589, "critic_loss": 4.289395347714424, "actor_loss": -92.67159880065918, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.701106309890747, "step": 42000}
{"episode_reward": 281.32293478542783, "episode": 43.0, "batch_reward": 0.1261680452823639, "critic_loss": 3.750219912528992, "actor_loss": -93.03166348266602, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.534618854522705, "step": 43000}
{"episode_reward": 313.927540792398, "episode": 44.0, "batch_reward": 0.1270241911560297, "critic_loss": 3.891735038161278, "actor_loss": -92.2238101348877, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.727372884750366, "step": 44000}
{"episode_reward": 34.83225560889954, "episode": 45.0, "batch_reward": 0.1292113467901945, "critic_loss": 3.8268888087272646, "actor_loss": -92.29811613464355, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.69539475440979, "step": 45000}
{"episode_reward": 529.96964385341, "episode": 46.0, "batch_reward": 0.1389511402770877, "critic_loss": 3.860124040365219, "actor_loss": -91.58991780090332, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.00723695755005, "step": 46000}
{"episode_reward": 542.7859430625709, "episode": 47.0, "batch_reward": 0.1475901417955756, "critic_loss": 3.7876365925073623, "actor_loss": -90.98703169250489, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.073055744171143, "step": 47000}
{"episode_reward": 543.5355166339148, "episode": 48.0, "batch_reward": 0.15807332967221738, "critic_loss": 3.758830815076828, "actor_loss": -91.50522581481934, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.201440811157227, "step": 48000}
{"episode_reward": 589.2859579170538, "episode": 49.0, "batch_reward": 0.1663521091043949, "critic_loss": 3.4983597836494447, "actor_loss": -91.10541314697265, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.202649116516113, "step": 49000}
{"episode_reward": 690.1054386942601, "episode": 50.0, "batch_reward": 0.1774145039394498, "critic_loss": 3.3723429609537123, "actor_loss": -90.34335026550293, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.94833278656006, "step": 50000}
{"episode_reward": 527.6926353317339, "episode": 51.0, "batch_reward": 0.1851763753592968, "critic_loss": 3.3736390600204467, "actor_loss": -90.23999125671386, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.30051398277283, "step": 51000}
{"episode_reward": 663.3086064944658, "episode": 52.0, "batch_reward": 0.19443914670497178, "critic_loss": 3.245252508878708, "actor_loss": -89.55208255004882, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.228386640548706, "step": 52000}
{"episode_reward": 793.6085953197809, "episode": 53.0, "batch_reward": 0.20289572931826114, "critic_loss": 3.1652236257791517, "actor_loss": -89.59291775512695, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.172834396362305, "step": 53000}
{"episode_reward": 481.35703973593974, "episode": 54.0, "batch_reward": 0.21108259376883506, "critic_loss": 3.0889971535205842, "actor_loss": -88.97677774047851, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.817673206329346, "step": 54000}
{"episode_reward": 706.220195973412, "episode": 55.0, "batch_reward": 0.21840632340312005, "critic_loss": 3.0377177109718323, "actor_loss": -88.26803143310546, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.58670997619629, "step": 55000}
{"episode_reward": 749.0287494836388, "episode": 56.0, "batch_reward": 0.22840394791960716, "critic_loss": 2.901038580417633, "actor_loss": -88.22171321105957, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.20224642753601, "step": 56000}
{"episode_reward": 829.7921006872295, "episode": 57.0, "batch_reward": 0.2404436637312174, "critic_loss": 2.760996177792549, "actor_loss": -87.8644083557129, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.70409393310547, "step": 57000}
{"episode_reward": 706.4858681745925, "episode": 58.0, "batch_reward": 0.24927119794487954, "critic_loss": 2.546856876730919, "actor_loss": -87.50837898254395, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.073253393173218, "step": 58000}
{"episode_reward": 741.6128088149235, "episode": 59.0, "batch_reward": 0.25758683574199676, "critic_loss": 2.464489633440971, "actor_loss": -87.00486311340332, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.612140655517578, "step": 59000}
{"episode_reward": 847.4702723098558, "episode": 60.0, "batch_reward": 0.26601373271644113, "critic_loss": 2.4476496974229813, "actor_loss": -86.76584945678711, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.81169819831848, "step": 60000}
{"episode_reward": 787.3693060113598, "episode": 61.0, "batch_reward": 0.27613632471859456, "critic_loss": 2.325248014688492, "actor_loss": -86.6625793762207, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.35807013511658, "step": 61000}
{"episode_reward": 847.7154496958827, "episode": 62.0, "batch_reward": 0.2851146485954523, "critic_loss": 2.3459208191633225, "actor_loss": -86.6433323059082, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.174718379974365, "step": 62000}
{"episode_reward": 892.6430996083498, "episode": 63.0, "batch_reward": 0.2875059538036585, "critic_loss": 2.1380387122631075, "actor_loss": -86.19925709533692, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.10215187072754, "step": 63000}
{"episode_reward": 76.63089588884021, "episode": 64.0, "batch_reward": 0.29157446371018886, "critic_loss": 2.0161347717046736, "actor_loss": -85.76242500305176, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.886486291885376, "step": 64000}
{"episode_reward": 801.9151415246829, "episode": 65.0, "batch_reward": 0.29977330774068833, "critic_loss": 1.9892189291119575, "actor_loss": -85.72924298095703, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.84984803199768, "step": 65000}
{"episode_reward": 842.9192574478059, "episode": 66.0, "batch_reward": 0.30768410237133503, "critic_loss": 1.9997420681118965, "actor_loss": -85.37734049987793, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.97156810760498, "step": 66000}
{"episode_reward": 873.2812755016114, "episode": 67.0, "batch_reward": 0.3154252656400204, "critic_loss": 1.88443329423666, "actor_loss": -85.26778813171387, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.764647960662842, "step": 67000}
{"episode_reward": 790.9066548454198, "episode": 68.0, "batch_reward": 0.32344200015068053, "critic_loss": 1.8217542855143547, "actor_loss": -85.24486146545411, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.15718126296997, "step": 68000}
{"episode_reward": 864.4156954607812, "episode": 69.0, "batch_reward": 0.33163631582260134, "critic_loss": 1.918792976796627, "actor_loss": -85.08042887878418, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.85340452194214, "step": 69000}
{"episode_reward": 873.2092085559527, "episode": 70.0, "batch_reward": 0.33830062295496466, "critic_loss": 1.7566311987638474, "actor_loss": -84.85274906921387, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.051599740982056, "step": 70000}
{"episode_reward": 627.1821841388819, "episode": 71.0, "batch_reward": 0.3394009228944778, "critic_loss": 1.7613553054332733, "actor_loss": -84.51131596374512, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.19667029380798, "step": 71000}
{"episode_reward": 400.4154239588549, "episode": 72.0, "batch_reward": 0.3440637961477041, "critic_loss": 1.729221979677677, "actor_loss": -84.36280632019043, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.785359621047974, "step": 72000}
{"episode_reward": 870.5590066872816, "episode": 73.0, "batch_reward": 0.3490981793999672, "critic_loss": 1.6914353539943696, "actor_loss": -84.15441885375976, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.51448893547058, "step": 73000}
{"episode_reward": 881.2970435056865, "episode": 74.0, "batch_reward": 0.3581782206594944, "critic_loss": 1.6855456632375718, "actor_loss": -84.17152026367188, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.692779064178467, "step": 74000}
{"episode_reward": 892.7557832077788, "episode": 75.0, "batch_reward": 0.36699166405200956, "critic_loss": 1.5799178559184075, "actor_loss": -84.12006460571288, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.09801697731018, "step": 75000}
{"episode_reward": 926.023780475318, "episode": 76.0, "batch_reward": 0.36939340870082377, "critic_loss": 1.5248277183175087, "actor_loss": -84.05192068481445, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.013205766677856, "step": 76000}
{"episode_reward": 23.030915644575582, "episode": 77.0, "batch_reward": 0.36920166125893594, "critic_loss": 1.494920998632908, "actor_loss": -83.88613026428223, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.90157461166382, "step": 77000}
{"episode_reward": 899.6641493122902, "episode": 78.0, "batch_reward": 0.36932667875289915, "critic_loss": 1.5172660044431687, "actor_loss": -83.7153249053955, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.296085119247437, "step": 78000}
{"episode_reward": 29.053223074703315, "episode": 79.0, "batch_reward": 0.3705942128896713, "critic_loss": 1.4070917110443115, "actor_loss": -83.35481604003907, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.850085258483887, "step": 79000}
{"episode_reward": 907.7329591026098, "episode": 80.0, "batch_reward": 0.3771851328611374, "critic_loss": 1.4167163280248642, "actor_loss": -83.32704367065429, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.307276964187622, "step": 80000}
{"episode_reward": 888.1617301713991, "episode": 81.0, "batch_reward": 0.38508226332068446, "critic_loss": 1.4136705540418626, "actor_loss": -83.13575160217285, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.81065630912781, "step": 81000}
{"episode_reward": 934.5741263038042, "episode": 82.0, "batch_reward": 0.3896908692419529, "critic_loss": 1.3308236988186837, "actor_loss": -83.07993737792968, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.7740216255188, "step": 82000}
{"episode_reward": 954.0778124592091, "episode": 83.0, "batch_reward": 0.39617720142006874, "critic_loss": 1.3603655825853347, "actor_loss": -83.03776528930663, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.953802585601807, "step": 83000}
{"episode_reward": 904.4120839369206, "episode": 84.0, "batch_reward": 0.40162277323007584, "critic_loss": 1.4685984657406808, "actor_loss": -83.2065887298584, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.29377007484436, "step": 84000}
{"episode_reward": 835.4553525355905, "episode": 85.0, "batch_reward": 0.4089052374958992, "critic_loss": 1.357792060494423, "actor_loss": -83.5094493713379, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.094538688659668, "step": 85000}
{"episode_reward": 914.1488143060794, "episode": 86.0, "batch_reward": 0.4152152822315693, "critic_loss": 1.2755748629570007, "actor_loss": -83.47724038696289, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.924772262573242, "step": 86000}
{"episode_reward": 921.9389945577698, "episode": 87.0, "batch_reward": 0.42039732909202576, "critic_loss": 1.1879985334277152, "actor_loss": -83.42488331604004, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.723823070526123, "step": 87000}
{"episode_reward": 846.316221132864, "episode": 88.0, "batch_reward": 0.4272507300376892, "critic_loss": 1.1807927258610726, "actor_loss": -83.49804788208007, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.675026655197144, "step": 88000}
{"episode_reward": 935.1630147367877, "episode": 89.0, "batch_reward": 0.43058099210262296, "critic_loss": 1.1335938638448715, "actor_loss": -83.37762721252442, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.433462381362915, "step": 89000}
{"episode_reward": 740.3785657915348, "episode": 90.0, "batch_reward": 0.43379790186882017, "critic_loss": 1.1413170366883278, "actor_loss": -83.13581939697265, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.823045015335083, "step": 90000}
{"episode_reward": 919.374483183141, "episode": 91.0, "batch_reward": 0.44080689558386804, "critic_loss": 1.1607602174282075, "actor_loss": -83.17237046813965, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.83948802947998, "step": 91000}
{"episode_reward": 892.6799151049194, "episode": 92.0, "batch_reward": 0.4456533797979355, "critic_loss": 1.1142479674220085, "actor_loss": -83.11236961364746, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.10259246826172, "step": 92000}
{"episode_reward": 928.4293837875407, "episode": 93.0, "batch_reward": 0.4496170487999916, "critic_loss": 1.1112396688461303, "actor_loss": -82.97412493896485, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.879982709884644, "step": 93000}
{"episode_reward": 964.6836106013742, "episode": 94.0, "batch_reward": 0.4559841360151768, "critic_loss": 1.1797703582048416, "actor_loss": -82.88285005187988, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.670053958892822, "step": 94000}
{"episode_reward": 879.1018308202044, "episode": 95.0, "batch_reward": 0.4604190007448196, "critic_loss": 1.1597215997576713, "actor_loss": -82.62323928833008, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.011688470840454, "step": 95000}
{"episode_reward": 880.1980515875302, "episode": 96.0, "batch_reward": 0.4656280464529991, "critic_loss": 1.2973294909000397, "actor_loss": -82.9988477935791, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.411678791046143, "step": 96000}
{"episode_reward": 928.8241885733837, "episode": 97.0, "batch_reward": 0.4690611138641834, "critic_loss": 1.3333424840569497, "actor_loss": -82.82834535217285, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.30288529396057, "step": 97000}
{"episode_reward": 918.6691806950558, "episode": 98.0, "batch_reward": 0.4729627902805805, "critic_loss": 1.254567911684513, "actor_loss": -82.7817082824707, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.059959173202515, "step": 98000}
{"episode_reward": 923.3801768826153, "episode": 99.0, "batch_reward": 0.47988089126348493, "critic_loss": 1.4079245188236236, "actor_loss": -83.22527592468262, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.200761318206787, "step": 99000}
{"episode_reward": 922.0105536034785, "episode": 100.0, "batch_reward": 0.47973087000846865, "critic_loss": 1.3670628299713135, "actor_loss": -83.20802536010743, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.844491481781006, "step": 100000}
{"episode_reward": 917.9511809904047, "episode": 101.0, "batch_reward": 0.48746865341067314, "critic_loss": 1.3375099255740643, "actor_loss": -83.6521085357666, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.15222358703613, "step": 101000}
{"episode_reward": 971.9197283325569, "episode": 102.0, "batch_reward": 0.48796879735589027, "critic_loss": 1.3902243484258652, "actor_loss": -83.28752296447755, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.186251640319824, "step": 102000}
{"episode_reward": 211.37014088220766, "episode": 103.0, "batch_reward": 0.4887803920805454, "critic_loss": 1.847963684618473, "actor_loss": -83.19825343322753, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.327329635620117, "step": 103000}
{"episode_reward": 669.1364780429324, "episode": 104.0, "batch_reward": 0.4892191412746906, "critic_loss": 1.4106101217269897, "actor_loss": -83.36883113098145, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.534770250320435, "step": 104000}
{"episode_reward": 941.6536704703417, "episode": 105.0, "batch_reward": 0.49633777484297753, "critic_loss": 1.2359332388043405, "actor_loss": -83.61467211914062, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.91948437690735, "step": 105000}
{"episode_reward": 953.1611233868618, "episode": 106.0, "batch_reward": 0.49899935686588287, "critic_loss": 1.6252282282710075, "actor_loss": -83.7140064239502, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.779022216796875, "step": 106000}
{"episode_reward": 942.4604098471926, "episode": 107.0, "batch_reward": 0.5043282298445702, "critic_loss": 2.289585296630859, "actor_loss": -83.66748320007324, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.981625080108643, "step": 107000}
{"episode_reward": 871.5195830077103, "episode": 108.0, "batch_reward": 0.5059404811263084, "critic_loss": 1.7632347509264945, "actor_loss": -83.62624668884277, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.4804584980011, "step": 108000}
{"episode_reward": 910.4447680610848, "episode": 109.0, "batch_reward": 0.5105839007496834, "critic_loss": 2.058764603495598, "actor_loss": -83.8863137512207, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.714298486709595, "step": 109000}
{"episode_reward": 884.3176937500781, "episode": 110.0, "batch_reward": 0.5110001424551011, "critic_loss": 2.6416678001880647, "actor_loss": -84.90784561157227, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.043699741363525, "step": 110000}
{"episode_reward": 47.4704754315743, "episode": 111.0, "batch_reward": 0.5096330756545067, "critic_loss": 1.9300466802716256, "actor_loss": -85.65706398010254, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.162110805511475, "step": 111000}
{"episode_reward": 932.3907619909772, "episode": 112.0, "batch_reward": 0.5135061015486717, "critic_loss": 2.2162110641002655, "actor_loss": -85.96831954956055, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.207183599472046, "step": 112000}
{"episode_reward": 895.8685522903547, "episode": 113.0, "batch_reward": 0.5182696472108365, "critic_loss": 2.6801999545693396, "actor_loss": -85.79347018432617, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.243062496185303, "step": 113000}
{"episode_reward": 965.3844509099782, "episode": 114.0, "batch_reward": 0.5207859658896923, "critic_loss": 1.8135309965610504, "actor_loss": -85.68904322814942, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.811720371246338, "step": 114000}
{"episode_reward": 971.5426457805681, "episode": 115.0, "batch_reward": 0.5204734266698361, "critic_loss": 3.398555159151554, "actor_loss": -86.66729194641113, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.148343563079834, "step": 115000}
{"episode_reward": 47.59671752847769, "episode": 116.0, "batch_reward": 0.5193099370896817, "critic_loss": 3.415538589417934, "actor_loss": -88.67292756652832, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.926248788833618, "step": 116000}
{"episode_reward": 47.14968218030326, "episode": 117.0, "batch_reward": 0.5130916146636009, "critic_loss": 3.693961767375469, "actor_loss": -89.82822442626953, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.9431369304657, "step": 117000}
{"episode_reward": 42.10461895002676, "episode": 118.0, "batch_reward": 0.5106004014909268, "critic_loss": 3.900602241277695, "actor_loss": -90.70476385498047, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.11687994003296, "step": 118000}
{"episode_reward": 41.65285181401615, "episode": 119.0, "batch_reward": 0.5110396194159985, "critic_loss": 4.323232570052147, "actor_loss": -91.17053088378906, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.79933762550354, "step": 119000}
{"episode_reward": 934.8234419110371, "episode": 120.0, "batch_reward": 0.5118890920579433, "critic_loss": 4.847066391706466, "actor_loss": -92.1538094177246, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.546539545059204, "step": 120000}
{"episode_reward": 973.4525533293292, "episode": 121.0, "batch_reward": 0.5124134326279164, "critic_loss": 5.745052166342735, "actor_loss": -93.77887478637696, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.50377917289734, "step": 121000}
{"episode_reward": 48.83820521864897, "episode": 122.0, "batch_reward": 0.5113401156365871, "critic_loss": 6.627725908279419, "actor_loss": -95.88127159118652, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.112154960632324, "step": 122000}
{"episode_reward": 54.74701491113239, "episode": 123.0, "batch_reward": 0.5052352259457111, "critic_loss": 7.481991416811943, "actor_loss": -98.21169532775879, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.11087989807129, "step": 123000}
{"episode_reward": 133.13363994156458, "episode": 124.0, "batch_reward": 0.5037930663228035, "critic_loss": 9.410501369237899, "actor_loss": -100.76815829467773, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.748143911361694, "step": 124000}
{"episode_reward": 81.13590229866718, "episode": 125.0, "batch_reward": 0.5012985845208168, "critic_loss": 11.750212362766266, "actor_loss": -105.58268708801269, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.833699226379395, "step": 125000}
{"episode_reward": 54.80575538691199, "episode": 126.0, "batch_reward": 0.49764014935493467, "critic_loss": 15.978081013679505, "actor_loss": -112.28058052062988, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.291621685028076, "step": 126000}
{"episode_reward": 94.84500871959823, "episode": 127.0, "batch_reward": 0.4915054042935371, "critic_loss": 20.435468272209167, "actor_loss": -118.73754913330077, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.143808126449585, "step": 127000}
{"episode_reward": 119.82401958635116, "episode": 128.0, "batch_reward": 0.48800844222307205, "critic_loss": 25.881303352355957, "actor_loss": -130.39369065856934, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.906925439834595, "step": 128000}
{"episode_reward": 51.0243948140571, "episode": 129.0, "batch_reward": 0.486477857708931, "critic_loss": 29.317836431503295, "actor_loss": -143.91903678894042, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.693493843078613, "step": 129000}
{"episode_reward": 46.735272613815944, "episode": 130.0, "batch_reward": 0.48220405998826027, "critic_loss": 31.481713676452635, "actor_loss": -154.96948574829102, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.00033974647522, "step": 130000}
{"episode_reward": 68.33200365883057, "episode": 131.0, "batch_reward": 0.47942371961474417, "critic_loss": 34.440776894569396, "actor_loss": -161.79587815856934, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.59018802642822, "step": 131000}
{"episode_reward": 89.95122424112576, "episode": 132.0, "batch_reward": 0.4749941738545895, "critic_loss": 32.27723497390747, "actor_loss": -168.64590005493164, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.10849356651306, "step": 132000}
{"episode_reward": 25.461180683173648, "episode": 133.0, "batch_reward": 0.4747153541147709, "critic_loss": 30.137795741081238, "actor_loss": -177.71132933044433, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.24362802505493, "step": 133000}
{"episode_reward": 23.694022681827605, "episode": 134.0, "batch_reward": 0.4701041946411133, "critic_loss": 26.622576484680177, "actor_loss": -179.1858952484131, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.01408576965332, "step": 134000}
{"episode_reward": 21.547874319517376, "episode": 135.0, "batch_reward": 0.4676648753285408, "critic_loss": 24.624705280303957, "actor_loss": -177.48815464782714, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.989633798599243, "step": 135000}
{"episode_reward": 46.917271381386, "episode": 136.0, "batch_reward": 0.4635685788691044, "critic_loss": 20.52757418346405, "actor_loss": -183.0627827758789, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.860854148864746, "step": 136000}
{"episode_reward": 830.2713759652718, "episode": 137.0, "batch_reward": 0.4653962327837944, "critic_loss": 17.503721125125885, "actor_loss": -179.00158232116698, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.66512155532837, "step": 137000}
{"episode_reward": 96.10152873254557, "episode": 138.0, "batch_reward": 0.46339772617816927, "critic_loss": 14.038796653747559, "actor_loss": -175.2852406311035, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.156556606292725, "step": 138000}
{"episode_reward": 22.451239033978286, "episode": 139.0, "batch_reward": 0.4611598045527935, "critic_loss": 12.003375400066377, "actor_loss": -181.3786866607666, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.096444845199585, "step": 139000}
{"episode_reward": 30.221415664942846, "episode": 140.0, "batch_reward": 0.46134175375103953, "critic_loss": 10.131067831039429, "actor_loss": -173.7070387878418, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.45278310775757, "step": 140000}
{"episode_reward": 735.5332201349298, "episode": 141.0, "batch_reward": 0.4586116485595703, "critic_loss": 8.411245598316192, "actor_loss": -168.47108958435058, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.70422148704529, "step": 141000}
{"episode_reward": 50.69229977412986, "episode": 142.0, "batch_reward": 0.45708686324954034, "critic_loss": 7.422037584304809, "actor_loss": -170.91031733703613, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.157124280929565, "step": 142000}
{"episode_reward": 829.7694819538416, "episode": 143.0, "batch_reward": 0.4593547835052013, "critic_loss": 6.114675878763199, "actor_loss": -168.17268522644042, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.821213245391846, "step": 143000}
{"episode_reward": 49.04306475637372, "episode": 144.0, "batch_reward": 0.45956654226779936, "critic_loss": 5.197130362272262, "actor_loss": -163.40506143188477, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.557994604110718, "step": 144000}
{"episode_reward": 897.39684870252, "episode": 145.0, "batch_reward": 0.4625415399670601, "critic_loss": 4.427932420730591, "actor_loss": -157.59143502807618, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.124780654907227, "step": 145000}
{"episode_reward": 883.3231454346303, "episode": 146.0, "batch_reward": 0.4612387853562832, "critic_loss": 3.933388752102852, "actor_loss": -153.17310456848145, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.847695112228394, "step": 146000}
{"episode_reward": 60.025068543239676, "episode": 147.0, "batch_reward": 0.4599805327057838, "critic_loss": 4.034119901061058, "actor_loss": -151.51555004882812, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.104344367980957, "step": 147000}
{"episode_reward": 799.8080123866317, "episode": 148.0, "batch_reward": 0.4640741436779499, "critic_loss": 3.7080241446495057, "actor_loss": -148.47827368164062, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.389180421829224, "step": 148000}
{"episode_reward": 895.5286533566497, "episode": 149.0, "batch_reward": 0.46509599283337594, "critic_loss": 3.8589899077415466, "actor_loss": -146.39210250854492, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.53791046142578, "step": 149000}
{"episode_reward": 969.3810993327945, "episode": 150.0, "batch_reward": 0.47128948441147805, "critic_loss": 3.624012923121452, "actor_loss": -142.10991853332519, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "step": 150000}
