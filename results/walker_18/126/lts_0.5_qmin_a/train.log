{"episode_reward": 0.0, "episode": 1.0, "duration": 22.058117628097534, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.9471209049224854, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.4367643302581675, "critic_loss": 0.07454749565570304, "actor_loss": -44.755873562115916, "actor_target_entropy": -6.0, "alpha_value": 0.002642586817083679, "duration": 63.53107738494873, "step": 3000}
{"episode_reward": 23.488858992752665, "episode": 4.0, "batch_reward": 0.2755761618167162, "critic_loss": 0.14074551688879727, "actor_loss": -39.60844406795502, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.762412786483765, "step": 4000}
{"episode_reward": 6.128886902203733, "episode": 5.0, "batch_reward": 0.22132353679090738, "critic_loss": 0.2367045970931649, "actor_loss": -42.206939877510074, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.62461543083191, "step": 5000}
{"episode_reward": 42.24713966058626, "episode": 6.0, "batch_reward": 0.18482985842227936, "critic_loss": 0.26194595522433517, "actor_loss": -39.02995310878754, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.03155827522278, "step": 6000}
{"episode_reward": 22.24530545162511, "episode": 7.0, "batch_reward": 0.16472716017067432, "critic_loss": 0.44648575990647077, "actor_loss": -39.50835556030273, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.780417680740356, "step": 7000}
{"episode_reward": 98.94304633930491, "episode": 8.0, "batch_reward": 0.16032166691869498, "critic_loss": 1.2633428504317998, "actor_loss": -43.62854636859894, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.28489089012146, "step": 8000}
{"episode_reward": 93.51006316833322, "episode": 9.0, "batch_reward": 0.14815156515687705, "critic_loss": 1.5279660810232163, "actor_loss": -45.38166876983642, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.52780532836914, "step": 9000}
{"episode_reward": 74.72048298990093, "episode": 10.0, "batch_reward": 0.13850499081611634, "critic_loss": 0.9912926805317401, "actor_loss": -46.98366827774048, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.566863536834717, "step": 10000}
{"episode_reward": 28.912271160525325, "episode": 11.0, "batch_reward": 0.1348200875967741, "critic_loss": 1.5527074751257897, "actor_loss": -45.892316528320315, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.28641319274902, "step": 11000}
{"episode_reward": 177.29460698691614, "episode": 12.0, "batch_reward": 0.13224539487063885, "critic_loss": 2.2024842749238016, "actor_loss": -49.213680019378664, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.731260538101196, "step": 12000}
{"episode_reward": 28.033431182113894, "episode": 13.0, "batch_reward": 0.12975486068427564, "critic_loss": 2.918103166103363, "actor_loss": -49.745917667388916, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.78279185295105, "step": 13000}
{"episode_reward": 235.31561221871547, "episode": 14.0, "batch_reward": 0.13575547475367786, "critic_loss": 4.124269839048385, "actor_loss": -53.3279771194458, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.54018998146057, "step": 14000}
{"episode_reward": 142.646680970889, "episode": 15.0, "batch_reward": 0.14183348286896943, "critic_loss": 5.154922500133514, "actor_loss": -54.81232396697998, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.43791913986206, "step": 15000}
{"episode_reward": 361.1213850237859, "episode": 16.0, "batch_reward": 0.15774368170648814, "critic_loss": 6.409911271095276, "actor_loss": -61.758634910583496, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.582443952560425, "step": 16000}
{"episode_reward": 262.0287015074361, "episode": 17.0, "batch_reward": 0.1562908645942807, "critic_loss": 5.67344244813919, "actor_loss": -64.18931543731689, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.517244577407837, "step": 17000}
{"episode_reward": 119.37846304448851, "episode": 18.0, "batch_reward": 0.15409507413953544, "critic_loss": 5.811461958169937, "actor_loss": -67.76244370269775, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.880523681640625, "step": 18000}
{"episode_reward": 133.490275899674, "episode": 19.0, "batch_reward": 0.16041958478093146, "critic_loss": 6.502634455680847, "actor_loss": -70.30859197998046, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.439351558685303, "step": 19000}
{"episode_reward": 300.06949467214844, "episode": 20.0, "batch_reward": 0.16345406194776296, "critic_loss": 5.7341562843322755, "actor_loss": -71.06000871276855, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.854713201522827, "step": 20000}
{"episode_reward": 129.14318585876433, "episode": 21.0, "batch_reward": 0.1574105951860547, "critic_loss": 4.938745002031326, "actor_loss": -72.56191515350342, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.35670566558838, "step": 21000}
{"episode_reward": 68.04368472228843, "episode": 22.0, "batch_reward": 0.15467758650332689, "critic_loss": 5.125826049089432, "actor_loss": -73.30942141723632, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.751728773117065, "step": 22000}
{"episode_reward": 90.377830618955, "episode": 23.0, "batch_reward": 0.15486695168167353, "critic_loss": 5.1372423858642575, "actor_loss": -73.98490043640136, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.576205730438232, "step": 23000}
{"episode_reward": 294.07047217829495, "episode": 24.0, "batch_reward": 0.1601663452759385, "critic_loss": 5.35539862203598, "actor_loss": -74.495489944458, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.744633197784424, "step": 24000}
{"episode_reward": 164.3594680185836, "episode": 25.0, "batch_reward": 0.1644137799590826, "critic_loss": 6.00816042304039, "actor_loss": -75.00397319030762, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.838130235671997, "step": 25000}
{"episode_reward": 343.83841727502255, "episode": 26.0, "batch_reward": 0.16629644418507813, "critic_loss": 5.482325155735015, "actor_loss": -75.60188925170898, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.84690570831299, "step": 26000}
{"episode_reward": 89.05826588255738, "episode": 27.0, "batch_reward": 0.16415630188584326, "critic_loss": 4.7686168081760405, "actor_loss": -75.54347033691407, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.515050888061523, "step": 27000}
{"episode_reward": 167.02241477961852, "episode": 28.0, "batch_reward": 0.1695747992619872, "critic_loss": 4.89757650065422, "actor_loss": -76.18237001037598, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.374696731567383, "step": 28000}
{"episode_reward": 501.9220180261643, "episode": 29.0, "batch_reward": 0.1793979295492172, "critic_loss": 5.182460405349731, "actor_loss": -76.03288648986816, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.51838731765747, "step": 29000}
{"episode_reward": 335.55647164315957, "episode": 30.0, "batch_reward": 0.18168373044580222, "critic_loss": 4.5510068471431735, "actor_loss": -75.83492808532715, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.02764630317688, "step": 30000}
{"episode_reward": 136.8081022859631, "episode": 31.0, "batch_reward": 0.18500287257134915, "critic_loss": 4.72375609588623, "actor_loss": -76.18058529663087, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.432312965393066, "step": 31000}
{"episode_reward": 554.9621731124661, "episode": 32.0, "batch_reward": 0.1932469440549612, "critic_loss": 5.325729032039642, "actor_loss": -76.79007382202148, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.60042643547058, "step": 32000}
{"episode_reward": 205.3199810022828, "episode": 33.0, "batch_reward": 0.19566575417667628, "critic_loss": 4.936363783597947, "actor_loss": -76.94812312316894, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.555202960968018, "step": 33000}
{"episode_reward": 383.17693895601684, "episode": 34.0, "batch_reward": 0.20199852567911147, "critic_loss": 5.250528878211975, "actor_loss": -77.46074841308594, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.25173568725586, "step": 34000}
{"episode_reward": 565.8278683168312, "episode": 35.0, "batch_reward": 0.211677188038826, "critic_loss": 4.905381551742554, "actor_loss": -77.92226853942871, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.688812732696533, "step": 35000}
{"episode_reward": 439.013175744805, "episode": 36.0, "batch_reward": 0.22132765805721283, "critic_loss": 4.822386141300202, "actor_loss": -78.42839102172852, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.782248497009277, "step": 36000}
{"episode_reward": 635.9057888037138, "episode": 37.0, "batch_reward": 0.23567805781960488, "critic_loss": 4.9702056140899655, "actor_loss": -78.75828381347657, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.582361698150635, "step": 37000}
{"episode_reward": 788.4587142898704, "episode": 38.0, "batch_reward": 0.24740388196706772, "critic_loss": 4.897401196718216, "actor_loss": -78.88363368225097, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.6472589969635, "step": 38000}
{"episode_reward": 643.1292157946021, "episode": 39.0, "batch_reward": 0.2595273858457804, "critic_loss": 4.7078198928833, "actor_loss": -79.44902366638183, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.698147535324097, "step": 39000}
{"episode_reward": 805.7587254453616, "episode": 40.0, "batch_reward": 0.2715405675917864, "critic_loss": 4.263272392511368, "actor_loss": -79.90459922790528, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.940035104751587, "step": 40000}
{"episode_reward": 806.9827486009499, "episode": 41.0, "batch_reward": 0.28657869721949103, "critic_loss": 4.140248211503029, "actor_loss": -80.45382737731934, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.98379182815552, "step": 41000}
{"episode_reward": 769.8132448381608, "episode": 42.0, "batch_reward": 0.2990905440300703, "critic_loss": 3.753021402955055, "actor_loss": -80.65024848937988, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.763815879821777, "step": 42000}
{"episode_reward": 846.066707814538, "episode": 43.0, "batch_reward": 0.31089659994840624, "critic_loss": 3.4830055302381515, "actor_loss": -81.14862811279296, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.530554056167603, "step": 43000}
{"episode_reward": 757.4259363798851, "episode": 44.0, "batch_reward": 0.3164867643415928, "critic_loss": 3.3066804245710375, "actor_loss": -81.19207077026367, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.54051375389099, "step": 44000}
{"episode_reward": 522.8080696550993, "episode": 45.0, "batch_reward": 0.326771919593215, "critic_loss": 2.980960116505623, "actor_loss": -81.1663200378418, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.82346224784851, "step": 45000}
{"episode_reward": 836.3348029899122, "episode": 46.0, "batch_reward": 0.3353798441886902, "critic_loss": 2.8475963008403777, "actor_loss": -81.38424732971191, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.725559949874878, "step": 46000}
{"episode_reward": 775.6245838347751, "episode": 47.0, "batch_reward": 0.345856546074152, "critic_loss": 2.804078652381897, "actor_loss": -81.58631114196777, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.54686713218689, "step": 47000}
{"episode_reward": 802.8044999734814, "episode": 48.0, "batch_reward": 0.35652409541606905, "critic_loss": 2.6510620106458664, "actor_loss": -81.46896559143066, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.539830684661865, "step": 48000}
{"episode_reward": 679.4285329957771, "episode": 49.0, "batch_reward": 0.36438017794489863, "critic_loss": 2.5011629427671433, "actor_loss": -81.4657682647705, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.81550884246826, "step": 49000}
{"episode_reward": 860.487894490033, "episode": 50.0, "batch_reward": 0.3736501224040985, "critic_loss": 2.396291893362999, "actor_loss": -81.27266181945801, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.778461694717407, "step": 50000}
{"episode_reward": 790.9463852704662, "episode": 51.0, "batch_reward": 0.3826143823862076, "critic_loss": 2.3382997053265573, "actor_loss": -80.95877699279785, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.310933351516724, "step": 51000}
{"episode_reward": 834.7573351061665, "episode": 52.0, "batch_reward": 0.3907459133565426, "critic_loss": 2.3408448120355607, "actor_loss": -81.46395846557617, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.97278380393982, "step": 52000}
{"episode_reward": 844.0357642615096, "episode": 53.0, "batch_reward": 0.39981481969356536, "critic_loss": 2.1343150681257246, "actor_loss": -80.70424894714355, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.81068730354309, "step": 53000}
{"episode_reward": 837.9008067944004, "episode": 54.0, "batch_reward": 0.4030143968164921, "critic_loss": 2.1686187707185747, "actor_loss": -81.40323167419433, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.633060932159424, "step": 54000}
{"episode_reward": 406.5092121926461, "episode": 55.0, "batch_reward": 0.4059756059348583, "critic_loss": 2.1508220389485357, "actor_loss": -80.98945127868652, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.86876606941223, "step": 55000}
{"episode_reward": 718.2238081702167, "episode": 56.0, "batch_reward": 0.4120260262787342, "critic_loss": 2.121768477022648, "actor_loss": -80.3158551940918, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.5739643573761, "step": 56000}
{"episode_reward": 876.8226995394828, "episode": 57.0, "batch_reward": 0.4239070445895195, "critic_loss": 2.0889405622482298, "actor_loss": -80.47755140686036, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.945136308670044, "step": 57000}
{"episode_reward": 910.7030053910895, "episode": 58.0, "batch_reward": 0.42998509147763253, "critic_loss": 2.0036122498512268, "actor_loss": -80.21538165283204, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.15039300918579, "step": 58000}
{"episode_reward": 883.863866667639, "episode": 59.0, "batch_reward": 0.4310360831618309, "critic_loss": 1.9918469710946083, "actor_loss": -80.49913233947754, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.180601596832275, "step": 59000}
{"episode_reward": 162.62852993467348, "episode": 60.0, "batch_reward": 0.43367745608091357, "critic_loss": 1.9353623658418655, "actor_loss": -80.79856858825684, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.826621294021606, "step": 60000}
{"episode_reward": 864.5168383509991, "episode": 61.0, "batch_reward": 0.4402880689203739, "critic_loss": 1.8520249511003495, "actor_loss": -80.53841506958008, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.31409406661987, "step": 61000}
{"episode_reward": 775.7541274972192, "episode": 62.0, "batch_reward": 0.44579551681876184, "critic_loss": 1.8276839697360991, "actor_loss": -80.04926014709473, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.62024450302124, "step": 62000}
{"episode_reward": 937.8634443300621, "episode": 63.0, "batch_reward": 0.4501344405412674, "critic_loss": 1.9103274817466736, "actor_loss": -80.05987915039063, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.554468631744385, "step": 63000}
{"episode_reward": 617.4075624048478, "episode": 64.0, "batch_reward": 0.45598179411888123, "critic_loss": 1.8412607924342155, "actor_loss": -80.4723657836914, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.67716121673584, "step": 64000}
{"episode_reward": 780.3125673600174, "episode": 65.0, "batch_reward": 0.4627888247072697, "critic_loss": 1.8683372447490691, "actor_loss": -80.29855302429199, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.384774208068848, "step": 65000}
{"episode_reward": 831.5234715743682, "episode": 66.0, "batch_reward": 0.4642588346302509, "critic_loss": 1.8854111312031745, "actor_loss": -80.37064167785644, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.162858963012695, "step": 66000}
{"episode_reward": 824.6086300522505, "episode": 67.0, "batch_reward": 0.4707505566179752, "critic_loss": 1.9201821957826615, "actor_loss": -80.07117184448242, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.758028745651245, "step": 67000}
{"episode_reward": 521.9075757630434, "episode": 68.0, "batch_reward": 0.4728826221227646, "critic_loss": 1.9421156280636787, "actor_loss": -80.48745114135743, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.65969944000244, "step": 68000}
{"episode_reward": 809.3791940246092, "episode": 69.0, "batch_reward": 0.47867338988184926, "critic_loss": 2.0090875343084336, "actor_loss": -80.50598866271973, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.39878797531128, "step": 69000}
{"episode_reward": 877.3722723217174, "episode": 70.0, "batch_reward": 0.4833829555809498, "critic_loss": 1.9948702292442322, "actor_loss": -80.7302642364502, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.36566662788391, "step": 70000}
{"episode_reward": 913.0341301999197, "episode": 71.0, "batch_reward": 0.4882498312294483, "critic_loss": 1.83749811732769, "actor_loss": -80.72323890686035, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.76849341392517, "step": 71000}
{"episode_reward": 923.5963431505687, "episode": 72.0, "batch_reward": 0.4953673256635666, "critic_loss": 1.8972642543315887, "actor_loss": -80.55375981140136, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.621495962142944, "step": 72000}
{"episode_reward": 914.3250340738426, "episode": 73.0, "batch_reward": 0.49996212995052336, "critic_loss": 1.9418206979036332, "actor_loss": -80.51420169067383, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.72225332260132, "step": 73000}
{"episode_reward": 916.1377380921743, "episode": 74.0, "batch_reward": 0.5064161194860936, "critic_loss": 1.820114565849304, "actor_loss": -80.80707832336425, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.00736713409424, "step": 74000}
{"episode_reward": 890.8267611224632, "episode": 75.0, "batch_reward": 0.5140107267796993, "critic_loss": 1.8885594294071197, "actor_loss": -80.93506233215332, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.61778163909912, "step": 75000}
{"episode_reward": 936.150278063865, "episode": 76.0, "batch_reward": 0.5184951771795749, "critic_loss": 1.8853202396035194, "actor_loss": -81.25874459838867, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.537044763565063, "step": 76000}
{"episode_reward": 919.9391932895333, "episode": 77.0, "batch_reward": 0.5254103122353554, "critic_loss": 1.7773046724200248, "actor_loss": -81.2112000579834, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.055886030197144, "step": 77000}
{"episode_reward": 906.9032500751453, "episode": 78.0, "batch_reward": 0.527496954202652, "critic_loss": 1.814691103041172, "actor_loss": -81.1733563079834, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.909857273101807, "step": 78000}
{"episode_reward": 903.8590227760544, "episode": 79.0, "batch_reward": 0.5317525445222855, "critic_loss": 1.7994164432287216, "actor_loss": -81.35805383300782, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.364957571029663, "step": 79000}
{"episode_reward": 881.9458825390844, "episode": 80.0, "batch_reward": 0.5345277519226074, "critic_loss": 1.7138179329633714, "actor_loss": -81.52541505432129, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.5604305267334, "step": 80000}
{"episode_reward": 815.1129243222965, "episode": 81.0, "batch_reward": 0.5427638387978077, "critic_loss": 1.8334474582076072, "actor_loss": -81.6285689086914, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.10095238685608, "step": 81000}
{"episode_reward": 902.4218034104634, "episode": 82.0, "batch_reward": 0.5404349910020828, "critic_loss": 1.7549476009607314, "actor_loss": -81.22567387390137, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.277459383010864, "step": 82000}
{"episode_reward": 880.9374170891325, "episode": 83.0, "batch_reward": 0.5491853758394718, "critic_loss": 1.785327919781208, "actor_loss": -81.98695756530762, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.891778230667114, "step": 83000}
{"episode_reward": 915.955320770695, "episode": 84.0, "batch_reward": 0.5526515732109547, "critic_loss": 1.7440028020739555, "actor_loss": -82.1982122039795, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.62976336479187, "step": 84000}
{"episode_reward": 925.4152692999905, "episode": 85.0, "batch_reward": 0.5561630600094796, "critic_loss": 1.7503545369505882, "actor_loss": -81.51110066223144, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.550182819366455, "step": 85000}
{"episode_reward": 923.5340779387277, "episode": 86.0, "batch_reward": 0.5639952389895916, "critic_loss": 1.7020565024018288, "actor_loss": -82.09510227966308, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.68159317970276, "step": 86000}
{"episode_reward": 946.9292423022121, "episode": 87.0, "batch_reward": 0.5667560124099255, "critic_loss": 1.6717142689824105, "actor_loss": -82.49636009216309, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.228259325027466, "step": 87000}
{"episode_reward": 937.3003976226198, "episode": 88.0, "batch_reward": 0.5732893337607383, "critic_loss": 1.7332877176404, "actor_loss": -82.75728793334962, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.77661156654358, "step": 88000}
{"episode_reward": 970.7838121186792, "episode": 89.0, "batch_reward": 0.5779536427557468, "critic_loss": 1.6365030083060264, "actor_loss": -82.31004998779296, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.034106492996216, "step": 89000}
{"episode_reward": 907.3597325113477, "episode": 90.0, "batch_reward": 0.5791582819819451, "critic_loss": 1.5444258783459663, "actor_loss": -82.63435821533203, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.361263275146484, "step": 90000}
{"episode_reward": 967.7133854953457, "episode": 91.0, "batch_reward": 0.5824487713575364, "critic_loss": 1.5016528620123863, "actor_loss": -82.54782594299317, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.11880660057068, "step": 91000}
{"episode_reward": 850.0030952345568, "episode": 92.0, "batch_reward": 0.5861469776034355, "critic_loss": 1.5016502895951271, "actor_loss": -82.77356111145019, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.676488876342773, "step": 92000}
{"episode_reward": 913.8315408822169, "episode": 93.0, "batch_reward": 0.5915814905762672, "critic_loss": 1.5869797775149346, "actor_loss": -83.11408270263672, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.30933165550232, "step": 93000}
{"episode_reward": 971.9030222555498, "episode": 94.0, "batch_reward": 0.5950279303789139, "critic_loss": 1.4785661650300026, "actor_loss": -83.27686895751953, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.528161764144897, "step": 94000}
{"episode_reward": 861.790707377192, "episode": 95.0, "batch_reward": 0.5958252210915088, "critic_loss": 1.5733339602947236, "actor_loss": -83.4763355102539, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.543084621429443, "step": 95000}
{"episode_reward": 852.8357263821833, "episode": 96.0, "batch_reward": 0.5998066031336784, "critic_loss": 1.4107395769357682, "actor_loss": -83.50917796325683, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.540891885757446, "step": 96000}
{"episode_reward": 925.2395874257118, "episode": 97.0, "batch_reward": 0.6020431623458863, "critic_loss": 1.5061579867005348, "actor_loss": -83.40845526123047, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.84695267677307, "step": 97000}
{"episode_reward": 930.5684833738883, "episode": 98.0, "batch_reward": 0.606687980800867, "critic_loss": 1.5197294769883156, "actor_loss": -83.21630169677735, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.6163809299469, "step": 98000}
{"episode_reward": 952.8245653790832, "episode": 99.0, "batch_reward": 0.6102463728189469, "critic_loss": 1.5251888706088066, "actor_loss": -84.05255149841308, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.983844995498657, "step": 99000}
{"episode_reward": 880.7179430447078, "episode": 100.0, "batch_reward": 0.6086742883622647, "critic_loss": 1.5287246062755584, "actor_loss": -83.78174736022949, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.071756601333618, "step": 100000}
{"episode_reward": 886.8564144794334, "episode": 101.0, "batch_reward": 0.6166067360639572, "critic_loss": 1.6018765100240708, "actor_loss": -84.0077879486084, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.26461863517761, "step": 101000}
{"episode_reward": 940.1003327349933, "episode": 102.0, "batch_reward": 0.6182648113965988, "critic_loss": 1.5448383988142014, "actor_loss": -84.17234439086914, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.53931975364685, "step": 102000}
{"episode_reward": 952.589163169353, "episode": 103.0, "batch_reward": 0.6224959279298783, "critic_loss": 1.582660596013069, "actor_loss": -84.12688450622558, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.495519399642944, "step": 103000}
{"episode_reward": 928.8326858640252, "episode": 104.0, "batch_reward": 0.6199445791244507, "critic_loss": 1.5215748648047447, "actor_loss": -84.45880885314942, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.44559407234192, "step": 104000}
{"episode_reward": 62.79130301135783, "episode": 105.0, "batch_reward": 0.6202944138050079, "critic_loss": 1.5359085758328437, "actor_loss": -84.06496168518066, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.512169361114502, "step": 105000}
{"episode_reward": 935.5593633960634, "episode": 106.0, "batch_reward": 0.6210453533530236, "critic_loss": 1.5406163656711578, "actor_loss": -84.46563021850586, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.528132438659668, "step": 106000}
{"episode_reward": 878.6501068573261, "episode": 107.0, "batch_reward": 0.6247109464406967, "critic_loss": 1.595769312798977, "actor_loss": -84.43715586853027, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.139450311660767, "step": 107000}
{"episode_reward": 893.7199369390269, "episode": 108.0, "batch_reward": 0.625921590924263, "critic_loss": 1.6682224268317223, "actor_loss": -83.9134395904541, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.533318758010864, "step": 108000}
{"episode_reward": 916.0224097335524, "episode": 109.0, "batch_reward": 0.6290030102729798, "critic_loss": 1.608634323656559, "actor_loss": -84.86285697937012, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.88590908050537, "step": 109000}
{"episode_reward": 865.3386875286518, "episode": 110.0, "batch_reward": 0.6312613794207573, "critic_loss": 1.5900074922442435, "actor_loss": -85.10000259399413, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.394111156463623, "step": 110000}
{"episode_reward": 820.7482866012505, "episode": 111.0, "batch_reward": 0.6331560143828392, "critic_loss": 1.5373347863554954, "actor_loss": -84.40457606506348, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.08566737174988, "step": 111000}
{"episode_reward": 935.251884888066, "episode": 112.0, "batch_reward": 0.6371423341035843, "critic_loss": 1.5846571505665779, "actor_loss": -85.4191851348877, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.65360927581787, "step": 112000}
{"episode_reward": 917.240895139766, "episode": 113.0, "batch_reward": 0.6404507437944412, "critic_loss": 1.5016705079674721, "actor_loss": -85.03184526062012, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.55487060546875, "step": 113000}
{"episode_reward": 956.1249944185134, "episode": 114.0, "batch_reward": 0.6408017527461052, "critic_loss": 1.535540815114975, "actor_loss": -85.04897184753418, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.67277431488037, "step": 114000}
{"episode_reward": 976.7660791553789, "episode": 115.0, "batch_reward": 0.6435122054815292, "critic_loss": 1.5221241973042487, "actor_loss": -85.16068276977539, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.237333297729492, "step": 115000}
{"episode_reward": 929.054641046589, "episode": 116.0, "batch_reward": 0.6484947632551193, "critic_loss": 1.5425761425495148, "actor_loss": -85.34756275939941, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.8482825756073, "step": 116000}
{"episode_reward": 885.8731451711556, "episode": 117.0, "batch_reward": 0.6478759484887123, "critic_loss": 1.4488320749402046, "actor_loss": -84.5970549621582, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.779476642608643, "step": 117000}
{"episode_reward": 885.8777460282978, "episode": 118.0, "batch_reward": 0.651493299305439, "critic_loss": 1.4879719881713391, "actor_loss": -85.14088858032227, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.715205192565918, "step": 118000}
{"episode_reward": 949.7720255866, "episode": 119.0, "batch_reward": 0.6538675148487091, "critic_loss": 1.4040868719518185, "actor_loss": -85.36785922241211, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.246984481811523, "step": 119000}
{"episode_reward": 956.578367717474, "episode": 120.0, "batch_reward": 0.6546721803545952, "critic_loss": 1.4846438281536103, "actor_loss": -85.19626498413086, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.473800659179688, "step": 120000}
{"episode_reward": 880.280771511931, "episode": 121.0, "batch_reward": 0.6571120694875717, "critic_loss": 1.4708084385991096, "actor_loss": -85.35144871520995, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.861892223358154, "step": 121000}
{"episode_reward": 908.9301555209344, "episode": 122.0, "batch_reward": 0.6610557777285576, "critic_loss": 1.4506436940431595, "actor_loss": -85.61078952026367, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.75356101989746, "step": 122000}
{"episode_reward": 932.1898660948906, "episode": 123.0, "batch_reward": 0.6625524841547012, "critic_loss": 1.467364652723074, "actor_loss": -85.80564929199218, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.071568489074707, "step": 123000}
{"episode_reward": 872.8547067093319, "episode": 124.0, "batch_reward": 0.6636836050450802, "critic_loss": 1.4184284529387952, "actor_loss": -85.90259617614745, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.791077613830566, "step": 124000}
{"episode_reward": 818.9590907155607, "episode": 125.0, "batch_reward": 0.6642274470329285, "critic_loss": 1.4928699647188186, "actor_loss": -85.89816674804688, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.554285526275635, "step": 125000}
{"episode_reward": 911.4100278749111, "episode": 126.0, "batch_reward": 0.6673365362882614, "critic_loss": 1.4779113807082176, "actor_loss": -85.68964967346191, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.748417615890503, "step": 126000}
{"episode_reward": 969.3668220288167, "episode": 127.0, "batch_reward": 0.6701538609266281, "critic_loss": 1.4675470952391625, "actor_loss": -86.28468374633789, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.055418491363525, "step": 127000}
{"episode_reward": 958.5290049154316, "episode": 128.0, "batch_reward": 0.671123627781868, "critic_loss": 1.452314704567194, "actor_loss": -86.0230708770752, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.14872097969055, "step": 128000}
{"episode_reward": 907.4979902705154, "episode": 129.0, "batch_reward": 0.6733701393604279, "critic_loss": 1.4604557392001152, "actor_loss": -85.98029209899903, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.88403820991516, "step": 129000}
{"episode_reward": 966.3683119152407, "episode": 130.0, "batch_reward": 0.6768278260231018, "critic_loss": 1.4541845793128014, "actor_loss": -86.20270321655273, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.539243698120117, "step": 130000}
{"episode_reward": 945.4720577684502, "episode": 131.0, "batch_reward": 0.6786926081180572, "critic_loss": 1.4312123156189918, "actor_loss": -86.47615185546876, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.371225118637085, "step": 131000}
{"episode_reward": 929.0437178663269, "episode": 132.0, "batch_reward": 0.6771837621331215, "critic_loss": 1.481897336244583, "actor_loss": -86.61431585693359, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.99587368965149, "step": 132000}
{"episode_reward": 915.2921434076774, "episode": 133.0, "batch_reward": 0.6838639469146729, "critic_loss": 1.4569801855385303, "actor_loss": -86.28232145690917, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.470266342163086, "step": 133000}
{"episode_reward": 902.6259388305197, "episode": 134.0, "batch_reward": 0.6829258911013604, "critic_loss": 1.4510524523854256, "actor_loss": -86.18833467102051, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.631460905075073, "step": 134000}
{"episode_reward": 893.4882989410501, "episode": 135.0, "batch_reward": 0.6853222890496254, "critic_loss": 1.3322720058858395, "actor_loss": -86.8868736114502, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.506539583206177, "step": 135000}
{"episode_reward": 939.9636624612504, "episode": 136.0, "batch_reward": 0.6874785143136978, "critic_loss": 1.3607816994786261, "actor_loss": -85.9540885925293, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.02207064628601, "step": 136000}
{"episode_reward": 884.3182312829778, "episode": 137.0, "batch_reward": 0.6864239008426666, "critic_loss": 1.396207692116499, "actor_loss": -86.84499099731445, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.139426708221436, "step": 137000}
{"episode_reward": 940.421494960102, "episode": 138.0, "batch_reward": 0.6909751896858215, "critic_loss": 1.398975051879883, "actor_loss": -86.90202183532715, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.685003757476807, "step": 138000}
{"episode_reward": 960.2388070224868, "episode": 139.0, "batch_reward": 0.6947119046449661, "critic_loss": 1.4249163646697998, "actor_loss": -87.00965489196777, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.05042314529419, "step": 139000}
{"episode_reward": 952.3104738407791, "episode": 140.0, "batch_reward": 0.6966119774580002, "critic_loss": 1.3511369421780108, "actor_loss": -87.2211436920166, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.238223791122437, "step": 140000}
{"episode_reward": 950.6503993858887, "episode": 141.0, "batch_reward": 0.6945672069787979, "critic_loss": 1.3383438045680522, "actor_loss": -87.12017300415039, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.953115940093994, "step": 141000}
{"episode_reward": 904.8407644908484, "episode": 142.0, "batch_reward": 0.6959267398118972, "critic_loss": 1.3215440075099467, "actor_loss": -86.76868022155762, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.972646951675415, "step": 142000}
{"episode_reward": 936.2217212961663, "episode": 143.0, "batch_reward": 0.6970397317409516, "critic_loss": 1.3607127940058708, "actor_loss": -86.83278048706055, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.245800256729126, "step": 143000}
{"episode_reward": 886.315589832702, "episode": 144.0, "batch_reward": 0.7022958685755729, "critic_loss": 1.294474434554577, "actor_loss": -87.56271650695801, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.897165536880493, "step": 144000}
{"episode_reward": 946.212589205904, "episode": 145.0, "batch_reward": 0.7021345242857933, "critic_loss": 1.2404864853024482, "actor_loss": -87.53374726867676, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.680063009262085, "step": 145000}
{"episode_reward": 903.0652869985203, "episode": 146.0, "batch_reward": 0.7024350291490555, "critic_loss": 1.2628719638884067, "actor_loss": -87.5252817993164, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.53941249847412, "step": 146000}
{"episode_reward": 938.521496517563, "episode": 147.0, "batch_reward": 0.7040485597848892, "critic_loss": 1.1596441623866558, "actor_loss": -87.57124279785157, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.92627263069153, "step": 147000}
{"episode_reward": 866.9096676894374, "episode": 148.0, "batch_reward": 0.705722304046154, "critic_loss": 1.2708838688731194, "actor_loss": -87.48672428894044, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.499346017837524, "step": 148000}
{"episode_reward": 948.4522437839368, "episode": 149.0, "batch_reward": 0.7077064085006713, "critic_loss": 1.1844683402180671, "actor_loss": -87.59391867065429, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.002033233642578, "step": 149000}
{"episode_reward": 983.1049554622712, "episode": 150.0, "batch_reward": 0.7097205210328102, "critic_loss": 1.2152037143409251, "actor_loss": -87.65983540344239, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "step": 150000}
