{"episode_reward": 0.0, "episode": 1.0, "duration": 22.21929693222046, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.9270238876342773, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.4699285299768445, "critic_loss": 0.1935650577241379, "actor_loss": -83.81089998865757, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 70.92796444892883, "step": 3000}
{"episode_reward": 583.314126017699, "episode": 4.0, "batch_reward": 0.5176458300948144, "critic_loss": 0.400801510617137, "actor_loss": -85.37508982849121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.591129541397095, "step": 4000}
{"episode_reward": 682.2155911065919, "episode": 5.0, "batch_reward": 0.5473614647090435, "critic_loss": 0.79604575958848, "actor_loss": -86.56057618713379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.57732892036438, "step": 5000}
{"episode_reward": 604.6027653347412, "episode": 6.0, "batch_reward": 0.5613330676853657, "critic_loss": 0.8541272361576557, "actor_loss": -87.23220890808105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.53528618812561, "step": 6000}
{"episode_reward": 670.8949017379387, "episode": 7.0, "batch_reward": 0.5773148364424705, "critic_loss": 0.9587784707546234, "actor_loss": -87.39782345581055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.53998565673828, "step": 7000}
{"episode_reward": 661.2210354929, "episode": 8.0, "batch_reward": 0.6057978736162186, "critic_loss": 0.944910603761673, "actor_loss": -88.29399645996094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.508288383483887, "step": 8000}
{"episode_reward": 816.9540861461214, "episode": 9.0, "batch_reward": 0.6219944195747376, "critic_loss": 1.0733585065603257, "actor_loss": -88.61416757202149, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.53137469291687, "step": 9000}
{"episode_reward": 647.8769988008148, "episode": 10.0, "batch_reward": 0.6326628625392914, "critic_loss": 1.1945639914274215, "actor_loss": -88.90223245239258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.541761875152588, "step": 10000}
{"episode_reward": 803.6533509466005, "episode": 11.0, "batch_reward": 0.6475113697648048, "critic_loss": 1.2023943601250648, "actor_loss": -89.45572476196288, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.20579695701599, "step": 11000}
{"episode_reward": 793.9673777818692, "episode": 12.0, "batch_reward": 0.6616054019927978, "critic_loss": 1.2365265113711357, "actor_loss": -89.73142567443848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.97981595993042, "step": 12000}
{"episode_reward": 860.3086692382823, "episode": 13.0, "batch_reward": 0.6772167732715607, "critic_loss": 1.188708080947399, "actor_loss": -90.12837313842773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.608781337738037, "step": 13000}
{"episode_reward": 851.7029415127778, "episode": 14.0, "batch_reward": 0.6884196774363518, "critic_loss": 1.1182853684425353, "actor_loss": -90.3364557800293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.628570318222046, "step": 14000}
{"episode_reward": 894.4631566944355, "episode": 15.0, "batch_reward": 0.7031228575706482, "critic_loss": 0.9788804615736008, "actor_loss": -90.43711065673828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.601168870925903, "step": 15000}
{"episode_reward": 872.28652069282, "episode": 16.0, "batch_reward": 0.7177968199253082, "critic_loss": 0.8970049700438977, "actor_loss": -91.18864785766601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.606464385986328, "step": 16000}
{"episode_reward": 929.9089848210705, "episode": 17.0, "batch_reward": 0.7268152415156365, "critic_loss": 0.8461486266851426, "actor_loss": -91.29986791992188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.587629318237305, "step": 17000}
{"episode_reward": 855.6903167309433, "episode": 18.0, "batch_reward": 0.7351150801777839, "critic_loss": 0.8327165985405445, "actor_loss": -91.4854094543457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.617511510849, "step": 18000}
{"episode_reward": 897.2380838746769, "episode": 19.0, "batch_reward": 0.7454447221159936, "critic_loss": 0.750257296860218, "actor_loss": -91.65649765014649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.58936858177185, "step": 19000}
{"episode_reward": 907.0917689322551, "episode": 20.0, "batch_reward": 0.7506014793515206, "critic_loss": 0.8217356933951377, "actor_loss": -91.5270909576416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.715517282485962, "step": 20000}
{"episode_reward": 824.0289485414309, "episode": 21.0, "batch_reward": 0.756580985724926, "critic_loss": 0.7488253765106201, "actor_loss": -91.71974755859375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.43088984489441, "step": 21000}
{"episode_reward": 930.2312472246948, "episode": 22.0, "batch_reward": 0.7657272788882256, "critic_loss": 0.7172700874507427, "actor_loss": -91.87085185241699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.632691860198975, "step": 22000}
{"episode_reward": 924.4217843320247, "episode": 23.0, "batch_reward": 0.7708160273432731, "critic_loss": 0.6939408414065837, "actor_loss": -91.9905610961914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.622607231140137, "step": 23000}
{"episode_reward": 909.0200983222975, "episode": 24.0, "batch_reward": 0.7789598388075829, "critic_loss": 0.6396948192119598, "actor_loss": -92.22384817504883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.662619829177856, "step": 24000}
{"episode_reward": 943.7339970550604, "episode": 25.0, "batch_reward": 0.784866133749485, "critic_loss": 0.6284323623776435, "actor_loss": -92.27970506286621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.648619413375854, "step": 25000}
{"episode_reward": 906.8987329522107, "episode": 26.0, "batch_reward": 0.7826350150704384, "critic_loss": 0.6819947783946991, "actor_loss": -92.1955972442627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.578285694122314, "step": 26000}
{"episode_reward": 349.4925948069027, "episode": 27.0, "batch_reward": 0.7752302156090737, "critic_loss": 0.6564979124069213, "actor_loss": -91.93180819702148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.618894338607788, "step": 27000}
{"episode_reward": 954.3797801075972, "episode": 28.0, "batch_reward": 0.7796681113243104, "critic_loss": 0.6253443233668804, "actor_loss": -92.13512368774414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.570085525512695, "step": 28000}
{"episode_reward": 924.2926102579288, "episode": 29.0, "batch_reward": 0.7866320486664772, "critic_loss": 0.6208276788294316, "actor_loss": -92.11669555664062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.63493251800537, "step": 29000}
{"episode_reward": 965.5404313190852, "episode": 30.0, "batch_reward": 0.7813314722776413, "critic_loss": 0.6130823547244072, "actor_loss": -91.88399455261231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.579737901687622, "step": 30000}
{"episode_reward": 598.5132627538769, "episode": 31.0, "batch_reward": 0.7827459105849266, "critic_loss": 0.6623556989729404, "actor_loss": -91.95597981262208, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.37213969230652, "step": 31000}
{"episode_reward": 880.3052918236315, "episode": 32.0, "batch_reward": 0.7874700172543526, "critic_loss": 0.6630689794421196, "actor_loss": -92.05512731933594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.587528228759766, "step": 32000}
{"episode_reward": 925.0490013159292, "episode": 33.0, "batch_reward": 0.7905138693451882, "critic_loss": 0.6637079900503159, "actor_loss": -92.06481666564942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.595839977264404, "step": 33000}
{"episode_reward": 909.8109972318925, "episode": 34.0, "batch_reward": 0.7935311207175255, "critic_loss": 0.6534107365608215, "actor_loss": -92.34166850280762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.574790477752686, "step": 34000}
{"episode_reward": 812.9796198913938, "episode": 35.0, "batch_reward": 0.7976771965026855, "critic_loss": 0.6462930115163327, "actor_loss": -92.28742083740234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.57360339164734, "step": 35000}
{"episode_reward": 917.4442349790106, "episode": 36.0, "batch_reward": 0.7990409768223763, "critic_loss": 0.6530826235413552, "actor_loss": -92.52716499328614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.571110486984253, "step": 36000}
{"episode_reward": 869.9630465659505, "episode": 37.0, "batch_reward": 0.8020398136377335, "critic_loss": 0.6442246385514736, "actor_loss": -92.54066082763671, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.548242807388306, "step": 37000}
{"episode_reward": 949.6023434393827, "episode": 38.0, "batch_reward": 0.8053824828863144, "critic_loss": 0.6241856519281864, "actor_loss": -92.46134603881836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.548259496688843, "step": 38000}
{"episode_reward": 917.7175825337519, "episode": 39.0, "batch_reward": 0.8089021428823471, "critic_loss": 0.611924456179142, "actor_loss": -92.69260720825196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.598248958587646, "step": 39000}
{"episode_reward": 941.4767145708137, "episode": 40.0, "batch_reward": 0.8119250256419182, "critic_loss": 0.6055632828474045, "actor_loss": -92.72625299072266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.57488179206848, "step": 40000}
{"episode_reward": 882.4071606317139, "episode": 41.0, "batch_reward": 0.8119703657627105, "critic_loss": 0.6298371682167053, "actor_loss": -92.84774349975586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.21546745300293, "step": 41000}
{"episode_reward": 875.8991937409774, "episode": 42.0, "batch_reward": 0.8124704825282096, "critic_loss": 0.6004877945482731, "actor_loss": -92.64301773071288, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.448084115982056, "step": 42000}
{"episode_reward": 817.9998976333221, "episode": 43.0, "batch_reward": 0.8157990617752076, "critic_loss": 0.6029270516335964, "actor_loss": -92.86001298522949, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.906121969223022, "step": 43000}
{"episode_reward": 936.5563363490319, "episode": 44.0, "batch_reward": 0.8163917984962463, "critic_loss": 0.6115490103960037, "actor_loss": -92.74865509033204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.6234929561615, "step": 44000}
{"episode_reward": 827.2337057677585, "episode": 45.0, "batch_reward": 0.8177052166461944, "critic_loss": 0.6336071491837502, "actor_loss": -92.71008082580566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.62785792350769, "step": 45000}
{"episode_reward": 930.2178911501856, "episode": 46.0, "batch_reward": 0.8209340313673019, "critic_loss": 0.6502264059185981, "actor_loss": -92.92499592590332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.622185230255127, "step": 46000}
{"episode_reward": 873.8828141699349, "episode": 47.0, "batch_reward": 0.8218015550971031, "critic_loss": 0.6709507892727852, "actor_loss": -92.99978909301758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.620887517929077, "step": 47000}
{"episode_reward": 868.5934797514574, "episode": 48.0, "batch_reward": 0.8232992137074471, "critic_loss": 0.6504517183303833, "actor_loss": -93.01622409057617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.613950967788696, "step": 48000}
{"episode_reward": 959.9510952553885, "episode": 49.0, "batch_reward": 0.8248553347587585, "critic_loss": 0.6498958335220814, "actor_loss": -93.02870964050292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.68514132499695, "step": 49000}
{"episode_reward": 878.6722297379949, "episode": 50.0, "batch_reward": 0.8266210094094276, "critic_loss": 0.6581668403744697, "actor_loss": -92.96575859069824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.599499225616455, "step": 50000}
{"episode_reward": 880.2746349422143, "episode": 51.0, "batch_reward": 0.8284845837950706, "critic_loss": 0.6526393980383873, "actor_loss": -93.13234152221679, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.36972904205322, "step": 51000}
{"episode_reward": 909.9572735632305, "episode": 52.0, "batch_reward": 0.8294564744234085, "critic_loss": 0.6609846514761448, "actor_loss": -93.17916394042969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.637763738632202, "step": 52000}
{"episode_reward": 905.2639537695603, "episode": 53.0, "batch_reward": 0.8318843165636063, "critic_loss": 0.623433345913887, "actor_loss": -92.97145780944824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.62438702583313, "step": 53000}
{"episode_reward": 924.735258486821, "episode": 54.0, "batch_reward": 0.832783521771431, "critic_loss": 0.626955826997757, "actor_loss": -93.44376623535156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.575078010559082, "step": 54000}
{"episode_reward": 938.3825435713984, "episode": 55.0, "batch_reward": 0.8338960351943969, "critic_loss": 0.5957732167840004, "actor_loss": -93.32449069213867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.663996696472168, "step": 55000}
{"episode_reward": 958.3180058852813, "episode": 56.0, "batch_reward": 0.8370656513571739, "critic_loss": 0.5823594523966312, "actor_loss": -93.16929983520508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.660121202468872, "step": 56000}
{"episode_reward": 975.5959907129269, "episode": 57.0, "batch_reward": 0.8382497754096985, "critic_loss": 0.5885922751128674, "actor_loss": -93.37267552185058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.61032223701477, "step": 57000}
{"episode_reward": 862.7365389696804, "episode": 58.0, "batch_reward": 0.8393814751505851, "critic_loss": 0.5888247693181038, "actor_loss": -93.39474554443359, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.693222761154175, "step": 58000}
{"episode_reward": 914.4196779038092, "episode": 59.0, "batch_reward": 0.8408993038535119, "critic_loss": 0.5691103786677122, "actor_loss": -93.49740156555175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.63440442085266, "step": 59000}
{"episode_reward": 884.6465780409493, "episode": 60.0, "batch_reward": 0.8416935557723045, "critic_loss": 0.6106285141408443, "actor_loss": -93.36845573425293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.634254932403564, "step": 60000}
{"episode_reward": 924.8384040083171, "episode": 61.0, "batch_reward": 0.8421839602589607, "critic_loss": 0.6289541134536266, "actor_loss": -93.51084158325196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.34888482093811, "step": 61000}
{"episode_reward": 864.3026629154091, "episode": 62.0, "batch_reward": 0.8418806849122047, "critic_loss": 0.620486911907792, "actor_loss": -93.31060382080078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.649160623550415, "step": 62000}
{"episode_reward": 948.8413705434976, "episode": 63.0, "batch_reward": 0.8430810870528221, "critic_loss": 0.6289787713289261, "actor_loss": -93.40003707885742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.626718044281006, "step": 63000}
{"episode_reward": 924.2991795917814, "episode": 64.0, "batch_reward": 0.8456886646747589, "critic_loss": 0.6135093947350979, "actor_loss": -93.58998731994629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.638949632644653, "step": 64000}
{"episode_reward": 918.3928655485247, "episode": 65.0, "batch_reward": 0.8471154437065125, "critic_loss": 0.5959743690043687, "actor_loss": -93.45986642456054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.630425691604614, "step": 65000}
{"episode_reward": 913.1635322578436, "episode": 66.0, "batch_reward": 0.8483443871736527, "critic_loss": 0.5787015190720558, "actor_loss": -93.55705680847169, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.592427253723145, "step": 66000}
{"episode_reward": 948.3672559872466, "episode": 67.0, "batch_reward": 0.8509137170314789, "critic_loss": 0.586239028096199, "actor_loss": -93.58884950256348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.581013679504395, "step": 67000}
{"episode_reward": 938.7399669952008, "episode": 68.0, "batch_reward": 0.8509504630565643, "critic_loss": 0.5568488043546677, "actor_loss": -93.82357083129882, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.60346555709839, "step": 68000}
{"episode_reward": 940.3094787057252, "episode": 69.0, "batch_reward": 0.853377818763256, "critic_loss": 0.5540677512437105, "actor_loss": -93.8228175201416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.564291954040527, "step": 69000}
{"episode_reward": 934.5380927429205, "episode": 70.0, "batch_reward": 0.8534081346392631, "critic_loss": 0.5632003278434277, "actor_loss": -93.93525033569335, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.54648780822754, "step": 70000}
{"episode_reward": 927.9634594199304, "episode": 71.0, "batch_reward": 0.8543865228891373, "critic_loss": 0.5615595665574074, "actor_loss": -93.7126902923584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.21555304527283, "step": 71000}
{"episode_reward": 938.0887519031377, "episode": 72.0, "batch_reward": 0.8563349070549011, "critic_loss": 0.5492887966185808, "actor_loss": -93.95676727294922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.532296180725098, "step": 72000}
{"episode_reward": 910.1930594357017, "episode": 73.0, "batch_reward": 0.8523500848412514, "critic_loss": 0.5529711851924658, "actor_loss": -93.90729841613769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.476449251174927, "step": 73000}
{"episode_reward": 537.6146882336316, "episode": 74.0, "batch_reward": 0.8512825201749802, "critic_loss": 0.5741148288697004, "actor_loss": -93.82297943115235, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.888809204101562, "step": 74000}
{"episode_reward": 891.2797127860086, "episode": 75.0, "batch_reward": 0.854546369612217, "critic_loss": 0.5531125733703375, "actor_loss": -93.96157708740235, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.624433279037476, "step": 75000}
{"episode_reward": 951.0340675911353, "episode": 76.0, "batch_reward": 0.8542214308381081, "critic_loss": 0.5878767096698284, "actor_loss": -93.98091180419922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.645142555236816, "step": 76000}
{"episode_reward": 938.3051725028054, "episode": 77.0, "batch_reward": 0.8560145965814591, "critic_loss": 0.5676733805835247, "actor_loss": -93.96101789855958, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.66681671142578, "step": 77000}
{"episode_reward": 970.2959135778397, "episode": 78.0, "batch_reward": 0.8564501224756241, "critic_loss": 0.5634851181060075, "actor_loss": -93.99509558105468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.66845941543579, "step": 78000}
{"episode_reward": 891.41525829105, "episode": 79.0, "batch_reward": 0.8554784094691277, "critic_loss": 0.55469080093503, "actor_loss": -94.02224830627442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.649896144866943, "step": 79000}
{"episode_reward": 917.2807617302017, "episode": 80.0, "batch_reward": 0.8560070121288299, "critic_loss": 0.5795678189694882, "actor_loss": -94.04118283081054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.64778161048889, "step": 80000}
{"episode_reward": 396.47667587154365, "episode": 81.0, "batch_reward": 0.8525403186678886, "critic_loss": 0.6008799907565117, "actor_loss": -93.79956187438965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.3897705078125, "step": 81000}
{"episode_reward": 936.5333831301741, "episode": 82.0, "batch_reward": 0.8515163095593452, "critic_loss": 0.5916527246236801, "actor_loss": -93.83743609619141, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.598495960235596, "step": 82000}
{"episode_reward": 910.3999275361482, "episode": 83.0, "batch_reward": 0.8542878332138062, "critic_loss": 0.5724275236874818, "actor_loss": -94.08421684265137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.627980947494507, "step": 83000}
{"episode_reward": 950.0200083562501, "episode": 84.0, "batch_reward": 0.8531507216095925, "critic_loss": 0.6132687757462263, "actor_loss": -94.06484741210937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.633123636245728, "step": 84000}
{"episode_reward": 868.3106171434913, "episode": 85.0, "batch_reward": 0.8542679742574691, "critic_loss": 0.6203320564776659, "actor_loss": -93.88608735656739, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.587236881256104, "step": 85000}
{"episode_reward": 938.1344060472188, "episode": 86.0, "batch_reward": 0.8566131509542465, "critic_loss": 0.6194482755064964, "actor_loss": -93.97198820495605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.6403865814209, "step": 86000}
{"episode_reward": 949.1875702745731, "episode": 87.0, "batch_reward": 0.8570255455970764, "critic_loss": 0.6153193439096213, "actor_loss": -94.07876228332519, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.651597261428833, "step": 87000}
{"episode_reward": 892.6239240039796, "episode": 88.0, "batch_reward": 0.8575466169118882, "critic_loss": 0.5791986303180456, "actor_loss": -94.11754804992675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.606961727142334, "step": 88000}
{"episode_reward": 969.3866213507953, "episode": 89.0, "batch_reward": 0.8593227119445801, "critic_loss": 0.6170559882819653, "actor_loss": -94.04719052124024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.662862300872803, "step": 89000}
{"episode_reward": 938.7608468286984, "episode": 90.0, "batch_reward": 0.8604213947057724, "critic_loss": 0.5904481904357671, "actor_loss": -94.15077801513672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.577972888946533, "step": 90000}
{"episode_reward": 958.5518308944938, "episode": 91.0, "batch_reward": 0.8616783019304276, "critic_loss": 0.5867762651890517, "actor_loss": -94.11604475402832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.30514574050903, "step": 91000}
{"episode_reward": 920.7024394163712, "episode": 92.0, "batch_reward": 0.8625051739215851, "critic_loss": 0.5759694451093673, "actor_loss": -94.18824909973145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.609285354614258, "step": 92000}
{"episode_reward": 951.1989032500225, "episode": 93.0, "batch_reward": 0.8638349632024765, "critic_loss": 0.5693160002231598, "actor_loss": -94.27288818359375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.617852926254272, "step": 93000}
{"episode_reward": 919.9442424405057, "episode": 94.0, "batch_reward": 0.8630801617503167, "critic_loss": 0.612360752493143, "actor_loss": -94.35778295898437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.60385537147522, "step": 94000}
{"episode_reward": 908.4764753693808, "episode": 95.0, "batch_reward": 0.8635493280291557, "critic_loss": 0.6284267272502184, "actor_loss": -94.37447718811035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.57246446609497, "step": 95000}
{"episode_reward": 939.5721100982058, "episode": 96.0, "batch_reward": 0.8649858704209328, "critic_loss": 0.6131398686915636, "actor_loss": -94.29463299560547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.60948133468628, "step": 96000}
{"episode_reward": 910.8870135234243, "episode": 97.0, "batch_reward": 0.8643078270554543, "critic_loss": 0.618153845012188, "actor_loss": -94.30011303710937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.591811180114746, "step": 97000}
{"episode_reward": 933.5145866254788, "episode": 98.0, "batch_reward": 0.8658159762620926, "critic_loss": 0.6222399662137031, "actor_loss": -94.2843482055664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.635541200637817, "step": 98000}
{"episode_reward": 936.452063825883, "episode": 99.0, "batch_reward": 0.866470771253109, "critic_loss": 0.6371853352338076, "actor_loss": -94.32806196594238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.568060874938965, "step": 99000}
{"episode_reward": 925.1181304601215, "episode": 100.0, "batch_reward": 0.8652697765231132, "critic_loss": 0.6327761506438255, "actor_loss": -94.35273237609863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.574981927871704, "step": 100000}
{"episode_reward": 952.4586150840511, "episode": 101.0, "batch_reward": 0.868013187944889, "critic_loss": 0.620668250516057, "actor_loss": -94.36775323486329, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.2531464099884, "step": 101000}
{"episode_reward": 948.0230498732152, "episode": 102.0, "batch_reward": 0.8690165366530418, "critic_loss": 0.6318544784784317, "actor_loss": -94.52754779052735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.498541355133057, "step": 102000}
{"episode_reward": 951.3852890485938, "episode": 103.0, "batch_reward": 0.8695903614759445, "critic_loss": 0.6062831023037434, "actor_loss": -94.35104316711426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.528330087661743, "step": 103000}
{"episode_reward": 936.7518611733891, "episode": 104.0, "batch_reward": 0.8691523231863976, "critic_loss": 0.5892744170427322, "actor_loss": -94.44480230712891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.462926149368286, "step": 104000}
{"episode_reward": 924.0832461887512, "episode": 105.0, "batch_reward": 0.8698397033810615, "critic_loss": 0.6263397319167853, "actor_loss": -94.28902778625488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.824079036712646, "step": 105000}
{"episode_reward": 877.3428251254622, "episode": 106.0, "batch_reward": 0.8704031191468239, "critic_loss": 0.6551533831655979, "actor_loss": -94.57448684692383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.647894382476807, "step": 106000}
{"episode_reward": 925.1709696525883, "episode": 107.0, "batch_reward": 0.8703668228387833, "critic_loss": 0.6602371123731137, "actor_loss": -94.43376849365234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.849794149398804, "step": 107000}
{"episode_reward": 904.8086330333305, "episode": 108.0, "batch_reward": 0.8706600551009178, "critic_loss": 0.6357187491208315, "actor_loss": -94.31372262573242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.660568952560425, "step": 108000}
{"episode_reward": 939.0269834912758, "episode": 109.0, "batch_reward": 0.8710930364727973, "critic_loss": 0.6167999764680863, "actor_loss": -94.49971154785156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.82126522064209, "step": 109000}
{"episode_reward": 923.9655611881595, "episode": 110.0, "batch_reward": 0.8735685427188873, "critic_loss": 0.6163434906452894, "actor_loss": -94.49088534545898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.608717679977417, "step": 110000}
{"episode_reward": 939.3878868427001, "episode": 111.0, "batch_reward": 0.8728926883935928, "critic_loss": 0.6153301389962434, "actor_loss": -94.4288108215332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.28828454017639, "step": 111000}
{"episode_reward": 915.7750702126087, "episode": 112.0, "batch_reward": 0.8731448100805282, "critic_loss": 0.5986427228748799, "actor_loss": -94.56651847839356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.63156247138977, "step": 112000}
{"episode_reward": 921.8483045439573, "episode": 113.0, "batch_reward": 0.8744907298088074, "critic_loss": 0.5891542897522449, "actor_loss": -94.58137228393555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.60115647315979, "step": 113000}
{"episode_reward": 905.0502641925028, "episode": 114.0, "batch_reward": 0.8730221253037452, "critic_loss": 0.5728706733137369, "actor_loss": -94.64635734558105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.630104303359985, "step": 114000}
{"episode_reward": 974.1111944214343, "episode": 115.0, "batch_reward": 0.8749063622951507, "critic_loss": 0.5590946531891823, "actor_loss": -94.62381481933593, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.62764072418213, "step": 115000}
{"episode_reward": 939.9083277997594, "episode": 116.0, "batch_reward": 0.8761095038056373, "critic_loss": 0.5764904893487692, "actor_loss": -94.67134184265137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.5687313079834, "step": 116000}
{"episode_reward": 913.3182991824726, "episode": 117.0, "batch_reward": 0.8765425260663032, "critic_loss": 0.5866925368458032, "actor_loss": -94.5742612915039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.68864631652832, "step": 117000}
{"episode_reward": 909.0218471150837, "episode": 118.0, "batch_reward": 0.8752957585453988, "critic_loss": 0.5882878794074059, "actor_loss": -94.60909866333007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.645188570022583, "step": 118000}
{"episode_reward": 919.6602189854063, "episode": 119.0, "batch_reward": 0.876566519856453, "critic_loss": 0.5946844693571329, "actor_loss": -94.64497453308105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.599903345108032, "step": 119000}
{"episode_reward": 898.8011412324342, "episode": 120.0, "batch_reward": 0.8767128305435181, "critic_loss": 0.616498255431652, "actor_loss": -94.57296018981934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.630345821380615, "step": 120000}
{"episode_reward": 958.9664330900658, "episode": 121.0, "batch_reward": 0.8778704836964607, "critic_loss": 0.5766666348874568, "actor_loss": -94.65176014709472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.328852891922, "step": 121000}
{"episode_reward": 881.4440894608742, "episode": 122.0, "batch_reward": 0.8768922189474105, "critic_loss": 0.5659229848831892, "actor_loss": -94.67561871337891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.546205520629883, "step": 122000}
{"episode_reward": 907.9649439084101, "episode": 123.0, "batch_reward": 0.8777056087851525, "critic_loss": 0.582617172345519, "actor_loss": -94.83457308959962, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.59606099128723, "step": 123000}
{"episode_reward": 939.493278740442, "episode": 124.0, "batch_reward": 0.8789603163003922, "critic_loss": 0.6239871457517147, "actor_loss": -94.82057257080078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.60214376449585, "step": 124000}
{"episode_reward": 916.4831102268856, "episode": 125.0, "batch_reward": 0.8777038490772248, "critic_loss": 0.6429340653568506, "actor_loss": -94.77281759643554, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.60160207748413, "step": 125000}
{"episode_reward": 903.9422866347286, "episode": 126.0, "batch_reward": 0.8801511211395263, "critic_loss": 0.5924707026928663, "actor_loss": -94.76484408569335, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.588576316833496, "step": 126000}
{"episode_reward": 901.5640978977651, "episode": 127.0, "batch_reward": 0.8790439868569374, "critic_loss": 0.6223716663718224, "actor_loss": -94.73129499816895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.623584747314453, "step": 127000}
{"episode_reward": 934.550793783679, "episode": 128.0, "batch_reward": 0.8791427746415138, "critic_loss": 0.6017869589477778, "actor_loss": -94.7745240020752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.580752849578857, "step": 128000}
{"episode_reward": 907.8577423605814, "episode": 129.0, "batch_reward": 0.8789585631489754, "critic_loss": 0.6020450546741486, "actor_loss": -94.68681034851075, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.593339920043945, "step": 129000}
{"episode_reward": 974.4307310795919, "episode": 130.0, "batch_reward": 0.8818133314251899, "critic_loss": 0.575974075242877, "actor_loss": -94.77159042358399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.548470973968506, "step": 130000}
{"episode_reward": 940.0556954639515, "episode": 131.0, "batch_reward": 0.8805536239743232, "critic_loss": 0.5856333796083927, "actor_loss": -94.77114912414551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.28016448020935, "step": 131000}
{"episode_reward": 887.7620674113818, "episode": 132.0, "batch_reward": 0.8799852989315987, "critic_loss": 0.5861893209815026, "actor_loss": -94.87703584289551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.530808687210083, "step": 132000}
{"episode_reward": 901.9869131557605, "episode": 133.0, "batch_reward": 0.8816375916600228, "critic_loss": 0.605905863031745, "actor_loss": -94.81684228515626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.501349925994873, "step": 133000}
{"episode_reward": 970.3850975936443, "episode": 134.0, "batch_reward": 0.8816435158848762, "critic_loss": 0.5903863509744406, "actor_loss": -94.81196697998047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.536508083343506, "step": 134000}
{"episode_reward": 925.0506592148265, "episode": 135.0, "batch_reward": 0.8815384305119515, "critic_loss": 0.5948709506690503, "actor_loss": -94.84332940673828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.45709776878357, "step": 135000}
{"episode_reward": 910.8868525674555, "episode": 136.0, "batch_reward": 0.8826478629112243, "critic_loss": 0.6023326355218888, "actor_loss": -94.6945652923584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.71458411216736, "step": 136000}
{"episode_reward": 903.8607330680599, "episode": 137.0, "batch_reward": 0.8817820121049881, "critic_loss": 0.5718542476296424, "actor_loss": -94.9119480895996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.654733896255493, "step": 137000}
{"episode_reward": 950.1139535810942, "episode": 138.0, "batch_reward": 0.8841267278194428, "critic_loss": 0.5795772051662207, "actor_loss": -94.98765774536133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.67033839225769, "step": 138000}
{"episode_reward": 944.0888575243982, "episode": 139.0, "batch_reward": 0.8840711085796357, "critic_loss": 0.5910204052105545, "actor_loss": -94.9544353942871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.64320945739746, "step": 139000}
{"episode_reward": 942.0914295836279, "episode": 140.0, "batch_reward": 0.8844615890979767, "critic_loss": 0.609062234595418, "actor_loss": -94.92943132019043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.624638080596924, "step": 140000}
{"episode_reward": 907.5876031262859, "episode": 141.0, "batch_reward": 0.8821500108242035, "critic_loss": 0.6164450422525406, "actor_loss": -94.86782727050782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.376739501953125, "step": 141000}
{"episode_reward": 924.3789106470872, "episode": 142.0, "batch_reward": 0.8841420450210571, "critic_loss": 0.5947058415263892, "actor_loss": -94.81416781616211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.603790760040283, "step": 142000}
{"episode_reward": 933.995642997939, "episode": 143.0, "batch_reward": 0.8835176877379417, "critic_loss": 0.586471573188901, "actor_loss": -94.89981698608399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.611865043640137, "step": 143000}
{"episode_reward": 869.8555217059018, "episode": 144.0, "batch_reward": 0.8845209995508194, "critic_loss": 0.5945253446996211, "actor_loss": -94.93949029541015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.612722158432007, "step": 144000}
{"episode_reward": 891.2099725680915, "episode": 145.0, "batch_reward": 0.8830434094071389, "critic_loss": 0.5947070794999599, "actor_loss": -94.9882612915039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.60706067085266, "step": 145000}
{"episode_reward": 872.4637537336512, "episode": 146.0, "batch_reward": 0.8845402625203133, "critic_loss": 0.5942683016061783, "actor_loss": -95.07007215881347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.664851188659668, "step": 146000}
{"episode_reward": 965.6401040648033, "episode": 147.0, "batch_reward": 0.8849638740420341, "critic_loss": 0.5759094150960445, "actor_loss": -95.02299006652832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.7099666595459, "step": 147000}
{"episode_reward": 909.012570146796, "episode": 148.0, "batch_reward": 0.8844272142648697, "critic_loss": 0.5815623781085014, "actor_loss": -95.06402856445312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.79153299331665, "step": 148000}
{"episode_reward": 914.8223081923733, "episode": 149.0, "batch_reward": 0.8844563378691673, "critic_loss": 0.5757013193964958, "actor_loss": -94.95907147216796, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.63463830947876, "step": 149000}
{"episode_reward": 974.745729676927, "episode": 150.0, "batch_reward": 0.8839457409977913, "critic_loss": 0.5614473706036807, "actor_loss": -95.01213342285156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
