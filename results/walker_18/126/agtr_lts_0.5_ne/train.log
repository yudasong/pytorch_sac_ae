{"episode_reward": 0.0, "episode": 1.0, "duration": 21.018779277801514, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.826228141784668, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.47081454067915507, "critic_loss": 0.16569240854338194, "actor_loss": -83.97597748511025, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.238983392715454, "step": 3000}
{"episode_reward": 624.1169351895313, "episode": 4.0, "batch_reward": 0.5445433350503445, "critic_loss": 0.3787836788445711, "actor_loss": -86.19682936096191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.030641794204712, "step": 4000}
{"episode_reward": 770.4055344000413, "episode": 5.0, "batch_reward": 0.5753796565532684, "critic_loss": 0.5667740543782711, "actor_loss": -87.0395597076416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.008235216140747, "step": 5000}
{"episode_reward": 568.45913768803, "episode": 6.0, "batch_reward": 0.5999080124795437, "critic_loss": 0.5107938832640648, "actor_loss": -87.81718737792968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997644901275635, "step": 6000}
{"episode_reward": 853.461792077434, "episode": 7.0, "batch_reward": 0.6414516975283623, "critic_loss": 0.49682664129137993, "actor_loss": -89.11252166748046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.010957717895508, "step": 7000}
{"episode_reward": 880.1724289399048, "episode": 8.0, "batch_reward": 0.670590602517128, "critic_loss": 0.48619076240062714, "actor_loss": -90.14301817321777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01511025428772, "step": 8000}
{"episode_reward": 708.8702026667975, "episode": 9.0, "batch_reward": 0.6568135736584664, "critic_loss": 0.5073421843349933, "actor_loss": -90.02298152160644, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99450421333313, "step": 9000}
{"episode_reward": 608.5188309843979, "episode": 10.0, "batch_reward": 0.6721251031160355, "critic_loss": 0.5597762121856212, "actor_loss": -90.46384396362305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00396704673767, "step": 10000}
{"episode_reward": 911.9705507368552, "episode": 11.0, "batch_reward": 0.6908663983345031, "critic_loss": 0.5958154847323894, "actor_loss": -90.8003642730713, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.56596350669861, "step": 11000}
{"episode_reward": 802.0579821436111, "episode": 12.0, "batch_reward": 0.690858546257019, "critic_loss": 0.6520013594627381, "actor_loss": -90.80913824462891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00235867500305, "step": 12000}
{"episode_reward": 712.8364661492186, "episode": 13.0, "batch_reward": 0.7041093825101853, "critic_loss": 0.5580401904284954, "actor_loss": -91.01241523742675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00894546508789, "step": 13000}
{"episode_reward": 901.839156088205, "episode": 14.0, "batch_reward": 0.7184975341558456, "critic_loss": 0.5061268087327481, "actor_loss": -91.41551657104492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.003040552139282, "step": 14000}
{"episode_reward": 912.3268583981832, "episode": 15.0, "batch_reward": 0.7263468030691147, "critic_loss": 0.49102641317248347, "actor_loss": -91.55874412536622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.985883474349976, "step": 15000}
{"episode_reward": 789.7809948240624, "episode": 16.0, "batch_reward": 0.737787292599678, "critic_loss": 0.45250625038146974, "actor_loss": -91.96856074523926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.021433115005493, "step": 16000}
{"episode_reward": 941.6850636314462, "episode": 17.0, "batch_reward": 0.7449781196117401, "critic_loss": 0.45278281907737256, "actor_loss": -92.04674375915528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.026865482330322, "step": 17000}
{"episode_reward": 838.8758527404635, "episode": 18.0, "batch_reward": 0.7526562452316284, "critic_loss": 0.41810523745417594, "actor_loss": -92.19423620605468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.046303749084473, "step": 18000}
{"episode_reward": 923.5607003198459, "episode": 19.0, "batch_reward": 0.761483550131321, "critic_loss": 0.4066088574677706, "actor_loss": -92.32776876831055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.050665140151978, "step": 19000}
{"episode_reward": 907.6064739341255, "episode": 20.0, "batch_reward": 0.7654156152606011, "critic_loss": 0.4413386839032173, "actor_loss": -92.237375289917, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.9990873336792, "step": 20000}
{"episode_reward": 817.571100840724, "episode": 21.0, "batch_reward": 0.7721145859956742, "critic_loss": 0.4156457403302193, "actor_loss": -92.40880094909667, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.573495626449585, "step": 21000}
{"episode_reward": 888.589556826132, "episode": 22.0, "batch_reward": 0.7772539149522781, "critic_loss": 0.44032145269215106, "actor_loss": -92.50220960998536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.020360946655273, "step": 22000}
{"episode_reward": 859.8067068349909, "episode": 23.0, "batch_reward": 0.7800440884232521, "critic_loss": 0.42800803199410437, "actor_loss": -92.47333108520507, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.044535636901855, "step": 23000}
{"episode_reward": 886.7420422157517, "episode": 24.0, "batch_reward": 0.7828119165301323, "critic_loss": 0.46828730760514736, "actor_loss": -92.50057489013672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02026104927063, "step": 24000}
{"episode_reward": 845.5550478063562, "episode": 25.0, "batch_reward": 0.7899756266474723, "critic_loss": 0.4236652981042862, "actor_loss": -92.623810546875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.039007663726807, "step": 25000}
{"episode_reward": 931.642489720825, "episode": 26.0, "batch_reward": 0.7935378690958023, "critic_loss": 0.42290191166102886, "actor_loss": -92.75446330261231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.999655723571777, "step": 26000}
{"episode_reward": 911.2675390986208, "episode": 27.0, "batch_reward": 0.7988671908974647, "critic_loss": 0.4096622619330883, "actor_loss": -92.77495390319824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.015469551086426, "step": 27000}
{"episode_reward": 929.7607960956824, "episode": 28.0, "batch_reward": 0.8032045795917511, "critic_loss": 0.3979092760235071, "actor_loss": -92.9123413696289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.073495149612427, "step": 28000}
{"episode_reward": 917.7494354851108, "episode": 29.0, "batch_reward": 0.8084165642261505, "critic_loss": 0.4206221087574959, "actor_loss": -92.90848669433593, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.028026819229126, "step": 29000}
{"episode_reward": 963.6158484927976, "episode": 30.0, "batch_reward": 0.8110212446451187, "critic_loss": 0.4181280238032341, "actor_loss": -92.98139852905274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.027658700942993, "step": 30000}
{"episode_reward": 865.9066901532894, "episode": 31.0, "batch_reward": 0.8123507254719734, "critic_loss": 0.42330728985369204, "actor_loss": -93.05298512268067, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 41.772465229034424, "step": 31000}
{"episode_reward": 886.3572609238872, "episode": 32.0, "batch_reward": 0.8157134776711464, "critic_loss": 0.422875163346529, "actor_loss": -93.1742366027832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.161802768707275, "step": 32000}
{"episode_reward": 906.5671984130855, "episode": 33.0, "batch_reward": 0.8129546353816987, "critic_loss": 0.45282428665459157, "actor_loss": -92.88720980834961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.169662714004517, "step": 33000}
{"episode_reward": 668.1703597448435, "episode": 34.0, "batch_reward": 0.8157465524673462, "critic_loss": 0.46242932984232904, "actor_loss": -93.02484829711914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.165950536727905, "step": 34000}
{"episode_reward": 884.005526067401, "episode": 35.0, "batch_reward": 0.8173841545581818, "critic_loss": 0.44618913212418554, "actor_loss": -93.10273806762696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.17611598968506, "step": 35000}
{"episode_reward": 919.4478043554828, "episode": 36.0, "batch_reward": 0.8190224855542183, "critic_loss": 0.44438297069072724, "actor_loss": -93.20398417663574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.13161611557007, "step": 36000}
{"episode_reward": 895.289711633098, "episode": 37.0, "batch_reward": 0.8215076406598091, "critic_loss": 0.445305590480566, "actor_loss": -93.26248310852051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.19938898086548, "step": 37000}
{"episode_reward": 877.9400616826421, "episode": 38.0, "batch_reward": 0.8249229000210762, "critic_loss": 0.44867074279487135, "actor_loss": -93.17075135803222, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.164798259735107, "step": 38000}
{"episode_reward": 949.0364286812717, "episode": 39.0, "batch_reward": 0.8259558907151222, "critic_loss": 0.47464059323072433, "actor_loss": -93.2629267578125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.15584397315979, "step": 39000}
{"episode_reward": 864.5152429622774, "episode": 40.0, "batch_reward": 0.8274650315642357, "critic_loss": 0.4563047483563423, "actor_loss": -93.3283998413086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.14279794692993, "step": 40000}
{"episode_reward": 950.2455828597818, "episode": 41.0, "batch_reward": 0.829243655025959, "critic_loss": 0.4591464399546385, "actor_loss": -93.42424633789062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.83234000205994, "step": 41000}
{"episode_reward": 869.148881820521, "episode": 42.0, "batch_reward": 0.8298891440033913, "critic_loss": 0.4488063798099756, "actor_loss": -93.35209939575195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.10762333869934, "step": 42000}
{"episode_reward": 874.1127813795274, "episode": 43.0, "batch_reward": 0.8320970264673233, "critic_loss": 0.463686461776495, "actor_loss": -93.39328970336913, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.166568756103516, "step": 43000}
{"episode_reward": 666.114481253319, "episode": 44.0, "batch_reward": 0.8289533657431603, "critic_loss": 0.42418212546408174, "actor_loss": -93.3378780670166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.162795305252075, "step": 44000}
{"episode_reward": 909.371617606777, "episode": 45.0, "batch_reward": 0.830632847070694, "critic_loss": 0.44004044131934644, "actor_loss": -93.28190518188477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.084190368652344, "step": 45000}
{"episode_reward": 919.2083579964296, "episode": 46.0, "batch_reward": 0.8322705298066139, "critic_loss": 0.4343317846953869, "actor_loss": -93.44344697570801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.138393878936768, "step": 46000}
{"episode_reward": 907.7901554210366, "episode": 47.0, "batch_reward": 0.826110354423523, "critic_loss": 0.433404387101531, "actor_loss": -93.26416883850098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.189617156982422, "step": 47000}
{"episode_reward": 63.96727589842661, "episode": 48.0, "batch_reward": 0.8173716943860054, "critic_loss": 0.40738168053328994, "actor_loss": -92.94371437072753, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.108675718307495, "step": 48000}
{"episode_reward": 944.8858532982658, "episode": 49.0, "batch_reward": 0.8210524586439133, "critic_loss": 0.42894027519226074, "actor_loss": -93.04384768676758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.09554362297058, "step": 49000}
{"episode_reward": 890.4333222537113, "episode": 50.0, "batch_reward": 0.8225946097970008, "critic_loss": 0.41915087421238423, "actor_loss": -92.95885081481934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.090550661087036, "step": 50000}
{"episode_reward": 916.2677779601156, "episode": 51.0, "batch_reward": 0.8258252679109573, "critic_loss": 0.4265598422139883, "actor_loss": -93.02074502563477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.77257680892944, "step": 51000}
{"episode_reward": 933.7443075139668, "episode": 52.0, "batch_reward": 0.825333334505558, "critic_loss": 0.4085891799479723, "actor_loss": -93.20616038513184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.110522985458374, "step": 52000}
{"episode_reward": 927.6998321805096, "episode": 53.0, "batch_reward": 0.8274169813990593, "critic_loss": 0.4124736016839743, "actor_loss": -93.07393786621094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.112817764282227, "step": 53000}
{"episode_reward": 906.6109420242963, "episode": 54.0, "batch_reward": 0.8297773079872132, "critic_loss": 0.40743194152414797, "actor_loss": -93.38491592407226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.096003770828247, "step": 54000}
{"episode_reward": 923.4178628953737, "episode": 55.0, "batch_reward": 0.8309911554455757, "critic_loss": 0.40929374541342256, "actor_loss": -93.35919787597656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.089260578155518, "step": 55000}
{"episode_reward": 949.3890215500267, "episode": 56.0, "batch_reward": 0.8345383118987083, "critic_loss": 0.37528910610079763, "actor_loss": -93.3719458618164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.082040071487427, "step": 56000}
{"episode_reward": 981.4426211283491, "episode": 57.0, "batch_reward": 0.8361521574854851, "critic_loss": 0.3838794824779034, "actor_loss": -93.45169648742676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.151966333389282, "step": 57000}
{"episode_reward": 943.9063279285089, "episode": 58.0, "batch_reward": 0.8381264511346816, "critic_loss": 0.3740495649576187, "actor_loss": -93.44524610900879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.093786001205444, "step": 58000}
{"episode_reward": 920.5806470937192, "episode": 59.0, "batch_reward": 0.8406234052181244, "critic_loss": 0.3593660285323858, "actor_loss": -93.61067887878419, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.019524335861206, "step": 59000}
{"episode_reward": 961.6216948922353, "episode": 60.0, "batch_reward": 0.8411961655020714, "critic_loss": 0.3806581611037254, "actor_loss": -93.70361253356934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.057642221450806, "step": 60000}
{"episode_reward": 869.3137912983792, "episode": 61.0, "batch_reward": 0.8426722886562348, "critic_loss": 0.35726239177584646, "actor_loss": -93.70021723937988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.64625144004822, "step": 61000}
{"episode_reward": 935.8465814300405, "episode": 62.0, "batch_reward": 0.8431593571305275, "critic_loss": 0.36532882722467186, "actor_loss": -93.63957708740234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.88227081298828, "step": 62000}
{"episode_reward": 969.2619891543519, "episode": 63.0, "batch_reward": 0.8438916860818862, "critic_loss": 0.3718042612373829, "actor_loss": -93.65976986694336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.663611888885498, "step": 63000}
{"episode_reward": 948.5087407278854, "episode": 64.0, "batch_reward": 0.8465788300037385, "critic_loss": 0.37528316940367223, "actor_loss": -93.72320314025879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.15145516395569, "step": 64000}
{"episode_reward": 830.1953889084298, "episode": 65.0, "batch_reward": 0.846586108148098, "critic_loss": 0.3939213357120752, "actor_loss": -93.74942837524414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.180925130844116, "step": 65000}
{"episode_reward": 950.019025274479, "episode": 66.0, "batch_reward": 0.8479448380470276, "critic_loss": 0.39325402525067327, "actor_loss": -93.73212721252442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.1621196269989, "step": 66000}
{"episode_reward": 949.6732870410765, "episode": 67.0, "batch_reward": 0.8510339644551277, "critic_loss": 0.35648011000454427, "actor_loss": -93.80368403625488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.2392578125, "step": 67000}
{"episode_reward": 950.4377787827583, "episode": 68.0, "batch_reward": 0.8509936065077782, "critic_loss": 0.36303420144319537, "actor_loss": -93.89591751098632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.15874218940735, "step": 68000}
{"episode_reward": 957.1760031404158, "episode": 69.0, "batch_reward": 0.8542678337097168, "critic_loss": 0.3632863903492689, "actor_loss": -93.98709312438965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.16647434234619, "step": 69000}
{"episode_reward": 966.615064313662, "episode": 70.0, "batch_reward": 0.8531733735203743, "critic_loss": 0.371582478761673, "actor_loss": -93.97999617004395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.13113498687744, "step": 70000}
{"episode_reward": 889.1628645771882, "episode": 71.0, "batch_reward": 0.8543891416192054, "critic_loss": 0.36088742916285993, "actor_loss": -93.96743556213379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.829689025878906, "step": 71000}
{"episode_reward": 941.1190921084996, "episode": 72.0, "batch_reward": 0.8566399214863777, "critic_loss": 0.3877893896773458, "actor_loss": -94.059564453125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.18980598449707, "step": 72000}
{"episode_reward": 906.089091889268, "episode": 73.0, "batch_reward": 0.8567166111469269, "critic_loss": 0.40717154924571514, "actor_loss": -93.99500814819336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.169793367385864, "step": 73000}
{"episode_reward": 881.465056260916, "episode": 74.0, "batch_reward": 0.8576026358604432, "critic_loss": 0.4304386233389378, "actor_loss": -94.0774839630127, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.123615264892578, "step": 74000}
{"episode_reward": 900.4869256172274, "episode": 75.0, "batch_reward": 0.8585300956368447, "critic_loss": 0.4193788716197014, "actor_loss": -94.10264796447754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.193109035491943, "step": 75000}
{"episode_reward": 962.907465615078, "episode": 76.0, "batch_reward": 0.8581962124109268, "critic_loss": 0.4024503360837698, "actor_loss": -94.11329981994629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.17391276359558, "step": 76000}
{"episode_reward": 879.1575510744368, "episode": 77.0, "batch_reward": 0.8597881074547767, "critic_loss": 0.4092167980670929, "actor_loss": -94.08353861999511, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.165566444396973, "step": 77000}
{"episode_reward": 928.7496948725912, "episode": 78.0, "batch_reward": 0.8597792465090751, "critic_loss": 0.37786159238219263, "actor_loss": -94.04993135070801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.17509174346924, "step": 78000}
{"episode_reward": 943.1232407680498, "episode": 79.0, "batch_reward": 0.8604188585281372, "critic_loss": 0.3980634835511446, "actor_loss": -94.12225215148926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.132320880889893, "step": 79000}
{"episode_reward": 935.6009164418269, "episode": 80.0, "batch_reward": 0.8628695024251938, "critic_loss": 0.38545925222337246, "actor_loss": -94.1737013092041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.12799620628357, "step": 80000}
{"episode_reward": 930.6659591842597, "episode": 81.0, "batch_reward": 0.8622747146487236, "critic_loss": 0.40750893381237985, "actor_loss": -94.07651754760742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.83883213996887, "step": 81000}
{"episode_reward": 912.6440301017842, "episode": 82.0, "batch_reward": 0.8627929423451424, "critic_loss": 0.4251583789139986, "actor_loss": -94.10250875854493, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.156221628189087, "step": 82000}
{"episode_reward": 874.4618503366763, "episode": 83.0, "batch_reward": 0.863665850520134, "critic_loss": 0.41361704604327676, "actor_loss": -94.22165144348145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.13507843017578, "step": 83000}
{"episode_reward": 935.8964380589274, "episode": 84.0, "batch_reward": 0.8643647354841232, "critic_loss": 0.41937473048269747, "actor_loss": -94.24857363891601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.140506505966187, "step": 84000}
{"episode_reward": 926.4635060986884, "episode": 85.0, "batch_reward": 0.8650468000769616, "critic_loss": 0.4082028384357691, "actor_loss": -94.15997650146484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.144159078598022, "step": 85000}
{"episode_reward": 947.4619290589931, "episode": 86.0, "batch_reward": 0.8654277435541153, "critic_loss": 0.39810181030631064, "actor_loss": -94.23427348327637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.15929865837097, "step": 86000}
{"episode_reward": 950.1130658195889, "episode": 87.0, "batch_reward": 0.8681490170359611, "critic_loss": 0.42306428448855876, "actor_loss": -94.40601232910156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.157984018325806, "step": 87000}
{"episode_reward": 884.4869350862066, "episode": 88.0, "batch_reward": 0.8684478128552436, "critic_loss": 0.4046107514500618, "actor_loss": -94.3734372253418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.096610069274902, "step": 88000}
{"episode_reward": 965.7953049002017, "episode": 89.0, "batch_reward": 0.8671980413198471, "critic_loss": 0.4213023585677147, "actor_loss": -94.29437948608398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.09196949005127, "step": 89000}
{"episode_reward": 889.4781210482487, "episode": 90.0, "batch_reward": 0.8685871853232384, "critic_loss": 0.3911303020268679, "actor_loss": -94.33060009765624, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.079843521118164, "step": 90000}
{"episode_reward": 935.5452667664011, "episode": 91.0, "batch_reward": 0.8699300063252449, "critic_loss": 0.3818405794203281, "actor_loss": -94.35345977783203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.75142288208008, "step": 91000}
{"episode_reward": 909.8012136629135, "episode": 92.0, "batch_reward": 0.8706753864884377, "critic_loss": 0.37791514886915684, "actor_loss": -94.45766796875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.07063603401184, "step": 92000}
{"episode_reward": 947.2013799004093, "episode": 93.0, "batch_reward": 0.8676035788059234, "critic_loss": 0.41523106468468907, "actor_loss": -94.37709548950195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.024913787841797, "step": 93000}
{"episode_reward": 84.0607798253751, "episode": 94.0, "batch_reward": 0.8613290202021598, "critic_loss": 0.45733481357991695, "actor_loss": -94.19005851745605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.198642015457153, "step": 94000}
{"episode_reward": 869.8645447828732, "episode": 95.0, "batch_reward": 0.8621927080750466, "critic_loss": 0.43768194152414797, "actor_loss": -94.27176245117188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.16807985305786, "step": 95000}
{"episode_reward": 918.465428283704, "episode": 96.0, "batch_reward": 0.8618332449197769, "critic_loss": 0.45001205772161484, "actor_loss": -94.2851058959961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.237346172332764, "step": 96000}
{"episode_reward": 942.674844279331, "episode": 97.0, "batch_reward": 0.8640306710004807, "critic_loss": 0.44582211378216746, "actor_loss": -94.3331291809082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.2159686088562, "step": 97000}
{"episode_reward": 956.5333492616703, "episode": 98.0, "batch_reward": 0.8647562847137451, "critic_loss": 0.4555840642899275, "actor_loss": -94.28345021057129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.159503936767578, "step": 98000}
{"episode_reward": 924.4565659439052, "episode": 99.0, "batch_reward": 0.8645380121469498, "critic_loss": 0.4278704473227263, "actor_loss": -94.38530447387696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.15889620780945, "step": 99000}
{"episode_reward": 902.1393710589372, "episode": 100.0, "batch_reward": 0.860816121339798, "critic_loss": 0.4848154416680336, "actor_loss": -94.26156155395508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.181601524353027, "step": 100000}
{"episode_reward": 86.3073235451432, "episode": 101.0, "batch_reward": 0.8586256467103958, "critic_loss": 0.4642555025368929, "actor_loss": -94.19628225708007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.85526776313782, "step": 101000}
{"episode_reward": 925.1397391922292, "episode": 102.0, "batch_reward": 0.858833807349205, "critic_loss": 0.48786807326972487, "actor_loss": -94.1365381011963, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.171194553375244, "step": 102000}
{"episode_reward": 956.6117305191068, "episode": 103.0, "batch_reward": 0.86058329641819, "critic_loss": 0.46075503328442574, "actor_loss": -94.15420465087891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.164921760559082, "step": 103000}
{"episode_reward": 949.2480931317879, "episode": 104.0, "batch_reward": 0.8604731329679489, "critic_loss": 0.4755247432142496, "actor_loss": -94.25048016357422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.18989109992981, "step": 104000}
{"episode_reward": 930.1037210379185, "episode": 105.0, "batch_reward": 0.8608921239972115, "critic_loss": 0.4635237788707018, "actor_loss": -94.19979916381835, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.136910438537598, "step": 105000}
{"episode_reward": 945.8585391605042, "episode": 106.0, "batch_reward": 0.8614501546025276, "critic_loss": 0.5127782555669547, "actor_loss": -94.28938859558106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.214359760284424, "step": 106000}
{"episode_reward": 866.4946395907552, "episode": 107.0, "batch_reward": 0.8625286533236504, "critic_loss": 0.5008131392300129, "actor_loss": -94.24237911987305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.181642293930054, "step": 107000}
{"episode_reward": 864.3722056234313, "episode": 108.0, "batch_reward": 0.8608535931110383, "critic_loss": 0.559573712721467, "actor_loss": -94.10878103637695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.10513710975647, "step": 108000}
{"episode_reward": 865.329646009295, "episode": 109.0, "batch_reward": 0.8609244692921638, "critic_loss": 0.48994953793287277, "actor_loss": -94.24899313354493, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.1625337600708, "step": 109000}
{"episode_reward": 941.3290064787451, "episode": 110.0, "batch_reward": 0.862837700009346, "critic_loss": 0.5059305562973022, "actor_loss": -94.32186360168457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.159019231796265, "step": 110000}
{"episode_reward": 921.596596101743, "episode": 111.0, "batch_reward": 0.8629561132788658, "critic_loss": 0.5458418961614371, "actor_loss": -94.22430406188965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.85220909118652, "step": 111000}
{"episode_reward": 915.356900861927, "episode": 112.0, "batch_reward": 0.8638432219624519, "critic_loss": 0.542796237334609, "actor_loss": -94.4281987915039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.109351634979248, "step": 112000}
{"episode_reward": 897.0420184945542, "episode": 113.0, "batch_reward": 0.8633441264629365, "critic_loss": 0.537107681170106, "actor_loss": -94.32487089538574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.154481887817383, "step": 113000}
{"episode_reward": 925.4769907130028, "episode": 114.0, "batch_reward": 0.863160552918911, "critic_loss": 0.5785836631208658, "actor_loss": -94.31740853881836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.161361694335938, "step": 114000}
{"episode_reward": 914.0829355216912, "episode": 115.0, "batch_reward": 0.8628621457219123, "critic_loss": 1.1321635426878929, "actor_loss": -95.1487982635498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.129451751708984, "step": 115000}
{"episode_reward": 205.19764340378694, "episode": 116.0, "batch_reward": 0.8571487232446671, "critic_loss": 4.246969368636608, "actor_loss": -99.3939603881836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.469178915023804, "step": 116000}
{"episode_reward": 140.42747606129697, "episode": 117.0, "batch_reward": 0.8515211876630783, "critic_loss": 21.752466690063475, "actor_loss": -111.92238069152832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.323343515396118, "step": 117000}
{"episode_reward": 563.8376013707938, "episode": 118.0, "batch_reward": 0.8465455716252327, "critic_loss": 71.71341127204894, "actor_loss": -127.55754981994629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.085965633392334, "step": 118000}
{"episode_reward": 150.46914063365037, "episode": 119.0, "batch_reward": 0.8425229356884957, "critic_loss": 129.18823835754395, "actor_loss": -144.0192319946289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.084086656570435, "step": 119000}
{"episode_reward": 314.67481629810567, "episode": 120.0, "batch_reward": 0.8388402468562126, "critic_loss": 170.5989808883667, "actor_loss": -168.90209991455077, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.099643230438232, "step": 120000}
{"episode_reward": 278.466625238, "episode": 121.0, "batch_reward": 0.8323160692453384, "critic_loss": 193.84438986968993, "actor_loss": -190.84051724243164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.804280042648315, "step": 121000}
{"episode_reward": 121.82139247327359, "episode": 122.0, "batch_reward": 0.8277409654259682, "critic_loss": 197.5548769607544, "actor_loss": -202.0048455810547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.09628653526306, "step": 122000}
{"episode_reward": 148.67428339935705, "episode": 123.0, "batch_reward": 0.8215515461564064, "critic_loss": 212.9176897277832, "actor_loss": -209.40355879211427, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.06179690361023, "step": 123000}
{"episode_reward": 107.43844513787774, "episode": 124.0, "batch_reward": 0.8181765953302383, "critic_loss": 252.0495442428589, "actor_loss": -220.67591206359864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.058920860290527, "step": 124000}
{"episode_reward": 478.07468618236027, "episode": 125.0, "batch_reward": 0.8151803592443466, "critic_loss": 250.69172828674317, "actor_loss": -226.29253140258788, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.972726106643677, "step": 125000}
{"episode_reward": 598.2482656307538, "episode": 126.0, "batch_reward": 0.8141012586951256, "critic_loss": 225.14014139556886, "actor_loss": -234.84288038635253, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.501900672912598, "step": 126000}
{"episode_reward": 756.2295516053555, "episode": 127.0, "batch_reward": 0.8114503856897354, "critic_loss": 185.93622744750976, "actor_loss": -221.54059902954103, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.214109182357788, "step": 127000}
{"episode_reward": 685.6947949544904, "episode": 128.0, "batch_reward": 0.8118573518395424, "critic_loss": 148.04072581100465, "actor_loss": -229.3109793701172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.17217516899109, "step": 128000}
{"episode_reward": 887.2109914947087, "episode": 129.0, "batch_reward": 0.8113909945487976, "critic_loss": 131.60902711486816, "actor_loss": -233.73275227355958, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.193238735198975, "step": 129000}
{"episode_reward": 983.5598887789163, "episode": 130.0, "batch_reward": 0.8145271260142326, "critic_loss": 106.24352185058594, "actor_loss": -231.43121307373048, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.167526721954346, "step": 130000}
{"episode_reward": 924.5155196268165, "episode": 131.0, "batch_reward": 0.8161902313828469, "critic_loss": 93.04522393035889, "actor_loss": -219.89148126220704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.88483285903931, "step": 131000}
{"episode_reward": 926.1055255285124, "episode": 132.0, "batch_reward": 0.816607959985733, "critic_loss": 77.51217893028259, "actor_loss": -214.69273475646972, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.138184785842896, "step": 132000}
{"episode_reward": 936.2326184618983, "episode": 133.0, "batch_reward": 0.8175234996676445, "critic_loss": 63.344249629974364, "actor_loss": -221.1733905029297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.18489980697632, "step": 133000}
{"episode_reward": 923.0967109681508, "episode": 134.0, "batch_reward": 0.8186930509209633, "critic_loss": 52.91331833648682, "actor_loss": -222.63744299316406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.14910125732422, "step": 134000}
{"episode_reward": 930.4702585708308, "episode": 135.0, "batch_reward": 0.8164724400043487, "critic_loss": 44.88363920688629, "actor_loss": -202.0705147705078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.199485301971436, "step": 135000}
{"episode_reward": 626.007971962436, "episode": 136.0, "batch_reward": 0.8175123074054718, "critic_loss": 38.437003843307494, "actor_loss": -222.88461328125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.207353830337524, "step": 136000}
{"episode_reward": 875.1583476316184, "episode": 137.0, "batch_reward": 0.8161698713898659, "critic_loss": 32.885074635505674, "actor_loss": -200.76969088745116, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.18748140335083, "step": 137000}
{"episode_reward": 743.4109909650605, "episode": 138.0, "batch_reward": 0.8164598169922829, "critic_loss": 27.269066935539247, "actor_loss": -198.37738055419922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.215569734573364, "step": 138000}
{"episode_reward": 590.4084075621884, "episode": 139.0, "batch_reward": 0.8137892237901687, "critic_loss": 22.900366991996766, "actor_loss": -194.8952216796875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.202917337417603, "step": 139000}
{"episode_reward": 547.1241578575034, "episode": 140.0, "batch_reward": 0.8138678327798844, "critic_loss": 18.458945992469786, "actor_loss": -190.66376290893555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.126921892166138, "step": 140000}
{"episode_reward": 596.0832121196353, "episode": 141.0, "batch_reward": 0.8095473242998124, "critic_loss": 16.56807568836212, "actor_loss": -186.18012539672853, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.06811714172363, "step": 141000}
{"episode_reward": 553.8274908437375, "episode": 142.0, "batch_reward": 0.8085240993499756, "critic_loss": 13.58468868970871, "actor_loss": -193.03614585876466, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.13756775856018, "step": 142000}
{"episode_reward": 543.3959899166956, "episode": 143.0, "batch_reward": 0.8084214680194854, "critic_loss": 11.255246094465257, "actor_loss": -190.2907513885498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.12200927734375, "step": 143000}
{"episode_reward": 670.7328813679262, "episode": 144.0, "batch_reward": 0.8073201180696488, "critic_loss": 9.808739992141724, "actor_loss": -174.39725910949707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.153209686279297, "step": 144000}
{"episode_reward": 726.3081513950094, "episode": 145.0, "batch_reward": 0.8058514353632927, "critic_loss": 8.732307121515275, "actor_loss": -172.73404306030272, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.158575534820557, "step": 145000}
{"episode_reward": 838.3904450713733, "episode": 146.0, "batch_reward": 0.8068594045042992, "critic_loss": 7.709926568984986, "actor_loss": -168.83082554626463, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.20931363105774, "step": 146000}
{"episode_reward": 855.1934287509772, "episode": 147.0, "batch_reward": 0.8076488115191459, "critic_loss": 6.695792673587799, "actor_loss": -165.21271606445313, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.162246227264404, "step": 147000}
{"episode_reward": 898.2176614368964, "episode": 148.0, "batch_reward": 0.8080631045103073, "critic_loss": 5.549655742049217, "actor_loss": -164.03825630187987, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.135165214538574, "step": 148000}
{"episode_reward": 937.2770506332972, "episode": 149.0, "batch_reward": 0.8059457257986069, "critic_loss": 4.843212444186211, "actor_loss": -160.15084423828125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.1128671169281, "step": 149000}
{"episode_reward": 968.414107065385, "episode": 150.0, "batch_reward": 0.8098055258989334, "critic_loss": 4.166140189051628, "actor_loss": -155.4307625427246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
