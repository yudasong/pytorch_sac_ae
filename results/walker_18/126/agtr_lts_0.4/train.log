{"episode_reward": 0.0, "episode": 1.0, "duration": 20.95052933692932, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.8249788284301758, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.47238361595987916, "critic_loss": 0.1302731295835777, "actor_loss": -84.33531992508918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.20350432395935, "step": 3000}
{"episode_reward": 662.5788947276294, "episode": 4.0, "batch_reward": 0.5596300218701362, "critic_loss": 0.3308975882232189, "actor_loss": -87.43046672058105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99670934677124, "step": 4000}
{"episode_reward": 694.9658405759451, "episode": 5.0, "batch_reward": 0.5601721475124359, "critic_loss": 0.4924375810921192, "actor_loss": -87.75981652832031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.000826597213745, "step": 5000}
{"episode_reward": 550.6101534514773, "episode": 6.0, "batch_reward": 0.5752283994853497, "critic_loss": 0.5514001954495907, "actor_loss": -88.07317053222656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.000704526901245, "step": 6000}
{"episode_reward": 714.329894826064, "episode": 7.0, "batch_reward": 0.5987652316689491, "critic_loss": 0.6629124630391597, "actor_loss": -88.59359016418458, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.991472959518433, "step": 7000}
{"episode_reward": 708.4340246925839, "episode": 8.0, "batch_reward": 0.6140015918016434, "critic_loss": 0.7530200160145759, "actor_loss": -89.00740007019043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.990158796310425, "step": 8000}
{"episode_reward": 689.7332199107037, "episode": 9.0, "batch_reward": 0.6291772847175598, "critic_loss": 0.6737350221574306, "actor_loss": -89.55542655944824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.994388580322266, "step": 9000}
{"episode_reward": 822.42723338716, "episode": 10.0, "batch_reward": 0.6534633826613426, "critic_loss": 0.6866510140001774, "actor_loss": -90.06601683044434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.989068746566772, "step": 10000}
{"episode_reward": 889.0282130217199, "episode": 11.0, "batch_reward": 0.6737144004106521, "critic_loss": 0.6490987902283668, "actor_loss": -90.50678295898437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.616138219833374, "step": 11000}
{"episode_reward": 849.944331247256, "episode": 12.0, "batch_reward": 0.6815515963435173, "critic_loss": 0.6095823869407176, "actor_loss": -90.6450299835205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.993077993392944, "step": 12000}
{"episode_reward": 747.6584857346604, "episode": 13.0, "batch_reward": 0.6924479570984841, "critic_loss": 0.5694860130250454, "actor_loss": -90.87790287780761, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.988017797470093, "step": 13000}
{"episode_reward": 870.5770045537557, "episode": 14.0, "batch_reward": 0.7071240842938423, "critic_loss": 0.5128919986784458, "actor_loss": -91.22703897094726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01709294319153, "step": 14000}
{"episode_reward": 922.6351009955682, "episode": 15.0, "batch_reward": 0.7218073770403862, "critic_loss": 0.4543435858786106, "actor_loss": -91.4831046447754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01851201057434, "step": 15000}
{"episode_reward": 895.0962837507775, "episode": 16.0, "batch_reward": 0.736042727291584, "critic_loss": 0.4219247260689735, "actor_loss": -91.94700804138184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02471399307251, "step": 16000}
{"episode_reward": 944.5738816921247, "episode": 17.0, "batch_reward": 0.7219097403287887, "critic_loss": 0.4053353261500597, "actor_loss": -91.51066990661622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.360543966293335, "step": 17000}
{"episode_reward": 62.05364502398137, "episode": 18.0, "batch_reward": 0.7085949026346207, "critic_loss": 0.3919810857325792, "actor_loss": -90.99145944213868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.006489515304565, "step": 18000}
{"episode_reward": 914.7355002347437, "episode": 19.0, "batch_reward": 0.7178623920083046, "critic_loss": 0.39538510659337045, "actor_loss": -91.14005505371094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.984611749649048, "step": 19000}
{"episode_reward": 917.7085537245043, "episode": 20.0, "batch_reward": 0.7282067180871964, "critic_loss": 0.38080034525692463, "actor_loss": -91.20616203308106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99008822441101, "step": 20000}
{"episode_reward": 905.4759853486916, "episode": 21.0, "batch_reward": 0.7402148874998092, "critic_loss": 0.3672392457127571, "actor_loss": -91.43928219604493, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.567314863204956, "step": 21000}
{"episode_reward": 945.3871491214566, "episode": 22.0, "batch_reward": 0.7483335956335068, "critic_loss": 0.362832510471344, "actor_loss": -91.51237384033203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01810908317566, "step": 22000}
{"episode_reward": 908.1689090242995, "episode": 23.0, "batch_reward": 0.7531425915956497, "critic_loss": 0.37057707405090334, "actor_loss": -91.6105736541748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.017380952835083, "step": 23000}
{"episode_reward": 829.3147761261149, "episode": 24.0, "batch_reward": 0.7393108820319175, "critic_loss": 0.38116035050153735, "actor_loss": -90.90015000915527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.029875993728638, "step": 24000}
{"episode_reward": 58.86601833515303, "episode": 25.0, "batch_reward": 0.7304521935582161, "critic_loss": 0.3816454346030951, "actor_loss": -90.45096423339844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.012170791625977, "step": 25000}
{"episode_reward": 906.1826088414148, "episode": 26.0, "batch_reward": 0.7380601943135262, "critic_loss": 0.38129778584837914, "actor_loss": -90.59426998901367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00629162788391, "step": 26000}
{"episode_reward": 926.4017481438754, "episode": 27.0, "batch_reward": 0.7442244902849198, "critic_loss": 0.4190933740735054, "actor_loss": -90.41646633911132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00809097290039, "step": 27000}
{"episode_reward": 919.1171926529922, "episode": 28.0, "batch_reward": 0.7488864815235138, "critic_loss": 0.4259762018024921, "actor_loss": -90.57533204650879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03565788269043, "step": 28000}
{"episode_reward": 939.8815614851741, "episode": 29.0, "batch_reward": 0.7574738456010819, "critic_loss": 0.4244407853037119, "actor_loss": -90.6241398010254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.022879362106323, "step": 29000}
{"episode_reward": 956.6211368340331, "episode": 30.0, "batch_reward": 0.762640834748745, "critic_loss": 0.42620979830622674, "actor_loss": -90.93363375854493, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.022062301635742, "step": 30000}
{"episode_reward": 921.1516797028173, "episode": 31.0, "batch_reward": 0.7646284533143044, "critic_loss": 0.4538049156218767, "actor_loss": -91.01727070617676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.527724504470825, "step": 31000}
{"episode_reward": 874.7054379888616, "episode": 32.0, "batch_reward": 0.7712058094739914, "critic_loss": 0.443498611882329, "actor_loss": -91.26974484252929, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.008145093917847, "step": 32000}
{"episode_reward": 918.3429650042531, "episode": 33.0, "batch_reward": 0.7757551612854003, "critic_loss": 0.4114275185614824, "actor_loss": -91.34134022521972, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.999887704849243, "step": 33000}
{"episode_reward": 857.4972896743778, "episode": 34.0, "batch_reward": 0.7675459436774253, "critic_loss": 0.45466851742565634, "actor_loss": -91.35200357055665, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01970624923706, "step": 34000}
{"episode_reward": 348.3527890577795, "episode": 35.0, "batch_reward": 0.7681145841479301, "critic_loss": 0.45926861691474913, "actor_loss": -91.31329849243164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.005232334136963, "step": 35000}
{"episode_reward": 947.1074300420937, "episode": 36.0, "batch_reward": 0.7676966188549995, "critic_loss": 0.5123793411552906, "actor_loss": -91.19728437805176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.001769304275513, "step": 36000}
{"episode_reward": 764.7778297568243, "episode": 37.0, "batch_reward": 0.7725933665037155, "critic_loss": 0.526951477944851, "actor_loss": -91.23738217163086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.002465963363647, "step": 37000}
{"episode_reward": 965.4577015224048, "episode": 38.0, "batch_reward": 0.7768560383319855, "critic_loss": 0.5376998475939035, "actor_loss": -91.19514395141601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01699948310852, "step": 38000}
{"episode_reward": 947.210509982132, "episode": 39.0, "batch_reward": 0.7811008381843567, "critic_loss": 0.5741513947695494, "actor_loss": -91.48455897521973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.007638692855835, "step": 39000}
{"episode_reward": 956.1419315485173, "episode": 40.0, "batch_reward": 0.7836465244293213, "critic_loss": 0.7113229022473097, "actor_loss": -91.6741794128418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.007330894470215, "step": 40000}
{"episode_reward": 928.605638537112, "episode": 41.0, "batch_reward": 0.7887673466205597, "critic_loss": 0.9537365781217814, "actor_loss": -91.8830626525879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.58116364479065, "step": 41000}
{"episode_reward": 915.6196441156754, "episode": 42.0, "batch_reward": 0.7922641174793243, "critic_loss": 1.2776694089770317, "actor_loss": -91.96430212402343, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03005290031433, "step": 42000}
{"episode_reward": 958.9357746039523, "episode": 43.0, "batch_reward": 0.7970489099621773, "critic_loss": 2.0675208403170107, "actor_loss": -92.24464904785157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.007543325424194, "step": 43000}
{"episode_reward": 856.3067368518851, "episode": 44.0, "batch_reward": 0.7914213168025017, "critic_loss": 2.367369354456663, "actor_loss": -92.21651284790039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.004462957382202, "step": 44000}
{"episode_reward": 592.9575315602469, "episode": 45.0, "batch_reward": 0.7833493113517761, "critic_loss": 3.688852540999651, "actor_loss": -92.88929148864746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.024195432662964, "step": 45000}
{"episode_reward": 17.00191866180945, "episode": 46.0, "batch_reward": 0.7738784080147744, "critic_loss": 3.202761041402817, "actor_loss": -93.63027346801758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.016785144805908, "step": 46000}
{"episode_reward": 703.2600384726512, "episode": 47.0, "batch_reward": 0.7654346374869346, "critic_loss": 2.770712933242321, "actor_loss": -94.39265887451172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03539776802063, "step": 47000}
{"episode_reward": 29.111993613250316, "episode": 48.0, "batch_reward": 0.7558710709810257, "critic_loss": 2.316609718859196, "actor_loss": -95.32978097534179, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.021743297576904, "step": 48000}
{"episode_reward": 692.9928497847602, "episode": 49.0, "batch_reward": 0.7562038314342499, "critic_loss": 2.237033309340477, "actor_loss": -95.36818711853027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.003796339035034, "step": 49000}
{"episode_reward": 850.2903176681651, "episode": 50.0, "batch_reward": 0.7540685128569603, "critic_loss": 2.1392886946201326, "actor_loss": -95.40714364624023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00826406478882, "step": 50000}
{"episode_reward": 268.2462773905684, "episode": 51.0, "batch_reward": 0.743626684486866, "critic_loss": 1.996419995367527, "actor_loss": -96.38192822265626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.62723207473755, "step": 51000}
{"episode_reward": 141.48397418806417, "episode": 52.0, "batch_reward": 0.7375921452045441, "critic_loss": 1.6892297188043595, "actor_loss": -95.7872811126709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01036834716797, "step": 52000}
{"episode_reward": 822.5683146769177, "episode": 53.0, "batch_reward": 0.730315502166748, "critic_loss": 1.6253363875746727, "actor_loss": -96.51490188598633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0327730178833, "step": 53000}
{"episode_reward": 14.756693100725785, "episode": 54.0, "batch_reward": 0.7188742697238922, "critic_loss": 1.54330870115757, "actor_loss": -96.21804667663574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.011929273605347, "step": 54000}
{"episode_reward": 29.27282508800293, "episode": 55.0, "batch_reward": 0.7067291829586029, "critic_loss": 1.4383258577287197, "actor_loss": -96.35286503601074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.030980825424194, "step": 55000}
{"episode_reward": 93.91246493933323, "episode": 56.0, "batch_reward": 0.6972534855008126, "critic_loss": 1.4397495198249817, "actor_loss": -96.83514901733399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.031904935836792, "step": 56000}
{"episode_reward": 213.72177137629134, "episode": 57.0, "batch_reward": 0.6845090661048889, "critic_loss": 1.4662162538170815, "actor_loss": -96.48921513366699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.040656089782715, "step": 57000}
{"episode_reward": 16.974032460188685, "episode": 58.0, "batch_reward": 0.679310135781765, "critic_loss": 1.267928731739521, "actor_loss": -96.27952265930176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.046406269073486, "step": 58000}
{"episode_reward": 926.1129327228805, "episode": 59.0, "batch_reward": 0.6798607057332993, "critic_loss": 1.1344395572841168, "actor_loss": -95.37738264465332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01862382888794, "step": 59000}
{"episode_reward": 44.647359403181596, "episode": 60.0, "batch_reward": 0.6736342664361, "critic_loss": 1.0164931690990924, "actor_loss": -94.6660740966797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00844430923462, "step": 60000}
{"episode_reward": 397.7672638317482, "episode": 61.0, "batch_reward": 0.6654647750258446, "critic_loss": 0.8822543434798717, "actor_loss": -94.31802659606933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.627246379852295, "step": 61000}
{"episode_reward": 75.32808736184582, "episode": 62.0, "batch_reward": 0.6563065540790558, "critic_loss": 0.8138169988691807, "actor_loss": -94.35647186279297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.004324913024902, "step": 62000}
{"episode_reward": 212.90860574680454, "episode": 63.0, "batch_reward": 0.645496211707592, "critic_loss": 0.8185269968509674, "actor_loss": -94.07712724304199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01745629310608, "step": 63000}
{"episode_reward": 33.00423073958091, "episode": 64.0, "batch_reward": 0.6355690759420395, "critic_loss": 0.6882771202027798, "actor_loss": -92.98977546691894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03067708015442, "step": 64000}
{"episode_reward": 53.33406790537869, "episode": 65.0, "batch_reward": 0.6267854900360107, "critic_loss": 0.598048694089055, "actor_loss": -92.1808141784668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.03387188911438, "step": 65000}
{"episode_reward": 14.719831338497308, "episode": 66.0, "batch_reward": 0.6244909718930721, "critic_loss": 0.5825085784047842, "actor_loss": -91.53522506713867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01715397834778, "step": 66000}
{"episode_reward": 959.9295983784656, "episode": 67.0, "batch_reward": 0.6239607778191566, "critic_loss": 0.6498835061192513, "actor_loss": -91.00155377197265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.04201364517212, "step": 67000}
{"episode_reward": 59.78766030083153, "episode": 68.0, "batch_reward": 0.6179674400687217, "critic_loss": 0.6521373412907123, "actor_loss": -90.36109194946289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.042201280593872, "step": 68000}
{"episode_reward": 382.5796803554618, "episode": 69.0, "batch_reward": 0.6167187484502792, "critic_loss": 0.6422976194918155, "actor_loss": -89.84832923889161, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.999338626861572, "step": 69000}
{"episode_reward": 977.2888794331307, "episode": 70.0, "batch_reward": 0.6220715342462063, "critic_loss": 0.6350533958673478, "actor_loss": -89.32287152099609, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.000020742416382, "step": 70000}
{"episode_reward": 917.2797455256793, "episode": 71.0, "batch_reward": 0.6284849980473518, "critic_loss": 0.6458904317617417, "actor_loss": -88.84897633361817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.60549283027649, "step": 71000}
{"episode_reward": 933.9498052751227, "episode": 72.0, "batch_reward": 0.6317486012578011, "critic_loss": 0.6335353209972382, "actor_loss": -88.70796745300294, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997599363327026, "step": 72000}
{"episode_reward": 906.2989693262957, "episode": 73.0, "batch_reward": 0.6356379345655442, "critic_loss": 0.6120528800934553, "actor_loss": -88.56831069946288, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.008177280426025, "step": 73000}
{"episode_reward": 937.1516355354205, "episode": 74.0, "batch_reward": 0.6403231404423714, "critic_loss": 0.6074587706327438, "actor_loss": -88.45917071533204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.007476806640625, "step": 74000}
{"episode_reward": 855.537858155881, "episode": 75.0, "batch_reward": 0.6414492381215096, "critic_loss": 0.6210797510445117, "actor_loss": -88.36595349121093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.997787475585938, "step": 75000}
{"episode_reward": 919.6073692271053, "episode": 76.0, "batch_reward": 0.6401086765825749, "critic_loss": 0.6165430941283703, "actor_loss": -88.17402770996094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.024829149246216, "step": 76000}
{"episode_reward": 61.88298164068306, "episode": 77.0, "batch_reward": 0.6375443312525749, "critic_loss": 0.5802877340614796, "actor_loss": -87.88012010192871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99457859992981, "step": 77000}
{"episode_reward": 975.0220969797195, "episode": 78.0, "batch_reward": 0.6368012775778771, "critic_loss": 0.5891222910284996, "actor_loss": -87.79321556091308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.020025968551636, "step": 78000}
{"episode_reward": 61.14665850736652, "episode": 79.0, "batch_reward": 0.6332564814090729, "critic_loss": 0.6029999999701977, "actor_loss": -87.48364427185058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.010760068893433, "step": 79000}
{"episode_reward": 893.2388909343689, "episode": 80.0, "batch_reward": 0.637167024731636, "critic_loss": 0.6033468711823226, "actor_loss": -87.56316430664063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.015743732452393, "step": 80000}
{"episode_reward": 938.3602167855896, "episode": 81.0, "batch_reward": 0.640234862267971, "critic_loss": 0.5968259266316891, "actor_loss": -87.36180348205566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.57940125465393, "step": 81000}
{"episode_reward": 936.1852285030413, "episode": 82.0, "batch_reward": 0.6422718088030815, "critic_loss": 0.6055452518463135, "actor_loss": -87.307478515625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.021701335906982, "step": 82000}
{"episode_reward": 60.062383658988644, "episode": 83.0, "batch_reward": 0.6388000412583351, "critic_loss": 0.613687098518014, "actor_loss": -87.1678406829834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00781798362732, "step": 83000}
{"episode_reward": 872.9310629600134, "episode": 84.0, "batch_reward": 0.6415945553183555, "critic_loss": 0.6237574999928475, "actor_loss": -87.10879838562012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.995882034301758, "step": 84000}
{"episode_reward": 866.7743040484855, "episode": 85.0, "batch_reward": 0.6443469950258732, "critic_loss": 0.6489204400181771, "actor_loss": -86.97971113586426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00187659263611, "step": 85000}
{"episode_reward": 942.7552401348478, "episode": 86.0, "batch_reward": 0.6477410977482796, "critic_loss": 0.7051643739491701, "actor_loss": -87.04217872619628, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.994786262512207, "step": 86000}
{"episode_reward": 954.1651777061013, "episode": 87.0, "batch_reward": 0.6536924447417259, "critic_loss": 0.6859754722118377, "actor_loss": -87.25746946716309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99548363685608, "step": 87000}
{"episode_reward": 924.7463595188259, "episode": 88.0, "batch_reward": 0.6533038482069969, "critic_loss": 0.6820642220079899, "actor_loss": -87.21961911010742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.010255813598633, "step": 88000}
{"episode_reward": 967.468212360758, "episode": 89.0, "batch_reward": 0.6538710712194443, "critic_loss": 0.6578570182025433, "actor_loss": -87.11591079711914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.014010190963745, "step": 89000}
{"episode_reward": 60.16552927141473, "episode": 90.0, "batch_reward": 0.6515640894770622, "critic_loss": 0.6775339356660843, "actor_loss": -87.03105555725098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99773335456848, "step": 90000}
{"episode_reward": 962.1192453995458, "episode": 91.0, "batch_reward": 0.6575399636626243, "critic_loss": 0.6738341272622347, "actor_loss": -87.24545944213867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.845887422561646, "step": 91000}
{"episode_reward": 916.7859699061014, "episode": 92.0, "batch_reward": 0.6590610625743866, "critic_loss": 0.674663735896349, "actor_loss": -87.31958882141113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.97639036178589, "step": 92000}
{"episode_reward": 993.2101566478117, "episode": 93.0, "batch_reward": 0.6629555900096893, "critic_loss": 0.6667185233682394, "actor_loss": -87.45232341003418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.319148063659668, "step": 93000}
{"episode_reward": 943.2178196928306, "episode": 94.0, "batch_reward": 0.6618675217032433, "critic_loss": 0.7114944894015789, "actor_loss": -87.45603010559083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00749182701111, "step": 94000}
{"episode_reward": 934.9371463496893, "episode": 95.0, "batch_reward": 0.6661498847603798, "critic_loss": 0.65449912327528, "actor_loss": -87.67782192993164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.98937678337097, "step": 95000}
{"episode_reward": 885.7326304347881, "episode": 96.0, "batch_reward": 0.6690887404084206, "critic_loss": 0.6712928375899792, "actor_loss": -87.94844761657716, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.99516248703003, "step": 96000}
{"episode_reward": 679.7244715394495, "episode": 97.0, "batch_reward": 0.6677949456572533, "critic_loss": 0.6629768724292516, "actor_loss": -87.72778483581543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0084011554718, "step": 97000}
{"episode_reward": 957.7082825574105, "episode": 98.0, "batch_reward": 0.6719329626560211, "critic_loss": 0.7040651586651802, "actor_loss": -88.00599610900879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01963996887207, "step": 98000}
{"episode_reward": 856.6848858370855, "episode": 99.0, "batch_reward": 0.6752641131877899, "critic_loss": 0.6688125886917115, "actor_loss": -88.34718727111816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.003037691116333, "step": 99000}
{"episode_reward": 912.313440252022, "episode": 100.0, "batch_reward": 0.6743084582090377, "critic_loss": 0.6599474254250527, "actor_loss": -88.28254797363282, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.005168676376343, "step": 100000}
{"episode_reward": 852.4294789969102, "episode": 101.0, "batch_reward": 0.6784639037847519, "critic_loss": 0.6258179124891758, "actor_loss": -88.5303134765625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.58679509162903, "step": 101000}
{"episode_reward": 966.104485608682, "episode": 102.0, "batch_reward": 0.6812680106163025, "critic_loss": 0.636905378088355, "actor_loss": -88.61616497802734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.005244970321655, "step": 102000}
{"episode_reward": 900.2284357289071, "episode": 103.0, "batch_reward": 0.6827316610813141, "critic_loss": 0.639927437081933, "actor_loss": -88.78861083984376, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.0059711933136, "step": 103000}
{"episode_reward": 916.1629792476534, "episode": 104.0, "batch_reward": 0.6829507505893707, "critic_loss": 0.7779634552597999, "actor_loss": -89.1521859588623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.015652418136597, "step": 104000}
{"episode_reward": 61.11135568426557, "episode": 105.0, "batch_reward": 0.680371533036232, "critic_loss": 0.5991918586492538, "actor_loss": -89.32213468933105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.008697032928467, "step": 105000}
{"episode_reward": 939.1014495702156, "episode": 106.0, "batch_reward": 0.6827102766633034, "critic_loss": 0.5925302826166153, "actor_loss": -89.33802659606934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01865029335022, "step": 106000}
{"episode_reward": 929.2066593374027, "episode": 107.0, "batch_reward": 0.6832939692139626, "critic_loss": 0.5759072569906711, "actor_loss": -89.26204643249511, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.031200647354126, "step": 107000}
{"episode_reward": 488.0794662942882, "episode": 108.0, "batch_reward": 0.678226438164711, "critic_loss": 0.5890771653354168, "actor_loss": -89.22983561706543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.051348447799683, "step": 108000}
{"episode_reward": 58.31221693750329, "episode": 109.0, "batch_reward": 0.6753469035625458, "critic_loss": 0.5719206002652645, "actor_loss": -89.28911758422852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.016497373580933, "step": 109000}
{"episode_reward": 897.789879289489, "episode": 110.0, "batch_reward": 0.6802222757339478, "critic_loss": 0.5729800343960524, "actor_loss": -89.3209714050293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.005935192108154, "step": 110000}
{"episode_reward": 899.2679352447128, "episode": 111.0, "batch_reward": 0.6806653388738633, "critic_loss": 0.5710072156637908, "actor_loss": -88.97326983642579, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.57261919975281, "step": 111000}
{"episode_reward": 939.2214441000414, "episode": 112.0, "batch_reward": 0.685160465836525, "critic_loss": 0.5438758628219366, "actor_loss": -89.25266145324707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00923752784729, "step": 112000}
{"episode_reward": 952.4787654517762, "episode": 113.0, "batch_reward": 0.6855186579227448, "critic_loss": 0.5426997111439705, "actor_loss": -89.05831184387208, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00537872314453, "step": 113000}
{"episode_reward": 938.2449141651094, "episode": 114.0, "batch_reward": 0.6852562099099159, "critic_loss": 0.5341594641804696, "actor_loss": -88.97976585388183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00498628616333, "step": 114000}
{"episode_reward": 969.9245427349846, "episode": 115.0, "batch_reward": 0.6934454370737075, "critic_loss": 0.5373574171811343, "actor_loss": -89.21285774230957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00401759147644, "step": 115000}
{"episode_reward": 932.5970406949253, "episode": 116.0, "batch_reward": 0.6915348033308983, "critic_loss": 0.5126269022822381, "actor_loss": -89.07545642089843, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00563073158264, "step": 116000}
{"episode_reward": 923.8426754864797, "episode": 117.0, "batch_reward": 0.6960713486671448, "critic_loss": 0.5203916453421116, "actor_loss": -89.06024580383301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00881266593933, "step": 117000}
{"episode_reward": 941.3874113420592, "episode": 118.0, "batch_reward": 0.6959727890491486, "critic_loss": 0.5132363291531801, "actor_loss": -89.05742318725586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.016488790512085, "step": 118000}
{"episode_reward": 946.5815421445996, "episode": 119.0, "batch_reward": 0.6979216265678406, "critic_loss": 0.4853934966623783, "actor_loss": -89.10924258422851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.008885383605957, "step": 119000}
{"episode_reward": 959.5571394386135, "episode": 120.0, "batch_reward": 0.6992752631902694, "critic_loss": 0.4546725832819939, "actor_loss": -89.11993551635742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02172350883484, "step": 120000}
{"episode_reward": 950.9820762020393, "episode": 121.0, "batch_reward": 0.7049352939128876, "critic_loss": 0.46545720911026, "actor_loss": -89.3850853729248, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.59897303581238, "step": 121000}
{"episode_reward": 916.9069846270781, "episode": 122.0, "batch_reward": 0.7036714259982109, "critic_loss": 0.4790565968155861, "actor_loss": -89.34531982421875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.002054691314697, "step": 122000}
{"episode_reward": 933.3831485148418, "episode": 123.0, "batch_reward": 0.7061467388868332, "critic_loss": 0.4653753601461649, "actor_loss": -89.48458828735352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01335620880127, "step": 123000}
{"episode_reward": 979.2302016753698, "episode": 124.0, "batch_reward": 0.7089038082361221, "critic_loss": 0.49023433910310266, "actor_loss": -89.52415650939942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.001682996749878, "step": 124000}
{"episode_reward": 937.6809369732625, "episode": 125.0, "batch_reward": 0.7103630748391151, "critic_loss": 0.47328656962513926, "actor_loss": -89.5515842590332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.012054204940796, "step": 125000}
{"episode_reward": 879.8757726798308, "episode": 126.0, "batch_reward": 0.7123761640787125, "critic_loss": 0.4554418456107378, "actor_loss": -89.48661961364746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.000068426132202, "step": 126000}
{"episode_reward": 961.5410596249419, "episode": 127.0, "batch_reward": 0.7120243560671806, "critic_loss": 0.4610819063335657, "actor_loss": -89.6892989654541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.010772705078125, "step": 127000}
{"episode_reward": 936.7159047165659, "episode": 128.0, "batch_reward": 0.7147275818586349, "critic_loss": 0.46728831221163275, "actor_loss": -89.5690934753418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.017154216766357, "step": 128000}
{"episode_reward": 892.2564255084715, "episode": 129.0, "batch_reward": 0.7169748055338859, "critic_loss": 0.46408762599527836, "actor_loss": -89.58754615783691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.009225130081177, "step": 129000}
{"episode_reward": 981.8488249030083, "episode": 130.0, "batch_reward": 0.7203180141448975, "critic_loss": 0.4346656640768051, "actor_loss": -89.70460121154785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.009005069732666, "step": 130000}
{"episode_reward": 963.0999828664754, "episode": 131.0, "batch_reward": 0.7208466590046883, "critic_loss": 0.44950361670553685, "actor_loss": -89.72180332946778, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.61458992958069, "step": 131000}
{"episode_reward": 933.3224978186277, "episode": 132.0, "batch_reward": 0.720959800541401, "critic_loss": 0.469765047416091, "actor_loss": -89.7510274810791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.027599573135376, "step": 132000}
{"episode_reward": 952.8513473295377, "episode": 133.0, "batch_reward": 0.7224240378141403, "critic_loss": 0.4260493168234825, "actor_loss": -89.59016984558106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.039021015167236, "step": 133000}
{"episode_reward": 910.7824563751409, "episode": 134.0, "batch_reward": 0.725139985024929, "critic_loss": 0.44501256684958934, "actor_loss": -89.53804415893555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.013940811157227, "step": 134000}
{"episode_reward": 965.007177586958, "episode": 135.0, "batch_reward": 0.7259733214974403, "critic_loss": 0.4540624455064535, "actor_loss": -89.91228649902344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00365161895752, "step": 135000}
{"episode_reward": 932.5747757118795, "episode": 136.0, "batch_reward": 0.7294340036511421, "critic_loss": 0.45947921551018955, "actor_loss": -89.77749998474121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00968313217163, "step": 136000}
{"episode_reward": 956.287678350423, "episode": 137.0, "batch_reward": 0.7313753759860993, "critic_loss": 0.4279803491383791, "actor_loss": -90.13879879760742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00948667526245, "step": 137000}
{"episode_reward": 958.122404537083, "episode": 138.0, "batch_reward": 0.7334325850605965, "critic_loss": 0.43546164655685426, "actor_loss": -90.21627206420898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.021378993988037, "step": 138000}
{"episode_reward": 929.3350927347278, "episode": 139.0, "batch_reward": 0.7354633273482323, "critic_loss": 0.44740256637334824, "actor_loss": -90.24231340026856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.01170563697815, "step": 139000}
{"episode_reward": 955.8299173117629, "episode": 140.0, "batch_reward": 0.7373160533905029, "critic_loss": 0.43313760598003864, "actor_loss": -90.42631178283692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.009461402893066, "step": 140000}
{"episode_reward": 939.8433947238517, "episode": 141.0, "batch_reward": 0.7353328520059585, "critic_loss": 0.43489745211601255, "actor_loss": -90.4328793182373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.5712513923645, "step": 141000}
{"episode_reward": 939.2330934073187, "episode": 142.0, "batch_reward": 0.7371821411848068, "critic_loss": 0.4270252093076706, "actor_loss": -90.36354089355468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.010140419006348, "step": 142000}
{"episode_reward": 957.3356014028086, "episode": 143.0, "batch_reward": 0.7385983368754387, "critic_loss": 0.42252613899111746, "actor_loss": -90.47328977966309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00948476791382, "step": 143000}
{"episode_reward": 936.5711835974631, "episode": 144.0, "batch_reward": 0.738953961789608, "critic_loss": 0.39205947840213773, "actor_loss": -90.5917604675293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.025217056274414, "step": 144000}
{"episode_reward": 931.8026878795126, "episode": 145.0, "batch_reward": 0.741448964715004, "critic_loss": 0.38349121080338955, "actor_loss": -90.75115164184571, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.026877880096436, "step": 145000}
{"episode_reward": 849.2638840506384, "episode": 146.0, "batch_reward": 0.7439827329516411, "critic_loss": 0.40669746059179307, "actor_loss": -90.82569027709961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02414298057556, "step": 146000}
{"episode_reward": 964.6500300416079, "episode": 147.0, "batch_reward": 0.7473512190580368, "critic_loss": 0.4019287641197443, "actor_loss": -90.8900791015625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.02415657043457, "step": 147000}
{"episode_reward": 946.642447907058, "episode": 148.0, "batch_reward": 0.7449323039650917, "critic_loss": 0.3745303349494934, "actor_loss": -90.752056640625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.00895357131958, "step": 148000}
{"episode_reward": 929.7746186294818, "episode": 149.0, "batch_reward": 0.7466114476323128, "critic_loss": 0.3657702357918024, "actor_loss": -90.74034132385253, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.011113166809082, "step": 149000}
{"episode_reward": 991.0593036957165, "episode": 150.0, "batch_reward": 0.747558738231659, "critic_loss": 0.3858839897364378, "actor_loss": -90.76733337402344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
