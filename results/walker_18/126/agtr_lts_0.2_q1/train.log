{"episode_reward": 0.0, "episode": 1.0, "duration": 23.683164596557617, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.9040942192077637, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.4460527212292244, "critic_loss": 0.16116455852210262, "actor_loss": -82.87043530791223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 67.50906467437744, "step": 3000}
{"episode_reward": 315.9096007300571, "episode": 4.0, "batch_reward": 0.4221624904870987, "critic_loss": 0.6090065977275372, "actor_loss": -81.67647549438476, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.497352123260498, "step": 4000}
{"episode_reward": 505.8188257164484, "episode": 5.0, "batch_reward": 0.4332710864543915, "critic_loss": 0.8792650284171104, "actor_loss": -82.26629365539551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.131543159484863, "step": 5000}
{"episode_reward": 484.96737511461527, "episode": 6.0, "batch_reward": 0.4636869183778763, "critic_loss": 0.9906693373322487, "actor_loss": -82.48131921386718, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.293423175811768, "step": 6000}
{"episode_reward": 542.7720884872509, "episode": 7.0, "batch_reward": 0.4535642423629761, "critic_loss": 0.8274851175248623, "actor_loss": -81.6776429901123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.491607427597046, "step": 7000}
{"episode_reward": 227.34979756721472, "episode": 8.0, "batch_reward": 0.4383410590291023, "critic_loss": 0.9579742988348007, "actor_loss": -80.95187535095215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.273277759552002, "step": 8000}
{"episode_reward": 602.5420904989652, "episode": 9.0, "batch_reward": 0.452474782705307, "critic_loss": 1.286292877972126, "actor_loss": -81.34978791809083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.6013081073761, "step": 9000}
{"episode_reward": 551.8270299357783, "episode": 10.0, "batch_reward": 0.47193130022287366, "critic_loss": 1.5075405374765396, "actor_loss": -81.52998292541504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.10850954055786, "step": 10000}
{"episode_reward": 656.7190652187619, "episode": 11.0, "batch_reward": 0.4926001727581024, "critic_loss": 1.7477070865631104, "actor_loss": -81.42144119262696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.83134436607361, "step": 11000}
{"episode_reward": 733.032142829027, "episode": 12.0, "batch_reward": 0.5130127940177918, "critic_loss": 1.8938961951732636, "actor_loss": -81.76407879638671, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.476349115371704, "step": 12000}
{"episode_reward": 750.5113832217064, "episode": 13.0, "batch_reward": 0.5059335336685181, "critic_loss": 1.7528478680849076, "actor_loss": -80.5885424194336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.8875253200531, "step": 13000}
{"episode_reward": 39.98672266236192, "episode": 14.0, "batch_reward": 0.49053071919083596, "critic_loss": 1.708668223142624, "actor_loss": -79.29478248596192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.51308250427246, "step": 14000}
{"episode_reward": 451.58661117624746, "episode": 15.0, "batch_reward": 0.492332744628191, "critic_loss": 1.7821482680439948, "actor_loss": -78.65483647155762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.314712285995483, "step": 15000}
{"episode_reward": 733.76944618601, "episode": 16.0, "batch_reward": 0.5082693342268467, "critic_loss": 1.68083583176136, "actor_loss": -79.8905186920166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.333335876464844, "step": 16000}
{"episode_reward": 748.197411373655, "episode": 17.0, "batch_reward": 0.5256791367232799, "critic_loss": 1.6252715324163436, "actor_loss": -80.60200463867187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.826988220214844, "step": 17000}
{"episode_reward": 819.316690418302, "episode": 18.0, "batch_reward": 0.5368997518122196, "critic_loss": 1.5439930762052536, "actor_loss": -80.43405792236328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.276291131973267, "step": 18000}
{"episode_reward": 713.7934150964754, "episode": 19.0, "batch_reward": 0.5493516755104065, "critic_loss": 1.4605333475470543, "actor_loss": -80.5125724182129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.941795587539673, "step": 19000}
{"episode_reward": 804.9354256594094, "episode": 20.0, "batch_reward": 0.5654040138721466, "critic_loss": 1.4096667374968528, "actor_loss": -80.5272663269043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.782346725463867, "step": 20000}
{"episode_reward": 815.0336933019632, "episode": 21.0, "batch_reward": 0.576695617556572, "critic_loss": 1.4726794945001602, "actor_loss": -81.03552354431153, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.92590260505676, "step": 21000}
{"episode_reward": 796.3113377559604, "episode": 22.0, "batch_reward": 0.5887625984251499, "critic_loss": 1.417123605787754, "actor_loss": -80.78812789916992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.106595039367676, "step": 22000}
{"episode_reward": 851.9142529767582, "episode": 23.0, "batch_reward": 0.5993850627839565, "critic_loss": 1.459456235229969, "actor_loss": -81.07656539916992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.56144666671753, "step": 23000}
{"episode_reward": 877.2659000196682, "episode": 24.0, "batch_reward": 0.6085505513846874, "critic_loss": 1.3357291819453239, "actor_loss": -81.17846165466308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.351956129074097, "step": 24000}
{"episode_reward": 842.9791055403731, "episode": 25.0, "batch_reward": 0.6141517043113709, "critic_loss": 1.2829337816238404, "actor_loss": -81.2854310760498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.385198831558228, "step": 25000}
{"episode_reward": 613.5807602004428, "episode": 26.0, "batch_reward": 0.6215664502978325, "critic_loss": 1.2695893515348435, "actor_loss": -81.692390335083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.699567556381226, "step": 26000}
{"episode_reward": 871.6067241307431, "episode": 27.0, "batch_reward": 0.6294038434028626, "critic_loss": 1.293282482087612, "actor_loss": -81.59100396728516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.356046438217163, "step": 27000}
{"episode_reward": 829.1075924928541, "episode": 28.0, "batch_reward": 0.6367937344908714, "critic_loss": 1.222350648522377, "actor_loss": -82.37470390319824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.718564748764038, "step": 28000}
{"episode_reward": 883.8210953491968, "episode": 29.0, "batch_reward": 0.6477770674824714, "critic_loss": 1.1496939784884452, "actor_loss": -82.15090647888184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.756173849105835, "step": 29000}
{"episode_reward": 943.2754210608981, "episode": 30.0, "batch_reward": 0.6556126705408096, "critic_loss": 1.0533482319116592, "actor_loss": -82.68425245666504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.823463678359985, "step": 30000}
{"episode_reward": 894.828299361671, "episode": 31.0, "batch_reward": 0.6608669604659081, "critic_loss": 1.010598137408495, "actor_loss": -82.83207389831543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 45.55675148963928, "step": 31000}
{"episode_reward": 814.9597962797383, "episode": 32.0, "batch_reward": 0.6643902928233146, "critic_loss": 1.0057271520495414, "actor_loss": -82.64483654785157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.252527713775635, "step": 32000}
{"episode_reward": 742.2032261987738, "episode": 33.0, "batch_reward": 0.6691691067814827, "critic_loss": 1.0684633613824845, "actor_loss": -82.64376560974121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.60787034034729, "step": 33000}
{"episode_reward": 684.3843824275239, "episode": 34.0, "batch_reward": 0.6700397586226463, "critic_loss": 1.1031418007016183, "actor_loss": -82.658398727417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.744030952453613, "step": 34000}
{"episode_reward": 802.0524510204352, "episode": 35.0, "batch_reward": 0.6755772535800934, "critic_loss": 1.194077498793602, "actor_loss": -82.63931837463379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.05362820625305, "step": 35000}
{"episode_reward": 863.5204150668453, "episode": 36.0, "batch_reward": 0.6811334810256958, "critic_loss": 1.213730677008629, "actor_loss": -83.18056732177735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.642507791519165, "step": 36000}
{"episode_reward": 852.8086362403308, "episode": 37.0, "batch_reward": 0.687527821302414, "critic_loss": 1.27042485332489, "actor_loss": -83.6765944366455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.168327808380127, "step": 37000}
{"episode_reward": 896.1232153218076, "episode": 38.0, "batch_reward": 0.6918484927415848, "critic_loss": 1.2129420828223227, "actor_loss": -83.13920558166504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.311370849609375, "step": 38000}
{"episode_reward": 893.8118555629463, "episode": 39.0, "batch_reward": 0.69670651948452, "critic_loss": 1.080067609488964, "actor_loss": -83.67005448913574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.433252096176147, "step": 39000}
{"episode_reward": 914.1996762961078, "episode": 40.0, "batch_reward": 0.699387051641941, "critic_loss": 1.0298437460064889, "actor_loss": -83.89933575439453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.710439682006836, "step": 40000}
{"episode_reward": 878.372722241886, "episode": 41.0, "batch_reward": 0.7049930728673935, "critic_loss": 0.9911308354139328, "actor_loss": -84.37003782653808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 45.059834480285645, "step": 41000}
{"episode_reward": 892.1249064193684, "episode": 42.0, "batch_reward": 0.711365651011467, "critic_loss": 0.985867224752903, "actor_loss": -84.51894876098633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.721555471420288, "step": 42000}
{"episode_reward": 943.739296441682, "episode": 43.0, "batch_reward": 0.7177121769189835, "critic_loss": 0.8666248797178269, "actor_loss": -84.44804872131348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.452874660491943, "step": 43000}
{"episode_reward": 909.940934609834, "episode": 44.0, "batch_reward": 0.7201262504458428, "critic_loss": 0.8262752262949944, "actor_loss": -84.73894924926758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.04984474182129, "step": 44000}
{"episode_reward": 869.7706118149202, "episode": 45.0, "batch_reward": 0.7233657107353211, "critic_loss": 0.8213729127347469, "actor_loss": -84.59345353698731, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.469674825668335, "step": 45000}
{"episode_reward": 822.2340698348193, "episode": 46.0, "batch_reward": 0.7267350929379464, "critic_loss": 0.8174076100587845, "actor_loss": -85.00999589538574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.644540309906006, "step": 46000}
{"episode_reward": 878.3591386256263, "episode": 47.0, "batch_reward": 0.7301315816044808, "critic_loss": 0.8076328508555889, "actor_loss": -85.27538653564453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.427600383758545, "step": 47000}
{"episode_reward": 900.3903858043423, "episode": 48.0, "batch_reward": 0.7342490301728248, "critic_loss": 0.7682977017462254, "actor_loss": -84.92995126342774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.28681516647339, "step": 48000}
{"episode_reward": 929.0535665938983, "episode": 49.0, "batch_reward": 0.7377229869961739, "critic_loss": 0.7604250076115131, "actor_loss": -85.24738020324708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.204445362091064, "step": 49000}
{"episode_reward": 915.5154506858811, "episode": 50.0, "batch_reward": 0.7419050864577293, "critic_loss": 0.8071462824940682, "actor_loss": -85.70384904479981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.782989501953125, "step": 50000}
{"episode_reward": 920.6422468025836, "episode": 51.0, "batch_reward": 0.7467594415545463, "critic_loss": 0.7848067507743836, "actor_loss": -85.66831510925293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.62968873977661, "step": 51000}
{"episode_reward": 921.0426838964586, "episode": 52.0, "batch_reward": 0.7459010189771652, "critic_loss": 0.7892315816581249, "actor_loss": -85.89740727233887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.145875453948975, "step": 52000}
{"episode_reward": 926.0015185115802, "episode": 53.0, "batch_reward": 0.7503493959307671, "critic_loss": 0.7827361813187599, "actor_loss": -85.85373162841798, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.183902740478516, "step": 53000}
{"episode_reward": 837.1704520734055, "episode": 54.0, "batch_reward": 0.7521057216525078, "critic_loss": 0.781274282246828, "actor_loss": -86.22236569213867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.985677003860474, "step": 54000}
{"episode_reward": 901.4245015564229, "episode": 55.0, "batch_reward": 0.7545842243432999, "critic_loss": 0.7666184041798115, "actor_loss": -86.43565306091308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.73775839805603, "step": 55000}
{"episode_reward": 892.9701765061117, "episode": 56.0, "batch_reward": 0.7592982969880104, "critic_loss": 0.7536462339758873, "actor_loss": -86.36573527526855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.540618419647217, "step": 56000}
{"episode_reward": 938.1730780844853, "episode": 57.0, "batch_reward": 0.7629320319890976, "critic_loss": 0.751080795377493, "actor_loss": -86.66609307861329, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.657065629959106, "step": 57000}
{"episode_reward": 952.2492196792888, "episode": 58.0, "batch_reward": 0.7632940203547478, "critic_loss": 0.7441136302649974, "actor_loss": -86.6908985748291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.158429861068726, "step": 58000}
{"episode_reward": 901.8205869477969, "episode": 59.0, "batch_reward": 0.7677291192412377, "critic_loss": 0.7229596365094185, "actor_loss": -87.0956739654541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.10562753677368, "step": 59000}
{"episode_reward": 927.6868113554899, "episode": 60.0, "batch_reward": 0.7700486848950386, "critic_loss": 0.6963157394230366, "actor_loss": -87.37161158752441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.99456000328064, "step": 60000}
{"episode_reward": 892.6842053223795, "episode": 61.0, "batch_reward": 0.7716330572962761, "critic_loss": 0.719525623768568, "actor_loss": -87.46564881896973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 45.32011532783508, "step": 61000}
{"episode_reward": 896.4249138564229, "episode": 62.0, "batch_reward": 0.7727160784602165, "critic_loss": 0.697870103776455, "actor_loss": -87.49138720703125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.467054843902588, "step": 62000}
{"episode_reward": 901.6353928643172, "episode": 63.0, "batch_reward": 0.7739009469151497, "critic_loss": 0.7508543645441532, "actor_loss": -87.67542904663085, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.116010904312134, "step": 63000}
{"episode_reward": 857.2276196802958, "episode": 64.0, "batch_reward": 0.7780544792413712, "critic_loss": 0.7488684257864953, "actor_loss": -88.08610307312011, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.212974071502686, "step": 64000}
{"episode_reward": 920.8810174206495, "episode": 65.0, "batch_reward": 0.780403628885746, "critic_loss": 0.71909842684865, "actor_loss": -88.09793516540527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.241613388061523, "step": 65000}
{"episode_reward": 915.6710343058537, "episode": 66.0, "batch_reward": 0.782523270368576, "critic_loss": 0.7177801429629326, "actor_loss": -88.43056230163575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.068378686904907, "step": 66000}
{"episode_reward": 958.7344772855048, "episode": 67.0, "batch_reward": 0.7831808021068573, "critic_loss": 0.6941667476892471, "actor_loss": -88.56968452453613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.915331602096558, "step": 67000}
{"episode_reward": 939.6041859806201, "episode": 68.0, "batch_reward": 0.7848643346428871, "critic_loss": 0.7268028054535389, "actor_loss": -88.777912109375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.959978103637695, "step": 68000}
{"episode_reward": 913.501773436236, "episode": 69.0, "batch_reward": 0.7895545115470887, "critic_loss": 0.6697583279907703, "actor_loss": -89.05605319213868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.120773792266846, "step": 69000}
{"episode_reward": 934.529514759914, "episode": 70.0, "batch_reward": 0.7907647249698639, "critic_loss": 0.6656891465187073, "actor_loss": -89.12094931030273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.007102727890015, "step": 70000}
{"episode_reward": 902.2147509581149, "episode": 71.0, "batch_reward": 0.790840332865715, "critic_loss": 0.6887588041424751, "actor_loss": -89.21407051086426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.564934492111206, "step": 71000}
{"episode_reward": 920.4226062868908, "episode": 72.0, "batch_reward": 0.7939274688363075, "critic_loss": 0.6467100800573826, "actor_loss": -89.44394641113281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.9414381980896, "step": 72000}
{"episode_reward": 907.2908823381244, "episode": 73.0, "batch_reward": 0.7948235839605331, "critic_loss": 0.6517679259181023, "actor_loss": -89.6050906829834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.30718755722046, "step": 73000}
{"episode_reward": 960.6459554964257, "episode": 74.0, "batch_reward": 0.7982807672619819, "critic_loss": 0.6468309550285339, "actor_loss": -89.71215982055664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.19445514678955, "step": 74000}
{"episode_reward": 944.6101164645672, "episode": 75.0, "batch_reward": 0.8013835420012474, "critic_loss": 0.6577599740922451, "actor_loss": -89.96272442626953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.51088857650757, "step": 75000}
{"episode_reward": 941.8314919849929, "episode": 76.0, "batch_reward": 0.8015040946006775, "critic_loss": 0.7200384939312935, "actor_loss": -90.15562576293945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.29896354675293, "step": 76000}
{"episode_reward": 915.856786678355, "episode": 77.0, "batch_reward": 0.8031346911787987, "critic_loss": 0.6904562665224075, "actor_loss": -90.2480337524414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.17034363746643, "step": 77000}
{"episode_reward": 893.9585838187043, "episode": 78.0, "batch_reward": 0.8025212088227272, "critic_loss": 0.744055183082819, "actor_loss": -90.14107736206054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.025396823883057, "step": 78000}
{"episode_reward": 856.8101046006553, "episode": 79.0, "batch_reward": 0.8043283185958863, "critic_loss": 0.7120927503108978, "actor_loss": -90.23247671508788, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.317323923110962, "step": 79000}
{"episode_reward": 957.7558715377832, "episode": 80.0, "batch_reward": 0.8064262398481369, "critic_loss": 0.6598009303361178, "actor_loss": -90.49891427612305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.719748973846436, "step": 80000}
{"episode_reward": 935.9199117274493, "episode": 81.0, "batch_reward": 0.8084426997900009, "critic_loss": 0.6737730174064637, "actor_loss": -90.53715858459472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.679354667663574, "step": 81000}
{"episode_reward": 928.2336693186792, "episode": 82.0, "batch_reward": 0.8086141942739486, "critic_loss": 0.7166069005727768, "actor_loss": -90.55845466613769, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.265772104263306, "step": 82000}
{"episode_reward": 961.0076605456802, "episode": 83.0, "batch_reward": 0.8107358292937279, "critic_loss": 0.6558291387557983, "actor_loss": -90.84983317565919, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.9134259223938, "step": 83000}
{"episode_reward": 912.8084659519307, "episode": 84.0, "batch_reward": 0.8118582767248154, "critic_loss": 0.6888795084059238, "actor_loss": -90.87436122131348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.589762926101685, "step": 84000}
{"episode_reward": 919.6553820394254, "episode": 85.0, "batch_reward": 0.8125206216573715, "critic_loss": 0.6638753194510937, "actor_loss": -90.88582257080078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.56722068786621, "step": 85000}
{"episode_reward": 952.0032181371746, "episode": 86.0, "batch_reward": 0.8152061081528663, "critic_loss": 0.6456424442827702, "actor_loss": -91.12653942871094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.852092027664185, "step": 86000}
{"episode_reward": 950.1204319437792, "episode": 87.0, "batch_reward": 0.8160967761874199, "critic_loss": 0.642530866086483, "actor_loss": -91.11702505493164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.33285164833069, "step": 87000}
{"episode_reward": 932.8947865289289, "episode": 88.0, "batch_reward": 0.8194160723090171, "critic_loss": 0.6504751698076725, "actor_loss": -91.28989376831055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.426303386688232, "step": 88000}
{"episode_reward": 981.354905754598, "episode": 89.0, "batch_reward": 0.8206908661723137, "critic_loss": 0.6192053577303887, "actor_loss": -91.20111004638672, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.604772090911865, "step": 89000}
{"episode_reward": 946.1445145207776, "episode": 90.0, "batch_reward": 0.8208538497686386, "critic_loss": 0.6475036744177342, "actor_loss": -91.12462454223633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.96718430519104, "step": 90000}
{"episode_reward": 906.0751009355911, "episode": 91.0, "batch_reward": 0.8229682974815369, "critic_loss": 0.6355520868301392, "actor_loss": -91.3692338256836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 45.03208804130554, "step": 91000}
{"episode_reward": 924.5666880229599, "episode": 92.0, "batch_reward": 0.8243846381306649, "critic_loss": 0.6233466043770314, "actor_loss": -91.53673887634277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.515564918518066, "step": 92000}
{"episode_reward": 966.0060766671013, "episode": 93.0, "batch_reward": 0.8259580221176147, "critic_loss": 0.5903800137192011, "actor_loss": -91.55495346069335, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.58209800720215, "step": 93000}
{"episode_reward": 977.6160035165988, "episode": 94.0, "batch_reward": 0.8267110102176666, "critic_loss": 0.6272262688577175, "actor_loss": -91.69565830993652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.180270433425903, "step": 94000}
{"episode_reward": 834.628956921029, "episode": 95.0, "batch_reward": 0.826893649995327, "critic_loss": 0.6031192596554756, "actor_loss": -91.5354492340088, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.4053897857666, "step": 95000}
{"episode_reward": 865.1483766229846, "episode": 96.0, "batch_reward": 0.8275953313708305, "critic_loss": 0.5763411074876785, "actor_loss": -91.91820344543457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.916813850402832, "step": 96000}
{"episode_reward": 913.5781603081349, "episode": 97.0, "batch_reward": 0.8274857184290886, "critic_loss": 0.6021510965228081, "actor_loss": -91.78761010742187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.18017315864563, "step": 97000}
{"episode_reward": 872.566185031113, "episode": 98.0, "batch_reward": 0.8286779190301895, "critic_loss": 0.5893748168498277, "actor_loss": -91.71703126525878, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.90901827812195, "step": 98000}
{"episode_reward": 932.836700165525, "episode": 99.0, "batch_reward": 0.8290486431121826, "critic_loss": 0.6001246471107006, "actor_loss": -92.09205052185058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.125860452651978, "step": 99000}
{"episode_reward": 931.3384298064303, "episode": 100.0, "batch_reward": 0.8280875393748284, "critic_loss": 0.6186941148340702, "actor_loss": -91.97980674743653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.87090015411377, "step": 100000}
{"episode_reward": 927.2040150940956, "episode": 101.0, "batch_reward": 0.8330485000014305, "critic_loss": 0.6349928929507732, "actor_loss": -92.30736477661132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 45.363993883132935, "step": 101000}
{"episode_reward": 978.95128178741, "episode": 102.0, "batch_reward": 0.8334836708307266, "critic_loss": 0.6201405004113912, "actor_loss": -92.21059866333007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.994494676589966, "step": 102000}
{"episode_reward": 929.540346072273, "episode": 103.0, "batch_reward": 0.8342743136286735, "critic_loss": 0.6217760542929173, "actor_loss": -92.25442283630372, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.06397557258606, "step": 103000}
{"episode_reward": 956.5857577955531, "episode": 104.0, "batch_reward": 0.8338672965168953, "critic_loss": 0.6205582766234875, "actor_loss": -92.34489291381836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.984468698501587, "step": 104000}
{"episode_reward": 918.8513124687321, "episode": 105.0, "batch_reward": 0.8363841241002082, "critic_loss": 0.5847102069854736, "actor_loss": -92.4479691619873, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.755592346191406, "step": 105000}
{"episode_reward": 943.9851122529246, "episode": 106.0, "batch_reward": 0.8359936963319778, "critic_loss": 0.6188655012845993, "actor_loss": -92.5305700378418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.046003580093384, "step": 106000}
{"episode_reward": 878.2933268481373, "episode": 107.0, "batch_reward": 0.838012198805809, "critic_loss": 0.5897608315199614, "actor_loss": -92.58047990417481, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.69698476791382, "step": 107000}
{"episode_reward": 874.410419048243, "episode": 108.0, "batch_reward": 0.8369986572861672, "critic_loss": 0.6166356408894063, "actor_loss": -92.50730993652344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.663729190826416, "step": 108000}
{"episode_reward": 947.3536762732982, "episode": 109.0, "batch_reward": 0.8380624742507935, "critic_loss": 0.6366288270950318, "actor_loss": -92.61338073730468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.173651695251465, "step": 109000}
{"episode_reward": 903.2611949487525, "episode": 110.0, "batch_reward": 0.8393653377890586, "critic_loss": 0.6164852492064238, "actor_loss": -92.75347099304199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.163002967834473, "step": 110000}
{"episode_reward": 948.8102173817153, "episode": 111.0, "batch_reward": 0.8406609264016152, "critic_loss": 0.5987885002195835, "actor_loss": -92.7214857788086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 45.14125609397888, "step": 111000}
{"episode_reward": 971.7329269204946, "episode": 112.0, "batch_reward": 0.8425264875888825, "critic_loss": 0.5858513925671578, "actor_loss": -92.9959584197998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.49502968788147, "step": 112000}
{"episode_reward": 915.251584337739, "episode": 113.0, "batch_reward": 0.8425175321102142, "critic_loss": 0.5895014058053494, "actor_loss": -92.97085946655274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.083792209625244, "step": 113000}
{"episode_reward": 956.8154478314134, "episode": 114.0, "batch_reward": 0.8425118488073349, "critic_loss": 0.5799700076580048, "actor_loss": -93.0597213897705, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.971449851989746, "step": 114000}
{"episode_reward": 965.6191863489048, "episode": 115.0, "batch_reward": 0.8437923856973648, "critic_loss": 0.5659733154177665, "actor_loss": -93.09844567871093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.29496169090271, "step": 115000}
{"episode_reward": 950.2708960318669, "episode": 116.0, "batch_reward": 0.8474907896518707, "critic_loss": 0.5630637785047292, "actor_loss": -93.22506605529784, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.632161855697632, "step": 116000}
{"episode_reward": 929.2086588878736, "episode": 117.0, "batch_reward": 0.8455304168462753, "critic_loss": 0.5767006910592317, "actor_loss": -93.13942102050781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.016459465026855, "step": 117000}
{"episode_reward": 947.428560823745, "episode": 118.0, "batch_reward": 0.8459929422736168, "critic_loss": 0.5818226716965437, "actor_loss": -93.21346340942382, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.266899585723877, "step": 118000}
{"episode_reward": 943.6871192858328, "episode": 119.0, "batch_reward": 0.8483841312527657, "critic_loss": 0.57262381914258, "actor_loss": -93.29396575927734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.66485071182251, "step": 119000}
{"episode_reward": 915.0675385609067, "episode": 120.0, "batch_reward": 0.8489070868492127, "critic_loss": 0.565435273066163, "actor_loss": -93.28805613708496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.75454545021057, "step": 120000}
{"episode_reward": 948.5986359986487, "episode": 121.0, "batch_reward": 0.8490859217047692, "critic_loss": 0.5516824908107519, "actor_loss": -93.40901889038086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 45.06411290168762, "step": 121000}
{"episode_reward": 962.9846948892975, "episode": 122.0, "batch_reward": 0.849635545194149, "critic_loss": 0.5456766357123852, "actor_loss": -93.41771075439453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.447226524353027, "step": 122000}
{"episode_reward": 910.4195951225021, "episode": 123.0, "batch_reward": 0.8508834299445153, "critic_loss": 0.5399298068583012, "actor_loss": -93.49122573852539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.032493591308594, "step": 123000}
{"episode_reward": 964.5831630833566, "episode": 124.0, "batch_reward": 0.8514696345329285, "critic_loss": 0.5632571888267994, "actor_loss": -93.59441889953614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.63868284225464, "step": 124000}
{"episode_reward": 921.8109972886928, "episode": 125.0, "batch_reward": 0.8511762949824333, "critic_loss": 0.5503120045512915, "actor_loss": -93.69479164123535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.940040588378906, "step": 125000}
{"episode_reward": 906.816352022393, "episode": 126.0, "batch_reward": 0.8538098934888839, "critic_loss": 0.5704295136332512, "actor_loss": -93.60549002075196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.511810779571533, "step": 126000}
{"episode_reward": 950.2079335478863, "episode": 127.0, "batch_reward": 0.8527161217331887, "critic_loss": 0.5738876522481442, "actor_loss": -93.67243739318847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.435176134109497, "step": 127000}
{"episode_reward": 928.5433324935744, "episode": 128.0, "batch_reward": 0.8521458401679992, "critic_loss": 0.5712414428889752, "actor_loss": -93.6591594543457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.920670747756958, "step": 128000}
{"episode_reward": 861.7833511601352, "episode": 129.0, "batch_reward": 0.8525171019434928, "critic_loss": 0.6162830504477024, "actor_loss": -93.56818510437012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.11264967918396, "step": 129000}
{"episode_reward": 987.2445793997315, "episode": 130.0, "batch_reward": 0.8573844542503357, "critic_loss": 0.580609979569912, "actor_loss": -93.7088801574707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.957106351852417, "step": 130000}
{"episode_reward": 943.9370351425993, "episode": 131.0, "batch_reward": 0.8545402224659919, "critic_loss": 0.6102123894691467, "actor_loss": -93.66275778198242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.45702505111694, "step": 131000}
{"episode_reward": 914.7002131755087, "episode": 132.0, "batch_reward": 0.8557372151613235, "critic_loss": 0.5861402765363455, "actor_loss": -93.6870110168457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.207300186157227, "step": 132000}
{"episode_reward": 921.5746783487817, "episode": 133.0, "batch_reward": 0.8571026576161385, "critic_loss": 0.6012103811353445, "actor_loss": -93.6457032623291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.627195358276367, "step": 133000}
{"episode_reward": 954.2838586538729, "episode": 134.0, "batch_reward": 0.857679565012455, "critic_loss": 0.5640818385034799, "actor_loss": -93.77375675964356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.44542622566223, "step": 134000}
{"episode_reward": 949.928722932123, "episode": 135.0, "batch_reward": 0.8585669630765915, "critic_loss": 0.5780037531405687, "actor_loss": -93.86122839355468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.31327533721924, "step": 135000}
{"episode_reward": 928.3949815347962, "episode": 136.0, "batch_reward": 0.8583366718292237, "critic_loss": 0.5825462107360363, "actor_loss": -93.79369471740722, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.765172481536865, "step": 136000}
{"episode_reward": 900.8071640455871, "episode": 137.0, "batch_reward": 0.8572146856188774, "critic_loss": 0.5841022341400385, "actor_loss": -93.86592524719238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.654727697372437, "step": 137000}
{"episode_reward": 959.097891742476, "episode": 138.0, "batch_reward": 0.8606154547333718, "critic_loss": 0.5619510659724474, "actor_loss": -93.91641209411621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.00716233253479, "step": 138000}
{"episode_reward": 963.1556312774306, "episode": 139.0, "batch_reward": 0.8615305361747742, "critic_loss": 0.5821988833844661, "actor_loss": -93.83803520202636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10807728767395, "step": 139000}
{"episode_reward": 953.2032128257157, "episode": 140.0, "batch_reward": 0.8617124450206757, "critic_loss": 0.6236727497577668, "actor_loss": -93.9969160308838, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.36893343925476, "step": 140000}
{"episode_reward": 957.2846694747988, "episode": 141.0, "batch_reward": 0.8599466005563736, "critic_loss": 0.6085918850302696, "actor_loss": -93.92468955993652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.08320689201355, "step": 141000}
{"episode_reward": 935.8177193858342, "episode": 142.0, "batch_reward": 0.8620738015174866, "critic_loss": 0.5800472213178873, "actor_loss": -93.89076058959961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.41732406616211, "step": 142000}
{"episode_reward": 935.5576945495646, "episode": 143.0, "batch_reward": 0.862556903719902, "critic_loss": 0.6081549810171127, "actor_loss": -93.94912950134277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.921770334243774, "step": 143000}
{"episode_reward": 937.0372072251137, "episode": 144.0, "batch_reward": 0.8647501962780952, "critic_loss": 0.5872600356042386, "actor_loss": -94.07434245300293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.622386693954468, "step": 144000}
{"episode_reward": 933.0702451729957, "episode": 145.0, "batch_reward": 0.8645681286454201, "critic_loss": 0.5800305173844099, "actor_loss": -94.13142503356934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.962175369262695, "step": 145000}
{"episode_reward": 853.1532441031122, "episode": 146.0, "batch_reward": 0.8638399002552033, "critic_loss": 0.5609840961098671, "actor_loss": -94.16099064636231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.58959174156189, "step": 146000}
{"episode_reward": 940.3011412362933, "episode": 147.0, "batch_reward": 0.8645125184059143, "critic_loss": 0.551012102752924, "actor_loss": -94.20868811035156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.25346279144287, "step": 147000}
{"episode_reward": 945.4764322961463, "episode": 148.0, "batch_reward": 0.8638664240241051, "critic_loss": 0.5710937221497298, "actor_loss": -94.17026733398437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.5710346698761, "step": 148000}
{"episode_reward": 949.4077849348872, "episode": 149.0, "batch_reward": 0.8656146419644356, "critic_loss": 0.5548661507219076, "actor_loss": -94.22599418640137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.49899983406067, "step": 149000}
{"episode_reward": 989.7364298658124, "episode": 150.0, "batch_reward": 0.8649217360615731, "critic_loss": 0.5551564621180296, "actor_loss": -94.23955278015137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
