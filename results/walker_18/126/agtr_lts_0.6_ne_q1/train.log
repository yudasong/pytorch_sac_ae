{"episode_reward": 0.0, "episode": 1.0, "duration": 33.620084047317505, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 2.988487958908081, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.4386538147886581, "critic_loss": 0.1765729561299036, "actor_loss": -82.94905037515494, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 82.22776675224304, "step": 3000}
{"episode_reward": 125.44146140977557, "episode": 4.0, "batch_reward": 0.3674213561117649, "critic_loss": 0.5135588555932045, "actor_loss": -80.37983387756347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.01613736152649, "step": 4000}
{"episode_reward": 413.01418958626203, "episode": 5.0, "batch_reward": 0.33149571871757505, "critic_loss": 0.45682545909285543, "actor_loss": -79.24073262023926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.647566080093384, "step": 5000}
{"episode_reward": 137.1728408023948, "episode": 6.0, "batch_reward": 0.3344679591357708, "critic_loss": 0.6298508133292198, "actor_loss": -78.61150895690918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.713488578796387, "step": 6000}
{"episode_reward": 491.40829592620975, "episode": 7.0, "batch_reward": 0.3690240910947323, "critic_loss": 0.7822488650381565, "actor_loss": -79.11831950378418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.99833917617798, "step": 7000}
{"episode_reward": 675.8933651484257, "episode": 8.0, "batch_reward": 0.4174230298399925, "critic_loss": 0.8711011900305748, "actor_loss": -80.70136161804199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.5033757686615, "step": 8000}
{"episode_reward": 725.8309981280993, "episode": 9.0, "batch_reward": 0.4518030973672867, "critic_loss": 1.0057727786898614, "actor_loss": -81.67984031677246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.904518842697144, "step": 9000}
{"episode_reward": 729.0068401711425, "episode": 10.0, "batch_reward": 0.48148926204442977, "critic_loss": 1.1750701915025712, "actor_loss": -82.91033964538575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.961479902267456, "step": 10000}
{"episode_reward": 737.3474789052603, "episode": 11.0, "batch_reward": 0.5070206352472305, "critic_loss": 1.3576196724176406, "actor_loss": -83.71760681152344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.41932964324951, "step": 11000}
{"episode_reward": 741.3990989971977, "episode": 12.0, "batch_reward": 0.5163894201517105, "critic_loss": 1.4495462040305138, "actor_loss": -83.86357666015626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.52692437171936, "step": 12000}
{"episode_reward": 599.6975887523439, "episode": 13.0, "batch_reward": 0.5265252402424813, "critic_loss": 1.571485173344612, "actor_loss": -83.62731640625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.184032917022705, "step": 13000}
{"episode_reward": 662.9121881401128, "episode": 14.0, "batch_reward": 0.5434166085720062, "critic_loss": 1.5907912141680718, "actor_loss": -84.11039477539063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.24830412864685, "step": 14000}
{"episode_reward": 784.7275801528754, "episode": 15.0, "batch_reward": 0.5536776125431061, "critic_loss": 1.604473369717598, "actor_loss": -83.61719174194336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.157888650894165, "step": 15000}
{"episode_reward": 652.5336915002442, "episode": 16.0, "batch_reward": 0.5665255566835403, "critic_loss": 1.5726422960162163, "actor_loss": -84.73532820129394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.694796800613403, "step": 16000}
{"episode_reward": 782.2069033885892, "episode": 17.0, "batch_reward": 0.579238804101944, "critic_loss": 1.6845019724965096, "actor_loss": -84.78043811035157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.436983585357666, "step": 17000}
{"episode_reward": 780.2313087501174, "episode": 18.0, "batch_reward": 0.5930987551510334, "critic_loss": 1.7371532171964645, "actor_loss": -85.04862454223633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.768298625946045, "step": 18000}
{"episode_reward": 885.320009854227, "episode": 19.0, "batch_reward": 0.6086241058707237, "critic_loss": 1.6649749282598496, "actor_loss": -85.62923017883301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.373920917510986, "step": 19000}
{"episode_reward": 861.0563161355133, "episode": 20.0, "batch_reward": 0.6180344715714454, "critic_loss": 1.615023572742939, "actor_loss": -84.93433291625976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.828171491622925, "step": 20000}
{"episode_reward": 783.6219787529916, "episode": 21.0, "batch_reward": 0.6295401449203492, "critic_loss": 1.5218596739172936, "actor_loss": -85.8421678161621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 62.042563915252686, "step": 21000}
{"episode_reward": 847.1613432231163, "episode": 22.0, "batch_reward": 0.6410221003293991, "critic_loss": 1.4090701030492783, "actor_loss": -85.82914622497559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.968720197677612, "step": 22000}
{"episode_reward": 894.4108333955056, "episode": 23.0, "batch_reward": 0.6478023232221604, "critic_loss": 1.3401783447265625, "actor_loss": -86.04685006713868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.928837776184082, "step": 23000}
{"episode_reward": 837.4313665350493, "episode": 24.0, "batch_reward": 0.6586525038480758, "critic_loss": 1.280632222533226, "actor_loss": -86.33144953918458, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.52044677734375, "step": 24000}
{"episode_reward": 847.1297387778596, "episode": 25.0, "batch_reward": 0.6652294990420341, "critic_loss": 1.3094140657782554, "actor_loss": -86.457091796875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.676260471343994, "step": 25000}
{"episode_reward": 807.3278277943597, "episode": 26.0, "batch_reward": 0.6718552788496017, "critic_loss": 1.375943427503109, "actor_loss": -86.83997941589355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.084929704666138, "step": 26000}
{"episode_reward": 817.1973967066522, "episode": 27.0, "batch_reward": 0.6795837123394013, "critic_loss": 1.3710968468785285, "actor_loss": -86.68512200927735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.55132484436035, "step": 27000}
{"episode_reward": 859.9750357573197, "episode": 28.0, "batch_reward": 0.6825867846608162, "critic_loss": 1.3359014981985091, "actor_loss": -86.85317503356933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.523008584976196, "step": 28000}
{"episode_reward": 859.838836664412, "episode": 29.0, "batch_reward": 0.6915041444897652, "critic_loss": 1.4138890163898468, "actor_loss": -86.83991635131837, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.675697326660156, "step": 29000}
{"episode_reward": 898.2809226402314, "episode": 30.0, "batch_reward": 0.6961166964173316, "critic_loss": 1.357275115787983, "actor_loss": -86.8771536102295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.636767864227295, "step": 30000}
{"episode_reward": 872.7034137483754, "episode": 31.0, "batch_reward": 0.7023015606999398, "critic_loss": 1.3675883330106735, "actor_loss": -87.2791649017334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.18607807159424, "step": 31000}
{"episode_reward": 856.6694442553684, "episode": 32.0, "batch_reward": 0.7083940442204475, "critic_loss": 1.3636254935264587, "actor_loss": -87.52015008544922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.239915370941162, "step": 32000}
{"episode_reward": 891.155846513846, "episode": 33.0, "batch_reward": 0.7129066327214241, "critic_loss": 1.3067839452624321, "actor_loss": -87.54396701049805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.489659070968628, "step": 33000}
{"episode_reward": 848.7883357047124, "episode": 34.0, "batch_reward": 0.7172109480500222, "critic_loss": 1.2483059284687041, "actor_loss": -88.11285899353027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.166306734085083, "step": 34000}
{"episode_reward": 884.9835418078962, "episode": 35.0, "batch_reward": 0.723572603225708, "critic_loss": 1.1981431764364243, "actor_loss": -87.99741177368163, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.656740427017212, "step": 35000}
{"episode_reward": 880.5950372164514, "episode": 36.0, "batch_reward": 0.7273587819933891, "critic_loss": 1.1627579048275947, "actor_loss": -88.70773985290528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.434927940368652, "step": 36000}
{"episode_reward": 844.8239082396708, "episode": 37.0, "batch_reward": 0.7319963920116425, "critic_loss": 1.1022376658916473, "actor_loss": -88.4890108795166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.377095222473145, "step": 37000}
{"episode_reward": 907.6303154298535, "episode": 38.0, "batch_reward": 0.7362893643975258, "critic_loss": 1.1174846668839455, "actor_loss": -88.191336227417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.258715867996216, "step": 38000}
{"episode_reward": 890.7465908615322, "episode": 39.0, "batch_reward": 0.7411797295808792, "critic_loss": 1.000450874388218, "actor_loss": -88.83949491882325, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.18475365638733, "step": 39000}
{"episode_reward": 938.9454843566887, "episode": 40.0, "batch_reward": 0.7422417403459549, "critic_loss": 0.9836065695285797, "actor_loss": -89.06758100891113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.728416204452515, "step": 40000}
{"episode_reward": 896.2797389969472, "episode": 41.0, "batch_reward": 0.7466717143058776, "critic_loss": 0.9382086678445339, "actor_loss": -89.3875800628662, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 61.60185694694519, "step": 41000}
{"episode_reward": 894.7139670556638, "episode": 42.0, "batch_reward": 0.750719793498516, "critic_loss": 0.9162817007601262, "actor_loss": -89.04601901245117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.99358296394348, "step": 42000}
{"episode_reward": 964.2854142679975, "episode": 43.0, "batch_reward": 0.7584167810678482, "critic_loss": 0.8798836326599121, "actor_loss": -89.61963949584961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.051186561584473, "step": 43000}
{"episode_reward": 905.3579071653799, "episode": 44.0, "batch_reward": 0.7605820781588555, "critic_loss": 0.8846105140745639, "actor_loss": -89.29793630981445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.390641927719116, "step": 44000}
{"episode_reward": 891.5677548963761, "episode": 45.0, "batch_reward": 0.7636854383945465, "critic_loss": 0.8949428510963917, "actor_loss": -89.27617077636718, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.540388822555542, "step": 45000}
{"episode_reward": 871.7063119126408, "episode": 46.0, "batch_reward": 0.7667306265830993, "critic_loss": 0.8816539948284626, "actor_loss": -89.85081417846679, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.527930736541748, "step": 46000}
{"episode_reward": 895.6361720903661, "episode": 47.0, "batch_reward": 0.7689018622636795, "critic_loss": 0.869110121756792, "actor_loss": -89.96567501831055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.255810737609863, "step": 47000}
{"episode_reward": 907.9848109198197, "episode": 48.0, "batch_reward": 0.7717792084813118, "critic_loss": 0.8186232159435749, "actor_loss": -90.12311804199219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.558579444885254, "step": 48000}
{"episode_reward": 903.9179937172979, "episode": 49.0, "batch_reward": 0.7755235069394112, "critic_loss": 0.8323757956027985, "actor_loss": -90.28993702697754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.944816827774048, "step": 49000}
{"episode_reward": 894.8968702193882, "episode": 50.0, "batch_reward": 0.7771069985032082, "critic_loss": 0.8288314641714096, "actor_loss": -90.07303831481934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.42383098602295, "step": 50000}
{"episode_reward": 851.7454005791443, "episode": 51.0, "batch_reward": 0.7789289774894714, "critic_loss": 0.8501419256329537, "actor_loss": -90.04015991210937, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 60.49913954734802, "step": 51000}
{"episode_reward": 907.3412529606661, "episode": 52.0, "batch_reward": 0.7810466906428337, "critic_loss": 0.8507565937340259, "actor_loss": -90.45962579345704, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.721527099609375, "step": 52000}
{"episode_reward": 915.9995334329892, "episode": 53.0, "batch_reward": 0.7842441172599792, "critic_loss": 0.822922759860754, "actor_loss": -89.88828929138184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.37438941001892, "step": 53000}
{"episode_reward": 912.8198253172058, "episode": 54.0, "batch_reward": 0.7857619823217392, "critic_loss": 0.8493767790496349, "actor_loss": -90.7660207977295, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.615623950958252, "step": 54000}
{"episode_reward": 895.2760382547533, "episode": 55.0, "batch_reward": 0.787648263335228, "critic_loss": 0.8321493941247463, "actor_loss": -90.65021817016601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.675132036209106, "step": 55000}
{"episode_reward": 904.3364682925451, "episode": 56.0, "batch_reward": 0.7900805894136429, "critic_loss": 0.8300761149525643, "actor_loss": -90.42315827941894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.522588968276978, "step": 56000}
{"episode_reward": 940.0412996563803, "episode": 57.0, "batch_reward": 0.7853634371757507, "critic_loss": 0.8511946192383766, "actor_loss": -90.49818096923828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.51064157485962, "step": 57000}
{"episode_reward": 133.94402796028555, "episode": 58.0, "batch_reward": 0.7803034723997117, "critic_loss": 0.8099766427576542, "actor_loss": -90.52128784179688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.54133939743042, "step": 58000}
{"episode_reward": 924.5295613947362, "episode": 59.0, "batch_reward": 0.7834169824123383, "critic_loss": 0.7872548868954181, "actor_loss": -90.59979724121094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.27421522140503, "step": 59000}
{"episode_reward": 891.703804019571, "episode": 60.0, "batch_reward": 0.7857920345067978, "critic_loss": 0.7786640258133412, "actor_loss": -90.71572453308106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.584890604019165, "step": 60000}
{"episode_reward": 917.4545482549522, "episode": 61.0, "batch_reward": 0.787805903017521, "critic_loss": 0.7808966688215733, "actor_loss": -90.9331436920166, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 59.1258020401001, "step": 61000}
{"episode_reward": 863.5658454869522, "episode": 62.0, "batch_reward": 0.7869418800473214, "critic_loss": 0.7832876267433166, "actor_loss": -90.56312280273437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.10443139076233, "step": 62000}
{"episode_reward": 947.7640111852338, "episode": 63.0, "batch_reward": 0.788970136165619, "critic_loss": 0.8381242375671863, "actor_loss": -90.62086581420898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.330719470977783, "step": 63000}
{"episode_reward": 882.9842098617419, "episode": 64.0, "batch_reward": 0.7922012072205543, "critic_loss": 0.8188688362240791, "actor_loss": -90.97509761047364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.204804182052612, "step": 64000}
{"episode_reward": 836.5467143139048, "episode": 65.0, "batch_reward": 0.793102134346962, "critic_loss": 0.8199578642845153, "actor_loss": -90.79816616821289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.659541845321655, "step": 65000}
{"episode_reward": 920.542233824548, "episode": 66.0, "batch_reward": 0.7951964363455772, "critic_loss": 0.7741274419724942, "actor_loss": -91.05945018005372, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.353664875030518, "step": 66000}
{"episode_reward": 953.7879392815498, "episode": 67.0, "batch_reward": 0.7988626400232315, "critic_loss": 0.7422966134250164, "actor_loss": -91.02977366638184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.53991961479187, "step": 67000}
{"episode_reward": 939.7316553406109, "episode": 68.0, "batch_reward": 0.8004920334219933, "critic_loss": 0.732574668854475, "actor_loss": -91.36150962829589, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.335975170135498, "step": 68000}
{"episode_reward": 949.4226984664103, "episode": 69.0, "batch_reward": 0.80281281965971, "critic_loss": 0.7725505453348159, "actor_loss": -91.36726268005371, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.576621055603027, "step": 69000}
{"episode_reward": 908.7009288766488, "episode": 70.0, "batch_reward": 0.8042904109358787, "critic_loss": 0.7547022701799869, "actor_loss": -91.73399870300292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.755531549453735, "step": 70000}
{"episode_reward": 874.7192765406885, "episode": 71.0, "batch_reward": 0.8039777954220771, "critic_loss": 0.7584071345925331, "actor_loss": -91.29255410766602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 57.580925941467285, "step": 71000}
{"episode_reward": 936.8013358698498, "episode": 72.0, "batch_reward": 0.806450067281723, "critic_loss": 0.7356715604662896, "actor_loss": -91.71415251159668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.621038675308228, "step": 72000}
{"episode_reward": 876.8529990239597, "episode": 73.0, "batch_reward": 0.8059877055287361, "critic_loss": 0.7264026180505753, "actor_loss": -91.62956140136718, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.744948625564575, "step": 73000}
{"episode_reward": 910.526592830823, "episode": 74.0, "batch_reward": 0.8090840036869049, "critic_loss": 0.6919147272109986, "actor_loss": -91.76193399047851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.219624996185303, "step": 74000}
{"episode_reward": 905.8125462322763, "episode": 75.0, "batch_reward": 0.8117036097049714, "critic_loss": 0.6881279611885548, "actor_loss": -91.8920712890625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.206545114517212, "step": 75000}
{"episode_reward": 938.2371090501866, "episode": 76.0, "batch_reward": 0.8118557410240174, "critic_loss": 0.6686139505207539, "actor_loss": -91.94844085693359, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.75667953491211, "step": 76000}
{"episode_reward": 898.8242906380804, "episode": 77.0, "batch_reward": 0.8139578157663345, "critic_loss": 0.7104259661436081, "actor_loss": -92.05618597412109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.131596088409424, "step": 77000}
{"episode_reward": 915.082648630646, "episode": 78.0, "batch_reward": 0.8136872454881668, "critic_loss": 0.6737145717442036, "actor_loss": -91.9361742553711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.218088626861572, "step": 78000}
{"episode_reward": 914.3857079744305, "episode": 79.0, "batch_reward": 0.8145775066614152, "critic_loss": 0.6527610744237899, "actor_loss": -92.08740896606446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.6103458404541, "step": 79000}
{"episode_reward": 931.2880073384711, "episode": 80.0, "batch_reward": 0.8178683301210403, "critic_loss": 0.6549713464379311, "actor_loss": -92.18788897705078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.05154061317444, "step": 80000}
{"episode_reward": 946.2973232027445, "episode": 81.0, "batch_reward": 0.8179792979955673, "critic_loss": 0.6378376014083624, "actor_loss": -92.12002066040039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 56.75148820877075, "step": 81000}
{"episode_reward": 902.2477693653481, "episode": 82.0, "batch_reward": 0.8177796883583068, "critic_loss": 0.6157165514975786, "actor_loss": -92.18717059326171, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.35223698616028, "step": 82000}
{"episode_reward": 892.3494490279029, "episode": 83.0, "batch_reward": 0.8193583867549896, "critic_loss": 0.6148894208818674, "actor_loss": -92.43549176025391, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.29042959213257, "step": 83000}
{"episode_reward": 940.6229202825407, "episode": 84.0, "batch_reward": 0.8211479957699775, "critic_loss": 0.596337877318263, "actor_loss": -92.64467189025879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.077406406402588, "step": 84000}
{"episode_reward": 864.7620262466257, "episode": 85.0, "batch_reward": 0.8208538339138031, "critic_loss": 0.6278598438054324, "actor_loss": -92.39977110290528, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.559415817260742, "step": 85000}
{"episode_reward": 787.3231761135363, "episode": 86.0, "batch_reward": 0.8212362952828407, "critic_loss": 0.6137672033160925, "actor_loss": -92.35978086853028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.676175832748413, "step": 86000}
{"episode_reward": 908.6536258248243, "episode": 87.0, "batch_reward": 0.8231777963042259, "critic_loss": 0.6321212443113327, "actor_loss": -92.59193992614746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.27103018760681, "step": 87000}
{"episode_reward": 911.3754372798039, "episode": 88.0, "batch_reward": 0.8233700859546661, "critic_loss": 0.6398988196849823, "actor_loss": -92.67442974853516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.763609886169434, "step": 88000}
{"episode_reward": 966.8539858375126, "episode": 89.0, "batch_reward": 0.8257982310652733, "critic_loss": 0.6898543008863925, "actor_loss": -92.49399119567872, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.455824613571167, "step": 89000}
{"episode_reward": 931.2339178370194, "episode": 90.0, "batch_reward": 0.8273354356884957, "critic_loss": 0.6448433988690376, "actor_loss": -92.66658053588867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.15611743927002, "step": 90000}
{"episode_reward": 935.9095821271567, "episode": 91.0, "batch_reward": 0.8279300680756569, "critic_loss": 0.6571640940904617, "actor_loss": -92.59695469665527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 55.8838164806366, "step": 91000}
{"episode_reward": 906.0309185717377, "episode": 92.0, "batch_reward": 0.8267118335962296, "critic_loss": 0.6995580027401447, "actor_loss": -92.55698318481446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.117027044296265, "step": 92000}
{"episode_reward": 749.6151323435612, "episode": 93.0, "batch_reward": 0.8288425357341767, "critic_loss": 0.6747746799141169, "actor_loss": -92.63255435180665, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.532305479049683, "step": 93000}
{"episode_reward": 960.760780022053, "episode": 94.0, "batch_reward": 0.8299379522204399, "critic_loss": 0.6807842237651348, "actor_loss": -92.78657336425782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.778069257736206, "step": 94000}
{"episode_reward": 906.9624571989153, "episode": 95.0, "batch_reward": 0.8303590732812881, "critic_loss": 0.6732966065704823, "actor_loss": -92.85662026977539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.622902870178223, "step": 95000}
{"episode_reward": 903.7247014127304, "episode": 96.0, "batch_reward": 0.8304728348851204, "critic_loss": 0.6789244467914104, "actor_loss": -92.815275390625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.47111964225769, "step": 96000}
{"episode_reward": 949.7987883471861, "episode": 97.0, "batch_reward": 0.8281112271547317, "critic_loss": 0.661632365912199, "actor_loss": -92.87391909790038, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.540876388549805, "step": 97000}
{"episode_reward": 313.70995602660423, "episode": 98.0, "batch_reward": 0.8267258013486862, "critic_loss": 0.6777391886562109, "actor_loss": -92.6748763885498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.44801425933838, "step": 98000}
{"episode_reward": 923.4011860523159, "episode": 99.0, "batch_reward": 0.8281572351455688, "critic_loss": 0.6695125487148762, "actor_loss": -92.8669609375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.60776400566101, "step": 99000}
{"episode_reward": 903.2995556329006, "episode": 100.0, "batch_reward": 0.8281155412197113, "critic_loss": 0.6475167529582977, "actor_loss": -92.85053587341308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.84723734855652, "step": 100000}
{"episode_reward": 942.3855155425634, "episode": 101.0, "batch_reward": 0.8307915534377098, "critic_loss": 0.6826115656197072, "actor_loss": -93.05659175109864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 54.674604177474976, "step": 101000}
{"episode_reward": 942.1280256758316, "episode": 102.0, "batch_reward": 0.8314863229990006, "critic_loss": 0.6812380796670914, "actor_loss": -93.01457919311524, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.410406589508057, "step": 102000}
{"episode_reward": 937.0124224242513, "episode": 103.0, "batch_reward": 0.832307332277298, "critic_loss": 0.6840880971848965, "actor_loss": -92.96111486816406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.350600242614746, "step": 103000}
{"episode_reward": 907.64031402722, "episode": 104.0, "batch_reward": 0.8322574752569198, "critic_loss": 0.710367218926549, "actor_loss": -93.09488821411132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.763386726379395, "step": 104000}
{"episode_reward": 900.0532900122296, "episode": 105.0, "batch_reward": 0.834113156914711, "critic_loss": 0.7025394019186497, "actor_loss": -92.94706553649903, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.501921892166138, "step": 105000}
{"episode_reward": 945.5220477602965, "episode": 106.0, "batch_reward": 0.8336184101104737, "critic_loss": 0.6991188313364982, "actor_loss": -93.14803643798828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.684484243392944, "step": 106000}
{"episode_reward": 889.5207578419256, "episode": 107.0, "batch_reward": 0.8341521306037902, "critic_loss": 0.7055204271078109, "actor_loss": -93.04905989074707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.398481130599976, "step": 107000}
{"episode_reward": 891.6904231451396, "episode": 108.0, "batch_reward": 0.8336766255497933, "critic_loss": 0.6860016575604677, "actor_loss": -92.93075343322754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.446280002593994, "step": 108000}
{"episode_reward": 930.3104294762707, "episode": 109.0, "batch_reward": 0.8336459922194481, "critic_loss": 0.7112700969874859, "actor_loss": -93.14629434204102, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.300384521484375, "step": 109000}
{"episode_reward": 733.6077007186814, "episode": 110.0, "batch_reward": 0.8348458896875381, "critic_loss": 0.7268205289840698, "actor_loss": -93.25218807983399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.653085708618164, "step": 110000}
{"episode_reward": 930.8896412870608, "episode": 111.0, "batch_reward": 0.8363248774409294, "critic_loss": 0.7355487988591194, "actor_loss": -92.97653410339356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 55.50172829627991, "step": 111000}
{"episode_reward": 899.6554622426652, "episode": 112.0, "batch_reward": 0.837291011929512, "critic_loss": 0.7561416360735893, "actor_loss": -93.27426765441895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.79930329322815, "step": 112000}
{"episode_reward": 921.6162069016121, "episode": 113.0, "batch_reward": 0.8376943413615227, "critic_loss": 0.7823142317384482, "actor_loss": -93.112810546875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.69553565979004, "step": 113000}
{"episode_reward": 936.055006512476, "episode": 114.0, "batch_reward": 0.8374653448462486, "critic_loss": 0.754329722136259, "actor_loss": -93.25565965270997, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.828038930892944, "step": 114000}
{"episode_reward": 955.8697536361177, "episode": 115.0, "batch_reward": 0.8392561374902725, "critic_loss": 0.7459143138527871, "actor_loss": -93.19393249511718, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.652165412902832, "step": 115000}
{"episode_reward": 934.0941124277458, "episode": 116.0, "batch_reward": 0.8409758962392807, "critic_loss": 0.7558518467098474, "actor_loss": -93.32477619934082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.57953143119812, "step": 116000}
{"episode_reward": 858.9702131200239, "episode": 117.0, "batch_reward": 0.8415933476090431, "critic_loss": 0.8534843017160892, "actor_loss": -93.08873580932617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.4913170337677, "step": 117000}
{"episode_reward": 904.5590636718738, "episode": 118.0, "batch_reward": 0.8395353760123253, "critic_loss": 0.8213236342072487, "actor_loss": -93.17469647216797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.635106325149536, "step": 118000}
{"episode_reward": 913.7894787487094, "episode": 119.0, "batch_reward": 0.8425243617296219, "critic_loss": 0.7901332297921181, "actor_loss": -93.26659007263184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.448190689086914, "step": 119000}
{"episode_reward": 933.1557875565987, "episode": 120.0, "batch_reward": 0.842174920618534, "critic_loss": 0.7675846135318279, "actor_loss": -93.2184651184082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.675715684890747, "step": 120000}
{"episode_reward": 933.5965626879653, "episode": 121.0, "batch_reward": 0.8430829781889916, "critic_loss": 0.7654443927407265, "actor_loss": -93.22915853881835, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 55.915008783340454, "step": 121000}
{"episode_reward": 922.0041201620774, "episode": 122.0, "batch_reward": 0.844146461546421, "critic_loss": 0.7511457462608814, "actor_loss": -93.2557152557373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.864330530166626, "step": 122000}
{"episode_reward": 891.1218346674623, "episode": 123.0, "batch_reward": 0.8445985137224198, "critic_loss": 0.7441522757411003, "actor_loss": -93.56854029846191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.385491609573364, "step": 123000}
{"episode_reward": 931.4613802042649, "episode": 124.0, "batch_reward": 0.8458154262900353, "critic_loss": 0.7613355676829815, "actor_loss": -93.45133638000489, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.743982315063477, "step": 124000}
{"episode_reward": 933.2529158861333, "episode": 125.0, "batch_reward": 0.8450906133055687, "critic_loss": 0.7458032768964767, "actor_loss": -93.55767665100097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.750566005706787, "step": 125000}
{"episode_reward": 905.5913917863015, "episode": 126.0, "batch_reward": 0.8464080481529236, "critic_loss": 0.771909017175436, "actor_loss": -93.41220370483398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.44332242012024, "step": 126000}
{"episode_reward": 943.5218003460944, "episode": 127.0, "batch_reward": 0.8467461512088775, "critic_loss": 0.7431840608268976, "actor_loss": -93.50302191162109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.55714464187622, "step": 127000}
{"episode_reward": 947.6421375081514, "episode": 128.0, "batch_reward": 0.8469232473373413, "critic_loss": 0.74126614305377, "actor_loss": -93.57462384033204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.448444366455078, "step": 128000}
{"episode_reward": 927.3752829237955, "episode": 129.0, "batch_reward": 0.8479006338119507, "critic_loss": 0.7226803773343563, "actor_loss": -93.47333479309081, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.645025730133057, "step": 129000}
{"episode_reward": 959.3347833452456, "episode": 130.0, "batch_reward": 0.8507681399583816, "critic_loss": 0.734560234695673, "actor_loss": -93.60902923583984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.291130304336548, "step": 130000}
{"episode_reward": 911.7119175021655, "episode": 131.0, "batch_reward": 0.8496847809553146, "critic_loss": 0.765073200955987, "actor_loss": -93.6111859741211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 56.89028739929199, "step": 131000}
{"episode_reward": 923.0154549813669, "episode": 132.0, "batch_reward": 0.8499540775418282, "critic_loss": 0.6819609445035457, "actor_loss": -93.83894049072265, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 28.07288908958435, "step": 132000}
{"episode_reward": 906.0011326635662, "episode": 133.0, "batch_reward": 0.8511101918816566, "critic_loss": 0.647474129781127, "actor_loss": -93.73206280517579, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.595219612121582, "step": 133000}
{"episode_reward": 932.1499903235056, "episode": 134.0, "batch_reward": 0.8518881008028985, "critic_loss": 0.6641482355296612, "actor_loss": -93.61916136169434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.230725049972534, "step": 134000}
{"episode_reward": 902.9274503502816, "episode": 135.0, "batch_reward": 0.8518007581830025, "critic_loss": 0.6429872405081988, "actor_loss": -93.90246899414062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.83397603034973, "step": 135000}
{"episode_reward": 907.6227399979975, "episode": 136.0, "batch_reward": 0.8517496578097343, "critic_loss": 0.6136612577736378, "actor_loss": -93.49013677978516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.733205556869507, "step": 136000}
{"episode_reward": 898.8402150807091, "episode": 137.0, "batch_reward": 0.851824383854866, "critic_loss": 0.6224381610751152, "actor_loss": -93.82450346374512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.525177240371704, "step": 137000}
{"episode_reward": 946.0186917815876, "episode": 138.0, "batch_reward": 0.8541478831768036, "critic_loss": 0.5883516167253255, "actor_loss": -93.86753875732421, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.35383105278015, "step": 138000}
{"episode_reward": 957.4942725530843, "episode": 139.0, "batch_reward": 0.8542052162885666, "critic_loss": 0.5775895472168923, "actor_loss": -93.84245875549317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.781594038009644, "step": 139000}
{"episode_reward": 945.1495072443706, "episode": 140.0, "batch_reward": 0.8557105566263199, "critic_loss": 0.5700144510567188, "actor_loss": -93.93116053771972, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 29.798049449920654, "step": 140000}
{"episode_reward": 933.0852755895503, "episode": 141.0, "batch_reward": 0.8540418766736985, "critic_loss": 0.571232231900096, "actor_loss": -93.88158645629883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 57.53353977203369, "step": 141000}
{"episode_reward": 901.6671010967463, "episode": 142.0, "batch_reward": 0.8554160194396973, "critic_loss": 0.5750401992946863, "actor_loss": -93.82852603149414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 27.032185077667236, "step": 142000}
{"episode_reward": 934.0857804658087, "episode": 143.0, "batch_reward": 0.8543427866101265, "critic_loss": 0.5696256769448519, "actor_loss": -93.8499430847168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.939809322357178, "step": 143000}
{"episode_reward": 911.8456000542513, "episode": 144.0, "batch_reward": 0.8569968162178994, "critic_loss": 0.5455970991104842, "actor_loss": -94.08118704223632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 26.970229864120483, "step": 144000}
{"episode_reward": 876.3478975893413, "episode": 145.0, "batch_reward": 0.8563656015992165, "critic_loss": 0.5258500581234693, "actor_loss": -94.04589047241211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.647709131240845, "step": 145000}
{"episode_reward": 885.4081736096157, "episode": 146.0, "batch_reward": 0.8561333518028259, "critic_loss": 0.5601208263784647, "actor_loss": -94.1144387512207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 31.109187841415405, "step": 146000}
{"episode_reward": 926.9685489874524, "episode": 147.0, "batch_reward": 0.8564228932261467, "critic_loss": 0.5371111568361521, "actor_loss": -94.04174812316894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.80713725090027, "step": 147000}
{"episode_reward": 902.8974493397194, "episode": 148.0, "batch_reward": 0.8563661977052689, "critic_loss": 0.5132898123115301, "actor_loss": -94.0114782409668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.840404987335205, "step": 148000}
{"episode_reward": 902.4691713327954, "episode": 149.0, "batch_reward": 0.8564188261032104, "critic_loss": 0.532118193462491, "actor_loss": -94.00111782836915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 30.408427238464355, "step": 149000}
{"episode_reward": 958.5366041869338, "episode": 150.0, "batch_reward": 0.8575857990384101, "critic_loss": 0.5260418768823146, "actor_loss": -94.07099552917481, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
