{"episode_reward": 0.0, "episode": 1.0, "duration": 21.799708127975464, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.9265387058258057, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.43625422595202346, "critic_loss": 0.12657953845228342, "actor_loss": -81.57270188959373, "actor_target_entropy": -6.0, "alpha_value": 0.002642586817083679, "duration": 68.48162055015564, "step": 3000}
{"episode_reward": 22.37481057574728, "episode": 4.0, "batch_reward": 0.2912139985263348, "critic_loss": 0.3424115486294031, "actor_loss": -75.48007479858398, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.68519926071167, "step": 4000}
{"episode_reward": 194.7696853532197, "episode": 5.0, "batch_reward": 0.2897304197996855, "critic_loss": 0.5668604427874089, "actor_loss": -76.57288696289062, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.291205644607544, "step": 5000}
{"episode_reward": 332.0915875760462, "episode": 6.0, "batch_reward": 0.3059574519097805, "critic_loss": 0.7247260791361332, "actor_loss": -77.3531879272461, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.190563440322876, "step": 6000}
{"episode_reward": 398.3319986061989, "episode": 7.0, "batch_reward": 0.3086505637168884, "critic_loss": 0.9984432240724563, "actor_loss": -77.85386932373046, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.20759105682373, "step": 7000}
{"episode_reward": 260.3934385401212, "episode": 8.0, "batch_reward": 0.3212160810679197, "critic_loss": 1.0223529851436615, "actor_loss": -78.90907009887695, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.240705966949463, "step": 8000}
{"episode_reward": 611.6921218678575, "episode": 9.0, "batch_reward": 0.3583535947203636, "critic_loss": 1.2758085809350013, "actor_loss": -79.72826235961914, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.053581714630127, "step": 9000}
{"episode_reward": 643.1779225274022, "episode": 10.0, "batch_reward": 0.39198853632807734, "critic_loss": 1.427679212272167, "actor_loss": -80.94299368286133, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.52984309196472, "step": 10000}
{"episode_reward": 688.3764455763742, "episode": 11.0, "batch_reward": 0.4234494854211807, "critic_loss": 1.5081865950226783, "actor_loss": -81.82200187683105, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.31256556510925, "step": 11000}
{"episode_reward": 795.4983602711866, "episode": 12.0, "batch_reward": 0.4540137372910976, "critic_loss": 1.5752693940997124, "actor_loss": -82.77590713500976, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.59302592277527, "step": 12000}
{"episode_reward": 751.7121847031555, "episode": 13.0, "batch_reward": 0.478773928642273, "critic_loss": 1.5310872492790222, "actor_loss": -83.28738429260254, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.59562659263611, "step": 13000}
{"episode_reward": 778.0800435421047, "episode": 14.0, "batch_reward": 0.49837544944882395, "critic_loss": 1.4691159360408783, "actor_loss": -83.9692619934082, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.761683702468872, "step": 14000}
{"episode_reward": 725.0885281098847, "episode": 15.0, "batch_reward": 0.5182591407299042, "critic_loss": 1.2848720179200173, "actor_loss": -84.03912762451172, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.131617307662964, "step": 15000}
{"episode_reward": 815.5659974326501, "episode": 16.0, "batch_reward": 0.5389417533874512, "critic_loss": 1.1286614094972611, "actor_loss": -85.24926293945313, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.592205047607422, "step": 16000}
{"episode_reward": 861.9695441527928, "episode": 17.0, "batch_reward": 0.5564325125813484, "critic_loss": 1.0436480973362923, "actor_loss": -85.51008567810058, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.95675492286682, "step": 17000}
{"episode_reward": 819.5685699058622, "episode": 18.0, "batch_reward": 0.5718491423726082, "critic_loss": 0.9241587265133858, "actor_loss": -85.81141041564942, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.968323230743408, "step": 18000}
{"episode_reward": 830.6381578362667, "episode": 19.0, "batch_reward": 0.5872670530080796, "critic_loss": 0.8241533925235272, "actor_loss": -86.26501640319825, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.008082628250122, "step": 19000}
{"episode_reward": 871.9375533421114, "episode": 20.0, "batch_reward": 0.6026474259793758, "critic_loss": 0.77207205042243, "actor_loss": -85.83452726745605, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.601783514022827, "step": 20000}
{"episode_reward": 854.7548802433776, "episode": 21.0, "batch_reward": 0.6126825273036957, "critic_loss": 0.7494947772622108, "actor_loss": -86.43616952514648, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 44.099817514419556, "step": 21000}
{"episode_reward": 775.9270619412484, "episode": 22.0, "batch_reward": 0.6240859269499779, "critic_loss": 0.7467024773657321, "actor_loss": -86.26938424682618, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.746450424194336, "step": 22000}
{"episode_reward": 861.5072115449929, "episode": 23.0, "batch_reward": 0.6311544992923737, "critic_loss": 0.6953975144326687, "actor_loss": -86.48974041748046, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.197040557861328, "step": 23000}
{"episode_reward": 874.0834843365188, "episode": 24.0, "batch_reward": 0.6404040731787681, "critic_loss": 0.6972654604911804, "actor_loss": -86.57922747802735, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.107401609420776, "step": 24000}
{"episode_reward": 800.918198741177, "episode": 25.0, "batch_reward": 0.6336604754328727, "critic_loss": 0.7222759520113469, "actor_loss": -86.20374101257325, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.834888458251953, "step": 25000}
{"episode_reward": 76.15500618819323, "episode": 26.0, "batch_reward": 0.6266785430908203, "critic_loss": 0.7031703947484493, "actor_loss": -86.2318108215332, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.367002487182617, "step": 26000}
{"episode_reward": 832.4415117932222, "episode": 27.0, "batch_reward": 0.6359097098708153, "critic_loss": 0.7125248164534569, "actor_loss": -86.07884399414063, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.444414377212524, "step": 27000}
{"episode_reward": 851.8619461247733, "episode": 28.0, "batch_reward": 0.6409014027714729, "critic_loss": 0.7282201525270939, "actor_loss": -86.25237191772462, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.89946746826172, "step": 28000}
{"episode_reward": 830.7543818933441, "episode": 29.0, "batch_reward": 0.6514243919849396, "critic_loss": 0.7356195049881935, "actor_loss": -86.19386886596679, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.266119241714478, "step": 29000}
{"episode_reward": 913.1578316767443, "episode": 30.0, "batch_reward": 0.6568563244342804, "critic_loss": 0.736690717190504, "actor_loss": -86.22798794555663, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.062728881835938, "step": 30000}
{"episode_reward": 846.6002231469395, "episode": 31.0, "batch_reward": 0.6625187755227089, "critic_loss": 0.7362284015715123, "actor_loss": -86.56130097961426, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.83114218711853, "step": 31000}
{"episode_reward": 857.8052788653438, "episode": 32.0, "batch_reward": 0.6657201161384583, "critic_loss": 0.7263400899469853, "actor_loss": -86.62858869934082, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.453768968582153, "step": 32000}
{"episode_reward": 656.0912297925513, "episode": 33.0, "batch_reward": 0.6706669932007789, "critic_loss": 0.6724102202951908, "actor_loss": -86.53821257019042, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.5390408039093, "step": 33000}
{"episode_reward": 877.5337307056636, "episode": 34.0, "batch_reward": 0.676872494161129, "critic_loss": 0.6857720567286014, "actor_loss": -87.09287390136718, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.41268491744995, "step": 34000}
{"episode_reward": 843.7168956888485, "episode": 35.0, "batch_reward": 0.681372913479805, "critic_loss": 0.6708825834989548, "actor_loss": -86.7716893157959, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.012895345687866, "step": 35000}
{"episode_reward": 932.9342979673565, "episode": 36.0, "batch_reward": 0.6854789764285087, "critic_loss": 0.7100239852070809, "actor_loss": -87.48450410461426, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.034878253936768, "step": 36000}
{"episode_reward": 756.7828927510363, "episode": 37.0, "batch_reward": 0.6922333487272263, "critic_loss": 0.7502959771454334, "actor_loss": -87.1799856262207, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.808218002319336, "step": 37000}
{"episode_reward": 917.2467953761924, "episode": 38.0, "batch_reward": 0.6980939395427704, "critic_loss": 0.7159755184948444, "actor_loss": -86.85087396240235, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.573787927627563, "step": 38000}
{"episode_reward": 913.5352471284268, "episode": 39.0, "batch_reward": 0.704081320643425, "critic_loss": 0.6895064682364463, "actor_loss": -87.51198626708984, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.510786533355713, "step": 39000}
{"episode_reward": 932.5641048283634, "episode": 40.0, "batch_reward": 0.7069200645685196, "critic_loss": 0.6812112301290035, "actor_loss": -87.80460118103028, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.15959858894348, "step": 40000}
{"episode_reward": 894.4236912816149, "episode": 41.0, "batch_reward": 0.7115566664934159, "critic_loss": 0.6585114476680756, "actor_loss": -88.05940815734863, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.2344708442688, "step": 41000}
{"episode_reward": 917.1263935211119, "episode": 42.0, "batch_reward": 0.7178913076519966, "critic_loss": 0.6700571098923683, "actor_loss": -87.67859060668945, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.152461290359497, "step": 42000}
{"episode_reward": 941.4182937554334, "episode": 43.0, "batch_reward": 0.7245791876912117, "critic_loss": 0.6589543788433075, "actor_loss": -88.27352449035645, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.330122470855713, "step": 43000}
{"episode_reward": 906.8406748280552, "episode": 44.0, "batch_reward": 0.7274904215931892, "critic_loss": 0.6664990026056766, "actor_loss": -87.84708114624023, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.940619230270386, "step": 44000}
{"episode_reward": 871.4588965230882, "episode": 45.0, "batch_reward": 0.7219771735668182, "critic_loss": 0.6691171092092991, "actor_loss": -87.55764761352539, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.63044834136963, "step": 45000}
{"episode_reward": 62.542437129217625, "episode": 46.0, "batch_reward": 0.7160323061943055, "critic_loss": 0.6583620715737343, "actor_loss": -87.91365896606445, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.68670105934143, "step": 46000}
{"episode_reward": 826.1846359608354, "episode": 47.0, "batch_reward": 0.7194443538188934, "critic_loss": 0.6320712473094463, "actor_loss": -88.04599104309082, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.363949298858643, "step": 47000}
{"episode_reward": 923.5468280044528, "episode": 48.0, "batch_reward": 0.7223262462615967, "critic_loss": 0.6548712202906608, "actor_loss": -88.2277953338623, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.783970594406128, "step": 48000}
{"episode_reward": 911.0813421411489, "episode": 49.0, "batch_reward": 0.7252960610985756, "critic_loss": 0.6389370923936367, "actor_loss": -88.28125132751465, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.796517372131348, "step": 49000}
{"episode_reward": 768.385905786847, "episode": 50.0, "batch_reward": 0.7274870562553406, "critic_loss": 0.6618221537470818, "actor_loss": -88.09291145324707, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.788737058639526, "step": 50000}
{"episode_reward": 814.2687905201115, "episode": 51.0, "batch_reward": 0.7287896168231964, "critic_loss": 0.6578084659278393, "actor_loss": -87.9639518585205, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.43372106552124, "step": 51000}
{"episode_reward": 890.3262330784155, "episode": 52.0, "batch_reward": 0.7312601671814919, "critic_loss": 0.6480374190211297, "actor_loss": -88.49314195251465, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.855576515197754, "step": 52000}
{"episode_reward": 924.4661301980664, "episode": 53.0, "batch_reward": 0.7368234986066818, "critic_loss": 0.6819778715968132, "actor_loss": -87.80764880371093, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.13723111152649, "step": 53000}
{"episode_reward": 929.0175864953118, "episode": 54.0, "batch_reward": 0.7397226398587227, "critic_loss": 0.6296152338087558, "actor_loss": -88.95896267700195, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.429982662200928, "step": 54000}
{"episode_reward": 875.1542447751046, "episode": 55.0, "batch_reward": 0.7408936674594879, "critic_loss": 0.6451870561540127, "actor_loss": -88.83828883361817, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.6789972782135, "step": 55000}
{"episode_reward": 847.0488812643247, "episode": 56.0, "batch_reward": 0.7452763331532478, "critic_loss": 0.6556949497759342, "actor_loss": -88.50214556884765, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.60853862762451, "step": 56000}
{"episode_reward": 969.9531980096943, "episode": 57.0, "batch_reward": 0.7481485204100609, "critic_loss": 0.6595359798967838, "actor_loss": -88.84052630615234, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.4040424823761, "step": 57000}
{"episode_reward": 879.1302783476895, "episode": 58.0, "batch_reward": 0.748851892054081, "critic_loss": 0.6666020678281784, "actor_loss": -89.01836645507812, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.049972534179688, "step": 58000}
{"episode_reward": 878.5303740354801, "episode": 59.0, "batch_reward": 0.7534117054343223, "critic_loss": 0.6663596158623696, "actor_loss": -89.05827342224121, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.250173807144165, "step": 59000}
{"episode_reward": 911.8725987634629, "episode": 60.0, "batch_reward": 0.7554105013608933, "critic_loss": 0.6930219336748124, "actor_loss": -89.16160836791992, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.118499279022217, "step": 60000}
{"episode_reward": 880.7824082573385, "episode": 61.0, "batch_reward": 0.7570458188652992, "critic_loss": 0.6789746982753276, "actor_loss": -89.40725103759766, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.64949917793274, "step": 61000}
{"episode_reward": 893.8165771533259, "episode": 62.0, "batch_reward": 0.7579913215041161, "critic_loss": 0.6682787346541882, "actor_loss": -88.98191593933106, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.35993981361389, "step": 62000}
{"episode_reward": 944.153772846084, "episode": 63.0, "batch_reward": 0.7606851491332054, "critic_loss": 0.6857357656955719, "actor_loss": -89.0298247680664, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.01594305038452, "step": 63000}
{"episode_reward": 881.1630647227145, "episode": 64.0, "batch_reward": 0.7637740093469619, "critic_loss": 0.6910785767138005, "actor_loss": -89.41615342712403, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.258894681930542, "step": 64000}
{"episode_reward": 880.2327699485626, "episode": 65.0, "batch_reward": 0.7669469774961472, "critic_loss": 0.660415059864521, "actor_loss": -89.27205000305176, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.16803789138794, "step": 65000}
{"episode_reward": 930.6761021270195, "episode": 66.0, "batch_reward": 0.7683817936182022, "critic_loss": 0.6452028598487377, "actor_loss": -89.57285261535644, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.784236669540405, "step": 66000}
{"episode_reward": 934.5783978551129, "episode": 67.0, "batch_reward": 0.7706202178001403, "critic_loss": 0.6491007139980793, "actor_loss": -89.4586375427246, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.793046474456787, "step": 67000}
{"episode_reward": 904.3570546114989, "episode": 68.0, "batch_reward": 0.7732030453681946, "critic_loss": 0.6429926844239235, "actor_loss": -89.92890631103515, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.867087364196777, "step": 68000}
{"episode_reward": 940.4906050052722, "episode": 69.0, "batch_reward": 0.7756044965982437, "critic_loss": 0.6285722715556622, "actor_loss": -89.91402221679688, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.540935277938843, "step": 69000}
{"episode_reward": 910.5920476883709, "episode": 70.0, "batch_reward": 0.7773119772672653, "critic_loss": 0.6143731862306595, "actor_loss": -90.28282923889161, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.67347741127014, "step": 70000}
{"episode_reward": 851.4982079856377, "episode": 71.0, "batch_reward": 0.7777627559304238, "critic_loss": 0.6483749521672726, "actor_loss": -89.79219136047364, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.74312734603882, "step": 71000}
{"episode_reward": 899.0060204072249, "episode": 72.0, "batch_reward": 0.7799488691091537, "critic_loss": 0.6280497829318047, "actor_loss": -90.2747873840332, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.56553888320923, "step": 72000}
{"episode_reward": 863.3240798118225, "episode": 73.0, "batch_reward": 0.7806358900666237, "critic_loss": 0.6453759537041187, "actor_loss": -90.18847511291504, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.494178295135498, "step": 73000}
{"episode_reward": 895.0219017505966, "episode": 74.0, "batch_reward": 0.7839429693818092, "critic_loss": 0.6712865724861622, "actor_loss": -90.34473251342773, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.973509788513184, "step": 74000}
{"episode_reward": 918.8187693203625, "episode": 75.0, "batch_reward": 0.7853675180077553, "critic_loss": 0.6892681257426738, "actor_loss": -90.47944149780274, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.43907880783081, "step": 75000}
{"episode_reward": 898.5040247007837, "episode": 76.0, "batch_reward": 0.787168736755848, "critic_loss": 0.6770808693170548, "actor_loss": -90.6098172302246, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.789849281311035, "step": 76000}
{"episode_reward": 946.4106334951566, "episode": 77.0, "batch_reward": 0.7899435775876045, "critic_loss": 0.6624856049418449, "actor_loss": -90.69292826843262, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.128052473068237, "step": 77000}
{"episode_reward": 933.2272340610118, "episode": 78.0, "batch_reward": 0.7890786125063897, "critic_loss": 0.7000638945698738, "actor_loss": -90.53771989440918, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.51300597190857, "step": 78000}
{"episode_reward": 940.8977090974106, "episode": 79.0, "batch_reward": 0.7914575350880623, "critic_loss": 0.6770286575555802, "actor_loss": -90.71254804992675, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.921868801116943, "step": 79000}
{"episode_reward": 881.8462915768523, "episode": 80.0, "batch_reward": 0.7928666244745255, "critic_loss": 0.6747952062189579, "actor_loss": -90.86526606750488, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.716958045959473, "step": 80000}
{"episode_reward": 931.1092539817322, "episode": 81.0, "batch_reward": 0.7950324118733406, "critic_loss": 0.6533944007456303, "actor_loss": -90.78990330505371, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 44.94416666030884, "step": 81000}
{"episode_reward": 888.9046006727422, "episode": 82.0, "batch_reward": 0.7945700629353524, "critic_loss": 0.6750940072536469, "actor_loss": -90.87056536865235, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.734327793121338, "step": 82000}
{"episode_reward": 920.452132091502, "episode": 83.0, "batch_reward": 0.7960098299384117, "critic_loss": 0.659011182129383, "actor_loss": -91.22283685302735, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.638326168060303, "step": 83000}
{"episode_reward": 945.0593316819262, "episode": 84.0, "batch_reward": 0.7980924458503723, "critic_loss": 0.6782506515979767, "actor_loss": -91.49013461303711, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.365782022476196, "step": 84000}
{"episode_reward": 868.9571512849418, "episode": 85.0, "batch_reward": 0.7988385933041573, "critic_loss": 0.683491793870926, "actor_loss": -91.20720481872559, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.450491905212402, "step": 85000}
{"episode_reward": 851.914711195714, "episode": 86.0, "batch_reward": 0.8003160002827644, "critic_loss": 0.6518017597794533, "actor_loss": -91.1486784210205, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.67392873764038, "step": 86000}
{"episode_reward": 929.798887044053, "episode": 87.0, "batch_reward": 0.8017043995857239, "critic_loss": 0.6430004125833512, "actor_loss": -91.43164779663086, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.02490997314453, "step": 87000}
{"episode_reward": 918.3519336279011, "episode": 88.0, "batch_reward": 0.8034412413239479, "critic_loss": 0.6337287348806858, "actor_loss": -91.58831170654297, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.693947792053223, "step": 88000}
{"episode_reward": 931.9492256944133, "episode": 89.0, "batch_reward": 0.7995789796710014, "critic_loss": 0.658842152774334, "actor_loss": -91.35869554138183, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.13317847251892, "step": 89000}
{"episode_reward": 74.17551982538146, "episode": 90.0, "batch_reward": 0.7960373716950416, "critic_loss": 0.6710728994309902, "actor_loss": -91.48259112548828, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.649232149124146, "step": 90000}
{"episode_reward": 955.9823848768239, "episode": 91.0, "batch_reward": 0.7973621149659157, "critic_loss": 0.6715562992691994, "actor_loss": -91.38477090454101, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.463831663131714, "step": 91000}
{"episode_reward": 868.828781846122, "episode": 92.0, "batch_reward": 0.7990256639719009, "critic_loss": 0.657684273391962, "actor_loss": -91.43270040893555, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.296830892562866, "step": 92000}
{"episode_reward": 888.53560587155, "episode": 93.0, "batch_reward": 0.8024632050395012, "critic_loss": 0.6508947797119617, "actor_loss": -91.55680986022949, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.983574390411377, "step": 93000}
{"episode_reward": 972.3618296471313, "episode": 94.0, "batch_reward": 0.8024782264828682, "critic_loss": 0.665338041305542, "actor_loss": -91.70630088806152, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.370195388793945, "step": 94000}
{"episode_reward": 922.2486356799667, "episode": 95.0, "batch_reward": 0.8028158422112465, "critic_loss": 0.6332127704173327, "actor_loss": -91.82360572814942, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.674277544021606, "step": 95000}
{"episode_reward": 917.9976941868703, "episode": 96.0, "batch_reward": 0.8041518448591233, "critic_loss": 0.6354929516166449, "actor_loss": -91.7310997619629, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.261481761932373, "step": 96000}
{"episode_reward": 905.6916501694518, "episode": 97.0, "batch_reward": 0.8044469231367111, "critic_loss": 0.6446784768402577, "actor_loss": -91.93298831176757, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.917605876922607, "step": 97000}
{"episode_reward": 936.0018938723496, "episode": 98.0, "batch_reward": 0.8056139131188392, "critic_loss": 0.6266481612920761, "actor_loss": -91.78961996459961, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.325374841690063, "step": 98000}
{"episode_reward": 897.6301652193094, "episode": 99.0, "batch_reward": 0.8081152108311653, "critic_loss": 0.6465356468260288, "actor_loss": -92.05388957214356, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.402421712875366, "step": 99000}
{"episode_reward": 893.9017590323765, "episode": 100.0, "batch_reward": 0.807471764922142, "critic_loss": 0.6539151366651058, "actor_loss": -91.99469270324707, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.12475085258484, "step": 100000}
{"episode_reward": 927.4828370112242, "episode": 101.0, "batch_reward": 0.8100542803406715, "critic_loss": 0.6495215586125851, "actor_loss": -92.17462823486328, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.32812142372131, "step": 101000}
{"episode_reward": 919.7019020874538, "episode": 102.0, "batch_reward": 0.8080596457123757, "critic_loss": 0.6638117025792599, "actor_loss": -92.16522685241699, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.63228726387024, "step": 102000}
{"episode_reward": 65.92738253398697, "episode": 103.0, "batch_reward": 0.8028825845718384, "critic_loss": 0.6164438354372979, "actor_loss": -91.99726113891602, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.569388151168823, "step": 103000}
{"episode_reward": 943.597217531805, "episode": 104.0, "batch_reward": 0.8039732794761658, "critic_loss": 0.5707481150478124, "actor_loss": -92.11945935058594, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.81168484687805, "step": 104000}
{"episode_reward": 917.0780012099335, "episode": 105.0, "batch_reward": 0.8064310638308525, "critic_loss": 0.6079238709062338, "actor_loss": -91.90905033874512, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.22457480430603, "step": 105000}
{"episode_reward": 947.9680729001562, "episode": 106.0, "batch_reward": 0.807394527733326, "critic_loss": 0.5837950340658427, "actor_loss": -92.14581488037109, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.78107500076294, "step": 106000}
{"episode_reward": 863.5500510731323, "episode": 107.0, "batch_reward": 0.8073795565366745, "critic_loss": 0.5924596936404705, "actor_loss": -91.9715212097168, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.970389366149902, "step": 107000}
{"episode_reward": 883.1502071464636, "episode": 108.0, "batch_reward": 0.8083134443759918, "critic_loss": 0.5925940365791321, "actor_loss": -91.85133744812012, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.08725929260254, "step": 108000}
{"episode_reward": 924.0075421827027, "episode": 109.0, "batch_reward": 0.8090888212323188, "critic_loss": 0.5806892450600862, "actor_loss": -92.096431930542, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.156861543655396, "step": 109000}
{"episode_reward": 868.4130052939852, "episode": 110.0, "batch_reward": 0.8101295657753944, "critic_loss": 0.5688826094418764, "actor_loss": -92.1594076538086, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.937793016433716, "step": 110000}
{"episode_reward": 886.1569957449908, "episode": 111.0, "batch_reward": 0.8106108521819114, "critic_loss": 0.5856129045188427, "actor_loss": -91.82260852050781, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.62093758583069, "step": 111000}
{"episode_reward": 923.8700148944636, "episode": 112.0, "batch_reward": 0.8118194906115532, "critic_loss": 0.5704037493914366, "actor_loss": -92.19244380187989, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.473393201828003, "step": 112000}
{"episode_reward": 908.0618518804619, "episode": 113.0, "batch_reward": 0.8130031870007515, "critic_loss": 0.5590968804657459, "actor_loss": -92.02002723693847, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.336830854415894, "step": 113000}
{"episode_reward": 948.6840958898688, "episode": 114.0, "batch_reward": 0.8131786378026009, "critic_loss": 0.5468036409169436, "actor_loss": -92.16410237121582, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.32759189605713, "step": 114000}
{"episode_reward": 971.3877451351175, "episode": 115.0, "batch_reward": 0.8137122032642364, "critic_loss": 0.5588264194279909, "actor_loss": -92.02506964111328, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.980984449386597, "step": 115000}
{"episode_reward": 922.6187748626805, "episode": 116.0, "batch_reward": 0.8181139109134674, "critic_loss": 0.5484062568098307, "actor_loss": -92.21355627441406, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.033175468444824, "step": 116000}
{"episode_reward": 914.6520721379455, "episode": 117.0, "batch_reward": 0.8162283763289452, "critic_loss": 0.5306907372474671, "actor_loss": -91.82048507690429, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.797182083129883, "step": 117000}
{"episode_reward": 922.6235296139574, "episode": 118.0, "batch_reward": 0.8171061192154885, "critic_loss": 0.5741072287708521, "actor_loss": -91.99882948303222, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.83235216140747, "step": 118000}
{"episode_reward": 845.3360114135829, "episode": 119.0, "batch_reward": 0.8183367989659309, "critic_loss": 0.5571274903565645, "actor_loss": -92.0723631286621, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.221200227737427, "step": 119000}
{"episode_reward": 946.0265873670237, "episode": 120.0, "batch_reward": 0.8210995526909828, "critic_loss": 0.5614606978446245, "actor_loss": -91.96601402282715, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.432535886764526, "step": 120000}
{"episode_reward": 939.0616963488045, "episode": 121.0, "batch_reward": 0.8201090506315232, "critic_loss": 0.5745689674913883, "actor_loss": -91.95421577453614, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.95692467689514, "step": 121000}
{"episode_reward": 936.3927057736977, "episode": 122.0, "batch_reward": 0.8213101927638053, "critic_loss": 0.5795309303104877, "actor_loss": -91.93807472229004, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.08217477798462, "step": 122000}
{"episode_reward": 915.5696463473997, "episode": 123.0, "batch_reward": 0.8226395322680473, "critic_loss": 0.5667786666452884, "actor_loss": -92.34647709655762, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.082502603530884, "step": 123000}
{"episode_reward": 925.3623942434298, "episode": 124.0, "batch_reward": 0.8236992514133453, "critic_loss": 0.567104781255126, "actor_loss": -92.17568270874024, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.526734113693237, "step": 124000}
{"episode_reward": 937.46905239916, "episode": 125.0, "batch_reward": 0.8207414922118187, "critic_loss": 0.5786699322909117, "actor_loss": -92.13477578735352, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.332838535308838, "step": 125000}
{"episode_reward": 72.713370321275, "episode": 126.0, "batch_reward": 0.818910683453083, "critic_loss": 0.5632232688218355, "actor_loss": -91.82657272338867, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.39510703086853, "step": 126000}
{"episode_reward": 944.6770763526043, "episode": 127.0, "batch_reward": 0.8191428775787354, "critic_loss": 0.5477143879532814, "actor_loss": -91.97782788085938, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.492573261260986, "step": 127000}
{"episode_reward": 927.4263153133667, "episode": 128.0, "batch_reward": 0.8183328429460526, "critic_loss": 0.5403019300401211, "actor_loss": -91.97225451660157, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.612812757492065, "step": 128000}
{"episode_reward": 850.6398931251384, "episode": 129.0, "batch_reward": 0.8201753123998642, "critic_loss": 0.5427751680016517, "actor_loss": -91.84140766906738, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.760239362716675, "step": 129000}
{"episode_reward": 969.201877853529, "episode": 130.0, "batch_reward": 0.8224973408579827, "critic_loss": 0.513869933232665, "actor_loss": -91.96237922668458, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.655417442321777, "step": 130000}
{"episode_reward": 924.5402962657155, "episode": 131.0, "batch_reward": 0.8213770072460175, "critic_loss": 0.5353816258013249, "actor_loss": -92.02251652526856, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.46877455711365, "step": 131000}
{"episode_reward": 922.2796388923955, "episode": 132.0, "batch_reward": 0.8228712418675422, "critic_loss": 0.5332809914201498, "actor_loss": -92.31992610168457, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.74606490135193, "step": 132000}
{"episode_reward": 877.2954470866193, "episode": 133.0, "batch_reward": 0.8205859051942825, "critic_loss": 0.5400910719782114, "actor_loss": -91.90435444641113, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.674171924591064, "step": 133000}
{"episode_reward": 59.02659337151465, "episode": 134.0, "batch_reward": 0.8182921555042267, "critic_loss": 0.5193823454678058, "actor_loss": -91.55164375305176, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.6770498752594, "step": 134000}
{"episode_reward": 911.1063909735802, "episode": 135.0, "batch_reward": 0.8183441160917282, "critic_loss": 0.5330438517481089, "actor_loss": -91.93587628173829, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.487762212753296, "step": 135000}
{"episode_reward": 908.1974383297671, "episode": 136.0, "batch_reward": 0.8191311995387077, "critic_loss": 0.520378235027194, "actor_loss": -91.21574432373046, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.341365814208984, "step": 136000}
{"episode_reward": 919.7718151060104, "episode": 137.0, "batch_reward": 0.8181166873574257, "critic_loss": 0.5447021107226611, "actor_loss": -91.76565280151367, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.07634162902832, "step": 137000}
{"episode_reward": 934.1284601438002, "episode": 138.0, "batch_reward": 0.8202201334238053, "critic_loss": 0.5041588742136955, "actor_loss": -91.78564656066895, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.13969922065735, "step": 138000}
{"episode_reward": 954.0089543335667, "episode": 139.0, "batch_reward": 0.8204103814959526, "critic_loss": 0.5034133164137602, "actor_loss": -91.75857186889648, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.39857792854309, "step": 139000}
{"episode_reward": 938.0874860323619, "episode": 140.0, "batch_reward": 0.8239855968356132, "critic_loss": 0.5006371789127588, "actor_loss": -91.95120433044434, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.158299684524536, "step": 140000}
{"episode_reward": 935.6735801316279, "episode": 141.0, "batch_reward": 0.821056664288044, "critic_loss": 0.4917461733222008, "actor_loss": -91.87968283081055, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 45.93545460700989, "step": 141000}
{"episode_reward": 926.3063257215131, "episode": 142.0, "batch_reward": 0.8226176261901855, "critic_loss": 0.5407970890253783, "actor_loss": -91.52180000305175, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.8614821434021, "step": 142000}
{"episode_reward": 892.6220831842786, "episode": 143.0, "batch_reward": 0.8242834545969963, "critic_loss": 0.5086288955956697, "actor_loss": -91.69093334960938, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.953198194503784, "step": 143000}
{"episode_reward": 933.0141373128259, "episode": 144.0, "batch_reward": 0.8258308153748513, "critic_loss": 0.5028066508024931, "actor_loss": -91.98362397766114, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.614574909210205, "step": 144000}
{"episode_reward": 894.4133875841871, "episode": 145.0, "batch_reward": 0.8268414579629898, "critic_loss": 0.5048479713201522, "actor_loss": -92.0757839050293, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.951010704040527, "step": 145000}
{"episode_reward": 875.53668525894, "episode": 146.0, "batch_reward": 0.826212573826313, "critic_loss": 0.5173592364788056, "actor_loss": -92.13823059082031, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.423595905303955, "step": 146000}
{"episode_reward": 911.011890800026, "episode": 147.0, "batch_reward": 0.826282233774662, "critic_loss": 0.5101587350815534, "actor_loss": -92.0304550933838, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.866101264953613, "step": 147000}
{"episode_reward": 936.0218589257969, "episode": 148.0, "batch_reward": 0.8256096597313881, "critic_loss": 0.5381987202912569, "actor_loss": -91.94499971008301, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.85558557510376, "step": 148000}
{"episode_reward": 923.87883447546, "episode": 149.0, "batch_reward": 0.8273779287934303, "critic_loss": 0.5528077875673771, "actor_loss": -91.9466399230957, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.779736518859863, "step": 149000}
{"episode_reward": 930.4602640536831, "episode": 150.0, "batch_reward": 0.8267879363894463, "critic_loss": 0.566650720834732, "actor_loss": -92.0635350189209, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "step": 150000}
