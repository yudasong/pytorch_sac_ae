{"episode_reward": 0.0, "episode": 1.0, "duration": 20.9709255695343, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.8234426975250244, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.4623886784262242, "critic_loss": 0.25868197688513017, "actor_loss": -84.02848299048624, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 60.482337474823, "step": 3000}
{"episode_reward": 525.4615115918848, "episode": 4.0, "batch_reward": 0.48800217789411543, "critic_loss": 0.6264298330247402, "actor_loss": -85.12356303405761, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26395082473755, "step": 4000}
{"episode_reward": 560.4203046133491, "episode": 5.0, "batch_reward": 0.501041019976139, "critic_loss": 0.7493802746236324, "actor_loss": -85.3799126739502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.24427843093872, "step": 5000}
{"episode_reward": 557.4967217881721, "episode": 6.0, "batch_reward": 0.5245915653407573, "critic_loss": 0.9473871894180774, "actor_loss": -86.06273612976074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.273409843444824, "step": 6000}
{"episode_reward": 700.0421364562419, "episode": 7.0, "batch_reward": 0.5479033717513084, "critic_loss": 1.1689396738409996, "actor_loss": -86.50239500427246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.269361972808838, "step": 7000}
{"episode_reward": 668.2918277416206, "episode": 8.0, "batch_reward": 0.5608994659483433, "critic_loss": 1.2694407151937486, "actor_loss": -87.15966659545899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.213634967803955, "step": 8000}
{"episode_reward": 598.1221814918391, "episode": 9.0, "batch_reward": 0.5393828928470612, "critic_loss": 1.4398313540816308, "actor_loss": -86.3472643737793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.241185665130615, "step": 9000}
{"episode_reward": 67.33085468321954, "episode": 10.0, "batch_reward": 0.5264917691946029, "critic_loss": 1.2897046744823455, "actor_loss": -85.90824990844726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.280223846435547, "step": 10000}
{"episode_reward": 563.8100246862818, "episode": 11.0, "batch_reward": 0.5275546394884586, "critic_loss": 1.3427839816212654, "actor_loss": -85.67170845031738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.933680057525635, "step": 11000}
{"episode_reward": 809.7474479321471, "episode": 12.0, "batch_reward": 0.5428313163220883, "critic_loss": 1.5174340907335282, "actor_loss": -85.89749418640136, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.25720715522766, "step": 12000}
{"episode_reward": 597.6791200049674, "episode": 13.0, "batch_reward": 0.5541164148449897, "critic_loss": 1.7393540179133415, "actor_loss": -85.98070834350585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.244327306747437, "step": 13000}
{"episode_reward": 758.2209856814184, "episode": 14.0, "batch_reward": 0.5735617071986199, "critic_loss": 1.6811253392696381, "actor_loss": -86.46160182189941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.242835998535156, "step": 14000}
{"episode_reward": 658.5743275938208, "episode": 15.0, "batch_reward": 0.5735900426208973, "critic_loss": 1.762882884800434, "actor_loss": -85.63265838623047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.266545057296753, "step": 15000}
{"episode_reward": 498.5289552292517, "episode": 16.0, "batch_reward": 0.5733801001608372, "critic_loss": 1.7852896022796632, "actor_loss": -86.40557409667969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.260644912719727, "step": 16000}
{"episode_reward": 827.462110017244, "episode": 17.0, "batch_reward": 0.5913355755507946, "critic_loss": 1.8537883170843124, "actor_loss": -86.52596356201173, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.222312688827515, "step": 17000}
{"episode_reward": 846.8811270227941, "episode": 18.0, "batch_reward": 0.6057958583235741, "critic_loss": 1.959174414396286, "actor_loss": -86.98628265380859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.22631525993347, "step": 18000}
{"episode_reward": 856.8199255267225, "episode": 19.0, "batch_reward": 0.6189305147528649, "critic_loss": 1.979979107618332, "actor_loss": -87.35165771484375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.23812508583069, "step": 19000}
{"episode_reward": 880.1753139266525, "episode": 20.0, "batch_reward": 0.6271232978105545, "critic_loss": 2.034666791975498, "actor_loss": -86.86248373413086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27059578895569, "step": 20000}
{"episode_reward": 782.7965812365394, "episode": 21.0, "batch_reward": 0.6392577277421951, "critic_loss": 1.7790104262828828, "actor_loss": -87.31405841064453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.7633101940155, "step": 21000}
{"episode_reward": 877.4818224568488, "episode": 22.0, "batch_reward": 0.6498577827811242, "critic_loss": 1.6594481086134911, "actor_loss": -87.43943110656738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21644616127014, "step": 22000}
{"episode_reward": 846.6779389573026, "episode": 23.0, "batch_reward": 0.6569831607937813, "critic_loss": 1.6026588084697724, "actor_loss": -87.8413522491455, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.182854413986206, "step": 23000}
{"episode_reward": 874.2858570642627, "episode": 24.0, "batch_reward": 0.6681236669421196, "critic_loss": 1.6057686291337012, "actor_loss": -87.9265258178711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.224718809127808, "step": 24000}
{"episode_reward": 852.4483937438218, "episode": 25.0, "batch_reward": 0.6700931878685952, "critic_loss": 1.5859857655763625, "actor_loss": -88.4519436340332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19061541557312, "step": 25000}
{"episode_reward": 762.798008468691, "episode": 26.0, "batch_reward": 0.6805491933822632, "critic_loss": 1.5754307975769044, "actor_loss": -88.17903163146973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.22063708305359, "step": 26000}
{"episode_reward": 891.7148968450898, "episode": 27.0, "batch_reward": 0.6902654407024383, "critic_loss": 1.639693396985531, "actor_loss": -88.36186547851563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26835346221924, "step": 27000}
{"episode_reward": 858.0160655879736, "episode": 28.0, "batch_reward": 0.6926801772713661, "critic_loss": 1.6674287040233613, "actor_loss": -88.64753549194336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.29802393913269, "step": 28000}
{"episode_reward": 803.0098767954776, "episode": 29.0, "batch_reward": 0.6966824389100075, "critic_loss": 1.7040119367837905, "actor_loss": -88.0727160949707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.271888971328735, "step": 29000}
{"episode_reward": 915.6371547388595, "episode": 30.0, "batch_reward": 0.7040329737067222, "critic_loss": 1.6390674061775208, "actor_loss": -88.29208540344239, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.279036283493042, "step": 30000}
{"episode_reward": 892.211892362863, "episode": 31.0, "batch_reward": 0.7096418651938439, "critic_loss": 1.610989878475666, "actor_loss": -89.15776458740234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.9137065410614, "step": 31000}
{"episode_reward": 885.1279256621424, "episode": 32.0, "batch_reward": 0.7168831711411476, "critic_loss": 1.6884746547937393, "actor_loss": -89.14238630676269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.265483856201172, "step": 32000}
{"episode_reward": 929.8867170086696, "episode": 33.0, "batch_reward": 0.721631873190403, "critic_loss": 1.5756798782944679, "actor_loss": -89.28138679504394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.25195813179016, "step": 33000}
{"episode_reward": 830.885798500121, "episode": 34.0, "batch_reward": 0.7266748341321945, "critic_loss": 1.5238612547516823, "actor_loss": -89.40267784118652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.24509310722351, "step": 34000}
{"episode_reward": 892.3800955002355, "episode": 35.0, "batch_reward": 0.7319160389900208, "critic_loss": 1.4959261940717696, "actor_loss": -89.17144346618652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.281557083129883, "step": 35000}
{"episode_reward": 915.207316612497, "episode": 36.0, "batch_reward": 0.7367188567519188, "critic_loss": 1.4770140695571898, "actor_loss": -90.21988778686523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.25180721282959, "step": 36000}
{"episode_reward": 884.3818358948462, "episode": 37.0, "batch_reward": 0.7414680293798447, "critic_loss": 1.4377988024950028, "actor_loss": -89.93690019226074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.259010076522827, "step": 37000}
{"episode_reward": 917.4545177101822, "episode": 38.0, "batch_reward": 0.7458851518034935, "critic_loss": 1.4861114251613616, "actor_loss": -89.5424361114502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.267044067382812, "step": 38000}
{"episode_reward": 941.7590368799771, "episode": 39.0, "batch_reward": 0.7512026941180229, "critic_loss": 1.4692440319657325, "actor_loss": -90.39089527893067, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.25843620300293, "step": 39000}
{"episode_reward": 942.8537623933632, "episode": 40.0, "batch_reward": 0.7527856813073158, "critic_loss": 1.4509906296133994, "actor_loss": -90.40570393371583, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.228188514709473, "step": 40000}
{"episode_reward": 916.6096161389636, "episode": 41.0, "batch_reward": 0.757431924700737, "critic_loss": 1.4810195047855377, "actor_loss": -91.00250012207032, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.86627721786499, "step": 41000}
{"episode_reward": 856.2414852679577, "episode": 42.0, "batch_reward": 0.7598767791986465, "critic_loss": 1.3722617909908295, "actor_loss": -90.08243598937989, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.266265392303467, "step": 42000}
{"episode_reward": 914.2341921187385, "episode": 43.0, "batch_reward": 0.7669367141127587, "critic_loss": 1.3153618773818017, "actor_loss": -90.912509475708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.20831036567688, "step": 43000}
{"episode_reward": 910.747106293394, "episode": 44.0, "batch_reward": 0.7694034168124199, "critic_loss": 1.3479512649178504, "actor_loss": -90.95341383361816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.241952180862427, "step": 44000}
{"episode_reward": 852.6550924342259, "episode": 45.0, "batch_reward": 0.7703170421719551, "critic_loss": 1.3289098326563835, "actor_loss": -90.86861195373535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.235732078552246, "step": 45000}
{"episode_reward": 839.3385105908005, "episode": 46.0, "batch_reward": 0.7714534258842468, "critic_loss": 1.3532279487252235, "actor_loss": -90.90340089416505, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.221298933029175, "step": 46000}
{"episode_reward": 851.4326941530122, "episode": 47.0, "batch_reward": 0.7717619905471802, "critic_loss": 1.3465352794528007, "actor_loss": -91.20475698852539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.203875064849854, "step": 47000}
{"episode_reward": 904.7498770892229, "episode": 48.0, "batch_reward": 0.777739741742611, "critic_loss": 1.2653597694635392, "actor_loss": -91.3083596496582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.22883105278015, "step": 48000}
{"episode_reward": 904.6239498935005, "episode": 49.0, "batch_reward": 0.7791533140540123, "critic_loss": 1.2014481748342514, "actor_loss": -91.50198197937011, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.247649908065796, "step": 49000}
{"episode_reward": 884.270475123238, "episode": 50.0, "batch_reward": 0.7815376880168915, "critic_loss": 1.1571420861780644, "actor_loss": -91.3045682220459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.219094276428223, "step": 50000}
{"episode_reward": 863.8017641166635, "episode": 51.0, "batch_reward": 0.7843369040489196, "critic_loss": 1.1517975693941116, "actor_loss": -91.50332043457031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.787723779678345, "step": 51000}
{"episode_reward": 908.7903477321764, "episode": 52.0, "batch_reward": 0.7840485166311264, "critic_loss": 1.1008645121455192, "actor_loss": -91.82026037597656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.209574699401855, "step": 52000}
{"episode_reward": 880.414137065514, "episode": 53.0, "batch_reward": 0.7870492031574249, "critic_loss": 1.178976910471916, "actor_loss": -91.3127727355957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.231666088104248, "step": 53000}
{"episode_reward": 869.3477597484531, "episode": 54.0, "batch_reward": 0.7880039249658585, "critic_loss": 1.1488079439997674, "actor_loss": -92.10223342895507, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.227473497390747, "step": 54000}
{"episode_reward": 868.0946033005735, "episode": 55.0, "batch_reward": 0.7888095930814744, "critic_loss": 1.0822407404482364, "actor_loss": -91.90058746337891, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.257100105285645, "step": 55000}
{"episode_reward": 872.282813383536, "episode": 56.0, "batch_reward": 0.7916859232187271, "critic_loss": 1.0809492219686507, "actor_loss": -91.53780018615723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26403522491455, "step": 56000}
{"episode_reward": 939.4354579035386, "episode": 57.0, "batch_reward": 0.7945420712828636, "critic_loss": 1.083256761610508, "actor_loss": -92.1301208190918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.257748126983643, "step": 57000}
{"episode_reward": 903.7289953028409, "episode": 58.0, "batch_reward": 0.7965219646692276, "critic_loss": 1.0482205749452114, "actor_loss": -91.9474048614502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.262484073638916, "step": 58000}
{"episode_reward": 903.3694396905672, "episode": 59.0, "batch_reward": 0.7983978740572929, "critic_loss": 0.9660489310026169, "actor_loss": -92.08406219482421, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.24538564682007, "step": 59000}
{"episode_reward": 912.6084007316913, "episode": 60.0, "batch_reward": 0.8007180694341659, "critic_loss": 0.944005756676197, "actor_loss": -92.21446948242188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.270094394683838, "step": 60000}
{"episode_reward": 900.9087115190496, "episode": 61.0, "batch_reward": 0.80131555134058, "critic_loss": 0.9903931920826435, "actor_loss": -92.41579815673828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.846819162368774, "step": 61000}
{"episode_reward": 867.7117683015247, "episode": 62.0, "batch_reward": 0.8014712715744973, "critic_loss": 0.9276904303431511, "actor_loss": -92.15517439270019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27122926712036, "step": 62000}
{"episode_reward": 906.6254236667631, "episode": 63.0, "batch_reward": 0.8032608830332756, "critic_loss": 0.9597041437625885, "actor_loss": -92.32177047729492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.245731592178345, "step": 63000}
{"episode_reward": 939.4936163319405, "episode": 64.0, "batch_reward": 0.8057114495038986, "critic_loss": 0.9350522371828556, "actor_loss": -92.4180399017334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.232649087905884, "step": 64000}
{"episode_reward": 897.1882117373556, "episode": 65.0, "batch_reward": 0.8077964491248131, "critic_loss": 0.916508201599121, "actor_loss": -92.35479258728027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.285871267318726, "step": 65000}
{"episode_reward": 899.9713378110152, "episode": 66.0, "batch_reward": 0.8091555150151253, "critic_loss": 0.9195003634393215, "actor_loss": -92.43620028686523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.266780614852905, "step": 66000}
{"episode_reward": 918.7058484808327, "episode": 67.0, "batch_reward": 0.8110818561315537, "critic_loss": 0.8991341698467732, "actor_loss": -92.37216540527344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.289241552352905, "step": 67000}
{"episode_reward": 920.6549688039488, "episode": 68.0, "batch_reward": 0.8114644181132317, "critic_loss": 0.9302152813076973, "actor_loss": -92.68589077758789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.281289100646973, "step": 68000}
{"episode_reward": 903.0182156920141, "episode": 69.0, "batch_reward": 0.8135717123150825, "critic_loss": 0.8810055419206619, "actor_loss": -92.7999842376709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2799174785614, "step": 69000}
{"episode_reward": 917.9221226357589, "episode": 70.0, "batch_reward": 0.8147151178717613, "critic_loss": 0.9067618977725506, "actor_loss": -92.80132164001465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.255558252334595, "step": 70000}
{"episode_reward": 876.6061741879241, "episode": 71.0, "batch_reward": 0.8159813772439957, "critic_loss": 0.8630336426496505, "actor_loss": -92.58594505310059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.87353849411011, "step": 71000}
{"episode_reward": 927.770549068523, "episode": 72.0, "batch_reward": 0.8177381956577301, "critic_loss": 0.8881947231888772, "actor_loss": -93.00626155090332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26759171485901, "step": 72000}
{"episode_reward": 864.5538547030485, "episode": 73.0, "batch_reward": 0.8172714068293572, "critic_loss": 0.9110120009779931, "actor_loss": -92.91366590881347, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.25334930419922, "step": 73000}
{"episode_reward": 915.6350604029349, "episode": 74.0, "batch_reward": 0.8205954769849777, "critic_loss": 0.9499404908120632, "actor_loss": -92.81477255249024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26925230026245, "step": 74000}
{"episode_reward": 843.8301017912938, "episode": 75.0, "batch_reward": 0.8212158604264259, "critic_loss": 1.0012233420908452, "actor_loss": -93.06950175476074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.25474524497986, "step": 75000}
{"episode_reward": 878.1589421381657, "episode": 76.0, "batch_reward": 0.8211274902820587, "critic_loss": 0.9417049716711045, "actor_loss": -92.91052519226074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.24834394454956, "step": 76000}
{"episode_reward": 949.8802329669028, "episode": 77.0, "batch_reward": 0.8222769393324852, "critic_loss": 0.872473023891449, "actor_loss": -92.86720086669922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.215343475341797, "step": 77000}
{"episode_reward": 902.5707458047385, "episode": 78.0, "batch_reward": 0.8228335177898407, "critic_loss": 0.8688953711688518, "actor_loss": -92.77672727966309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.226423501968384, "step": 78000}
{"episode_reward": 889.1003687030762, "episode": 79.0, "batch_reward": 0.8236160196065903, "critic_loss": 0.8541104628145695, "actor_loss": -93.05166641235351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.23183798789978, "step": 79000}
{"episode_reward": 909.6185836872615, "episode": 80.0, "batch_reward": 0.8254667021036148, "critic_loss": 0.8478425842821598, "actor_loss": -93.14756942749024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.25824284553528, "step": 80000}
{"episode_reward": 913.185086146367, "episode": 81.0, "batch_reward": 0.8259404531121254, "critic_loss": 0.8119604873359203, "actor_loss": -93.13559187316895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.9014835357666, "step": 81000}
{"episode_reward": 883.4062673653999, "episode": 82.0, "batch_reward": 0.8264689839482308, "critic_loss": 0.8022591897547245, "actor_loss": -93.09585516357421, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.269200325012207, "step": 82000}
{"episode_reward": 882.9016613176112, "episode": 83.0, "batch_reward": 0.8268611862659454, "critic_loss": 0.8341506379842758, "actor_loss": -93.13240658569336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.260056972503662, "step": 83000}
{"episode_reward": 789.8178462044447, "episode": 84.0, "batch_reward": 0.8264439220428467, "critic_loss": 0.8630044547021389, "actor_loss": -93.43512800598144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2266583442688, "step": 84000}
{"episode_reward": 842.423392851479, "episode": 85.0, "batch_reward": 0.8267645367383957, "critic_loss": 0.8457383607029915, "actor_loss": -93.21085140991211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.25057315826416, "step": 85000}
{"episode_reward": 945.1522783452411, "episode": 86.0, "batch_reward": 0.8295392033457756, "critic_loss": 0.8154340216219426, "actor_loss": -93.34426947021484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.231650590896606, "step": 86000}
{"episode_reward": 919.9198069072944, "episode": 87.0, "batch_reward": 0.8310938794016838, "critic_loss": 0.842896084100008, "actor_loss": -93.43205734252929, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.23987865447998, "step": 87000}
{"episode_reward": 881.8109451866001, "episode": 88.0, "batch_reward": 0.8311611641049385, "critic_loss": 0.8607349841594696, "actor_loss": -93.4525329284668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.211326122283936, "step": 88000}
{"episode_reward": 937.537343197214, "episode": 89.0, "batch_reward": 0.8316050124168396, "critic_loss": 0.9030096867978573, "actor_loss": -93.30857162475586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.240640878677368, "step": 89000}
{"episode_reward": 870.2186098082748, "episode": 90.0, "batch_reward": 0.8318657054901123, "critic_loss": 0.9805777629911899, "actor_loss": -93.35226797485352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.259114027023315, "step": 90000}
{"episode_reward": 901.0052777542583, "episode": 91.0, "batch_reward": 0.8324085799455643, "critic_loss": 0.9425696775913238, "actor_loss": -93.21865744018555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.03393769264221, "step": 91000}
{"episode_reward": 875.6100798761032, "episode": 92.0, "batch_reward": 0.8333155925273895, "critic_loss": 0.9063476427197457, "actor_loss": -93.35512129211426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.219592332839966, "step": 92000}
{"episode_reward": 821.9595208726116, "episode": 93.0, "batch_reward": 0.8348701219558716, "critic_loss": 0.909770221889019, "actor_loss": -93.58921809387208, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.222633838653564, "step": 93000}
{"episode_reward": 912.247263488256, "episode": 94.0, "batch_reward": 0.8354988867640495, "critic_loss": 0.9452157620489597, "actor_loss": -93.59326434326172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.207828283309937, "step": 94000}
{"episode_reward": 915.1781743327202, "episode": 95.0, "batch_reward": 0.8343901990056037, "critic_loss": 0.9613645913302898, "actor_loss": -93.58484312438965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19847083091736, "step": 95000}
{"episode_reward": 845.107139202679, "episode": 96.0, "batch_reward": 0.8339458578228951, "critic_loss": 0.9493829916417599, "actor_loss": -93.42313792419434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.255608797073364, "step": 96000}
{"episode_reward": 889.5135574666417, "episode": 97.0, "batch_reward": 0.8365128804445267, "critic_loss": 0.9173375928401947, "actor_loss": -93.63315911865234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.238418102264404, "step": 97000}
{"episode_reward": 937.6112676665996, "episode": 98.0, "batch_reward": 0.8360358115434646, "critic_loss": 0.9250659978687763, "actor_loss": -93.64500694274902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.24956965446472, "step": 98000}
{"episode_reward": 877.905990099641, "episode": 99.0, "batch_reward": 0.8366384450793266, "critic_loss": 0.9250967689454556, "actor_loss": -93.54871487426757, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.24657368659973, "step": 99000}
{"episode_reward": 858.1837587265908, "episode": 100.0, "batch_reward": 0.8368546195030212, "critic_loss": 0.9277645143568516, "actor_loss": -93.75161079406739, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.241565704345703, "step": 100000}
{"episode_reward": 948.3675345689135, "episode": 101.0, "batch_reward": 0.8394682031869888, "critic_loss": 0.945318142324686, "actor_loss": -93.73596740722657, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.87042570114136, "step": 101000}
{"episode_reward": 905.0121713186323, "episode": 102.0, "batch_reward": 0.8389794915318489, "critic_loss": 0.9100602795183659, "actor_loss": -93.85351374816895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.24971580505371, "step": 102000}
{"episode_reward": 913.2878025227878, "episode": 103.0, "batch_reward": 0.8390208015441895, "critic_loss": 0.8689275150299072, "actor_loss": -93.44542977905273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.252147436141968, "step": 103000}
{"episode_reward": 877.9671390197008, "episode": 104.0, "batch_reward": 0.8399307397007942, "critic_loss": 0.9128849413096904, "actor_loss": -93.70982643127441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.251878261566162, "step": 104000}
{"episode_reward": 868.7986950635103, "episode": 105.0, "batch_reward": 0.8403845406174659, "critic_loss": 0.9493113726079464, "actor_loss": -93.57063146972656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.217803955078125, "step": 105000}
{"episode_reward": 930.2752819470832, "episode": 106.0, "batch_reward": 0.8411974004507065, "critic_loss": 0.915124751597643, "actor_loss": -93.94330378723144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.23186421394348, "step": 106000}
{"episode_reward": 905.9605185807466, "episode": 107.0, "batch_reward": 0.8410492611527443, "critic_loss": 1.0033367366194725, "actor_loss": -93.87359893798828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2391140460968, "step": 107000}
{"episode_reward": 829.3299451693678, "episode": 108.0, "batch_reward": 0.8400400534868241, "critic_loss": 1.079103936702013, "actor_loss": -93.56203234863281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.541850566864014, "step": 108000}
{"episode_reward": 876.4315680982774, "episode": 109.0, "batch_reward": 0.840906562924385, "critic_loss": 1.0090481517016887, "actor_loss": -93.78186895751954, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.23564314842224, "step": 109000}
{"episode_reward": 811.7455429199997, "episode": 110.0, "batch_reward": 0.841733805179596, "critic_loss": 1.0257139300704003, "actor_loss": -93.69576870727539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.206660509109497, "step": 110000}
{"episode_reward": 857.1288048353186, "episode": 111.0, "batch_reward": 0.8419618911743164, "critic_loss": 1.1208313190639019, "actor_loss": -93.6035477142334, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.838324546813965, "step": 111000}
{"episode_reward": 879.47821841437, "episode": 112.0, "batch_reward": 0.8423088482618332, "critic_loss": 1.0289226725995542, "actor_loss": -93.81989540100098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26396346092224, "step": 112000}
{"episode_reward": 882.3959418034156, "episode": 113.0, "batch_reward": 0.8434913453459739, "critic_loss": 1.0494422853589058, "actor_loss": -93.91141947937011, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.254631280899048, "step": 113000}
{"episode_reward": 931.6017596732964, "episode": 114.0, "batch_reward": 0.843268088042736, "critic_loss": 1.0664900706708431, "actor_loss": -93.90265394592285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.26629900932312, "step": 114000}
{"episode_reward": 948.1293639417602, "episode": 115.0, "batch_reward": 0.8426245887279511, "critic_loss": 1.0268972807824612, "actor_loss": -93.72091764831544, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.27504801750183, "step": 115000}
{"episode_reward": 804.3290429307448, "episode": 116.0, "batch_reward": 0.8441475437879562, "critic_loss": 1.1058534567952156, "actor_loss": -93.79591352844238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.267895221710205, "step": 116000}
{"episode_reward": 833.6776907167248, "episode": 117.0, "batch_reward": 0.843877933382988, "critic_loss": 1.0646189442574978, "actor_loss": -93.50701521301269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.247753620147705, "step": 117000}
{"episode_reward": 912.828052791651, "episode": 118.0, "batch_reward": 0.8441364200115203, "critic_loss": 1.0653944807648659, "actor_loss": -93.64860586547852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.231609582901, "step": 118000}
{"episode_reward": 877.5280979621564, "episode": 119.0, "batch_reward": 0.8445807816982269, "critic_loss": 1.1469884306192397, "actor_loss": -93.67193241882325, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21008324623108, "step": 119000}
{"episode_reward": 898.3885581011461, "episode": 120.0, "batch_reward": 0.8454037886857987, "critic_loss": 1.1072231402099133, "actor_loss": -93.67096353149414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.241764068603516, "step": 120000}
{"episode_reward": 902.924346635832, "episode": 121.0, "batch_reward": 0.8452761657834053, "critic_loss": 1.0928966775238513, "actor_loss": -93.72833847045898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.883533239364624, "step": 121000}
{"episode_reward": 898.9741659050687, "episode": 122.0, "batch_reward": 0.8463645462989807, "critic_loss": 1.077943781286478, "actor_loss": -93.89049005126954, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.257375955581665, "step": 122000}
{"episode_reward": 897.2235538005857, "episode": 123.0, "batch_reward": 0.8465190463662148, "critic_loss": 1.0819952321350574, "actor_loss": -94.01999719238282, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.232850313186646, "step": 123000}
{"episode_reward": 927.0497097777284, "episode": 124.0, "batch_reward": 0.8476350395083427, "critic_loss": 1.0511498042345047, "actor_loss": -93.99569723510743, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.24706220626831, "step": 124000}
{"episode_reward": 899.6230572453543, "episode": 125.0, "batch_reward": 0.8482747603058814, "critic_loss": 1.1357921877205372, "actor_loss": -93.97655642700195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.23835039138794, "step": 125000}
{"episode_reward": 909.154136925678, "episode": 126.0, "batch_reward": 0.8489272040724755, "critic_loss": 1.195492023050785, "actor_loss": -93.82079721069336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.24204730987549, "step": 126000}
{"episode_reward": 920.6599590303606, "episode": 127.0, "batch_reward": 0.8484401692748069, "critic_loss": 1.1866647122204304, "actor_loss": -93.66300035095215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.247434854507446, "step": 127000}
{"episode_reward": 927.5632970988732, "episode": 128.0, "batch_reward": 0.8482278504371643, "critic_loss": 1.1476145099401474, "actor_loss": -93.77045631408691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.258418083190918, "step": 128000}
{"episode_reward": 864.7564685049792, "episode": 129.0, "batch_reward": 0.8492215933203697, "critic_loss": 1.0792983675599097, "actor_loss": -93.89379176330566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.263993501663208, "step": 129000}
{"episode_reward": 953.2317782796483, "episode": 130.0, "batch_reward": 0.8512467718720436, "critic_loss": 1.087747528657317, "actor_loss": -93.8428701171875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.241544723510742, "step": 130000}
{"episode_reward": 926.3236216644034, "episode": 131.0, "batch_reward": 0.8504787007570267, "critic_loss": 1.122760816037655, "actor_loss": -94.00558209228515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.80587935447693, "step": 131000}
{"episode_reward": 915.931322380059, "episode": 132.0, "batch_reward": 0.850263400733471, "critic_loss": 1.056574869543314, "actor_loss": -94.18402365112304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.22822856903076, "step": 132000}
{"episode_reward": 892.8055625504877, "episode": 133.0, "batch_reward": 0.8522823240756988, "critic_loss": 1.075070145636797, "actor_loss": -94.09009869384765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.252971649169922, "step": 133000}
{"episode_reward": 938.3406462871454, "episode": 134.0, "batch_reward": 0.8529425683617592, "critic_loss": 1.086769207715988, "actor_loss": -94.0020312652588, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.248383283615112, "step": 134000}
{"episode_reward": 867.1571888103417, "episode": 135.0, "batch_reward": 0.8529525475502014, "critic_loss": 1.082538804024458, "actor_loss": -93.9263502960205, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2360577583313, "step": 135000}
{"episode_reward": 894.7657484990634, "episode": 136.0, "batch_reward": 0.8534022530317307, "critic_loss": 1.0735648986697197, "actor_loss": -93.79029084777832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.249491930007935, "step": 136000}
{"episode_reward": 762.8356053943163, "episode": 137.0, "batch_reward": 0.851045142531395, "critic_loss": 1.143086576461792, "actor_loss": -94.15697074890137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19036364555359, "step": 137000}
{"episode_reward": 931.7898670729933, "episode": 138.0, "batch_reward": 0.8537462668418885, "critic_loss": 1.0437947629094124, "actor_loss": -94.10164514160157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.209073781967163, "step": 138000}
{"episode_reward": 949.2172658085289, "episode": 139.0, "batch_reward": 0.8525528019666672, "critic_loss": 1.0906342609226705, "actor_loss": -93.97540953063965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.274477005004883, "step": 139000}
{"episode_reward": 928.5103691457958, "episode": 140.0, "batch_reward": 0.8552383097410202, "critic_loss": 1.0987377457022667, "actor_loss": -94.04564973449708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.255275011062622, "step": 140000}
{"episode_reward": 888.5146557217163, "episode": 141.0, "batch_reward": 0.8524140336513519, "critic_loss": 1.0687250313460828, "actor_loss": -94.08042272949218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.888434410095215, "step": 141000}
{"episode_reward": 919.6216300698834, "episode": 142.0, "batch_reward": 0.8539477170705795, "critic_loss": 1.0922936742305756, "actor_loss": -93.77263684082031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2483172416687, "step": 142000}
{"episode_reward": 930.1876366463744, "episode": 143.0, "batch_reward": 0.8540985975265503, "critic_loss": 1.1077421153187752, "actor_loss": -93.89621855163574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.266236782073975, "step": 143000}
{"episode_reward": 875.022026715712, "episode": 144.0, "batch_reward": 0.8564119582176208, "critic_loss": 1.079337633550167, "actor_loss": -94.11465867614746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.237215042114258, "step": 144000}
{"episode_reward": 892.658281615144, "episode": 145.0, "batch_reward": 0.8555808402299881, "critic_loss": 1.0363464715480804, "actor_loss": -94.28098397827148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.226179838180542, "step": 145000}
{"episode_reward": 827.845078716539, "episode": 146.0, "batch_reward": 0.8546920036673545, "critic_loss": 1.0748749161362647, "actor_loss": -94.18702993774414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.24108338356018, "step": 146000}
{"episode_reward": 898.5855478025771, "episode": 147.0, "batch_reward": 0.8544489423036575, "critic_loss": 1.065371985554695, "actor_loss": -94.00268821716308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.21910524368286, "step": 147000}
{"episode_reward": 873.8058825557199, "episode": 148.0, "batch_reward": 0.8557000562548638, "critic_loss": 1.1075139993727208, "actor_loss": -94.22593867492675, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.248810291290283, "step": 148000}
{"episode_reward": 884.714567925817, "episode": 149.0, "batch_reward": 0.856428701043129, "critic_loss": 1.1373771342933179, "actor_loss": -93.99813743591308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.302351236343384, "step": 149000}
{"episode_reward": 946.4681116221172, "episode": 150.0, "batch_reward": 0.8547590100169182, "critic_loss": 1.1283452355265617, "actor_loss": -94.18432205200196, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
