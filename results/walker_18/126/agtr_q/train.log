{"episode": 1.0, "duration": 23.071327209472656, "episode_reward": 29.08591335645728, "step": 1000}
{"episode": 2.0, "duration": 2.1725690364837646, "episode_reward": 898.6342244091321, "step": 2000}
{"episode": 3.0, "batch_reward": 0.44185822503532557, "actor_loss": -83.45821564709868, "actor_target_entropy": -6.0, "alpha_value": 0.002642586817083679, "duration": 53.82039213180542, "episode_reward": 152.07971960770502, "step": 3000}
{"episode": 4.0, "batch_reward": 0.3495946990400553, "actor_loss": -81.55562504577637, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.167885780334473, "episode_reward": 262.9122240884739, "step": 4000}
{"episode": 5.0, "batch_reward": 0.3391589101701975, "actor_loss": -81.3710113067627, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.62798261642456, "episode_reward": 393.4501933417553, "step": 5000}
{"episode": 6.0, "batch_reward": 0.34354604256153104, "actor_loss": -82.34411553955078, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 15.967439889907837, "episode_reward": 288.36543447850244, "step": 6000}
{"episode": 7.0, "batch_reward": 0.32628776717185975, "actor_loss": -82.51585311889649, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.149492025375366, "episode_reward": 165.80530145755137, "step": 7000}
{"episode": 8.0, "batch_reward": 0.3107994043380022, "actor_loss": -82.38085437011719, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.958389282226562, "episode_reward": 193.0469092024812, "step": 8000}
{"episode": 9.0, "batch_reward": 0.30906688277423383, "actor_loss": -82.39105867004395, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.59161353111267, "episode_reward": 427.17347665023175, "step": 9000}
{"episode": 10.0, "batch_reward": 0.3187691269814968, "actor_loss": -78.38590644836425, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 3981.19238615036, "episode_reward": 441.17380618733995, "step": 10000}
{"episode": 11.0, "batch_reward": 0.32634835423529146, "actor_loss": -79.02164476013184, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 37.49551963806152, "episode_reward": 383.12143918090044, "step": 11000}
{"episode": 12.0, "batch_reward": 0.33184861497581003, "actor_loss": -76.33973028564454, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 433.41127276420593, "episode_reward": 416.737669006281, "step": 12000}
{"episode": 13.0, "batch_reward": 0.34534410095214846, "actor_loss": -77.08418737792968, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.20343565940857, "episode_reward": 539.1951274945641, "step": 13000}
{"episode": 14.0, "batch_reward": 0.35809211161732674, "actor_loss": -76.8903205871582, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 441.1559417247772, "episode_reward": 429.4321689450149, "step": 14000}
{"episode": 15.0, "batch_reward": 0.36283453366160395, "actor_loss": -77.2198115234375, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.014466285705566, "episode_reward": 558.7027263594405, "step": 15000}
{"episode": 16.0, "batch_reward": 0.37513014325499533, "actor_loss": -77.04753930664063, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 432.89570593833923, "episode_reward": 452.46729371974385, "step": 16000}
{"episode": 17.0, "batch_reward": 0.38009824284911153, "actor_loss": -77.44171879577637, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.153679370880127, "episode_reward": 474.31033188184733, "step": 17000}
{"episode": 18.0, "batch_reward": 0.3875413399040699, "actor_loss": -76.18729191589355, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 431.3243384361267, "episode_reward": 567.9674874965765, "step": 18000}
{"episode": 19.0, "batch_reward": 0.3959851782619953, "actor_loss": -76.52339465332031, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.983206033706665, "episode_reward": 538.4064013724781, "step": 19000}
{"episode": 20.0, "batch_reward": 0.405436047822237, "actor_loss": -76.31358624267578, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 429.97386026382446, "episode_reward": 629.4483861225995, "step": 20000}
{"episode": 21.0, "batch_reward": 0.41694437053799627, "actor_loss": -76.77870307922363, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 37.54615521430969, "episode_reward": 682.6715589181482, "step": 21000}
{"episode": 22.0, "batch_reward": 0.4265887250900269, "actor_loss": -77.08329931640625, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 429.9800179004669, "episode_reward": 603.2938712673237, "step": 22000}
{"episode": 23.0, "batch_reward": 0.43632032990455627, "actor_loss": -77.36003204345702, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.06261658668518, "episode_reward": 568.1571834136447, "step": 23000}
{"episode": 24.0, "batch_reward": 0.44218019422888755, "actor_loss": -77.1192748413086, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 431.8341600894928, "episode_reward": 668.0228725479064, "step": 24000}
{"episode": 25.0, "batch_reward": 0.451144972473383, "actor_loss": -77.58936672973633, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.320209741592407, "episode_reward": 564.2999345762339, "step": 25000}
{"episode": 26.0, "batch_reward": 0.4564189457297325, "actor_loss": -77.75034509277344, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 433.5379309654236, "episode_reward": 612.1933576116822, "step": 26000}
{"episode": 27.0, "batch_reward": 0.46283013963699343, "actor_loss": -78.04867762756348, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.26017427444458, "episode_reward": 728.6441482425327, "step": 27000}
{"episode": 28.0, "batch_reward": 0.4720279979109764, "actor_loss": -77.15942175292969, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 440.15241527557373, "episode_reward": 620.7631370185873, "step": 28000}
{"episode": 29.0, "batch_reward": 0.4770304052233696, "actor_loss": -77.36077226257325, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.908098936080933, "episode_reward": 617.969998791066, "step": 29000}
{"episode": 30.0, "batch_reward": 0.48137566465139386, "actor_loss": -77.08124603271484, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 433.9419400691986, "episode_reward": 569.6481019833386, "step": 30000}
{"episode": 31.0, "batch_reward": 0.4855242712199688, "actor_loss": -77.18449151611328, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.52177953720093, "episode_reward": 716.0676174217286, "step": 31000}
{"episode": 32.0, "batch_reward": 0.49364941197633744, "actor_loss": -77.70198733520508, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 433.7076861858368, "episode_reward": 584.816294417213, "step": 32000}
{"episode": 33.0, "batch_reward": 0.49688457652926443, "actor_loss": -77.77206903076171, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.18065333366394, "episode_reward": 725.5520314641321, "step": 33000}
{"episode": 34.0, "batch_reward": 0.4989260303080082, "actor_loss": -77.95776010131836, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 436.60220432281494, "episode_reward": 583.9821468872473, "step": 34000}
{"episode": 35.0, "batch_reward": 0.5051090486049652, "actor_loss": -78.12136622619629, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.50350069999695, "episode_reward": 671.4797539893001, "step": 35000}
{"episode": 36.0, "batch_reward": 0.5070555984675884, "actor_loss": -77.7261531829834, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 428.9993278980255, "episode_reward": 641.5863178139787, "step": 36000}
{"episode": 37.0, "batch_reward": 0.5114198619127274, "actor_loss": -77.98613185119629, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.21510410308838, "episode_reward": 560.2236830423238, "step": 37000}
{"episode": 38.0, "batch_reward": 0.5162107899487018, "actor_loss": -78.41196730041504, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 435.93661880493164, "episode_reward": 823.1377631366778, "step": 38000}
{"episode": 39.0, "batch_reward": 0.5195698162317276, "actor_loss": -78.55271492004394, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.790358781814575, "episode_reward": 639.6927805169057, "step": 39000}
{"episode": 40.0, "batch_reward": 0.5250932880342006, "actor_loss": -78.4166024017334, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 432.87152338027954, "episode_reward": 705.601052734459, "step": 40000}
{"episode": 41.0, "batch_reward": 0.5314901866018772, "actor_loss": -78.56773658752441, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 37.760356187820435, "episode_reward": 691.195006070243, "step": 41000}
{"episode": 42.0, "batch_reward": 0.5341766920685768, "actor_loss": -78.26404365539551, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 429.5168228149414, "episode_reward": 513.1615548318972, "step": 42000}
{"episode": 43.0, "batch_reward": 0.5315068000555039, "actor_loss": -78.10826417541504, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.492552280426025, "episode_reward": 709.8440006499178, "step": 43000}
{"episode": 44.0, "batch_reward": 0.5386455685794354, "actor_loss": -78.03178814697266, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 433.75746297836304, "episode_reward": 727.6603276930462, "step": 44000}
{"episode": 45.0, "batch_reward": 0.5401924608647823, "actor_loss": -78.10443351745606, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.030170440673828, "episode_reward": 710.6742505714801, "step": 45000}
{"episode": 46.0, "batch_reward": 0.5446547454595566, "actor_loss": -77.98897825622558, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 441.3574261665344, "episode_reward": 759.1107683494137, "step": 46000}
{"episode": 47.0, "batch_reward": 0.5498348504900933, "actor_loss": -78.07490592956543, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.722080945968628, "episode_reward": 774.3230294884643, "step": 47000}
{"episode": 48.0, "batch_reward": 0.5525687556266785, "actor_loss": -76.80591131591797, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 441.55029249191284, "episode_reward": 649.4254023265189, "step": 48000}
{"episode": 49.0, "batch_reward": 0.5587064490616321, "actor_loss": -76.93902374267579, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.296159505844116, "episode_reward": 795.0044179054979, "step": 49000}
{"episode": 50.0, "batch_reward": 0.5615120074748993, "actor_loss": -76.15793342590332, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 432.0931944847107, "episode_reward": 722.1737462301021, "step": 50000}
{"episode": 51.0, "batch_reward": 0.5663537175953388, "actor_loss": -76.44037889099121, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 37.73483324050903, "episode_reward": 800.4010973019609, "step": 51000}
{"episode": 52.0, "batch_reward": 0.5699654435813427, "actor_loss": -75.68889485168457, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 433.0305120944977, "episode_reward": 846.2340475539366, "step": 52000}
{"episode": 53.0, "batch_reward": 0.5770731199681759, "actor_loss": -75.88689237976074, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.05666160583496, "episode_reward": 887.5695692440663, "step": 53000}
{"episode": 54.0, "batch_reward": 0.5826084122657776, "actor_loss": -75.61692654418945, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 429.2137403488159, "episode_reward": 834.1191436546504, "step": 54000}
{"episode": 55.0, "batch_reward": 0.5858150041103363, "actor_loss": -75.74266708374023, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.29047179222107, "episode_reward": 859.0645939441292, "step": 55000}
{"episode": 56.0, "batch_reward": 0.5890663141012191, "actor_loss": -74.76242234802245, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 437.14625334739685, "episode_reward": 751.5363889154166, "step": 56000}
{"episode": 57.0, "batch_reward": 0.5931436470150948, "actor_loss": -75.03975862121582, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.653259992599487, "episode_reward": 756.8785761683248, "step": 57000}
{"episode": 58.0, "batch_reward": 0.5971235882341862, "actor_loss": -72.79119886779785, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 427.19424843788147, "episode_reward": 714.1172263327636, "step": 58000}
{"episode": 59.0, "batch_reward": 0.5988041899204254, "actor_loss": -72.9676517791748, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.3599693775177, "episode_reward": 785.6312292823599, "step": 59000}
{"episode": 60.0, "batch_reward": 0.6001516181826592, "actor_loss": -72.7368724822998, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 435.84741377830505, "episode_reward": 773.3204467911783, "step": 60000}
{"episode": 61.0, "batch_reward": 0.6040508456230164, "actor_loss": -72.92684480285645, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.10395336151123, "episode_reward": 710.934370946096, "step": 61000}
{"episode": 62.0, "batch_reward": 0.6054080783128738, "actor_loss": -71.98568086242676, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 431.8594551086426, "episode_reward": 802.7528586674475, "step": 62000}
{"episode": 63.0, "batch_reward": 0.6095307618379593, "actor_loss": -72.09782633972168, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.37692880630493, "episode_reward": 751.6984311623917, "step": 63000}
{"episode": 64.0, "batch_reward": 0.6109014165401458, "actor_loss": -71.63907304382325, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 440.1439960002899, "episode_reward": 757.5837722429312, "step": 64000}
{"episode": 65.0, "batch_reward": 0.61398676019907, "actor_loss": -71.79153231811523, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.978882789611816, "episode_reward": 860.9444138676394, "step": 65000}
{"episode": 66.0, "batch_reward": 0.6183798592090607, "actor_loss": -72.2536146850586, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 439.49464297294617, "episode_reward": 859.2251394828313, "step": 66000}
{"episode": 67.0, "batch_reward": 0.6193485532402992, "actor_loss": -72.37085534667969, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.95367455482483, "episode_reward": 565.1744040796535, "step": 67000}
{"episode": 68.0, "batch_reward": 0.6205111709833145, "actor_loss": -71.97949847412109, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 437.2157461643219, "episode_reward": 778.3143514891887, "step": 68000}
{"episode": 69.0, "batch_reward": 0.6222267352938652, "actor_loss": -72.03178785705566, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.20612907409668, "episode_reward": 764.1221421694189, "step": 69000}
{"episode": 70.0, "batch_reward": 0.6242436600923538, "actor_loss": -72.05561125183105, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 439.7229723930359, "episode_reward": 726.371805790511, "step": 70000}
{"episode": 71.0, "batch_reward": 0.6268125396370888, "actor_loss": -72.20557725524903, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 39.647594928741455, "episode_reward": 762.6565405877168, "step": 71000}
{"episode": 72.0, "batch_reward": 0.6278206933736801, "actor_loss": -72.15736875915528, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 433.27441334724426, "episode_reward": 789.7848332915721, "step": 72000}
{"episode": 73.0, "batch_reward": 0.6304645503163337, "actor_loss": -72.20148797607422, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.522592306137085, "episode_reward": 824.2593379763236, "step": 73000}
{"episode": 74.0, "batch_reward": 0.6329032095074654, "actor_loss": -72.71923999023437, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 435.37113785743713, "episode_reward": 749.0311280135099, "step": 74000}
{"episode": 75.0, "batch_reward": 0.6343577002882957, "actor_loss": -72.88182231140136, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.948456048965454, "episode_reward": 802.2924182388963, "step": 75000}
{"episode": 76.0, "batch_reward": 0.6368725537061691, "actor_loss": -72.56378807067871, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 431.51523876190186, "episode_reward": 804.6035996340465, "step": 76000}
{"episode": 77.0, "batch_reward": 0.6397691959738732, "actor_loss": -72.70742106628418, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.25411820411682, "episode_reward": 872.2648045652519, "step": 77000}
{"episode": 78.0, "batch_reward": 0.6446840737462044, "actor_loss": -73.66266818237305, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 445.43178033828735, "episode_reward": 769.3278156111066, "step": 78000}
{"episode": 79.0, "batch_reward": 0.6392769516706467, "actor_loss": -73.50997991943359, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.414747714996338, "episode_reward": 342.55025265400866, "step": 79000}
{"episode": 80.0, "batch_reward": 0.6398432583808898, "actor_loss": -73.85453096008301, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 440.2690818309784, "episode_reward": 795.1755999724459, "step": 80000}
{"episode": 81.0, "batch_reward": 0.6402800117731094, "actor_loss": -73.91670835876465, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.14081859588623, "episode_reward": 843.697217564191, "step": 81000}
{"episode": 82.0, "batch_reward": 0.6449969826936722, "actor_loss": -73.83875981140137, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 439.2376251220703, "episode_reward": 891.3096210485685, "step": 82000}
{"episode": 83.0, "batch_reward": 0.6460629313588142, "actor_loss": -73.8714903564453, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.66283392906189, "episode_reward": 717.2390157152364, "step": 83000}
{"episode": 84.0, "batch_reward": 0.6471805971264839, "actor_loss": -73.96577206420899, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 440.5026080608368, "episode_reward": 829.498321460179, "step": 84000}
{"episode": 85.0, "batch_reward": 0.647311996102333, "actor_loss": -74.1024195098877, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.176204204559326, "episode_reward": 37.28406638008298, "step": 85000}
{"episode": 86.0, "batch_reward": 0.6423248028755189, "actor_loss": -73.86884907531739, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 439.7187008857727, "episode_reward": 827.9807299181149, "step": 86000}
{"episode": 87.0, "batch_reward": 0.6448503767848015, "actor_loss": -74.00892643737792, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.42379140853882, "episode_reward": 865.0404745669455, "step": 87000}
{"episode": 88.0, "batch_reward": 0.6492648180723191, "actor_loss": -73.97935916137695, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 434.06898069381714, "episode_reward": 869.9787376471612, "step": 88000}
{"episode": 89.0, "batch_reward": 0.6516177144646644, "actor_loss": -74.10856526184082, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.412007570266724, "episode_reward": 881.9024892479441, "step": 89000}
{"episode": 90.0, "batch_reward": 0.6534408456683158, "actor_loss": -74.41099395751954, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 433.3130204677582, "episode_reward": 849.0564907417756, "step": 90000}
{"episode": 91.0, "batch_reward": 0.6542966336607933, "actor_loss": -74.48706886291504, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.525914430618286, "episode_reward": 888.1353342702281, "step": 91000}
{"episode": 92.0, "batch_reward": 0.6582628962993622, "actor_loss": -74.67157748413086, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 421.4194915294647, "episode_reward": 874.300052537329, "step": 92000}
{"episode": 93.0, "batch_reward": 0.661179516017437, "actor_loss": -74.7810694732666, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.183310747146606, "episode_reward": 943.923544584533, "step": 93000}
{"episode": 94.0, "batch_reward": 0.6642872238755226, "actor_loss": -75.78311120605468, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 436.41772651672363, "episode_reward": 855.3015594663583, "step": 94000}
{"episode": 95.0, "batch_reward": 0.6640692762732506, "actor_loss": -75.7632049560547, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.320800065994263, "episode_reward": 834.8553804749419, "step": 95000}
{"episode": 96.0, "batch_reward": 0.6657962845563888, "actor_loss": -75.64003904724122, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 428.75317788124084, "episode_reward": 735.3213323242621, "step": 96000}
{"episode": 97.0, "batch_reward": 0.6664834055900574, "actor_loss": -75.62056594848633, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.083838939666748, "episode_reward": 813.432524490068, "step": 97000}
{"episode": 98.0, "batch_reward": 0.669449189722538, "actor_loss": -75.92379234313965, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 433.50959181785583, "episode_reward": 822.8729596056419, "step": 98000}
{"episode": 99.0, "batch_reward": 0.6703998545408248, "actor_loss": -75.98409284973144, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.002411603927612, "episode_reward": 799.4896031346004, "step": 99000}
{"episode": 100.0, "batch_reward": 0.6710658749341964, "actor_loss": -76.61187409973145, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 436.4679653644562, "episode_reward": 826.9267969030662, "step": 100000}
{"episode": 101.0, "batch_reward": 0.67389260160923, "actor_loss": -76.7617843322754, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 39.36684966087341, "episode_reward": 876.128437714637, "step": 101000}
{"episode": 102.0, "batch_reward": 0.6748261237144471, "actor_loss": -76.52764918518066, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 439.378093957901, "episode_reward": 842.4097866722575, "step": 102000}
{"episode": 103.0, "batch_reward": 0.677575738132, "actor_loss": -76.64383012390137, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.229457139968872, "episode_reward": 879.6943710405097, "step": 103000}
{"episode": 104.0, "batch_reward": 0.6794078948497773, "actor_loss": -76.65068786621094, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 444.3339259624481, "episode_reward": 891.5253662157245, "step": 104000}
{"episode": 105.0, "batch_reward": 0.6814738890528679, "actor_loss": -76.75093002319336, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.497565507888794, "episode_reward": 898.5879591797677, "step": 105000}
{"episode": 106.0, "batch_reward": 0.6833805766701698, "actor_loss": -77.2264090270996, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 437.8231956958771, "episode_reward": 842.8021693695795, "step": 106000}
{"episode": 107.0, "batch_reward": 0.6864408313035965, "actor_loss": -77.29258854675292, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.50463104248047, "episode_reward": 867.1679430042016, "step": 107000}
{"episode": 108.0, "batch_reward": 0.6870466588735581, "actor_loss": -77.35951002502442, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 443.69123339653015, "episode_reward": 895.3696493052635, "step": 108000}
{"episode": 109.0, "batch_reward": 0.6874155340790749, "actor_loss": -77.37247958374023, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.330080270767212, "episode_reward": 892.2856043128276, "step": 109000}
{"episode": 110.0, "batch_reward": 0.6897779276371002, "actor_loss": -77.4586174621582, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 441.73645281791687, "episode_reward": 839.6559374285013, "step": 110000}
{"episode": 111.0, "batch_reward": 0.6914409238100052, "actor_loss": -77.46801330566406, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.04219889640808, "episode_reward": 822.2201458505059, "step": 111000}
{"episode": 112.0, "batch_reward": 0.692943835735321, "actor_loss": -77.26847088623047, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 429.53645181655884, "episode_reward": 856.199791389005, "step": 112000}
{"episode": 113.0, "batch_reward": 0.69427620023489, "actor_loss": -77.31448759460449, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.22178292274475, "episode_reward": 924.9717684988128, "step": 113000}
{"episode": 114.0, "batch_reward": 0.6949897006750106, "actor_loss": -76.95791928100586, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 432.26784920692444, "episode_reward": 896.3702692006843, "step": 114000}
{"episode": 115.0, "batch_reward": 0.6973938808441162, "actor_loss": -77.01737602233887, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.0494167804718, "episode_reward": 823.7706873370306, "step": 115000}
{"episode": 116.0, "batch_reward": 0.6999582260847091, "actor_loss": -77.14083409118652, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 433.3849980831146, "episode_reward": 852.9490844282973, "step": 116000}
{"episode": 117.0, "batch_reward": 0.6987182162404061, "actor_loss": -77.05956080627442, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.154011249542236, "episode_reward": 894.3369866906457, "step": 117000}
{"episode": 118.0, "batch_reward": 0.7027516722679138, "actor_loss": -77.16574028015137, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 432.6577489376068, "episode_reward": 925.1094061509634, "step": 118000}
{"episode": 119.0, "batch_reward": 0.7031525292396545, "actor_loss": -77.24794844055175, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.20430040359497, "episode_reward": 868.7643531691332, "step": 119000}
{"episode": 120.0, "batch_reward": 0.7047655654549598, "actor_loss": -77.11538220214844, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 433.23870372772217, "episode_reward": 878.7407179690942, "step": 120000}
{"episode": 121.0, "batch_reward": 0.7069045266509056, "actor_loss": -77.20874761962891, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 38.19082188606262, "episode_reward": 855.7022105340836, "step": 121000}
{"episode": 122.0, "batch_reward": 0.706547769010067, "actor_loss": -77.19420590209961, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 427.0971488952637, "episode_reward": 850.0690514251186, "step": 122000}
{"episode": 123.0, "batch_reward": 0.7087961868643761, "actor_loss": -77.2545131072998, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.213528156280518, "episode_reward": 868.1485089805412, "step": 123000}
{"episode": 124.0, "batch_reward": 0.7098936620354652, "actor_loss": -77.23181059265137, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 434.1696512699127, "episode_reward": 867.0296625628873, "step": 124000}
{"episode": 125.0, "batch_reward": 0.7117445241212845, "actor_loss": -77.3560290222168, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.188750982284546, "episode_reward": 855.9177904647696, "step": 125000}
{"episode": 126.0, "batch_reward": 0.7123133670091629, "actor_loss": -77.28790011596679, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 434.4242329597473, "episode_reward": 850.7486174594366, "step": 126000}
{"episode": 127.0, "batch_reward": 0.7127737830281258, "actor_loss": -77.36703067016602, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.159703493118286, "episode_reward": 863.9623659762251, "step": 127000}
{"episode": 128.0, "batch_reward": 0.7155063026547432, "actor_loss": -77.66286225891113, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 431.78629660606384, "episode_reward": 873.1808112616408, "step": 128000}
{"episode": 129.0, "batch_reward": 0.7161774262785912, "actor_loss": -77.70095750427247, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.092371225357056, "episode_reward": 857.4887950541489, "step": 129000}
{"episode": 130.0, "batch_reward": 0.7179010004997254, "actor_loss": -77.51958874511719, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 444.9795649051666, "episode_reward": 863.0291802629137, "step": 130000}
{"episode": 131.0, "batch_reward": 0.718258750975132, "actor_loss": -77.57617155456543, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 39.752734422683716, "episode_reward": 817.7318013389158, "step": 131000}
{"episode": 132.0, "batch_reward": 0.7196959065794944, "actor_loss": -77.9239781036377, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 440.6302902698517, "episode_reward": 881.3849809003704, "step": 132000}
{"episode": 133.0, "batch_reward": 0.7208803592324257, "actor_loss": -77.98304418945312, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.118831157684326, "episode_reward": 923.2138085478391, "step": 133000}
{"episode": 134.0, "batch_reward": 0.7217229655981063, "actor_loss": -78.05508862304687, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 445.63602328300476, "episode_reward": 837.0136822326965, "step": 134000}
{"episode": 135.0, "batch_reward": 0.7225557905435562, "actor_loss": -78.13469636535645, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 16.49054217338562, "episode_reward": 818.0157686296452, "step": 135000}
{"episode": 136.0, "batch_reward": 0.7241689893603325, "actor_loss": -78.5839086151123, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 441.19579672813416, "episode_reward": 878.5090897416761, "step": 136000}
{"episode": 137.0, "batch_reward": 0.7266448658108712, "actor_loss": -78.6604036102295, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.496623039245605, "episode_reward": 886.6568036518431, "step": 137000}
{"episode": 138.0, "batch_reward": 0.7270777049660683, "actor_loss": -78.55626383972168, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 444.3191237449646, "episode_reward": 886.3258603289705, "step": 138000}
{"episode": 139.0, "batch_reward": 0.7263536276817322, "actor_loss": -78.57220431518554, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.822848320007324, "episode_reward": 834.1325650916849, "step": 139000}
{"episode": 140.0, "batch_reward": 0.727707479774952, "actor_loss": -78.54903469848632, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 442.89688634872437, "episode_reward": 905.749423726158, "step": 140000}
{"episode": 141.0, "batch_reward": 0.7302410770058632, "actor_loss": -78.59006153869629, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 36.823752880096436, "episode_reward": 881.6948237298141, "step": 141000}
{"episode": 142.0, "batch_reward": 0.7296914476752281, "actor_loss": -79.3445749053955, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 431.9394600391388, "episode_reward": 875.5757809540042, "step": 142000}
{"episode": 143.0, "batch_reward": 0.729774235010147, "actor_loss": -79.39088610839843, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.669118881225586, "episode_reward": 838.4470095855869, "step": 143000}
{"episode": 144.0, "batch_reward": 0.7322047107219696, "actor_loss": -79.41988920593262, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 465.1783208847046, "episode_reward": 848.1155246544913, "step": 144000}
{"episode": 145.0, "batch_reward": 0.7336582816243171, "actor_loss": -79.48061213684082, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.262242555618286, "episode_reward": 773.3670586387342, "step": 145000}
{"episode": 146.0, "batch_reward": 0.7334447994232177, "actor_loss": -79.37754284667969, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 483.1663827896118, "episode_reward": 910.6664689660792, "step": 146000}
{"episode": 147.0, "batch_reward": 0.7350523911714554, "actor_loss": -79.38986962890625, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.145605325698853, "episode_reward": 844.8746414583276, "step": 147000}
{"episode": 148.0, "batch_reward": 0.7354197494387626, "actor_loss": -79.60644006347657, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 470.5653440952301, "episode_reward": 687.1439138387096, "step": 148000}
{"episode": 149.0, "batch_reward": 0.7356948534250259, "actor_loss": -79.63855834960937, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 17.620991468429565, "episode_reward": 929.6856270977252, "step": 149000}
{"episode": 150.0, "batch_reward": 0.7349845702648163, "actor_loss": -79.81664891052246, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "step": 150000}
