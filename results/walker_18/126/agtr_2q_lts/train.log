{"episode_reward": 0.0, "episode": 1.0, "duration": 17.98362946510315, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.6076319217681885, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.45495232121870494, "critic_loss": 0.16540002326129197, "actor_loss": -83.54303739012695, "actor_target_entropy": -6.0, "alpha_value": 0.002642586817083679, "duration": 84.29334688186646, "step": 3000}
{"episode_reward": 394.3448970118279, "episode": 4.0, "batch_reward": 0.48114213305711745, "critic_loss": 0.4088081616908312, "actor_loss": -85.33115184020996, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.579313278198242, "step": 4000}
{"episode_reward": 771.413422022118, "episode": 5.0, "batch_reward": 0.5464804841279983, "critic_loss": 0.42493540978431704, "actor_loss": -87.13893981933593, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.658782720565796, "step": 5000}
{"episode_reward": 762.3830324600934, "episode": 6.0, "batch_reward": 0.5806123019456864, "critic_loss": 0.5395861059427262, "actor_loss": -87.76362492370606, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.919979333877563, "step": 6000}
{"episode_reward": 688.4958243739832, "episode": 7.0, "batch_reward": 0.5895471111238003, "critic_loss": 0.6335158247649669, "actor_loss": -87.62228392028808, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.0898654460907, "step": 7000}
{"episode_reward": 644.3451983804011, "episode": 8.0, "batch_reward": 0.610740445703268, "critic_loss": 0.7059585277438164, "actor_loss": -87.7450975189209, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.65730333328247, "step": 8000}
{"episode_reward": 779.7690710560589, "episode": 9.0, "batch_reward": 0.6294400407075882, "critic_loss": 0.7127660463452339, "actor_loss": -88.2502239074707, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.215686082839966, "step": 9000}
{"episode_reward": 820.1031346906021, "episode": 10.0, "batch_reward": 0.6576459860801697, "critic_loss": 0.6969743273556233, "actor_loss": -88.8495125579834, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.73115348815918, "step": 10000}
{"episode_reward": 932.2254781180819, "episode": 11.0, "batch_reward": 0.6809808906912803, "critic_loss": 0.7145513781011105, "actor_loss": -89.61925503540039, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.53508472442627, "step": 11000}
{"episode_reward": 903.9265276582998, "episode": 12.0, "batch_reward": 0.6868398303985596, "critic_loss": 0.8459778261780739, "actor_loss": -89.70378654479981, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.465128183364868, "step": 12000}
{"episode_reward": 730.4517523360048, "episode": 13.0, "batch_reward": 0.7007335884571075, "critic_loss": 0.6866709935367108, "actor_loss": -90.0502897491455, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.782827377319336, "step": 13000}
{"episode_reward": 895.6406041812188, "episode": 14.0, "batch_reward": 0.715500342130661, "critic_loss": 0.6341046191751957, "actor_loss": -90.25610260009766, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.444374799728394, "step": 14000}
{"episode_reward": 879.0945564238307, "episode": 15.0, "batch_reward": 0.7043970572948456, "critic_loss": 0.6914859527051449, "actor_loss": -89.95634864807128, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.403478145599365, "step": 15000}
{"episode_reward": 389.0359290518132, "episode": 16.0, "batch_reward": 0.7065487300753593, "critic_loss": 0.6487293892502785, "actor_loss": -89.6310499420166, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.443217039108276, "step": 16000}
{"episode_reward": 900.672533520739, "episode": 17.0, "batch_reward": 0.718911924302578, "critic_loss": 0.5986641162633896, "actor_loss": -89.9608890838623, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.21401357650757, "step": 17000}
{"episode_reward": 915.9456497253406, "episode": 18.0, "batch_reward": 0.730424266397953, "critic_loss": 0.6118065340816975, "actor_loss": -90.07990682983399, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.944158792495728, "step": 18000}
{"episode_reward": 855.8331425064853, "episode": 19.0, "batch_reward": 0.7344908729791642, "critic_loss": 0.6832497369349003, "actor_loss": -90.19170080566406, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.57298469543457, "step": 19000}
{"episode_reward": 896.6862810631058, "episode": 20.0, "batch_reward": 0.7443867471814155, "critic_loss": 0.6539382090568543, "actor_loss": -90.56751791381836, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.476627111434937, "step": 20000}
{"episode_reward": 881.4303237117928, "episode": 21.0, "batch_reward": 0.7528125573396682, "critic_loss": 0.5795591486394406, "actor_loss": -90.54942616271973, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.46571183204651, "step": 21000}
{"episode_reward": 974.2600481667794, "episode": 22.0, "batch_reward": 0.7551061592698097, "critic_loss": 0.7077883049547672, "actor_loss": -90.56642584228516, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.751651763916016, "step": 22000}
{"episode_reward": 702.3039718779265, "episode": 23.0, "batch_reward": 0.7559979313611984, "critic_loss": 0.6257391013801098, "actor_loss": -90.53143653869628, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 27.09573531150818, "step": 23000}
{"episode_reward": 892.4547807940006, "episode": 24.0, "batch_reward": 0.7619829741716385, "critic_loss": 0.6968265582025052, "actor_loss": -90.59452087402343, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.639524936676025, "step": 24000}
{"episode_reward": 836.7617432867141, "episode": 25.0, "batch_reward": 0.7667182953357696, "critic_loss": 0.6790302385091782, "actor_loss": -90.6708253326416, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.808881282806396, "step": 25000}
{"episode_reward": 906.2130716707948, "episode": 26.0, "batch_reward": 0.7738194096684455, "critic_loss": 0.6206248329281807, "actor_loss": -90.64073890686035, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.46015501022339, "step": 26000}
{"episode_reward": 916.3334247125104, "episode": 27.0, "batch_reward": 0.7811770802140235, "critic_loss": 0.5725498155355454, "actor_loss": -91.05494009399413, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 25.383683919906616, "step": 27000}
{"episode_reward": 940.5308727715047, "episode": 28.0, "batch_reward": 0.7841945520043373, "critic_loss": 0.5756568472087383, "actor_loss": -90.79638575744629, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.537375450134277, "step": 28000}
{"episode_reward": 936.5379839635328, "episode": 29.0, "batch_reward": 0.7916780925393104, "critic_loss": 0.5361024156957864, "actor_loss": -91.25838876342773, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.685433626174927, "step": 29000}
{"episode_reward": 966.5966384494993, "episode": 30.0, "batch_reward": 0.795406453192234, "critic_loss": 0.5160552230626345, "actor_loss": -91.34987910461426, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.786027669906616, "step": 30000}
{"episode_reward": 939.9143048588713, "episode": 31.0, "batch_reward": 0.7999372251033783, "critic_loss": 0.48046277356147765, "actor_loss": -91.24380258178711, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.18777132034302, "step": 31000}
{"episode_reward": 918.5442185121088, "episode": 32.0, "batch_reward": 0.8045165638327598, "critic_loss": 0.4805455950349569, "actor_loss": -91.35905876159669, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.752432584762573, "step": 32000}
{"episode_reward": 939.1163524894461, "episode": 33.0, "batch_reward": 0.8067787835001945, "critic_loss": 0.4760531706809998, "actor_loss": -91.71134257507325, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.634043216705322, "step": 33000}
{"episode_reward": 869.8937743170226, "episode": 34.0, "batch_reward": 0.8101035602092743, "critic_loss": 0.47094457641243936, "actor_loss": -91.55694143676757, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.635276079177856, "step": 34000}
{"episode_reward": 927.5825224479337, "episode": 35.0, "batch_reward": 0.8139438765645027, "critic_loss": 0.4288376000374556, "actor_loss": -91.61499807739258, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 27.198397874832153, "step": 35000}
{"episode_reward": 957.9797909499831, "episode": 36.0, "batch_reward": 0.8184841565489769, "critic_loss": 0.4089048470854759, "actor_loss": -91.62159530639649, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.576828956604004, "step": 36000}
{"episode_reward": 926.9489976757602, "episode": 37.0, "batch_reward": 0.8213983378410339, "critic_loss": 0.380685973405838, "actor_loss": -91.8817345123291, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 25.28245449066162, "step": 37000}
{"episode_reward": 946.3948056416393, "episode": 38.0, "batch_reward": 0.8256287774443627, "critic_loss": 0.35113693882524966, "actor_loss": -92.22354841613769, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.251365900039673, "step": 38000}
{"episode_reward": 937.27248714495, "episode": 39.0, "batch_reward": 0.8277314155101776, "critic_loss": 0.36069203199446204, "actor_loss": -92.12682862854004, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 27.231956005096436, "step": 39000}
{"episode_reward": 956.2712464497359, "episode": 40.0, "batch_reward": 0.828030993103981, "critic_loss": 0.36113993149995804, "actor_loss": -91.98820541381836, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.630192756652832, "step": 40000}
{"episode_reward": 881.3033770745831, "episode": 41.0, "batch_reward": 0.8318208478093148, "critic_loss": 0.3165482360124588, "actor_loss": -91.99707916259766, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.39149618148804, "step": 41000}
{"episode_reward": 925.49808305204, "episode": 42.0, "batch_reward": 0.8336459658145905, "critic_loss": 0.3147450893372297, "actor_loss": -92.31845266723633, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.7053644657135, "step": 42000}
{"episode_reward": 944.4170218514691, "episode": 43.0, "batch_reward": 0.8369817848205566, "critic_loss": 0.32664486518502234, "actor_loss": -92.23668522644043, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.721829414367676, "step": 43000}
{"episode_reward": 891.593236481139, "episode": 44.0, "batch_reward": 0.8390103335976601, "critic_loss": 0.3259646522253752, "actor_loss": -92.44663986206055, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.7847638130188, "step": 44000}
{"episode_reward": 895.4192631661267, "episode": 45.0, "batch_reward": 0.838930358171463, "critic_loss": 0.33272174808382987, "actor_loss": -92.58706161499023, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.452922105789185, "step": 45000}
{"episode_reward": 916.1272022216488, "episode": 46.0, "batch_reward": 0.8412825440764428, "critic_loss": 0.34127519151568414, "actor_loss": -92.40261309814453, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.25962805747986, "step": 46000}
{"episode_reward": 899.0231082553762, "episode": 47.0, "batch_reward": 0.8417185586690903, "critic_loss": 0.35291060964763166, "actor_loss": -92.30144017028809, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 25.99535822868347, "step": 47000}
{"episode_reward": 936.380331103699, "episode": 48.0, "batch_reward": 0.8451945933699608, "critic_loss": 0.32252133056521415, "actor_loss": -92.51843276977539, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.706392288208008, "step": 48000}
{"episode_reward": 947.7696002492081, "episode": 49.0, "batch_reward": 0.8471394066810608, "critic_loss": 0.3261930587440729, "actor_loss": -92.51948886108399, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 27.008583545684814, "step": 49000}
{"episode_reward": 937.4039603100601, "episode": 50.0, "batch_reward": 0.8471474906802178, "critic_loss": 0.330679353967309, "actor_loss": -92.64206362915039, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.38306999206543, "step": 50000}
{"episode_reward": 856.2719779371521, "episode": 51.0, "batch_reward": 0.8487283964753151, "critic_loss": 0.34331276002526284, "actor_loss": -92.94917501831054, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.71703886985779, "step": 51000}
{"episode_reward": 860.0596461735216, "episode": 52.0, "batch_reward": 0.8474813369512558, "critic_loss": 0.34116094949841497, "actor_loss": -92.40826011657715, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.683959484100342, "step": 52000}
{"episode_reward": 925.565359158193, "episode": 53.0, "batch_reward": 0.850505328297615, "critic_loss": 0.354426220998168, "actor_loss": -92.92885948181153, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.822277069091797, "step": 53000}
{"episode_reward": 938.6261144255577, "episode": 54.0, "batch_reward": 0.8515708325505257, "critic_loss": 0.34808476878702643, "actor_loss": -92.53559925842285, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.735447883605957, "step": 54000}
{"episode_reward": 895.4215818570792, "episode": 55.0, "batch_reward": 0.852663017988205, "critic_loss": 0.32319112558662894, "actor_loss": -92.66608737182617, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.71059489250183, "step": 55000}
{"episode_reward": 956.2762647677891, "episode": 56.0, "batch_reward": 0.8550137003660202, "critic_loss": 0.33267356123030184, "actor_loss": -92.97537867736817, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.438354969024658, "step": 56000}
{"episode_reward": 977.1152768304624, "episode": 57.0, "batch_reward": 0.8565077630281448, "critic_loss": 0.3324318808168173, "actor_loss": -92.91963592529297, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.220981121063232, "step": 57000}
{"episode_reward": 944.2232649873638, "episode": 58.0, "batch_reward": 0.8581814137101174, "critic_loss": 0.31607162380218506, "actor_loss": -93.08566662597656, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.9068820476532, "step": 58000}
{"episode_reward": 886.8688180440463, "episode": 59.0, "batch_reward": 0.8589896194338799, "critic_loss": 0.31949280625581744, "actor_loss": -92.96456254577637, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.581981658935547, "step": 59000}
{"episode_reward": 896.8706431579373, "episode": 60.0, "batch_reward": 0.8588831593394279, "critic_loss": 0.3291524600088596, "actor_loss": -92.82256646728516, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.56649899482727, "step": 60000}
{"episode_reward": 912.1392456900513, "episode": 61.0, "batch_reward": 0.8598196406960488, "critic_loss": 0.32622509883344175, "actor_loss": -92.91172581481933, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.48116683959961, "step": 61000}
{"episode_reward": 877.915082976987, "episode": 62.0, "batch_reward": 0.8601484062671662, "critic_loss": 0.3196370524466038, "actor_loss": -93.21287153625488, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.627931118011475, "step": 62000}
{"episode_reward": 972.448635961328, "episode": 63.0, "batch_reward": 0.8603549599051475, "critic_loss": 0.34721038268506527, "actor_loss": -93.18691633605957, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.52367329597473, "step": 63000}
{"episode_reward": 877.8499836494029, "episode": 64.0, "batch_reward": 0.8627738184928894, "critic_loss": 0.3492943574041128, "actor_loss": -93.17152166748046, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.978967666625977, "step": 64000}
{"episode_reward": 889.9559212708256, "episode": 65.0, "batch_reward": 0.8628890709280967, "critic_loss": 0.34157152050733564, "actor_loss": -93.20814477539062, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.48079824447632, "step": 65000}
{"episode_reward": 943.4830588954383, "episode": 66.0, "batch_reward": 0.8648352792263031, "critic_loss": 0.35003545054793356, "actor_loss": -93.23001715087891, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.695932149887085, "step": 66000}
{"episode_reward": 949.5163610876883, "episode": 67.0, "batch_reward": 0.8667417813539505, "critic_loss": 0.3407059423625469, "actor_loss": -93.43903285217286, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.853564739227295, "step": 67000}
{"episode_reward": 917.197677034724, "episode": 68.0, "batch_reward": 0.8652342020273208, "critic_loss": 0.32819809892773627, "actor_loss": -93.27440690612794, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.533610343933105, "step": 68000}
{"episode_reward": 947.5111048368618, "episode": 69.0, "batch_reward": 0.8687029843926429, "critic_loss": 0.3189438235908747, "actor_loss": -93.35000480651856, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.506072998046875, "step": 69000}
{"episode_reward": 940.6751726766905, "episode": 70.0, "batch_reward": 0.8687421575188636, "critic_loss": 0.32607491326332094, "actor_loss": -93.27895011901856, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.50646686553955, "step": 70000}
{"episode_reward": 931.2925168424399, "episode": 71.0, "batch_reward": 0.8685889208912849, "critic_loss": 0.3057134286910296, "actor_loss": -93.2780262145996, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.70909309387207, "step": 71000}
{"episode_reward": 918.0341764140295, "episode": 72.0, "batch_reward": 0.8697413180470467, "critic_loss": 0.3203889561444521, "actor_loss": -93.41790475463867, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.725627899169922, "step": 72000}
{"episode_reward": 868.5456345657476, "episode": 73.0, "batch_reward": 0.8691941674351692, "critic_loss": 0.3125431333333254, "actor_loss": -93.39762939453125, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.866267442703247, "step": 73000}
{"episode_reward": 898.2485181708186, "episode": 74.0, "batch_reward": 0.8703097808361053, "critic_loss": 0.33131593687832356, "actor_loss": -93.42190663146972, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.46853470802307, "step": 74000}
{"episode_reward": 935.2186847241597, "episode": 75.0, "batch_reward": 0.8727880328893661, "critic_loss": 0.3298468442708254, "actor_loss": -93.47880465698242, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.82042694091797, "step": 75000}
{"episode_reward": 958.071026029447, "episode": 76.0, "batch_reward": 0.8728272382020951, "critic_loss": 0.3187585218846798, "actor_loss": -93.49000231933594, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.40816307067871, "step": 76000}
{"episode_reward": 925.7115230105342, "episode": 77.0, "batch_reward": 0.8730564785003662, "critic_loss": 0.3367761523127556, "actor_loss": -93.6102554473877, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.780179977416992, "step": 77000}
{"episode_reward": 958.3959482280106, "episode": 78.0, "batch_reward": 0.872719071149826, "critic_loss": 0.34468102508038284, "actor_loss": -93.5834031829834, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.34373378753662, "step": 78000}
{"episode_reward": 896.0554931707869, "episode": 79.0, "batch_reward": 0.8729240425229072, "critic_loss": 0.31401644015312197, "actor_loss": -93.64705783081055, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.616244077682495, "step": 79000}
{"episode_reward": 942.9470126820719, "episode": 80.0, "batch_reward": 0.8734051510691643, "critic_loss": 0.32000206573307516, "actor_loss": -93.63047895812988, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 27.034138917922974, "step": 80000}
{"episode_reward": 653.2296262676288, "episode": 81.0, "batch_reward": 0.8712289971709252, "critic_loss": 0.3194764372184873, "actor_loss": -93.57361283874512, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.61530065536499, "step": 81000}
{"episode_reward": 882.2156721325503, "episode": 82.0, "batch_reward": 0.8709698026776314, "critic_loss": 0.35245755334198475, "actor_loss": -93.6588508605957, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.593040466308594, "step": 82000}
{"episode_reward": 875.6574305054282, "episode": 83.0, "batch_reward": 0.8718894442915917, "critic_loss": 0.3373510710597038, "actor_loss": -93.5710821685791, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 27.044782876968384, "step": 83000}
{"episode_reward": 935.6049448418086, "episode": 84.0, "batch_reward": 0.8726935794949532, "critic_loss": 0.3367609729617834, "actor_loss": -93.57527336120606, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.636377573013306, "step": 84000}
{"episode_reward": 891.9974581454233, "episode": 85.0, "batch_reward": 0.8740672554373741, "critic_loss": 0.33659250392019746, "actor_loss": -93.81547639465332, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.69574785232544, "step": 85000}
{"episode_reward": 961.1943521511148, "episode": 86.0, "batch_reward": 0.8744028304219246, "critic_loss": 0.32257124972343443, "actor_loss": -93.72869111633301, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.48753333091736, "step": 86000}
{"episode_reward": 961.782748244808, "episode": 87.0, "batch_reward": 0.8762212762236595, "critic_loss": 0.32578411561250686, "actor_loss": -93.7547942199707, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.874051094055176, "step": 87000}
{"episode_reward": 905.8661459935912, "episode": 88.0, "batch_reward": 0.8764308516383171, "critic_loss": 0.3255783657580614, "actor_loss": -93.75167961120606, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.38247799873352, "step": 88000}
{"episode_reward": 978.8716864598072, "episode": 89.0, "batch_reward": 0.8769860777258873, "critic_loss": 0.31409833424538375, "actor_loss": -93.93404978942871, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.60631012916565, "step": 89000}
{"episode_reward": 951.8547996738927, "episode": 90.0, "batch_reward": 0.8777314724922181, "critic_loss": 0.32926987667381763, "actor_loss": -93.9007667388916, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.520996809005737, "step": 90000}
{"episode_reward": 928.8624716541425, "episode": 91.0, "batch_reward": 0.8786307017803192, "critic_loss": 0.31862967103719714, "actor_loss": -93.95012924194336, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.42595434188843, "step": 91000}
{"episode_reward": 914.3214427898789, "episode": 92.0, "batch_reward": 0.8794313169717789, "critic_loss": 0.3025239976868033, "actor_loss": -93.97521211242676, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 27.121490955352783, "step": 92000}
{"episode_reward": 944.0830023476585, "episode": 93.0, "batch_reward": 0.8808143533468247, "critic_loss": 0.30900633911043407, "actor_loss": -93.974013381958, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.308031797409058, "step": 93000}
{"episode_reward": 942.8595607702216, "episode": 94.0, "batch_reward": 0.8802346475720405, "critic_loss": 0.30683986797183754, "actor_loss": -93.96909422302247, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.89939522743225, "step": 94000}
{"episode_reward": 914.6243251481362, "episode": 95.0, "batch_reward": 0.8811408323645592, "critic_loss": 0.311649825155735, "actor_loss": -93.92486045837403, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.626909255981445, "step": 95000}
{"episode_reward": 926.0840417897404, "episode": 96.0, "batch_reward": 0.8808314301967621, "critic_loss": 0.3064714799374342, "actor_loss": -93.94018013000488, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.763649940490723, "step": 96000}
{"episode_reward": 941.0610768870393, "episode": 97.0, "batch_reward": 0.881104170024395, "critic_loss": 0.29806187692284586, "actor_loss": -93.98352035522461, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.552595138549805, "step": 97000}
{"episode_reward": 954.8381652322299, "episode": 98.0, "batch_reward": 0.8827266182303428, "critic_loss": 0.2974216574952006, "actor_loss": -94.11237455749512, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.262590408325195, "step": 98000}
{"episode_reward": 940.9352276425808, "episode": 99.0, "batch_reward": 0.8832121300697326, "critic_loss": 0.29870635069161655, "actor_loss": -93.94700129699707, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.27139949798584, "step": 99000}
{"episode_reward": 895.4190369428063, "episode": 100.0, "batch_reward": 0.8823541678786277, "critic_loss": 0.3032674735635519, "actor_loss": -94.00425115966797, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.636033296585083, "step": 100000}
{"episode_reward": 951.4927479885466, "episode": 101.0, "batch_reward": 0.8842132239937782, "critic_loss": 0.29217661803215744, "actor_loss": -94.05713287353515, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.389888286590576, "step": 101000}
{"episode_reward": 937.6798186623873, "episode": 102.0, "batch_reward": 0.8848266270160675, "critic_loss": 0.29735785502940415, "actor_loss": -94.02949728393554, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.353370428085327, "step": 102000}
{"episode_reward": 967.5532369147843, "episode": 103.0, "batch_reward": 0.8855492635965347, "critic_loss": 0.2850324552506208, "actor_loss": -94.12431581115723, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.751832246780396, "step": 103000}
{"episode_reward": 934.1978369574305, "episode": 104.0, "batch_reward": 0.885277308344841, "critic_loss": 0.2658859261199832, "actor_loss": -94.07595669555664, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.571261644363403, "step": 104000}
{"episode_reward": 917.6175150410303, "episode": 105.0, "batch_reward": 0.8861344592571259, "critic_loss": 0.26316886919736865, "actor_loss": -94.17295887756347, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.755494356155396, "step": 105000}
{"episode_reward": 970.1396177582167, "episode": 106.0, "batch_reward": 0.887060249209404, "critic_loss": 0.2796929319426417, "actor_loss": -94.15923800659179, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 25.762269973754883, "step": 106000}
{"episode_reward": 932.6814448702755, "episode": 107.0, "batch_reward": 0.8862711211442947, "critic_loss": 0.2730188035443425, "actor_loss": -94.1846060333252, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.45288848876953, "step": 107000}
{"episode_reward": 906.2706386490204, "episode": 108.0, "batch_reward": 0.8866149585843086, "critic_loss": 0.2810596287548542, "actor_loss": -94.31884112548828, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.802682876586914, "step": 108000}
{"episode_reward": 946.2495392234093, "episode": 109.0, "batch_reward": 0.8871561863422394, "critic_loss": 0.26755488334596156, "actor_loss": -94.12232420349122, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.910355806350708, "step": 109000}
{"episode_reward": 932.0350751920859, "episode": 110.0, "batch_reward": 0.8893332629203796, "critic_loss": 0.268949408352375, "actor_loss": -94.19970768737792, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.99787998199463, "step": 110000}
{"episode_reward": 954.2833947275925, "episode": 111.0, "batch_reward": 0.8891689669489861, "critic_loss": 0.2727737601324916, "actor_loss": -94.40061613464356, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.5018310546875, "step": 111000}
{"episode_reward": 950.1202594929023, "episode": 112.0, "batch_reward": 0.8897696639895439, "critic_loss": 0.2687165783494711, "actor_loss": -94.2144072265625, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.8265221118927, "step": 112000}
{"episode_reward": 935.702150090117, "episode": 113.0, "batch_reward": 0.8902417983412743, "critic_loss": 0.2687229163199663, "actor_loss": -94.35599717712402, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.775168895721436, "step": 113000}
{"episode_reward": 950.5354793788911, "episode": 114.0, "batch_reward": 0.8895725902915, "critic_loss": 0.27690325352549555, "actor_loss": -94.3164993133545, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.99180507659912, "step": 114000}
{"episode_reward": 965.4349678591752, "episode": 115.0, "batch_reward": 0.891200475037098, "critic_loss": 0.2730828199386597, "actor_loss": -94.37853540039063, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 27.03368616104126, "step": 115000}
{"episode_reward": 956.3624809357805, "episode": 116.0, "batch_reward": 0.8922191886305809, "critic_loss": 0.2765502028688788, "actor_loss": -94.41739050292969, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.022289276123047, "step": 116000}
{"episode_reward": 944.2543913540527, "episode": 117.0, "batch_reward": 0.8913838916420936, "critic_loss": 0.2715256344377995, "actor_loss": -94.59626321411133, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.51775336265564, "step": 117000}
{"episode_reward": 885.7543199493006, "episode": 118.0, "batch_reward": 0.8911077979803085, "critic_loss": 0.27694355791062114, "actor_loss": -94.4744493560791, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.800249814987183, "step": 118000}
{"episode_reward": 954.0337291530901, "episode": 119.0, "batch_reward": 0.8925216109156608, "critic_loss": 0.27410511576384305, "actor_loss": -94.4600341644287, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.71904730796814, "step": 119000}
{"episode_reward": 950.5945047869562, "episode": 120.0, "batch_reward": 0.8935846440196037, "critic_loss": 0.2842733226567507, "actor_loss": -94.58384376525879, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.29032588005066, "step": 120000}
{"episode_reward": 957.9789537224815, "episode": 121.0, "batch_reward": 0.8943861747980117, "critic_loss": 0.26320897532254456, "actor_loss": -94.61236920166016, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.825958490371704, "step": 121000}
{"episode_reward": 957.9914240963094, "episode": 122.0, "batch_reward": 0.894194734632969, "critic_loss": 0.2631017576083541, "actor_loss": -94.58023629760743, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.739391565322876, "step": 122000}
{"episode_reward": 947.3406326673671, "episode": 123.0, "batch_reward": 0.8949551159143447, "critic_loss": 0.2695323244407773, "actor_loss": -94.53495738220215, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.855867624282837, "step": 123000}
{"episode_reward": 972.1487705403533, "episode": 124.0, "batch_reward": 0.896072754919529, "critic_loss": 0.27319605255126955, "actor_loss": -94.62567515563966, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.665855884552002, "step": 124000}
{"episode_reward": 953.7169088742266, "episode": 125.0, "batch_reward": 0.8948993366956711, "critic_loss": 0.26876631478965285, "actor_loss": -94.64512359619141, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.583764791488647, "step": 125000}
{"episode_reward": 856.228133989066, "episode": 126.0, "batch_reward": 0.8961875728368759, "critic_loss": 0.271341484002769, "actor_loss": -94.7384656982422, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.593445301055908, "step": 126000}
{"episode_reward": 947.330905199823, "episode": 127.0, "batch_reward": 0.8954295701980591, "critic_loss": 0.28107455108314755, "actor_loss": -94.55938793945313, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.662582635879517, "step": 127000}
{"episode_reward": 951.0339621127432, "episode": 128.0, "batch_reward": 0.8953757121562957, "critic_loss": 0.2839125567600131, "actor_loss": -94.63945433044434, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.63517713546753, "step": 128000}
{"episode_reward": 937.9291531142086, "episode": 129.0, "batch_reward": 0.8954541432261467, "critic_loss": 0.27146109817922115, "actor_loss": -94.72181312561035, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.678082704544067, "step": 129000}
{"episode_reward": 964.8993481590081, "episode": 130.0, "batch_reward": 0.8984106376767158, "critic_loss": 0.2707251640930772, "actor_loss": -94.79836354064942, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.507108211517334, "step": 130000}
{"episode_reward": 956.9517636552686, "episode": 131.0, "batch_reward": 0.8972313709259033, "critic_loss": 0.28138651994615793, "actor_loss": -94.66578590393067, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.9129376411438, "step": 131000}
{"episode_reward": 939.7254537632685, "episode": 132.0, "batch_reward": 0.897475513279438, "critic_loss": 0.2803014930188656, "actor_loss": -94.69803883361817, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.450759172439575, "step": 132000}
{"episode_reward": 947.4901999232098, "episode": 133.0, "batch_reward": 0.898373774111271, "critic_loss": 0.2798670510649681, "actor_loss": -94.78197372436523, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.840551376342773, "step": 133000}
{"episode_reward": 954.0996244786884, "episode": 134.0, "batch_reward": 0.8994762224555015, "critic_loss": 0.264287576533854, "actor_loss": -94.86355622863769, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.413426160812378, "step": 134000}
{"episode_reward": 946.1353937223696, "episode": 135.0, "batch_reward": 0.8993918796777726, "critic_loss": 0.27366982312500476, "actor_loss": -94.6802406616211, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.307708978652954, "step": 135000}
{"episode_reward": 930.4948100687473, "episode": 136.0, "batch_reward": 0.9000471674799919, "critic_loss": 0.2668695780932903, "actor_loss": -94.98269032287598, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 25.44997239112854, "step": 136000}
{"episode_reward": 945.8081670374028, "episode": 137.0, "batch_reward": 0.8990262973904609, "critic_loss": 0.2937030712664127, "actor_loss": -94.7466784362793, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.285911798477173, "step": 137000}
{"episode_reward": 953.9398489380715, "episode": 138.0, "batch_reward": 0.9010325278639794, "critic_loss": 0.2866382358819246, "actor_loss": -94.81024461364746, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.84870934486389, "step": 138000}
{"episode_reward": 973.0446798518042, "episode": 139.0, "batch_reward": 0.9011039720773697, "critic_loss": 0.2617611845135689, "actor_loss": -94.83571170043945, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.776827096939087, "step": 139000}
{"episode_reward": 935.1050700133575, "episode": 140.0, "batch_reward": 0.9026955119371414, "critic_loss": 0.26884109918028115, "actor_loss": -94.86649095153808, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.76557230949402, "step": 140000}
{"episode_reward": 917.9685686489918, "episode": 141.0, "batch_reward": 0.900177268743515, "critic_loss": 0.2857167498394847, "actor_loss": -94.7310436706543, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.462651014328, "step": 141000}
{"episode_reward": 946.970785151678, "episode": 142.0, "batch_reward": 0.9003575572371483, "critic_loss": 0.28475166171044114, "actor_loss": -94.89544398498535, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 27.303025484085083, "step": 142000}
{"episode_reward": 938.7085723114359, "episode": 143.0, "batch_reward": 0.9005307003259658, "critic_loss": 0.28576827343553307, "actor_loss": -94.90883460998535, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.545012712478638, "step": 143000}
{"episode_reward": 908.7300851465802, "episode": 144.0, "batch_reward": 0.901387031018734, "critic_loss": 0.3082936882674694, "actor_loss": -94.77928495788574, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.634758472442627, "step": 144000}
{"episode_reward": 933.8960676326518, "episode": 145.0, "batch_reward": 0.9019702593684197, "critic_loss": 0.29334807939082386, "actor_loss": -94.81338996887207, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.919491052627563, "step": 145000}
{"episode_reward": 912.3201707096458, "episode": 146.0, "batch_reward": 0.9021711817383766, "critic_loss": 0.29723387528210876, "actor_loss": -94.86289122009278, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.147407054901123, "step": 146000}
{"episode_reward": 978.0956521530483, "episode": 147.0, "batch_reward": 0.9029199663996696, "critic_loss": 0.28712786914408206, "actor_loss": -94.82690155029297, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 25.94299006462097, "step": 147000}
{"episode_reward": 946.9728748203763, "episode": 148.0, "batch_reward": 0.9004531071782113, "critic_loss": 0.2941406873911619, "actor_loss": -94.80340295410156, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.980234384536743, "step": 148000}
{"episode_reward": 831.3967423401043, "episode": 149.0, "batch_reward": 0.9020780559182167, "critic_loss": 0.28991712012887, "actor_loss": -94.87485809326172, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.833174467086792, "step": 149000}
{"episode_reward": 971.2298874933067, "episode": 150.0, "batch_reward": 0.9018849611282349, "critic_loss": 0.306625243127346, "actor_loss": -94.79585121154786, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "step": 150000}
