{"episode_reward": 0.0, "episode": 1.0, "duration": 20.997129917144775, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.8325374126434326, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.4375617294788122, "critic_loss": 0.08746262365798725, "actor_loss": -83.67603972130844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.67711663246155, "step": 3000}
{"episode_reward": 106.70376096632893, "episode": 4.0, "batch_reward": 0.3685301175713539, "critic_loss": 0.2932248998582363, "actor_loss": -80.63067971801757, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.163139820098877, "step": 4000}
{"episode_reward": 535.139076810582, "episode": 5.0, "batch_reward": 0.4047560484409332, "critic_loss": 0.3752540876567364, "actor_loss": -82.49725079345703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.158865928649902, "step": 5000}
{"episode_reward": 519.484629560224, "episode": 6.0, "batch_reward": 0.43736340472102164, "critic_loss": 0.4443110358566046, "actor_loss": -83.7453445739746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.144232749938965, "step": 6000}
{"episode_reward": 614.8050777540507, "episode": 7.0, "batch_reward": 0.46392644035816194, "critic_loss": 0.49944459944963454, "actor_loss": -84.53503758239746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.132846117019653, "step": 7000}
{"episode_reward": 714.2851629480825, "episode": 8.0, "batch_reward": 0.49866326051950455, "critic_loss": 0.5806971372961998, "actor_loss": -85.40165016174316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.134429454803467, "step": 8000}
{"episode_reward": 694.4391517522625, "episode": 9.0, "batch_reward": 0.5302756896615028, "critic_loss": 0.5763957390487194, "actor_loss": -86.28461784362793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.154447317123413, "step": 9000}
{"episode_reward": 842.1530249886013, "episode": 10.0, "batch_reward": 0.565029398471117, "critic_loss": 0.6899943836927414, "actor_loss": -87.29029512023926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.170547008514404, "step": 10000}
{"episode_reward": 852.5697087877547, "episode": 11.0, "batch_reward": 0.5946727940440177, "critic_loss": 0.7576290082633496, "actor_loss": -88.15260417175293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.79494667053223, "step": 11000}
{"episode_reward": 909.2179416377156, "episode": 12.0, "batch_reward": 0.6196878869533539, "critic_loss": 1.0196044346690178, "actor_loss": -89.058312789917, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.182307243347168, "step": 12000}
{"episode_reward": 855.4150074188893, "episode": 13.0, "batch_reward": 0.6152103272974491, "critic_loss": 1.3245497504472732, "actor_loss": -89.43457949829101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15717315673828, "step": 13000}
{"episode_reward": 455.20945901624816, "episode": 14.0, "batch_reward": 0.6253147142529487, "critic_loss": 1.6585442308187486, "actor_loss": -90.28063627624512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16180682182312, "step": 14000}
{"episode_reward": 898.0162276943852, "episode": 15.0, "batch_reward": 0.6436559668183327, "critic_loss": 2.6351748385429383, "actor_loss": -91.23783894348145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.167171955108643, "step": 15000}
{"episode_reward": 827.4584047466129, "episode": 16.0, "batch_reward": 0.6376824889779091, "critic_loss": 8.4327727394104, "actor_loss": -92.3899005126953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.184017658233643, "step": 16000}
{"episode_reward": 179.62994677044844, "episode": 17.0, "batch_reward": 0.6053535496592521, "critic_loss": 16.123437479257582, "actor_loss": -97.38852415466309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.164510011672974, "step": 17000}
{"episode_reward": 52.87093332413279, "episode": 18.0, "batch_reward": 0.5709247122704982, "critic_loss": 22.854453808784484, "actor_loss": -110.3732200012207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.176949739456177, "step": 18000}
{"episode_reward": 19.2330160851262, "episode": 19.0, "batch_reward": 0.5416537941694259, "critic_loss": 22.031997155189515, "actor_loss": -118.19303234863281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.147395372390747, "step": 19000}
{"episode_reward": 24.158101385977506, "episode": 20.0, "batch_reward": 0.5170366441607476, "critic_loss": 21.14523533439636, "actor_loss": -124.71555784606933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.168344974517822, "step": 20000}
{"episode_reward": 13.819472698220318, "episode": 21.0, "batch_reward": 0.4923164363205433, "critic_loss": 19.71152525615692, "actor_loss": -127.47432398986817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.91537642478943, "step": 21000}
{"episode_reward": 25.65492301635526, "episode": 22.0, "batch_reward": 0.4681040513813496, "critic_loss": 17.810245436668396, "actor_loss": -135.6752595977783, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.148911237716675, "step": 22000}
{"episode_reward": 40.74387572665312, "episode": 23.0, "batch_reward": 0.45061933994293213, "critic_loss": 15.746736247062683, "actor_loss": -137.79171641540526, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16650938987732, "step": 23000}
{"episode_reward": 42.814342711721565, "episode": 24.0, "batch_reward": 0.4329003666937351, "critic_loss": 13.696093983650208, "actor_loss": -143.2088538970947, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.189029932022095, "step": 24000}
{"episode_reward": 54.69549682481919, "episode": 25.0, "batch_reward": 0.4188933872282505, "critic_loss": 13.230229708194733, "actor_loss": -145.31408952331543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.176241636276245, "step": 25000}
{"episode_reward": 80.48502741982773, "episode": 26.0, "batch_reward": 0.404793424218893, "critic_loss": 12.292298922538757, "actor_loss": -147.3567667388916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.180965185165405, "step": 26000}
{"episode_reward": 46.93974192578701, "episode": 27.0, "batch_reward": 0.3944925013780594, "critic_loss": 12.339655594825745, "actor_loss": -151.72516537475585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16158390045166, "step": 27000}
{"episode_reward": 70.21414123175164, "episode": 28.0, "batch_reward": 0.3790340444147587, "critic_loss": 13.02024920463562, "actor_loss": -152.018107711792, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.153484106063843, "step": 28000}
{"episode_reward": 46.182246260123925, "episode": 29.0, "batch_reward": 0.36701650023460386, "critic_loss": 13.683068647384644, "actor_loss": -160.55132975769044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14958143234253, "step": 29000}
{"episode_reward": 61.55628006517237, "episode": 30.0, "batch_reward": 0.35840997290611265, "critic_loss": 12.861679665565491, "actor_loss": -156.22706684875487, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1486337184906, "step": 30000}
{"episode_reward": 101.96250014628586, "episode": 31.0, "batch_reward": 0.3498643135726452, "critic_loss": 10.43433553314209, "actor_loss": -154.94553370666503, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.89912819862366, "step": 31000}
{"episode_reward": 115.90946926009158, "episode": 32.0, "batch_reward": 0.3394287920892239, "critic_loss": 7.817016448736191, "actor_loss": -156.40188145446777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16254210472107, "step": 32000}
{"episode_reward": 38.710954418450804, "episode": 33.0, "batch_reward": 0.33220911924540997, "critic_loss": 6.216609061002731, "actor_loss": -157.32942585754395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14108681678772, "step": 33000}
{"episode_reward": 39.97475512565961, "episode": 34.0, "batch_reward": 0.3249999700039625, "critic_loss": 4.86974147105217, "actor_loss": -150.42710600280762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.178794384002686, "step": 34000}
{"episode_reward": 198.80343834982642, "episode": 35.0, "batch_reward": 0.3266681995242834, "critic_loss": 3.791123280286789, "actor_loss": -151.27797970581054, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15932273864746, "step": 35000}
{"episode_reward": 414.07714451915444, "episode": 36.0, "batch_reward": 0.32229384656250476, "critic_loss": 3.1290164211988447, "actor_loss": -146.10568673706055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1746985912323, "step": 36000}
{"episode_reward": 45.840648980103765, "episode": 37.0, "batch_reward": 0.3246644190996885, "critic_loss": 2.676593067884445, "actor_loss": -141.7705930480957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.158255577087402, "step": 37000}
{"episode_reward": 799.0852598253708, "episode": 38.0, "batch_reward": 0.33443581238389014, "critic_loss": 2.380755434989929, "actor_loss": -142.4681790008545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.188506603240967, "step": 38000}
{"episode_reward": 667.8946440754172, "episode": 39.0, "batch_reward": 0.3372732946425676, "critic_loss": 2.0419195919036865, "actor_loss": -137.49874969482423, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.166294813156128, "step": 39000}
{"episode_reward": 40.28243517501014, "episode": 40.0, "batch_reward": 0.33469241885840895, "critic_loss": 1.7335834667682648, "actor_loss": -133.20403053283692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.17032241821289, "step": 40000}
{"episode_reward": 638.1940867138256, "episode": 41.0, "batch_reward": 0.34803578516840933, "critic_loss": 1.559591235935688, "actor_loss": -129.61161016845702, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.75834536552429, "step": 41000}
{"episode_reward": 852.5295488271815, "episode": 42.0, "batch_reward": 0.35707056176662444, "critic_loss": 1.4453698682188987, "actor_loss": -127.96511680603027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15397572517395, "step": 42000}
{"episode_reward": 766.0620582842475, "episode": 43.0, "batch_reward": 0.3673400972485542, "critic_loss": 1.3404180191159247, "actor_loss": -124.74471868896484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14009714126587, "step": 43000}
{"episode_reward": 839.3325840321702, "episode": 44.0, "batch_reward": 0.3803647801280022, "critic_loss": 1.1953506346344949, "actor_loss": -122.49790701293945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.140739917755127, "step": 44000}
{"episode_reward": 882.4549688560988, "episode": 45.0, "batch_reward": 0.38996611285209654, "critic_loss": 1.1623341930508613, "actor_loss": -121.44000451660156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.136483430862427, "step": 45000}
{"episode_reward": 907.8995484615522, "episode": 46.0, "batch_reward": 0.4008824461996555, "critic_loss": 1.1418178532719612, "actor_loss": -118.32255812072754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.130317449569702, "step": 46000}
{"episode_reward": 837.9555613308585, "episode": 47.0, "batch_reward": 0.41020167884230613, "critic_loss": 1.097462826371193, "actor_loss": -115.12428620910644, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.12814736366272, "step": 47000}
{"episode_reward": 899.4267530596521, "episode": 48.0, "batch_reward": 0.4229893452227116, "critic_loss": 1.022681134223938, "actor_loss": -116.0169790802002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11565351486206, "step": 48000}
{"episode_reward": 966.839805726884, "episode": 49.0, "batch_reward": 0.43306525123119355, "critic_loss": 1.0088675998449326, "actor_loss": -113.9394744873047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.167840480804443, "step": 49000}
{"episode_reward": 897.2054587686495, "episode": 50.0, "batch_reward": 0.4414403507113457, "critic_loss": 1.0221990987062455, "actor_loss": -112.06066828918458, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.136508464813232, "step": 50000}
{"episode_reward": 884.1815360436219, "episode": 51.0, "batch_reward": 0.4520561157166958, "critic_loss": 1.0183994542360306, "actor_loss": -113.18959869384766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.722015380859375, "step": 51000}
{"episode_reward": 901.0531254049129, "episode": 52.0, "batch_reward": 0.4587939827442169, "critic_loss": 0.9794946185946465, "actor_loss": -109.9320210571289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.115413188934326, "step": 52000}
{"episode_reward": 899.0551537497686, "episode": 53.0, "batch_reward": 0.46806835767626764, "critic_loss": 0.9575759036839009, "actor_loss": -110.99113636779785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.139798164367676, "step": 53000}
{"episode_reward": 946.6339370026836, "episode": 54.0, "batch_reward": 0.47928790748119354, "critic_loss": 0.8725064450204373, "actor_loss": -108.95961088562012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.156290531158447, "step": 54000}
{"episode_reward": 947.2061320630634, "episode": 55.0, "batch_reward": 0.4870381736755371, "critic_loss": 0.7867440854609012, "actor_loss": -107.74895286560059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14293074607849, "step": 55000}
{"episode_reward": 965.5669933003543, "episode": 56.0, "batch_reward": 0.4944999411404133, "critic_loss": 0.7516386914551259, "actor_loss": -107.62508856201171, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1183443069458, "step": 56000}
{"episode_reward": 980.6594351967202, "episode": 57.0, "batch_reward": 0.5049682929813862, "critic_loss": 0.7413501049280167, "actor_loss": -106.37936235046386, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.166445016860962, "step": 57000}
{"episode_reward": 951.5751071237744, "episode": 58.0, "batch_reward": 0.5115237984955311, "critic_loss": 0.7310340080559253, "actor_loss": -106.41406262207032, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15775203704834, "step": 58000}
{"episode_reward": 914.6470423603242, "episode": 59.0, "batch_reward": 0.5174602017700672, "critic_loss": 0.7435654576420784, "actor_loss": -105.21615574645996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15249252319336, "step": 59000}
{"episode_reward": 934.6063716768929, "episode": 60.0, "batch_reward": 0.5260093449056149, "critic_loss": 0.7866869486570358, "actor_loss": -103.99206465148926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.129854917526245, "step": 60000}
{"episode_reward": 923.8591022714826, "episode": 61.0, "batch_reward": 0.530179702013731, "critic_loss": 0.7922860749065876, "actor_loss": -103.46241899108887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.78458213806152, "step": 61000}
{"episode_reward": 879.0162365475136, "episode": 62.0, "batch_reward": 0.5367203527390957, "critic_loss": 0.8463395918309689, "actor_loss": -103.60531684875488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.126566886901855, "step": 62000}
{"episode_reward": 950.1420276790085, "episode": 63.0, "batch_reward": 0.5438804903030395, "critic_loss": 0.7656008328199386, "actor_loss": -102.99950802612305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.149784803390503, "step": 63000}
{"episode_reward": 972.7474943713723, "episode": 64.0, "batch_reward": 0.5505030417442321, "critic_loss": 0.7142894461452961, "actor_loss": -101.81725137329101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.173254013061523, "step": 64000}
{"episode_reward": 926.1342242195016, "episode": 65.0, "batch_reward": 0.5572926807701588, "critic_loss": 0.6533375250995159, "actor_loss": -101.7064373626709, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.127231121063232, "step": 65000}
{"episode_reward": 957.8999766430844, "episode": 66.0, "batch_reward": 0.5633057916462422, "critic_loss": 0.6363073369264602, "actor_loss": -101.16275909423828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14382553100586, "step": 66000}
{"episode_reward": 965.1786437902438, "episode": 67.0, "batch_reward": 0.568685862839222, "critic_loss": 0.6135948303937911, "actor_loss": -101.1542488861084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.164149045944214, "step": 67000}
{"episode_reward": 917.4805475343178, "episode": 68.0, "batch_reward": 0.5734181311130524, "critic_loss": 0.6379096832871437, "actor_loss": -100.43507737731933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.157721281051636, "step": 68000}
{"episode_reward": 932.1981106414739, "episode": 69.0, "batch_reward": 0.5821883397996426, "critic_loss": 0.5955499822199345, "actor_loss": -100.2426586151123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.161705017089844, "step": 69000}
{"episode_reward": 956.4777256508311, "episode": 70.0, "batch_reward": 0.5837045659422875, "critic_loss": 0.5616658907234668, "actor_loss": -99.11532386779785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16179323196411, "step": 70000}
{"episode_reward": 929.4633492371786, "episode": 71.0, "batch_reward": 0.5890186999440193, "critic_loss": 0.5231250497996807, "actor_loss": -99.2611969909668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.69030165672302, "step": 71000}
{"episode_reward": 953.5065009839177, "episode": 72.0, "batch_reward": 0.5946275074183941, "critic_loss": 0.5152065197974444, "actor_loss": -98.54622190856934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14510989189148, "step": 72000}
{"episode_reward": 900.2061084221915, "episode": 73.0, "batch_reward": 0.5964158417880535, "critic_loss": 0.4978221174031496, "actor_loss": -97.96585191345216, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13074564933777, "step": 73000}
{"episode_reward": 961.9827204335893, "episode": 74.0, "batch_reward": 0.6012890177667141, "critic_loss": 0.46466894590854646, "actor_loss": -97.25854890441894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.148648023605347, "step": 74000}
{"episode_reward": 902.0949421556833, "episode": 75.0, "batch_reward": 0.6104326188564301, "critic_loss": 0.45405737125873563, "actor_loss": -96.90151177978515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14221167564392, "step": 75000}
{"episode_reward": 974.3472984401892, "episode": 76.0, "batch_reward": 0.6132717265486717, "critic_loss": 0.49540304620563985, "actor_loss": -96.24732409667969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15165615081787, "step": 76000}
{"episode_reward": 958.7478451414393, "episode": 77.0, "batch_reward": 0.6169360297918319, "critic_loss": 0.4968507492989302, "actor_loss": -96.36739584350586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.136319160461426, "step": 77000}
{"episode_reward": 984.6299571116327, "episode": 78.0, "batch_reward": 0.6193752380013466, "critic_loss": 0.5087727909684181, "actor_loss": -95.80918772888184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.138671159744263, "step": 78000}
{"episode_reward": 911.5667791009357, "episode": 79.0, "batch_reward": 0.6232758034765721, "critic_loss": 0.4942701194435358, "actor_loss": -95.57493603515626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.146491765975952, "step": 79000}
{"episode_reward": 957.7450165538892, "episode": 80.0, "batch_reward": 0.6295180533528328, "critic_loss": 0.4757596212476492, "actor_loss": -95.24542105102539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.144014835357666, "step": 80000}
{"episode_reward": 931.8592226273729, "episode": 81.0, "batch_reward": 0.6350012232065201, "critic_loss": 0.4919066486209631, "actor_loss": -95.32355490112305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.702171325683594, "step": 81000}
{"episode_reward": 956.2187767417846, "episode": 82.0, "batch_reward": 0.6342359804511071, "critic_loss": 0.48464810685813425, "actor_loss": -95.12745115661622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.148820161819458, "step": 82000}
{"episode_reward": 951.9133993455614, "episode": 83.0, "batch_reward": 0.6398979100584984, "critic_loss": 0.47772776073217393, "actor_loss": -94.89558769226075, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.142606258392334, "step": 83000}
{"episode_reward": 963.4225914405527, "episode": 84.0, "batch_reward": 0.6407610631883144, "critic_loss": 0.4557715832144022, "actor_loss": -94.73364414978028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.135549068450928, "step": 84000}
{"episode_reward": 872.2545635392405, "episode": 85.0, "batch_reward": 0.6477271656990051, "critic_loss": 0.445896887421608, "actor_loss": -94.92167878723144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14668917655945, "step": 85000}
{"episode_reward": 962.9336200810122, "episode": 86.0, "batch_reward": 0.6525114121437072, "critic_loss": 0.43785497844219207, "actor_loss": -94.4883090209961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15608811378479, "step": 86000}
{"episode_reward": 968.6865769951592, "episode": 87.0, "batch_reward": 0.6536014428138733, "critic_loss": 0.454792652875185, "actor_loss": -94.31827409362793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.140769004821777, "step": 87000}
{"episode_reward": 852.673513978027, "episode": 88.0, "batch_reward": 0.6586255622506142, "critic_loss": 0.44040977135300635, "actor_loss": -94.11251013183593, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.154728412628174, "step": 88000}
{"episode_reward": 970.8460788699834, "episode": 89.0, "batch_reward": 0.661518651664257, "critic_loss": 0.42617161841690543, "actor_loss": -93.8764132232666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15585160255432, "step": 89000}
{"episode_reward": 947.4854142362814, "episode": 90.0, "batch_reward": 0.6639157167673111, "critic_loss": 0.4349207044988871, "actor_loss": -93.75711605834961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.138784408569336, "step": 90000}
{"episode_reward": 962.5504084797383, "episode": 91.0, "batch_reward": 0.6672558768391609, "critic_loss": 0.43576369421184064, "actor_loss": -93.60476179504394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.69550657272339, "step": 91000}
{"episode_reward": 929.9750445577653, "episode": 92.0, "batch_reward": 0.6703391370177268, "critic_loss": 0.42776252292096617, "actor_loss": -93.53195179748535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14686632156372, "step": 92000}
{"episode_reward": 992.741569731184, "episode": 93.0, "batch_reward": 0.6735476976633072, "critic_loss": 0.4367194100320339, "actor_loss": -93.59332015991211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.129030227661133, "step": 93000}
{"episode_reward": 990.7144568181694, "episode": 94.0, "batch_reward": 0.6774027411937713, "critic_loss": 0.4570125778913498, "actor_loss": -93.64021488952636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.115802764892578, "step": 94000}
{"episode_reward": 945.3637948983535, "episode": 95.0, "batch_reward": 0.6795188373327256, "critic_loss": 0.455725402250886, "actor_loss": -93.7967078857422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.130944967269897, "step": 95000}
{"episode_reward": 884.3280758320105, "episode": 96.0, "batch_reward": 0.6822190122008324, "critic_loss": 0.4538627897053957, "actor_loss": -93.49508345031738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11439037322998, "step": 96000}
{"episode_reward": 970.9359517356277, "episode": 97.0, "batch_reward": 0.6845901587605476, "critic_loss": 0.46478623332083224, "actor_loss": -93.5750093383789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1320481300354, "step": 97000}
{"episode_reward": 948.721574553019, "episode": 98.0, "batch_reward": 0.6905791009664536, "critic_loss": 0.4634235277920961, "actor_loss": -93.78691046142578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15511178970337, "step": 98000}
{"episode_reward": 967.7976002849559, "episode": 99.0, "batch_reward": 0.6903563739061356, "critic_loss": 0.466143896356225, "actor_loss": -93.46537272644044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.146644115447998, "step": 99000}
{"episode_reward": 942.7614441615859, "episode": 100.0, "batch_reward": 0.6872705097794533, "critic_loss": 0.4199165830910206, "actor_loss": -93.3089141998291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.186214685440063, "step": 100000}
{"episode_reward": 54.75855137404777, "episode": 101.0, "batch_reward": 0.686624441921711, "critic_loss": 0.4058243147134781, "actor_loss": -93.07825387573243, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.7235324382782, "step": 101000}
{"episode_reward": 978.1295475072421, "episode": 102.0, "batch_reward": 0.6849858121871948, "critic_loss": 0.416285283729434, "actor_loss": -92.7200714111328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.181462049484253, "step": 102000}
{"episode_reward": 66.08847292728082, "episode": 103.0, "batch_reward": 0.6853766555786133, "critic_loss": 0.4081131696999073, "actor_loss": -92.5153419342041, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.156699657440186, "step": 103000}
{"episode_reward": 938.3802196454417, "episode": 104.0, "batch_reward": 0.6845801917314529, "critic_loss": 0.4001841736584902, "actor_loss": -92.40906640625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.166014194488525, "step": 104000}
{"episode_reward": 922.2946398206153, "episode": 105.0, "batch_reward": 0.6894052476882935, "critic_loss": 0.4145141432136297, "actor_loss": -92.32541743469238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15495467185974, "step": 105000}
{"episode_reward": 973.5839259466374, "episode": 106.0, "batch_reward": 0.6900423992276191, "critic_loss": 0.4249083890169859, "actor_loss": -92.16000233459472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.150869131088257, "step": 106000}
{"episode_reward": 934.1661634419062, "episode": 107.0, "batch_reward": 0.6929005044698715, "critic_loss": 0.4130294159054756, "actor_loss": -92.07711323547363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15337324142456, "step": 107000}
{"episode_reward": 913.5097210544786, "episode": 108.0, "batch_reward": 0.6956458839178086, "critic_loss": 0.41013164100050925, "actor_loss": -92.01039326477051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.142566680908203, "step": 108000}
{"episode_reward": 947.6144888453783, "episode": 109.0, "batch_reward": 0.6976328727602958, "critic_loss": 0.41793825970590115, "actor_loss": -91.94198182678223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14363932609558, "step": 109000}
{"episode_reward": 919.1087378970087, "episode": 110.0, "batch_reward": 0.6997529799938202, "critic_loss": 0.44459286154806615, "actor_loss": -92.03286735534668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15423822402954, "step": 110000}
{"episode_reward": 947.5239341019022, "episode": 111.0, "batch_reward": 0.701204832136631, "critic_loss": 0.4382022777497768, "actor_loss": -92.03673448181152, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.70577311515808, "step": 111000}
{"episode_reward": 948.560190644372, "episode": 112.0, "batch_reward": 0.7047774050831794, "critic_loss": 0.42256831012666224, "actor_loss": -92.08691746520996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16740083694458, "step": 112000}
{"episode_reward": 933.6839153058472, "episode": 113.0, "batch_reward": 0.7066414561867714, "critic_loss": 0.44245889255404475, "actor_loss": -92.06966970825195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.132551431655884, "step": 113000}
{"episode_reward": 967.3683801520694, "episode": 114.0, "batch_reward": 0.7083633923530579, "critic_loss": 0.42405160976946354, "actor_loss": -91.96552624511719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.116584539413452, "step": 114000}
{"episode_reward": 988.2179748369614, "episode": 115.0, "batch_reward": 0.7096987919807434, "critic_loss": 0.44379203183948995, "actor_loss": -91.92040867614746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14681577682495, "step": 115000}
{"episode_reward": 953.1266161397306, "episode": 116.0, "batch_reward": 0.7150175797939301, "critic_loss": 0.42996138463914396, "actor_loss": -92.11540393066406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.151412963867188, "step": 116000}
{"episode_reward": 938.4952221075015, "episode": 117.0, "batch_reward": 0.7135729830861092, "critic_loss": 0.42620912221074103, "actor_loss": -91.99110896301269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1374192237854, "step": 117000}
{"episode_reward": 931.3844825935587, "episode": 118.0, "batch_reward": 0.7166647462248802, "critic_loss": 0.4476699070632458, "actor_loss": -92.11985652160645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1468722820282, "step": 118000}
{"episode_reward": 929.3875173476331, "episode": 119.0, "batch_reward": 0.7192058212161064, "critic_loss": 0.4462392690628767, "actor_loss": -92.09813943481446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15451979637146, "step": 119000}
{"episode_reward": 934.7210606047935, "episode": 120.0, "batch_reward": 0.7193628675937652, "critic_loss": 0.44497969175875185, "actor_loss": -92.15104187011718, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.161970376968384, "step": 120000}
{"episode_reward": 951.6275169454175, "episode": 121.0, "batch_reward": 0.7221131731271744, "critic_loss": 0.4662265516221523, "actor_loss": -92.25210160827636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.87818360328674, "step": 121000}
{"episode_reward": 947.0663993432387, "episode": 122.0, "batch_reward": 0.7236203374862671, "critic_loss": 0.4571002775430679, "actor_loss": -92.26357563781738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.35908842086792, "step": 122000}
{"episode_reward": 911.3661600951381, "episode": 123.0, "batch_reward": 0.7240943284630775, "critic_loss": 0.4573587720245123, "actor_loss": -92.24794734191894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.108694314956665, "step": 123000}
{"episode_reward": 923.3713850973529, "episode": 124.0, "batch_reward": 0.7277014937400818, "critic_loss": 0.49607650184631347, "actor_loss": -92.37198175048829, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.08380103111267, "step": 124000}
{"episode_reward": 951.282956031223, "episode": 125.0, "batch_reward": 0.7301415695548058, "critic_loss": 0.5299492666125297, "actor_loss": -92.42671162414551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.145909070968628, "step": 125000}
{"episode_reward": 895.8088149499254, "episode": 126.0, "batch_reward": 0.7303971300125122, "critic_loss": 0.6772043637633324, "actor_loss": -92.47505294799805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15531063079834, "step": 126000}
{"episode_reward": 968.7697989942616, "episode": 127.0, "batch_reward": 0.7324840636253357, "critic_loss": 0.7656029451191425, "actor_loss": -92.74340798950195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.17249894142151, "step": 127000}
{"episode_reward": 967.6557245778192, "episode": 128.0, "batch_reward": 0.7331229478120804, "critic_loss": 0.6343472400009632, "actor_loss": -92.76005644226075, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.15234351158142, "step": 128000}
{"episode_reward": 950.8029109007316, "episode": 129.0, "batch_reward": 0.7340000826120376, "critic_loss": 0.4711078257262707, "actor_loss": -92.56781248474121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.182470560073853, "step": 129000}
{"episode_reward": 972.7919466106164, "episode": 130.0, "batch_reward": 0.7389467133879661, "critic_loss": 0.40845695163309576, "actor_loss": -92.63713052368163, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.160754203796387, "step": 130000}
{"episode_reward": 924.5965893582301, "episode": 131.0, "batch_reward": 0.7392861132621765, "critic_loss": 0.4025928720831871, "actor_loss": -92.39410639953613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.755077838897705, "step": 131000}
{"episode_reward": 947.8677678784617, "episode": 132.0, "batch_reward": 0.7383428015112877, "critic_loss": 0.4148203576952219, "actor_loss": -92.3018282623291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.153316736221313, "step": 132000}
{"episode_reward": 931.6135046627488, "episode": 133.0, "batch_reward": 0.7429973222613334, "critic_loss": 0.4278842341154814, "actor_loss": -92.2254659729004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16122317314148, "step": 133000}
{"episode_reward": 956.2009195124516, "episode": 134.0, "batch_reward": 0.7433765649795532, "critic_loss": 0.41643036566674707, "actor_loss": -92.17437901306153, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.117733001708984, "step": 134000}
{"episode_reward": 959.7881485714825, "episode": 135.0, "batch_reward": 0.744727805018425, "critic_loss": 0.43086357998847963, "actor_loss": -92.19955554199218, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.152260065078735, "step": 135000}
{"episode_reward": 905.7964132154668, "episode": 136.0, "batch_reward": 0.744770563840866, "critic_loss": 0.4159786657243967, "actor_loss": -92.12099781799317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.164149522781372, "step": 136000}
{"episode_reward": 937.3421587674433, "episode": 137.0, "batch_reward": 0.7472656660676003, "critic_loss": 0.43521301847696303, "actor_loss": -92.27825424194336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.158279418945312, "step": 137000}
{"episode_reward": 977.825784746845, "episode": 138.0, "batch_reward": 0.7505428455471993, "critic_loss": 0.38925529731810093, "actor_loss": -92.3486745300293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.135174036026, "step": 138000}
{"episode_reward": 977.636639448801, "episode": 139.0, "batch_reward": 0.7523652889728546, "critic_loss": 0.40314839319884777, "actor_loss": -92.44606072998047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.150603771209717, "step": 139000}
{"episode_reward": 933.9968272911738, "episode": 140.0, "batch_reward": 0.7551774826645851, "critic_loss": 0.3922002568542957, "actor_loss": -92.51319715881348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14816904067993, "step": 140000}
{"episode_reward": 959.571320992428, "episode": 141.0, "batch_reward": 0.7521947006583214, "critic_loss": 0.402646895095706, "actor_loss": -92.30024868774414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.73428225517273, "step": 141000}
{"episode_reward": 939.3631703112245, "episode": 142.0, "batch_reward": 0.7517005056142807, "critic_loss": 0.3977931422740221, "actor_loss": -92.25423429870605, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.14096689224243, "step": 142000}
{"episode_reward": 955.0731613833912, "episode": 143.0, "batch_reward": 0.7556306099891663, "critic_loss": 0.36378734132647517, "actor_loss": -92.38172326660157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13871121406555, "step": 143000}
{"episode_reward": 936.5891251219111, "episode": 144.0, "batch_reward": 0.7590529003739357, "critic_loss": 0.3698045575469732, "actor_loss": -92.46164784240723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.141432762145996, "step": 144000}
{"episode_reward": 913.7725870888383, "episode": 145.0, "batch_reward": 0.7590068904161453, "critic_loss": 0.3409922694414854, "actor_loss": -92.45748489379883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.142573356628418, "step": 145000}
{"episode_reward": 924.911003033554, "episode": 146.0, "batch_reward": 0.7595056299567222, "critic_loss": 0.3584827478080988, "actor_loss": -92.57541069030762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.13461709022522, "step": 146000}
{"episode_reward": 956.5280131770353, "episode": 147.0, "batch_reward": 0.7616496436595916, "critic_loss": 0.3916129565089941, "actor_loss": -92.62785748291016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.160969495773315, "step": 147000}
{"episode_reward": 891.106476568942, "episode": 148.0, "batch_reward": 0.7635699568390846, "critic_loss": 0.36269154231250283, "actor_loss": -92.5487474822998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.141746997833252, "step": 148000}
{"episode_reward": 938.4808841469538, "episode": 149.0, "batch_reward": 0.7638986743688584, "critic_loss": 0.3612436480820179, "actor_loss": -92.57429130554199, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.155064582824707, "step": 149000}
{"episode_reward": 990.1647921696768, "episode": 150.0, "batch_reward": 0.7649731503129006, "critic_loss": 0.35759492955356836, "actor_loss": -92.52640411376953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
