{"episode_reward": 0.0, "episode": 1.0, "duration": 21.534563541412354, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.8565423488616943, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.43498911119055933, "critic_loss": 0.0677541186363834, "actor_loss": -52.5722815410859, "actor_target_entropy": -6.0, "alpha_value": 0.002642586817083679, "duration": 63.30941581726074, "step": 3000}
{"episode_reward": 4.07391554283549, "episode": 4.0, "batch_reward": 0.26976058189570906, "critic_loss": 0.09034071136824787, "actor_loss": -45.69244253158569, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.735331296920776, "step": 4000}
{"episode_reward": 3.6628227636285504, "episode": 5.0, "batch_reward": 0.21083219660818578, "critic_loss": 0.11287047451734543, "actor_loss": -45.33711994791031, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.526386976242065, "step": 5000}
{"episode_reward": 7.216799385225132, "episode": 6.0, "batch_reward": 0.17397613804787398, "critic_loss": 0.1689938793592155, "actor_loss": -42.266525111675264, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.05060362815857, "step": 6000}
{"episode_reward": 11.053917382384912, "episode": 7.0, "batch_reward": 0.15170290171355008, "critic_loss": 0.2561054218970239, "actor_loss": -42.501609686374664, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.19313359260559, "step": 7000}
{"episode_reward": 49.09435472929377, "episode": 8.0, "batch_reward": 0.13916824136301875, "critic_loss": 0.33346557669341564, "actor_loss": -46.02610632038117, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.986279249191284, "step": 8000}
{"episode_reward": 47.69475002390011, "episode": 9.0, "batch_reward": 0.1265727863907814, "critic_loss": 0.5744915592744947, "actor_loss": -43.71744193792343, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.757206201553345, "step": 9000}
{"episode_reward": 41.750076302893184, "episode": 10.0, "batch_reward": 0.12087637905031443, "critic_loss": 0.9520775986909866, "actor_loss": -45.50096033024788, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.47881770133972, "step": 10000}
{"episode_reward": 98.55658486145892, "episode": 11.0, "batch_reward": 0.12216976396366953, "critic_loss": 1.440234953135252, "actor_loss": -45.30590169286728, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.39772915840149, "step": 11000}
{"episode_reward": 170.8371470720161, "episode": 12.0, "batch_reward": 0.12128997389227152, "critic_loss": 2.1458358115553855, "actor_loss": -47.83769404602051, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.508095502853394, "step": 12000}
{"episode_reward": 48.36956465907219, "episode": 13.0, "batch_reward": 0.11450807656347751, "critic_loss": 3.9792715524435045, "actor_loss": -48.43065960216522, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.02056884765625, "step": 13000}
{"episode_reward": 27.497164954558155, "episode": 14.0, "batch_reward": 0.10711275897547602, "critic_loss": 5.331921751022339, "actor_loss": -52.46001204872131, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.908317804336548, "step": 14000}
{"episode_reward": 45.138113865564286, "episode": 15.0, "batch_reward": 0.10360054777190089, "critic_loss": 5.73156619644165, "actor_loss": -54.62181742858887, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.91104483604431, "step": 15000}
{"episode_reward": 25.098862913878605, "episode": 16.0, "batch_reward": 0.10013869357481599, "critic_loss": 6.536093584537506, "actor_loss": -61.41145154571533, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.107452630996704, "step": 16000}
{"episode_reward": 69.7191269233352, "episode": 17.0, "batch_reward": 0.09610255139693617, "critic_loss": 4.9143682286739345, "actor_loss": -63.7766169052124, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.096740245819092, "step": 17000}
{"episode_reward": 26.886152823280618, "episode": 18.0, "batch_reward": 0.09303918565064669, "critic_loss": 5.114685121774674, "actor_loss": -65.7457095489502, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.09720802307129, "step": 18000}
{"episode_reward": 50.38137554775888, "episode": 19.0, "batch_reward": 0.09973470301926136, "critic_loss": 7.6987417030334475, "actor_loss": -68.00750200653076, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.614739179611206, "step": 19000}
{"episode_reward": 315.5491630664076, "episode": 20.0, "batch_reward": 0.10945702759176493, "critic_loss": 6.939540818214416, "actor_loss": -69.24500665283203, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.5045108795166, "step": 20000}
{"episode_reward": 365.6029601360871, "episode": 21.0, "batch_reward": 0.11943354503810406, "critic_loss": 8.368444031476974, "actor_loss": -71.35429384613037, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.93140244483948, "step": 21000}
{"episode_reward": 203.27793894830052, "episode": 22.0, "batch_reward": 0.12555256232619286, "critic_loss": 11.209921095848083, "actor_loss": -72.75523475646973, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.598000526428223, "step": 22000}
{"episode_reward": 330.4457356649325, "episode": 23.0, "batch_reward": 0.12895033647865056, "critic_loss": 12.467343723773956, "actor_loss": -75.04269012451172, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.07684564590454, "step": 23000}
{"episode_reward": 52.717022287342694, "episode": 24.0, "batch_reward": 0.12928970334678888, "critic_loss": 11.753481331825256, "actor_loss": -77.38754522705078, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.20022940635681, "step": 24000}
{"episode_reward": 154.27345906468503, "episode": 25.0, "batch_reward": 0.12954149013012647, "critic_loss": 9.403680970907212, "actor_loss": -78.10392863464355, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.063539266586304, "step": 25000}
{"episode_reward": 124.57927487129493, "episode": 26.0, "batch_reward": 0.13133191986382006, "critic_loss": 9.856030926704406, "actor_loss": -78.14534336853028, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.90629816055298, "step": 26000}
{"episode_reward": 180.35734439746955, "episode": 27.0, "batch_reward": 0.13159061989933252, "critic_loss": 9.734991894721984, "actor_loss": -79.0461297302246, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.66302227973938, "step": 27000}
{"episode_reward": 119.9470954902215, "episode": 28.0, "batch_reward": 0.12613812350481748, "critic_loss": 8.37103662633896, "actor_loss": -79.76050119018555, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.294639348983765, "step": 28000}
{"episode_reward": 36.4657496064071, "episode": 29.0, "batch_reward": 0.12767672841995956, "critic_loss": 7.711919288158417, "actor_loss": -81.63517880249023, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.510448932647705, "step": 29000}
{"episode_reward": 167.3162415347188, "episode": 30.0, "batch_reward": 0.12737165079265833, "critic_loss": 5.736728072881698, "actor_loss": -82.97872030639648, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.50797700881958, "step": 30000}
{"episode_reward": 151.90372870500894, "episode": 31.0, "batch_reward": 0.1286308008208871, "critic_loss": 4.755903227329254, "actor_loss": -82.60126908874511, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.410475969314575, "step": 31000}
{"episode_reward": 87.97476747646316, "episode": 32.0, "batch_reward": 0.12722529781609773, "critic_loss": 3.8418273751735685, "actor_loss": -82.37024317932129, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.633128881454468, "step": 32000}
{"episode_reward": 271.84562944385124, "episode": 33.0, "batch_reward": 0.13608479301631451, "critic_loss": 3.6845528082847596, "actor_loss": -81.91902702331544, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.642467975616455, "step": 33000}
{"episode_reward": 342.7914804862029, "episode": 34.0, "batch_reward": 0.14561245580017568, "critic_loss": 3.0971524200439453, "actor_loss": -81.08163414001464, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.251338243484497, "step": 34000}
{"episode_reward": 693.3463313097328, "episode": 35.0, "batch_reward": 0.16262057390064, "critic_loss": 3.2143658345937727, "actor_loss": -80.91525309753418, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.474629402160645, "step": 35000}
{"episode_reward": 686.4258649582365, "episode": 36.0, "batch_reward": 0.17527167940884827, "critic_loss": 3.0389336341619493, "actor_loss": -80.11140063476563, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.81722402572632, "step": 36000}
{"episode_reward": 526.0619648042057, "episode": 37.0, "batch_reward": 0.18627692717313765, "critic_loss": 3.0012741210460665, "actor_loss": -79.95445014953613, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.459378004074097, "step": 37000}
{"episode_reward": 576.1087965603126, "episode": 38.0, "batch_reward": 0.19047265488654375, "critic_loss": 2.9867085843086243, "actor_loss": -79.68633671569825, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.69332790374756, "step": 38000}
{"episode_reward": 163.66333394855556, "episode": 39.0, "batch_reward": 0.1972096658051014, "critic_loss": 2.8258008229732514, "actor_loss": -79.53153382873535, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.81628394126892, "step": 39000}
{"episode_reward": 762.7112051362093, "episode": 40.0, "batch_reward": 0.20814605769515038, "critic_loss": 2.7663542431592942, "actor_loss": -79.48186804199219, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.005228281021118, "step": 40000}
{"episode_reward": 748.1833889994128, "episode": 41.0, "batch_reward": 0.2216957188397646, "critic_loss": 2.7239440433979034, "actor_loss": -79.3796575012207, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.28942584991455, "step": 41000}
{"episode_reward": 682.1688631883248, "episode": 42.0, "batch_reward": 0.2327644719481468, "critic_loss": 2.743721158981323, "actor_loss": -79.13410311889649, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.75419569015503, "step": 42000}
{"episode_reward": 640.6129314913089, "episode": 43.0, "batch_reward": 0.24480491790175438, "critic_loss": 2.792236956000328, "actor_loss": -79.36735365295411, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.131264686584473, "step": 43000}
{"episode_reward": 767.8115335249232, "episode": 44.0, "batch_reward": 0.25671984133124354, "critic_loss": 2.8542713108062743, "actor_loss": -79.28090266418457, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.765157222747803, "step": 44000}
{"episode_reward": 735.6374822322817, "episode": 45.0, "batch_reward": 0.2672730533927679, "critic_loss": 2.872163440108299, "actor_loss": -79.2479833984375, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.50979447364807, "step": 45000}
{"episode_reward": 746.4973422902846, "episode": 46.0, "batch_reward": 0.2766144858449697, "critic_loss": 2.9096789518594743, "actor_loss": -79.60234657287597, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.021785974502563, "step": 46000}
{"episode_reward": 676.5920631578032, "episode": 47.0, "batch_reward": 0.28401176577806475, "critic_loss": 2.714968649148941, "actor_loss": -79.69530213928223, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.70952081680298, "step": 47000}
{"episode_reward": 542.0347474067325, "episode": 48.0, "batch_reward": 0.2942027530670166, "critic_loss": 2.731060463309288, "actor_loss": -79.89375970458984, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.689859628677368, "step": 48000}
{"episode_reward": 821.8226265053357, "episode": 49.0, "batch_reward": 0.3051602073013783, "critic_loss": 2.7142176369428634, "actor_loss": -79.90133448791504, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.434720754623413, "step": 49000}
{"episode_reward": 849.2089852343167, "episode": 50.0, "batch_reward": 0.3142785287499428, "critic_loss": 2.542457175254822, "actor_loss": -79.75044670104981, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.647154808044434, "step": 50000}
{"episode_reward": 770.1808182150744, "episode": 51.0, "batch_reward": 0.32448984391987323, "critic_loss": 2.4204951446056366, "actor_loss": -79.78701318359376, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.044042110443115, "step": 51000}
{"episode_reward": 796.3102429903237, "episode": 52.0, "batch_reward": 0.33364785473048686, "critic_loss": 2.2599718136787414, "actor_loss": -80.12980966186524, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.64095950126648, "step": 52000}
{"episode_reward": 832.9752337817257, "episode": 53.0, "batch_reward": 0.3418222620785236, "critic_loss": 2.191588302016258, "actor_loss": -79.5306634979248, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.384784698486328, "step": 53000}
{"episode_reward": 797.9935637608932, "episode": 54.0, "batch_reward": 0.35046026434004307, "critic_loss": 2.130494537651539, "actor_loss": -80.49289570617675, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.908363580703735, "step": 54000}
{"episode_reward": 815.4995500813401, "episode": 55.0, "batch_reward": 0.35863860818743704, "critic_loss": 1.970855687856674, "actor_loss": -80.36266780090332, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.555124044418335, "step": 55000}
{"episode_reward": 884.566349994656, "episode": 56.0, "batch_reward": 0.3697160947918892, "critic_loss": 1.9762573330402373, "actor_loss": -80.16706002807618, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.154125928878784, "step": 56000}
{"episode_reward": 953.5970086514269, "episode": 57.0, "batch_reward": 0.38230929303169253, "critic_loss": 1.8475139850378037, "actor_loss": -80.59876681518554, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.88324475288391, "step": 57000}
{"episode_reward": 911.8407562658615, "episode": 58.0, "batch_reward": 0.38956273755431176, "critic_loss": 1.7417237067222595, "actor_loss": -80.78676574707032, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.843133687973022, "step": 58000}
{"episode_reward": 887.7661784481104, "episode": 59.0, "batch_reward": 0.3969753083884716, "critic_loss": 1.8060940216183663, "actor_loss": -80.85246557617188, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.277877807617188, "step": 59000}
{"episode_reward": 913.3253776531519, "episode": 60.0, "batch_reward": 0.4060651761889458, "critic_loss": 1.7590465349555016, "actor_loss": -81.10166172790527, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.586371183395386, "step": 60000}
{"episode_reward": 856.7753777078622, "episode": 61.0, "batch_reward": 0.4125555687248707, "critic_loss": 1.7803886221647263, "actor_loss": -81.2509234161377, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.89987826347351, "step": 61000}
{"episode_reward": 755.8491354294215, "episode": 62.0, "batch_reward": 0.4191943713128567, "critic_loss": 1.7792660012245178, "actor_loss": -80.96534843444825, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.634888648986816, "step": 62000}
{"episode_reward": 927.3817311447812, "episode": 63.0, "batch_reward": 0.42466236305236815, "critic_loss": 1.7058017620444297, "actor_loss": -80.89927575683593, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.8278169631958, "step": 63000}
{"episode_reward": 853.3821406446004, "episode": 64.0, "batch_reward": 0.4349460926949978, "critic_loss": 1.6755753724575042, "actor_loss": -81.42325846862794, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.801014184951782, "step": 64000}
{"episode_reward": 880.4944619099466, "episode": 65.0, "batch_reward": 0.44151888382434845, "critic_loss": 1.6745118852257728, "actor_loss": -81.12526022338866, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.73079252243042, "step": 65000}
{"episode_reward": 923.3008823920687, "episode": 66.0, "batch_reward": 0.4470477711558342, "critic_loss": 1.6539252618551255, "actor_loss": -81.44392510986329, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.768569707870483, "step": 66000}
{"episode_reward": 892.0003885699379, "episode": 67.0, "batch_reward": 0.4546693920195103, "critic_loss": 1.6019175603985787, "actor_loss": -81.35732981872559, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.0254807472229, "step": 67000}
{"episode_reward": 873.0322674820733, "episode": 68.0, "batch_reward": 0.4610939659178257, "critic_loss": 1.5746853476762772, "actor_loss": -81.95776020812988, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.05245351791382, "step": 68000}
{"episode_reward": 839.6857752440511, "episode": 69.0, "batch_reward": 0.4678822121322155, "critic_loss": 1.6683507817983627, "actor_loss": -81.92512408447266, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.31497836112976, "step": 69000}
{"episode_reward": 902.4054793422811, "episode": 70.0, "batch_reward": 0.4736763628721237, "critic_loss": 1.637198705136776, "actor_loss": -82.46662670898438, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.73495054244995, "step": 70000}
{"episode_reward": 851.4142495041709, "episode": 71.0, "batch_reward": 0.4766628974676132, "critic_loss": 1.5760224585533142, "actor_loss": -81.83307878112792, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.612090826034546, "step": 71000}
{"episode_reward": 899.6660285388417, "episode": 72.0, "batch_reward": 0.48428874239325526, "critic_loss": 1.5920263503193854, "actor_loss": -82.47775650024414, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.745515823364258, "step": 72000}
{"episode_reward": 868.0376370909028, "episode": 73.0, "batch_reward": 0.487736299932003, "critic_loss": 1.5488025751113892, "actor_loss": -82.55611143493653, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.54078984260559, "step": 73000}
{"episode_reward": 888.3001991939566, "episode": 74.0, "batch_reward": 0.49519871339201926, "critic_loss": 1.5441748700141906, "actor_loss": -82.75157106018067, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.06780219078064, "step": 74000}
{"episode_reward": 877.0098206998473, "episode": 75.0, "batch_reward": 0.5021648325324058, "critic_loss": 1.5076653557419777, "actor_loss": -83.00411326599121, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.796530961990356, "step": 75000}
{"episode_reward": 894.4770402978899, "episode": 76.0, "batch_reward": 0.5079132685363292, "critic_loss": 1.5334676904082298, "actor_loss": -83.25392425537109, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.368313312530518, "step": 76000}
{"episode_reward": 930.9603066595297, "episode": 77.0, "batch_reward": 0.5112738963961602, "critic_loss": 1.4102794112563133, "actor_loss": -83.32737579345704, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.670400619506836, "step": 77000}
{"episode_reward": 888.2063554633703, "episode": 78.0, "batch_reward": 0.5148036811053753, "critic_loss": 1.6319341067671775, "actor_loss": -83.05153660583495, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.729398727416992, "step": 78000}
{"episode_reward": 885.2105403616035, "episode": 79.0, "batch_reward": 0.5200773670375347, "critic_loss": 1.4558018139004707, "actor_loss": -83.31001257324219, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.973379135131836, "step": 79000}
{"episode_reward": 929.6933621068092, "episode": 80.0, "batch_reward": 0.525168254584074, "critic_loss": 1.5927387794852257, "actor_loss": -83.40048170471191, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.09296417236328, "step": 80000}
{"episode_reward": 905.3002165331521, "episode": 81.0, "batch_reward": 0.5316713698208332, "critic_loss": 1.822039261341095, "actor_loss": -83.57916688537598, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.12360668182373, "step": 81000}
{"episode_reward": 912.2916348225779, "episode": 82.0, "batch_reward": 0.532794493407011, "critic_loss": 2.6804402747750284, "actor_loss": -83.93350263977051, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.871795892715454, "step": 82000}
{"episode_reward": 899.5000514691679, "episode": 83.0, "batch_reward": 0.5332241750061512, "critic_loss": 3.66520621907711, "actor_loss": -84.84934208679199, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.05516505241394, "step": 83000}
{"episode_reward": 14.418069540140898, "episode": 84.0, "batch_reward": 0.5261690284013748, "critic_loss": 3.5420147656202317, "actor_loss": -85.28906605529785, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.0010986328125, "step": 84000}
{"episode_reward": 15.837513828190232, "episode": 85.0, "batch_reward": 0.5192516729831695, "critic_loss": 3.59481680393219, "actor_loss": -85.35292881774902, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.761982679367065, "step": 85000}
{"episode_reward": 17.813819315142442, "episode": 86.0, "batch_reward": 0.5166946997046471, "critic_loss": 3.039373596251011, "actor_loss": -85.64343589782715, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.38821268081665, "step": 86000}
{"episode_reward": 16.605513061893404, "episode": 87.0, "batch_reward": 0.5144875490665436, "critic_loss": 2.883330586314201, "actor_loss": -85.49971418762208, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.187657117843628, "step": 87000}
{"episode_reward": 870.681747627218, "episode": 88.0, "batch_reward": 0.5205532646477222, "critic_loss": 2.5090661112070083, "actor_loss": -85.57185252380371, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.503801107406616, "step": 88000}
{"episode_reward": 940.9354093987351, "episode": 89.0, "batch_reward": 0.5173543644249439, "critic_loss": 2.3727304818630217, "actor_loss": -85.19881997680665, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.61392855644226, "step": 89000}
{"episode_reward": 14.913028938353484, "episode": 90.0, "batch_reward": 0.5177460803091526, "critic_loss": 2.0958810670375825, "actor_loss": -85.27232418823242, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.043965816497803, "step": 90000}
{"episode_reward": 951.3149959571, "episode": 91.0, "batch_reward": 0.5235368550121784, "critic_loss": 2.007438936114311, "actor_loss": -85.08672499084473, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.106751680374146, "step": 91000}
{"episode_reward": 895.740356433169, "episode": 92.0, "batch_reward": 0.5272785662412643, "critic_loss": 1.8640328803658486, "actor_loss": -84.95717321777343, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.808610916137695, "step": 92000}
{"episode_reward": 891.1001995991419, "episode": 93.0, "batch_reward": 0.5317784640192985, "critic_loss": 1.7902744611501693, "actor_loss": -84.85027758789063, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.941782236099243, "step": 93000}
{"episode_reward": 926.6564983926335, "episode": 94.0, "batch_reward": 0.5361509130299091, "critic_loss": 1.8036386718153954, "actor_loss": -84.90428146362305, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.835609912872314, "step": 94000}
{"episode_reward": 751.0950931206106, "episode": 95.0, "batch_reward": 0.5369772188961506, "critic_loss": 1.7232237063646316, "actor_loss": -84.74386441040039, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.50512933731079, "step": 95000}
{"episode_reward": 783.4362045697743, "episode": 96.0, "batch_reward": 0.5398887712061405, "critic_loss": 1.677401070833206, "actor_loss": -84.39936535644532, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.07119393348694, "step": 96000}
{"episode_reward": 939.8640750792974, "episode": 97.0, "batch_reward": 0.5394626342952251, "critic_loss": 1.9128037750720979, "actor_loss": -84.65345867919922, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.275092124938965, "step": 97000}
{"episode_reward": 26.81238368315105, "episode": 98.0, "batch_reward": 0.5339037024378777, "critic_loss": 2.2672225009202958, "actor_loss": -85.07848597717285, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.557702779769897, "step": 98000}
{"episode_reward": 24.7923184364745, "episode": 99.0, "batch_reward": 0.535444736212492, "critic_loss": 2.617019786119461, "actor_loss": -86.19473072814941, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.820230960845947, "step": 99000}
{"episode_reward": 895.3756200917835, "episode": 100.0, "batch_reward": 0.531862746655941, "critic_loss": 2.938858411550522, "actor_loss": -86.96577697753906, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.65142035484314, "step": 100000}
{"episode_reward": 69.32378858256034, "episode": 101.0, "batch_reward": 0.5326520088016987, "critic_loss": 2.7680865759849547, "actor_loss": -87.43022885131836, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.30468273162842, "step": 101000}
{"episode_reward": 960.6657756009918, "episode": 102.0, "batch_reward": 0.5337310469150544, "critic_loss": 2.958530387699604, "actor_loss": -87.85413041687012, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.65970492362976, "step": 102000}
{"episode_reward": 47.69863533956018, "episode": 103.0, "batch_reward": 0.529228945761919, "critic_loss": 2.932051659822464, "actor_loss": -88.21206631469727, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.04855179786682, "step": 103000}
{"episode_reward": 25.010420899707437, "episode": 104.0, "batch_reward": 0.5218033985793591, "critic_loss": 2.9022784064412117, "actor_loss": -88.1654923400879, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.159575939178467, "step": 104000}
{"episode_reward": 24.796555223189856, "episode": 105.0, "batch_reward": 0.5234088667631149, "critic_loss": 2.607395820915699, "actor_loss": -88.29134338378907, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.962960720062256, "step": 105000}
{"episode_reward": 934.6535289674985, "episode": 106.0, "batch_reward": 0.5242431033849716, "critic_loss": 2.386206840157509, "actor_loss": -88.08926742553712, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.860034227371216, "step": 106000}
{"episode_reward": 858.3797192080058, "episode": 107.0, "batch_reward": 0.5252097975313663, "critic_loss": 2.4114605004787446, "actor_loss": -87.79228239440918, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.5416841506958, "step": 107000}
{"episode_reward": 28.85924992818167, "episode": 108.0, "batch_reward": 0.5217636919021607, "critic_loss": 2.4821521400809288, "actor_loss": -87.73349320983887, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.372729778289795, "step": 108000}
{"episode_reward": 25.85510970941431, "episode": 109.0, "batch_reward": 0.5144448886215687, "critic_loss": 2.1693545058369637, "actor_loss": -87.50609838867187, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.148181438446045, "step": 109000}
{"episode_reward": 32.81000181053985, "episode": 110.0, "batch_reward": 0.5126529670655727, "critic_loss": 2.2063741241693497, "actor_loss": -87.14665773010253, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.526765823364258, "step": 110000}
{"episode_reward": 34.75841458174527, "episode": 111.0, "batch_reward": 0.5116387250423431, "critic_loss": 2.0191037522554396, "actor_loss": -86.65800611877441, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.017528772354126, "step": 111000}
{"episode_reward": 899.7859108983342, "episode": 112.0, "batch_reward": 0.5137538091242313, "critic_loss": 2.090100160598755, "actor_loss": -86.49280068969726, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.870577812194824, "step": 112000}
{"episode_reward": 877.3106537215225, "episode": 113.0, "batch_reward": 0.5182133764028549, "critic_loss": 1.9387933864593505, "actor_loss": -86.03734115600587, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.902976512908936, "step": 113000}
{"episode_reward": 934.0820076875123, "episode": 114.0, "batch_reward": 0.5177583892941475, "critic_loss": 1.836931727707386, "actor_loss": -85.76820541381836, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.54010272026062, "step": 114000}
{"episode_reward": 39.13809390695073, "episode": 115.0, "batch_reward": 0.512870272397995, "critic_loss": 1.8296410563588141, "actor_loss": -85.055411819458, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.274227380752563, "step": 115000}
{"episode_reward": 617.5410533092119, "episode": 116.0, "batch_reward": 0.5167323644459247, "critic_loss": 1.7137127724289893, "actor_loss": -84.824174118042, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.458307027816772, "step": 116000}
{"episode_reward": 357.98928979909493, "episode": 117.0, "batch_reward": 0.510271894812584, "critic_loss": 1.6121222501397132, "actor_loss": -83.89110990905762, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.504820108413696, "step": 117000}
{"episode_reward": 39.803006036652384, "episode": 118.0, "batch_reward": 0.5125626847445964, "critic_loss": 1.6032480506896973, "actor_loss": -83.92628744506835, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.851390838623047, "step": 118000}
{"episode_reward": 41.53778731799445, "episode": 119.0, "batch_reward": 0.509645366102457, "critic_loss": 1.6733649017214776, "actor_loss": -83.70942881774903, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.64548945426941, "step": 119000}
{"episode_reward": 903.4319608717267, "episode": 120.0, "batch_reward": 0.5141299797594547, "critic_loss": 1.9106840280890465, "actor_loss": -83.52812733459473, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.609265565872192, "step": 120000}
{"episode_reward": 903.650134317464, "episode": 121.0, "batch_reward": 0.5114558875858783, "critic_loss": 2.180972063720226, "actor_loss": -83.55573828125, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.75510287284851, "step": 121000}
{"episode_reward": 41.39406553151555, "episode": 122.0, "batch_reward": 0.5113101976215839, "critic_loss": 2.1616061785817147, "actor_loss": -83.99982249450683, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.751588106155396, "step": 122000}
{"episode_reward": 428.9872167165631, "episode": 123.0, "batch_reward": 0.5090780974626541, "critic_loss": 2.0262582063674928, "actor_loss": -84.55548834228516, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.03514790534973, "step": 123000}
{"episode_reward": 919.6163879345752, "episode": 124.0, "batch_reward": 0.5148494848608971, "critic_loss": 1.7862760660648347, "actor_loss": -84.29201521301269, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.530386686325073, "step": 124000}
{"episode_reward": 928.0009991632254, "episode": 125.0, "batch_reward": 0.5140376866459847, "critic_loss": 1.722497320175171, "actor_loss": -84.55506553649903, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.34114146232605, "step": 125000}
{"episode_reward": 57.44334629323321, "episode": 126.0, "batch_reward": 0.5138412080109119, "critic_loss": 1.5835934216976166, "actor_loss": -84.31818298339844, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.600335597991943, "step": 126000}
{"episode_reward": 907.9287247464586, "episode": 127.0, "batch_reward": 0.5171943240165711, "critic_loss": 1.4041048815250396, "actor_loss": -84.61760528564453, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.491519689559937, "step": 127000}
{"episode_reward": 942.8888386385943, "episode": 128.0, "batch_reward": 0.5182165597677231, "critic_loss": 1.3375683596134187, "actor_loss": -84.49854254150391, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.19861888885498, "step": 128000}
{"episode_reward": 839.8678510063369, "episode": 129.0, "batch_reward": 0.5230180893242359, "critic_loss": 1.2503133777379989, "actor_loss": -84.03118618774414, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.785624027252197, "step": 129000}
{"episode_reward": 970.3117438378122, "episode": 130.0, "batch_reward": 0.5263443732261658, "critic_loss": 1.1544975163936615, "actor_loss": -84.10370431518555, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.525185346603394, "step": 130000}
{"episode_reward": 819.1386374907179, "episode": 131.0, "batch_reward": 0.5299263556301593, "critic_loss": 1.1513044533133507, "actor_loss": -84.12249356079101, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.327258586883545, "step": 131000}
{"episode_reward": 900.7733234460688, "episode": 132.0, "batch_reward": 0.5299709644317627, "critic_loss": 1.1528516196608543, "actor_loss": -84.30846603393555, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.12479519844055, "step": 132000}
{"episode_reward": 908.3103396308642, "episode": 133.0, "batch_reward": 0.5354169138073921, "critic_loss": 1.1301959231197833, "actor_loss": -83.63562489318848, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.089856147766113, "step": 133000}
{"episode_reward": 890.7357339057064, "episode": 134.0, "batch_reward": 0.5364917141795158, "critic_loss": 1.1062589260935782, "actor_loss": -83.0855534210205, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.968989372253418, "step": 134000}
{"episode_reward": 896.9271308637519, "episode": 135.0, "batch_reward": 0.5399536873400211, "critic_loss": 1.1225751776397228, "actor_loss": -83.89161614990235, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.821985244750977, "step": 135000}
{"episode_reward": 902.0168046563664, "episode": 136.0, "batch_reward": 0.5412912853956222, "critic_loss": 1.120577195763588, "actor_loss": -82.58641061401367, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.52515935897827, "step": 136000}
{"episode_reward": 896.5719241046966, "episode": 137.0, "batch_reward": 0.5436673934459686, "critic_loss": 1.1647337271571159, "actor_loss": -83.68760055541992, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.159443855285645, "step": 137000}
{"episode_reward": 940.542206782582, "episode": 138.0, "batch_reward": 0.5474200358390808, "critic_loss": 1.1902661990821362, "actor_loss": -83.61940893554687, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.823181867599487, "step": 138000}
{"episode_reward": 961.723009192614, "episode": 139.0, "batch_reward": 0.5499469277262687, "critic_loss": 1.2032573968768119, "actor_loss": -83.637513381958, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.715660095214844, "step": 139000}
{"episode_reward": 888.3189160068603, "episode": 140.0, "batch_reward": 0.5565253058671952, "critic_loss": 1.2332550588846207, "actor_loss": -84.0509705657959, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.83044195175171, "step": 140000}
{"episode_reward": 911.2885308326228, "episode": 141.0, "batch_reward": 0.5541323775649071, "critic_loss": 1.1954941235184668, "actor_loss": -84.1045104675293, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.63215136528015, "step": 141000}
{"episode_reward": 942.3470307794727, "episode": 142.0, "batch_reward": 0.5564958344995975, "critic_loss": 1.1961158158779144, "actor_loss": -83.82349551391601, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.5377037525177, "step": 142000}
{"episode_reward": 879.0574625477639, "episode": 143.0, "batch_reward": 0.5577887414693833, "critic_loss": 1.1210700835585594, "actor_loss": -84.00861750793457, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.374556303024292, "step": 143000}
{"episode_reward": 933.224871869849, "episode": 144.0, "batch_reward": 0.56551506665349, "critic_loss": 1.087134303510189, "actor_loss": -84.73261228942872, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.75730037689209, "step": 144000}
{"episode_reward": 900.452005223037, "episode": 145.0, "batch_reward": 0.5659552309513092, "critic_loss": 1.0431378290653228, "actor_loss": -84.83127897644043, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.591933727264404, "step": 145000}
{"episode_reward": 891.9648138701072, "episode": 146.0, "batch_reward": 0.5657252560257912, "critic_loss": 1.0640641119778156, "actor_loss": -85.0251547241211, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.7323796749115, "step": 146000}
{"episode_reward": 918.5546533364228, "episode": 147.0, "batch_reward": 0.5701319035589695, "critic_loss": 1.0061723231077193, "actor_loss": -84.98875057983399, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.52714228630066, "step": 147000}
{"episode_reward": 891.2462941753136, "episode": 148.0, "batch_reward": 0.572002389639616, "critic_loss": 0.9908139235377311, "actor_loss": -85.01997178649903, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.591942310333252, "step": 148000}
{"episode_reward": 899.6390211587925, "episode": 149.0, "batch_reward": 0.5739922414422035, "critic_loss": 1.0273023729622364, "actor_loss": -84.94668284606934, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.799344301223755, "step": 149000}
{"episode_reward": 928.2648347542624, "episode": 150.0, "batch_reward": 0.5767309406101704, "critic_loss": 1.0030453913807869, "actor_loss": -85.34936540222168, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "step": 150000}
