{"episode_reward": 0.0, "episode": 1.0, "duration": 25.0556697845459, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 2.1084301471710205, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.46015390006452056, "critic_loss": 0.25256400392398554, "actor_loss": -84.01627367560793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 67.69657921791077, "step": 3000}
{"episode_reward": 507.621742761952, "episode": 4.0, "batch_reward": 0.4869869676530361, "critic_loss": 0.6152983472943306, "actor_loss": -84.61651066589356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.92492389678955, "step": 4000}
{"episode_reward": 558.1662948919328, "episode": 5.0, "batch_reward": 0.4904859934747219, "critic_loss": 0.8674981234669685, "actor_loss": -84.27424139404297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.56380295753479, "step": 5000}
{"episode_reward": 520.7789223102124, "episode": 6.0, "batch_reward": 0.5134848634898662, "critic_loss": 1.1039410919547081, "actor_loss": -84.96874154663087, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.913787364959717, "step": 6000}
{"episode_reward": 677.1295106654145, "episode": 7.0, "batch_reward": 0.5423823219239712, "critic_loss": 1.1927966116070747, "actor_loss": -85.5163103942871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.832284927368164, "step": 7000}
{"episode_reward": 636.7293897727812, "episode": 8.0, "batch_reward": 0.5511663355231285, "critic_loss": 1.405338448226452, "actor_loss": -86.06929930114747, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.60016107559204, "step": 8000}
{"episode_reward": 630.2816063795984, "episode": 9.0, "batch_reward": 0.5608091594874859, "critic_loss": 1.544391440987587, "actor_loss": -86.18232891845703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.519546508789062, "step": 9000}
{"episode_reward": 699.5841738291507, "episode": 10.0, "batch_reward": 0.585044348180294, "critic_loss": 1.5396100898981095, "actor_loss": -86.59559246826171, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.816380977630615, "step": 10000}
{"episode_reward": 764.0533371940597, "episode": 11.0, "batch_reward": 0.6020870079398155, "critic_loss": 1.5884600912928581, "actor_loss": -86.99023999023437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.641329526901245, "step": 11000}
{"episode_reward": 819.8745476489975, "episode": 12.0, "batch_reward": 0.6228706468939781, "critic_loss": 1.4935890044569968, "actor_loss": -87.22951521301269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.788268327713013, "step": 12000}
{"episode_reward": 844.5229822924221, "episode": 13.0, "batch_reward": 0.6367340763807297, "critic_loss": 1.5395005087256433, "actor_loss": -87.42932974243163, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.65009117126465, "step": 13000}
{"episode_reward": 804.5476866258522, "episode": 14.0, "batch_reward": 0.648466797709465, "critic_loss": 1.61576639854908, "actor_loss": -87.42253639221191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.586246728897095, "step": 14000}
{"episode_reward": 792.6555154251988, "episode": 15.0, "batch_reward": 0.6631573302745819, "critic_loss": 1.5317126501202583, "actor_loss": -86.95360247802735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.90039086341858, "step": 15000}
{"episode_reward": 889.2446337095662, "episode": 16.0, "batch_reward": 0.6774113669395446, "critic_loss": 1.4995414598584176, "actor_loss": -88.23059925842286, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.964051246643066, "step": 16000}
{"episode_reward": 865.0579773056515, "episode": 17.0, "batch_reward": 0.6841029002666473, "critic_loss": 1.5794738131165504, "actor_loss": -88.05212521362304, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.8631751537323, "step": 17000}
{"episode_reward": 738.5043879056274, "episode": 18.0, "batch_reward": 0.6898660796284676, "critic_loss": 1.6212259526252746, "actor_loss": -88.19810815429688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.771864891052246, "step": 18000}
{"episode_reward": 858.5322552687635, "episode": 19.0, "batch_reward": 0.6990866931676865, "critic_loss": 1.5680814282894135, "actor_loss": -88.36020314025879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.317851305007935, "step": 19000}
{"episode_reward": 867.2331874432037, "episode": 20.0, "batch_reward": 0.7081400455832482, "critic_loss": 1.568597073495388, "actor_loss": -87.88754299926758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.99976944923401, "step": 20000}
{"episode_reward": 837.7832744062277, "episode": 21.0, "batch_reward": 0.7155366066098213, "critic_loss": 1.5779333806037903, "actor_loss": -88.28772331237793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 45.11920189857483, "step": 21000}
{"episode_reward": 889.771492652968, "episode": 22.0, "batch_reward": 0.7249804755449295, "critic_loss": 1.5556358519792557, "actor_loss": -88.42244201660156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.59288191795349, "step": 22000}
{"episode_reward": 845.5732069715566, "episode": 23.0, "batch_reward": 0.7277791677117348, "critic_loss": 1.5928722325563431, "actor_loss": -88.64385299682617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.267436265945435, "step": 23000}
{"episode_reward": 845.2484511104387, "episode": 24.0, "batch_reward": 0.7343960207104683, "critic_loss": 1.5312131308317185, "actor_loss": -88.95046340942383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.521817445755005, "step": 24000}
{"episode_reward": 920.3840098436473, "episode": 25.0, "batch_reward": 0.7416655172705651, "critic_loss": 1.4517191765904427, "actor_loss": -88.9680440826416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.304277658462524, "step": 25000}
{"episode_reward": 913.6435626599352, "episode": 26.0, "batch_reward": 0.749587613761425, "critic_loss": 1.363664013147354, "actor_loss": -89.16611849975585, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.09676194190979, "step": 26000}
{"episode_reward": 947.8382679633263, "episode": 27.0, "batch_reward": 0.7564530410170555, "critic_loss": 1.3445099709033965, "actor_loss": -89.14959225463868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.534061193466187, "step": 27000}
{"episode_reward": 866.6481486955182, "episode": 28.0, "batch_reward": 0.7599121311306953, "critic_loss": 1.2481421367526055, "actor_loss": -89.58822727966309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.646694660186768, "step": 28000}
{"episode_reward": 928.1072196402714, "episode": 29.0, "batch_reward": 0.7661079879999161, "critic_loss": 1.1679298685789108, "actor_loss": -89.40910075378417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.415898323059082, "step": 29000}
{"episode_reward": 927.6614956668742, "episode": 30.0, "batch_reward": 0.7705868902802467, "critic_loss": 1.1861285219192506, "actor_loss": -89.5745892791748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.81695246696472, "step": 30000}
{"episode_reward": 891.8190810300716, "episode": 31.0, "batch_reward": 0.772467908859253, "critic_loss": 1.1701268140673637, "actor_loss": -89.93927311706543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 46.00750684738159, "step": 31000}
{"episode_reward": 829.9021182367998, "episode": 32.0, "batch_reward": 0.7757096724510193, "critic_loss": 1.2200686576962472, "actor_loss": -89.99313511657715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.196625232696533, "step": 32000}
{"episode_reward": 837.3298952934649, "episode": 33.0, "batch_reward": 0.770699063718319, "critic_loss": 1.3068253270983696, "actor_loss": -89.66367951965331, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.60177445411682, "step": 33000}
{"episode_reward": 567.0287571119651, "episode": 34.0, "batch_reward": 0.771396383881569, "critic_loss": 1.3221697697639465, "actor_loss": -90.14832189941406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.61671471595764, "step": 34000}
{"episode_reward": 822.7402211367779, "episode": 35.0, "batch_reward": 0.7746363356113434, "critic_loss": 1.3004103807210923, "actor_loss": -89.77554243469238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.857614755630493, "step": 35000}
{"episode_reward": 941.9979751169498, "episode": 36.0, "batch_reward": 0.7795343925952911, "critic_loss": 1.2784632079601288, "actor_loss": -90.57406317138671, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.75181555747986, "step": 36000}
{"episode_reward": 903.3489843351405, "episode": 37.0, "batch_reward": 0.7835277137160301, "critic_loss": 1.2472459257245063, "actor_loss": -90.33641833496094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.537060499191284, "step": 37000}
{"episode_reward": 898.9390991054688, "episode": 38.0, "batch_reward": 0.7860567386746407, "critic_loss": 1.303353879570961, "actor_loss": -89.9745750579834, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.341250896453857, "step": 38000}
{"episode_reward": 921.5210400053109, "episode": 39.0, "batch_reward": 0.7888929898738861, "critic_loss": 1.3070504505634308, "actor_loss": -90.56336505126953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.262187957763672, "step": 39000}
{"episode_reward": 930.6333720794975, "episode": 40.0, "batch_reward": 0.7915150189995765, "critic_loss": 1.2822405055761337, "actor_loss": -90.68305519104004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.917128562927246, "step": 40000}
{"episode_reward": 926.3359826134056, "episode": 41.0, "batch_reward": 0.7943590987920761, "critic_loss": 1.2413482325673104, "actor_loss": -91.04195538330079, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.40063500404358, "step": 41000}
{"episode_reward": 898.0776129744997, "episode": 42.0, "batch_reward": 0.7978038809299469, "critic_loss": 1.2571327440738678, "actor_loss": -90.76770721435547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.999149322509766, "step": 42000}
{"episode_reward": 938.965818770707, "episode": 43.0, "batch_reward": 0.8040699928998947, "critic_loss": 1.137147928416729, "actor_loss": -91.23987327575684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.345301389694214, "step": 43000}
{"episode_reward": 931.0127955259866, "episode": 44.0, "batch_reward": 0.8043414179086685, "critic_loss": 1.1562335034906863, "actor_loss": -90.99648158264161, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.081332683563232, "step": 44000}
{"episode_reward": 897.5144910492863, "episode": 45.0, "batch_reward": 0.8072244067788124, "critic_loss": 1.1167662985622884, "actor_loss": -91.00215156555176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.884681701660156, "step": 45000}
{"episode_reward": 945.6813878166369, "episode": 46.0, "batch_reward": 0.810214233994484, "critic_loss": 1.0426123563051224, "actor_loss": -91.384487991333, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.99910593032837, "step": 46000}
{"episode_reward": 906.1712442996134, "episode": 47.0, "batch_reward": 0.81268297290802, "critic_loss": 1.0192573243379592, "actor_loss": -91.57559684753419, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.226011753082275, "step": 47000}
{"episode_reward": 919.7461730493114, "episode": 48.0, "batch_reward": 0.8144927505254745, "critic_loss": 1.0431897977292537, "actor_loss": -91.59618817138671, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.189367294311523, "step": 48000}
{"episode_reward": 924.2779892627232, "episode": 49.0, "batch_reward": 0.8175393254160881, "critic_loss": 1.0172560291588306, "actor_loss": -91.77832144165039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.522677659988403, "step": 49000}
{"episode_reward": 931.5503541145017, "episode": 50.0, "batch_reward": 0.8197105299830437, "critic_loss": 1.0179400093853475, "actor_loss": -91.63991773986817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.972402811050415, "step": 50000}
{"episode_reward": 914.6282920545508, "episode": 51.0, "batch_reward": 0.8228490781188011, "critic_loss": 0.9955591804385185, "actor_loss": -91.96892138671875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 45.527260065078735, "step": 51000}
{"episode_reward": 951.3903782914336, "episode": 52.0, "batch_reward": 0.8223280106186867, "critic_loss": 0.9367226751446724, "actor_loss": -92.12008610534669, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.09427785873413, "step": 52000}
{"episode_reward": 922.6799767411068, "episode": 53.0, "batch_reward": 0.8253660027980805, "critic_loss": 0.9297888661921024, "actor_loss": -91.73532521057129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.48959517478943, "step": 53000}
{"episode_reward": 922.4306069050551, "episode": 54.0, "batch_reward": 0.8276318955421448, "critic_loss": 0.9103586679399014, "actor_loss": -92.64685050964356, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.194896936416626, "step": 54000}
{"episode_reward": 915.8443294892986, "episode": 55.0, "batch_reward": 0.8276433554291726, "critic_loss": 0.9002090967595577, "actor_loss": -92.4516358947754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.936686992645264, "step": 55000}
{"episode_reward": 887.3415957946397, "episode": 56.0, "batch_reward": 0.8306469081640243, "critic_loss": 0.8566580616235733, "actor_loss": -92.16015930175782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.239237070083618, "step": 56000}
{"episode_reward": 970.5069940526944, "episode": 57.0, "batch_reward": 0.8323899943232537, "critic_loss": 0.8810301076769829, "actor_loss": -92.55613421630859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.54193425178528, "step": 57000}
{"episode_reward": 939.7696692444906, "episode": 58.0, "batch_reward": 0.8335184500217437, "critic_loss": 0.8455979808568954, "actor_loss": -92.5890798034668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.274360179901123, "step": 58000}
{"episode_reward": 873.3159322232665, "episode": 59.0, "batch_reward": 0.8357274942994117, "critic_loss": 0.8470690908432007, "actor_loss": -92.76240919494629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.39029550552368, "step": 59000}
{"episode_reward": 911.1868795392475, "episode": 60.0, "batch_reward": 0.8368122156262398, "critic_loss": 0.834286147415638, "actor_loss": -92.58674810791015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.813091278076172, "step": 60000}
{"episode_reward": 912.6523991377419, "episode": 61.0, "batch_reward": 0.8373407765626907, "critic_loss": 0.8707873294949532, "actor_loss": -92.84876629638671, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.97062063217163, "step": 61000}
{"episode_reward": 883.6678320423022, "episode": 62.0, "batch_reward": 0.8366013812422752, "critic_loss": 0.891667973548174, "actor_loss": -92.56439793395997, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.38172197341919, "step": 62000}
{"episode_reward": 915.3554298844114, "episode": 63.0, "batch_reward": 0.8375331925749778, "critic_loss": 0.8636380798220634, "actor_loss": -92.72796409606934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.01113224029541, "step": 63000}
{"episode_reward": 883.7334416385921, "episode": 64.0, "batch_reward": 0.8409482028484344, "critic_loss": 0.8607721422016621, "actor_loss": -92.96270492553711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.27228021621704, "step": 64000}
{"episode_reward": 911.2983120156858, "episode": 65.0, "batch_reward": 0.8407810730934143, "critic_loss": 0.8499778750538826, "actor_loss": -92.7298964996338, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.246964931488037, "step": 65000}
{"episode_reward": 933.2822227315723, "episode": 66.0, "batch_reward": 0.8421973447799682, "critic_loss": 0.8778531051576137, "actor_loss": -92.82403594970702, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.870818853378296, "step": 66000}
{"episode_reward": 936.9218318043942, "episode": 67.0, "batch_reward": 0.8442981157302857, "critic_loss": 0.8476695974469185, "actor_loss": -92.83441897583008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.565114736557007, "step": 67000}
{"episode_reward": 929.5887080775994, "episode": 68.0, "batch_reward": 0.8448936628699303, "critic_loss": 0.8479025335609913, "actor_loss": -93.24793174743652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.943742752075195, "step": 68000}
{"episode_reward": 923.4849013897896, "episode": 69.0, "batch_reward": 0.8480833659172058, "critic_loss": 0.8450800840556622, "actor_loss": -93.23470184326172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.426029443740845, "step": 69000}
{"episode_reward": 920.6136919532113, "episode": 70.0, "batch_reward": 0.846635647535324, "critic_loss": 0.818862725943327, "actor_loss": -93.3704210205078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.46582341194153, "step": 70000}
{"episode_reward": 903.4245252708267, "episode": 71.0, "batch_reward": 0.8482133541107177, "critic_loss": 0.7974973758459091, "actor_loss": -92.98839860534667, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 45.234591007232666, "step": 71000}
{"episode_reward": 921.9480689425249, "episode": 72.0, "batch_reward": 0.8486654071807861, "critic_loss": 0.7974466791152954, "actor_loss": -93.32181298828125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.983652591705322, "step": 72000}
{"episode_reward": 880.355948378462, "episode": 73.0, "batch_reward": 0.8493776653409004, "critic_loss": 0.7865950919389725, "actor_loss": -93.3904122619629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.568453073501587, "step": 73000}
{"episode_reward": 946.1956481873373, "episode": 74.0, "batch_reward": 0.8505601621866227, "critic_loss": 0.7819571019113064, "actor_loss": -93.40627320861816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.692851305007935, "step": 74000}
{"episode_reward": 894.1366423579128, "episode": 75.0, "batch_reward": 0.8520545135140419, "critic_loss": 0.7832406624555588, "actor_loss": -93.52607852172852, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.268889904022217, "step": 75000}
{"episode_reward": 947.1162286358899, "episode": 76.0, "batch_reward": 0.8519276448488236, "critic_loss": 0.7712725611031055, "actor_loss": -93.45356448364258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.24212408065796, "step": 76000}
{"episode_reward": 887.8198507275872, "episode": 77.0, "batch_reward": 0.8539330565929413, "critic_loss": 0.756704847663641, "actor_loss": -93.45296176147461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.012097358703613, "step": 77000}
{"episode_reward": 896.0239616520313, "episode": 78.0, "batch_reward": 0.8533279892802238, "critic_loss": 0.7997039930820465, "actor_loss": -93.47541546630859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.036118745803833, "step": 78000}
{"episode_reward": 935.415074895092, "episode": 79.0, "batch_reward": 0.8547360859513283, "critic_loss": 0.7739865404963493, "actor_loss": -93.50311508178712, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.60658025741577, "step": 79000}
{"episode_reward": 907.1438004454405, "episode": 80.0, "batch_reward": 0.8553240533471107, "critic_loss": 0.7863705133497715, "actor_loss": -93.59698696899414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.918071746826172, "step": 80000}
{"episode_reward": 885.0782110277413, "episode": 81.0, "batch_reward": 0.8555904744863511, "critic_loss": 0.7694310026466846, "actor_loss": -93.39840629577637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.99563670158386, "step": 81000}
{"episode_reward": 917.7090211307001, "episode": 82.0, "batch_reward": 0.8545657254457474, "critic_loss": 0.7934414778351784, "actor_loss": -93.48290228271485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.28560161590576, "step": 82000}
{"episode_reward": 939.6185411674124, "episode": 83.0, "batch_reward": 0.85718735820055, "critic_loss": 0.7841148892343044, "actor_loss": -93.7982074432373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.743377447128296, "step": 83000}
{"episode_reward": 932.2784720624948, "episode": 84.0, "batch_reward": 0.857985582947731, "critic_loss": 0.7845876766741275, "actor_loss": -93.87860276794433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.723560333251953, "step": 84000}
{"episode_reward": 899.643848931271, "episode": 85.0, "batch_reward": 0.8582970166802406, "critic_loss": 0.8237908685207367, "actor_loss": -93.58565306091309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.935306787490845, "step": 85000}
{"episode_reward": 921.232041996302, "episode": 86.0, "batch_reward": 0.8588806121349335, "critic_loss": 0.7909882063865662, "actor_loss": -93.696795211792, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.722820281982422, "step": 86000}
{"episode_reward": 943.0319420641591, "episode": 87.0, "batch_reward": 0.8609026386141777, "critic_loss": 0.7883219414055348, "actor_loss": -93.8662230834961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.096174240112305, "step": 87000}
{"episode_reward": 898.323938787464, "episode": 88.0, "batch_reward": 0.8616714658737182, "critic_loss": 0.778663058578968, "actor_loss": -93.94928910827636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.646992206573486, "step": 88000}
{"episode_reward": 938.6157758381062, "episode": 89.0, "batch_reward": 0.8620356498360634, "critic_loss": 0.7801625373363494, "actor_loss": -93.77045248413086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.353405475616455, "step": 89000}
{"episode_reward": 911.1055313893828, "episode": 90.0, "batch_reward": 0.8616170704960823, "critic_loss": 0.8151409540474415, "actor_loss": -93.91236088562012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.95895791053772, "step": 90000}
{"episode_reward": 943.0608025783966, "episode": 91.0, "batch_reward": 0.8630684644579888, "critic_loss": 0.8455021689534188, "actor_loss": -93.80281066894531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 45.65996313095093, "step": 91000}
{"episode_reward": 881.5975606812435, "episode": 92.0, "batch_reward": 0.8646293788552284, "critic_loss": 0.8073416811525822, "actor_loss": -93.98002064514161, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.468773365020752, "step": 92000}
{"episode_reward": 945.2829482658166, "episode": 93.0, "batch_reward": 0.8651914783120155, "critic_loss": 0.800674868017435, "actor_loss": -94.03457273864746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.845303535461426, "step": 93000}
{"episode_reward": 944.3538504640322, "episode": 94.0, "batch_reward": 0.8654987064003944, "critic_loss": 0.8330899884700775, "actor_loss": -94.20730326843261, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.199528217315674, "step": 94000}
{"episode_reward": 878.6511773257964, "episode": 95.0, "batch_reward": 0.8662680681347847, "critic_loss": 0.7992049318552017, "actor_loss": -94.20299713134766, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.42903423309326, "step": 95000}
{"episode_reward": 911.1140901117582, "episode": 96.0, "batch_reward": 0.8652383356690406, "critic_loss": 0.870990726351738, "actor_loss": -94.08883596801758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.076146841049194, "step": 96000}
{"episode_reward": 890.5427581290332, "episode": 97.0, "batch_reward": 0.8658721717000007, "critic_loss": 0.8333024406433105, "actor_loss": -94.06597599792481, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.349375247955322, "step": 97000}
{"episode_reward": 953.9183707839603, "episode": 98.0, "batch_reward": 0.8673171755671502, "critic_loss": 0.8457830847799778, "actor_loss": -94.08091012573242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.27696466445923, "step": 98000}
{"episode_reward": 923.6595994094465, "episode": 99.0, "batch_reward": 0.8679982144236564, "critic_loss": 0.8178147859275341, "actor_loss": -94.14661639404297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.56872057914734, "step": 99000}
{"episode_reward": 930.1139648830114, "episode": 100.0, "batch_reward": 0.8672395757436753, "critic_loss": 0.8654977875053883, "actor_loss": -94.15864068603516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.368988275527954, "step": 100000}
{"episode_reward": 941.5211141830736, "episode": 101.0, "batch_reward": 0.8694087658524513, "critic_loss": 0.8856888607740402, "actor_loss": -94.17142901611328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.917654037475586, "step": 101000}
{"episode_reward": 837.9330455593064, "episode": 102.0, "batch_reward": 0.8690725963711738, "critic_loss": 0.8865866658091545, "actor_loss": -94.35350694274902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.750965356826782, "step": 102000}
{"episode_reward": 958.609353436919, "episode": 103.0, "batch_reward": 0.8696935446858406, "critic_loss": 0.8727975187301635, "actor_loss": -94.14791900634765, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.29524040222168, "step": 103000}
{"episode_reward": 933.6362806244337, "episode": 104.0, "batch_reward": 0.8706326466202736, "critic_loss": 0.8923713132143021, "actor_loss": -94.31284587097169, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.506821870803833, "step": 104000}
{"episode_reward": 936.6109176125609, "episode": 105.0, "batch_reward": 0.8704725931882858, "critic_loss": 0.901613227456808, "actor_loss": -94.08740145874023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.21145987510681, "step": 105000}
{"episode_reward": 957.972393998381, "episode": 106.0, "batch_reward": 0.8718147050142289, "critic_loss": 0.9147002873122692, "actor_loss": -94.43397897338868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.74387550354004, "step": 106000}
{"episode_reward": 829.8561247735649, "episode": 107.0, "batch_reward": 0.8704567314386368, "critic_loss": 0.8967329252064228, "actor_loss": -94.21507447814942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.646996021270752, "step": 107000}
{"episode_reward": 818.1716343471405, "episode": 108.0, "batch_reward": 0.8698697600364685, "critic_loss": 0.8956126392483711, "actor_loss": -94.05092024230957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.787840127944946, "step": 108000}
{"episode_reward": 912.7771698544685, "episode": 109.0, "batch_reward": 0.8704709847569465, "critic_loss": 0.8943875583410263, "actor_loss": -94.31527807617188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.4548180103302, "step": 109000}
{"episode_reward": 934.5675362529508, "episode": 110.0, "batch_reward": 0.8713805039525032, "critic_loss": 0.9036646621525287, "actor_loss": -94.21358088684082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.982940912246704, "step": 110000}
{"episode_reward": 876.5526653358656, "episode": 111.0, "batch_reward": 0.8716701479554176, "critic_loss": 0.8959643075168133, "actor_loss": -94.12142088317871, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.71379899978638, "step": 111000}
{"episode_reward": 934.7381676560027, "episode": 112.0, "batch_reward": 0.8719680822491646, "critic_loss": 0.873259946167469, "actor_loss": -94.37910192871094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.186016082763672, "step": 112000}
{"episode_reward": 915.4143085108477, "episode": 113.0, "batch_reward": 0.873858264029026, "critic_loss": 0.8425813822746276, "actor_loss": -94.3788636932373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.541180849075317, "step": 113000}
{"episode_reward": 960.2586360545451, "episode": 114.0, "batch_reward": 0.8725498732924462, "critic_loss": 0.8546379576027393, "actor_loss": -94.46878199768067, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.646023511886597, "step": 114000}
{"episode_reward": 966.3886541917236, "episode": 115.0, "batch_reward": 0.8739154033660889, "critic_loss": 0.8286354662179947, "actor_loss": -94.37626266479492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.256476402282715, "step": 115000}
{"episode_reward": 923.8873665881922, "episode": 116.0, "batch_reward": 0.8752081590890884, "critic_loss": 0.8769252699315548, "actor_loss": -94.46263949584961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.579418659210205, "step": 116000}
{"episode_reward": 868.3332737825884, "episode": 117.0, "batch_reward": 0.8743794052004814, "critic_loss": 0.8468525329977274, "actor_loss": -94.28383447265625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.68816328048706, "step": 117000}
{"episode_reward": 892.9805737544463, "episode": 118.0, "batch_reward": 0.8748660220503807, "critic_loss": 0.8337754374146461, "actor_loss": -94.39952478027344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.588260173797607, "step": 118000}
{"episode_reward": 942.2801077673114, "episode": 119.0, "batch_reward": 0.8764854111671447, "critic_loss": 0.808681833177805, "actor_loss": -94.49027526855468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.117740392684937, "step": 119000}
{"episode_reward": 953.5538524214095, "episode": 120.0, "batch_reward": 0.8758358965516091, "critic_loss": 0.770482235699892, "actor_loss": -94.39210340881348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.773550510406494, "step": 120000}
{"episode_reward": 886.9038723179642, "episode": 121.0, "batch_reward": 0.8769578040838242, "critic_loss": 0.798941471517086, "actor_loss": -94.40021348571777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.065661668777466, "step": 121000}
{"episode_reward": 956.8293203734327, "episode": 122.0, "batch_reward": 0.8761661316752434, "critic_loss": 0.7559911158680915, "actor_loss": -94.51289186096191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.328591346740723, "step": 122000}
{"episode_reward": 933.271347665744, "episode": 123.0, "batch_reward": 0.8768449128270149, "critic_loss": 0.7320321879982948, "actor_loss": -94.70443379211426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.005665063858032, "step": 123000}
{"episode_reward": 960.3604064999898, "episode": 124.0, "batch_reward": 0.8785640887618065, "critic_loss": 0.7724225457906723, "actor_loss": -94.68506582641602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 25.088720321655273, "step": 124000}
{"episode_reward": 929.5682320642373, "episode": 125.0, "batch_reward": 0.8792103250622749, "critic_loss": 0.7319382944107056, "actor_loss": -94.66613331604005, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.782390356063843, "step": 125000}
{"episode_reward": 932.851229364818, "episode": 126.0, "batch_reward": 0.8804181752800941, "critic_loss": 0.7370873668789863, "actor_loss": -94.56802668762207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.587278127670288, "step": 126000}
{"episode_reward": 972.1328604430724, "episode": 127.0, "batch_reward": 0.8792549164891243, "critic_loss": 0.7406273148953915, "actor_loss": -94.53011351013184, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.209388256072998, "step": 127000}
{"episode_reward": 949.5548747506149, "episode": 128.0, "batch_reward": 0.8762956390380859, "critic_loss": 0.7029823571443558, "actor_loss": -94.54800039672851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.45296597480774, "step": 128000}
{"episode_reward": 151.9279347930616, "episode": 129.0, "batch_reward": 0.8741584852337837, "critic_loss": 0.7203882126510144, "actor_loss": -94.32478092956543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.911792039871216, "step": 129000}
{"episode_reward": 963.6724843191728, "episode": 130.0, "batch_reward": 0.8770558121800422, "critic_loss": 0.7306172413229942, "actor_loss": -94.44858166503906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.985385417938232, "step": 130000}
{"episode_reward": 944.1986305546841, "episode": 131.0, "batch_reward": 0.8749450470805168, "critic_loss": 0.7317895430028438, "actor_loss": -94.39352996826172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.94776010513306, "step": 131000}
{"episode_reward": 920.5783767572885, "episode": 132.0, "batch_reward": 0.8754389528036117, "critic_loss": 0.7700252969264985, "actor_loss": -94.5503494720459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.62136721611023, "step": 132000}
{"episode_reward": 885.6281242042754, "episode": 133.0, "batch_reward": 0.876628409743309, "critic_loss": 0.7765305920243263, "actor_loss": -94.45782699584962, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.069822788238525, "step": 133000}
{"episode_reward": 950.7772052582717, "episode": 134.0, "batch_reward": 0.877148087143898, "critic_loss": 0.7906394842267036, "actor_loss": -94.40130461120606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.42947745323181, "step": 134000}
{"episode_reward": 904.7486293045921, "episode": 135.0, "batch_reward": 0.8777233809232712, "critic_loss": 0.8004956959635019, "actor_loss": -94.47714503479004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.75671935081482, "step": 135000}
{"episode_reward": 926.9619868111498, "episode": 136.0, "batch_reward": 0.8769210920929909, "critic_loss": 0.8067915234267712, "actor_loss": -94.2060288848877, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.258912801742554, "step": 136000}
{"episode_reward": 904.182943313405, "episode": 137.0, "batch_reward": 0.8764458243846893, "critic_loss": 0.7970141926705837, "actor_loss": -94.54343774414062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.37869381904602, "step": 137000}
{"episode_reward": 955.7841027163133, "episode": 138.0, "batch_reward": 0.8788998697400093, "critic_loss": 0.8238593532145023, "actor_loss": -94.63473390197754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.49455165863037, "step": 138000}
{"episode_reward": 939.6735973977005, "episode": 139.0, "batch_reward": 0.8782651752829552, "critic_loss": 0.7715285925120116, "actor_loss": -94.51054649353027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.548680543899536, "step": 139000}
{"episode_reward": 916.2768956447259, "episode": 140.0, "batch_reward": 0.8797428821921348, "critic_loss": 0.728104253128171, "actor_loss": -94.52536492919921, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.510682344436646, "step": 140000}
{"episode_reward": 915.0081798561766, "episode": 141.0, "batch_reward": 0.8768676800131798, "critic_loss": 0.7264424923658371, "actor_loss": -94.47075611877442, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.02983117103577, "step": 141000}
{"episode_reward": 930.3384510795996, "episode": 142.0, "batch_reward": 0.8786127477288246, "critic_loss": 0.7892972274124622, "actor_loss": -94.368172164917, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.810302257537842, "step": 142000}
{"episode_reward": 939.4268568484806, "episode": 143.0, "batch_reward": 0.8796139435768128, "critic_loss": 0.8486124328374862, "actor_loss": -94.48431770324707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.534282445907593, "step": 143000}
{"episode_reward": 906.5189465382024, "episode": 144.0, "batch_reward": 0.8801662493944168, "critic_loss": 0.804222701728344, "actor_loss": -94.53071862792969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.35679030418396, "step": 144000}
{"episode_reward": 914.9122251147172, "episode": 145.0, "batch_reward": 0.8805061559081078, "critic_loss": 0.7633631973564625, "actor_loss": -94.6545902709961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.872151613235474, "step": 145000}
{"episode_reward": 883.8778049744712, "episode": 146.0, "batch_reward": 0.880793964266777, "critic_loss": 0.792507495969534, "actor_loss": -94.68707472229003, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.172838926315308, "step": 146000}
{"episode_reward": 937.4439037169575, "episode": 147.0, "batch_reward": 0.8803514944314956, "critic_loss": 0.7855217753350735, "actor_loss": -94.64517488098144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.600754499435425, "step": 147000}
{"episode_reward": 878.7461634860771, "episode": 148.0, "batch_reward": 0.8798777408003807, "critic_loss": 0.7549517022669315, "actor_loss": -94.68292582702637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.2847797870636, "step": 148000}
{"episode_reward": 880.8568710043443, "episode": 149.0, "batch_reward": 0.8797325881719589, "critic_loss": 0.7379724151492119, "actor_loss": -94.53616850280761, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.44980525970459, "step": 149000}
{"episode_reward": 976.5702563997173, "episode": 150.0, "batch_reward": 0.8801808122992516, "critic_loss": 0.7595148379057646, "actor_loss": -94.5811439666748, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
