{"episode": 1.0, "duration": 20.396036386489868, "episode_reward": 29.08591335645728, "step": 1000}
{"episode": 2.0, "duration": 1.8007915019989014, "episode_reward": 898.6342244091321, "step": 2000}
{"episode": 3.0, "batch_reward": 0.4677963251072234, "critic_loss": 0.28473326210808303, "actor_loss": -83.87395501108158, "actor_target_entropy": -6.0, "alpha_value": 0.002642586817083679, "duration": 77.4577362537384, "episode_reward": 495.1918444943222, "step": 3000}
{"episode": 4.0, "batch_reward": 0.4928814381957054, "critic_loss": 1.4282942682504653, "actor_loss": -86.07328062438965, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 25.446001768112183, "episode_reward": 621.383770827489, "step": 4000}
{"episode": 5.0, "batch_reward": 0.5124142961204052, "critic_loss": 2.045525668442249, "actor_loss": -86.90174285888672, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 25.334155082702637, "episode_reward": 608.2214790339989, "step": 5000}
{"episode": 6.0, "batch_reward": 0.5334502703547478, "critic_loss": 2.8894952137470247, "actor_loss": -87.75608952331542, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 25.135704040527344, "episode_reward": 607.905636702985, "step": 6000}
{"episode": 7.0, "batch_reward": 0.539523768901825, "critic_loss": 4.392588289499283, "actor_loss": -87.9214428100586, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 25.176737546920776, "episode_reward": 514.0933604638726, "step": 7000}
{"episode": 8.0, "batch_reward": 0.5454066725373268, "critic_loss": 4.941250829219818, "actor_loss": -88.25345056152344, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 25.20778179168701, "episode_reward": 652.010613660034, "step": 8000}
{"episode": 9.0, "batch_reward": 0.5502270086705685, "critic_loss": 5.242524621248245, "actor_loss": -88.61311459350586, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.874982357025146, "episode_reward": 419.86234965429674, "step": 9000}
{"episode": 10.0, "batch_reward": 0.5356413378119469, "critic_loss": 5.321692930698394, "actor_loss": -82.83637248229981, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 4149.091877222061, "episode_reward": 402.378751799574, "step": 10000}
{"episode": 11.0, "batch_reward": 0.5289575513899326, "critic_loss": 4.4303763301372525, "actor_loss": -82.78297953796387, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 38.66553330421448, "episode_reward": 571.9770847596087, "step": 11000}
{"episode": 12.0, "batch_reward": 0.5329738800227642, "critic_loss": 3.625806360721588, "actor_loss": -79.80568406677246, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 460.2568883895874, "episode_reward": 617.011477014534, "step": 12000}
{"episode": 13.0, "batch_reward": 0.5289146249294281, "critic_loss": 2.9511485273838045, "actor_loss": -79.85071055603028, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.79962706565857, "episode_reward": 348.5267777147874, "step": 13000}
{"episode": 14.0, "batch_reward": 0.5236876182258129, "critic_loss": 2.4344765458106994, "actor_loss": -77.90199458312988, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 501.6930191516876, "episode_reward": 637.0188021360527, "step": 14000}
{"episode": 15.0, "batch_reward": 0.5170298587679864, "critic_loss": 2.1268507888317107, "actor_loss": -77.69818913269043, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 25.55976176261902, "episode_reward": 139.61095767117837, "step": 15000}
{"episode": 16.0, "batch_reward": 0.5093511281013489, "critic_loss": 1.8347653027176858, "actor_loss": -77.24095132446288, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 457.045578956604, "episode_reward": 701.3003840161858, "step": 16000}
{"episode": 17.0, "batch_reward": 0.516622516900301, "critic_loss": 1.5991013168096542, "actor_loss": -77.69020817565918, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 25.46207904815674, "episode_reward": 612.3212269248196, "step": 17000}
{"episode": 18.0, "batch_reward": 0.5263955558836461, "critic_loss": 1.534097058057785, "actor_loss": -76.7280048828125, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 484.0762577056885, "episode_reward": 686.3523137268212, "step": 18000}
{"episode": 19.0, "batch_reward": 0.5345818740129471, "critic_loss": 1.4213443750739096, "actor_loss": -77.15132844543457, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.62035298347473, "episode_reward": 632.8758822920288, "step": 19000}
{"episode": 20.0, "batch_reward": 0.5383091647624969, "critic_loss": 1.415219135582447, "actor_loss": -77.19071801757812, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 464.9712345600128, "episode_reward": 682.6107041884086, "step": 20000}
{"episode": 21.0, "batch_reward": 0.5501209024488926, "critic_loss": 1.4385181465744972, "actor_loss": -77.66910731506347, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.05674123764038, "episode_reward": 790.9474290160578, "step": 21000}
{"episode": 22.0, "batch_reward": 0.5564804909825325, "critic_loss": 1.4658121195435525, "actor_loss": -77.92372434997559, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 459.0852963924408, "episode_reward": 690.0972225758237, "step": 22000}
{"episode": 23.0, "batch_reward": 0.5582588225603103, "critic_loss": 1.5656973457336425, "actor_loss": -77.96352494812012, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.422593355178833, "episode_reward": 554.6397405334475, "step": 23000}
{"episode": 24.0, "batch_reward": 0.5659895443618298, "critic_loss": 1.7468286232948302, "actor_loss": -78.85592895507813, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 483.76259899139404, "episode_reward": 771.1101048534251, "step": 24000}
{"episode": 25.0, "batch_reward": 0.5713166071474552, "critic_loss": 1.927867386341095, "actor_loss": -79.21566081237793, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.823694705963135, "episode_reward": 688.6636889546812, "step": 25000}
{"episode": 26.0, "batch_reward": 0.5784653514921665, "critic_loss": 2.0635242997407914, "actor_loss": -79.0103084564209, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 454.57084226608276, "episode_reward": 769.4658702989091, "step": 26000}
{"episode": 27.0, "batch_reward": 0.5868425416946411, "critic_loss": 2.1780379855632783, "actor_loss": -79.26888955688477, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.914672136306763, "episode_reward": 803.8877628386139, "step": 27000}
{"episode": 28.0, "batch_reward": 0.5918814162015915, "critic_loss": 2.263430441737175, "actor_loss": -79.55948332214355, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 476.6725654602051, "episode_reward": 705.2519205869852, "step": 28000}
{"episode": 29.0, "batch_reward": 0.5990801944732665, "critic_loss": 2.3856997200250625, "actor_loss": -79.76558921813965, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.262073278427124, "episode_reward": 799.365443964945, "step": 29000}
{"episode": 30.0, "batch_reward": 0.6030696806907654, "critic_loss": 2.516084849238396, "actor_loss": -79.38660725402832, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 429.32189416885376, "episode_reward": 713.9969869863208, "step": 30000}
{"episode": 31.0, "batch_reward": 0.6064118527770043, "critic_loss": 2.569379294514656, "actor_loss": -79.54089276123047, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.03420543670654, "episode_reward": 735.2848679052887, "step": 31000}
{"episode": 32.0, "batch_reward": 0.6116248117089271, "critic_loss": 2.6030413068532945, "actor_loss": -80.37924293518067, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 424.62917733192444, "episode_reward": 723.4086560812129, "step": 32000}
{"episode": 33.0, "batch_reward": 0.6143382303118706, "critic_loss": 2.5730191975831986, "actor_loss": -80.56191116333008, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 25.346874952316284, "episode_reward": 718.2034339749297, "step": 33000}
{"episode": 34.0, "batch_reward": 0.6171573853492737, "critic_loss": 2.6378845674991607, "actor_loss": -80.59669285583496, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 467.1842243671417, "episode_reward": 633.306568919718, "step": 34000}
{"episode": 35.0, "batch_reward": 0.6193609601259231, "critic_loss": 2.6687219063043592, "actor_loss": -80.69673678588867, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 25.173632621765137, "episode_reward": 814.1956990398643, "step": 35000}
{"episode": 36.0, "batch_reward": 0.6246558538079262, "critic_loss": 2.715248549222946, "actor_loss": -80.65851794433594, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 439.6019968986511, "episode_reward": 771.4501971623921, "step": 36000}
{"episode": 37.0, "batch_reward": 0.6287420229315758, "critic_loss": 2.73340311062336, "actor_loss": -80.82284942626953, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.212470769882202, "episode_reward": 745.4366458808759, "step": 37000}
{"episode": 38.0, "batch_reward": 0.6308128085136414, "critic_loss": 2.7610549237728117, "actor_loss": -80.61695051574706, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 464.36903738975525, "episode_reward": 796.6651612404595, "step": 38000}
{"episode": 39.0, "batch_reward": 0.6351306517720222, "critic_loss": 2.8242092331647872, "actor_loss": -80.81215151977538, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.88638973236084, "episode_reward": 660.8429377970805, "step": 39000}
{"episode": 40.0, "batch_reward": 0.6356214584708214, "critic_loss": 2.8160249191522597, "actor_loss": -81.2908618774414, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 458.3838908672333, "episode_reward": 754.2895414948237, "step": 40000}
{"episode": 41.0, "batch_reward": 0.639247633934021, "critic_loss": 2.784320767760277, "actor_loss": -81.37516275024414, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 44.92809557914734, "episode_reward": 751.3878168354223, "step": 41000}
{"episode": 42.0, "batch_reward": 0.6426225746273995, "critic_loss": 2.840303614139557, "actor_loss": -81.39633995056153, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 470.36803126335144, "episode_reward": 853.2216673343139, "step": 42000}
{"episode": 43.0, "batch_reward": 0.6461011363267899, "critic_loss": 2.9242429620027544, "actor_loss": -81.43895433044433, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.315228700637817, "episode_reward": 821.0545772124117, "step": 43000}
{"episode": 44.0, "batch_reward": 0.6512478370666503, "critic_loss": 2.828796849370003, "actor_loss": -81.24649780273438, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 490.9539363384247, "episode_reward": 812.8150302587169, "step": 44000}
{"episode": 45.0, "batch_reward": 0.6521191756129265, "critic_loss": 2.9608089799880983, "actor_loss": -81.31756184387207, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.312830448150635, "episode_reward": 679.8053465043636, "step": 45000}
{"episode": 46.0, "batch_reward": 0.6561958206892013, "critic_loss": 2.8908811750411987, "actor_loss": -81.07128721618652, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 416.38237953186035, "episode_reward": 830.6188416383651, "step": 46000}
{"episode": 47.0, "batch_reward": 0.6586086947917938, "critic_loss": 2.6899313491582872, "actor_loss": -81.17018435668945, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.25377058982849, "episode_reward": 821.3323641665603, "step": 47000}
{"episode": 48.0, "batch_reward": 0.6621282836198806, "critic_loss": 2.6667936762571336, "actor_loss": -81.43418296813965, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 460.32152104377747, "episode_reward": 817.2598703941873, "step": 48000}
{"episode": 49.0, "batch_reward": 0.6650982909798622, "critic_loss": 2.694734768629074, "actor_loss": -81.51292333984375, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.8455810546875, "episode_reward": 726.6421599638948, "step": 49000}
{"episode": 50.0, "batch_reward": 0.667504098713398, "critic_loss": 2.8191255630254743, "actor_loss": -81.69180096435547, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 483.8488600254059, "episode_reward": 790.160931905254, "step": 50000}
{"episode": 51.0, "batch_reward": 0.6689632326960564, "critic_loss": 2.709747771501541, "actor_loss": -81.78927345275879, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.067949056625366, "episode_reward": 782.6981680508546, "step": 51000}
{"episode": 52.0, "batch_reward": 0.6709558089971542, "critic_loss": 2.587000373840332, "actor_loss": -81.33067007446289, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 456.95106959342957, "episode_reward": 743.7481634203732, "step": 52000}
{"episode": 53.0, "batch_reward": 0.6727979446053505, "critic_loss": 2.6200110006332396, "actor_loss": -81.3544917755127, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.79551076889038, "episode_reward": 767.6014041112014, "step": 53000}
{"episode": 54.0, "batch_reward": 0.6723430654406548, "critic_loss": 2.695426195383072, "actor_loss": -80.57333404541015, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 438.4822585582733, "episode_reward": 720.0320973273493, "step": 54000}
{"episode": 55.0, "batch_reward": 0.6739334930181503, "critic_loss": 2.6422379528284075, "actor_loss": -80.63700485229492, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.39508295059204, "episode_reward": 835.676144481093, "step": 55000}
{"episode": 56.0, "batch_reward": 0.6770623866915703, "critic_loss": 2.779502994298935, "actor_loss": -80.54715869140625, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 473.9322578907013, "episode_reward": 825.5468422418172, "step": 56000}
{"episode": 57.0, "batch_reward": 0.6805119618177414, "critic_loss": 2.8163447312116623, "actor_loss": -80.72649114990234, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.219748973846436, "episode_reward": 795.3196354640498, "step": 57000}
{"episode": 58.0, "batch_reward": 0.6831506232023239, "critic_loss": 2.742190671443939, "actor_loss": -80.34394174194335, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 460.2774622440338, "episode_reward": 871.1461176601966, "step": 58000}
{"episode": 59.0, "batch_reward": 0.6876482526659966, "critic_loss": 2.6472598284482958, "actor_loss": -80.524046875, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.746013641357422, "episode_reward": 819.0370797484155, "step": 59000}
{"episode": 60.0, "batch_reward": 0.6889292233586312, "critic_loss": 2.6228652271032336, "actor_loss": -80.57920050048828, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 413.8134229183197, "episode_reward": 759.5759075096202, "step": 60000}
{"episode": 61.0, "batch_reward": 0.6893294041752815, "critic_loss": 2.664955795288086, "actor_loss": -80.58703092956543, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 38.43959856033325, "episode_reward": 863.5483849979884, "step": 61000}
{"episode": 62.0, "batch_reward": 0.6926180233359337, "critic_loss": 2.601443668246269, "actor_loss": -80.47896789550781, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 480.5728726387024, "episode_reward": 885.4587086011207, "step": 62000}
{"episode": 63.0, "batch_reward": 0.6967813500165939, "critic_loss": 2.5428565284013747, "actor_loss": -80.64162289428711, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.93184733390808, "episode_reward": 895.2390575523252, "step": 63000}
{"episode": 64.0, "batch_reward": 0.6991793808937072, "critic_loss": 2.5481645916700364, "actor_loss": -80.68160942077637, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 437.6585030555725, "episode_reward": 765.6801910829862, "step": 64000}
{"episode": 65.0, "batch_reward": 0.6996000173091889, "critic_loss": 2.6427307161092757, "actor_loss": -80.68390045166015, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.003212213516235, "episode_reward": 847.556124227496, "step": 65000}
{"episode": 66.0, "batch_reward": 0.7032613587379456, "critic_loss": 2.701913819909096, "actor_loss": -81.00965484619141, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 495.70692443847656, "episode_reward": 844.8901387585024, "step": 66000}
{"episode": 67.0, "batch_reward": 0.7048642898797989, "critic_loss": 2.8199309078454973, "actor_loss": -81.03456968688965, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 25.507763862609863, "episode_reward": 788.7934151906304, "step": 67000}
{"episode": 68.0, "batch_reward": 0.7051085649132729, "critic_loss": 2.9042213871479032, "actor_loss": -81.18560963439941, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 443.53489542007446, "episode_reward": 721.4368219092163, "step": 68000}
{"episode": 69.0, "batch_reward": 0.7059841621518135, "critic_loss": 2.8442154928445817, "actor_loss": -81.22158647155761, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.76005244255066, "episode_reward": 851.0098218794997, "step": 69000}
{"episode": 70.0, "batch_reward": 0.7078861454129219, "critic_loss": 2.7545657477378844, "actor_loss": -80.82408549499512, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 484.8869318962097, "episode_reward": 839.5737397627788, "step": 70000}
{"episode": 71.0, "batch_reward": 0.7103033636808396, "critic_loss": 2.7266914603710175, "actor_loss": -80.94848968505859, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 39.321008920669556, "episode_reward": 861.2195445197673, "step": 71000}
{"episode": 72.0, "batch_reward": 0.7103829863667488, "critic_loss": 2.70463883626461, "actor_loss": -81.21494355773926, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 481.34930300712585, "episode_reward": 847.0702121080309, "step": 72000}
{"episode": 73.0, "batch_reward": 0.7153484659194946, "critic_loss": 2.725388922929764, "actor_loss": -81.36541723632813, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 25.29639482498169, "episode_reward": 869.0596419765577, "step": 73000}
{"episode": 74.0, "batch_reward": 0.7166255635619163, "critic_loss": 2.7103307334184645, "actor_loss": -81.25137425231934, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 387.51145792007446, "episode_reward": 825.4721225861391, "step": 74000}
{"episode": 75.0, "batch_reward": 0.7179510362744331, "critic_loss": 2.739393258213997, "actor_loss": -81.29167378234864, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.961942672729492, "episode_reward": 781.6050154640922, "step": 75000}
{"episode": 76.0, "batch_reward": 0.7185674360990524, "critic_loss": 2.7795498653650283, "actor_loss": -81.105453414917, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 425.91058588027954, "episode_reward": 763.38500968086, "step": 76000}
{"episode": 77.0, "batch_reward": 0.7195175427794457, "critic_loss": 2.9467945305109025, "actor_loss": -81.1342877960205, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.814478874206543, "episode_reward": 797.9962228817897, "step": 77000}
{"episode": 78.0, "batch_reward": 0.7195285757184029, "critic_loss": 2.9865431936979294, "actor_loss": -79.76371025085449, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 442.09672951698303, "episode_reward": 822.917704214686, "step": 78000}
{"episode": 79.0, "batch_reward": 0.7200800483822822, "critic_loss": 3.041002585053444, "actor_loss": -79.83370608520508, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.20069909095764, "episode_reward": 810.4871138164906, "step": 79000}
{"episode": 80.0, "batch_reward": 0.7232722316384316, "critic_loss": 3.0645171813964844, "actor_loss": -79.1416664428711, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 473.1616232395172, "episode_reward": 784.5733218674808, "step": 80000}
{"episode": 81.0, "batch_reward": 0.7233805250525475, "critic_loss": 3.2146136757135393, "actor_loss": -79.20028958129883, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 38.5710289478302, "episode_reward": 758.1381990512632, "step": 81000}
{"episode": 82.0, "batch_reward": 0.7226945909261704, "critic_loss": 3.411119879722595, "actor_loss": -78.14925259399413, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 413.21705317497253, "episode_reward": 751.2077793052533, "step": 82000}
{"episode": 83.0, "batch_reward": 0.7220976367592812, "critic_loss": 3.6885721751451492, "actor_loss": -78.12538459777832, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.814523458480835, "episode_reward": 613.7016483021004, "step": 83000}
{"episode": 84.0, "batch_reward": 0.7221171723604203, "critic_loss": 3.7938584349155424, "actor_loss": -77.78548413085937, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 446.82296323776245, "episode_reward": 478.14009799629764, "step": 84000}
{"episode": 85.0, "batch_reward": 0.7185314753651619, "critic_loss": 3.933278191804886, "actor_loss": -77.73899649047851, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.504493236541748, "episode_reward": 727.3315728148973, "step": 85000}
{"episode": 86.0, "batch_reward": 0.7187320429682732, "critic_loss": 4.104981551647186, "actor_loss": -77.08915487670899, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 446.19521856307983, "episode_reward": 723.1840516007115, "step": 86000}
{"episode": 87.0, "batch_reward": 0.7194336782693863, "critic_loss": 4.174281210660935, "actor_loss": -77.23302857971191, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.919861793518066, "episode_reward": 658.3727732163667, "step": 87000}
{"episode": 88.0, "batch_reward": 0.7194473111033439, "critic_loss": 4.333845257043839, "actor_loss": -77.40345867919922, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 458.9509930610657, "episode_reward": 791.3582376508763, "step": 88000}
{"episode": 89.0, "batch_reward": 0.7211699002981186, "critic_loss": 4.263791197061539, "actor_loss": -77.48368704223633, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.485065698623657, "episode_reward": 818.1225407838813, "step": 89000}
{"episode": 90.0, "batch_reward": 0.7216675497889519, "critic_loss": 4.38240344619751, "actor_loss": -77.42439051818847, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 452.31016993522644, "episode_reward": 805.7491200218486, "step": 90000}
{"episode": 91.0, "batch_reward": 0.7227958415150643, "critic_loss": 4.4265753586292265, "actor_loss": -77.51239494323731, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.41599202156067, "episode_reward": 789.1750410384308, "step": 91000}
{"episode": 92.0, "batch_reward": 0.7233995967507363, "critic_loss": 4.333373361349106, "actor_loss": -78.05177996826171, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 437.71956181526184, "episode_reward": 866.9328522892806, "step": 92000}
{"episode": 93.0, "batch_reward": 0.7244998234510421, "critic_loss": 4.278835630655289, "actor_loss": -78.03055917358398, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.668370008468628, "episode_reward": 865.7611053324224, "step": 93000}
{"episode": 94.0, "batch_reward": 0.7259079046845436, "critic_loss": 4.266812586545944, "actor_loss": -78.3952554321289, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 442.72934675216675, "episode_reward": 881.9656893080111, "step": 94000}
{"episode": 95.0, "batch_reward": 0.7288880199790001, "critic_loss": 4.231854876518249, "actor_loss": -78.51304330444336, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.81422185897827, "episode_reward": 854.2415625262121, "step": 95000}
{"episode": 96.0, "batch_reward": 0.7293156914114952, "critic_loss": 4.3208236398696895, "actor_loss": -78.34872747802734, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 414.81608986854553, "episode_reward": 898.1433182092826, "step": 96000}
{"episode": 97.0, "batch_reward": 0.7299188482761383, "critic_loss": 4.434902545213699, "actor_loss": -78.44749241638183, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.319451332092285, "episode_reward": 860.2894374966156, "step": 97000}
{"episode": 98.0, "batch_reward": 0.7309766888022423, "critic_loss": 4.624364862203598, "actor_loss": -78.83226776123047, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 438.61589193344116, "episode_reward": 873.6903875053728, "step": 98000}
{"episode": 99.0, "batch_reward": 0.7332138696908951, "critic_loss": 4.946592154741287, "actor_loss": -78.94887965393066, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.10962414741516, "episode_reward": 835.1129910262365, "step": 99000}
{"episode": 100.0, "batch_reward": 0.7352923642992973, "critic_loss": 5.020988865613937, "actor_loss": -79.12824047851562, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 455.0726137161255, "episode_reward": 934.5781135617112, "step": 100000}
{"episode": 101.0, "batch_reward": 0.7376248260736465, "critic_loss": 5.457367940664291, "actor_loss": -79.19824562072753, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.09912419319153, "episode_reward": 914.2671711367134, "step": 101000}
{"episode": 102.0, "batch_reward": 0.7383972818851471, "critic_loss": 5.537894224405289, "actor_loss": -79.19704211425781, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 446.64443731307983, "episode_reward": 897.3052978920814, "step": 102000}
{"episode": 103.0, "batch_reward": 0.738344553887844, "critic_loss": 5.592880824327469, "actor_loss": -79.15540492248535, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.176676273345947, "episode_reward": 860.1021926484262, "step": 103000}
{"episode": 104.0, "batch_reward": 0.7413574994802475, "critic_loss": 5.514536010980606, "actor_loss": -80.24643058776856, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 421.87639236450195, "episode_reward": 897.5560189253483, "step": 104000}
{"episode": 105.0, "batch_reward": 0.7429018111228943, "critic_loss": 5.50675057387352, "actor_loss": -80.20771818542481, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 25.442562580108643, "episode_reward": 751.2442855475837, "step": 105000}
{"episode": 106.0, "batch_reward": 0.743051419198513, "critic_loss": 5.413059901952743, "actor_loss": -80.22104692077637, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 475.87382650375366, "episode_reward": 815.799815569221, "step": 106000}
{"episode": 107.0, "batch_reward": 0.743426912009716, "critic_loss": 5.3420352487564084, "actor_loss": -80.27476672363281, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 25.087764978408813, "episode_reward": 802.3972461297953, "step": 107000}
{"episode": 108.0, "batch_reward": 0.7439080956578255, "critic_loss": 5.373088946580887, "actor_loss": -80.59184829711914, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 464.32627868652344, "episode_reward": 863.9920676703756, "step": 108000}
{"episode": 109.0, "batch_reward": 0.7453462200164795, "critic_loss": 5.1719676325321196, "actor_loss": -80.70575476074218, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.629324674606323, "episode_reward": 900.8292908846006, "step": 109000}
{"episode": 110.0, "batch_reward": 0.7466790019273758, "critic_loss": 5.236924973726272, "actor_loss": -80.96515432739258, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 470.0726399421692, "episode_reward": 832.6635087552723, "step": 110000}
{"episode": 111.0, "batch_reward": 0.7459208738803863, "critic_loss": 5.234874143838883, "actor_loss": -80.98321687316894, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 45.234689474105835, "episode_reward": 803.0219404514081, "step": 111000}
{"episode": 112.0, "batch_reward": 0.7480600726008415, "critic_loss": 5.261609752416611, "actor_loss": -81.38343450927735, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 478.90348076820374, "episode_reward": 883.9415611987895, "step": 112000}
{"episode": 113.0, "batch_reward": 0.7487181597948074, "critic_loss": 5.317453951358795, "actor_loss": -81.40742449951172, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.698874473571777, "episode_reward": 853.9510026435103, "step": 113000}
{"episode": 114.0, "batch_reward": 0.7494823173880577, "critic_loss": 5.239303674221039, "actor_loss": -81.18081971740723, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 441.5931532382965, "episode_reward": 834.8911004405093, "step": 114000}
{"episode": 115.0, "batch_reward": 0.7503904322385788, "critic_loss": 5.224574027538299, "actor_loss": -81.26962156677246, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.680834770202637, "episode_reward": 918.2038406356478, "step": 115000}
{"episode": 116.0, "batch_reward": 0.7524865783452988, "critic_loss": 4.929937643051147, "actor_loss": -81.50738609313964, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 485.4618926048279, "episode_reward": 848.5017180186865, "step": 116000}
{"episode": 117.0, "batch_reward": 0.7530389773845673, "critic_loss": 4.908749003171921, "actor_loss": -81.58009938049317, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.821146726608276, "episode_reward": 801.8897651474905, "step": 117000}
{"episode": 118.0, "batch_reward": 0.7536681419610978, "critic_loss": 4.986048478364944, "actor_loss": -80.98152684020997, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 438.4925220012665, "episode_reward": 885.8069011125999, "step": 118000}
{"episode": 119.0, "batch_reward": 0.7545019934177398, "critic_loss": 5.133989006757736, "actor_loss": -81.09524742126465, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.273475408554077, "episode_reward": 895.6427085118606, "step": 119000}
{"episode": 120.0, "batch_reward": 0.755755143225193, "critic_loss": 5.270059538125992, "actor_loss": -80.6749641571045, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 461.55519938468933, "episode_reward": 877.7274826911977, "step": 120000}
{"episode": 121.0, "batch_reward": 0.7567335628867149, "critic_loss": 5.335432903289795, "actor_loss": -80.71942301940918, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.12986421585083, "episode_reward": 854.989961365307, "step": 121000}
{"episode": 122.0, "batch_reward": 0.7567144425511361, "critic_loss": 5.609894317388535, "actor_loss": -80.13464447021484, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 446.25245666503906, "episode_reward": 856.8881768023538, "step": 122000}
{"episode": 123.0, "batch_reward": 0.7582254756093025, "critic_loss": 5.426579813957215, "actor_loss": -80.14846730041504, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.98540472984314, "episode_reward": 902.570576326412, "step": 123000}
{"episode": 124.0, "batch_reward": 0.7588342301249504, "critic_loss": 5.236171033382416, "actor_loss": -79.67018719482422, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 466.79235649108887, "episode_reward": 879.6098850171204, "step": 124000}
{"episode": 125.0, "batch_reward": 0.7604871135950089, "critic_loss": 5.070264871120453, "actor_loss": -79.76276481628418, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.900864839553833, "episode_reward": 865.7661268007787, "step": 125000}
{"episode": 126.0, "batch_reward": 0.7606569105386733, "critic_loss": 4.685665640830994, "actor_loss": -78.96391534423829, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 446.6201629638672, "episode_reward": 822.45187444516, "step": 126000}
{"episode": 127.0, "batch_reward": 0.7630202837586403, "critic_loss": 4.513156189918518, "actor_loss": -79.02878132629395, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.46759057044983, "episode_reward": 918.9041299126308, "step": 127000}
{"episode": 128.0, "batch_reward": 0.7615637901425362, "critic_loss": 4.462243280410767, "actor_loss": -78.85882588195801, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 452.2110059261322, "episode_reward": 923.9914849813061, "step": 128000}
{"episode": 129.0, "batch_reward": 0.764933198094368, "critic_loss": 4.53464501953125, "actor_loss": -78.95864448547363, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.267172813415527, "episode_reward": 944.5440668514916, "step": 129000}
{"episode": 130.0, "batch_reward": 0.763324484705925, "critic_loss": 4.65019995379448, "actor_loss": -78.72030444335938, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 440.7868733406067, "episode_reward": 772.2378501695382, "step": 130000}
{"episode": 131.0, "batch_reward": 0.764788221359253, "critic_loss": 4.494491255283355, "actor_loss": -78.80341162109374, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 39.29021072387695, "episode_reward": 903.4875891381611, "step": 131000}
{"episode": 132.0, "batch_reward": 0.7678663420081139, "critic_loss": 4.332031123638153, "actor_loss": -78.77503221130371, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 453.17330288887024, "episode_reward": 879.2921283904246, "step": 132000}
{"episode": 133.0, "batch_reward": 0.7680523327589035, "critic_loss": 4.272582089543342, "actor_loss": -78.81797026062011, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.159385204315186, "episode_reward": 918.4454356660494, "step": 133000}
{"episode": 134.0, "batch_reward": 0.7699002860188484, "critic_loss": 4.329408633112908, "actor_loss": -78.41405326843261, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 439.03640961647034, "episode_reward": 901.6303003621417, "step": 134000}
{"episode": 135.0, "batch_reward": 0.7697429786324501, "critic_loss": 4.213665000677109, "actor_loss": -78.39898356628417, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.182793617248535, "episode_reward": 888.6192766216782, "step": 135000}
{"episode": 136.0, "batch_reward": 0.7703800077438354, "critic_loss": 3.9486096094846728, "actor_loss": -77.76182472229004, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 482.6722905635834, "episode_reward": 930.6624935833881, "step": 136000}
{"episode": 137.0, "batch_reward": 0.7715344504117966, "critic_loss": 3.8058558275699617, "actor_loss": -77.81874650573731, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.312671899795532, "episode_reward": 922.3028608498136, "step": 137000}
{"episode": 138.0, "batch_reward": 0.7734337267875672, "critic_loss": 3.818742594718933, "actor_loss": -77.95830557250977, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 486.8582549095154, "episode_reward": 930.2404766525673, "step": 138000}
{"episode": 139.0, "batch_reward": 0.7733364531993866, "critic_loss": 3.8447969468832017, "actor_loss": -77.98383377075196, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 25.369932174682617, "episode_reward": 887.4856752149853, "step": 139000}
{"episode": 140.0, "batch_reward": 0.7760701920986176, "critic_loss": 3.7002034335136416, "actor_loss": -77.88584620666504, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 503.0633637905121, "episode_reward": 940.7776926241255, "step": 140000}
{"episode": 141.0, "batch_reward": 0.7749103274941445, "critic_loss": 3.5916593073606493, "actor_loss": -77.91793524169921, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 39.85283279418945, "episode_reward": 910.9107667717085, "step": 141000}
{"episode": 142.0, "batch_reward": 0.777538294672966, "critic_loss": 3.5154739435911178, "actor_loss": -78.46475566101074, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 450.5915267467499, "episode_reward": 903.0867545871073, "step": 142000}
{"episode": 143.0, "batch_reward": 0.7771466777324677, "critic_loss": 3.4366977039575577, "actor_loss": -78.47683828735352, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 25.58517289161682, "episode_reward": 886.723079516843, "step": 143000}
{"episode": 144.0, "batch_reward": 0.7776344019174576, "critic_loss": 3.2225629736185075, "actor_loss": -78.78061250305176, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 500.59837675094604, "episode_reward": 891.5477043193738, "step": 144000}
{"episode": 145.0, "batch_reward": 0.7789642099738121, "critic_loss": 3.2136390278339384, "actor_loss": -78.8603882598877, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 25.219415187835693, "episode_reward": 936.5234702272952, "step": 145000}
{"episode": 146.0, "batch_reward": 0.7805631366372109, "critic_loss": 3.08516994702816, "actor_loss": -79.01636198425292, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 482.41343665122986, "episode_reward": 884.8917712556291, "step": 146000}
{"episode": 147.0, "batch_reward": 0.7822304546236992, "critic_loss": 3.0821056767702104, "actor_loss": -79.0988141784668, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.828354358673096, "episode_reward": 902.023146115769, "step": 147000}
{"episode": 148.0, "batch_reward": 0.7823153086304665, "critic_loss": 3.1963518077135085, "actor_loss": -79.66363125610351, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 488.04191875457764, "episode_reward": 891.0154167490358, "step": 148000}
{"episode": 149.0, "batch_reward": 0.7832074387073517, "critic_loss": 3.180914289355278, "actor_loss": -79.7564465637207, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 25.144561052322388, "episode_reward": 938.0053295054475, "step": 149000}
{"episode": 150.0, "batch_reward": 0.7851277135014534, "critic_loss": 3.1702941015958785, "actor_loss": -80.51409523010254, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "step": 150000}
