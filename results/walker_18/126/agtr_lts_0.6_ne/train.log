{"episode_reward": 0.0, "episode": 1.0, "duration": 22.262156009674072, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.9219903945922852, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.472232535873981, "critic_loss": 0.15865707867252465, "actor_loss": -83.8766940644666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 69.21811842918396, "step": 3000}
{"episode_reward": 631.7950694098705, "episode": 4.0, "batch_reward": 0.5484412430822849, "critic_loss": 0.3736567882746458, "actor_loss": -86.53772442626953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.138073205947876, "step": 4000}
{"episode_reward": 771.5810380263719, "episode": 5.0, "batch_reward": 0.5837360323965549, "critic_loss": 0.49387429681420325, "actor_loss": -87.83409135437012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.0496883392334, "step": 5000}
{"episode_reward": 667.6279082919517, "episode": 6.0, "batch_reward": 0.613871341586113, "critic_loss": 0.5001996361613273, "actor_loss": -88.58271383666992, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.610668420791626, "step": 6000}
{"episode_reward": 780.6182506416899, "episode": 7.0, "batch_reward": 0.6358271992206573, "critic_loss": 0.5132673316299915, "actor_loss": -89.36620922851563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.24527883529663, "step": 7000}
{"episode_reward": 720.9250628554414, "episode": 8.0, "batch_reward": 0.6288833372592926, "critic_loss": 0.6087592074871063, "actor_loss": -89.29215115356445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.251030921936035, "step": 8000}
{"episode_reward": 282.87421539994244, "episode": 9.0, "batch_reward": 0.6092833553254604, "critic_loss": 0.638196382522583, "actor_loss": -88.74197769165039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.22327971458435, "step": 9000}
{"episode_reward": 807.1428902444735, "episode": 10.0, "batch_reward": 0.6291390066742897, "critic_loss": 0.6993050353825092, "actor_loss": -89.25564976501465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.225066423416138, "step": 10000}
{"episode_reward": 804.8696925190534, "episode": 11.0, "batch_reward": 0.6477720338106155, "critic_loss": 0.7964573817849159, "actor_loss": -89.62683457946777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.01122283935547, "step": 11000}
{"episode_reward": 800.9539864626656, "episode": 12.0, "batch_reward": 0.659830653309822, "critic_loss": 0.7956143776774407, "actor_loss": -89.88025622558594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.202685832977295, "step": 12000}
{"episode_reward": 839.7742596552637, "episode": 13.0, "batch_reward": 0.6758965005278588, "critic_loss": 0.7910196481347084, "actor_loss": -90.14072245788574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.24232268333435, "step": 13000}
{"episode_reward": 890.0883999005616, "episode": 14.0, "batch_reward": 0.6914976745247841, "critic_loss": 0.7569457215964794, "actor_loss": -90.49756285095215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.276012659072876, "step": 14000}
{"episode_reward": 895.6045046814261, "episode": 15.0, "batch_reward": 0.7032149528861046, "critic_loss": 0.6574281859397888, "actor_loss": -90.63127597045899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.26598811149597, "step": 15000}
{"episode_reward": 832.4988136506253, "episode": 16.0, "batch_reward": 0.7145150889158249, "critic_loss": 0.5941538406908512, "actor_loss": -91.19002877807617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.264558792114258, "step": 16000}
{"episode_reward": 913.0467575122647, "episode": 17.0, "batch_reward": 0.7274790422916413, "critic_loss": 0.5097059962451458, "actor_loss": -91.42180726623535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.18653154373169, "step": 17000}
{"episode_reward": 920.947061330615, "episode": 18.0, "batch_reward": 0.7396910687685013, "critic_loss": 0.469573925152421, "actor_loss": -91.66688606262207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.256008863449097, "step": 18000}
{"episode_reward": 918.7133399494775, "episode": 19.0, "batch_reward": 0.7438403732180595, "critic_loss": 0.47039262402057647, "actor_loss": -91.74905862426758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.268498182296753, "step": 19000}
{"episode_reward": 845.459056087903, "episode": 20.0, "batch_reward": 0.7518724340200424, "critic_loss": 0.4623808155059814, "actor_loss": -91.61116098022461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.187811613082886, "step": 20000}
{"episode_reward": 886.3217335737029, "episode": 21.0, "batch_reward": 0.758958509862423, "critic_loss": 0.4933264561891556, "actor_loss": -91.84488548278809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.04794692993164, "step": 21000}
{"episode_reward": 875.2833283604971, "episode": 22.0, "batch_reward": 0.7640971364974976, "critic_loss": 0.585771147787571, "actor_loss": -91.79596479797364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.18551254272461, "step": 22000}
{"episode_reward": 809.2528989805411, "episode": 23.0, "batch_reward": 0.7655893057584763, "critic_loss": 0.5656026462614536, "actor_loss": -91.77071640014648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.20420527458191, "step": 23000}
{"episode_reward": 912.6758058633264, "episode": 24.0, "batch_reward": 0.7735950067639351, "critic_loss": 0.5201396324336529, "actor_loss": -91.8856837158203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.226181745529175, "step": 24000}
{"episode_reward": 934.6084016197934, "episode": 25.0, "batch_reward": 0.7771088096499443, "critic_loss": 0.5546884346306324, "actor_loss": -91.909845703125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.253963708877563, "step": 25000}
{"episode_reward": 844.3998692645711, "episode": 26.0, "batch_reward": 0.7819740926623344, "critic_loss": 0.5637351203560829, "actor_loss": -92.05954566955566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.23926830291748, "step": 26000}
{"episode_reward": 888.6670978037469, "episode": 27.0, "batch_reward": 0.7873042938709259, "critic_loss": 0.5655235488414765, "actor_loss": -92.04243980407715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.21242666244507, "step": 27000}
{"episode_reward": 880.2459282903876, "episode": 28.0, "batch_reward": 0.7898949917554855, "critic_loss": 0.5522923041880131, "actor_loss": -92.13308389282227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.226076126098633, "step": 28000}
{"episode_reward": 933.6379073032806, "episode": 29.0, "batch_reward": 0.7946768407821655, "critic_loss": 0.5380874391198158, "actor_loss": -92.088509765625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.22631001472473, "step": 29000}
{"episode_reward": 967.5996474270145, "episode": 30.0, "batch_reward": 0.7983211069703102, "critic_loss": 0.5331617550551891, "actor_loss": -92.13246412658691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.173708200454712, "step": 30000}
{"episode_reward": 859.7035175084198, "episode": 31.0, "batch_reward": 0.7995303761959076, "critic_loss": 0.5669872719347477, "actor_loss": -92.25760151672364, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.883060455322266, "step": 31000}
{"episode_reward": 837.8508483524029, "episode": 32.0, "batch_reward": 0.8042761483192444, "critic_loss": 0.5383027158677578, "actor_loss": -92.36891354370117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.15488314628601, "step": 32000}
{"episode_reward": 900.9192247546539, "episode": 33.0, "batch_reward": 0.8065142293572426, "critic_loss": 0.5660489262342453, "actor_loss": -92.36859799194336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.114745378494263, "step": 33000}
{"episode_reward": 878.4269879219581, "episode": 34.0, "batch_reward": 0.8070852997899055, "critic_loss": 0.56623113951087, "actor_loss": -92.53444772338867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.14226770401001, "step": 34000}
{"episode_reward": 799.362720860084, "episode": 35.0, "batch_reward": 0.809438471376896, "critic_loss": 0.5807997710704803, "actor_loss": -92.51638150024414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.111424207687378, "step": 35000}
{"episode_reward": 961.9512573849884, "episode": 36.0, "batch_reward": 0.8096402978301048, "critic_loss": 0.5932040903270245, "actor_loss": -92.76417936706542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.05613946914673, "step": 36000}
{"episode_reward": 792.4581544966626, "episode": 37.0, "batch_reward": 0.8140131385326386, "critic_loss": 0.5667245780527592, "actor_loss": -92.72766165161133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.237173080444336, "step": 37000}
{"episode_reward": 944.675194130226, "episode": 38.0, "batch_reward": 0.8172803671956063, "critic_loss": 0.5746490013301373, "actor_loss": -92.62652334594726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.183468341827393, "step": 38000}
{"episode_reward": 953.206142635111, "episode": 39.0, "batch_reward": 0.8198355076909065, "critic_loss": 0.5725962189286947, "actor_loss": -92.86855772399902, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.236541271209717, "step": 39000}
{"episode_reward": 904.7172265623327, "episode": 40.0, "batch_reward": 0.8217392294406891, "critic_loss": 0.5773833110332489, "actor_loss": -93.01536676025391, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.244583129882812, "step": 40000}
{"episode_reward": 933.6667238344319, "episode": 41.0, "batch_reward": 0.8233060777783394, "critic_loss": 0.5428254332840443, "actor_loss": -93.11893276977538, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.02124857902527, "step": 41000}
{"episode_reward": 866.6239685801854, "episode": 42.0, "batch_reward": 0.8251537135243416, "critic_loss": 0.5341399354040622, "actor_loss": -93.02754771423339, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.22455620765686, "step": 42000}
{"episode_reward": 964.5333342617416, "episode": 43.0, "batch_reward": 0.8282740098834038, "critic_loss": 0.5243431883901357, "actor_loss": -93.24934954833985, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.28044629096985, "step": 43000}
{"episode_reward": 810.290907713642, "episode": 44.0, "batch_reward": 0.8282098906040192, "critic_loss": 0.5127277050316333, "actor_loss": -93.08132362365723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.21054768562317, "step": 44000}
{"episode_reward": 933.6581115761915, "episode": 45.0, "batch_reward": 0.8302346771359443, "critic_loss": 0.5186637379825115, "actor_loss": -93.09729843139648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.261176824569702, "step": 45000}
{"episode_reward": 910.7942334352463, "episode": 46.0, "batch_reward": 0.8315415415167808, "critic_loss": 0.5138029553592205, "actor_loss": -93.31413375854493, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.18607449531555, "step": 46000}
{"episode_reward": 900.9050180058276, "episode": 47.0, "batch_reward": 0.833560230076313, "critic_loss": 0.5020063885748386, "actor_loss": -93.41510815429687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.275075674057007, "step": 47000}
{"episode_reward": 907.7416992622894, "episode": 48.0, "batch_reward": 0.8359608805179596, "critic_loss": 0.49504740646481515, "actor_loss": -93.45409786987305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.236477613449097, "step": 48000}
{"episode_reward": 942.3735743241039, "episode": 49.0, "batch_reward": 0.8383392329812049, "critic_loss": 0.5005029075890779, "actor_loss": -93.51899311828613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.196649074554443, "step": 49000}
{"episode_reward": 931.4061211371754, "episode": 50.0, "batch_reward": 0.8400884659290314, "critic_loss": 0.5065962147116662, "actor_loss": -93.46434352111817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.314536571502686, "step": 50000}
{"episode_reward": 914.5429112865573, "episode": 51.0, "batch_reward": 0.841913596868515, "critic_loss": 0.5148345927894116, "actor_loss": -93.53358575439454, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.936585664749146, "step": 51000}
{"episode_reward": 835.0531280395863, "episode": 52.0, "batch_reward": 0.8405958814024925, "critic_loss": 0.5241763207316399, "actor_loss": -93.61788191223144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.279401063919067, "step": 52000}
{"episode_reward": 940.0352852505245, "episode": 53.0, "batch_reward": 0.8436117233037949, "critic_loss": 0.5216236181259155, "actor_loss": -93.45200578308105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.21401882171631, "step": 53000}
{"episode_reward": 918.9928754544807, "episode": 54.0, "batch_reward": 0.8450686202049256, "critic_loss": 0.5108603291064501, "actor_loss": -93.8308755493164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.24937677383423, "step": 54000}
{"episode_reward": 917.1939168301955, "episode": 55.0, "batch_reward": 0.8451490213871002, "critic_loss": 0.538276117324829, "actor_loss": -93.77401164245606, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.16304612159729, "step": 55000}
{"episode_reward": 917.0251896185981, "episode": 56.0, "batch_reward": 0.8478341661691665, "critic_loss": 0.5919091029167175, "actor_loss": -93.71832695007325, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.221498250961304, "step": 56000}
{"episode_reward": 980.275654694897, "episode": 57.0, "batch_reward": 0.8494464347958565, "critic_loss": 0.6340801113843918, "actor_loss": -93.82831022644044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.236873388290405, "step": 57000}
{"episode_reward": 939.0053899186, "episode": 58.0, "batch_reward": 0.8496877751350402, "critic_loss": 0.7046251433193683, "actor_loss": -93.8894384765625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.204963445663452, "step": 58000}
{"episode_reward": 863.9667386885325, "episode": 59.0, "batch_reward": 0.8517213338017464, "critic_loss": 0.5938349136412143, "actor_loss": -93.95034980773926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.183214902877808, "step": 59000}
{"episode_reward": 918.0363972968872, "episode": 60.0, "batch_reward": 0.8520172375440598, "critic_loss": 0.5909975919425488, "actor_loss": -93.97918174743653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.21440601348877, "step": 60000}
{"episode_reward": 887.7826428612224, "episode": 61.0, "batch_reward": 0.8526566313505173, "critic_loss": 0.6161741475462914, "actor_loss": -94.01152722167969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.931705474853516, "step": 61000}
{"episode_reward": 868.853885483639, "episode": 62.0, "batch_reward": 0.8524222724437713, "critic_loss": 0.6660328430235386, "actor_loss": -93.89414363098145, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.180543422698975, "step": 62000}
{"episode_reward": 930.2731987181584, "episode": 63.0, "batch_reward": 0.853243593275547, "critic_loss": 0.6391166128516197, "actor_loss": -93.90003526306153, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.16768765449524, "step": 63000}
{"episode_reward": 930.6458984941405, "episode": 64.0, "batch_reward": 0.8564674922823906, "critic_loss": 0.6972754366099835, "actor_loss": -94.05631422424317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.172244548797607, "step": 64000}
{"episode_reward": 928.4276536175182, "episode": 65.0, "batch_reward": 0.8564416300058365, "critic_loss": 0.9112270427048206, "actor_loss": -94.00809951782226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.125282526016235, "step": 65000}
{"episode_reward": 940.9527537704902, "episode": 66.0, "batch_reward": 0.8583593602180482, "critic_loss": 0.9434839253723621, "actor_loss": -94.12331616210938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.08426022529602, "step": 66000}
{"episode_reward": 933.5942331740259, "episode": 67.0, "batch_reward": 0.859309359550476, "critic_loss": 1.1037708732783795, "actor_loss": -94.15065785217286, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.125845670700073, "step": 67000}
{"episode_reward": 910.1193634780684, "episode": 68.0, "batch_reward": 0.8590985647439957, "critic_loss": 1.6309834444522857, "actor_loss": -94.3188017578125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.095898389816284, "step": 68000}
{"episode_reward": 916.7699723183686, "episode": 69.0, "batch_reward": 0.8608592807054519, "critic_loss": 1.8963739990592003, "actor_loss": -94.35809281921387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.38949227333069, "step": 69000}
{"episode_reward": 911.0738113704242, "episode": 70.0, "batch_reward": 0.8609098588228226, "critic_loss": 1.8045004736185073, "actor_loss": -94.48845333862305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.25205087661743, "step": 70000}
{"episode_reward": 830.2290808570731, "episode": 71.0, "batch_reward": 0.8600019208192825, "critic_loss": 2.1970738583207132, "actor_loss": -94.3186300048828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.04780054092407, "step": 71000}
{"episode_reward": 865.830761295478, "episode": 72.0, "batch_reward": 0.8613266583681106, "critic_loss": 2.1383354083895685, "actor_loss": -94.46447158813477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.314940214157104, "step": 72000}
{"episode_reward": 867.9383311957342, "episode": 73.0, "batch_reward": 0.8611559862494469, "critic_loss": 3.0274445335566997, "actor_loss": -94.47862631225586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.230039834976196, "step": 73000}
{"episode_reward": 820.4416591053007, "episode": 74.0, "batch_reward": 0.8594133003354073, "critic_loss": 4.115623199611902, "actor_loss": -94.51081842041016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.29164457321167, "step": 74000}
{"episode_reward": 816.330935367975, "episode": 75.0, "batch_reward": 0.8607081096172333, "critic_loss": 3.1410962079465388, "actor_loss": -94.63540751647949, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.241281986236572, "step": 75000}
{"episode_reward": 831.9310692084379, "episode": 76.0, "batch_reward": 0.8540477733016014, "critic_loss": 4.1650245949029925, "actor_loss": -94.63052000427246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.275569200515747, "step": 76000}
{"episode_reward": 70.55884967091339, "episode": 77.0, "batch_reward": 0.8476628888249397, "critic_loss": 3.510409211218357, "actor_loss": -94.69247566223144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.245438814163208, "step": 77000}
{"episode_reward": 468.10991827995593, "episode": 78.0, "batch_reward": 0.8434354059696197, "critic_loss": 2.865169204592705, "actor_loss": -94.68842483520508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.242682456970215, "step": 78000}
{"episode_reward": 860.7792349947464, "episode": 79.0, "batch_reward": 0.8440072924494744, "critic_loss": 2.1811917981505395, "actor_loss": -94.67691841125489, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.28579354286194, "step": 79000}
{"episode_reward": 850.0053924554204, "episode": 80.0, "batch_reward": 0.8386152587532997, "critic_loss": 2.2234874606132506, "actor_loss": -94.77633575439454, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.23039197921753, "step": 80000}
{"episode_reward": 61.25974728005184, "episode": 81.0, "batch_reward": 0.8340001588463783, "critic_loss": 1.860165984481573, "actor_loss": -94.8766326599121, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.052401542663574, "step": 81000}
{"episode_reward": 846.1817402219502, "episode": 82.0, "batch_reward": 0.8294960517287254, "critic_loss": 1.9452909516096115, "actor_loss": -94.89030895996093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.220533847808838, "step": 82000}
{"episode_reward": 308.8008492033494, "episode": 83.0, "batch_reward": 0.8273981430530548, "critic_loss": 1.8398705686330796, "actor_loss": -94.95624197387696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.237146377563477, "step": 83000}
{"episode_reward": 785.6123353866218, "episode": 84.0, "batch_reward": 0.8274512792825699, "critic_loss": 1.7102740988135339, "actor_loss": -94.97039739990234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.259937047958374, "step": 84000}
{"episode_reward": 892.3855173176661, "episode": 85.0, "batch_reward": 0.8233529543876648, "critic_loss": 1.740745685249567, "actor_loss": -95.0577607421875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.166633367538452, "step": 85000}
{"episode_reward": 63.26943665633451, "episode": 86.0, "batch_reward": 0.8182612776756286, "critic_loss": 1.6804588878154754, "actor_loss": -95.23972244262696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.17143201828003, "step": 86000}
{"episode_reward": 950.3196802875274, "episode": 87.0, "batch_reward": 0.8168875925540924, "critic_loss": 1.634925606906414, "actor_loss": -95.24125408935546, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.19127655029297, "step": 87000}
{"episode_reward": 65.43876220592041, "episode": 88.0, "batch_reward": 0.8134104892611503, "critic_loss": 1.4438092823922635, "actor_loss": -95.15246139526367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.21173644065857, "step": 88000}
{"episode_reward": 965.7576207960561, "episode": 89.0, "batch_reward": 0.8142079836130143, "critic_loss": 1.3621306128799915, "actor_loss": -95.25637344360352, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.208734273910522, "step": 89000}
{"episode_reward": 779.4856085873646, "episode": 90.0, "batch_reward": 0.8143069114089012, "critic_loss": 1.2278902394771576, "actor_loss": -95.0780961303711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.222575187683105, "step": 90000}
{"episode_reward": 977.0342016389563, "episode": 91.0, "batch_reward": 0.816426593542099, "critic_loss": 1.1565381547510625, "actor_loss": -94.98304243469238, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.93751883506775, "step": 91000}
{"episode_reward": 914.5523647620478, "episode": 92.0, "batch_reward": 0.8172710276842118, "critic_loss": 1.0578116289973258, "actor_loss": -95.10850889587402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.193357706069946, "step": 92000}
{"episode_reward": 924.3216449322733, "episode": 93.0, "batch_reward": 0.8187431671619415, "critic_loss": 0.9697108903080225, "actor_loss": -95.06532926940918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.16855525970459, "step": 93000}
{"episode_reward": 928.3103604588288, "episode": 94.0, "batch_reward": 0.81498719227314, "critic_loss": 0.917231773674488, "actor_loss": -94.96936337280273, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.164752960205078, "step": 94000}
{"episode_reward": 72.48910434324071, "episode": 95.0, "batch_reward": 0.8076018190383911, "critic_loss": 0.8642508028447629, "actor_loss": -94.78909785461425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.1360924243927, "step": 95000}
{"episode_reward": 66.41758574586152, "episode": 96.0, "batch_reward": 0.8039563955664635, "critic_loss": 0.7616394566595555, "actor_loss": -94.6612212677002, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.15860390663147, "step": 96000}
{"episode_reward": 940.6171228165581, "episode": 97.0, "batch_reward": 0.8043253183960914, "critic_loss": 0.7153124823868274, "actor_loss": -94.51043293762207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.121516704559326, "step": 97000}
{"episode_reward": 957.6971266577951, "episode": 98.0, "batch_reward": 0.8027824227809905, "critic_loss": 0.6922893449664116, "actor_loss": -94.45525813293457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.120544910430908, "step": 98000}
{"episode_reward": 69.05681319070847, "episode": 99.0, "batch_reward": 0.7985461208224297, "critic_loss": 0.6426759293079376, "actor_loss": -94.21655822753907, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.079684495925903, "step": 99000}
{"episode_reward": 920.0363368340174, "episode": 100.0, "batch_reward": 0.7981960425972938, "critic_loss": 0.6600039748847485, "actor_loss": -94.06449810791015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.807636737823486, "step": 100000}
{"episode_reward": 755.467267098451, "episode": 101.0, "batch_reward": 0.8000807466506958, "critic_loss": 0.6288508977591991, "actor_loss": -93.90897637939453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.780468702316284, "step": 101000}
{"episode_reward": 964.9254180719688, "episode": 102.0, "batch_reward": 0.8015571547746658, "critic_loss": 0.6369470461010933, "actor_loss": -93.76204107666015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.252079248428345, "step": 102000}
{"episode_reward": 965.2057952217066, "episode": 103.0, "batch_reward": 0.8039063299894333, "critic_loss": 0.653360603183508, "actor_loss": -93.60128900146485, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.242069959640503, "step": 103000}
{"episode_reward": 940.5879330545974, "episode": 104.0, "batch_reward": 0.8045200390219689, "critic_loss": 0.6571565603017807, "actor_loss": -93.54236659240722, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.249231100082397, "step": 104000}
{"episode_reward": 924.227902708336, "episode": 105.0, "batch_reward": 0.8047629597783089, "critic_loss": 0.6739764404892922, "actor_loss": -93.28164405822754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.22481918334961, "step": 105000}
{"episode_reward": 938.2230534473749, "episode": 106.0, "batch_reward": 0.8085152073502541, "critic_loss": 0.6800244618952275, "actor_loss": -93.3553692779541, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.276560068130493, "step": 106000}
{"episode_reward": 921.7539896377143, "episode": 107.0, "batch_reward": 0.8069446324110031, "critic_loss": 0.7137207114547491, "actor_loss": -93.13820639038086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.261055946350098, "step": 107000}
{"episode_reward": 871.1483415703923, "episode": 108.0, "batch_reward": 0.8079222250580788, "critic_loss": 0.71524254783988, "actor_loss": -92.99012570190429, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.273077964782715, "step": 108000}
{"episode_reward": 906.3902432041198, "episode": 109.0, "batch_reward": 0.8081990960240364, "critic_loss": 0.7207060242295266, "actor_loss": -93.07133776855468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.20305895805359, "step": 109000}
{"episode_reward": 943.7207756587085, "episode": 110.0, "batch_reward": 0.8103598465919495, "critic_loss": 0.7168170250058175, "actor_loss": -93.1687770690918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.267149209976196, "step": 110000}
{"episode_reward": 930.6409566563179, "episode": 111.0, "batch_reward": 0.812073971092701, "critic_loss": 0.7195614066123962, "actor_loss": -93.0424610748291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.42504286766052, "step": 111000}
{"episode_reward": 943.5862584774405, "episode": 112.0, "batch_reward": 0.813366740167141, "critic_loss": 0.7412777576744557, "actor_loss": -93.31009408569336, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.335950136184692, "step": 112000}
{"episode_reward": 931.8612986552766, "episode": 113.0, "batch_reward": 0.8144694638848304, "critic_loss": 0.7713474328517914, "actor_loss": -93.22677207946778, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.221671104431152, "step": 113000}
{"episode_reward": 934.636101286363, "episode": 114.0, "batch_reward": 0.8142044095396995, "critic_loss": 0.7217891410291195, "actor_loss": -93.32200244140626, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.16189670562744, "step": 114000}
{"episode_reward": 989.6775888409549, "episode": 115.0, "batch_reward": 0.8177911814451218, "critic_loss": 0.7071755825281143, "actor_loss": -93.34040599060059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.260586500167847, "step": 115000}
{"episode_reward": 959.8449929798853, "episode": 116.0, "batch_reward": 0.8179722014069557, "critic_loss": 0.7092090242207051, "actor_loss": -93.41124424743653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.239489555358887, "step": 116000}
{"episode_reward": 944.9938810674976, "episode": 117.0, "batch_reward": 0.8182311838269234, "critic_loss": 0.7095270368754863, "actor_loss": -93.35666604614258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.21014714241028, "step": 117000}
{"episode_reward": 900.120433264431, "episode": 118.0, "batch_reward": 0.8185122061371803, "critic_loss": 0.6769506281018257, "actor_loss": -93.41558409118652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.174346446990967, "step": 118000}
{"episode_reward": 904.447102259685, "episode": 119.0, "batch_reward": 0.8210001890659332, "critic_loss": 0.6599519485235215, "actor_loss": -93.52254127502441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.246063709259033, "step": 119000}
{"episode_reward": 943.1711129625811, "episode": 120.0, "batch_reward": 0.8212299090027809, "critic_loss": 0.6301901815533638, "actor_loss": -93.49481999206543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.258436918258667, "step": 120000}
{"episode_reward": 939.1318266008126, "episode": 121.0, "batch_reward": 0.8223584313988686, "critic_loss": 0.5821795703619719, "actor_loss": -93.49792774963379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.932337045669556, "step": 121000}
{"episode_reward": 957.1227656252133, "episode": 122.0, "batch_reward": 0.82158638215065, "critic_loss": 0.5761005121916533, "actor_loss": -93.53666792297363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.263410329818726, "step": 122000}
{"episode_reward": 932.8838083016165, "episode": 123.0, "batch_reward": 0.8244474785327911, "critic_loss": 0.5789949274510146, "actor_loss": -93.69854644775391, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.170145750045776, "step": 123000}
{"episode_reward": 952.5040997417191, "episode": 124.0, "batch_reward": 0.8253260583281518, "critic_loss": 0.5573762806355953, "actor_loss": -93.72657005310059, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.198559045791626, "step": 124000}
{"episode_reward": 935.8154749655857, "episode": 125.0, "batch_reward": 0.8268200801610947, "critic_loss": 0.5819289404302835, "actor_loss": -93.80093746948242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.14470338821411, "step": 125000}
{"episode_reward": 948.3507068530962, "episode": 126.0, "batch_reward": 0.8286006708145142, "critic_loss": 0.577653963521123, "actor_loss": -93.7508244934082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.157620191574097, "step": 126000}
{"episode_reward": 934.7501776344626, "episode": 127.0, "batch_reward": 0.8281489638090134, "critic_loss": 0.563721782758832, "actor_loss": -93.79372680664062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.143462657928467, "step": 127000}
{"episode_reward": 961.1210527647413, "episode": 128.0, "batch_reward": 0.8286186760663986, "critic_loss": 0.572101187646389, "actor_loss": -93.81156307983399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.093383073806763, "step": 128000}
{"episode_reward": 938.099260513349, "episode": 129.0, "batch_reward": 0.828096677005291, "critic_loss": 0.5497581245005131, "actor_loss": -93.76325790405274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.11039900779724, "step": 129000}
{"episode_reward": 987.4010026873666, "episode": 130.0, "batch_reward": 0.8327216471433639, "critic_loss": 0.5074931997358799, "actor_loss": -93.8633299407959, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.13854146003723, "step": 130000}
{"episode_reward": 957.4520231576864, "episode": 131.0, "batch_reward": 0.8328380069136619, "critic_loss": 0.4939913981705904, "actor_loss": -93.88855216979981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.025883436203, "step": 131000}
{"episode_reward": 927.3161177915503, "episode": 132.0, "batch_reward": 0.8327959021925926, "critic_loss": 0.49845047007501125, "actor_loss": -94.0383090209961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.274803400039673, "step": 132000}
{"episode_reward": 929.5980139942285, "episode": 133.0, "batch_reward": 0.8333330793976784, "critic_loss": 0.5016562523394823, "actor_loss": -93.95531480407715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.232592344284058, "step": 133000}
{"episode_reward": 942.6251983712294, "episode": 134.0, "batch_reward": 0.8339247295856476, "critic_loss": 0.5040356015563011, "actor_loss": -93.87685102844239, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.252973556518555, "step": 134000}
{"episode_reward": 940.3576670912789, "episode": 135.0, "batch_reward": 0.8350016311407089, "critic_loss": 0.5073388904929161, "actor_loss": -94.0724090576172, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.231443166732788, "step": 135000}
{"episode_reward": 929.8340144335531, "episode": 136.0, "batch_reward": 0.8372626738548279, "critic_loss": 0.4800949058830738, "actor_loss": -93.93739770507813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.2185697555542, "step": 136000}
{"episode_reward": 951.0512405566179, "episode": 137.0, "batch_reward": 0.8367548899650574, "critic_loss": 0.46278407935798166, "actor_loss": -94.088166015625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.237829208374023, "step": 137000}
{"episode_reward": 958.8649451547911, "episode": 138.0, "batch_reward": 0.8381330267786979, "critic_loss": 0.45293017338216307, "actor_loss": -94.10041191101074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.226466417312622, "step": 138000}
{"episode_reward": 974.6028789261932, "episode": 139.0, "batch_reward": 0.8392956021428108, "critic_loss": 0.4558407632857561, "actor_loss": -94.18238031005859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.189920902252197, "step": 139000}
{"episode_reward": 922.1840700029685, "episode": 140.0, "batch_reward": 0.842115967810154, "critic_loss": 0.4312473932355642, "actor_loss": -94.24837768554687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.25101065635681, "step": 140000}
{"episode_reward": 952.1810389523536, "episode": 141.0, "batch_reward": 0.8387323272824287, "critic_loss": 0.4410488904118538, "actor_loss": -94.16897795104981, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.022343158721924, "step": 141000}
{"episode_reward": 920.2402308510368, "episode": 142.0, "batch_reward": 0.8401566806435585, "critic_loss": 0.4220970228910446, "actor_loss": -94.12830780029297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.23788547515869, "step": 142000}
{"episode_reward": 961.869171165429, "episode": 143.0, "batch_reward": 0.8408995358943939, "critic_loss": 0.41594352497160436, "actor_loss": -94.11877323913575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.242852210998535, "step": 143000}
{"episode_reward": 868.9341823359146, "episode": 144.0, "batch_reward": 0.8425429712533951, "critic_loss": 0.45687354129552843, "actor_loss": -94.25679385375976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.25547766685486, "step": 144000}
{"episode_reward": 937.543839757601, "episode": 145.0, "batch_reward": 0.8416216107010841, "critic_loss": 0.4057486264258623, "actor_loss": -94.24289045715332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.28659176826477, "step": 145000}
{"episode_reward": 915.1258661243543, "episode": 146.0, "batch_reward": 0.8432056309580803, "critic_loss": 0.4257419034540653, "actor_loss": -94.31515892028808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.22789454460144, "step": 146000}
{"episode_reward": 956.4619145955446, "episode": 147.0, "batch_reward": 0.8440040140151978, "critic_loss": 0.4096653691008687, "actor_loss": -94.30682362365722, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.249937534332275, "step": 147000}
{"episode_reward": 943.7075989243202, "episode": 148.0, "batch_reward": 0.8435532649159432, "critic_loss": 0.4282403381168842, "actor_loss": -94.25939837646484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.204530954360962, "step": 148000}
{"episode_reward": 897.9490609390022, "episode": 149.0, "batch_reward": 0.8449686971902848, "critic_loss": 0.40826009491086007, "actor_loss": -94.35078515625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.225370168685913, "step": 149000}
{"episode_reward": 987.2564083894107, "episode": 150.0, "batch_reward": 0.844052949309349, "critic_loss": 0.41363769795000555, "actor_loss": -94.33502641296387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
