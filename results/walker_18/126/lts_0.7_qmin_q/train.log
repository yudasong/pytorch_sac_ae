{"episode_reward": 0.0, "episode": 1.0, "duration": 22.45369029045105, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 2.140676259994507, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.43792215290765996, "critic_loss": 0.19002729492083753, "actor_loss": -82.88055273073584, "actor_target_entropy": -6.0, "alpha_value": 0.002642586817083679, "duration": 64.3868978023529, "step": 3000}
{"episode_reward": 61.685424450046064, "episode": 4.0, "batch_reward": 0.30347068777680397, "critic_loss": 0.35573651565611364, "actor_loss": -80.70392178344727, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.456154108047485, "step": 4000}
{"episode_reward": 163.4962491418139, "episode": 5.0, "batch_reward": 0.2875959260761738, "critic_loss": 0.4875627039968967, "actor_loss": -80.10692895507813, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.255110025405884, "step": 5000}
{"episode_reward": 305.84036446068865, "episode": 6.0, "batch_reward": 0.30046525147557257, "critic_loss": 0.7606326083540916, "actor_loss": -80.13848013305665, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.671513080596924, "step": 6000}
{"episode_reward": 404.41430762295914, "episode": 7.0, "batch_reward": 0.3105682686269283, "critic_loss": 1.095266101449728, "actor_loss": -79.94095481872559, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.265551567077637, "step": 7000}
{"episode_reward": 274.7727941601944, "episode": 8.0, "batch_reward": 0.3137705177515745, "critic_loss": 1.5203800493478774, "actor_loss": -80.703058883667, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.06416916847229, "step": 8000}
{"episode_reward": 397.907223687724, "episode": 9.0, "batch_reward": 0.32508673129975796, "critic_loss": 1.8671659029722214, "actor_loss": -80.21098374938965, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.544923782348633, "step": 9000}
{"episode_reward": 489.96153343393223, "episode": 10.0, "batch_reward": 0.35740552872419357, "critic_loss": 2.370996654868126, "actor_loss": -80.75233120727539, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.539303064346313, "step": 10000}
{"episode_reward": 718.7621192484138, "episode": 11.0, "batch_reward": 0.3879746505022049, "critic_loss": 3.61671150636673, "actor_loss": -81.59719943237305, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.63327717781067, "step": 11000}
{"episode_reward": 635.772808589517, "episode": 12.0, "batch_reward": 0.4063769372701645, "critic_loss": 6.370877961397171, "actor_loss": -82.0480306854248, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.81483244895935, "step": 12000}
{"episode_reward": 589.0026555759483, "episode": 13.0, "batch_reward": 0.4228337812423706, "critic_loss": 10.028277928829192, "actor_loss": -82.89540908813477, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.72129487991333, "step": 13000}
{"episode_reward": 665.0467227180267, "episode": 14.0, "batch_reward": 0.4239834504425526, "critic_loss": 22.08623170757294, "actor_loss": -83.91291235351562, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.562636852264404, "step": 14000}
{"episode_reward": 124.65608849777098, "episode": 15.0, "batch_reward": 0.3991348194181919, "critic_loss": 44.668824855804445, "actor_loss": -86.13178451538086, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.351415634155273, "step": 15000}
{"episode_reward": 22.209935470867105, "episode": 16.0, "batch_reward": 0.37523649057745934, "critic_loss": 49.691587861061095, "actor_loss": -89.02877766418457, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.76719331741333, "step": 16000}
{"episode_reward": 38.10649011147054, "episode": 17.0, "batch_reward": 0.35210790440440176, "critic_loss": 62.14856279563904, "actor_loss": -97.45562159729003, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.68521523475647, "step": 17000}
{"episode_reward": 15.221169072553351, "episode": 18.0, "batch_reward": 0.3346012183725834, "critic_loss": 95.33579690170288, "actor_loss": -109.70277787780762, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.06900453567505, "step": 18000}
{"episode_reward": 35.92454070242355, "episode": 19.0, "batch_reward": 0.3194162725955248, "critic_loss": 142.17912563323975, "actor_loss": -122.31986157226562, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.34776282310486, "step": 19000}
{"episode_reward": 42.304205091052516, "episode": 20.0, "batch_reward": 0.3050974332988262, "critic_loss": 176.2572712097168, "actor_loss": -139.07736862182617, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.08765482902527, "step": 20000}
{"episode_reward": 25.393912125605254, "episode": 21.0, "batch_reward": 0.2904655694514513, "critic_loss": 174.5626012649536, "actor_loss": -141.48328005981446, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.237863063812256, "step": 21000}
{"episode_reward": 47.600047224187094, "episode": 22.0, "batch_reward": 0.2784158815443516, "critic_loss": 152.11833996582033, "actor_loss": -147.82134396362304, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.962644815444946, "step": 22000}
{"episode_reward": 31.8596516540444, "episode": 23.0, "batch_reward": 0.267329961001873, "critic_loss": 132.96632673645018, "actor_loss": -148.08821495056154, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.10292100906372, "step": 23000}
{"episode_reward": 39.8417840003618, "episode": 24.0, "batch_reward": 0.25909099243581296, "critic_loss": 118.30705574417114, "actor_loss": -149.05664463806153, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.6053147315979, "step": 24000}
{"episode_reward": 37.19189928142873, "episode": 25.0, "batch_reward": 0.2505028356611729, "critic_loss": 97.77743591690063, "actor_loss": -156.18413766479492, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.097763299942017, "step": 25000}
{"episode_reward": 42.159946953447694, "episode": 26.0, "batch_reward": 0.2459819559454918, "critic_loss": 80.7323173789978, "actor_loss": -157.9930240020752, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.517359018325806, "step": 26000}
{"episode_reward": 205.4456568163502, "episode": 27.0, "batch_reward": 0.24223406967520714, "critic_loss": 60.34018310546875, "actor_loss": -161.77063751220703, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.62523317337036, "step": 27000}
{"episode_reward": 38.695304171085496, "episode": 28.0, "batch_reward": 0.2422516292333603, "critic_loss": 47.477810930252076, "actor_loss": -152.11018185424805, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.397191762924194, "step": 28000}
{"episode_reward": 650.48013942223, "episode": 29.0, "batch_reward": 0.25405165830254556, "critic_loss": 38.80822032737732, "actor_loss": -155.969484664917, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.331835746765137, "step": 29000}
{"episode_reward": 429.4431483399035, "episode": 30.0, "batch_reward": 0.26208783279359343, "critic_loss": 30.142386533737184, "actor_loss": -153.53479792785646, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.44454526901245, "step": 30000}
{"episode_reward": 557.9372706977722, "episode": 31.0, "batch_reward": 0.27094971369206905, "critic_loss": 23.12780359363556, "actor_loss": -144.64903218078612, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.50561261177063, "step": 31000}
{"episode_reward": 463.5132442701077, "episode": 32.0, "batch_reward": 0.2698486230820417, "critic_loss": 17.341779673576355, "actor_loss": -143.61745957946778, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.519559144973755, "step": 32000}
{"episode_reward": 29.637187023843822, "episode": 33.0, "batch_reward": 0.2627302820980549, "critic_loss": 13.185054860591888, "actor_loss": -143.22473751831055, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.841403484344482, "step": 33000}
{"episode_reward": 72.34267203610665, "episode": 34.0, "batch_reward": 0.2594178014397621, "critic_loss": 10.901617563724518, "actor_loss": -134.02240367126464, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.41490936279297, "step": 34000}
{"episode_reward": 342.6710698725512, "episode": 35.0, "batch_reward": 0.26001870107650754, "critic_loss": 9.335631232261658, "actor_loss": -136.6614970397949, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.214609384536743, "step": 35000}
{"episode_reward": 38.338173162509854, "episode": 36.0, "batch_reward": 0.2521892029941082, "critic_loss": 7.596767035007477, "actor_loss": -125.49128190612792, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.81727433204651, "step": 36000}
{"episode_reward": 33.52375898420629, "episode": 37.0, "batch_reward": 0.2533586793392897, "critic_loss": 6.585067981004715, "actor_loss": -127.40148762512207, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.645102500915527, "step": 37000}
{"episode_reward": 652.6417156232042, "episode": 38.0, "batch_reward": 0.26658155415952206, "critic_loss": 5.5332921028137205, "actor_loss": -129.75885621643067, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.88344931602478, "step": 38000}
{"episode_reward": 719.0112555334669, "episode": 39.0, "batch_reward": 0.2763272157162428, "critic_loss": 5.523685495615005, "actor_loss": -122.80689524841308, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.806103229522705, "step": 39000}
{"episode_reward": 605.8317472805514, "episode": 40.0, "batch_reward": 0.2850767635405064, "critic_loss": 4.749431397438049, "actor_loss": -120.41330821228027, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.896219968795776, "step": 40000}
{"episode_reward": 797.9911428653652, "episode": 41.0, "batch_reward": 0.2994594028145075, "critic_loss": 4.413840770483017, "actor_loss": -116.00600315856934, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.571702003479004, "step": 41000}
{"episode_reward": 723.8194610586222, "episode": 42.0, "batch_reward": 0.3083815594762564, "critic_loss": 3.8617939685583114, "actor_loss": -118.27184922790528, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.18325114250183, "step": 42000}
{"episode_reward": 791.0410395657583, "episode": 43.0, "batch_reward": 0.3180513481497765, "critic_loss": 3.702835074901581, "actor_loss": -113.7248860321045, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.621807098388672, "step": 43000}
{"episode_reward": 517.6093067008746, "episode": 44.0, "batch_reward": 0.32094356846809385, "critic_loss": 3.2305066992044447, "actor_loss": -114.53877212524414, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.062332153320312, "step": 44000}
{"episode_reward": 241.28051433655435, "episode": 45.0, "batch_reward": 0.3224432511627674, "critic_loss": 2.913275945544243, "actor_loss": -113.3405212097168, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.398248434066772, "step": 45000}
{"episode_reward": 702.7985119587634, "episode": 46.0, "batch_reward": 0.33262435023486614, "critic_loss": 2.751238148212433, "actor_loss": -109.83461891174316, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.460750102996826, "step": 46000}
{"episode_reward": 818.1521681515387, "episode": 47.0, "batch_reward": 0.34225570310652254, "critic_loss": 2.8099809510707856, "actor_loss": -107.21027899169921, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.95756769180298, "step": 47000}
{"episode_reward": 832.2441882867946, "episode": 48.0, "batch_reward": 0.35430639004707337, "critic_loss": 2.720167078733444, "actor_loss": -106.0601959991455, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.815876960754395, "step": 48000}
{"episode_reward": 811.7210580543384, "episode": 49.0, "batch_reward": 0.36312557888031005, "critic_loss": 2.4632797164916993, "actor_loss": -104.55048759460449, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.44020104408264, "step": 49000}
{"episode_reward": 811.4648225782873, "episode": 50.0, "batch_reward": 0.37254556024074553, "critic_loss": 2.510986944794655, "actor_loss": -104.4680696258545, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.213061809539795, "step": 50000}
{"episode_reward": 767.0203730398894, "episode": 51.0, "batch_reward": 0.3813725628256798, "critic_loss": 2.1035611490011217, "actor_loss": -102.25708554077148, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 45.22496294975281, "step": 51000}
{"episode_reward": 833.3962096168618, "episode": 52.0, "batch_reward": 0.3873691009879112, "critic_loss": 2.104326197743416, "actor_loss": -99.88149612426758, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.468481302261353, "step": 52000}
{"episode_reward": 864.8420413575363, "episode": 53.0, "batch_reward": 0.39851263210177423, "critic_loss": 2.1502922508716584, "actor_loss": -101.15304670715332, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.2562472820282, "step": 53000}
{"episode_reward": 855.3069948519793, "episode": 54.0, "batch_reward": 0.407261137843132, "critic_loss": 2.0307277572155, "actor_loss": -96.91667448425292, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.894686937332153, "step": 54000}
{"episode_reward": 878.1445766631493, "episode": 55.0, "batch_reward": 0.415127258092165, "critic_loss": 2.0143647486567495, "actor_loss": -97.1005637664795, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.902588367462158, "step": 55000}
{"episode_reward": 875.1252667359854, "episode": 56.0, "batch_reward": 0.4230598454475403, "critic_loss": 1.988641201198101, "actor_loss": -98.06947912597656, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.4422709941864, "step": 56000}
{"episode_reward": 930.3171230654908, "episode": 57.0, "batch_reward": 0.4344295030832291, "critic_loss": 1.8636528397798537, "actor_loss": -96.31993954467774, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.27065396308899, "step": 57000}
{"episode_reward": 894.3046634477199, "episode": 58.0, "batch_reward": 0.4398607751429081, "critic_loss": 1.9036875630021095, "actor_loss": -96.05976086425781, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.316924333572388, "step": 58000}
{"episode_reward": 861.5674906254095, "episode": 59.0, "batch_reward": 0.44672490695118905, "critic_loss": 1.8242539451718331, "actor_loss": -95.0779925994873, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.04521942138672, "step": 59000}
{"episode_reward": 820.5858889518036, "episode": 60.0, "batch_reward": 0.454399789005518, "critic_loss": 1.8224905768036843, "actor_loss": -95.34345066833497, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.443232536315918, "step": 60000}
{"episode_reward": 833.3374589543045, "episode": 61.0, "batch_reward": 0.45914242684841156, "critic_loss": 1.7789075738787652, "actor_loss": -94.02912121582031, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.5229172706604, "step": 61000}
{"episode_reward": 809.283413071575, "episode": 62.0, "batch_reward": 0.4651108474433422, "critic_loss": 1.6735670145154, "actor_loss": -94.48234059143067, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.071308612823486, "step": 62000}
{"episode_reward": 900.0467914850002, "episode": 63.0, "batch_reward": 0.4711247787773609, "critic_loss": 1.5929069662690163, "actor_loss": -93.63319660949708, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.522528648376465, "step": 63000}
{"episode_reward": 783.6221479759998, "episode": 64.0, "batch_reward": 0.4787628131508827, "critic_loss": 1.4981633100509644, "actor_loss": -93.05310888671875, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.82736587524414, "step": 64000}
{"episode_reward": 838.2532395287461, "episode": 65.0, "batch_reward": 0.4867174862921238, "critic_loss": 1.4371635954380035, "actor_loss": -93.23257313537597, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.450766563415527, "step": 65000}
{"episode_reward": 901.0617477692764, "episode": 66.0, "batch_reward": 0.48976631405949594, "critic_loss": 1.425656340777874, "actor_loss": -92.71072041320801, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.11557650566101, "step": 66000}
{"episode_reward": 910.2452701037909, "episode": 67.0, "batch_reward": 0.49601581105589865, "critic_loss": 1.3489508504271508, "actor_loss": -92.53570509338378, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.06257152557373, "step": 67000}
{"episode_reward": 911.7524511815802, "episode": 68.0, "batch_reward": 0.5032989099025726, "critic_loss": 1.2681072942614555, "actor_loss": -91.89964573669434, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.94002366065979, "step": 68000}
{"episode_reward": 909.4687524098599, "episode": 69.0, "batch_reward": 0.5115425266325474, "critic_loss": 1.257597633600235, "actor_loss": -91.8323895263672, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.633233785629272, "step": 69000}
{"episode_reward": 899.1617672011738, "episode": 70.0, "batch_reward": 0.5136518920660019, "critic_loss": 1.3089445952773093, "actor_loss": -91.35711717224122, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.227784395217896, "step": 70000}
{"episode_reward": 850.985420683349, "episode": 71.0, "batch_reward": 0.5184418151378631, "critic_loss": 1.221703152358532, "actor_loss": -91.49503889465332, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 45.773903369903564, "step": 71000}
{"episode_reward": 902.5100825347282, "episode": 72.0, "batch_reward": 0.524276826351881, "critic_loss": 1.2028815376758575, "actor_loss": -91.09180471801758, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.284364938735962, "step": 72000}
{"episode_reward": 864.451659651699, "episode": 73.0, "batch_reward": 0.5276508702635765, "critic_loss": 1.191166154384613, "actor_loss": -90.75709487915039, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.897928476333618, "step": 73000}
{"episode_reward": 892.1103317151919, "episode": 74.0, "batch_reward": 0.5333270386755466, "critic_loss": 1.2191533950567246, "actor_loss": -90.63176022338867, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.14750385284424, "step": 74000}
{"episode_reward": 882.4464468542993, "episode": 75.0, "batch_reward": 0.5410874496102334, "critic_loss": 1.1387044397592545, "actor_loss": -90.52558360290527, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.902655124664307, "step": 75000}
{"episode_reward": 940.3943962803147, "episode": 76.0, "batch_reward": 0.5442143562436104, "critic_loss": 1.1189894070923327, "actor_loss": -90.31749198913575, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.43503189086914, "step": 76000}
{"episode_reward": 881.2467936707502, "episode": 77.0, "batch_reward": 0.5496184009611607, "critic_loss": 1.1363658175468445, "actor_loss": -90.27695491027832, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.581443786621094, "step": 77000}
{"episode_reward": 947.1419596799345, "episode": 78.0, "batch_reward": 0.5527676685452462, "critic_loss": 1.1259856429100037, "actor_loss": -90.00352532958985, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.32865262031555, "step": 78000}
{"episode_reward": 883.6595645864393, "episode": 79.0, "batch_reward": 0.5557760412693024, "critic_loss": 1.0729599036574364, "actor_loss": -89.88099980163574, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.249590396881104, "step": 79000}
{"episode_reward": 900.5824070525858, "episode": 80.0, "batch_reward": 0.5622976736426354, "critic_loss": 1.020505265623331, "actor_loss": -89.8626383972168, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.974591970443726, "step": 80000}
{"episode_reward": 912.616052169982, "episode": 81.0, "batch_reward": 0.5674191681742669, "critic_loss": 0.9739983317255974, "actor_loss": -89.76600122070313, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.8761203289032, "step": 81000}
{"episode_reward": 880.0382037157664, "episode": 82.0, "batch_reward": 0.5666279259622097, "critic_loss": 1.0496825088858603, "actor_loss": -89.65552426147461, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.332905292510986, "step": 82000}
{"episode_reward": 772.635116477624, "episode": 83.0, "batch_reward": 0.5725241807103157, "critic_loss": 1.0255354971289634, "actor_loss": -89.69378741455078, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.36993980407715, "step": 83000}
{"episode_reward": 902.2138946632069, "episode": 84.0, "batch_reward": 0.5750932064950466, "critic_loss": 0.9423648438453675, "actor_loss": -89.63492236328125, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.366499185562134, "step": 84000}
{"episode_reward": 877.4787987455065, "episode": 85.0, "batch_reward": 0.5798513238132, "critic_loss": 0.9647457594573497, "actor_loss": -89.36922682189942, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.04000997543335, "step": 85000}
{"episode_reward": 898.4198453664915, "episode": 86.0, "batch_reward": 0.5843261136412621, "critic_loss": 0.956201167345047, "actor_loss": -89.42855429077149, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.22987675666809, "step": 86000}
{"episode_reward": 918.1468840598395, "episode": 87.0, "batch_reward": 0.5866349042654038, "critic_loss": 0.9481906505227089, "actor_loss": -89.45713662719727, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.117687940597534, "step": 87000}
{"episode_reward": 880.981426728298, "episode": 88.0, "batch_reward": 0.5936173216104508, "critic_loss": 0.9175491006374359, "actor_loss": -89.53652774047852, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.66928791999817, "step": 88000}
{"episode_reward": 942.6775395128069, "episode": 89.0, "batch_reward": 0.5963835360705853, "critic_loss": 0.9179014949798584, "actor_loss": -89.28891581726074, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.496591329574585, "step": 89000}
{"episode_reward": 938.0234731935439, "episode": 90.0, "batch_reward": 0.5990505109131337, "critic_loss": 0.9063821056187152, "actor_loss": -89.48015299987793, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.786865949630737, "step": 90000}
{"episode_reward": 932.4849924767187, "episode": 91.0, "batch_reward": 0.6028617367744445, "critic_loss": 0.9336042333841323, "actor_loss": -89.2664997253418, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.55179738998413, "step": 91000}
{"episode_reward": 877.8876888338492, "episode": 92.0, "batch_reward": 0.6057706046104431, "critic_loss": 0.8998523883223534, "actor_loss": -89.36364332580567, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.49606966972351, "step": 92000}
{"episode_reward": 910.6583405666388, "episode": 93.0, "batch_reward": 0.6100600110292435, "critic_loss": 0.910652070581913, "actor_loss": -89.43182865905762, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.49443507194519, "step": 93000}
{"episode_reward": 961.7104063713864, "episode": 94.0, "batch_reward": 0.6131169890463353, "critic_loss": 0.8591424830853939, "actor_loss": -89.60318664550782, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.365487098693848, "step": 94000}
{"episode_reward": 897.0566813873331, "episode": 95.0, "batch_reward": 0.6162220384180546, "critic_loss": 0.9301830548346043, "actor_loss": -89.50090794372558, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.556127309799194, "step": 95000}
{"episode_reward": 889.1250870735194, "episode": 96.0, "batch_reward": 0.618886454820633, "critic_loss": 0.9138012306392193, "actor_loss": -89.39260855102539, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.460168600082397, "step": 96000}
{"episode_reward": 886.0717685643733, "episode": 97.0, "batch_reward": 0.6212061060667038, "critic_loss": 0.9007701584994793, "actor_loss": -89.3650139465332, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.03615164756775, "step": 97000}
{"episode_reward": 900.736227601654, "episode": 98.0, "batch_reward": 0.625176086962223, "critic_loss": 0.9238509844541549, "actor_loss": -89.3525182800293, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.98528504371643, "step": 98000}
{"episode_reward": 946.2200402935066, "episode": 99.0, "batch_reward": 0.6266442215442658, "critic_loss": 0.933395887285471, "actor_loss": -89.38437559509278, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.509164094924927, "step": 99000}
{"episode_reward": 885.8694410482684, "episode": 100.0, "batch_reward": 0.6266461002826691, "critic_loss": 0.9147878992259503, "actor_loss": -89.31000646972656, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.13131332397461, "step": 100000}
{"episode_reward": 905.6000707678721, "episode": 101.0, "batch_reward": 0.6332943978905677, "critic_loss": 0.9739427531957626, "actor_loss": -89.28858267211913, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 44.131978034973145, "step": 101000}
{"episode_reward": 943.8508884016096, "episode": 102.0, "batch_reward": 0.6367052841484546, "critic_loss": 0.924849905192852, "actor_loss": -89.67346897888184, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.289971590042114, "step": 102000}
{"episode_reward": 920.9502468512967, "episode": 103.0, "batch_reward": 0.6384718365073204, "critic_loss": 0.8712038331627846, "actor_loss": -89.16634921264648, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.23550581932068, "step": 103000}
{"episode_reward": 948.8202400623085, "episode": 104.0, "batch_reward": 0.6415645833611489, "critic_loss": 0.890149547368288, "actor_loss": -89.4573006591797, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.041253566741943, "step": 104000}
{"episode_reward": 903.4036929707615, "episode": 105.0, "batch_reward": 0.6443612605929375, "critic_loss": 0.8598469581305981, "actor_loss": -89.1127318725586, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.553492307662964, "step": 105000}
{"episode_reward": 936.9538052404469, "episode": 106.0, "batch_reward": 0.6450662028193473, "critic_loss": 0.8534698924720288, "actor_loss": -89.64485772705078, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.907406091690063, "step": 106000}
{"episode_reward": 868.2209895675767, "episode": 107.0, "batch_reward": 0.6477272397875786, "critic_loss": 0.8555662242472172, "actor_loss": -89.42938928222657, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.41630482673645, "step": 107000}
{"episode_reward": 777.8355191340147, "episode": 108.0, "batch_reward": 0.6482584971189499, "critic_loss": 0.8800883597433568, "actor_loss": -89.04477841186524, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.873350143432617, "step": 108000}
{"episode_reward": 935.9012782215752, "episode": 109.0, "batch_reward": 0.6520738179087638, "critic_loss": 0.8666355078220367, "actor_loss": -89.66893710327149, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.085833311080933, "step": 109000}
{"episode_reward": 866.8384491336537, "episode": 110.0, "batch_reward": 0.6548319433927536, "critic_loss": 0.8888005653321743, "actor_loss": -89.39718699645996, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.27109384536743, "step": 110000}
{"episode_reward": 903.672431419086, "episode": 111.0, "batch_reward": 0.6575727571845055, "critic_loss": 0.8992450503408909, "actor_loss": -89.27715576171875, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.35153341293335, "step": 111000}
{"episode_reward": 868.7597525503045, "episode": 112.0, "batch_reward": 0.6593128123283386, "critic_loss": 0.8807598268985748, "actor_loss": -89.63324365234375, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.792306423187256, "step": 112000}
{"episode_reward": 844.4909566837921, "episode": 113.0, "batch_reward": 0.6591629189252853, "critic_loss": 0.8839562198519707, "actor_loss": -89.53411564636231, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.949718475341797, "step": 113000}
{"episode_reward": 925.4466423340483, "episode": 114.0, "batch_reward": 0.6622961655259132, "critic_loss": 0.8544744954407215, "actor_loss": -89.7794538269043, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.178484439849854, "step": 114000}
{"episode_reward": 968.8142899263569, "episode": 115.0, "batch_reward": 0.663763278901577, "critic_loss": 0.8475198560059071, "actor_loss": -89.56851281738281, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.765335083007812, "step": 115000}
{"episode_reward": 931.8652830075376, "episode": 116.0, "batch_reward": 0.6713011376261712, "critic_loss": 0.8693478597700596, "actor_loss": -89.82102830505372, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.223251581192017, "step": 116000}
{"episode_reward": 871.2731693675879, "episode": 117.0, "batch_reward": 0.6679164800047874, "critic_loss": 0.856753603130579, "actor_loss": -89.37078182983399, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.159827947616577, "step": 117000}
{"episode_reward": 924.6390048947056, "episode": 118.0, "batch_reward": 0.6725209529995918, "critic_loss": 0.8431853157579898, "actor_loss": -89.71208605957031, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.757994651794434, "step": 118000}
{"episode_reward": 937.4562373014786, "episode": 119.0, "batch_reward": 0.6743605207800866, "critic_loss": 0.8530519537627697, "actor_loss": -89.80124810791015, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.680380821228027, "step": 119000}
{"episode_reward": 936.4951684702867, "episode": 120.0, "batch_reward": 0.6760593026876449, "critic_loss": 0.842347903072834, "actor_loss": -89.60611222839356, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.831543445587158, "step": 120000}
{"episode_reward": 935.9855690768508, "episode": 121.0, "batch_reward": 0.6772928704619408, "critic_loss": 0.7791130063831806, "actor_loss": -89.62319519042968, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.33960771560669, "step": 121000}
{"episode_reward": 929.4000702000684, "episode": 122.0, "batch_reward": 0.6811584567427635, "critic_loss": 0.7984420799016952, "actor_loss": -89.84597290039062, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.668797492980957, "step": 122000}
{"episode_reward": 891.8167714548241, "episode": 123.0, "batch_reward": 0.6822446403503418, "critic_loss": 0.8278328448832035, "actor_loss": -90.2031245880127, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.858607292175293, "step": 123000}
{"episode_reward": 942.2784367586152, "episode": 124.0, "batch_reward": 0.6846372190713882, "critic_loss": 0.8281354536116123, "actor_loss": -90.13637536621094, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.189173698425293, "step": 124000}
{"episode_reward": 919.1078444851007, "episode": 125.0, "batch_reward": 0.6862104117274285, "critic_loss": 0.8264614257216454, "actor_loss": -90.08910545349121, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.678696155548096, "step": 125000}
{"episode_reward": 882.1281308595043, "episode": 126.0, "batch_reward": 0.687752494931221, "critic_loss": 0.8108299923837184, "actor_loss": -89.86784790039063, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.64421820640564, "step": 126000}
{"episode_reward": 936.2786653561207, "episode": 127.0, "batch_reward": 0.6877711725831032, "critic_loss": 0.8096205732226371, "actor_loss": -89.87580911254882, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.067754983901978, "step": 127000}
{"episode_reward": 867.7802194209355, "episode": 128.0, "batch_reward": 0.6896812089085579, "critic_loss": 0.8061794054210186, "actor_loss": -90.15596025085449, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.651910543441772, "step": 128000}
{"episode_reward": 898.2008254176336, "episode": 129.0, "batch_reward": 0.6906733956336976, "critic_loss": 0.8067156974077224, "actor_loss": -89.88702685546875, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.23698329925537, "step": 129000}
{"episode_reward": 958.8104401149926, "episode": 130.0, "batch_reward": 0.6957819470763207, "critic_loss": 0.8180679520666599, "actor_loss": -90.07871980285644, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.528135776519775, "step": 130000}
{"episode_reward": 908.9866488744461, "episode": 131.0, "batch_reward": 0.6959830248951911, "critic_loss": 0.7969503347277641, "actor_loss": -90.1408483581543, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.67210626602173, "step": 131000}
{"episode_reward": 907.8250809895897, "episode": 132.0, "batch_reward": 0.6963189015388489, "critic_loss": 0.8166907543241978, "actor_loss": -90.33951976013184, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.569831609725952, "step": 132000}
{"episode_reward": 886.4602898565981, "episode": 133.0, "batch_reward": 0.7005281955599785, "critic_loss": 0.8418718838393688, "actor_loss": -90.21707612609863, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.657505989074707, "step": 133000}
{"episode_reward": 945.1437610069129, "episode": 134.0, "batch_reward": 0.7023244537711143, "critic_loss": 0.8125245464146137, "actor_loss": -90.07884922790528, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.403218269348145, "step": 134000}
{"episode_reward": 899.2816349022797, "episode": 135.0, "batch_reward": 0.7029242817759513, "critic_loss": 0.8152248732149601, "actor_loss": -90.2462240600586, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.628588914871216, "step": 135000}
{"episode_reward": 893.0602896666758, "episode": 136.0, "batch_reward": 0.7030839603543282, "critic_loss": 0.7899424327909946, "actor_loss": -89.71859521484375, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.81970715522766, "step": 136000}
{"episode_reward": 922.9292246826109, "episode": 137.0, "batch_reward": 0.7051061729192734, "critic_loss": 0.7886517796218395, "actor_loss": -90.51223429870605, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.374263525009155, "step": 137000}
{"episode_reward": 915.4416407636153, "episode": 138.0, "batch_reward": 0.7079240057468414, "critic_loss": 0.7984444137215614, "actor_loss": -90.70173651123046, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.740652561187744, "step": 138000}
{"episode_reward": 944.474353193428, "episode": 139.0, "batch_reward": 0.7110388164520264, "critic_loss": 0.7671482802033425, "actor_loss": -90.50239987182617, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.371857404708862, "step": 139000}
{"episode_reward": 944.442748160862, "episode": 140.0, "batch_reward": 0.7130616289377213, "critic_loss": 0.7865281625390053, "actor_loss": -90.4687953338623, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.150766134262085, "step": 140000}
{"episode_reward": 928.9694639511034, "episode": 141.0, "batch_reward": 0.7111043647527695, "critic_loss": 0.8088658394217492, "actor_loss": -90.43747566223145, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 45.12258172035217, "step": 141000}
{"episode_reward": 925.5560022655368, "episode": 142.0, "batch_reward": 0.7119433757662773, "critic_loss": 0.8021521345376968, "actor_loss": -90.09871836853027, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.916333436965942, "step": 142000}
{"episode_reward": 938.6144742925991, "episode": 143.0, "batch_reward": 0.7139940073490143, "critic_loss": 0.777742307305336, "actor_loss": -90.39010566711426, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.346466541290283, "step": 143000}
{"episode_reward": 918.586941929642, "episode": 144.0, "batch_reward": 0.7170734641551971, "critic_loss": 0.7660337841510773, "actor_loss": -90.50875439453125, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.314183235168457, "step": 144000}
{"episode_reward": 869.4642939524985, "episode": 145.0, "batch_reward": 0.7188112061619759, "critic_loss": 0.7622027483582496, "actor_loss": -90.78469459533692, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.030343294143677, "step": 145000}
{"episode_reward": 897.0305633090043, "episode": 146.0, "batch_reward": 0.7160331757664681, "critic_loss": 0.7825498479306698, "actor_loss": -90.77851205444335, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.23491406440735, "step": 146000}
{"episode_reward": 101.29929400162385, "episode": 147.0, "batch_reward": 0.7145352361798286, "critic_loss": 0.784638766437769, "actor_loss": -90.60132739257813, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.8262619972229, "step": 147000}
{"episode_reward": 896.7970824101766, "episode": 148.0, "batch_reward": 0.7155118301510811, "critic_loss": 0.8069727674126626, "actor_loss": -90.79005279541016, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.56439733505249, "step": 148000}
{"episode_reward": 911.2552703399112, "episode": 149.0, "batch_reward": 0.7181913079619408, "critic_loss": 0.7842080487012864, "actor_loss": -90.46539645385742, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.063295125961304, "step": 149000}
{"episode_reward": 966.0717746964476, "episode": 150.0, "batch_reward": 0.7189942433238029, "critic_loss": 0.7991542535722256, "actor_loss": -90.66400415039062, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "step": 150000}
