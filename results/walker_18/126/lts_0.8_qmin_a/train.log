{"episode_reward": 0.0, "episode": 1.0, "duration": 21.66886305809021, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.8573613166809082, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.43503357191290926, "critic_loss": 0.06620092925197306, "actor_loss": -67.76145023046708, "actor_target_entropy": -6.0, "alpha_value": 0.002642586817083679, "duration": 62.11584162712097, "step": 3000}
{"episode_reward": 4.480671722451679, "episode": 4.0, "batch_reward": 0.27267115873098374, "critic_loss": 0.1622046761661768, "actor_loss": -61.74588275003433, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.417354583740234, "step": 4000}
{"episode_reward": 45.330068647732865, "episode": 5.0, "batch_reward": 0.2252426083907485, "critic_loss": 0.368665130559355, "actor_loss": -61.11024834728241, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.778732299804688, "step": 5000}
{"episode_reward": 44.77454087318929, "episode": 6.0, "batch_reward": 0.19027386271208524, "critic_loss": 0.22078281457722188, "actor_loss": -59.27041160482168, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.292879343032837, "step": 6000}
{"episode_reward": 63.45088059186304, "episode": 7.0, "batch_reward": 0.1856597441881895, "critic_loss": 0.2830465230718255, "actor_loss": -60.55965079087019, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.09069800376892, "step": 7000}
{"episode_reward": 201.81275780073568, "episode": 8.0, "batch_reward": 0.18674149546027183, "critic_loss": 0.3212768683433533, "actor_loss": -63.26039012646675, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.34125256538391, "step": 8000}
{"episode_reward": 239.86837412051108, "episode": 9.0, "batch_reward": 0.20127537009119986, "critic_loss": 0.3062755656316876, "actor_loss": -61.88032041192055, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.35822081565857, "step": 9000}
{"episode_reward": 327.7739275738066, "episode": 10.0, "batch_reward": 0.2117264965325594, "critic_loss": 0.3383789123892784, "actor_loss": -63.39326037168503, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.556600093841553, "step": 10000}
{"episode_reward": 301.169574879959, "episode": 11.0, "batch_reward": 0.2137995532900095, "critic_loss": 0.5562529467493296, "actor_loss": -63.4305499663353, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.13678455352783, "step": 11000}
{"episode_reward": 108.98720791639927, "episode": 12.0, "batch_reward": 0.20040500688552856, "critic_loss": 0.6221533275544643, "actor_loss": -63.69092815685272, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.196892023086548, "step": 12000}
{"episode_reward": 66.57977811816929, "episode": 13.0, "batch_reward": 0.1892820549160242, "critic_loss": 0.6715785000920296, "actor_loss": -63.61260862445831, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.466496467590332, "step": 13000}
{"episode_reward": 62.247067554656, "episode": 14.0, "batch_reward": 0.18848608073592185, "critic_loss": 0.8109353897571564, "actor_loss": -64.39119975757599, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.54185962677002, "step": 14000}
{"episode_reward": 418.51526532092623, "episode": 15.0, "batch_reward": 0.1973923733085394, "critic_loss": 0.8486234209537507, "actor_loss": -61.17914716911316, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.96005344390869, "step": 15000}
{"episode_reward": 81.66516749830492, "episode": 16.0, "batch_reward": 0.20064728313684463, "critic_loss": 1.081474287211895, "actor_loss": -65.79436863803863, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.512656211853027, "step": 16000}
{"episode_reward": 463.9831320266259, "episode": 17.0, "batch_reward": 0.20987461486458778, "critic_loss": 1.393286664366722, "actor_loss": -65.06305507469177, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.242753982543945, "step": 17000}
{"episode_reward": 305.15529155069004, "episode": 18.0, "batch_reward": 0.22052843087911606, "critic_loss": 1.9041862087249757, "actor_loss": -66.19291977500916, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.678102493286133, "step": 18000}
{"episode_reward": 471.76122785865556, "episode": 19.0, "batch_reward": 0.2398019454628229, "critic_loss": 2.2366594123244288, "actor_loss": -67.64908617210388, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.50899839401245, "step": 19000}
{"episode_reward": 547.5780743081981, "episode": 20.0, "batch_reward": 0.2522296299636364, "critic_loss": 2.616884871006012, "actor_loss": -65.65382293510437, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.32310938835144, "step": 20000}
{"episode_reward": 343.54907153761224, "episode": 21.0, "batch_reward": 0.2566183952689171, "critic_loss": 2.862067042827606, "actor_loss": -66.86848410987854, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.2327835559845, "step": 21000}
{"episode_reward": 365.71757535560937, "episode": 22.0, "batch_reward": 0.26194177456200124, "critic_loss": 3.310121709704399, "actor_loss": -66.81505840682983, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.286001682281494, "step": 22000}
{"episode_reward": 497.1347301538447, "episode": 23.0, "batch_reward": 0.27088978949189185, "critic_loss": 3.816815522670746, "actor_loss": -68.61505527114868, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.628647565841675, "step": 23000}
{"episode_reward": 347.81145317725776, "episode": 24.0, "batch_reward": 0.26754164688289167, "critic_loss": 3.7100129631757737, "actor_loss": -68.6270844116211, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.389660358428955, "step": 24000}
{"episode_reward": 194.5703243672983, "episode": 25.0, "batch_reward": 0.27337275524437427, "critic_loss": 3.791007951259613, "actor_loss": -70.99349898147582, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.003466844558716, "step": 25000}
{"episode_reward": 581.8613758101219, "episode": 26.0, "batch_reward": 0.2838563391417265, "critic_loss": 3.979167576551437, "actor_loss": -69.94663542938233, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.499123334884644, "step": 26000}
{"episode_reward": 417.2197918203648, "episode": 27.0, "batch_reward": 0.29163089863955977, "critic_loss": 3.8828572874069214, "actor_loss": -70.79221391296387, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.194772720336914, "step": 27000}
{"episode_reward": 641.7909827835982, "episode": 28.0, "batch_reward": 0.3024351014494896, "critic_loss": 4.24475292468071, "actor_loss": -72.12797323226928, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.87266707420349, "step": 28000}
{"episode_reward": 650.8980974999533, "episode": 29.0, "batch_reward": 0.31734018501639366, "critic_loss": 4.332404154539108, "actor_loss": -70.87305911254883, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.56618022918701, "step": 29000}
{"episode_reward": 650.8407894189218, "episode": 30.0, "batch_reward": 0.3278859480321407, "critic_loss": 4.1785959877967835, "actor_loss": -71.47167743682861, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.25677180290222, "step": 30000}
{"episode_reward": 627.8866894891664, "episode": 31.0, "batch_reward": 0.33528087878227236, "critic_loss": 4.189825909852981, "actor_loss": -74.17983331298828, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.83375525474548, "step": 31000}
{"episode_reward": 540.5126876799233, "episode": 32.0, "batch_reward": 0.34440278977155686, "critic_loss": 4.104860812425613, "actor_loss": -73.92688457489014, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.211591243743896, "step": 32000}
{"episode_reward": 426.51076649985947, "episode": 33.0, "batch_reward": 0.34731756055355073, "critic_loss": 4.04018589925766, "actor_loss": -74.28123082733154, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.962477684020996, "step": 33000}
{"episode_reward": 611.3297626754504, "episode": 34.0, "batch_reward": 0.35293769535422326, "critic_loss": 3.965756280899048, "actor_loss": -74.81282001495362, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.517252445220947, "step": 34000}
{"episode_reward": 316.01536023771666, "episode": 35.0, "batch_reward": 0.3549894327521324, "critic_loss": 3.809611922264099, "actor_loss": -74.02785223388672, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.219284296035767, "step": 35000}
{"episode_reward": 694.7361530741777, "episode": 36.0, "batch_reward": 0.3646844388842583, "critic_loss": 3.7757126536369325, "actor_loss": -76.97496915435791, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.518219709396362, "step": 36000}
{"episode_reward": 697.0342300738268, "episode": 37.0, "batch_reward": 0.36929488644003866, "critic_loss": 3.470105784535408, "actor_loss": -75.93806550598144, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.96238899230957, "step": 37000}
{"episode_reward": 283.5926359387683, "episode": 38.0, "batch_reward": 0.36436106422543524, "critic_loss": 3.2291682151556014, "actor_loss": -74.6683406906128, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.680830478668213, "step": 38000}
{"episode_reward": 114.52515233463465, "episode": 39.0, "batch_reward": 0.36209029364585876, "critic_loss": 3.045705003261566, "actor_loss": -76.4346194229126, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.677019596099854, "step": 39000}
{"episode_reward": 365.9071202952945, "episode": 40.0, "batch_reward": 0.3640421569645405, "critic_loss": 2.859951901435852, "actor_loss": -76.51826650238037, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.015801191329956, "step": 40000}
{"episode_reward": 782.1562772488228, "episode": 41.0, "batch_reward": 0.37280558854341506, "critic_loss": 2.789593529820442, "actor_loss": -77.88359983062745, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.73823523521423, "step": 41000}
{"episode_reward": 639.5719633096538, "episode": 42.0, "batch_reward": 0.37637540107965467, "critic_loss": 2.7360550012588503, "actor_loss": -75.38708261871338, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.670168161392212, "step": 42000}
{"episode_reward": 200.4413903020304, "episode": 43.0, "batch_reward": 0.3774293681681156, "critic_loss": 2.6648052977323533, "actor_loss": -77.29503827667236, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.741812467575073, "step": 43000}
{"episode_reward": 736.031752942662, "episode": 44.0, "batch_reward": 0.38600028347969056, "critic_loss": 2.599502386927605, "actor_loss": -77.45381209564209, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.08634042739868, "step": 44000}
{"episode_reward": 790.4435378666168, "episode": 45.0, "batch_reward": 0.39554358619451524, "critic_loss": 2.564597293496132, "actor_loss": -77.34694870758057, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.212729454040527, "step": 45000}
{"episode_reward": 764.9291700889847, "episode": 46.0, "batch_reward": 0.4021298468708992, "critic_loss": 2.503193570137024, "actor_loss": -77.33486755371094, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.17404556274414, "step": 46000}
{"episode_reward": 782.1283170064594, "episode": 47.0, "batch_reward": 0.4100677412748337, "critic_loss": 2.6274178334474563, "actor_loss": -78.40073554992676, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.5343234539032, "step": 47000}
{"episode_reward": 772.1073207035503, "episode": 48.0, "batch_reward": 0.4204823468327522, "critic_loss": 2.504473067879677, "actor_loss": -78.47811274719238, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.20465588569641, "step": 48000}
{"episode_reward": 832.8703838619507, "episode": 49.0, "batch_reward": 0.4274143483042717, "critic_loss": 2.4440197561979295, "actor_loss": -79.09616418457031, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.411852836608887, "step": 49000}
{"episode_reward": 759.2723265219095, "episode": 50.0, "batch_reward": 0.4343334200382233, "critic_loss": 2.3416874910593033, "actor_loss": -78.19846160125732, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.020548582077026, "step": 50000}
{"episode_reward": 568.6705694006417, "episode": 51.0, "batch_reward": 0.4380517252981663, "critic_loss": 2.3737665914297104, "actor_loss": -78.52707103729249, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.65533232688904, "step": 51000}
{"episode_reward": 783.2058459584294, "episode": 52.0, "batch_reward": 0.44374328398704527, "critic_loss": 2.4713703609704973, "actor_loss": -79.78397922515869, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.96045184135437, "step": 52000}
{"episode_reward": 727.3067249100228, "episode": 53.0, "batch_reward": 0.4491390073597431, "critic_loss": 2.3978633242845535, "actor_loss": -78.01115840148925, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.339097023010254, "step": 53000}
{"episode_reward": 781.411221628183, "episode": 54.0, "batch_reward": 0.4554649173915386, "critic_loss": 2.4174038803577425, "actor_loss": -80.54834078979492, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.666640758514404, "step": 54000}
{"episode_reward": 794.5322502676919, "episode": 55.0, "batch_reward": 0.46080333614349367, "critic_loss": 2.4845744140148165, "actor_loss": -79.99878071594239, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.293140411376953, "step": 55000}
{"episode_reward": 622.1055865800157, "episode": 56.0, "batch_reward": 0.4642304197251797, "critic_loss": 2.4564141801595687, "actor_loss": -78.73215953063965, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.36537790298462, "step": 56000}
{"episode_reward": 883.329952219412, "episode": 57.0, "batch_reward": 0.472020016849041, "critic_loss": 2.5534579250812532, "actor_loss": -80.57330312347412, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.625486135482788, "step": 57000}
{"episode_reward": 752.771726251413, "episode": 58.0, "batch_reward": 0.47701223397254944, "critic_loss": 2.603937127828598, "actor_loss": -79.97701952362061, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.245265007019043, "step": 58000}
{"episode_reward": 811.6806066229333, "episode": 59.0, "batch_reward": 0.483179211884737, "critic_loss": 2.51416804087162, "actor_loss": -80.39153499603272, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.21629524230957, "step": 59000}
{"episode_reward": 774.4508137311085, "episode": 60.0, "batch_reward": 0.48620779356360433, "critic_loss": 2.5618642342090605, "actor_loss": -80.44358686828613, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.702861309051514, "step": 60000}
{"episode_reward": 719.8817721451574, "episode": 61.0, "batch_reward": 0.4923861893415451, "critic_loss": 2.5260406782627105, "actor_loss": -81.3712236404419, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.308753967285156, "step": 61000}
{"episode_reward": 839.3000535315807, "episode": 62.0, "batch_reward": 0.4952983760535717, "critic_loss": 2.5327403281927108, "actor_loss": -80.46384103393555, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.82124400138855, "step": 62000}
{"episode_reward": 855.7350062881119, "episode": 63.0, "batch_reward": 0.5014312575757504, "critic_loss": 2.3886565668582915, "actor_loss": -81.02043309783936, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.43759322166443, "step": 63000}
{"episode_reward": 749.7450677243395, "episode": 64.0, "batch_reward": 0.5058988389372826, "critic_loss": 2.3813970460891722, "actor_loss": -81.37500197601318, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.062208652496338, "step": 64000}
{"episode_reward": 722.6365125971308, "episode": 65.0, "batch_reward": 0.5111696349382401, "critic_loss": 2.3695078755617143, "actor_loss": -81.23436638641357, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.72407627105713, "step": 65000}
{"episode_reward": 754.1590008458749, "episode": 66.0, "batch_reward": 0.514802085697651, "critic_loss": 2.3237527203559876, "actor_loss": -81.53032703399658, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.238576650619507, "step": 66000}
{"episode_reward": 901.1830740139957, "episode": 67.0, "batch_reward": 0.5144228759407997, "critic_loss": 2.2251751440763474, "actor_loss": -81.04595673370362, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.64528226852417, "step": 67000}
{"episode_reward": 23.202322473280017, "episode": 68.0, "batch_reward": 0.5120990144908428, "critic_loss": 2.220061128497124, "actor_loss": -81.99016394042968, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.681007862091064, "step": 68000}
{"episode_reward": 823.452149256173, "episode": 69.0, "batch_reward": 0.5172273932993412, "critic_loss": 2.1501306269168854, "actor_loss": -82.25095938873291, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.245959281921387, "step": 69000}
{"episode_reward": 893.622875874316, "episode": 70.0, "batch_reward": 0.523505411118269, "critic_loss": 2.1808613475561143, "actor_loss": -82.490766456604, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.88429570198059, "step": 70000}
{"episode_reward": 797.600516230899, "episode": 71.0, "batch_reward": 0.5242027459740639, "critic_loss": 2.1950599738359453, "actor_loss": -81.69510121917725, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.2123064994812, "step": 71000}
{"episode_reward": 856.4312480672122, "episode": 72.0, "batch_reward": 0.5302331992089748, "critic_loss": 2.164264378786087, "actor_loss": -82.96684967041016, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.993603706359863, "step": 72000}
{"episode_reward": 739.7125550970893, "episode": 73.0, "batch_reward": 0.5325646025240421, "critic_loss": 2.1200013996362688, "actor_loss": -82.88873599243163, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.57622528076172, "step": 73000}
{"episode_reward": 829.6886398763223, "episode": 74.0, "batch_reward": 0.5372851968705654, "critic_loss": 2.063966851353645, "actor_loss": -82.54839747619629, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.273547172546387, "step": 74000}
{"episode_reward": 829.8589609908009, "episode": 75.0, "batch_reward": 0.5415821193158626, "critic_loss": 2.094675016880035, "actor_loss": -83.29041362762452, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.32873272895813, "step": 75000}
{"episode_reward": 808.2635316747256, "episode": 76.0, "batch_reward": 0.5470473838746548, "critic_loss": 2.054016361117363, "actor_loss": -83.07065745544433, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.86557960510254, "step": 76000}
{"episode_reward": 874.0004810710278, "episode": 77.0, "batch_reward": 0.5500048543214798, "critic_loss": 2.043275411963463, "actor_loss": -82.98383522796631, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.204996585845947, "step": 77000}
{"episode_reward": 830.8115441964003, "episode": 78.0, "batch_reward": 0.549407764673233, "critic_loss": 2.1065825144052504, "actor_loss": -82.58350651550293, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.142493724822998, "step": 78000}
{"episode_reward": 99.03683408362163, "episode": 79.0, "batch_reward": 0.546979838013649, "critic_loss": 2.009619959652424, "actor_loss": -83.25602185058594, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.613390684127808, "step": 79000}
{"episode_reward": 834.9788094917565, "episode": 80.0, "batch_reward": 0.5501010033786297, "critic_loss": 2.031954735517502, "actor_loss": -83.44209153747559, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.559627294540405, "step": 80000}
{"episode_reward": 880.4032402169966, "episode": 81.0, "batch_reward": 0.556053666383028, "critic_loss": 1.943422568321228, "actor_loss": -83.57143337249755, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.89786958694458, "step": 81000}
{"episode_reward": 818.9579552170416, "episode": 82.0, "batch_reward": 0.5566117899119853, "critic_loss": 1.9922495402097702, "actor_loss": -83.3890780029297, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.957548141479492, "step": 82000}
{"episode_reward": 806.3750431538692, "episode": 83.0, "batch_reward": 0.5603913550078868, "critic_loss": 1.9782810800075532, "actor_loss": -83.65031791687012, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.572612285614014, "step": 83000}
{"episode_reward": 844.064148322002, "episode": 84.0, "batch_reward": 0.562915130674839, "critic_loss": 2.0639111011624336, "actor_loss": -84.582846534729, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.61820340156555, "step": 84000}
{"episode_reward": 816.113044720788, "episode": 85.0, "batch_reward": 0.5657492364346981, "critic_loss": 2.090605308532715, "actor_loss": -83.99616767120361, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.291234254837036, "step": 85000}
{"episode_reward": 818.7796095795676, "episode": 86.0, "batch_reward": 0.5712136218249798, "critic_loss": 1.9268343786001205, "actor_loss": -84.49604120635986, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.183764696121216, "step": 86000}
{"episode_reward": 866.8477236423996, "episode": 87.0, "batch_reward": 0.5743602922260761, "critic_loss": 1.9969020253419876, "actor_loss": -84.4958012008667, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.93848752975464, "step": 87000}
{"episode_reward": 803.8452408319783, "episode": 88.0, "batch_reward": 0.5788901354670525, "critic_loss": 1.9939938760995866, "actor_loss": -84.75612725067138, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.858205556869507, "step": 88000}
{"episode_reward": 850.6864681462984, "episode": 89.0, "batch_reward": 0.5769989565610886, "critic_loss": 2.0769255194664002, "actor_loss": -84.14246718597413, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.32554602622986, "step": 89000}
{"episode_reward": 592.7761956782659, "episode": 90.0, "batch_reward": 0.5804293768703938, "critic_loss": 2.134373303771019, "actor_loss": -84.35899181365967, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.554874181747437, "step": 90000}
{"episode_reward": 927.1495701215537, "episode": 91.0, "batch_reward": 0.5846250355541706, "critic_loss": 2.0427437850236894, "actor_loss": -84.12381442260742, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.858442068099976, "step": 91000}
{"episode_reward": 864.0300040844123, "episode": 92.0, "batch_reward": 0.5887169295847416, "critic_loss": 2.0226797674298287, "actor_loss": -84.35017315673828, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.603626251220703, "step": 92000}
{"episode_reward": 886.5540339673524, "episode": 93.0, "batch_reward": 0.5912614886164665, "critic_loss": 1.9427911373972893, "actor_loss": -85.26739797210693, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.76201367378235, "step": 93000}
{"episode_reward": 916.697699617311, "episode": 94.0, "batch_reward": 0.5943730826973915, "critic_loss": 2.0502169922590254, "actor_loss": -85.21837335968017, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.486939907073975, "step": 94000}
{"episode_reward": 864.3408391917857, "episode": 95.0, "batch_reward": 0.5966273287534714, "critic_loss": 1.9582998992800713, "actor_loss": -85.40538495635987, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.720996618270874, "step": 95000}
{"episode_reward": 876.5261751013, "episode": 96.0, "batch_reward": 0.5985840242505074, "critic_loss": 1.920084435582161, "actor_loss": -85.00267440795898, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.448679447174072, "step": 96000}
{"episode_reward": 845.5665476444964, "episode": 97.0, "batch_reward": 0.6006378234624863, "critic_loss": 1.9809806379675865, "actor_loss": -85.51824761199951, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.814645290374756, "step": 97000}
{"episode_reward": 756.8576638073635, "episode": 98.0, "batch_reward": 0.6034029828906059, "critic_loss": 2.0244787402153017, "actor_loss": -85.6406813583374, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.615008115768433, "step": 98000}
{"episode_reward": 841.0745304798712, "episode": 99.0, "batch_reward": 0.6074919346570968, "critic_loss": 2.0734374665617943, "actor_loss": -85.49361138916015, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.268654108047485, "step": 99000}
{"episode_reward": 879.0523125948938, "episode": 100.0, "batch_reward": 0.605527515232563, "critic_loss": 2.0043564016222954, "actor_loss": -86.08031120300294, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.47697901725769, "step": 100000}
{"episode_reward": 818.724222269693, "episode": 101.0, "batch_reward": 0.6116140262484551, "critic_loss": 2.0128026463985442, "actor_loss": -86.05839183044434, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.954102754592896, "step": 101000}
{"episode_reward": 930.0591165189564, "episode": 102.0, "batch_reward": 0.6133316569924354, "critic_loss": 2.0046710032820703, "actor_loss": -86.60968404388427, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.42866325378418, "step": 102000}
{"episode_reward": 846.9895934913958, "episode": 103.0, "batch_reward": 0.6158868290781975, "critic_loss": 2.1604286639690398, "actor_loss": -85.26832644653321, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.588233709335327, "step": 103000}
{"episode_reward": 754.1078889676129, "episode": 104.0, "batch_reward": 0.6174847342967987, "critic_loss": 2.0480032718777657, "actor_loss": -86.06165894317627, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.27565026283264, "step": 104000}
{"episode_reward": 887.7853430572676, "episode": 105.0, "batch_reward": 0.6218668477535247, "critic_loss": 2.103846132397652, "actor_loss": -85.75300617980957, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.3282573223114, "step": 105000}
{"episode_reward": 905.3820249162774, "episode": 106.0, "batch_reward": 0.6223188591599464, "critic_loss": 2.0914981805086135, "actor_loss": -86.81483605957031, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.302327871322632, "step": 106000}
{"episode_reward": 853.377734234889, "episode": 107.0, "batch_reward": 0.6255249361991883, "critic_loss": 2.0847426956892012, "actor_loss": -86.8460403289795, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.16643500328064, "step": 107000}
{"episode_reward": 716.0642211046526, "episode": 108.0, "batch_reward": 0.6241454050540924, "critic_loss": 2.0405579418540003, "actor_loss": -86.00859538269043, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.963305234909058, "step": 108000}
{"episode_reward": 881.9954000380507, "episode": 109.0, "batch_reward": 0.6274018886685372, "critic_loss": 2.041354179084301, "actor_loss": -86.65576321411133, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.3873929977417, "step": 109000}
{"episode_reward": 883.1999208834704, "episode": 110.0, "batch_reward": 0.628478750884533, "critic_loss": 2.07544343572855, "actor_loss": -86.4761376953125, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.247785806655884, "step": 110000}
{"episode_reward": 401.68815241138844, "episode": 111.0, "batch_reward": 0.6283952419757843, "critic_loss": 2.0153145096302034, "actor_loss": -86.15712382507324, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.91595149040222, "step": 111000}
{"episode_reward": 875.870365502564, "episode": 112.0, "batch_reward": 0.6304691341519356, "critic_loss": 2.000927576601505, "actor_loss": -86.74084280395508, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.221633434295654, "step": 112000}
{"episode_reward": 821.6673603188917, "episode": 113.0, "batch_reward": 0.633112251341343, "critic_loss": 2.1926341053247453, "actor_loss": -87.04859980773925, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.56722092628479, "step": 113000}
{"episode_reward": 798.9619775560462, "episode": 114.0, "batch_reward": 0.63165493029356, "critic_loss": 2.158801605820656, "actor_loss": -87.04657554626465, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.665875673294067, "step": 114000}
{"episode_reward": 824.9945579229799, "episode": 115.0, "batch_reward": 0.6337300939559937, "critic_loss": 2.1541563758850097, "actor_loss": -86.50123063659667, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.225403308868408, "step": 115000}
{"episode_reward": 723.9636897249912, "episode": 116.0, "batch_reward": 0.6384761171936989, "critic_loss": 2.088258226156235, "actor_loss": -86.84953793334961, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.696004629135132, "step": 116000}
{"episode_reward": 842.4265120256048, "episode": 117.0, "batch_reward": 0.6372054721713066, "critic_loss": 2.055406763613224, "actor_loss": -85.98674719238281, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.538906574249268, "step": 117000}
{"episode_reward": 868.4230728508901, "episode": 118.0, "batch_reward": 0.6410377987027168, "critic_loss": 2.0474505425691603, "actor_loss": -86.6313098449707, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.217583656311035, "step": 118000}
{"episode_reward": 904.1377358217945, "episode": 119.0, "batch_reward": 0.6437767857313156, "critic_loss": 1.8819906280636787, "actor_loss": -86.71546717834472, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.593755960464478, "step": 119000}
{"episode_reward": 891.139634299995, "episode": 120.0, "batch_reward": 0.6433643239140511, "critic_loss": 1.8765090647339822, "actor_loss": -86.76044766235351, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.692238569259644, "step": 120000}
{"episode_reward": 876.4939699871319, "episode": 121.0, "batch_reward": 0.645759815812111, "critic_loss": 1.8743195766210556, "actor_loss": -86.83428936767578, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.55606031417847, "step": 121000}
{"episode_reward": 867.4931817278627, "episode": 122.0, "batch_reward": 0.6491264408230781, "critic_loss": 1.8838736850619315, "actor_loss": -87.36775080871583, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.67316174507141, "step": 122000}
{"episode_reward": 809.1284306870209, "episode": 123.0, "batch_reward": 0.6490823038220406, "critic_loss": 1.9288716134428978, "actor_loss": -87.71001954650879, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.615966796875, "step": 123000}
{"episode_reward": 884.5285706057634, "episode": 124.0, "batch_reward": 0.6511559902429581, "critic_loss": 1.8595852810740472, "actor_loss": -87.5625725402832, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.222631454467773, "step": 124000}
{"episode_reward": 878.5565493072938, "episode": 125.0, "batch_reward": 0.6522723181247712, "critic_loss": 1.9245455029010772, "actor_loss": -87.55848968505859, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.493518352508545, "step": 125000}
{"episode_reward": 817.2959774121459, "episode": 126.0, "batch_reward": 0.6562077313065529, "critic_loss": 1.9454308426976203, "actor_loss": -87.10664428710938, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.191092491149902, "step": 126000}
{"episode_reward": 856.3613833431336, "episode": 127.0, "batch_reward": 0.654619324862957, "critic_loss": 1.9552800563573838, "actor_loss": -86.83922639465332, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.213024854660034, "step": 127000}
{"episode_reward": 878.0608298270328, "episode": 128.0, "batch_reward": 0.6559758811593056, "critic_loss": 1.9077160533070565, "actor_loss": -87.12505831909179, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.36870002746582, "step": 128000}
{"episode_reward": 820.9523131018233, "episode": 129.0, "batch_reward": 0.6602828701734543, "critic_loss": 1.916569478869438, "actor_loss": -87.49456298828125, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.562535047531128, "step": 129000}
{"episode_reward": 951.2627427164588, "episode": 130.0, "batch_reward": 0.6625313116908074, "critic_loss": 1.9124723443388938, "actor_loss": -87.31212217712402, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.534218788146973, "step": 130000}
{"episode_reward": 828.9325199782056, "episode": 131.0, "batch_reward": 0.6618955806493759, "critic_loss": 1.8894957128167151, "actor_loss": -87.72710757446289, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.69534397125244, "step": 131000}
{"episode_reward": 886.1407994079892, "episode": 132.0, "batch_reward": 0.6637847687005997, "critic_loss": 2.0079414935708044, "actor_loss": -88.24685163879394, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.196531772613525, "step": 132000}
{"episode_reward": 807.8141537270839, "episode": 133.0, "batch_reward": 0.6656776865124703, "critic_loss": 1.9653813589215279, "actor_loss": -87.93757151794433, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.134616136550903, "step": 133000}
{"episode_reward": 919.4022621574002, "episode": 134.0, "batch_reward": 0.668527937233448, "critic_loss": 2.0471823273301126, "actor_loss": -87.66881980895997, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.811026096343994, "step": 134000}
{"episode_reward": 811.3419599105669, "episode": 135.0, "batch_reward": 0.6689336903691292, "critic_loss": 1.9120905802845956, "actor_loss": -87.51416072082519, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.205023765563965, "step": 135000}
{"episode_reward": 873.6943123406714, "episode": 136.0, "batch_reward": 0.6701573647260666, "critic_loss": 1.971627474784851, "actor_loss": -87.28264671325684, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.254916191101074, "step": 136000}
{"episode_reward": 879.1513591346383, "episode": 137.0, "batch_reward": 0.6704200002551078, "critic_loss": 1.9217535275816917, "actor_loss": -88.3949533996582, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.27503204345703, "step": 137000}
{"episode_reward": 898.9364632556401, "episode": 138.0, "batch_reward": 0.6746157810688019, "critic_loss": 1.9433681098222733, "actor_loss": -88.19145043945312, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.214387893676758, "step": 138000}
{"episode_reward": 898.185216441713, "episode": 139.0, "batch_reward": 0.6738754204511642, "critic_loss": 1.8931347380280494, "actor_loss": -87.85831489562989, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.243013620376587, "step": 139000}
{"episode_reward": 249.60778887767, "episode": 140.0, "batch_reward": 0.6729283815026283, "critic_loss": 1.914894207715988, "actor_loss": -87.89384443664551, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.624053239822388, "step": 140000}
{"episode_reward": 768.7178098079432, "episode": 141.0, "batch_reward": 0.6701106729507447, "critic_loss": 1.902340530872345, "actor_loss": -88.10631661987304, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.911250829696655, "step": 141000}
{"episode_reward": 848.9442994404307, "episode": 142.0, "batch_reward": 0.6719480975866318, "critic_loss": 1.8873497835993767, "actor_loss": -87.18654196166992, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.37535047531128, "step": 142000}
{"episode_reward": 917.1727595463161, "episode": 143.0, "batch_reward": 0.6747262666225433, "critic_loss": 1.8453775720596313, "actor_loss": -87.56890277099609, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.236867427825928, "step": 143000}
{"episode_reward": 840.2001901854504, "episode": 144.0, "batch_reward": 0.6769396190643311, "critic_loss": 1.793446155190468, "actor_loss": -88.111484085083, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.33076763153076, "step": 144000}
{"episode_reward": 883.1185524392301, "episode": 145.0, "batch_reward": 0.6794492092132568, "critic_loss": 1.880546432197094, "actor_loss": -88.65375942993164, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.837112188339233, "step": 145000}
{"episode_reward": 822.685668633361, "episode": 146.0, "batch_reward": 0.6776007896661759, "critic_loss": 1.9381970756053926, "actor_loss": -88.48543304443359, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.18145203590393, "step": 146000}
{"episode_reward": 905.1665984744044, "episode": 147.0, "batch_reward": 0.6815153478980064, "critic_loss": 1.9220301815867424, "actor_loss": -88.04339291381837, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.42385721206665, "step": 147000}
{"episode_reward": 890.374747994538, "episode": 148.0, "batch_reward": 0.6811769015789032, "critic_loss": 1.958100089609623, "actor_loss": -88.74523561096191, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.33510184288025, "step": 148000}
{"episode_reward": 868.9148266959382, "episode": 149.0, "batch_reward": 0.6820197443962097, "critic_loss": 1.9767248722910882, "actor_loss": -87.96914361572266, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.252805948257446, "step": 149000}
{"episode_reward": 948.0250713854863, "episode": 150.0, "batch_reward": 0.6845925849676132, "critic_loss": 1.8362468049526215, "actor_loss": -88.6741764831543, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "step": 150000}
