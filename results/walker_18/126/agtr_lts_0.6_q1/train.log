{"episode_reward": 0.0, "episode": 1.0, "duration": 22.87526535987854, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 2.279566764831543, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.46591030590412574, "critic_loss": 0.23919128917627194, "actor_loss": -83.58302352007698, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 68.44877552986145, "step": 3000}
{"episode_reward": 510.39769488306695, "episode": 4.0, "batch_reward": 0.48322672870755196, "critic_loss": 0.5454227416068316, "actor_loss": -83.35666554260254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.77772617340088, "step": 4000}
{"episode_reward": 554.526363900783, "episode": 5.0, "batch_reward": 0.5082868755459785, "critic_loss": 0.8021303868889809, "actor_loss": -84.00427561950684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.628071784973145, "step": 5000}
{"episode_reward": 638.0375371648998, "episode": 6.0, "batch_reward": 0.5404897516965866, "critic_loss": 1.0766758090257644, "actor_loss": -84.60417590332031, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.86290693283081, "step": 6000}
{"episode_reward": 724.2834158638367, "episode": 7.0, "batch_reward": 0.5707967855632305, "critic_loss": 1.3007169976234436, "actor_loss": -85.45037496948243, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.98617649078369, "step": 7000}
{"episode_reward": 766.6490377472521, "episode": 8.0, "batch_reward": 0.6012629205286503, "critic_loss": 1.5327559182047843, "actor_loss": -86.54774598693848, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.099165439605713, "step": 8000}
{"episode_reward": 762.0498723212137, "episode": 9.0, "batch_reward": 0.6180224828720092, "critic_loss": 1.784794898033142, "actor_loss": -86.7994591369629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.139103174209595, "step": 9000}
{"episode_reward": 684.5228241687458, "episode": 10.0, "batch_reward": 0.5924880140721798, "critic_loss": 1.797061930656433, "actor_loss": -86.16144485473633, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.761932849884033, "step": 10000}
{"episode_reward": 87.86791036192373, "episode": 11.0, "batch_reward": 0.576101080328226, "critic_loss": 1.7266603534817695, "actor_loss": -85.37029725646973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.43611168861389, "step": 11000}
{"episode_reward": 805.2050180271502, "episode": 12.0, "batch_reward": 0.5807911791801452, "critic_loss": 1.8705767728090286, "actor_loss": -85.43682479858398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.803171396255493, "step": 12000}
{"episode_reward": 560.8257851108646, "episode": 13.0, "batch_reward": 0.594050089776516, "critic_loss": 1.878288241624832, "actor_loss": -85.3240470123291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.507086038589478, "step": 13000}
{"episode_reward": 817.2618166090666, "episode": 14.0, "batch_reward": 0.6078743137419224, "critic_loss": 1.653867312371731, "actor_loss": -85.71837594604492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.899132013320923, "step": 14000}
{"episode_reward": 850.8911339534693, "episode": 15.0, "batch_reward": 0.6266170010566712, "critic_loss": 1.4833988047838211, "actor_loss": -85.30499153137207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.792149305343628, "step": 15000}
{"episode_reward": 854.1613128415576, "episode": 16.0, "batch_reward": 0.6402619278430939, "critic_loss": 1.3731125473976136, "actor_loss": -86.40975262451173, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.649661779403687, "step": 16000}
{"episode_reward": 888.4589956082161, "episode": 17.0, "batch_reward": 0.6560849047899247, "critic_loss": 1.2361573350429536, "actor_loss": -86.41927194213868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.091434240341187, "step": 17000}
{"episode_reward": 813.6001358938973, "episode": 18.0, "batch_reward": 0.6645314887166023, "critic_loss": 1.188553440093994, "actor_loss": -86.60447637939453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.552024841308594, "step": 18000}
{"episode_reward": 854.9177027639879, "episode": 19.0, "batch_reward": 0.6777630135416984, "critic_loss": 1.1603827384710312, "actor_loss": -87.07590570068359, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.04787540435791, "step": 19000}
{"episode_reward": 874.5445114301921, "episode": 20.0, "batch_reward": 0.6850320815443992, "critic_loss": 1.219576840698719, "actor_loss": -86.1777201385498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.707751512527466, "step": 20000}
{"episode_reward": 790.7745279244606, "episode": 21.0, "batch_reward": 0.6889069331884384, "critic_loss": 1.2504526771306992, "actor_loss": -86.85680992126464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.5963978767395, "step": 21000}
{"episode_reward": 800.4820866223527, "episode": 22.0, "batch_reward": 0.6936261777877808, "critic_loss": 1.3229356945753097, "actor_loss": -86.58445486450195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.883891344070435, "step": 22000}
{"episode_reward": 766.1940347873274, "episode": 23.0, "batch_reward": 0.6974107947945595, "critic_loss": 1.32510087287426, "actor_loss": -86.7870961303711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.98128318786621, "step": 23000}
{"episode_reward": 875.434264380265, "episode": 24.0, "batch_reward": 0.7068735176920891, "critic_loss": 1.2917628887295722, "actor_loss": -87.03863835144043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.349634408950806, "step": 24000}
{"episode_reward": 904.1022819407642, "episode": 25.0, "batch_reward": 0.7125999938845634, "critic_loss": 1.3247222365736961, "actor_loss": -87.17053846740723, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.181740045547485, "step": 25000}
{"episode_reward": 821.6684687820973, "episode": 26.0, "batch_reward": 0.7206335509419441, "critic_loss": 1.292677988231182, "actor_loss": -87.72270854187012, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.117952823638916, "step": 26000}
{"episode_reward": 890.808864893301, "episode": 27.0, "batch_reward": 0.7283533350229263, "critic_loss": 1.2319903393387794, "actor_loss": -87.58027000427246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.007736921310425, "step": 27000}
{"episode_reward": 921.035733808524, "episode": 28.0, "batch_reward": 0.7344275809526444, "critic_loss": 1.1277115354537963, "actor_loss": -87.97481640625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.196175813674927, "step": 28000}
{"episode_reward": 918.673485216693, "episode": 29.0, "batch_reward": 0.740014841914177, "critic_loss": 1.0744716121554374, "actor_loss": -87.85417155456543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.512628078460693, "step": 29000}
{"episode_reward": 900.989504757442, "episode": 30.0, "batch_reward": 0.7444267911911011, "critic_loss": 1.0274531425833702, "actor_loss": -87.86240588378907, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.314898252487183, "step": 30000}
{"episode_reward": 895.4677376738719, "episode": 31.0, "batch_reward": 0.7476874724626541, "critic_loss": 1.014557693719864, "actor_loss": -88.33158253479004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.16555857658386, "step": 31000}
{"episode_reward": 854.6156391810788, "episode": 32.0, "batch_reward": 0.7544523921608924, "critic_loss": 0.9839824309945107, "actor_loss": -88.5619033050537, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.687052488327026, "step": 32000}
{"episode_reward": 892.0484023268882, "episode": 33.0, "batch_reward": 0.757704162478447, "critic_loss": 0.9011961316764354, "actor_loss": -88.52783531188965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.099004983901978, "step": 33000}
{"episode_reward": 884.3259256949007, "episode": 34.0, "batch_reward": 0.7617154499292373, "critic_loss": 0.8855715173780918, "actor_loss": -89.05659521484375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.022085428237915, "step": 34000}
{"episode_reward": 930.0422526970718, "episode": 35.0, "batch_reward": 0.7667292705178261, "critic_loss": 0.866582066565752, "actor_loss": -88.88359053039551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.430005073547363, "step": 35000}
{"episode_reward": 931.5750885123, "episode": 36.0, "batch_reward": 0.7710078775286674, "critic_loss": 0.8346582704484463, "actor_loss": -89.64925617980957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.054610013961792, "step": 36000}
{"episode_reward": 880.6969824751997, "episode": 37.0, "batch_reward": 0.7748699280023574, "critic_loss": 0.8469259080886841, "actor_loss": -89.47141624450684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.819217443466187, "step": 37000}
{"episode_reward": 898.5294519880042, "episode": 38.0, "batch_reward": 0.7800689788460732, "critic_loss": 0.8532281107604504, "actor_loss": -89.1659567565918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.844855070114136, "step": 38000}
{"episode_reward": 931.1304513195028, "episode": 39.0, "batch_reward": 0.7827323718667031, "critic_loss": 0.8164050733745098, "actor_loss": -89.76158219909668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.942508459091187, "step": 39000}
{"episode_reward": 937.7672255041097, "episode": 40.0, "batch_reward": 0.7837386195063591, "critic_loss": 0.8323999238610268, "actor_loss": -90.05567324829101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.593679904937744, "step": 40000}
{"episode_reward": 910.5383101794672, "episode": 41.0, "batch_reward": 0.7882086439132691, "critic_loss": 0.7850592440962791, "actor_loss": -90.33816149902344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 43.99247670173645, "step": 41000}
{"episode_reward": 921.7986526966653, "episode": 42.0, "batch_reward": 0.792474821805954, "critic_loss": 0.7811916899383068, "actor_loss": -90.06692652893067, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.598047733306885, "step": 42000}
{"episode_reward": 969.8272286531259, "episode": 43.0, "batch_reward": 0.7965828186869621, "critic_loss": 0.7638915637135506, "actor_loss": -90.59527035522461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.965060234069824, "step": 43000}
{"episode_reward": 895.0711179902386, "episode": 44.0, "batch_reward": 0.7992929075360298, "critic_loss": 0.7918155600726604, "actor_loss": -90.28498565673829, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.568293809890747, "step": 44000}
{"episode_reward": 925.3877531548469, "episode": 45.0, "batch_reward": 0.8011654076576233, "critic_loss": 0.7679884023666382, "actor_loss": -90.29614822387695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.520126819610596, "step": 45000}
{"episode_reward": 925.4167725563799, "episode": 46.0, "batch_reward": 0.8041385544538497, "critic_loss": 0.7540268530845642, "actor_loss": -90.86706602478027, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.993640661239624, "step": 46000}
{"episode_reward": 892.6859836802367, "episode": 47.0, "batch_reward": 0.8063217036724091, "critic_loss": 0.739611559510231, "actor_loss": -91.07528302001953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.463217735290527, "step": 47000}
{"episode_reward": 931.2791886042394, "episode": 48.0, "batch_reward": 0.8056480773687362, "critic_loss": 0.731022372096777, "actor_loss": -91.12683683776855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.278499603271484, "step": 48000}
{"episode_reward": 753.9304862880919, "episode": 49.0, "batch_reward": 0.8087806880474091, "critic_loss": 0.7051995887458324, "actor_loss": -91.27096484375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.56995415687561, "step": 49000}
{"episode_reward": 923.0094883968991, "episode": 50.0, "batch_reward": 0.8100900651216507, "critic_loss": 0.7398670011758804, "actor_loss": -91.05150489807129, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.11103868484497, "step": 50000}
{"episode_reward": 865.6257443716742, "episode": 51.0, "batch_reward": 0.8111730847358704, "critic_loss": 0.7633492751121521, "actor_loss": -91.05553436279297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.60865879058838, "step": 51000}
{"episode_reward": 876.9494033740663, "episode": 52.0, "batch_reward": 0.8116767850518226, "critic_loss": 0.7408215910792351, "actor_loss": -91.35017974853515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.251739978790283, "step": 52000}
{"episode_reward": 887.0887227746135, "episode": 53.0, "batch_reward": 0.8133111251592636, "critic_loss": 0.7593856289982795, "actor_loss": -90.80183067321778, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.344024896621704, "step": 53000}
{"episode_reward": 876.9412108789751, "episode": 54.0, "batch_reward": 0.8158193783164024, "critic_loss": 0.7643601283431053, "actor_loss": -91.61241136169434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.113301038742065, "step": 54000}
{"episode_reward": 908.7330172134248, "episode": 55.0, "batch_reward": 0.815260501563549, "critic_loss": 0.7867049821913242, "actor_loss": -91.43246228027344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.435410976409912, "step": 55000}
{"episode_reward": 828.3166181315338, "episode": 56.0, "batch_reward": 0.8167500463724137, "critic_loss": 0.7789027904272079, "actor_loss": -91.14729296875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.97838807106018, "step": 56000}
{"episode_reward": 967.1311311992749, "episode": 57.0, "batch_reward": 0.8187933669686317, "critic_loss": 0.7694165114164352, "actor_loss": -91.33702110290527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.504891872406006, "step": 57000}
{"episode_reward": 895.8468895625557, "episode": 58.0, "batch_reward": 0.8195944187641144, "critic_loss": 0.7481598487496376, "actor_loss": -91.47329397583007, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.218947172164917, "step": 58000}
{"episode_reward": 909.0880735800692, "episode": 59.0, "batch_reward": 0.8188197925686836, "critic_loss": 0.7917289395630359, "actor_loss": -91.39905096435547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.846500635147095, "step": 59000}
{"episode_reward": 320.1171689644779, "episode": 60.0, "batch_reward": 0.8136816929578781, "critic_loss": 0.8777560966908932, "actor_loss": -91.28612351989746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.633132934570312, "step": 60000}
{"episode_reward": 907.0230566981314, "episode": 61.0, "batch_reward": 0.8151761830449105, "critic_loss": 0.8641879741251469, "actor_loss": -91.46551083374024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.7478301525116, "step": 61000}
{"episode_reward": 863.6417190229473, "episode": 62.0, "batch_reward": 0.8152480491399765, "critic_loss": 0.8544436228573322, "actor_loss": -91.03045739746094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.401068687438965, "step": 62000}
{"episode_reward": 965.6881622671056, "episode": 63.0, "batch_reward": 0.8154412079453468, "critic_loss": 0.904477710723877, "actor_loss": -91.0126946105957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.559906005859375, "step": 63000}
{"episode_reward": 827.6074040900871, "episode": 64.0, "batch_reward": 0.8183933685421944, "critic_loss": 0.8881539650559426, "actor_loss": -91.33384213256836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.36691427230835, "step": 64000}
{"episode_reward": 929.0385174745694, "episode": 65.0, "batch_reward": 0.8207610040903092, "critic_loss": 0.9169484329819679, "actor_loss": -91.17763735961914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.81817078590393, "step": 65000}
{"episode_reward": 930.1250841179725, "episode": 66.0, "batch_reward": 0.8227811424136162, "critic_loss": 0.9229732302129269, "actor_loss": -91.40527537536622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.32488751411438, "step": 66000}
{"episode_reward": 930.6909915098166, "episode": 67.0, "batch_reward": 0.8255765770077705, "critic_loss": 0.8605495396256447, "actor_loss": -91.40088873291016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.4736008644104, "step": 67000}
{"episode_reward": 945.4266336301944, "episode": 68.0, "batch_reward": 0.8248602691292762, "critic_loss": 0.8345543382167816, "actor_loss": -91.6491551361084, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.706883430480957, "step": 68000}
{"episode_reward": 950.2495003666036, "episode": 69.0, "batch_reward": 0.8282737638950348, "critic_loss": 0.8511160134673118, "actor_loss": -91.76943603515625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.943389654159546, "step": 69000}
{"episode_reward": 957.4719122506268, "episode": 70.0, "batch_reward": 0.8292932953834534, "critic_loss": 0.8441029628813267, "actor_loss": -92.10700415039062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.83689260482788, "step": 70000}
{"episode_reward": 885.7097085397126, "episode": 71.0, "batch_reward": 0.8296548276543617, "critic_loss": 0.8547193095982075, "actor_loss": -91.58245726013183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 45.76094937324524, "step": 71000}
{"episode_reward": 898.9139702142902, "episode": 72.0, "batch_reward": 0.8318589343428612, "critic_loss": 0.873725851714611, "actor_loss": -91.98890757751465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.515169620513916, "step": 72000}
{"episode_reward": 907.3231745332668, "episode": 73.0, "batch_reward": 0.8312588323950767, "critic_loss": 0.8191459352076054, "actor_loss": -91.94615919494629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.37055468559265, "step": 73000}
{"episode_reward": 935.7670659539763, "episode": 74.0, "batch_reward": 0.833750459432602, "critic_loss": 0.8030185521841049, "actor_loss": -92.02606504821777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.51094913482666, "step": 74000}
{"episode_reward": 936.1013992524697, "episode": 75.0, "batch_reward": 0.8364618484377861, "critic_loss": 0.7910851925313472, "actor_loss": -92.17846063232422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.65665578842163, "step": 75000}
{"episode_reward": 952.8849854468368, "episode": 76.0, "batch_reward": 0.8364370527267456, "critic_loss": 0.8123464711308479, "actor_loss": -92.26859703063965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.001678943634033, "step": 76000}
{"episode_reward": 874.8304680606932, "episode": 77.0, "batch_reward": 0.8370169287323952, "critic_loss": 0.7751313495635986, "actor_loss": -92.29039707946778, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.913730144500732, "step": 77000}
{"episode_reward": 965.1903650312759, "episode": 78.0, "batch_reward": 0.8390206431150437, "critic_loss": 0.7397556129097939, "actor_loss": -92.25210714721679, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.072048664093018, "step": 78000}
{"episode_reward": 953.0080760801083, "episode": 79.0, "batch_reward": 0.8386172003746033, "critic_loss": 0.7596302731633187, "actor_loss": -92.37622239685058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.48526620864868, "step": 79000}
{"episode_reward": 925.2451017933358, "episode": 80.0, "batch_reward": 0.8418407324552536, "critic_loss": 0.7368601714372635, "actor_loss": -92.51282809448242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.264798641204834, "step": 80000}
{"episode_reward": 939.4227301952287, "episode": 81.0, "batch_reward": 0.8411492208242416, "critic_loss": 0.7439170376062393, "actor_loss": -92.38435499572753, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.560272455215454, "step": 81000}
{"episode_reward": 901.5746870296077, "episode": 82.0, "batch_reward": 0.8423649787306785, "critic_loss": 0.7494325390160084, "actor_loss": -92.44778163146972, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.763944387435913, "step": 82000}
{"episode_reward": 901.2923155966524, "episode": 83.0, "batch_reward": 0.8440808048844337, "critic_loss": 0.719836998283863, "actor_loss": -92.7412631072998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.53392267227173, "step": 83000}
{"episode_reward": 928.5040863815792, "episode": 84.0, "batch_reward": 0.8448831194043159, "critic_loss": 0.7409609528779983, "actor_loss": -92.94241203308106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.059905290603638, "step": 84000}
{"episode_reward": 896.0828070988211, "episode": 85.0, "batch_reward": 0.8439113271832466, "critic_loss": 0.7200992936789989, "actor_loss": -92.56979557800292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.47442317008972, "step": 85000}
{"episode_reward": 931.9024019464057, "episode": 86.0, "batch_reward": 0.8467861125469208, "critic_loss": 0.7267904061377048, "actor_loss": -92.6746591796875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.581484079360962, "step": 86000}
{"episode_reward": 942.608218020939, "episode": 87.0, "batch_reward": 0.8472728108763695, "critic_loss": 0.6990933894515038, "actor_loss": -92.85121307373046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.94630217552185, "step": 87000}
{"episode_reward": 925.9593322359027, "episode": 88.0, "batch_reward": 0.8478994547724724, "critic_loss": 0.6818098983317613, "actor_loss": -93.01525253295898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.050240755081177, "step": 88000}
{"episode_reward": 974.0307061882389, "episode": 89.0, "batch_reward": 0.8493977704048157, "critic_loss": 0.6893655507564544, "actor_loss": -92.81337719726562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.564146280288696, "step": 89000}
{"episode_reward": 934.0976896582648, "episode": 90.0, "batch_reward": 0.8512543457150459, "critic_loss": 0.6879333011209965, "actor_loss": -93.02563203430176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.93336534500122, "step": 90000}
{"episode_reward": 956.0577433006243, "episode": 91.0, "batch_reward": 0.851813068807125, "critic_loss": 0.6916516005396843, "actor_loss": -92.95698094177246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.3439302444458, "step": 91000}
{"episode_reward": 894.184566845826, "episode": 92.0, "batch_reward": 0.853177554666996, "critic_loss": 0.7255744099318981, "actor_loss": -92.94895422363281, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.65767765045166, "step": 92000}
{"episode_reward": 936.8623000663914, "episode": 93.0, "batch_reward": 0.854491720020771, "critic_loss": 0.689009561792016, "actor_loss": -93.0254271697998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.395933866500854, "step": 93000}
{"episode_reward": 958.6842938381882, "episode": 94.0, "batch_reward": 0.8560240123271942, "critic_loss": 0.6639285833537578, "actor_loss": -93.19157737731933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.252092599868774, "step": 94000}
{"episode_reward": 934.9525985315961, "episode": 95.0, "batch_reward": 0.8550210207104683, "critic_loss": 0.697316151857376, "actor_loss": -93.17635733032226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.150740385055542, "step": 95000}
{"episode_reward": 855.5884749609415, "episode": 96.0, "batch_reward": 0.8541344872117043, "critic_loss": 0.7262763758301735, "actor_loss": -93.05366757202148, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.94530963897705, "step": 96000}
{"episode_reward": 943.4434716225214, "episode": 97.0, "batch_reward": 0.855100026667118, "critic_loss": 0.7084418062567711, "actor_loss": -93.2024881439209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.52134895324707, "step": 97000}
{"episode_reward": 946.8751993148162, "episode": 98.0, "batch_reward": 0.8561493512988091, "critic_loss": 0.7020386627614498, "actor_loss": -93.07784162902831, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.714807748794556, "step": 98000}
{"episode_reward": 920.1307297998999, "episode": 99.0, "batch_reward": 0.8584536581039429, "critic_loss": 0.6907178793549538, "actor_loss": -93.32754129028321, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.32865047454834, "step": 99000}
{"episode_reward": 916.2148196834829, "episode": 100.0, "batch_reward": 0.8575798853039741, "critic_loss": 0.7094345156848431, "actor_loss": -93.23519850158691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.78271722793579, "step": 100000}
{"episode_reward": 920.2045315966379, "episode": 101.0, "batch_reward": 0.8602517924308777, "critic_loss": 0.6990190742313862, "actor_loss": -93.38268754577636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 45.27104425430298, "step": 101000}
{"episode_reward": 953.4269250607765, "episode": 102.0, "batch_reward": 0.8602958220839501, "critic_loss": 0.6831252205967903, "actor_loss": -93.38454571533204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.172101736068726, "step": 102000}
{"episode_reward": 964.1985618529603, "episode": 103.0, "batch_reward": 0.8609367319345475, "critic_loss": 0.6785780418515205, "actor_loss": -93.30086880493164, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.85772204399109, "step": 103000}
{"episode_reward": 947.675988485836, "episode": 104.0, "batch_reward": 0.8611042548418045, "critic_loss": 0.6854474718719721, "actor_loss": -93.46772589111328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10861587524414, "step": 104000}
{"episode_reward": 938.3256550792872, "episode": 105.0, "batch_reward": 0.862686531662941, "critic_loss": 0.7314374526143074, "actor_loss": -93.31481376647949, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.374380588531494, "step": 105000}
{"episode_reward": 951.138316030271, "episode": 106.0, "batch_reward": 0.8627239887714386, "critic_loss": 0.6599460879564285, "actor_loss": -93.55332849121093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.986379146575928, "step": 106000}
{"episode_reward": 918.0658770607049, "episode": 107.0, "batch_reward": 0.8640459104776382, "critic_loss": 0.6592588979452848, "actor_loss": -93.47681718444824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.57063055038452, "step": 107000}
{"episode_reward": 917.7717065556021, "episode": 108.0, "batch_reward": 0.8634628227353096, "critic_loss": 0.6533856493383646, "actor_loss": -93.34049342346191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.278019428253174, "step": 108000}
{"episode_reward": 945.0681903286438, "episode": 109.0, "batch_reward": 0.8637829132080078, "critic_loss": 0.6688467391878367, "actor_loss": -93.5697684173584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.43245244026184, "step": 109000}
{"episode_reward": 915.4545604765856, "episode": 110.0, "batch_reward": 0.8656294326782227, "critic_loss": 0.6669885089695453, "actor_loss": -93.72810343933105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.259217500686646, "step": 110000}
{"episode_reward": 930.0356282553125, "episode": 111.0, "batch_reward": 0.8658203102946281, "critic_loss": 0.6675051072537899, "actor_loss": -93.43047549438477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.10440731048584, "step": 111000}
{"episode_reward": 937.9517807753006, "episode": 112.0, "batch_reward": 0.8667925629019737, "critic_loss": 0.6533156619817019, "actor_loss": -93.8129849395752, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.636395931243896, "step": 112000}
{"episode_reward": 898.5085682029913, "episode": 113.0, "batch_reward": 0.8678293618559837, "critic_loss": 0.6537724341750145, "actor_loss": -93.6998636932373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.320390462875366, "step": 113000}
{"episode_reward": 926.4359481212969, "episode": 114.0, "batch_reward": 0.8666420472860337, "critic_loss": 0.6545324565470219, "actor_loss": -93.73852561950683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.578424215316772, "step": 114000}
{"episode_reward": 958.9571074827694, "episode": 115.0, "batch_reward": 0.8685774682164192, "critic_loss": 0.6361628482490778, "actor_loss": -93.71509544372559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.705358505249023, "step": 115000}
{"episode_reward": 944.3511278013749, "episode": 116.0, "batch_reward": 0.8695864377021789, "critic_loss": 0.648352709889412, "actor_loss": -93.83291798400879, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.81069564819336, "step": 116000}
{"episode_reward": 931.9618661094738, "episode": 117.0, "batch_reward": 0.8690684248805046, "critic_loss": 0.6658015810698271, "actor_loss": -93.57943884277344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.13233971595764, "step": 117000}
{"episode_reward": 946.6880002548852, "episode": 118.0, "batch_reward": 0.8686349599957466, "critic_loss": 0.6693387394100427, "actor_loss": -93.68654949951171, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.422236919403076, "step": 118000}
{"episode_reward": 921.011665487451, "episode": 119.0, "batch_reward": 0.87121236795187, "critic_loss": 0.6745698427557946, "actor_loss": -93.77280033874511, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.500631093978882, "step": 119000}
{"episode_reward": 935.9815211338715, "episode": 120.0, "batch_reward": 0.8705336081385613, "critic_loss": 0.6706035536825656, "actor_loss": -93.70471412658691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.438517808914185, "step": 120000}
{"episode_reward": 962.6119646055546, "episode": 121.0, "batch_reward": 0.8719968883991241, "critic_loss": 0.659015224993229, "actor_loss": -93.78389566040039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.68632173538208, "step": 121000}
{"episode_reward": 934.814542978831, "episode": 122.0, "batch_reward": 0.8726903854012489, "critic_loss": 0.6649179156422615, "actor_loss": -93.72534921264648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.764213800430298, "step": 122000}
{"episode_reward": 927.0586671577933, "episode": 123.0, "batch_reward": 0.8737071323990822, "critic_loss": 0.6412793502062559, "actor_loss": -94.02268061828613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.220803022384644, "step": 123000}
{"episode_reward": 958.290057991478, "episode": 124.0, "batch_reward": 0.8739753139615059, "critic_loss": 0.6582964206784964, "actor_loss": -93.91314581298828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.090663194656372, "step": 124000}
{"episode_reward": 907.1860103796895, "episode": 125.0, "batch_reward": 0.8740198553204537, "critic_loss": 0.6800122294127942, "actor_loss": -93.97852001953125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.877387285232544, "step": 125000}
{"episode_reward": 886.2124545479003, "episode": 126.0, "batch_reward": 0.8748631734251976, "critic_loss": 0.6765853619873524, "actor_loss": -93.81147602844239, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.262659788131714, "step": 126000}
{"episode_reward": 926.4274521885498, "episode": 127.0, "batch_reward": 0.8744473439455033, "critic_loss": 0.7106668127030135, "actor_loss": -93.93714544677735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.202937364578247, "step": 127000}
{"episode_reward": 926.6786611939143, "episode": 128.0, "batch_reward": 0.8737295398712158, "critic_loss": 0.6349039408713579, "actor_loss": -93.94361186218262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.639854431152344, "step": 128000}
{"episode_reward": 911.0817575029228, "episode": 129.0, "batch_reward": 0.8735193759799004, "critic_loss": 0.6757230823636055, "actor_loss": -93.83943778991699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.744261264801025, "step": 129000}
{"episode_reward": 965.6397161974045, "episode": 130.0, "batch_reward": 0.8774369034171104, "critic_loss": 0.6272027012258768, "actor_loss": -93.98221305847169, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.374942302703857, "step": 130000}
{"episode_reward": 940.0458305452805, "episode": 131.0, "batch_reward": 0.8762256580591202, "critic_loss": 0.622410511046648, "actor_loss": -94.02326417541504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.24073791503906, "step": 131000}
{"episode_reward": 882.4467755806552, "episode": 132.0, "batch_reward": 0.8763271675705909, "critic_loss": 0.6097707960158586, "actor_loss": -94.17253001403809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.76589560508728, "step": 132000}
{"episode_reward": 928.1557647754906, "episode": 133.0, "batch_reward": 0.8764210138916969, "critic_loss": 0.6109592221528292, "actor_loss": -94.01420491027832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.966581106185913, "step": 133000}
{"episode_reward": 955.6977018749318, "episode": 134.0, "batch_reward": 0.8775903685092926, "critic_loss": 0.5901232079267502, "actor_loss": -93.91464570617676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.282897233963013, "step": 134000}
{"episode_reward": 945.9999101281153, "episode": 135.0, "batch_reward": 0.8773286263346672, "critic_loss": 0.5797184603363276, "actor_loss": -94.21236357116699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.728920698165894, "step": 135000}
{"episode_reward": 914.4551404655344, "episode": 136.0, "batch_reward": 0.878755509018898, "critic_loss": 0.5481181254535914, "actor_loss": -93.80482872009277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.30160355567932, "step": 136000}
{"episode_reward": 908.3216433350926, "episode": 137.0, "batch_reward": 0.8763966985344886, "critic_loss": 0.5762234461456537, "actor_loss": -94.10720936584472, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.93595314025879, "step": 137000}
{"episode_reward": 948.2663229878897, "episode": 138.0, "batch_reward": 0.879470989882946, "critic_loss": 0.5755527351349592, "actor_loss": -94.15163603210449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.902503490447998, "step": 138000}
{"episode_reward": 971.2578473970719, "episode": 139.0, "batch_reward": 0.8802922438979149, "critic_loss": 0.6009522241055966, "actor_loss": -94.18225048828126, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.222878217697144, "step": 139000}
{"episode_reward": 955.5669437679707, "episode": 140.0, "batch_reward": 0.8817094815373421, "critic_loss": 0.5713681460469962, "actor_loss": -94.21584152221679, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.10629367828369, "step": 140000}
{"episode_reward": 930.4502298913017, "episode": 141.0, "batch_reward": 0.8794649490118027, "critic_loss": 0.5897351045906544, "actor_loss": -94.22288430786134, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 45.09256982803345, "step": 141000}
{"episode_reward": 917.9138966838967, "episode": 142.0, "batch_reward": 0.8799638137221336, "critic_loss": 0.575797843337059, "actor_loss": -94.01581498718262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.962352752685547, "step": 142000}
{"episode_reward": 883.2224885028551, "episode": 143.0, "batch_reward": 0.8799289122819901, "critic_loss": 0.5919844706058502, "actor_loss": -94.0378498840332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.979254484176636, "step": 143000}
{"episode_reward": 935.4768358877119, "episode": 144.0, "batch_reward": 0.8816099527478218, "critic_loss": 0.5807407963573933, "actor_loss": -94.26583467102051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.627493381500244, "step": 144000}
{"episode_reward": 911.5599332919485, "episode": 145.0, "batch_reward": 0.8817817394733429, "critic_loss": 0.585738568007946, "actor_loss": -94.30685208129883, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.778640747070312, "step": 145000}
{"episode_reward": 898.5910170337985, "episode": 146.0, "batch_reward": 0.8813871605396271, "critic_loss": 0.5878691624253988, "actor_loss": -94.3865227508545, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.964080333709717, "step": 146000}
{"episode_reward": 956.8170147484584, "episode": 147.0, "batch_reward": 0.8821294873356819, "critic_loss": 0.5754146582782268, "actor_loss": -94.31819712829589, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.63601303100586, "step": 147000}
{"episode_reward": 904.0172949359129, "episode": 148.0, "batch_reward": 0.8815426164269448, "critic_loss": 0.5879561719447375, "actor_loss": -94.300400680542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.476228952407837, "step": 148000}
{"episode_reward": 932.6887537123107, "episode": 149.0, "batch_reward": 0.8818773344159127, "critic_loss": 0.5830189444720745, "actor_loss": -94.2985287322998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.95266819000244, "step": 149000}
{"episode_reward": 987.0452884624389, "episode": 150.0, "batch_reward": 0.882235554754734, "critic_loss": 0.5459100152254105, "actor_loss": -94.37082521057128, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
