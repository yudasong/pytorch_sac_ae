{"episode_reward": 0.0, "episode": 1.0, "duration": 22.661123514175415, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 2.001591205596924, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.4376069524807706, "critic_loss": 0.11087584185993803, "actor_loss": -81.32695531826012, "actor_target_entropy": -6.0, "alpha_value": 0.002642586817083679, "duration": 64.0233986377716, "step": 3000}
{"episode_reward": 53.42647770413296, "episode": 4.0, "batch_reward": 0.29710133756697177, "critic_loss": 0.24108728608489036, "actor_loss": -76.31498115539551, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.225462198257446, "step": 4000}
{"episode_reward": 115.13891948746073, "episode": 5.0, "batch_reward": 0.2799371625930071, "critic_loss": 0.49774398471415043, "actor_loss": -77.22583058166504, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.7524254322052, "step": 5000}
{"episode_reward": 303.59000766827137, "episode": 6.0, "batch_reward": 0.28783781798183916, "critic_loss": 0.693575810700655, "actor_loss": -77.31378115844727, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.79049515724182, "step": 6000}
{"episode_reward": 359.25120953247693, "episode": 7.0, "batch_reward": 0.30494989252090454, "critic_loss": 0.954989933848381, "actor_loss": -78.0136096496582, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.022150993347168, "step": 7000}
{"episode_reward": 386.78856102265064, "episode": 8.0, "batch_reward": 0.30988558396697047, "critic_loss": 1.1156902643442155, "actor_loss": -78.7586979675293, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.402337074279785, "step": 8000}
{"episode_reward": 419.6384323765017, "episode": 9.0, "batch_reward": 0.32423457154631613, "critic_loss": 1.328411304295063, "actor_loss": -79.4251265411377, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.99557590484619, "step": 9000}
{"episode_reward": 335.2075769346867, "episode": 10.0, "batch_reward": 0.33281536315381527, "critic_loss": 1.5672578392028809, "actor_loss": -79.80808435058594, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.425222635269165, "step": 10000}
{"episode_reward": 573.4009891078941, "episode": 11.0, "batch_reward": 0.3534706017971039, "critic_loss": 1.6057632798552512, "actor_loss": -80.12025433349609, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.98421382904053, "step": 11000}
{"episode_reward": 615.9131873968687, "episode": 12.0, "batch_reward": 0.3722561036348343, "critic_loss": 1.6304549069404601, "actor_loss": -80.59641763305665, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.831897258758545, "step": 12000}
{"episode_reward": 515.0483532318241, "episode": 13.0, "batch_reward": 0.3894354900121689, "critic_loss": 1.722334024131298, "actor_loss": -80.5091905670166, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.02044415473938, "step": 13000}
{"episode_reward": 526.0598453702883, "episode": 14.0, "batch_reward": 0.4046398949623108, "critic_loss": 1.923637514591217, "actor_loss": -81.01977183532715, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.509320735931396, "step": 14000}
{"episode_reward": 686.2092156847539, "episode": 15.0, "batch_reward": 0.42052368065714835, "critic_loss": 2.1990077023506163, "actor_loss": -80.96302546691895, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.811766862869263, "step": 15000}
{"episode_reward": 667.9321608692193, "episode": 16.0, "batch_reward": 0.4400272954702377, "critic_loss": 2.7657935239076616, "actor_loss": -82.65862115478515, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.3506338596344, "step": 16000}
{"episode_reward": 767.1944815653777, "episode": 17.0, "batch_reward": 0.44273749721050265, "critic_loss": 4.714879959821701, "actor_loss": -84.40232516479492, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.526594161987305, "step": 17000}
{"episode_reward": 79.9529283823922, "episode": 18.0, "batch_reward": 0.4208690848350525, "critic_loss": 6.39902747964859, "actor_loss": -87.30720614624023, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.564578533172607, "step": 18000}
{"episode_reward": 71.25656361230959, "episode": 19.0, "batch_reward": 0.40291226568818095, "critic_loss": 9.172611829042435, "actor_loss": -91.12505201721191, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.156436681747437, "step": 19000}
{"episode_reward": 81.70661456612547, "episode": 20.0, "batch_reward": 0.3857785409092903, "critic_loss": 11.866242702007293, "actor_loss": -95.4155972442627, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.951151371002197, "step": 20000}
{"episode_reward": 38.40516887039472, "episode": 21.0, "batch_reward": 0.369337319791317, "critic_loss": 17.12015093421936, "actor_loss": -100.98479508972169, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.20918297767639, "step": 21000}
{"episode_reward": 50.38955015036289, "episode": 22.0, "batch_reward": 0.3524194608926773, "critic_loss": 21.57683045578003, "actor_loss": -108.65703686523437, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.039067029953003, "step": 22000}
{"episode_reward": 14.295200845839693, "episode": 23.0, "batch_reward": 0.33693076649308207, "critic_loss": 20.635221554756164, "actor_loss": -112.32677279663086, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.567840576171875, "step": 23000}
{"episode_reward": 27.373490570853043, "episode": 24.0, "batch_reward": 0.324383961379528, "critic_loss": 17.591193084716796, "actor_loss": -116.65190473937989, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.821009635925293, "step": 24000}
{"episode_reward": 33.14599780606825, "episode": 25.0, "batch_reward": 0.312727719694376, "critic_loss": 14.802943716526032, "actor_loss": -121.28914024353027, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.393463134765625, "step": 25000}
{"episode_reward": 25.168867418174425, "episode": 26.0, "batch_reward": 0.3034006486982107, "critic_loss": 11.95162703227997, "actor_loss": -121.67887899780274, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.621901988983154, "step": 26000}
{"episode_reward": 82.43098973094231, "episode": 27.0, "batch_reward": 0.2968737426698208, "critic_loss": 8.997174530506134, "actor_loss": -126.22192692565918, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.788352251052856, "step": 27000}
{"episode_reward": 135.37119409782764, "episode": 28.0, "batch_reward": 0.2928732015043497, "critic_loss": 6.917532485008239, "actor_loss": -121.47792774963379, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.068015813827515, "step": 28000}
{"episode_reward": 322.9016148626892, "episode": 29.0, "batch_reward": 0.2955809128880501, "critic_loss": 5.075375032663345, "actor_loss": -124.47944633483887, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.661571741104126, "step": 29000}
{"episode_reward": 535.945150331609, "episode": 30.0, "batch_reward": 0.30112556846439836, "critic_loss": 3.905942577123642, "actor_loss": -122.218228515625, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.19442892074585, "step": 30000}
{"episode_reward": 377.74584974261643, "episode": 31.0, "batch_reward": 0.307638030320406, "critic_loss": 3.0104398883581163, "actor_loss": -117.26815078735352, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.567195415496826, "step": 31000}
{"episode_reward": 541.2448874091361, "episode": 32.0, "batch_reward": 0.313558553725481, "critic_loss": 2.404760724902153, "actor_loss": -115.17009761047363, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.783199787139893, "step": 32000}
{"episode_reward": 530.9904333728682, "episode": 33.0, "batch_reward": 0.31820565995573996, "critic_loss": 2.038984125494957, "actor_loss": -116.31913984680176, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.866562843322754, "step": 33000}
{"episode_reward": 186.75874070673711, "episode": 34.0, "batch_reward": 0.31083801765739916, "critic_loss": 1.7048812210559845, "actor_loss": -110.99754502868652, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.690009117126465, "step": 34000}
{"episode_reward": 24.18277770356172, "episode": 35.0, "batch_reward": 0.30254205691814423, "critic_loss": 1.501315518140793, "actor_loss": -107.9682038269043, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.57507562637329, "step": 35000}
{"episode_reward": 23.55421453141798, "episode": 36.0, "batch_reward": 0.30225856441259386, "critic_loss": 1.4295370908379554, "actor_loss": -105.06791517639161, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.28110361099243, "step": 36000}
{"episode_reward": 606.4741244474243, "episode": 37.0, "batch_reward": 0.3134664603471756, "critic_loss": 1.4862094368338585, "actor_loss": -104.1773899230957, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.93637990951538, "step": 37000}
{"episode_reward": 844.2214942250503, "episode": 38.0, "batch_reward": 0.3260969186872244, "critic_loss": 1.4735623181462287, "actor_loss": -104.40806913757324, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.62361478805542, "step": 38000}
{"episode_reward": 766.6360216719532, "episode": 39.0, "batch_reward": 0.3390501131117344, "critic_loss": 1.5111188440918923, "actor_loss": -101.85538250732422, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.945566415786743, "step": 39000}
{"episode_reward": 836.1287711944848, "episode": 40.0, "batch_reward": 0.3502706823348999, "critic_loss": 1.5219814460277556, "actor_loss": -99.84665393066406, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.611571073532104, "step": 40000}
{"episode_reward": 805.9096034282509, "episode": 41.0, "batch_reward": 0.3628565909564495, "critic_loss": 1.6290306664705276, "actor_loss": -98.20022183227539, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 44.99123740196228, "step": 41000}
{"episode_reward": 786.2315763366837, "episode": 42.0, "batch_reward": 0.3723606546223164, "critic_loss": 1.7477109117507934, "actor_loss": -98.48197297668457, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.599024534225464, "step": 42000}
{"episode_reward": 876.2782341244833, "episode": 43.0, "batch_reward": 0.3861566599011421, "critic_loss": 1.7968657002449036, "actor_loss": -97.12925390625, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.119207859039307, "step": 43000}
{"episode_reward": 811.7115022995484, "episode": 44.0, "batch_reward": 0.39412261006236077, "critic_loss": 1.6877061683535577, "actor_loss": -97.02483644104004, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.585717916488647, "step": 44000}
{"episode_reward": 822.4661961828742, "episode": 45.0, "batch_reward": 0.40369957756996155, "critic_loss": 1.7179853250384332, "actor_loss": -96.8200266418457, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.48240900039673, "step": 45000}
{"episode_reward": 904.4412148593863, "episode": 46.0, "batch_reward": 0.414364442974329, "critic_loss": 1.8585342479348184, "actor_loss": -95.34152908325196, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.803634643554688, "step": 46000}
{"episode_reward": 795.9656618007361, "episode": 47.0, "batch_reward": 0.42297487872838974, "critic_loss": 1.8418510574698448, "actor_loss": -94.49701643371581, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.607887268066406, "step": 47000}
{"episode_reward": 851.4784725814376, "episode": 48.0, "batch_reward": 0.43449025532603264, "critic_loss": 1.8688672538399695, "actor_loss": -94.51726362609864, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.24951958656311, "step": 48000}
{"episode_reward": 910.0437217401557, "episode": 49.0, "batch_reward": 0.44274450972676277, "critic_loss": 2.088607394039631, "actor_loss": -93.80519808959961, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.91211438179016, "step": 49000}
{"episode_reward": 785.4754483719122, "episode": 50.0, "batch_reward": 0.44863160455226897, "critic_loss": 2.9430566501021387, "actor_loss": -93.72861138916015, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.734716415405273, "step": 50000}
{"episode_reward": 744.1576753777578, "episode": 51.0, "batch_reward": 0.4561939123868942, "critic_loss": 2.0709164476394655, "actor_loss": -93.55589233398437, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.77878928184509, "step": 51000}
{"episode_reward": 888.1302422036034, "episode": 52.0, "batch_reward": 0.4621518039107323, "critic_loss": 2.123515070915222, "actor_loss": -92.06524548339844, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.172057390213013, "step": 52000}
{"episode_reward": 792.5852793414255, "episode": 53.0, "batch_reward": 0.47073142823576924, "critic_loss": 1.704532982170582, "actor_loss": -92.49060260009766, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.41364288330078, "step": 53000}
{"episode_reward": 864.4471237235439, "episode": 54.0, "batch_reward": 0.47747163674235343, "critic_loss": 1.5774795836806297, "actor_loss": -91.46476484680176, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.447243213653564, "step": 54000}
{"episode_reward": 834.346181297965, "episode": 55.0, "batch_reward": 0.48236757320165635, "critic_loss": 1.5007419164776803, "actor_loss": -91.2187158203125, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.219727039337158, "step": 55000}
{"episode_reward": 894.4078025610509, "episode": 56.0, "batch_reward": 0.49139172419905663, "critic_loss": 1.4374558748602868, "actor_loss": -91.35810945129394, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.81385064125061, "step": 56000}
{"episode_reward": 956.7224656350901, "episode": 57.0, "batch_reward": 0.5016957043707371, "critic_loss": 1.3740841238498687, "actor_loss": -91.13576875305176, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.86335587501526, "step": 57000}
{"episode_reward": 931.2611500559813, "episode": 58.0, "batch_reward": 0.5070216798484325, "critic_loss": 1.4307200136184692, "actor_loss": -90.925441696167, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.600106239318848, "step": 58000}
{"episode_reward": 870.3576643904531, "episode": 59.0, "batch_reward": 0.5128617798984051, "critic_loss": 1.2886501325368882, "actor_loss": -90.54637030029296, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.30384349822998, "step": 59000}
{"episode_reward": 867.0737738698366, "episode": 60.0, "batch_reward": 0.5172495271265507, "critic_loss": 1.4492348963022232, "actor_loss": -90.11797317504883, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.269596099853516, "step": 60000}
{"episode_reward": 714.6544520591628, "episode": 61.0, "batch_reward": 0.5226847330629826, "critic_loss": 1.4679916148781778, "actor_loss": -89.85824403381348, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.54853081703186, "step": 61000}
{"episode_reward": 879.6967508024801, "episode": 62.0, "batch_reward": 0.5286673448085785, "critic_loss": 1.1864724824428559, "actor_loss": -89.84787205505371, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.578967094421387, "step": 62000}
{"episode_reward": 947.1287264768213, "episode": 63.0, "batch_reward": 0.5338633926212788, "critic_loss": 1.0308014359176159, "actor_loss": -89.59235374450684, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.0546817779541, "step": 63000}
{"episode_reward": 887.4050335856508, "episode": 64.0, "batch_reward": 0.5417021975517273, "critic_loss": 0.9826121821999549, "actor_loss": -89.55798770141601, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.716272354125977, "step": 64000}
{"episode_reward": 864.3409863888452, "episode": 65.0, "batch_reward": 0.5454781031608582, "critic_loss": 0.9321280493736267, "actor_loss": -89.36554238891601, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.26941156387329, "step": 65000}
{"episode_reward": 934.9485920587928, "episode": 66.0, "batch_reward": 0.5520586502254009, "critic_loss": 0.8946008220016957, "actor_loss": -89.3572707824707, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.694725513458252, "step": 66000}
{"episode_reward": 951.215108637126, "episode": 67.0, "batch_reward": 0.5586167283952236, "critic_loss": 0.8597046995460987, "actor_loss": -89.34007281494141, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.903611660003662, "step": 67000}
{"episode_reward": 912.850670582855, "episode": 68.0, "batch_reward": 0.5640174976885318, "critic_loss": 0.847344499617815, "actor_loss": -89.37164138793945, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.32426118850708, "step": 68000}
{"episode_reward": 935.5485682686628, "episode": 69.0, "batch_reward": 0.5700192841887474, "critic_loss": 0.817421558380127, "actor_loss": -89.31615840148926, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.522088050842285, "step": 69000}
{"episode_reward": 933.8443539187034, "episode": 70.0, "batch_reward": 0.5745080356001854, "critic_loss": 0.8204573945701122, "actor_loss": -89.21273323059081, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.647862434387207, "step": 70000}
{"episode_reward": 890.3049492654153, "episode": 71.0, "batch_reward": 0.5773462899625301, "critic_loss": 0.7779098397195339, "actor_loss": -89.15586650085449, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 44.500216245651245, "step": 71000}
{"episode_reward": 898.9845245973005, "episode": 72.0, "batch_reward": 0.5825579034984112, "critic_loss": 0.7751580332219601, "actor_loss": -89.03660308837891, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.04160189628601, "step": 72000}
{"episode_reward": 909.0348482971184, "episode": 73.0, "batch_reward": 0.586004075050354, "critic_loss": 0.8013708055019378, "actor_loss": -88.94082563781738, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.867639780044556, "step": 73000}
{"episode_reward": 941.0140080187879, "episode": 74.0, "batch_reward": 0.5912796857059002, "critic_loss": 0.7686133657097817, "actor_loss": -89.02661862182617, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.317312240600586, "step": 74000}
{"episode_reward": 925.6366154338222, "episode": 75.0, "batch_reward": 0.5995936163663864, "critic_loss": 0.80262567076087, "actor_loss": -89.11333296203614, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.725053548812866, "step": 75000}
{"episode_reward": 913.45979741684, "episode": 76.0, "batch_reward": 0.6032776757478714, "critic_loss": 0.8047740302681923, "actor_loss": -89.13887100219726, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.67454695701599, "step": 76000}
{"episode_reward": 932.5225001631669, "episode": 77.0, "batch_reward": 0.6050454081594944, "critic_loss": 0.7734846070706844, "actor_loss": -89.04611555480957, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.35608720779419, "step": 77000}
{"episode_reward": 921.2476976907316, "episode": 78.0, "batch_reward": 0.6081248279511928, "critic_loss": 0.7521868013441563, "actor_loss": -88.91622840881348, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.337573289871216, "step": 78000}
{"episode_reward": 898.169252216107, "episode": 79.0, "batch_reward": 0.6125830985605717, "critic_loss": 0.7264600273966789, "actor_loss": -88.89580519104004, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.164103507995605, "step": 79000}
{"episode_reward": 946.6548829547704, "episode": 80.0, "batch_reward": 0.61639057046175, "critic_loss": 0.7211754370927811, "actor_loss": -89.01771713256836, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.845305681228638, "step": 80000}
{"episode_reward": 921.7473650401437, "episode": 81.0, "batch_reward": 0.6221150527596474, "critic_loss": 0.7136743958890438, "actor_loss": -88.94910102844239, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.287195920944214, "step": 81000}
{"episode_reward": 858.1285243313304, "episode": 82.0, "batch_reward": 0.6214518444538116, "critic_loss": 0.7192626388072968, "actor_loss": -88.91482418823242, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.220070123672485, "step": 82000}
{"episode_reward": 933.1029896246542, "episode": 83.0, "batch_reward": 0.6269132280349732, "critic_loss": 0.7261245481669902, "actor_loss": -89.12306988525391, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.086243391036987, "step": 83000}
{"episode_reward": 912.6048139290496, "episode": 84.0, "batch_reward": 0.6286396491825581, "critic_loss": 0.7255105848908424, "actor_loss": -89.09049435424805, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.792139768600464, "step": 84000}
{"episode_reward": 863.374912105879, "episode": 85.0, "batch_reward": 0.6325485168695449, "critic_loss": 0.7536291501522064, "actor_loss": -88.95748561096191, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.21819496154785, "step": 85000}
{"episode_reward": 929.5848248371523, "episode": 86.0, "batch_reward": 0.6397373948693276, "critic_loss": 0.7260807009637356, "actor_loss": -89.15064498901367, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.005300998687744, "step": 86000}
{"episode_reward": 941.3616077596066, "episode": 87.0, "batch_reward": 0.6398182255625725, "critic_loss": 0.7424238599836827, "actor_loss": -89.23088703918457, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.650911808013916, "step": 87000}
{"episode_reward": 890.7785351913052, "episode": 88.0, "batch_reward": 0.6444499303102493, "critic_loss": 0.7124280135333538, "actor_loss": -89.2712576751709, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.817699193954468, "step": 88000}
{"episode_reward": 960.1091012471262, "episode": 89.0, "batch_reward": 0.6482460802197456, "critic_loss": 0.7072576168179512, "actor_loss": -89.10194100952148, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.39673113822937, "step": 89000}
{"episode_reward": 931.4703697094203, "episode": 90.0, "batch_reward": 0.6504339710474014, "critic_loss": 0.7130664437413216, "actor_loss": -89.15931895446778, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.332595348358154, "step": 90000}
{"episode_reward": 953.8402390722173, "episode": 91.0, "batch_reward": 0.6541270686984062, "critic_loss": 0.6751708111763001, "actor_loss": -89.09849064636231, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.864752531051636, "step": 91000}
{"episode_reward": 875.4454180558363, "episode": 92.0, "batch_reward": 0.6562052148580552, "critic_loss": 0.6859726822674275, "actor_loss": -89.22396281433106, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.586800813674927, "step": 92000}
{"episode_reward": 926.9854291819028, "episode": 93.0, "batch_reward": 0.6598179388642311, "critic_loss": 0.6736002354025841, "actor_loss": -89.31722364807129, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.774954319000244, "step": 93000}
{"episode_reward": 966.4590088367642, "episode": 94.0, "batch_reward": 0.6634162479043006, "critic_loss": 0.6493895568549634, "actor_loss": -89.40853919982911, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.330039978027344, "step": 94000}
{"episode_reward": 947.5083859852574, "episode": 95.0, "batch_reward": 0.665897764801979, "critic_loss": 0.6378063727170229, "actor_loss": -89.51742640686035, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.128239154815674, "step": 95000}
{"episode_reward": 933.2154186098153, "episode": 96.0, "batch_reward": 0.6676441215872765, "critic_loss": 0.6397783598899841, "actor_loss": -89.4466145324707, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.280950784683228, "step": 96000}
{"episode_reward": 939.726249742309, "episode": 97.0, "batch_reward": 0.6704229818582534, "critic_loss": 0.6122020059525967, "actor_loss": -89.50918643188477, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.674211740493774, "step": 97000}
{"episode_reward": 963.2087461905488, "episode": 98.0, "batch_reward": 0.6752388176918029, "critic_loss": 0.5961621973216533, "actor_loss": -89.41204385375977, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.081111192703247, "step": 98000}
{"episode_reward": 923.6177814895505, "episode": 99.0, "batch_reward": 0.676119217634201, "critic_loss": 0.590466177880764, "actor_loss": -89.68637504577637, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.05877661705017, "step": 99000}
{"episode_reward": 926.0484757355789, "episode": 100.0, "batch_reward": 0.6767525309920311, "critic_loss": 0.5979991518259048, "actor_loss": -89.61590734863282, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.03497076034546, "step": 100000}
{"episode_reward": 963.2195223293417, "episode": 101.0, "batch_reward": 0.6817677832841873, "critic_loss": 0.5959505693316459, "actor_loss": -89.73294561767578, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 44.48702120780945, "step": 101000}
{"episode_reward": 955.8824808170297, "episode": 102.0, "batch_reward": 0.6841202744245529, "critic_loss": 0.6043162260949612, "actor_loss": -89.69813998413086, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.756552696228027, "step": 102000}
{"episode_reward": 926.8983988186498, "episode": 103.0, "batch_reward": 0.6873735720515252, "critic_loss": 0.5986072064340114, "actor_loss": -89.73920278930665, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.490431308746338, "step": 103000}
{"episode_reward": 947.0523437266609, "episode": 104.0, "batch_reward": 0.6887697994112968, "critic_loss": 0.584227919280529, "actor_loss": -89.93848916625977, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.503785371780396, "step": 104000}
{"episode_reward": 931.7430303759171, "episode": 105.0, "batch_reward": 0.6919046301841736, "critic_loss": 0.5885224169790745, "actor_loss": -89.77567701721192, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.344221830368042, "step": 105000}
{"episode_reward": 902.627417765096, "episode": 106.0, "batch_reward": 0.6919340856075287, "critic_loss": 0.5907583686709404, "actor_loss": -89.9263955078125, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.05331778526306, "step": 106000}
{"episode_reward": 891.5421909127676, "episode": 107.0, "batch_reward": 0.6946024377346038, "critic_loss": 0.6025998706072568, "actor_loss": -89.86293844604492, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.800395488739014, "step": 107000}
{"episode_reward": 863.9442493820462, "episode": 108.0, "batch_reward": 0.6963387888073921, "critic_loss": 0.5723008205294609, "actor_loss": -89.63884297180176, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.26536273956299, "step": 108000}
{"episode_reward": 941.0354881245786, "episode": 109.0, "batch_reward": 0.6979394266009331, "critic_loss": 0.5632020753622055, "actor_loss": -90.0715353088379, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.287218809127808, "step": 109000}
{"episode_reward": 916.5520594874463, "episode": 110.0, "batch_reward": 0.7023661946058273, "critic_loss": 0.5728040843009948, "actor_loss": -90.13822944641113, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.373822927474976, "step": 110000}
{"episode_reward": 942.7465807967642, "episode": 111.0, "batch_reward": 0.7034088189601898, "critic_loss": 0.5870109319686889, "actor_loss": -89.7690107421875, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.90032362937927, "step": 111000}
{"episode_reward": 902.5892835766018, "episode": 112.0, "batch_reward": 0.7064568442106247, "critic_loss": 0.6058196405768395, "actor_loss": -90.3297329864502, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.636703729629517, "step": 112000}
{"episode_reward": 934.1799256190436, "episode": 113.0, "batch_reward": 0.7083367797136306, "critic_loss": 0.5867335026562214, "actor_loss": -90.0800246887207, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.92328715324402, "step": 113000}
{"episode_reward": 949.79852402319, "episode": 114.0, "batch_reward": 0.7078615233302117, "critic_loss": 0.5824952545464039, "actor_loss": -90.03424632263183, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.988561868667603, "step": 114000}
{"episode_reward": 899.032756054025, "episode": 115.0, "batch_reward": 0.708717988550663, "critic_loss": 0.5849175412803889, "actor_loss": -90.1114409942627, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.41287064552307, "step": 115000}
{"episode_reward": 951.0662457268268, "episode": 116.0, "batch_reward": 0.7154278252124786, "critic_loss": 0.6248245130479336, "actor_loss": -90.34347932434082, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.592721939086914, "step": 116000}
{"episode_reward": 812.8209656259985, "episode": 117.0, "batch_reward": 0.7137738733291626, "critic_loss": 0.6004518363773823, "actor_loss": -89.88817980957032, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.16777515411377, "step": 117000}
{"episode_reward": 932.0295125141088, "episode": 118.0, "batch_reward": 0.7158623523116112, "critic_loss": 0.6147215718626976, "actor_loss": -90.20878094482421, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.274784803390503, "step": 118000}
{"episode_reward": 927.6183689773494, "episode": 119.0, "batch_reward": 0.7183148211836815, "critic_loss": 0.6190389558523893, "actor_loss": -90.31161495971679, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.826156616210938, "step": 119000}
{"episode_reward": 943.0016624678142, "episode": 120.0, "batch_reward": 0.7204034210443496, "critic_loss": 0.5881553184688091, "actor_loss": -90.19306809997559, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.378244876861572, "step": 120000}
{"episode_reward": 943.9193965885363, "episode": 121.0, "batch_reward": 0.7212178347706795, "critic_loss": 0.5590788828581572, "actor_loss": -90.21867951965332, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.588706254959106, "step": 121000}
{"episode_reward": 931.2580122875107, "episode": 122.0, "batch_reward": 0.7237670156955719, "critic_loss": 0.5558471060097218, "actor_loss": -90.2394711303711, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.600619792938232, "step": 122000}
{"episode_reward": 882.9837448584861, "episode": 123.0, "batch_reward": 0.7243395931720734, "critic_loss": 0.5436236301064491, "actor_loss": -90.34178784179687, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.861778020858765, "step": 123000}
{"episode_reward": 947.6123321642332, "episode": 124.0, "batch_reward": 0.7266044951677323, "critic_loss": 0.5423188042342663, "actor_loss": -90.41151512145996, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.481568098068237, "step": 124000}
{"episode_reward": 907.1959023877591, "episode": 125.0, "batch_reward": 0.7281838269233704, "critic_loss": 0.5627819268405437, "actor_loss": -90.47276733398438, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.84103775024414, "step": 125000}
{"episode_reward": 934.8762646355948, "episode": 126.0, "batch_reward": 0.729641431093216, "critic_loss": 0.5459062461704016, "actor_loss": -90.34770083618164, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.559083938598633, "step": 126000}
{"episode_reward": 950.7563155671818, "episode": 127.0, "batch_reward": 0.729902384519577, "critic_loss": 0.5266224854290485, "actor_loss": -90.56469975280761, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.861023426055908, "step": 127000}
{"episode_reward": 904.553185739466, "episode": 128.0, "batch_reward": 0.7318214792609214, "critic_loss": 0.5300968464165926, "actor_loss": -90.51093971252442, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.417834758758545, "step": 128000}
{"episode_reward": 934.5646964582992, "episode": 129.0, "batch_reward": 0.732816688477993, "critic_loss": 0.5249231282472611, "actor_loss": -90.37879376220702, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.301181077957153, "step": 129000}
{"episode_reward": 977.5927408168293, "episode": 130.0, "batch_reward": 0.7366500779390335, "critic_loss": 0.49584891974925993, "actor_loss": -90.55989036560058, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.546974420547485, "step": 130000}
{"episode_reward": 925.03509637042, "episode": 131.0, "batch_reward": 0.7376180807948113, "critic_loss": 0.5325066619813442, "actor_loss": -90.72421514892578, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 45.77126884460449, "step": 131000}
{"episode_reward": 933.9986579768532, "episode": 132.0, "batch_reward": 0.7369423942565918, "critic_loss": 0.5383230247199535, "actor_loss": -90.79182083129882, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.86371350288391, "step": 132000}
{"episode_reward": 899.6872283892434, "episode": 133.0, "batch_reward": 0.7424817531108856, "critic_loss": 0.5287563185691834, "actor_loss": -90.65230645751953, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.534907341003418, "step": 133000}
{"episode_reward": 942.6021907311679, "episode": 134.0, "batch_reward": 0.7416969248056412, "critic_loss": 0.5390034848451615, "actor_loss": -90.52508111572266, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.01016116142273, "step": 134000}
{"episode_reward": 914.6383908001156, "episode": 135.0, "batch_reward": 0.7439177944660187, "critic_loss": 0.5203189006596803, "actor_loss": -90.95633856201172, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.87631320953369, "step": 135000}
{"episode_reward": 922.8486548913062, "episode": 136.0, "batch_reward": 0.7428933174610138, "critic_loss": 0.5075173092037439, "actor_loss": -90.37553454589843, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.699225902557373, "step": 136000}
{"episode_reward": 931.8271113553714, "episode": 137.0, "batch_reward": 0.7442019300460816, "critic_loss": 0.5061708509624004, "actor_loss": -90.91210578918457, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.46150779724121, "step": 137000}
{"episode_reward": 930.4233328517854, "episode": 138.0, "batch_reward": 0.7479931042194367, "critic_loss": 0.5113574268221855, "actor_loss": -90.92143844604492, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.197638034820557, "step": 138000}
{"episode_reward": 968.8563573988765, "episode": 139.0, "batch_reward": 0.7500375702381133, "critic_loss": 0.49339496180415154, "actor_loss": -90.96623889160156, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.31663417816162, "step": 139000}
{"episode_reward": 926.17113499964, "episode": 140.0, "batch_reward": 0.7518375935554504, "critic_loss": 0.47627205614745616, "actor_loss": -91.06004472351074, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.53255295753479, "step": 140000}
{"episode_reward": 914.9692056875853, "episode": 141.0, "batch_reward": 0.7492804571390151, "critic_loss": 0.5079166504293681, "actor_loss": -90.93452833557129, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.88710165023804, "step": 141000}
{"episode_reward": 927.7310977838371, "episode": 142.0, "batch_reward": 0.7503837106823921, "critic_loss": 0.49104045470058916, "actor_loss": -90.71034852600097, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.712105989456177, "step": 142000}
{"episode_reward": 932.1998900286034, "episode": 143.0, "batch_reward": 0.7523273339271546, "critic_loss": 0.4901800116151571, "actor_loss": -90.78100804138184, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.313133716583252, "step": 143000}
{"episode_reward": 951.2247411489807, "episode": 144.0, "batch_reward": 0.7562885838747024, "critic_loss": 0.5001318011134863, "actor_loss": -91.17673533630371, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.868292808532715, "step": 144000}
{"episode_reward": 892.9371902234392, "episode": 145.0, "batch_reward": 0.7559963553547859, "critic_loss": 0.5028365241289139, "actor_loss": -91.12556707763672, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.674956560134888, "step": 145000}
{"episode_reward": 891.0736129859995, "episode": 146.0, "batch_reward": 0.7562679019570351, "critic_loss": 0.5111482932716608, "actor_loss": -91.14852149963379, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.356870651245117, "step": 146000}
{"episode_reward": 935.6708869788669, "episode": 147.0, "batch_reward": 0.7568690389990806, "critic_loss": 0.4977024584561586, "actor_loss": -91.2304373626709, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.80856156349182, "step": 147000}
{"episode_reward": 905.3539703578211, "episode": 148.0, "batch_reward": 0.7581516837477684, "critic_loss": 0.4977527252882719, "actor_loss": -91.1067958831787, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.12350559234619, "step": 148000}
{"episode_reward": 924.2943107671031, "episode": 149.0, "batch_reward": 0.7590810428857804, "critic_loss": 0.5154574939608574, "actor_loss": -91.1513283996582, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.037632703781128, "step": 149000}
{"episode_reward": 966.2374637218255, "episode": 150.0, "batch_reward": 0.7610939820408821, "critic_loss": 0.5024370048940182, "actor_loss": -91.21436779785157, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "step": 150000}
