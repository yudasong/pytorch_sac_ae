{"episode_reward": 0.0, "episode": 1.0, "duration": 22.661123514175415, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 2.001591205596924, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.4376069524807706, "critic_loss": 0.11087584185993803, "actor_loss": -81.32695531826012, "actor_target_entropy": -6.0, "alpha_value": 0.002642586817083679, "duration": 64.0233986377716, "step": 3000}
{"episode_reward": 53.42647770413296, "episode": 4.0, "batch_reward": 0.29710133756697177, "critic_loss": 0.24108728608489036, "actor_loss": -76.31498115539551, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.225462198257446, "step": 4000}
{"episode_reward": 115.13891948746073, "episode": 5.0, "batch_reward": 0.2799371625930071, "critic_loss": 0.49774398471415043, "actor_loss": -77.22583058166504, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.7524254322052, "step": 5000}
{"episode_reward": 303.59000766827137, "episode": 6.0, "batch_reward": 0.28783781798183916, "critic_loss": 0.693575810700655, "actor_loss": -77.31378115844727, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.79049515724182, "step": 6000}
{"episode_reward": 359.25120953247693, "episode": 7.0, "batch_reward": 0.30494989252090454, "critic_loss": 0.954989933848381, "actor_loss": -78.0136096496582, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.022150993347168, "step": 7000}
{"episode_reward": 386.78856102265064, "episode": 8.0, "batch_reward": 0.30988558396697047, "critic_loss": 1.1156902643442155, "actor_loss": -78.7586979675293, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.402337074279785, "step": 8000}
{"episode_reward": 419.6384323765017, "episode": 9.0, "batch_reward": 0.32423457154631613, "critic_loss": 1.328411304295063, "actor_loss": -79.4251265411377, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.99557590484619, "step": 9000}
{"episode_reward": 335.2075769346867, "episode": 10.0, "batch_reward": 0.33281536315381527, "critic_loss": 1.5672578392028809, "actor_loss": -79.80808435058594, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.425222635269165, "step": 10000}
{"episode_reward": 573.4009891078941, "episode": 11.0, "batch_reward": 0.3534706017971039, "critic_loss": 1.6057632798552512, "actor_loss": -80.12025433349609, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.98421382904053, "step": 11000}
{"episode_reward": 615.9131873968687, "episode": 12.0, "batch_reward": 0.3722561036348343, "critic_loss": 1.6304549069404601, "actor_loss": -80.59641763305665, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.831897258758545, "step": 12000}
{"episode_reward": 515.0483532318241, "episode": 13.0, "batch_reward": 0.3894354900121689, "critic_loss": 1.722334024131298, "actor_loss": -80.5091905670166, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.02044415473938, "step": 13000}
{"episode_reward": 526.0598453702883, "episode": 14.0, "batch_reward": 0.4046398949623108, "critic_loss": 1.923637514591217, "actor_loss": -81.01977183532715, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.509320735931396, "step": 14000}
{"episode_reward": 686.2092156847539, "episode": 15.0, "batch_reward": 0.42052368065714835, "critic_loss": 2.1990077023506163, "actor_loss": -80.96302546691895, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.811766862869263, "step": 15000}
{"episode_reward": 667.9321608692193, "episode": 16.0, "batch_reward": 0.4400272954702377, "critic_loss": 2.7657935239076616, "actor_loss": -82.65862115478515, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.3506338596344, "step": 16000}
{"episode_reward": 767.1944815653777, "episode": 17.0, "batch_reward": 0.44273749721050265, "critic_loss": 4.714879959821701, "actor_loss": -84.40232516479492, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.526594161987305, "step": 17000}
{"episode_reward": 79.9529283823922, "episode": 18.0, "batch_reward": 0.4208690848350525, "critic_loss": 6.39902747964859, "actor_loss": -87.30720614624023, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.564578533172607, "step": 18000}
{"episode_reward": 71.25656361230959, "episode": 19.0, "batch_reward": 0.40291226568818095, "critic_loss": 9.172611829042435, "actor_loss": -91.12505201721191, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.156436681747437, "step": 19000}
{"episode_reward": 81.70661456612547, "episode": 20.0, "batch_reward": 0.3857785409092903, "critic_loss": 11.866242702007293, "actor_loss": -95.4155972442627, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.951151371002197, "step": 20000}
{"episode_reward": 38.40516887039472, "episode": 21.0, "batch_reward": 0.369337319791317, "critic_loss": 17.12015093421936, "actor_loss": -100.98479508972169, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.20918297767639, "step": 21000}
{"episode_reward": 50.38955015036289, "episode": 22.0, "batch_reward": 0.3524194608926773, "critic_loss": 21.57683045578003, "actor_loss": -108.65703686523437, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.039067029953003, "step": 22000}
{"episode_reward": 14.295200845839693, "episode": 23.0, "batch_reward": 0.33693076649308207, "critic_loss": 20.635221554756164, "actor_loss": -112.32677279663086, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.567840576171875, "step": 23000}
{"episode_reward": 27.373490570853043, "episode": 24.0, "batch_reward": 0.324383961379528, "critic_loss": 17.591193084716796, "actor_loss": -116.65190473937989, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.821009635925293, "step": 24000}
{"episode_reward": 33.14599780606825, "episode": 25.0, "batch_reward": 0.312727719694376, "critic_loss": 14.802943716526032, "actor_loss": -121.28914024353027, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.393463134765625, "step": 25000}
{"episode_reward": 25.168867418174425, "episode": 26.0, "batch_reward": 0.3034006486982107, "critic_loss": 11.95162703227997, "actor_loss": -121.67887899780274, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.621901988983154, "step": 26000}
{"episode_reward": 82.43098973094231, "episode": 27.0, "batch_reward": 0.2968737426698208, "critic_loss": 8.997174530506134, "actor_loss": -126.22192692565918, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.788352251052856, "step": 27000}
{"episode_reward": 135.37119409782764, "episode": 28.0, "batch_reward": 0.2928732015043497, "critic_loss": 6.917532485008239, "actor_loss": -121.47792774963379, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.068015813827515, "step": 28000}
{"episode_reward": 322.9016148626892, "episode": 29.0, "batch_reward": 0.2955809128880501, "critic_loss": 5.075375032663345, "actor_loss": -124.47944633483887, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.661571741104126, "step": 29000}
{"episode_reward": 535.945150331609, "episode": 30.0, "batch_reward": 0.30112556846439836, "critic_loss": 3.905942577123642, "actor_loss": -122.218228515625, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.19442892074585, "step": 30000}
{"episode_reward": 377.74584974261643, "episode": 31.0, "batch_reward": 0.307638030320406, "critic_loss": 3.0104398883581163, "actor_loss": -117.26815078735352, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.567195415496826, "step": 31000}
{"episode_reward": 541.2448874091361, "episode": 32.0, "batch_reward": 0.313558553725481, "critic_loss": 2.404760724902153, "actor_loss": -115.17009761047363, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.783199787139893, "step": 32000}
{"episode_reward": 530.9904333728682, "episode": 33.0, "batch_reward": 0.31820565995573996, "critic_loss": 2.038984125494957, "actor_loss": -116.31913984680176, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.866562843322754, "step": 33000}
{"episode_reward": 186.75874070673711, "episode": 34.0, "batch_reward": 0.31083801765739916, "critic_loss": 1.7048812210559845, "actor_loss": -110.99754502868652, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.690009117126465, "step": 34000}
{"episode_reward": 24.18277770356172, "episode": 35.0, "batch_reward": 0.30254205691814423, "critic_loss": 1.501315518140793, "actor_loss": -107.9682038269043, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.57507562637329, "step": 35000}
{"episode_reward": 23.55421453141798, "episode": 36.0, "batch_reward": 0.30225856441259386, "critic_loss": 1.4295370908379554, "actor_loss": -105.06791517639161, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.28110361099243, "step": 36000}
{"episode_reward": 606.4741244474243, "episode": 37.0, "batch_reward": 0.3134664603471756, "critic_loss": 1.4862094368338585, "actor_loss": -104.1773899230957, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.93637990951538, "step": 37000}
{"episode_reward": 844.2214942250503, "episode": 38.0, "batch_reward": 0.3260969186872244, "critic_loss": 1.4735623181462287, "actor_loss": -104.40806913757324, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.62361478805542, "step": 38000}
{"episode_reward": 766.6360216719532, "episode": 39.0, "batch_reward": 0.3390501131117344, "critic_loss": 1.5111188440918923, "actor_loss": -101.85538250732422, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.945566415786743, "step": 39000}
{"episode_reward": 836.1287711944848, "episode": 40.0, "batch_reward": 0.3502706823348999, "critic_loss": 1.5219814460277556, "actor_loss": -99.84665393066406, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.611571073532104, "step": 40000}
{"episode_reward": 805.9096034282509, "episode": 41.0, "batch_reward": 0.3628565909564495, "critic_loss": 1.6290306664705276, "actor_loss": -98.20022183227539, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 44.99123740196228, "step": 41000}
{"episode_reward": 786.2315763366837, "episode": 42.0, "batch_reward": 0.3723606546223164, "critic_loss": 1.7477109117507934, "actor_loss": -98.48197297668457, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.599024534225464, "step": 42000}
{"episode_reward": 876.2782341244833, "episode": 43.0, "batch_reward": 0.3861566599011421, "critic_loss": 1.7968657002449036, "actor_loss": -97.12925390625, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.119207859039307, "step": 43000}
{"episode_reward": 811.7115022995484, "episode": 44.0, "batch_reward": 0.39412261006236077, "critic_loss": 1.6877061683535577, "actor_loss": -97.02483644104004, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.585717916488647, "step": 44000}
{"episode_reward": 822.4661961828742, "episode": 45.0, "batch_reward": 0.40369957756996155, "critic_loss": 1.7179853250384332, "actor_loss": -96.8200266418457, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.48240900039673, "step": 45000}
{"episode_reward": 904.4412148593863, "episode": 46.0, "batch_reward": 0.414364442974329, "critic_loss": 1.8585342479348184, "actor_loss": -95.34152908325196, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.803634643554688, "step": 46000}
{"episode_reward": 795.9656618007361, "episode": 47.0, "batch_reward": 0.42297487872838974, "critic_loss": 1.8418510574698448, "actor_loss": -94.49701643371581, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.607887268066406, "step": 47000}
{"episode_reward": 851.4784725814376, "episode": 48.0, "batch_reward": 0.43449025532603264, "critic_loss": 1.8688672538399695, "actor_loss": -94.51726362609864, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.24951958656311, "step": 48000}
{"episode_reward": 910.0437217401557, "episode": 49.0, "batch_reward": 0.44274450972676277, "critic_loss": 2.088607394039631, "actor_loss": -93.80519808959961, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.91211438179016, "step": 49000}
{"episode_reward": 785.4754483719122, "episode": 50.0, "batch_reward": 0.44863160455226897, "critic_loss": 2.9430566501021387, "actor_loss": -93.72861138916015, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.734716415405273, "step": 50000}
{"episode_reward": 744.1576753777578, "episode": 51.0, "batch_reward": 0.4561939123868942, "critic_loss": 2.0709164476394655, "actor_loss": -93.55589233398437, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.77878928184509, "step": 51000}
{"episode_reward": 888.1302422036034, "episode": 52.0, "batch_reward": 0.4621518039107323, "critic_loss": 2.123515070915222, "actor_loss": -92.06524548339844, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.172057390213013, "step": 52000}
{"episode_reward": 792.5852793414255, "episode": 53.0, "batch_reward": 0.47073142823576924, "critic_loss": 1.704532982170582, "actor_loss": -92.49060260009766, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.41364288330078, "step": 53000}
{"episode_reward": 864.4471237235439, "episode": 54.0, "batch_reward": 0.47747163674235343, "critic_loss": 1.5774795836806297, "actor_loss": -91.46476484680176, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.447243213653564, "step": 54000}
{"episode_reward": 834.346181297965, "episode": 55.0, "batch_reward": 0.48236757320165635, "critic_loss": 1.5007419164776803, "actor_loss": -91.2187158203125, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.219727039337158, "step": 55000}
{"episode_reward": 894.4078025610509, "episode": 56.0, "batch_reward": 0.49139172419905663, "critic_loss": 1.4374558748602868, "actor_loss": -91.35810945129394, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.81385064125061, "step": 56000}
{"episode_reward": 956.7224656350901, "episode": 57.0, "batch_reward": 0.5016957043707371, "critic_loss": 1.3740841238498687, "actor_loss": -91.13576875305176, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.86335587501526, "step": 57000}
{"episode_reward": 931.2611500559813, "episode": 58.0, "batch_reward": 0.5070216798484325, "critic_loss": 1.4307200136184692, "actor_loss": -90.925441696167, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.600106239318848, "step": 58000}
{"episode_reward": 870.3576643904531, "episode": 59.0, "batch_reward": 0.5128617798984051, "critic_loss": 1.2886501325368882, "actor_loss": -90.54637030029296, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.30384349822998, "step": 59000}
{"episode_reward": 867.0737738698366, "episode": 60.0, "batch_reward": 0.5172495271265507, "critic_loss": 1.4492348963022232, "actor_loss": -90.11797317504883, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.269596099853516, "step": 60000}
{"episode_reward": 714.6544520591628, "episode": 61.0, "batch_reward": 0.5226847330629826, "critic_loss": 1.4679916148781778, "actor_loss": -89.85824403381348, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.54853081703186, "step": 61000}
{"episode_reward": 879.6967508024801, "episode": 62.0, "batch_reward": 0.5286673448085785, "critic_loss": 1.1864724824428559, "actor_loss": -89.84787205505371, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.578967094421387, "step": 62000}
{"episode_reward": 947.1287264768213, "episode": 63.0, "batch_reward": 0.5338633926212788, "critic_loss": 1.0308014359176159, "actor_loss": -89.59235374450684, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.0546817779541, "step": 63000}
{"episode_reward": 887.4050335856508, "episode": 64.0, "batch_reward": 0.5417021975517273, "critic_loss": 0.9826121821999549, "actor_loss": -89.55798770141601, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.716272354125977, "step": 64000}
{"episode_reward": 864.3409863888452, "episode": 65.0, "batch_reward": 0.5454781031608582, "critic_loss": 0.9321280493736267, "actor_loss": -89.36554238891601, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.26941156387329, "step": 65000}
{"episode_reward": 934.9485920587928, "episode": 66.0, "batch_reward": 0.5520586502254009, "critic_loss": 0.8946008220016957, "actor_loss": -89.3572707824707, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.694725513458252, "step": 66000}
{"episode_reward": 951.215108637126, "episode": 67.0, "batch_reward": 0.5586167283952236, "critic_loss": 0.8597046995460987, "actor_loss": -89.34007281494141, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.903611660003662, "step": 67000}
{"episode_reward": 912.850670582855, "episode": 68.0, "batch_reward": 0.5640174976885318, "critic_loss": 0.847344499617815, "actor_loss": -89.37164138793945, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.32426118850708, "step": 68000}
{"episode_reward": 935.5485682686628, "episode": 69.0, "batch_reward": 0.5700192841887474, "critic_loss": 0.817421558380127, "actor_loss": -89.31615840148926, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.522088050842285, "step": 69000}
{"episode_reward": 933.8443539187034, "episode": 70.0, "batch_reward": 0.5745080356001854, "critic_loss": 0.8204573945701122, "actor_loss": -89.21273323059081, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.647862434387207, "step": 70000}
{"episode_reward": 890.3049492654153, "episode": 71.0, "batch_reward": 0.5773462899625301, "critic_loss": 0.7779098397195339, "actor_loss": -89.15586650085449, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 44.500216245651245, "step": 71000}
{"episode_reward": 898.9845245973005, "episode": 72.0, "batch_reward": 0.5825579034984112, "critic_loss": 0.7751580332219601, "actor_loss": -89.03660308837891, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.04160189628601, "step": 72000}
{"episode_reward": 909.0348482971184, "episode": 73.0, "batch_reward": 0.586004075050354, "critic_loss": 0.8013708055019378, "actor_loss": -88.94082563781738, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.867639780044556, "step": 73000}
{"episode_reward": 941.0140080187879, "episode": 74.0, "batch_reward": 0.5912796857059002, "critic_loss": 0.7686133657097817, "actor_loss": -89.02661862182617, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.317312240600586, "step": 74000}
{"episode_reward": 925.6366154338222, "episode": 75.0, "batch_reward": 0.5995936163663864, "critic_loss": 0.80262567076087, "actor_loss": -89.11333296203614, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.725053548812866, "step": 75000}
{"episode_reward": 913.45979741684, "episode": 76.0, "batch_reward": 0.6032776757478714, "critic_loss": 0.8047740302681923, "actor_loss": -89.13887100219726, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.67454695701599, "step": 76000}
{"episode_reward": 932.5225001631669, "episode": 77.0, "batch_reward": 0.6050454081594944, "critic_loss": 0.7734846070706844, "actor_loss": -89.04611555480957, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.35608720779419, "step": 77000}
{"episode_reward": 921.2476976907316, "episode": 78.0, "batch_reward": 0.6081248279511928, "critic_loss": 0.7521868013441563, "actor_loss": -88.91622840881348, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.337573289871216, "step": 78000}
{"episode_reward": 898.169252216107, "episode": 79.0, "batch_reward": 0.6125830985605717, "critic_loss": 0.7264600273966789, "actor_loss": -88.89580519104004, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.164103507995605, "step": 79000}
{"episode_reward": 946.6548829547704, "episode": 80.0, "batch_reward": 0.61639057046175, "critic_loss": 0.7211754370927811, "actor_loss": -89.01771713256836, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.845305681228638, "step": 80000}
{"episode_reward": 921.7473650401437, "episode": 81.0, "batch_reward": 0.6221150527596474, "critic_loss": 0.7136743958890438, "actor_loss": -88.94910102844239, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.287195920944214, "step": 81000}
{"episode_reward": 858.1285243313304, "episode": 82.0, "batch_reward": 0.6214518444538116, "critic_loss": 0.7192626388072968, "actor_loss": -88.91482418823242, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.220070123672485, "step": 82000}
{"episode_reward": 933.1029896246542, "episode": 83.0, "batch_reward": 0.6269132280349732, "critic_loss": 0.7261245481669902, "actor_loss": -89.12306988525391, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.086243391036987, "step": 83000}
{"episode_reward": 912.6048139290496, "episode": 84.0, "batch_reward": 0.6286396491825581, "critic_loss": 0.7255105848908424, "actor_loss": -89.09049435424805, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.792139768600464, "step": 84000}
{"episode_reward": 863.374912105879, "episode": 85.0, "batch_reward": 0.6325485168695449, "critic_loss": 0.7536291501522064, "actor_loss": -88.95748561096191, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.21819496154785, "step": 85000}
{"episode_reward": 929.5848248371523, "episode": 86.0, "batch_reward": 0.6397373948693276, "critic_loss": 0.7260807009637356, "actor_loss": -89.15064498901367, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 24.005300998687744, "step": 86000}
{"episode_reward": 941.3616077596066, "episode": 87.0, "batch_reward": 0.6398182255625725, "critic_loss": 0.7424238599836827, "actor_loss": -89.23088703918457, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.650911808013916, "step": 87000}
{"episode_reward": 890.7785351913052, "episode": 88.0, "batch_reward": 0.6444499303102493, "critic_loss": 0.7124280135333538, "actor_loss": -89.2712576751709, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.817699193954468, "step": 88000}
{"episode_reward": 960.1091012471262, "episode": 89.0, "batch_reward": 0.6482460802197456, "critic_loss": 0.7072576168179512, "actor_loss": -89.10194100952148, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.39673113822937, "step": 89000}
{"episode_reward": 931.4703697094203, "episode": 90.0, "batch_reward": 0.6504339710474014, "critic_loss": 0.7130664437413216, "actor_loss": -89.15931895446778, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.332595348358154, "step": 90000}
{"episode_reward": 953.8402390722173, "episode": 91.0, "batch_reward": 0.6541270686984062, "critic_loss": 0.6751708111763001, "actor_loss": -89.09849064636231, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.864752531051636, "step": 91000}
{"episode_reward": 875.4454180558363, "episode": 92.0, "batch_reward": 0.6562052148580552, "critic_loss": 0.6859726822674275, "actor_loss": -89.22396281433106, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.586800813674927, "step": 92000}
{"episode_reward": 926.9854291819028, "episode": 93.0, "batch_reward": 0.6598179388642311, "critic_loss": 0.6736002354025841, "actor_loss": -89.31722364807129, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.774954319000244, "step": 93000}
{"episode_reward": 966.4590088367642, "episode": 94.0, "batch_reward": 0.6634162479043006, "critic_loss": 0.6493895568549634, "actor_loss": -89.40853919982911, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.330039978027344, "step": 94000}
{"episode_reward": 947.5083859852574, "episode": 95.0, "batch_reward": 0.665897764801979, "critic_loss": 0.6378063727170229, "actor_loss": -89.51742640686035, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.128239154815674, "step": 95000}
{"episode_reward": 933.2154186098153, "episode": 96.0, "batch_reward": 0.6676441215872765, "critic_loss": 0.6397783598899841, "actor_loss": -89.4466145324707, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.280950784683228, "step": 96000}
