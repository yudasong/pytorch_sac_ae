{"episode_reward": 0.0, "episode": 1.0, "duration": 21.10836625099182, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.8384904861450195, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.45778247530200394, "critic_loss": 0.20940567799615598, "actor_loss": -83.78296378060502, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 60.192567586898804, "step": 3000}
{"episode_reward": 432.54362573408775, "episode": 4.0, "batch_reward": 0.47994726929068565, "critic_loss": 0.4983204289674759, "actor_loss": -84.19363116455078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.149495840072632, "step": 4000}
{"episode_reward": 643.3411530557105, "episode": 5.0, "batch_reward": 0.5063897600471974, "critic_loss": 0.574022211164236, "actor_loss": -84.79687858581543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15610909461975, "step": 5000}
{"episode_reward": 422.5093343327092, "episode": 6.0, "batch_reward": 0.505418245434761, "critic_loss": 0.7632551175355912, "actor_loss": -84.69412753295899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.14926552772522, "step": 6000}
{"episode_reward": 726.9537744265614, "episode": 7.0, "batch_reward": 0.5345910062491894, "critic_loss": 0.9265706023275853, "actor_loss": -85.43053501892089, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.144455432891846, "step": 7000}
{"episode_reward": 710.5669540061872, "episode": 8.0, "batch_reward": 0.5635398639142514, "critic_loss": 1.0874389562010764, "actor_loss": -86.54161059570312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.130847215652466, "step": 8000}
{"episode_reward": 744.4780580467498, "episode": 9.0, "batch_reward": 0.571677720606327, "critic_loss": 1.1467077637314795, "actor_loss": -86.67180378723144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.155457496643066, "step": 9000}
{"episode_reward": 581.4548294741497, "episode": 10.0, "batch_reward": 0.5607941423654557, "critic_loss": 1.0988085417747497, "actor_loss": -86.62212788391113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.12458062171936, "step": 10000}
{"episode_reward": 412.26471670112915, "episode": 11.0, "batch_reward": 0.5705420022010803, "critic_loss": 1.1705952451229096, "actor_loss": -86.87872549438477, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.94074201583862, "step": 11000}
{"episode_reward": 801.9201941187729, "episode": 12.0, "batch_reward": 0.592994843006134, "critic_loss": 1.1353263429999352, "actor_loss": -87.39978005981445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.145201206207275, "step": 12000}
{"episode_reward": 861.67530711416, "episode": 13.0, "batch_reward": 0.613492857158184, "critic_loss": 1.1089094698429107, "actor_loss": -87.65681066894531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.125742435455322, "step": 13000}
{"episode_reward": 854.7418501111803, "episode": 14.0, "batch_reward": 0.6282694754600525, "critic_loss": 1.194066727399826, "actor_loss": -88.0819116821289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.10879683494568, "step": 14000}
{"episode_reward": 806.4686370684601, "episode": 15.0, "batch_reward": 0.6427838899493218, "critic_loss": 1.118259487092495, "actor_loss": -87.99064430236817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15031862258911, "step": 15000}
{"episode_reward": 863.3010384482671, "episode": 16.0, "batch_reward": 0.657455549299717, "critic_loss": 1.0578843814134598, "actor_loss": -88.83873638916016, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.132912397384644, "step": 16000}
{"episode_reward": 804.2204093520932, "episode": 17.0, "batch_reward": 0.6634421456456184, "critic_loss": 1.06886249679327, "actor_loss": -88.78571516418457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.13320803642273, "step": 17000}
{"episode_reward": 777.8037264080468, "episode": 18.0, "batch_reward": 0.6740710775852203, "critic_loss": 0.9389087765812874, "actor_loss": -89.00862219238282, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16168975830078, "step": 18000}
{"episode_reward": 867.2042807380307, "episode": 19.0, "batch_reward": 0.684795236825943, "critic_loss": 0.9463600626587868, "actor_loss": -89.28000448608398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.1842098236084, "step": 19000}
{"episode_reward": 871.5010913281936, "episode": 20.0, "batch_reward": 0.6917257885336876, "critic_loss": 0.8670884519517422, "actor_loss": -88.7914871673584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16162610054016, "step": 20000}
{"episode_reward": 848.0421569031988, "episode": 21.0, "batch_reward": 0.6999305236339569, "critic_loss": 0.8325997760891914, "actor_loss": -89.34017121887207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.90916419029236, "step": 21000}
{"episode_reward": 820.5090769295697, "episode": 22.0, "batch_reward": 0.7061045904755592, "critic_loss": 0.8617104492485523, "actor_loss": -89.1060121307373, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.148186683654785, "step": 22000}
{"episode_reward": 826.8068552319861, "episode": 23.0, "batch_reward": 0.7101797480583191, "critic_loss": 0.8804611134231091, "actor_loss": -89.16373075866699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.165180683135986, "step": 23000}
{"episode_reward": 881.9982466655515, "episode": 24.0, "batch_reward": 0.717557903945446, "critic_loss": 0.8664893907606601, "actor_loss": -89.2517421875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.171340703964233, "step": 24000}
{"episode_reward": 875.4900934483236, "episode": 25.0, "batch_reward": 0.7268206660747528, "critic_loss": 0.8029003917574883, "actor_loss": -89.39842330932618, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.161744594573975, "step": 25000}
{"episode_reward": 928.7059450040579, "episode": 26.0, "batch_reward": 0.7348947328329086, "critic_loss": 0.8187315099537372, "actor_loss": -89.77633647155761, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.143192529678345, "step": 26000}
{"episode_reward": 925.1818873202443, "episode": 27.0, "batch_reward": 0.7420725261569023, "critic_loss": 0.775431087911129, "actor_loss": -89.66473356628418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.1393883228302, "step": 27000}
{"episode_reward": 937.2636212165296, "episode": 28.0, "batch_reward": 0.7469935466647148, "critic_loss": 0.7292639816403389, "actor_loss": -89.83571426391602, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.157283306121826, "step": 28000}
{"episode_reward": 888.9451058972686, "episode": 29.0, "batch_reward": 0.7546640253663063, "critic_loss": 0.7380198011696338, "actor_loss": -89.85904714965821, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.14783263206482, "step": 29000}
{"episode_reward": 944.0009435605168, "episode": 30.0, "batch_reward": 0.7573821102976799, "critic_loss": 0.724124337553978, "actor_loss": -90.02978814697266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.138304948806763, "step": 30000}
{"episode_reward": 870.8630939667622, "episode": 31.0, "batch_reward": 0.7616363619565963, "critic_loss": 0.681968102902174, "actor_loss": -90.39686991882324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.896536111831665, "step": 31000}
{"episode_reward": 884.690342074648, "episode": 32.0, "batch_reward": 0.7672503155469894, "critic_loss": 0.6692774856984616, "actor_loss": -90.60483502197266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.205490589141846, "step": 32000}
{"episode_reward": 903.1438712044121, "episode": 33.0, "batch_reward": 0.7727266451716424, "critic_loss": 0.6585455301404, "actor_loss": -90.6577876586914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17105221748352, "step": 33000}
{"episode_reward": 904.0430533438913, "episode": 34.0, "batch_reward": 0.7758509649634361, "critic_loss": 0.6431916256248951, "actor_loss": -91.04795932006836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.177735090255737, "step": 34000}
{"episode_reward": 924.0744981307056, "episode": 35.0, "batch_reward": 0.7796149965524674, "critic_loss": 0.6134381173551082, "actor_loss": -90.95716775512696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.198418140411377, "step": 35000}
{"episode_reward": 907.4240545774916, "episode": 36.0, "batch_reward": 0.78341324198246, "critic_loss": 0.6162656398415566, "actor_loss": -91.44403016662598, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.177103519439697, "step": 36000}
{"episode_reward": 874.5232847196752, "episode": 37.0, "batch_reward": 0.7878198917508126, "critic_loss": 0.6077916659712791, "actor_loss": -91.39075836181641, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16652798652649, "step": 37000}
{"episode_reward": 921.5659815261042, "episode": 38.0, "batch_reward": 0.7903747333884239, "critic_loss": 0.59158108907938, "actor_loss": -91.19199313354493, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.210882902145386, "step": 38000}
{"episode_reward": 930.1791101555402, "episode": 39.0, "batch_reward": 0.7951380932331085, "critic_loss": 0.546766393572092, "actor_loss": -91.628040725708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.150824546813965, "step": 39000}
{"episode_reward": 956.6119115428661, "episode": 40.0, "batch_reward": 0.7961856791973114, "critic_loss": 0.5587278969287872, "actor_loss": -91.83197145080567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.14177370071411, "step": 40000}
{"episode_reward": 925.6836737984664, "episode": 41.0, "batch_reward": 0.8016142095923424, "critic_loss": 0.5480481691658496, "actor_loss": -92.01458264160156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.816009283065796, "step": 41000}
{"episode_reward": 958.7490501166654, "episode": 42.0, "batch_reward": 0.8040942984223366, "critic_loss": 0.5369801670014859, "actor_loss": -91.83752249145508, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.188748836517334, "step": 42000}
{"episode_reward": 954.8990404080071, "episode": 43.0, "batch_reward": 0.8077462337613106, "critic_loss": 0.5867893842756748, "actor_loss": -92.14774263000488, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15857172012329, "step": 43000}
{"episode_reward": 852.612959939839, "episode": 44.0, "batch_reward": 0.8092630221247673, "critic_loss": 0.6109149100780487, "actor_loss": -91.90808460998535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15601396560669, "step": 44000}
{"episode_reward": 930.1773461835796, "episode": 45.0, "batch_reward": 0.810561523258686, "critic_loss": 0.5698244163095951, "actor_loss": -91.85497071838378, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.177347898483276, "step": 45000}
{"episode_reward": 872.049056571469, "episode": 46.0, "batch_reward": 0.8135119042396546, "critic_loss": 0.5564833019673824, "actor_loss": -92.28799296569824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.153034210205078, "step": 46000}
{"episode_reward": 895.3596021988341, "episode": 47.0, "batch_reward": 0.8160602679848671, "critic_loss": 0.5686342857033014, "actor_loss": -92.35682955932617, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16554856300354, "step": 47000}
{"episode_reward": 940.4793458441814, "episode": 48.0, "batch_reward": 0.8192246223092079, "critic_loss": 0.5579723380506039, "actor_loss": -92.52850077819824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.181750535964966, "step": 48000}
{"episode_reward": 934.8042371404837, "episode": 49.0, "batch_reward": 0.8202625514864922, "critic_loss": 0.5459064739644528, "actor_loss": -92.60111233520507, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.150739908218384, "step": 49000}
{"episode_reward": 876.9229624124312, "episode": 50.0, "batch_reward": 0.8222756915092468, "critic_loss": 0.5535074569135904, "actor_loss": -92.49562586975098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17412233352661, "step": 50000}
{"episode_reward": 914.5418187564293, "episode": 51.0, "batch_reward": 0.8250097113251686, "critic_loss": 0.5418817606419325, "actor_loss": -92.58786114501953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.96041703224182, "step": 51000}
{"episode_reward": 927.6659854025606, "episode": 52.0, "batch_reward": 0.824083421587944, "critic_loss": 0.5409767035841941, "actor_loss": -92.74973294067382, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.14172673225403, "step": 52000}
{"episode_reward": 880.0587011832248, "episode": 53.0, "batch_reward": 0.8261574491858482, "critic_loss": 0.5357660796791315, "actor_loss": -92.42659426879882, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.183120012283325, "step": 53000}
{"episode_reward": 907.4009560957863, "episode": 54.0, "batch_reward": 0.8267856413125991, "critic_loss": 0.5649819395244121, "actor_loss": -92.95312573242188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.173449516296387, "step": 54000}
{"episode_reward": 915.4010162750591, "episode": 55.0, "batch_reward": 0.8294337594509125, "critic_loss": 0.5241611305177212, "actor_loss": -92.88145581054688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.191197633743286, "step": 55000}
{"episode_reward": 947.7305270932211, "episode": 56.0, "batch_reward": 0.8327670438289643, "critic_loss": 0.5403951964974404, "actor_loss": -92.77806422424317, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.178134441375732, "step": 56000}
{"episode_reward": 969.3532864288597, "episode": 57.0, "batch_reward": 0.8331819741129876, "critic_loss": 0.5471114609837532, "actor_loss": -92.91958422851563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.177590131759644, "step": 57000}
{"episode_reward": 911.7557251270586, "episode": 58.0, "batch_reward": 0.8350594440698623, "critic_loss": 0.5511104600429535, "actor_loss": -93.05408749389649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.1378436088562, "step": 58000}
{"episode_reward": 897.9408394186702, "episode": 59.0, "batch_reward": 0.8373648111224175, "critic_loss": 0.5325457299053669, "actor_loss": -93.1008871459961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17164182662964, "step": 59000}
{"episode_reward": 931.8023048269096, "episode": 60.0, "batch_reward": 0.8378713911175728, "critic_loss": 0.5530298491120338, "actor_loss": -93.12426608276367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.167621612548828, "step": 60000}
{"episode_reward": 900.314113577743, "episode": 61.0, "batch_reward": 0.8391042495369911, "critic_loss": 0.552054600611329, "actor_loss": -93.2344400024414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.9196572303772, "step": 61000}
{"episode_reward": 872.1303432298356, "episode": 62.0, "batch_reward": 0.8386059301495552, "critic_loss": 0.5429320159554482, "actor_loss": -93.04764100646973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.183257341384888, "step": 62000}
{"episode_reward": 932.1867155945217, "episode": 63.0, "batch_reward": 0.8393956966996193, "critic_loss": 0.5561971051841974, "actor_loss": -93.03572396850586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.181867599487305, "step": 63000}
{"episode_reward": 901.9114212171786, "episode": 64.0, "batch_reward": 0.8422795350551605, "critic_loss": 0.5737986598610878, "actor_loss": -93.24915101623534, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.146470308303833, "step": 64000}
{"episode_reward": 883.6642666704654, "episode": 65.0, "batch_reward": 0.8428993850946427, "critic_loss": 0.5469534739553928, "actor_loss": -93.17333891296387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.13271141052246, "step": 65000}
{"episode_reward": 960.3696213832646, "episode": 66.0, "batch_reward": 0.8443372568488121, "critic_loss": 0.5222202482521534, "actor_loss": -93.31575860595703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15114188194275, "step": 66000}
{"episode_reward": 948.4986654106696, "episode": 67.0, "batch_reward": 0.8461016771793366, "critic_loss": 0.506668484672904, "actor_loss": -93.3165918121338, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.187796115875244, "step": 67000}
{"episode_reward": 929.764912487151, "episode": 68.0, "batch_reward": 0.8466668651103973, "critic_loss": 0.5298544605374336, "actor_loss": -93.46956996154785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.169028520584106, "step": 68000}
{"episode_reward": 920.334241089836, "episode": 69.0, "batch_reward": 0.8495755062103272, "critic_loss": 0.5371123606562614, "actor_loss": -93.54705345153809, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.170867204666138, "step": 69000}
{"episode_reward": 969.1146263719808, "episode": 70.0, "batch_reward": 0.8498224502205849, "critic_loss": 0.5337473042905331, "actor_loss": -93.71654713439942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.164165019989014, "step": 70000}
{"episode_reward": 929.5694312504174, "episode": 71.0, "batch_reward": 0.8499183673858642, "critic_loss": 0.5123606618195772, "actor_loss": -93.47067195129395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.87998867034912, "step": 71000}
{"episode_reward": 934.7745460301579, "episode": 72.0, "batch_reward": 0.8524605310559272, "critic_loss": 0.5555209428668022, "actor_loss": -93.76602543640136, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.12633228302002, "step": 72000}
{"episode_reward": 937.6260666607907, "episode": 73.0, "batch_reward": 0.8523449919223786, "critic_loss": 0.5167591076642275, "actor_loss": -93.72754534912109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.161388635635376, "step": 73000}
{"episode_reward": 937.113801438727, "episode": 74.0, "batch_reward": 0.855123210966587, "critic_loss": 0.5036758223474026, "actor_loss": -93.8248656463623, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.183082818984985, "step": 74000}
{"episode_reward": 944.7853935343987, "episode": 75.0, "batch_reward": 0.8572973793745041, "critic_loss": 0.5519116652160883, "actor_loss": -93.93286375427246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.192760944366455, "step": 75000}
{"episode_reward": 952.2350069247258, "episode": 76.0, "batch_reward": 0.8571028347015381, "critic_loss": 0.4894721494615078, "actor_loss": -93.98783238220214, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18424916267395, "step": 76000}
{"episode_reward": 932.9468765042159, "episode": 77.0, "batch_reward": 0.858866816341877, "critic_loss": 0.48711125454306603, "actor_loss": -94.01858808898926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18158268928528, "step": 77000}
{"episode_reward": 960.2809987081212, "episode": 78.0, "batch_reward": 0.8587213173508644, "critic_loss": 0.5033270070254803, "actor_loss": -93.90030625915527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.150378465652466, "step": 78000}
{"episode_reward": 869.1464127153795, "episode": 79.0, "batch_reward": 0.8583367456197739, "critic_loss": 0.48883770368993285, "actor_loss": -94.00673486328125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.170806646347046, "step": 79000}
{"episode_reward": 887.8486484369746, "episode": 80.0, "batch_reward": 0.8602548838853836, "critic_loss": 0.5288234359323979, "actor_loss": -94.0357437286377, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.13994812965393, "step": 80000}
{"episode_reward": 904.6770749538339, "episode": 81.0, "batch_reward": 0.8593141543269157, "critic_loss": 0.5020594596117735, "actor_loss": -93.96322673034668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.93727517127991, "step": 81000}
{"episode_reward": 921.5621376908068, "episode": 82.0, "batch_reward": 0.8600061437487603, "critic_loss": 0.5079949725866317, "actor_loss": -93.98809753417969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.169384002685547, "step": 82000}
{"episode_reward": 933.4183498183809, "episode": 83.0, "batch_reward": 0.8617087366580963, "critic_loss": 0.4718520164936781, "actor_loss": -94.19043852233887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.11880922317505, "step": 83000}
{"episode_reward": 947.8996483903277, "episode": 84.0, "batch_reward": 0.8631687515974045, "critic_loss": 0.49993401585519315, "actor_loss": -94.28346929931641, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.152292251586914, "step": 84000}
{"episode_reward": 911.6241387468411, "episode": 85.0, "batch_reward": 0.8623049713969231, "critic_loss": 0.5249156106561422, "actor_loss": -94.05875717163086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.178958654403687, "step": 85000}
{"episode_reward": 930.5040568447914, "episode": 86.0, "batch_reward": 0.8643067309260368, "critic_loss": 0.5557285105735064, "actor_loss": -94.13925514221191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.160327434539795, "step": 86000}
{"episode_reward": 957.2916535650952, "episode": 87.0, "batch_reward": 0.865045436680317, "critic_loss": 0.5108616808056832, "actor_loss": -94.23009515380859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15396809577942, "step": 87000}
{"episode_reward": 919.8377379793811, "episode": 88.0, "batch_reward": 0.8662529320716857, "critic_loss": 0.4799791092574596, "actor_loss": -94.32796644592285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.10872530937195, "step": 88000}
{"episode_reward": 975.3062729837608, "episode": 89.0, "batch_reward": 0.8626745423078537, "critic_loss": 0.46805728079378606, "actor_loss": -94.0974345703125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.138275384902954, "step": 89000}
{"episode_reward": 64.00042351570283, "episode": 90.0, "batch_reward": 0.8582285008430481, "critic_loss": 0.498523227930069, "actor_loss": -94.0021918334961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.154210567474365, "step": 90000}
{"episode_reward": 965.3630244240571, "episode": 91.0, "batch_reward": 0.8595771761536598, "critic_loss": 0.48343834875524044, "actor_loss": -93.99733166503906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.92133402824402, "step": 91000}
{"episode_reward": 929.4521199606157, "episode": 92.0, "batch_reward": 0.8610148698091507, "critic_loss": 0.4614710888117552, "actor_loss": -93.98257223510743, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.13563299179077, "step": 92000}
{"episode_reward": 971.8507176455546, "episode": 93.0, "batch_reward": 0.8625531247258187, "critic_loss": 0.47004249691963196, "actor_loss": -94.04756085205078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18785858154297, "step": 93000}
{"episode_reward": 969.4897997966448, "episode": 94.0, "batch_reward": 0.8624997371435166, "critic_loss": 0.46647025968134403, "actor_loss": -94.10885026550292, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16348934173584, "step": 94000}
{"episode_reward": 914.1917809797119, "episode": 95.0, "batch_reward": 0.8633706800341606, "critic_loss": 0.47749961568415167, "actor_loss": -94.16869006347656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16093897819519, "step": 95000}
{"episode_reward": 955.473557503071, "episode": 96.0, "batch_reward": 0.864313924729824, "critic_loss": 0.4802841245085001, "actor_loss": -94.11262219238282, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.179225206375122, "step": 96000}
{"episode_reward": 953.4950323928206, "episode": 97.0, "batch_reward": 0.8635821694731712, "critic_loss": 0.4528693542927504, "actor_loss": -94.13206889343262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.18258309364319, "step": 97000}
{"episode_reward": 956.91303423847, "episode": 98.0, "batch_reward": 0.8660490369796753, "critic_loss": 0.4294313424229622, "actor_loss": -94.0700990447998, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.180338621139526, "step": 98000}
{"episode_reward": 917.0303594773452, "episode": 99.0, "batch_reward": 0.8670078213214875, "critic_loss": 0.4668367249518633, "actor_loss": -94.21637736511231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17833638191223, "step": 99000}
{"episode_reward": 899.9034519578527, "episode": 100.0, "batch_reward": 0.8654252599477767, "critic_loss": 0.5053206832110881, "actor_loss": -94.13572830200195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.159444093704224, "step": 100000}
{"episode_reward": 884.5857163122872, "episode": 101.0, "batch_reward": 0.868012417435646, "critic_loss": 0.4870639067739248, "actor_loss": -94.26799108886719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.01246118545532, "step": 101000}
{"episode_reward": 950.8495945325107, "episode": 102.0, "batch_reward": 0.8685899628400803, "critic_loss": 0.5020356386452913, "actor_loss": -94.24351651000977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.107141971588135, "step": 102000}
{"episode_reward": 968.4700026816301, "episode": 103.0, "batch_reward": 0.8686857069730759, "critic_loss": 0.4536515502929688, "actor_loss": -94.22187254333497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.159674644470215, "step": 103000}
{"episode_reward": 952.3116863563396, "episode": 104.0, "batch_reward": 0.8688812261819839, "critic_loss": 0.4578588035851717, "actor_loss": -94.30443908691406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.149470806121826, "step": 104000}
{"episode_reward": 929.9359593353918, "episode": 105.0, "batch_reward": 0.8707751705646515, "critic_loss": 0.45779779452085495, "actor_loss": -94.23991191101074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16467046737671, "step": 105000}
{"episode_reward": 945.3009708057112, "episode": 106.0, "batch_reward": 0.8705323248505592, "critic_loss": 0.4541448786407709, "actor_loss": -94.35862088012695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.12730383872986, "step": 106000}
{"episode_reward": 874.695741486748, "episode": 107.0, "batch_reward": 0.8710672132372856, "critic_loss": 0.47232882280647753, "actor_loss": -94.26468115234375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.159427881240845, "step": 107000}
{"episode_reward": 877.3234233418262, "episode": 108.0, "batch_reward": 0.8702187516093254, "critic_loss": 0.49225405833125113, "actor_loss": -94.1494196472168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.194888591766357, "step": 108000}
{"episode_reward": 913.7998123841892, "episode": 109.0, "batch_reward": 0.870784345984459, "critic_loss": 0.48665605545043944, "actor_loss": -94.31156567382813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.184483528137207, "step": 109000}
{"episode_reward": 933.7499580419609, "episode": 110.0, "batch_reward": 0.8720146034955978, "critic_loss": 0.4516643165796995, "actor_loss": -94.36512287902832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.161776542663574, "step": 110000}
{"episode_reward": 917.1017025888453, "episode": 111.0, "batch_reward": 0.8725443277359008, "critic_loss": 0.45656147941946984, "actor_loss": -94.14979402160644, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.90419292449951, "step": 111000}
{"episode_reward": 927.8698116047531, "episode": 112.0, "batch_reward": 0.8730118448734283, "critic_loss": 0.4611907654106617, "actor_loss": -94.3910528869629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.171337604522705, "step": 112000}
{"episode_reward": 921.3939663200769, "episode": 113.0, "batch_reward": 0.8736385732293129, "critic_loss": 0.49699058379232885, "actor_loss": -94.31904412841797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17663812637329, "step": 113000}
{"episode_reward": 922.3509923851046, "episode": 114.0, "batch_reward": 0.8724943002462388, "critic_loss": 0.4970032551884651, "actor_loss": -94.35475468444824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.169737815856934, "step": 114000}
{"episode_reward": 976.0849816380173, "episode": 115.0, "batch_reward": 0.8739214423894882, "critic_loss": 0.5114976751357317, "actor_loss": -94.25545195007324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.191683769226074, "step": 115000}
{"episode_reward": 949.6647753320132, "episode": 116.0, "batch_reward": 0.8766002379059792, "critic_loss": 0.514148639202118, "actor_loss": -94.36077159118652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.47489094734192, "step": 116000}
{"episode_reward": 918.3267933558391, "episode": 117.0, "batch_reward": 0.8749977112412453, "critic_loss": 0.5471744279265404, "actor_loss": -94.16167253112793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.13418960571289, "step": 117000}
{"episode_reward": 929.0448064972202, "episode": 118.0, "batch_reward": 0.8752917177677154, "critic_loss": 0.4999820773154497, "actor_loss": -94.2663616027832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.10931658744812, "step": 118000}
{"episode_reward": 953.4276827924859, "episode": 119.0, "batch_reward": 0.8776866015195847, "critic_loss": 0.5073720249980688, "actor_loss": -94.34624104309081, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.138078927993774, "step": 119000}
{"episode_reward": 938.2508116474479, "episode": 120.0, "batch_reward": 0.8775061106085777, "critic_loss": 0.4936683961749077, "actor_loss": -94.2875729675293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19441270828247, "step": 120000}
{"episode_reward": 956.5880905859098, "episode": 121.0, "batch_reward": 0.8780987935066223, "critic_loss": 0.48576337453722956, "actor_loss": -94.31231718444825, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.87005949020386, "step": 121000}
{"episode_reward": 953.8293228992417, "episode": 122.0, "batch_reward": 0.8780225481987, "critic_loss": 0.5091214990317822, "actor_loss": -94.25864228820801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.14315700531006, "step": 122000}
{"episode_reward": 936.6671318972722, "episode": 123.0, "batch_reward": 0.8787155796885491, "critic_loss": 0.5016501636058092, "actor_loss": -94.5163480834961, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.146444082260132, "step": 123000}
{"episode_reward": 945.7889210262099, "episode": 124.0, "batch_reward": 0.8797119283676147, "critic_loss": 0.5036809196621179, "actor_loss": -94.44895318603515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.155354261398315, "step": 124000}
{"episode_reward": 950.2534822714856, "episode": 125.0, "batch_reward": 0.8795103202462197, "critic_loss": 0.5163483416438103, "actor_loss": -94.46341641235351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.171061754226685, "step": 125000}
{"episode_reward": 896.942345579924, "episode": 126.0, "batch_reward": 0.8819784635305404, "critic_loss": 0.5056794088631869, "actor_loss": -94.32183953857422, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.191838264465332, "step": 126000}
{"episode_reward": 966.5044818025134, "episode": 127.0, "batch_reward": 0.8814568288326263, "critic_loss": 0.4790819097906351, "actor_loss": -94.49972676086426, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.177557706832886, "step": 127000}
{"episode_reward": 933.1245658760971, "episode": 128.0, "batch_reward": 0.8804597916603089, "critic_loss": 0.46294743245840075, "actor_loss": -94.49849281311035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17384433746338, "step": 128000}
{"episode_reward": 847.7576166212573, "episode": 129.0, "batch_reward": 0.8805355741977692, "critic_loss": 0.4691589485704899, "actor_loss": -94.42532048034668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.14893937110901, "step": 129000}
{"episode_reward": 986.4143833300737, "episode": 130.0, "batch_reward": 0.883699818432331, "critic_loss": 0.46522454047203066, "actor_loss": -94.53001481628418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.111673831939697, "step": 130000}
{"episode_reward": 949.5739921245171, "episode": 131.0, "batch_reward": 0.8823981344103813, "critic_loss": 0.458184753999114, "actor_loss": -94.56637356567383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.88303256034851, "step": 131000}
{"episode_reward": 944.1322415859822, "episode": 132.0, "batch_reward": 0.882083226442337, "critic_loss": 0.45797073040902614, "actor_loss": -94.69387463378906, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.174118757247925, "step": 132000}
{"episode_reward": 950.4077718486486, "episode": 133.0, "batch_reward": 0.8834945637583732, "critic_loss": 0.45481249935925006, "actor_loss": -94.55191952514649, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.183350086212158, "step": 133000}
{"episode_reward": 964.0631841011758, "episode": 134.0, "batch_reward": 0.8844238815903663, "critic_loss": 0.43816910491883754, "actor_loss": -94.48209461975098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.197862148284912, "step": 134000}
{"episode_reward": 921.7745917501983, "episode": 135.0, "batch_reward": 0.8849956090450287, "critic_loss": 0.4444481159299612, "actor_loss": -94.70828994750977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.148631811141968, "step": 135000}
{"episode_reward": 914.5950954311065, "episode": 136.0, "batch_reward": 0.8851670274734497, "critic_loss": 0.43938098375499246, "actor_loss": -94.3986589050293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.191770315170288, "step": 136000}
{"episode_reward": 897.6518571117023, "episode": 137.0, "batch_reward": 0.8836865743994713, "critic_loss": 0.4615005409121513, "actor_loss": -94.63658758544922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17350435256958, "step": 137000}
{"episode_reward": 959.5037836640254, "episode": 138.0, "batch_reward": 0.8860143412947654, "critic_loss": 0.43179738415777685, "actor_loss": -94.67296975708008, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.15713906288147, "step": 138000}
{"episode_reward": 968.409238514569, "episode": 139.0, "batch_reward": 0.885770096540451, "critic_loss": 0.4157640918791294, "actor_loss": -94.66830570983886, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.176209688186646, "step": 139000}
{"episode_reward": 938.3355167067629, "episode": 140.0, "batch_reward": 0.8868238681554794, "critic_loss": 0.44072571162879465, "actor_loss": -94.7579108581543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.176286220550537, "step": 140000}
{"episode_reward": 918.4942345968196, "episode": 141.0, "batch_reward": 0.8848311771154403, "critic_loss": 0.46123803709447386, "actor_loss": -94.69536630249023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.89818072319031, "step": 141000}
{"episode_reward": 886.9959198553654, "episode": 142.0, "batch_reward": 0.8863627784252167, "critic_loss": 0.4466822331249714, "actor_loss": -94.58471934509278, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.186719179153442, "step": 142000}
{"episode_reward": 941.4284305843756, "episode": 143.0, "batch_reward": 0.8865308441519737, "critic_loss": 0.4284121262282133, "actor_loss": -94.64503602600098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.192609548568726, "step": 143000}
{"episode_reward": 930.9984352661562, "episode": 144.0, "batch_reward": 0.8871903918385505, "critic_loss": 0.4102395825535059, "actor_loss": -94.79975666809082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.16454768180847, "step": 144000}
{"episode_reward": 907.6043472713213, "episode": 145.0, "batch_reward": 0.8882552281022071, "critic_loss": 0.4232418425679207, "actor_loss": -94.81317181396484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.13892936706543, "step": 145000}
{"episode_reward": 870.2308712602527, "episode": 146.0, "batch_reward": 0.8864053670167923, "critic_loss": 0.44839298360049723, "actor_loss": -94.81528198242188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.19318151473999, "step": 146000}
{"episode_reward": 921.3262659360591, "episode": 147.0, "batch_reward": 0.8876615257859231, "critic_loss": 0.43197019962966443, "actor_loss": -94.77439768981934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.17658019065857, "step": 147000}
{"episode_reward": 920.9393446058455, "episode": 148.0, "batch_reward": 0.8859490380883217, "critic_loss": 0.4470092869699001, "actor_loss": -94.73222763061523, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.147151708602905, "step": 148000}
{"episode_reward": 846.8621483610381, "episode": 149.0, "batch_reward": 0.8862936263680458, "critic_loss": 0.4529308288022876, "actor_loss": -94.73235765075684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.177101135253906, "step": 149000}
{"episode_reward": 970.4861824544424, "episode": 150.0, "batch_reward": 0.8860944207310677, "critic_loss": 0.4436768571138382, "actor_loss": -94.78501826477051, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
