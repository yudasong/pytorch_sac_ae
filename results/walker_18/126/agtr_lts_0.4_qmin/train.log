{"episode_reward": 0.0, "episode": 1.0, "duration": 21.0244460105896, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.8296549320220947, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.4586140722304672, "critic_loss": 0.16315692267062346, "actor_loss": -84.16117248290918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 60.05833601951599, "step": 3000}
{"episode_reward": 463.2602794047447, "episode": 4.0, "batch_reward": 0.46025333312153816, "critic_loss": 0.35200859124958517, "actor_loss": -84.61324107360839, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.055909872055054, "step": 4000}
{"episode_reward": 443.42938271732555, "episode": 5.0, "batch_reward": 0.46798528131842615, "critic_loss": 0.4961131805330515, "actor_loss": -85.58811198425293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.054222106933594, "step": 5000}
{"episode_reward": 617.3976873835836, "episode": 6.0, "batch_reward": 0.4704509465992451, "critic_loss": 0.5404329243004322, "actor_loss": -85.69199882507324, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.037781238555908, "step": 6000}
{"episode_reward": 317.2486675134806, "episode": 7.0, "batch_reward": 0.45334180295467374, "critic_loss": 0.5695312197208404, "actor_loss": -85.084605178833, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.065792083740234, "step": 7000}
{"episode_reward": 269.30533463850117, "episode": 8.0, "batch_reward": 0.4465032616853714, "critic_loss": 0.6731122066527605, "actor_loss": -84.65416275024414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.068848371505737, "step": 8000}
{"episode_reward": 613.7618733078192, "episode": 9.0, "batch_reward": 0.4402545722126961, "critic_loss": 0.7588588669598103, "actor_loss": -84.04444938659668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.019537448883057, "step": 9000}
{"episode_reward": 143.68731753187225, "episode": 10.0, "batch_reward": 0.4214699955880642, "critic_loss": 0.802350077688694, "actor_loss": -82.927775390625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.059762954711914, "step": 10000}
{"episode_reward": 517.3476990214438, "episode": 11.0, "batch_reward": 0.44755694368481636, "critic_loss": 0.8975415801107883, "actor_loss": -83.32677409362793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.69081687927246, "step": 11000}
{"episode_reward": 826.9309176450046, "episode": 12.0, "batch_reward": 0.4767735541462898, "critic_loss": 0.989577429562807, "actor_loss": -84.11293092346192, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.063443422317505, "step": 12000}
{"episode_reward": 762.3508435273299, "episode": 13.0, "batch_reward": 0.5057034304440021, "critic_loss": 0.8980326279401779, "actor_loss": -84.74040556335449, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.077006101608276, "step": 13000}
{"episode_reward": 800.5030667852678, "episode": 14.0, "batch_reward": 0.5278914257586003, "critic_loss": 0.8965595860481262, "actor_loss": -85.33938301086425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.362518787384033, "step": 14000}
{"episode_reward": 879.3213502049393, "episode": 15.0, "batch_reward": 0.5475903368890286, "critic_loss": 0.9073434181511402, "actor_loss": -85.61048686218261, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.049716234207153, "step": 15000}
{"episode_reward": 757.1587151897327, "episode": 16.0, "batch_reward": 0.5651261349618435, "critic_loss": 0.7874595473110676, "actor_loss": -86.65231733703614, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.027003049850464, "step": 16000}
{"episode_reward": 892.7153488994128, "episode": 17.0, "batch_reward": 0.5802555330097675, "critic_loss": 0.7610408902466297, "actor_loss": -86.94565646362305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03044581413269, "step": 17000}
{"episode_reward": 795.9389716677031, "episode": 18.0, "batch_reward": 0.596115600079298, "critic_loss": 0.702654965788126, "actor_loss": -87.20278434753418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.043492794036865, "step": 18000}
{"episode_reward": 876.4133799046218, "episode": 19.0, "batch_reward": 0.6117669103741645, "critic_loss": 0.6668660618960858, "actor_loss": -87.43886524963379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04772162437439, "step": 19000}
{"episode_reward": 871.3374024282178, "episode": 20.0, "batch_reward": 0.6244421828389167, "critic_loss": 0.6488335507214069, "actor_loss": -87.42361083984375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03060245513916, "step": 20000}
{"episode_reward": 845.0912119094403, "episode": 21.0, "batch_reward": 0.6355630391836167, "critic_loss": 0.6213355245292187, "actor_loss": -87.82251867675781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.63127946853638, "step": 21000}
{"episode_reward": 824.6866765236688, "episode": 22.0, "batch_reward": 0.6437529569268227, "critic_loss": 0.6820055958926677, "actor_loss": -87.70555433654785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05516505241394, "step": 22000}
{"episode_reward": 785.5717125651745, "episode": 23.0, "batch_reward": 0.6496616942286492, "critic_loss": 0.644851231187582, "actor_loss": -88.05799238586425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05881428718567, "step": 23000}
{"episode_reward": 843.1121725652775, "episode": 24.0, "batch_reward": 0.6582749210596085, "critic_loss": 0.6338944995999336, "actor_loss": -88.06112892150878, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.056643962860107, "step": 24000}
{"episode_reward": 872.2595474120059, "episode": 25.0, "batch_reward": 0.6676500190496445, "critic_loss": 0.6452634172439575, "actor_loss": -88.38423155212402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.067755222320557, "step": 25000}
{"episode_reward": 882.9886336627056, "episode": 26.0, "batch_reward": 0.6769525449872017, "critic_loss": 0.6231062733232975, "actor_loss": -88.71965562438965, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05282998085022, "step": 26000}
{"episode_reward": 900.2620979856251, "episode": 27.0, "batch_reward": 0.6861042118668557, "critic_loss": 0.6194964309632778, "actor_loss": -88.67961499023437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03825879096985, "step": 27000}
{"episode_reward": 923.9589347112677, "episode": 28.0, "batch_reward": 0.6931444830298423, "critic_loss": 0.6004004825353623, "actor_loss": -89.11843241882325, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03847098350525, "step": 28000}
{"episode_reward": 873.6024033475994, "episode": 29.0, "batch_reward": 0.7023766544461251, "critic_loss": 0.5715132764577866, "actor_loss": -89.00343379211425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.014808177947998, "step": 29000}
{"episode_reward": 946.2728815232214, "episode": 30.0, "batch_reward": 0.7078625612258911, "critic_loss": 0.5940008565187455, "actor_loss": -89.27778343200684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03671383857727, "step": 30000}
{"episode_reward": 919.3448883023617, "episode": 31.0, "batch_reward": 0.7143212613463402, "critic_loss": 0.5625619797706604, "actor_loss": -89.62724015808105, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.547202587127686, "step": 31000}
{"episode_reward": 908.759681564747, "episode": 32.0, "batch_reward": 0.7236285675764084, "critic_loss": 0.5568898414373398, "actor_loss": -89.74411505126953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03857707977295, "step": 32000}
{"episode_reward": 952.2878423928044, "episode": 33.0, "batch_reward": 0.729500206887722, "critic_loss": 0.5231701769083739, "actor_loss": -89.6292548980713, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.06512951850891, "step": 33000}
{"episode_reward": 931.5066097384813, "episode": 34.0, "batch_reward": 0.7349972199797631, "critic_loss": 0.49334617176651957, "actor_loss": -90.09139343261718, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.06069040298462, "step": 34000}
{"episode_reward": 919.5555840897364, "episode": 35.0, "batch_reward": 0.7403034617304802, "critic_loss": 0.48136523585021496, "actor_loss": -90.22461463928222, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.013563871383667, "step": 35000}
{"episode_reward": 922.8933867130539, "episode": 36.0, "batch_reward": 0.7440389300584793, "critic_loss": 0.4787041897177696, "actor_loss": -90.29530625915527, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.013537645339966, "step": 36000}
{"episode_reward": 842.9543871853461, "episode": 37.0, "batch_reward": 0.7504056850671769, "critic_loss": 0.4634214942753315, "actor_loss": -90.51420594787598, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.036216735839844, "step": 37000}
{"episode_reward": 958.7825476541353, "episode": 38.0, "batch_reward": 0.7554137606024742, "critic_loss": 0.44788455176353453, "actor_loss": -90.42920335388183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.050917387008667, "step": 38000}
{"episode_reward": 963.1984606107582, "episode": 39.0, "batch_reward": 0.7596176334619522, "critic_loss": 0.42641488257050514, "actor_loss": -90.62939122009277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.043968439102173, "step": 39000}
{"episode_reward": 941.9692098426742, "episode": 40.0, "batch_reward": 0.7620127736926079, "critic_loss": 0.4296997417062521, "actor_loss": -90.89625537109374, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.070072889328003, "step": 40000}
{"episode_reward": 907.430117499557, "episode": 41.0, "batch_reward": 0.7676592917442322, "critic_loss": 0.40278502145409584, "actor_loss": -91.17973858642578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.61469316482544, "step": 41000}
{"episode_reward": 918.0772630376999, "episode": 42.0, "batch_reward": 0.770726902604103, "critic_loss": 0.407294654905796, "actor_loss": -91.10889057922363, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05478525161743, "step": 42000}
{"episode_reward": 814.4471461178196, "episode": 43.0, "batch_reward": 0.7737357944846154, "critic_loss": 0.4244807274341583, "actor_loss": -91.20914785766601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05677103996277, "step": 43000}
{"episode_reward": 913.6209997504344, "episode": 44.0, "batch_reward": 0.7764831480979919, "critic_loss": 0.4160696301609278, "actor_loss": -91.26289933776856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.023728132247925, "step": 44000}
{"episode_reward": 936.0726952596422, "episode": 45.0, "batch_reward": 0.7789837104082108, "critic_loss": 0.43792299288511277, "actor_loss": -91.2879658203125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.046628713607788, "step": 45000}
{"episode_reward": 881.0602238001807, "episode": 46.0, "batch_reward": 0.7798393085598946, "critic_loss": 0.43111417058110235, "actor_loss": -91.4457421875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.048031091690063, "step": 46000}
{"episode_reward": 857.7653956543073, "episode": 47.0, "batch_reward": 0.7834767588973045, "critic_loss": 0.41619638158380984, "actor_loss": -91.61238786315919, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.043404579162598, "step": 47000}
{"episode_reward": 892.2245435238689, "episode": 48.0, "batch_reward": 0.7859210487604141, "critic_loss": 0.420284427523613, "actor_loss": -91.55203240966797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05757451057434, "step": 48000}
{"episode_reward": 887.8845604850931, "episode": 49.0, "batch_reward": 0.787882315158844, "critic_loss": 0.41497392125427723, "actor_loss": -91.65331227111817, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.043216228485107, "step": 49000}
{"episode_reward": 911.0631725076892, "episode": 50.0, "batch_reward": 0.7895367085337639, "critic_loss": 0.41677241115272046, "actor_loss": -91.82587092590332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.010444164276123, "step": 50000}
{"episode_reward": 882.142560078976, "episode": 51.0, "batch_reward": 0.7934591979980469, "critic_loss": 0.40706597730517385, "actor_loss": -91.71748020935058, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.59285545349121, "step": 51000}
{"episode_reward": 891.9247487115175, "episode": 52.0, "batch_reward": 0.7932706094384193, "critic_loss": 0.41425297206640244, "actor_loss": -91.99378729248046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.058997631072998, "step": 52000}
{"episode_reward": 859.4014092855339, "episode": 53.0, "batch_reward": 0.7950773677825927, "critic_loss": 0.4346160382479429, "actor_loss": -91.78780993652343, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.052947998046875, "step": 53000}
{"episode_reward": 914.2804060480871, "episode": 54.0, "batch_reward": 0.7985644318461418, "critic_loss": 0.4223584098368883, "actor_loss": -92.16054154968262, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.024556875228882, "step": 54000}
{"episode_reward": 944.0439605922962, "episode": 55.0, "batch_reward": 0.7990261124372482, "critic_loss": 0.4109735027551651, "actor_loss": -92.10169316101074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.046363592147827, "step": 55000}
{"episode_reward": 951.2383905026924, "episode": 56.0, "batch_reward": 0.803019399881363, "critic_loss": 0.40497255735099313, "actor_loss": -92.06837812805176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.047364473342896, "step": 56000}
{"episode_reward": 954.9893383359721, "episode": 57.0, "batch_reward": 0.804641901254654, "critic_loss": 0.39138068100810053, "actor_loss": -92.21573724365234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.022504568099976, "step": 57000}
{"episode_reward": 943.9571772262448, "episode": 58.0, "batch_reward": 0.8067113820314408, "critic_loss": 0.39671001183986665, "actor_loss": -92.25684375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.033982038497925, "step": 58000}
{"episode_reward": 895.4442146840231, "episode": 59.0, "batch_reward": 0.8100661996603012, "critic_loss": 0.3912248945385218, "actor_loss": -92.48657733154297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.040436029434204, "step": 59000}
{"episode_reward": 943.7479306489704, "episode": 60.0, "batch_reward": 0.8112244112491608, "critic_loss": 0.41480449536442754, "actor_loss": -92.60251837158204, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.020644903182983, "step": 60000}
{"episode_reward": 877.7064395297728, "episode": 61.0, "batch_reward": 0.8137253350615501, "critic_loss": 0.4331551717817783, "actor_loss": -92.51699401855468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.559114933013916, "step": 61000}
{"episode_reward": 888.8115925396534, "episode": 62.0, "batch_reward": 0.8136866438388825, "critic_loss": 0.39282110147178173, "actor_loss": -92.4192043762207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.055699825286865, "step": 62000}
{"episode_reward": 968.8407429048775, "episode": 63.0, "batch_reward": 0.8141822137832642, "critic_loss": 0.41579599530994893, "actor_loss": -92.42303637695312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03049612045288, "step": 63000}
{"episode_reward": 947.4081420395246, "episode": 64.0, "batch_reward": 0.8188752091526985, "critic_loss": 0.39587543869018554, "actor_loss": -92.71069987487793, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.040027379989624, "step": 64000}
{"episode_reward": 925.4634655559694, "episode": 65.0, "batch_reward": 0.8196896300911903, "critic_loss": 0.42571592539548875, "actor_loss": -92.6814490814209, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.053966760635376, "step": 65000}
{"episode_reward": 922.9835747706387, "episode": 66.0, "batch_reward": 0.8197087512612343, "critic_loss": 0.4075793225467205, "actor_loss": -92.64397555541993, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.061920642852783, "step": 66000}
{"episode_reward": 450.52388536611295, "episode": 67.0, "batch_reward": 0.8174566681981087, "critic_loss": 0.4168046054244041, "actor_loss": -92.60029223632813, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.029892444610596, "step": 67000}
{"episode_reward": 945.858720375494, "episode": 68.0, "batch_reward": 0.8142255324721336, "critic_loss": 0.4361198258399963, "actor_loss": -92.63823043823243, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.050435304641724, "step": 68000}
{"episode_reward": 680.870209873409, "episode": 69.0, "batch_reward": 0.8161781752705574, "critic_loss": 0.4256900287419558, "actor_loss": -92.58205078125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.030380725860596, "step": 69000}
{"episode_reward": 960.4876768062209, "episode": 70.0, "batch_reward": 0.8173725273609161, "critic_loss": 0.4434063105732203, "actor_loss": -92.7164409942627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.986579656600952, "step": 70000}
{"episode_reward": 899.3479922653167, "episode": 71.0, "batch_reward": 0.818399466753006, "critic_loss": 0.4456670637577772, "actor_loss": -92.74934983825683, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.59005522727966, "step": 71000}
{"episode_reward": 951.1660616988554, "episode": 72.0, "batch_reward": 0.8223573741912842, "critic_loss": 0.4513102324008942, "actor_loss": -92.77827632141113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05459976196289, "step": 72000}
{"episode_reward": 951.2679293475343, "episode": 73.0, "batch_reward": 0.82269413459301, "critic_loss": 0.45466702279448507, "actor_loss": -92.79884375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.055887460708618, "step": 73000}
{"episode_reward": 958.4611564897274, "episode": 74.0, "batch_reward": 0.8255183405280113, "critic_loss": 0.452694851025939, "actor_loss": -92.94992353820801, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03678035736084, "step": 74000}
{"episode_reward": 946.9176038795376, "episode": 75.0, "batch_reward": 0.8281729690432549, "critic_loss": 0.45568424846231936, "actor_loss": -92.94980526733399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.032636404037476, "step": 75000}
{"episode_reward": 950.3552718340899, "episode": 76.0, "batch_reward": 0.8285569324493408, "critic_loss": 0.43654030422866347, "actor_loss": -93.04462530517579, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.014655828475952, "step": 76000}
{"episode_reward": 942.22201796245, "episode": 77.0, "batch_reward": 0.829585960149765, "critic_loss": 0.42649532113969324, "actor_loss": -92.89016557312011, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04029893875122, "step": 77000}
{"episode_reward": 970.2854821509441, "episode": 78.0, "batch_reward": 0.8316459382176399, "critic_loss": 0.4181390279829502, "actor_loss": -92.95461779785157, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.020994901657104, "step": 78000}
{"episode_reward": 949.9115799993398, "episode": 79.0, "batch_reward": 0.8329631496071815, "critic_loss": 0.3990744311362505, "actor_loss": -93.0373842010498, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.07054114341736, "step": 79000}
{"episode_reward": 940.381280232273, "episode": 80.0, "batch_reward": 0.8341344926357269, "critic_loss": 0.40922329963743687, "actor_loss": -93.16426829528808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.051294326782227, "step": 80000}
{"episode_reward": 931.3180051464168, "episode": 81.0, "batch_reward": 0.8347167597413063, "critic_loss": 0.3895908626765013, "actor_loss": -93.11496188354492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.65163707733154, "step": 81000}
{"episode_reward": 948.2221333003155, "episode": 82.0, "batch_reward": 0.8356777991652489, "critic_loss": 0.4161729366183281, "actor_loss": -93.13439459228516, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04313063621521, "step": 82000}
{"episode_reward": 932.172370042047, "episode": 83.0, "batch_reward": 0.8368944156169892, "critic_loss": 0.40906238178908827, "actor_loss": -93.27767085266113, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.055704593658447, "step": 83000}
{"episode_reward": 910.7146219816748, "episode": 84.0, "batch_reward": 0.8378429735898971, "critic_loss": 0.4213286526054144, "actor_loss": -93.3354979095459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.047266483306885, "step": 84000}
{"episode_reward": 907.4643820633693, "episode": 85.0, "batch_reward": 0.8384099144339562, "critic_loss": 0.41464999328553676, "actor_loss": -93.19784881591796, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.075800895690918, "step": 85000}
{"episode_reward": 941.8692026841032, "episode": 86.0, "batch_reward": 0.8407702934145928, "critic_loss": 0.40774384739995, "actor_loss": -93.3177632446289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.046972036361694, "step": 86000}
{"episode_reward": 952.5021128623424, "episode": 87.0, "batch_reward": 0.8421525110602379, "critic_loss": 0.4041637539714575, "actor_loss": -93.43848262023926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.048604726791382, "step": 87000}
{"episode_reward": 935.2388333321969, "episode": 88.0, "batch_reward": 0.8428468070626259, "critic_loss": 0.40288949528336526, "actor_loss": -93.47273515319824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.00442147254944, "step": 88000}
{"episode_reward": 973.7931276332694, "episode": 89.0, "batch_reward": 0.8429139471054077, "critic_loss": 0.4112757549881935, "actor_loss": -93.4151508178711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03175687789917, "step": 89000}
{"episode_reward": 928.4533342221179, "episode": 90.0, "batch_reward": 0.845509005188942, "critic_loss": 0.38131585547327995, "actor_loss": -93.53573669433594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.011329650878906, "step": 90000}
{"episode_reward": 951.3330596219839, "episode": 91.0, "batch_reward": 0.8471347257494927, "critic_loss": 0.3929916777908802, "actor_loss": -93.55959968566894, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.54272723197937, "step": 91000}
{"episode_reward": 948.4705621690291, "episode": 92.0, "batch_reward": 0.8485041912794113, "critic_loss": 0.38681928291916845, "actor_loss": -93.67840026855468, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03843927383423, "step": 92000}
{"episode_reward": 975.4449752052196, "episode": 93.0, "batch_reward": 0.8511422232389451, "critic_loss": 0.3868709124773741, "actor_loss": -93.78930923461914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.053674459457397, "step": 93000}
{"episode_reward": 895.9607654458406, "episode": 94.0, "batch_reward": 0.8502483714222908, "critic_loss": 0.40374057659506796, "actor_loss": -93.74626249694825, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04189157485962, "step": 94000}
{"episode_reward": 918.7849598986566, "episode": 95.0, "batch_reward": 0.8499708424806595, "critic_loss": 0.4141169312298298, "actor_loss": -93.75154104614258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.052265882492065, "step": 95000}
{"episode_reward": 866.5966012179645, "episode": 96.0, "batch_reward": 0.8490762264728546, "critic_loss": 0.42164869292080404, "actor_loss": -93.80059773254395, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.012768507003784, "step": 96000}
{"episode_reward": 920.8192199036348, "episode": 97.0, "batch_reward": 0.8514214154481888, "critic_loss": 0.42563018219172954, "actor_loss": -93.77111442565918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.02532958984375, "step": 97000}
{"episode_reward": 959.8470757002066, "episode": 98.0, "batch_reward": 0.8515881852507591, "critic_loss": 0.42254015807807443, "actor_loss": -93.77361630249024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.004124402999878, "step": 98000}
{"episode_reward": 909.9153310519577, "episode": 99.0, "batch_reward": 0.8535430778265, "critic_loss": 0.40645716205239296, "actor_loss": -93.94717056274413, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 19.99174189567566, "step": 99000}
{"episode_reward": 923.1178235159451, "episode": 100.0, "batch_reward": 0.8522886015176773, "critic_loss": 0.4531684563010931, "actor_loss": -93.84619787597656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.007144451141357, "step": 100000}
{"episode_reward": 922.0277360953551, "episode": 101.0, "batch_reward": 0.8556335651278496, "critic_loss": 0.4115118390545249, "actor_loss": -93.89626651000977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.971083641052246, "step": 101000}
{"episode_reward": 942.4720209120584, "episode": 102.0, "batch_reward": 0.8549184613227844, "critic_loss": 0.4412265850007534, "actor_loss": -93.86005946350097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.022948265075684, "step": 102000}
{"episode_reward": 957.5997124431228, "episode": 103.0, "batch_reward": 0.8553575842380524, "critic_loss": 0.4179310009777546, "actor_loss": -93.8712678527832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.02202081680298, "step": 103000}
{"episode_reward": 943.8912613376215, "episode": 104.0, "batch_reward": 0.8556582746505738, "critic_loss": 0.42801086758077145, "actor_loss": -93.97004069519043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.006442070007324, "step": 104000}
{"episode_reward": 915.1727718372443, "episode": 105.0, "batch_reward": 0.8582985351085662, "critic_loss": 0.4362880039066076, "actor_loss": -94.01398468017578, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.07430338859558, "step": 105000}
{"episode_reward": 940.4014936593323, "episode": 106.0, "batch_reward": 0.859179800748825, "critic_loss": 0.45250831116735935, "actor_loss": -94.1341985168457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.060698986053467, "step": 106000}
{"episode_reward": 896.5534346190699, "episode": 107.0, "batch_reward": 0.8575843796133995, "critic_loss": 0.42623420667648315, "actor_loss": -94.0395393371582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.058086156845093, "step": 107000}
{"episode_reward": 885.3660933465638, "episode": 108.0, "batch_reward": 0.8576726183891297, "critic_loss": 0.4466964681148529, "actor_loss": -93.96620649719239, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.063336610794067, "step": 108000}
{"episode_reward": 906.7620408995961, "episode": 109.0, "batch_reward": 0.8582878394722938, "critic_loss": 0.41700265602767467, "actor_loss": -94.0952527770996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.0618417263031, "step": 109000}
{"episode_reward": 924.0915225033197, "episode": 110.0, "batch_reward": 0.8599955376982689, "critic_loss": 0.4171566202491522, "actor_loss": -94.1209680480957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05287766456604, "step": 110000}
{"episode_reward": 942.0458931028109, "episode": 111.0, "batch_reward": 0.8610004767179489, "critic_loss": 0.4431585027575493, "actor_loss": -94.05342669677735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.77577042579651, "step": 111000}
{"episode_reward": 959.7088028390269, "episode": 112.0, "batch_reward": 0.8612799251079559, "critic_loss": 0.44288849852979184, "actor_loss": -94.2821769104004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.184361696243286, "step": 112000}
{"episode_reward": 918.5749658344814, "episode": 113.0, "batch_reward": 0.8629027345776558, "critic_loss": 0.4387722527235746, "actor_loss": -94.19698162841797, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.019672393798828, "step": 113000}
{"episode_reward": 932.3039308814422, "episode": 114.0, "batch_reward": 0.8619844841957093, "critic_loss": 0.4223641230165958, "actor_loss": -94.18557746887207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03748893737793, "step": 114000}
{"episode_reward": 972.8094369062313, "episode": 115.0, "batch_reward": 0.8630724732875824, "critic_loss": 0.40854703697562217, "actor_loss": -94.20374867248535, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.034716367721558, "step": 115000}
{"episode_reward": 935.1327813358727, "episode": 116.0, "batch_reward": 0.8654260640740394, "critic_loss": 0.40535255713760854, "actor_loss": -94.25167791748046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.00940728187561, "step": 116000}
{"episode_reward": 918.4118138632698, "episode": 117.0, "batch_reward": 0.8654735448360443, "critic_loss": 0.4166245808005333, "actor_loss": -94.21548522949219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.041646242141724, "step": 117000}
{"episode_reward": 958.1689120535331, "episode": 118.0, "batch_reward": 0.8653412119746208, "critic_loss": 0.3991375302374363, "actor_loss": -94.24174923706055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05002760887146, "step": 118000}
{"episode_reward": 971.2578577894446, "episode": 119.0, "batch_reward": 0.8672511397600174, "critic_loss": 0.40093365316092966, "actor_loss": -94.30792881774903, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.01927089691162, "step": 119000}
{"episode_reward": 919.920904190874, "episode": 120.0, "batch_reward": 0.8664863374829292, "critic_loss": 0.3939019950777292, "actor_loss": -94.27045335388183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05277371406555, "step": 120000}
{"episode_reward": 961.5729229701096, "episode": 121.0, "batch_reward": 0.8676267868280411, "critic_loss": 0.3837597566395998, "actor_loss": -94.42726443481445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.62978196144104, "step": 121000}
{"episode_reward": 919.8752269381376, "episode": 122.0, "batch_reward": 0.868086739063263, "critic_loss": 0.3763023794814944, "actor_loss": -94.42004112243653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.058612823486328, "step": 122000}
{"episode_reward": 949.3632171173367, "episode": 123.0, "batch_reward": 0.8702093663811684, "critic_loss": 0.37070808942615985, "actor_loss": -94.50463635253907, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.04093909263611, "step": 123000}
{"episode_reward": 984.8000900451148, "episode": 124.0, "batch_reward": 0.8701504513025283, "critic_loss": 0.3714436637163162, "actor_loss": -94.56269761657715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.042218446731567, "step": 124000}
{"episode_reward": 938.4334940667736, "episode": 125.0, "batch_reward": 0.8706763743758201, "critic_loss": 0.3876495104134083, "actor_loss": -94.62460548400878, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.060697317123413, "step": 125000}
{"episode_reward": 922.1244395090342, "episode": 126.0, "batch_reward": 0.8718659117817879, "critic_loss": 0.38077868086099625, "actor_loss": -94.52369735717774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.068965196609497, "step": 126000}
{"episode_reward": 945.2959802766972, "episode": 127.0, "batch_reward": 0.8710499011874199, "critic_loss": 0.37655224205553534, "actor_loss": -94.63192698669434, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.06225824356079, "step": 127000}
{"episode_reward": 950.786028316228, "episode": 128.0, "batch_reward": 0.8710106400251388, "critic_loss": 0.3668177859634161, "actor_loss": -94.58121072387695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.052875995635986, "step": 128000}
{"episode_reward": 944.3531989749631, "episode": 129.0, "batch_reward": 0.8714471299648285, "critic_loss": 0.3561664481163025, "actor_loss": -94.56188191223144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.076438903808594, "step": 129000}
{"episode_reward": 982.8235800086272, "episode": 130.0, "batch_reward": 0.8757914116382599, "critic_loss": 0.35035854506492614, "actor_loss": -94.6873761138916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.067838668823242, "step": 130000}
{"episode_reward": 935.2152837430033, "episode": 131.0, "batch_reward": 0.873964751958847, "critic_loss": 0.3661653581857681, "actor_loss": -94.67361376953124, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.59603476524353, "step": 131000}
{"episode_reward": 944.6647051990077, "episode": 132.0, "batch_reward": 0.8737113199830056, "critic_loss": 0.3578835141137242, "actor_loss": -94.76742027282715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.041929006576538, "step": 132000}
{"episode_reward": 928.2882355647863, "episode": 133.0, "batch_reward": 0.8741377145648003, "critic_loss": 0.37154224099218847, "actor_loss": -94.67375213623046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.058356285095215, "step": 133000}
{"episode_reward": 974.1108571161426, "episode": 134.0, "batch_reward": 0.8757012814283371, "critic_loss": 0.34434192648530004, "actor_loss": -94.76123530578613, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.06367588043213, "step": 134000}
{"episode_reward": 937.9402383743981, "episode": 135.0, "batch_reward": 0.8759390400648117, "critic_loss": 0.3342070665061474, "actor_loss": -94.83421499633789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.06973433494568, "step": 135000}
{"episode_reward": 940.483587553987, "episode": 136.0, "batch_reward": 0.8772453006505966, "critic_loss": 0.3341509955897927, "actor_loss": -94.7356837310791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.087219715118408, "step": 136000}
{"episode_reward": 943.127220893118, "episode": 137.0, "batch_reward": 0.8757895812392235, "critic_loss": 0.3380101998448372, "actor_loss": -94.80792517089844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.07545757293701, "step": 137000}
{"episode_reward": 959.1637559447074, "episode": 138.0, "batch_reward": 0.8795872787833214, "critic_loss": 0.3370348469018936, "actor_loss": -94.91315124511719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.067500591278076, "step": 138000}
{"episode_reward": 976.6515779599237, "episode": 139.0, "batch_reward": 0.8784057509303093, "critic_loss": 0.33969020351022483, "actor_loss": -94.84902026367187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.062373399734497, "step": 139000}
{"episode_reward": 922.3896344643344, "episode": 140.0, "batch_reward": 0.8807541210055351, "critic_loss": 0.338938670873642, "actor_loss": -94.99914808654785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.03040862083435, "step": 140000}
{"episode_reward": 937.3218388971283, "episode": 141.0, "batch_reward": 0.8786708223223686, "critic_loss": 0.3372624347060919, "actor_loss": -94.8677446899414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.60162544250488, "step": 141000}
{"episode_reward": 927.6745868955584, "episode": 142.0, "batch_reward": 0.8795603783726692, "critic_loss": 0.34323532463610174, "actor_loss": -94.86341178894043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.05391216278076, "step": 142000}
{"episode_reward": 950.0884855239607, "episode": 143.0, "batch_reward": 0.8800680502653122, "critic_loss": 0.32830977816134693, "actor_loss": -94.89412062072753, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.046948194503784, "step": 143000}
{"episode_reward": 913.1080803908275, "episode": 144.0, "batch_reward": 0.8812130568623543, "critic_loss": 0.3527924714908004, "actor_loss": -94.99414375305176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.07142996788025, "step": 144000}
{"episode_reward": 931.4048424714302, "episode": 145.0, "batch_reward": 0.8803333020210267, "critic_loss": 0.34161090715229514, "actor_loss": -94.9899246520996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.06890368461609, "step": 145000}
{"episode_reward": 937.8039569781566, "episode": 146.0, "batch_reward": 0.8798185598254203, "critic_loss": 0.3512410723567009, "actor_loss": -95.01461026000976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.07323384284973, "step": 146000}
{"episode_reward": 928.0555237081037, "episode": 147.0, "batch_reward": 0.8813883326649666, "critic_loss": 0.3338976515457034, "actor_loss": -95.00067315673829, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.060014247894287, "step": 147000}
{"episode_reward": 916.9673686454605, "episode": 148.0, "batch_reward": 0.8807349206209183, "critic_loss": 0.3463872018828988, "actor_loss": -94.9833716430664, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.0230872631073, "step": 148000}
{"episode_reward": 895.9775538913829, "episode": 149.0, "batch_reward": 0.8808930112719536, "critic_loss": 0.3421237577497959, "actor_loss": -95.02021896362305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.039729118347168, "step": 149000}
{"episode_reward": 958.7554140123651, "episode": 150.0, "batch_reward": 0.8802977341413498, "critic_loss": 0.3424548961520195, "actor_loss": -95.00459684753417, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
