{"episode_reward": 0.0, "episode": 1.0, "duration": 21.68942880630493, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.8698248863220215, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.4349751236658169, "critic_loss": 0.0628684289399727, "actor_loss": -60.12061096761836, "actor_target_entropy": -6.0, "alpha_value": 0.002642586817083679, "duration": 62.36755657196045, "step": 3000}
{"episode_reward": 3.9625057369002454, "episode": 4.0, "batch_reward": 0.2703140413016081, "critic_loss": 0.10056652804650366, "actor_loss": -53.501165226936344, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.251103401184082, "step": 4000}
{"episode_reward": 8.958242508421865, "episode": 5.0, "batch_reward": 0.21598935136198996, "critic_loss": 0.18675680939108133, "actor_loss": -51.67211062049866, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.74867272377014, "step": 5000}
{"episode_reward": 30.19088052151815, "episode": 6.0, "batch_reward": 0.1813622365966439, "critic_loss": 0.3226781967505813, "actor_loss": -51.179847547054294, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.706331491470337, "step": 6000}
{"episode_reward": 50.672799441219695, "episode": 7.0, "batch_reward": 0.1635552933141589, "critic_loss": 0.32002473555877803, "actor_loss": -49.86842500734329, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.9202721118927, "step": 7000}
{"episode_reward": 58.932618469020746, "episode": 8.0, "batch_reward": 0.14863913329690695, "critic_loss": 0.240116443593055, "actor_loss": -52.7696783695221, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.439246654510498, "step": 8000}
{"episode_reward": 58.34548901533528, "episode": 9.0, "batch_reward": 0.13830222967267036, "critic_loss": 0.25082415032573047, "actor_loss": -50.15216120481491, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.27266836166382, "step": 9000}
{"episode_reward": 92.6673263331331, "episode": 10.0, "batch_reward": 0.13623589700460434, "critic_loss": 0.4767291305363178, "actor_loss": -50.92939527201653, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.29733943939209, "step": 10000}
{"episode_reward": 100.27185704048688, "episode": 11.0, "batch_reward": 0.13903766001015902, "critic_loss": 0.7969874309077859, "actor_loss": -52.45761124563217, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.96415901184082, "step": 11000}
{"episode_reward": 271.5996050905903, "episode": 12.0, "batch_reward": 0.14756593725830316, "critic_loss": 1.5770975738465787, "actor_loss": -53.42448210144043, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.167672157287598, "step": 12000}
{"episode_reward": 147.97922994436408, "episode": 13.0, "batch_reward": 0.14791846657544375, "critic_loss": 2.18522951900959, "actor_loss": -55.21344015789032, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.476433753967285, "step": 13000}
{"episode_reward": 127.3925716078134, "episode": 14.0, "batch_reward": 0.1413490576595068, "critic_loss": 2.5014085739851, "actor_loss": -55.72765867614746, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.272392749786377, "step": 14000}
{"episode_reward": 70.8947643964509, "episode": 15.0, "batch_reward": 0.14067625462263822, "critic_loss": 2.829840187072754, "actor_loss": -53.55602527999878, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.799216508865356, "step": 15000}
{"episode_reward": 108.96136374757936, "episode": 16.0, "batch_reward": 0.13928798390179872, "critic_loss": 4.365187819004059, "actor_loss": -59.924051334381105, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.695757150650024, "step": 16000}
{"episode_reward": 145.3575816955987, "episode": 17.0, "batch_reward": 0.1360548831745982, "critic_loss": 4.619629501223564, "actor_loss": -59.77228330230713, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.306870460510254, "step": 17000}
{"episode_reward": 69.3260378234697, "episode": 18.0, "batch_reward": 0.13463660887628795, "critic_loss": 6.071201534986496, "actor_loss": -61.326847244262694, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.979456663131714, "step": 18000}
{"episode_reward": 123.20960321373514, "episode": 19.0, "batch_reward": 0.1347729094326496, "critic_loss": 6.1127691378593445, "actor_loss": -63.48037686920166, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.124826192855835, "step": 19000}
{"episode_reward": 128.28778279840125, "episode": 20.0, "batch_reward": 0.13740711788088084, "critic_loss": 8.08064835357666, "actor_loss": -62.83001692581177, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.284056901931763, "step": 20000}
{"episode_reward": 349.66676794388223, "episode": 21.0, "batch_reward": 0.14757702926546334, "critic_loss": 9.560809221982955, "actor_loss": -66.19744116973877, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.02373218536377, "step": 21000}
{"episode_reward": 237.1792383358043, "episode": 22.0, "batch_reward": 0.15199997263401746, "critic_loss": 9.526791901350022, "actor_loss": -69.00298818206787, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.263752460479736, "step": 22000}
{"episode_reward": 213.89737969413915, "episode": 23.0, "batch_reward": 0.1575137863829732, "critic_loss": 8.46874130487442, "actor_loss": -71.50752114105225, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.761617183685303, "step": 23000}
{"episode_reward": 485.7245667675645, "episode": 24.0, "batch_reward": 0.1642291898056865, "critic_loss": 7.6855609698295595, "actor_loss": -73.62455119323731, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.092547178268433, "step": 24000}
{"episode_reward": 73.67008043624271, "episode": 25.0, "batch_reward": 0.16722883073985575, "critic_loss": 6.954835084676742, "actor_loss": -74.80413394165039, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.51622724533081, "step": 25000}
{"episode_reward": 404.9275604567154, "episode": 26.0, "batch_reward": 0.17171285204589368, "critic_loss": 6.118410296678543, "actor_loss": -76.06090895080567, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.524473905563354, "step": 26000}
{"episode_reward": 113.90114418289878, "episode": 27.0, "batch_reward": 0.1719545030221343, "critic_loss": 4.928627602577209, "actor_loss": -76.91705015563964, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.92570161819458, "step": 27000}
{"episode_reward": 185.92347829450003, "episode": 28.0, "batch_reward": 0.16792240715771914, "critic_loss": 3.9798849279880524, "actor_loss": -76.97821266174316, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.875860452651978, "step": 28000}
{"episode_reward": 120.414564395663, "episode": 29.0, "batch_reward": 0.17311564218252898, "critic_loss": 3.3097194021940233, "actor_loss": -76.37024842834472, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.646694660186768, "step": 29000}
{"episode_reward": 313.5669866814786, "episode": 30.0, "batch_reward": 0.17247423432022332, "critic_loss": 2.667378735303879, "actor_loss": -75.9959642791748, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.320399284362793, "step": 30000}
{"episode_reward": 105.43222503363039, "episode": 31.0, "batch_reward": 0.16952621763199568, "critic_loss": 2.351511760354042, "actor_loss": -75.82990187835694, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.32853388786316, "step": 31000}
{"episode_reward": 63.230902797698626, "episode": 32.0, "batch_reward": 0.167931387796998, "critic_loss": 2.2039359308481217, "actor_loss": -75.3517674407959, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.283690214157104, "step": 32000}
{"episode_reward": 354.7730600848958, "episode": 33.0, "batch_reward": 0.1759059579372406, "critic_loss": 2.0446683367490768, "actor_loss": -74.79863199615478, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.629709720611572, "step": 33000}
{"episode_reward": 331.1307782202641, "episode": 34.0, "batch_reward": 0.18216876646876334, "critic_loss": 2.13032750082016, "actor_loss": -75.11178302001953, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.459935665130615, "step": 34000}
{"episode_reward": 580.3635035097496, "episode": 35.0, "batch_reward": 0.19425162313878536, "critic_loss": 2.2306218467950822, "actor_loss": -74.40571993255615, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.46622943878174, "step": 35000}
{"episode_reward": 529.3242028100495, "episode": 36.0, "batch_reward": 0.20004253455996512, "critic_loss": 2.1372398280501366, "actor_loss": -75.39946300506591, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.812503814697266, "step": 36000}
{"episode_reward": 332.8234321702653, "episode": 37.0, "batch_reward": 0.21240791857242583, "critic_loss": 2.2447492327690126, "actor_loss": -74.91296521759033, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.757244348526, "step": 37000}
{"episode_reward": 737.4147885520487, "episode": 38.0, "batch_reward": 0.22395112273097037, "critic_loss": 2.450873930811882, "actor_loss": -74.38200763702393, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.54815125465393, "step": 38000}
{"episode_reward": 766.633242691602, "episode": 39.0, "batch_reward": 0.23108202089369298, "critic_loss": 2.6154186441898344, "actor_loss": -75.1941889038086, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.520460844039917, "step": 39000}
{"episode_reward": 93.20088064332236, "episode": 40.0, "batch_reward": 0.2311767651438713, "critic_loss": 2.697257730603218, "actor_loss": -75.13438558197022, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.396961450576782, "step": 40000}
{"episode_reward": 286.247028000883, "episode": 41.0, "batch_reward": 0.23264168511331082, "critic_loss": 2.6697456933259964, "actor_loss": -75.68676354980468, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.105571269989014, "step": 41000}
{"episode_reward": 539.8676077648274, "episode": 42.0, "batch_reward": 0.24328819100558757, "critic_loss": 2.6997764624357226, "actor_loss": -75.0470816268921, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.38543725013733, "step": 42000}
{"episode_reward": 636.2888467127356, "episode": 43.0, "batch_reward": 0.2515493447035551, "critic_loss": 2.907987861156464, "actor_loss": -75.91430155181885, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.182358741760254, "step": 43000}
{"episode_reward": 517.8584465033016, "episode": 44.0, "batch_reward": 0.2586409662216902, "critic_loss": 2.9667066155672073, "actor_loss": -75.44480297851563, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.158818006515503, "step": 44000}
{"episode_reward": 645.1870300316021, "episode": 45.0, "batch_reward": 0.2670412949621677, "critic_loss": 2.825049546957016, "actor_loss": -75.38040032958985, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.267083883285522, "step": 45000}
{"episode_reward": 749.6442292445836, "episode": 46.0, "batch_reward": 0.2777019745707512, "critic_loss": 2.6542774616479874, "actor_loss": -76.06651049804688, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.4722740650177, "step": 46000}
{"episode_reward": 694.3455416139416, "episode": 47.0, "batch_reward": 0.28671991302073, "critic_loss": 2.6985264459848404, "actor_loss": -76.52853774261474, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.24190092086792, "step": 47000}
{"episode_reward": 739.2443659703, "episode": 48.0, "batch_reward": 0.29924718849360943, "critic_loss": 2.7513970180749894, "actor_loss": -76.58926164245605, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.509231090545654, "step": 48000}
{"episode_reward": 745.5956700695208, "episode": 49.0, "batch_reward": 0.30750129017233846, "critic_loss": 2.610390301346779, "actor_loss": -76.88372900390625, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.552385091781616, "step": 49000}
{"episode_reward": 746.8238119764485, "episode": 50.0, "batch_reward": 0.3146184400469065, "critic_loss": 2.587485639333725, "actor_loss": -76.38760144805909, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.851338386535645, "step": 50000}
{"episode_reward": 752.396402983998, "episode": 51.0, "batch_reward": 0.32603937473893163, "critic_loss": 2.476933770298958, "actor_loss": -76.94395994567871, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.49993109703064, "step": 51000}
{"episode_reward": 842.8968321525041, "episode": 52.0, "batch_reward": 0.33237521144747734, "critic_loss": 2.578692627429962, "actor_loss": -77.53927381896973, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.26746916770935, "step": 52000}
{"episode_reward": 546.6614225964669, "episode": 53.0, "batch_reward": 0.33923654632270334, "critic_loss": 2.522355694651604, "actor_loss": -76.3395910949707, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.64777970314026, "step": 53000}
{"episode_reward": 822.5920582494975, "episode": 54.0, "batch_reward": 0.3486994856894016, "critic_loss": 2.558706328868866, "actor_loss": -78.73470081329346, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.975491285324097, "step": 54000}
{"episode_reward": 800.0596784480482, "episode": 55.0, "batch_reward": 0.3535918024778366, "critic_loss": 2.4958190556764603, "actor_loss": -78.15220824432373, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.275550842285156, "step": 55000}
{"episode_reward": 816.5877147038492, "episode": 56.0, "batch_reward": 0.3645526525080204, "critic_loss": 2.409456494808197, "actor_loss": -77.33402378845214, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.465574026107788, "step": 56000}
{"episode_reward": 928.1337310103261, "episode": 57.0, "batch_reward": 0.37510219237208364, "critic_loss": 2.373387812376022, "actor_loss": -78.53115112304687, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.842278718948364, "step": 57000}
{"episode_reward": 820.4230460121564, "episode": 58.0, "batch_reward": 0.38262010481953623, "critic_loss": 2.3196164509057997, "actor_loss": -78.46091680145264, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.265750408172607, "step": 58000}
{"episode_reward": 813.0158255254235, "episode": 59.0, "batch_reward": 0.38977983275055883, "critic_loss": 2.2760864326953887, "actor_loss": -79.02451708984376, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.70869541168213, "step": 59000}
{"episode_reward": 869.5246010815673, "episode": 60.0, "batch_reward": 0.3972593407034874, "critic_loss": 2.165142582178116, "actor_loss": -78.72525045776368, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.96462059020996, "step": 60000}
{"episode_reward": 781.1925385067372, "episode": 61.0, "batch_reward": 0.4025174798965454, "critic_loss": 2.106330107629299, "actor_loss": -79.61900971221924, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.913546323776245, "step": 61000}
{"episode_reward": 584.8223116756702, "episode": 62.0, "batch_reward": 0.40626028287410737, "critic_loss": 2.1032911401987078, "actor_loss": -79.0513203048706, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.40667223930359, "step": 62000}
{"episode_reward": 858.891406640545, "episode": 63.0, "batch_reward": 0.41209121787548064, "critic_loss": 1.9846174849271774, "actor_loss": -79.7715372543335, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.989808082580566, "step": 63000}
{"episode_reward": 879.0945889602176, "episode": 64.0, "batch_reward": 0.42185703966021537, "critic_loss": 2.0478322688937185, "actor_loss": -80.68790585327149, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.43812656402588, "step": 64000}
{"episode_reward": 866.7738141192827, "episode": 65.0, "batch_reward": 0.428533480077982, "critic_loss": 2.00981705313921, "actor_loss": -80.28054499816895, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.60086417198181, "step": 65000}
{"episode_reward": 864.5241732323445, "episode": 66.0, "batch_reward": 0.4339352106153965, "critic_loss": 1.8787796060442925, "actor_loss": -80.76721626281739, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.115880250930786, "step": 66000}
{"episode_reward": 868.1666576623309, "episode": 67.0, "batch_reward": 0.44041300264000893, "critic_loss": 1.7469546287059783, "actor_loss": -80.629898147583, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.328049898147583, "step": 67000}
{"episode_reward": 860.6652528879633, "episode": 68.0, "batch_reward": 0.449062603443861, "critic_loss": 1.7630380621552468, "actor_loss": -81.73686903381348, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.242203950881958, "step": 68000}
{"episode_reward": 934.4776189523054, "episode": 69.0, "batch_reward": 0.45617844596505164, "critic_loss": 1.6169292771816253, "actor_loss": -81.58019227600097, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.001591444015503, "step": 69000}
{"episode_reward": 885.9964794395327, "episode": 70.0, "batch_reward": 0.46068323880434037, "critic_loss": 1.7224996357560158, "actor_loss": -82.17688438415527, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.940662384033203, "step": 70000}
{"episode_reward": 865.6856320775662, "episode": 71.0, "batch_reward": 0.46415170925855637, "critic_loss": 1.6560589960813523, "actor_loss": -80.98269526672364, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.09918785095215, "step": 71000}
{"episode_reward": 887.8681616196658, "episode": 72.0, "batch_reward": 0.47235439535975454, "critic_loss": 1.6434443020224572, "actor_loss": -82.13476309204101, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.675905227661133, "step": 72000}
{"episode_reward": 868.6761847467517, "episode": 73.0, "batch_reward": 0.4770321082174778, "critic_loss": 1.5906075654029845, "actor_loss": -82.4307250213623, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.364265203475952, "step": 73000}
{"episode_reward": 883.1209652461857, "episode": 74.0, "batch_reward": 0.48304020768404005, "critic_loss": 1.5654697979092598, "actor_loss": -82.57754081726074, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.089301586151123, "step": 74000}
{"episode_reward": 865.5786494571169, "episode": 75.0, "batch_reward": 0.48968528044223786, "critic_loss": 1.5581378739476204, "actor_loss": -82.99881120300293, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.478739976882935, "step": 75000}
{"episode_reward": 853.8973531345802, "episode": 76.0, "batch_reward": 0.4947133235633373, "critic_loss": 1.5717074014544488, "actor_loss": -83.02317004394531, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.272298574447632, "step": 76000}
{"episode_reward": 907.178189176229, "episode": 77.0, "batch_reward": 0.5001802534162998, "critic_loss": 1.455448767364025, "actor_loss": -83.08328675842286, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.023152828216553, "step": 77000}
{"episode_reward": 912.3192779143436, "episode": 78.0, "batch_reward": 0.502318867713213, "critic_loss": 1.4911766905784607, "actor_loss": -83.25047669982911, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.722720623016357, "step": 78000}
{"episode_reward": 849.2796214672824, "episode": 79.0, "batch_reward": 0.5092410113811493, "critic_loss": 1.4277537550330162, "actor_loss": -83.3227139892578, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.481969833374023, "step": 79000}
{"episode_reward": 879.1300656098343, "episode": 80.0, "batch_reward": 0.5125113678574562, "critic_loss": 1.4116449288725852, "actor_loss": -83.54659219360352, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.392282724380493, "step": 80000}
{"episode_reward": 863.6072316677794, "episode": 81.0, "batch_reward": 0.5188307688534259, "critic_loss": 1.3637457209229469, "actor_loss": -83.36959008789063, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.97379922866821, "step": 81000}
{"episode_reward": 867.6530833445289, "episode": 82.0, "batch_reward": 0.5177207614779472, "critic_loss": 1.4497111693024636, "actor_loss": -83.50091743469238, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.354990005493164, "step": 82000}
{"episode_reward": 812.8049236635713, "episode": 83.0, "batch_reward": 0.5248914926946163, "critic_loss": 1.4428953006863594, "actor_loss": -84.40183877563477, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.997196912765503, "step": 83000}
{"episode_reward": 890.3014994239792, "episode": 84.0, "batch_reward": 0.5276588256657123, "critic_loss": 1.4191851657032966, "actor_loss": -84.49944627380371, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.353707790374756, "step": 84000}
{"episode_reward": 899.7597458565308, "episode": 85.0, "batch_reward": 0.5326331992745399, "critic_loss": 1.4242889212965966, "actor_loss": -83.90375605773926, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.885393381118774, "step": 85000}
{"episode_reward": 911.0143595787193, "episode": 86.0, "batch_reward": 0.5402901385426522, "critic_loss": 1.3926046484708785, "actor_loss": -84.24947792053223, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.902714729309082, "step": 86000}
{"episode_reward": 908.8711740185498, "episode": 87.0, "batch_reward": 0.5422868965268135, "critic_loss": 1.3219287626743317, "actor_loss": -84.52896829223633, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.24910855293274, "step": 87000}
{"episode_reward": 880.6062898946938, "episode": 88.0, "batch_reward": 0.5496333354115486, "critic_loss": 1.367079311311245, "actor_loss": -84.91767951965332, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.418874263763428, "step": 88000}
{"episode_reward": 914.5776609228157, "episode": 89.0, "batch_reward": 0.5496314743459225, "critic_loss": 1.376156275689602, "actor_loss": -84.35930499267577, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.926909923553467, "step": 89000}
{"episode_reward": 719.6774955721464, "episode": 90.0, "batch_reward": 0.5531098081767559, "critic_loss": 1.3575631829500199, "actor_loss": -84.90873582458497, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.49816083908081, "step": 90000}
{"episode_reward": 933.6570517998061, "episode": 91.0, "batch_reward": 0.5568589232861996, "critic_loss": 1.3185636462569237, "actor_loss": -84.70981233215332, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.44038701057434, "step": 91000}
{"episode_reward": 871.6983098588953, "episode": 92.0, "batch_reward": 0.560099693030119, "critic_loss": 1.317579587161541, "actor_loss": -85.13211280822753, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.2861168384552, "step": 92000}
{"episode_reward": 890.3940924478297, "episode": 93.0, "batch_reward": 0.5643504773378372, "critic_loss": 1.306007019519806, "actor_loss": -85.4248151397705, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.49544072151184, "step": 93000}
{"episode_reward": 907.1988756790686, "episode": 94.0, "batch_reward": 0.5688718939423562, "critic_loss": 1.2884770473837852, "actor_loss": -85.96908155822754, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.25722599029541, "step": 94000}
{"episode_reward": 853.542669827843, "episode": 95.0, "batch_reward": 0.5707335618436337, "critic_loss": 1.3367968919873237, "actor_loss": -85.8775057067871, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.272298574447632, "step": 95000}
{"episode_reward": 910.2659014869582, "episode": 96.0, "batch_reward": 0.5739154148697853, "critic_loss": 1.350016127884388, "actor_loss": -85.74462367248535, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.178494930267334, "step": 96000}
{"episode_reward": 882.8738771352146, "episode": 97.0, "batch_reward": 0.5763083864152432, "critic_loss": 1.3197648793458938, "actor_loss": -85.6770651550293, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.29088521003723, "step": 97000}
{"episode_reward": 907.1605218446089, "episode": 98.0, "batch_reward": 0.581528361171484, "critic_loss": 1.3161284612417221, "actor_loss": -85.62375318908691, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.101627826690674, "step": 98000}
{"episode_reward": 894.4671693439321, "episode": 99.0, "batch_reward": 0.5844637300670147, "critic_loss": 1.3030619673132897, "actor_loss": -85.93975393676757, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.815165042877197, "step": 99000}
{"episode_reward": 881.016735977848, "episode": 100.0, "batch_reward": 0.5860244463980198, "critic_loss": 1.3550522621273995, "actor_loss": -85.99347611999512, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.30185317993164, "step": 100000}
{"episode_reward": 894.2267292290258, "episode": 101.0, "batch_reward": 0.5898128117918968, "critic_loss": 1.3642930136322975, "actor_loss": -86.01104780578613, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.68827986717224, "step": 101000}
{"episode_reward": 883.9627314829111, "episode": 102.0, "batch_reward": 0.5905541198849678, "critic_loss": 1.4062717550992965, "actor_loss": -86.61188014221192, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.27921462059021, "step": 102000}
{"episode_reward": 471.47886231035193, "episode": 103.0, "batch_reward": 0.5918062774240971, "critic_loss": 1.3580408968925477, "actor_loss": -85.89753312683105, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.78053641319275, "step": 103000}
{"episode_reward": 914.9294914812533, "episode": 104.0, "batch_reward": 0.5926574438214302, "critic_loss": 1.4204571258425713, "actor_loss": -86.29649452209473, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.134345531463623, "step": 104000}
{"episode_reward": 900.9278061204091, "episode": 105.0, "batch_reward": 0.5987544159293174, "critic_loss": 1.4525737809538841, "actor_loss": -85.93446833801269, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.448512077331543, "step": 105000}
{"episode_reward": 897.5208032613917, "episode": 106.0, "batch_reward": 0.5997080778479577, "critic_loss": 1.3880884965062141, "actor_loss": -86.86277239990234, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.70470929145813, "step": 106000}
{"episode_reward": 891.4267736894913, "episode": 107.0, "batch_reward": 0.6044712153375149, "critic_loss": 1.365394818842411, "actor_loss": -86.47405314636231, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.28333044052124, "step": 107000}
{"episode_reward": 883.7981383407803, "episode": 108.0, "batch_reward": 0.6055231537520885, "critic_loss": 1.3830982962250709, "actor_loss": -86.0343628692627, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.39261031150818, "step": 108000}
{"episode_reward": 913.9861715000485, "episode": 109.0, "batch_reward": 0.6089221556782722, "critic_loss": 1.380490322291851, "actor_loss": -86.85695793151855, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.7460458278656, "step": 109000}
{"episode_reward": 871.1138913711318, "episode": 110.0, "batch_reward": 0.6111542429327965, "critic_loss": 1.3819378325343132, "actor_loss": -86.61350048828125, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.565256118774414, "step": 110000}
{"episode_reward": 902.5394887384895, "episode": 111.0, "batch_reward": 0.6137250514924526, "critic_loss": 1.3740331320762633, "actor_loss": -86.42279821777343, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.66949391365051, "step": 111000}
{"episode_reward": 877.2348114930271, "episode": 112.0, "batch_reward": 0.616930923640728, "critic_loss": 1.4164143611788749, "actor_loss": -87.00788856506348, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.491220235824585, "step": 112000}
{"episode_reward": 923.3931344569296, "episode": 113.0, "batch_reward": 0.6195621459484101, "critic_loss": 1.4389993801116943, "actor_loss": -87.08272607421875, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.660727500915527, "step": 113000}
{"episode_reward": 905.1359111474403, "episode": 114.0, "batch_reward": 0.6208773396015167, "critic_loss": 1.429675089120865, "actor_loss": -87.44225631713867, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.23262858390808, "step": 114000}
{"episode_reward": 921.7115291514876, "episode": 115.0, "batch_reward": 0.6230778562426567, "critic_loss": 1.3590127273201942, "actor_loss": -87.09860539245605, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.261174201965332, "step": 115000}
{"episode_reward": 877.8573552092847, "episode": 116.0, "batch_reward": 0.6280769054889679, "critic_loss": 1.5335489486455918, "actor_loss": -87.32035980224609, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.235515594482422, "step": 116000}
{"episode_reward": 883.8823923176892, "episode": 117.0, "batch_reward": 0.6276867444515228, "critic_loss": 1.572838838160038, "actor_loss": -86.78350549316406, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.323240756988525, "step": 117000}
{"episode_reward": 921.3354524901647, "episode": 118.0, "batch_reward": 0.630214930832386, "critic_loss": 1.744724552690983, "actor_loss": -87.25559652709961, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.27124333381653, "step": 118000}
{"episode_reward": 901.4975706121693, "episode": 119.0, "batch_reward": 0.6344160429239273, "critic_loss": 1.9134724976420403, "actor_loss": -87.38925018310547, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.325015544891357, "step": 119000}
{"episode_reward": 877.9531746648194, "episode": 120.0, "batch_reward": 0.6352432325482369, "critic_loss": 2.0276344938874247, "actor_loss": -87.20805862426758, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.793770790100098, "step": 120000}
{"episode_reward": 912.5191989022255, "episode": 121.0, "batch_reward": 0.6369427781105041, "critic_loss": 2.4260981711149214, "actor_loss": -87.14626121520996, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.98955965042114, "step": 121000}
{"episode_reward": 897.4295592251736, "episode": 122.0, "batch_reward": 0.6399874665141105, "critic_loss": 2.9887297449707986, "actor_loss": -87.52803115844726, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.644229412078857, "step": 122000}
{"episode_reward": 759.6640880346467, "episode": 123.0, "batch_reward": 0.6400618653297424, "critic_loss": 3.341050789773464, "actor_loss": -87.99262028503418, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.715312242507935, "step": 123000}
{"episode_reward": 883.7805628679882, "episode": 124.0, "batch_reward": 0.6430343113541603, "critic_loss": 3.8181060630083086, "actor_loss": -87.9238020477295, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.543546438217163, "step": 124000}
{"episode_reward": 913.2222813861863, "episode": 125.0, "batch_reward": 0.643246383190155, "critic_loss": 5.540641557216644, "actor_loss": -88.05283103942871, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.77708387374878, "step": 125000}
{"episode_reward": 667.5995062922384, "episode": 126.0, "batch_reward": 0.6452501811981202, "critic_loss": 5.045210348367691, "actor_loss": -87.88838217163087, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.869351625442505, "step": 126000}
{"episode_reward": 910.4264547579435, "episode": 127.0, "batch_reward": 0.6463081718683242, "critic_loss": 5.321582762360573, "actor_loss": -87.95146801757812, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.128031253814697, "step": 127000}
{"episode_reward": 903.3570101680182, "episode": 128.0, "batch_reward": 0.6466499128937722, "critic_loss": 5.8087322944402695, "actor_loss": -88.30710182189941, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.28501534461975, "step": 128000}
{"episode_reward": 770.934995227931, "episode": 129.0, "batch_reward": 0.6487703206539154, "critic_loss": 5.063626160144806, "actor_loss": -88.25418922424316, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.22575545310974, "step": 129000}
{"episode_reward": 927.2526503001415, "episode": 130.0, "batch_reward": 0.6533485263586044, "critic_loss": 4.813418017864227, "actor_loss": -88.47487545776367, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.991050004959106, "step": 130000}
{"episode_reward": 833.298793983037, "episode": 131.0, "batch_reward": 0.6502071486115456, "critic_loss": 4.995811481952667, "actor_loss": -88.6758031463623, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.66732454299927, "step": 131000}
{"episode_reward": 63.04124267379438, "episode": 132.0, "batch_reward": 0.6470042484998703, "critic_loss": 4.983074529528618, "actor_loss": -88.89435205078125, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.028532028198242, "step": 132000}
{"episode_reward": 870.1380140689474, "episode": 133.0, "batch_reward": 0.6488043355345726, "critic_loss": 4.371138296246529, "actor_loss": -88.82938629150391, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.470202684402466, "step": 133000}
{"episode_reward": 60.85254349889053, "episode": 134.0, "batch_reward": 0.6467496986985206, "critic_loss": 4.213545259356499, "actor_loss": -88.75426831054688, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.77605104446411, "step": 134000}
{"episode_reward": 930.7599083078395, "episode": 135.0, "batch_reward": 0.6495758855938911, "critic_loss": 3.7762541600465775, "actor_loss": -88.88712599182129, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.4930636882782, "step": 135000}
{"episode_reward": 906.018868250418, "episode": 136.0, "batch_reward": 0.6499659395813941, "critic_loss": 3.519259707272053, "actor_loss": -88.4823461151123, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.608214855194092, "step": 136000}
{"episode_reward": 916.3247869410674, "episode": 137.0, "batch_reward": 0.6513726625442505, "critic_loss": 3.90092097812891, "actor_loss": -89.13202940368652, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.75982928276062, "step": 137000}
{"episode_reward": 920.1428975178194, "episode": 138.0, "batch_reward": 0.6551563739180565, "critic_loss": 3.6625278554558753, "actor_loss": -89.30545544433593, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.7271625995636, "step": 138000}
{"episode_reward": 942.6525809815985, "episode": 139.0, "batch_reward": 0.6575041282176971, "critic_loss": 3.7668242576122286, "actor_loss": -89.25006617736817, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.506718635559082, "step": 139000}
{"episode_reward": 885.7891562371043, "episode": 140.0, "batch_reward": 0.6609917923808097, "critic_loss": 3.9202860209345816, "actor_loss": -89.24570613098145, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.56342840194702, "step": 140000}
{"episode_reward": 890.463171961735, "episode": 141.0, "batch_reward": 0.6583923599123955, "critic_loss": 4.0392658457756045, "actor_loss": -89.2789264831543, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.12567591667175, "step": 141000}
{"episode_reward": 887.7603756786446, "episode": 142.0, "batch_reward": 0.6592685727477073, "critic_loss": 3.8813619782328606, "actor_loss": -89.12900932312012, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.9239764213562, "step": 142000}
{"episode_reward": 905.7802905483682, "episode": 143.0, "batch_reward": 0.6610766059756279, "critic_loss": 3.8944638440012933, "actor_loss": -89.38724308776855, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.25560736656189, "step": 143000}
{"episode_reward": 866.6676784085155, "episode": 144.0, "batch_reward": 0.6642718511223793, "critic_loss": 3.3730193269252777, "actor_loss": -89.51765197753906, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.5764377117157, "step": 144000}
{"episode_reward": 882.5018929754331, "episode": 145.0, "batch_reward": 0.6667813954949379, "critic_loss": 3.8930291550159453, "actor_loss": -89.7713681640625, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.784857988357544, "step": 145000}
{"episode_reward": 742.5242858695451, "episode": 146.0, "batch_reward": 0.6656675854325295, "critic_loss": 3.411983746051788, "actor_loss": -89.71618368530274, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.528101444244385, "step": 146000}
{"episode_reward": 863.961289253369, "episode": 147.0, "batch_reward": 0.6647852445840836, "critic_loss": 3.3445138385295867, "actor_loss": -89.65839833068847, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.66137409210205, "step": 147000}
{"episode_reward": 59.564857066979854, "episode": 148.0, "batch_reward": 0.662971548140049, "critic_loss": 2.861492294192314, "actor_loss": -89.7257998046875, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.301136016845703, "step": 148000}
{"episode_reward": 820.0447984984122, "episode": 149.0, "batch_reward": 0.664647945702076, "critic_loss": 2.755455887079239, "actor_loss": -89.46833041381836, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.479743003845215, "step": 149000}
{"episode_reward": 964.9074264020537, "episode": 150.0, "batch_reward": 0.666063154399395, "critic_loss": 2.4315744988322257, "actor_loss": -89.43457417297363, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "step": 150000}
