{"episode_reward": 0.0, "episode": 1.0, "duration": 20.88947057723999, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.8207063674926758, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.46679872789157156, "critic_loss": 0.2541558916390777, "actor_loss": -83.58879772917467, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 63.94850420951843, "step": 3000}
{"episode_reward": 599.7057683002963, "episode": 4.0, "batch_reward": 0.5003250155746937, "critic_loss": 0.5698658038079739, "actor_loss": -85.1455650024414, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.212318658828735, "step": 4000}
{"episode_reward": 310.3453691860591, "episode": 5.0, "batch_reward": 0.4475718311071396, "critic_loss": 0.5964755075275898, "actor_loss": -84.44192196655274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.21493673324585, "step": 5000}
{"episode_reward": 236.6314682103941, "episode": 6.0, "batch_reward": 0.445146112382412, "critic_loss": 0.62327725481987, "actor_loss": -84.54026837158203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20250630378723, "step": 6000}
{"episode_reward": 816.3924238323295, "episode": 7.0, "batch_reward": 0.45509662869572637, "critic_loss": 0.692374069750309, "actor_loss": -84.68350454711914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.230567693710327, "step": 7000}
{"episode_reward": 99.26671527488875, "episode": 8.0, "batch_reward": 0.4461961919367313, "critic_loss": 0.7925978756248951, "actor_loss": -84.78238821411132, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.208404541015625, "step": 8000}
{"episode_reward": 744.8844204759621, "episode": 9.0, "batch_reward": 0.47468799209594725, "critic_loss": 1.0687920669913291, "actor_loss": -85.16080679321288, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.211446285247803, "step": 9000}
{"episode_reward": 626.16230439078, "episode": 10.0, "batch_reward": 0.5040970202386379, "critic_loss": 1.2074807760715485, "actor_loss": -85.8531993560791, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.201356887817383, "step": 10000}
{"episode_reward": 835.2802019582771, "episode": 11.0, "batch_reward": 0.5330624530613423, "critic_loss": 1.2613027871251106, "actor_loss": -86.48545045471191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.703500509262085, "step": 11000}
{"episode_reward": 795.417147743405, "episode": 12.0, "batch_reward": 0.5391986307501793, "critic_loss": 1.2183868523836137, "actor_loss": -86.48019728088379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.215648889541626, "step": 12000}
{"episode_reward": 595.4203553142788, "episode": 13.0, "batch_reward": 0.556547972023487, "critic_loss": 1.1882330446243285, "actor_loss": -86.73183489990234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20210886001587, "step": 13000}
{"episode_reward": 827.1405046945009, "episode": 14.0, "batch_reward": 0.5803663230836391, "critic_loss": 1.1187538731694222, "actor_loss": -87.23381434631348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.190762281417847, "step": 14000}
{"episode_reward": 908.1854508313205, "episode": 15.0, "batch_reward": 0.6026910182833671, "critic_loss": 1.1395139905810356, "actor_loss": -87.18164019775391, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.507566452026367, "step": 15000}
{"episode_reward": 838.9442026629584, "episode": 16.0, "batch_reward": 0.619860550403595, "critic_loss": 1.1156866241693497, "actor_loss": -88.30633854675293, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.186347007751465, "step": 16000}
{"episode_reward": 930.6094435674315, "episode": 17.0, "batch_reward": 0.6340219496488572, "critic_loss": 1.1457230280041695, "actor_loss": -88.3944223022461, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.160054445266724, "step": 17000}
{"episode_reward": 809.3336058037295, "episode": 18.0, "batch_reward": 0.6457664390802383, "critic_loss": 1.158234827876091, "actor_loss": -88.72740046691895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.176319360733032, "step": 18000}
{"episode_reward": 861.0095087373538, "episode": 19.0, "batch_reward": 0.657805728495121, "critic_loss": 1.1538034568428994, "actor_loss": -89.05680574035645, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.217427968978882, "step": 19000}
{"episode_reward": 861.8387818269449, "episode": 20.0, "batch_reward": 0.6685237321853638, "critic_loss": 1.21391002035141, "actor_loss": -88.80685653686524, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.217265129089355, "step": 20000}
{"episode_reward": 888.4076429370836, "episode": 21.0, "batch_reward": 0.6773935502171516, "critic_loss": 1.2939092703461648, "actor_loss": -89.12397747802734, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.67163848876953, "step": 21000}
{"episode_reward": 824.4541619265549, "episode": 22.0, "batch_reward": 0.6867349097132682, "critic_loss": 1.256934212744236, "actor_loss": -89.23168534851074, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.192856788635254, "step": 22000}
{"episode_reward": 875.7143128896877, "episode": 23.0, "batch_reward": 0.6778557895421982, "critic_loss": 1.223644152879715, "actor_loss": -89.07639689636231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.199225425720215, "step": 23000}
{"episode_reward": 128.79295459602454, "episode": 24.0, "batch_reward": 0.6706005893349648, "critic_loss": 1.2146722561120986, "actor_loss": -88.68815283203125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.198293447494507, "step": 24000}
{"episode_reward": 899.7980282874248, "episode": 25.0, "batch_reward": 0.6821000553965568, "critic_loss": 1.2210215135216713, "actor_loss": -89.36967417907715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.195920705795288, "step": 25000}
{"episode_reward": 928.5801414178669, "episode": 26.0, "batch_reward": 0.6898402506113053, "critic_loss": 1.2106206833720208, "actor_loss": -89.21903381347656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.18513011932373, "step": 26000}
{"episode_reward": 911.7604642613612, "episode": 27.0, "batch_reward": 0.6979982364177704, "critic_loss": 1.1509195549190046, "actor_loss": -89.39278062438964, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.195466995239258, "step": 27000}
{"episode_reward": 848.340966370259, "episode": 28.0, "batch_reward": 0.7006562251448631, "critic_loss": 1.2277482833862305, "actor_loss": -89.60529350280761, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.187750816345215, "step": 28000}
{"episode_reward": 807.0312795413339, "episode": 29.0, "batch_reward": 0.7049932008385659, "critic_loss": 1.248493255853653, "actor_loss": -89.2565228881836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.186967134475708, "step": 29000}
{"episode_reward": 797.59019679437, "episode": 30.0, "batch_reward": 0.707921273112297, "critic_loss": 1.2378270052671432, "actor_loss": -89.37454879760742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.18663263320923, "step": 30000}
{"episode_reward": 862.1385117085418, "episode": 31.0, "batch_reward": 0.7126368820667267, "critic_loss": 1.276470741212368, "actor_loss": -89.98635562133789, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.688167333602905, "step": 31000}
{"episode_reward": 815.1004326145769, "episode": 32.0, "batch_reward": 0.7212215033769608, "critic_loss": 1.2833510373830794, "actor_loss": -90.01923800659179, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.216410636901855, "step": 32000}
{"episode_reward": 947.8964889375698, "episode": 33.0, "batch_reward": 0.7257450632452965, "critic_loss": 1.3046306495070457, "actor_loss": -90.03725703430176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.208232402801514, "step": 33000}
{"episode_reward": 924.5023653862039, "episode": 34.0, "batch_reward": 0.7312762254476547, "critic_loss": 1.186223700106144, "actor_loss": -90.30900581359863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.212092638015747, "step": 34000}
{"episode_reward": 907.6857898697422, "episode": 35.0, "batch_reward": 0.7373579376339913, "critic_loss": 1.154991489946842, "actor_loss": -90.15916705322266, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.199122667312622, "step": 35000}
{"episode_reward": 943.5594620669237, "episode": 36.0, "batch_reward": 0.7431031227111816, "critic_loss": 1.1534732056260109, "actor_loss": -90.96933389282226, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.187416076660156, "step": 36000}
{"episode_reward": 809.2247484962227, "episode": 37.0, "batch_reward": 0.7464540625810623, "critic_loss": 1.1340184885263442, "actor_loss": -90.68707501220703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20092463493347, "step": 37000}
{"episode_reward": 932.3242199241287, "episode": 38.0, "batch_reward": 0.7465748156309128, "critic_loss": 1.2112600987553597, "actor_loss": -90.28146412658691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.191685676574707, "step": 38000}
{"episode_reward": 792.6870140201277, "episode": 39.0, "batch_reward": 0.7510542284846305, "critic_loss": 1.2385854354202748, "actor_loss": -90.92054899597169, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.19622039794922, "step": 39000}
{"episode_reward": 906.3102857902779, "episode": 40.0, "batch_reward": 0.7531029733419419, "critic_loss": 1.2781854776740074, "actor_loss": -90.96550987243653, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.19985556602478, "step": 40000}
{"episode_reward": 902.1999915459545, "episode": 41.0, "batch_reward": 0.755705596089363, "critic_loss": 1.3088140859007835, "actor_loss": -91.34194570922851, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.671125650405884, "step": 41000}
{"episode_reward": 831.928856005532, "episode": 42.0, "batch_reward": 0.7575687419772148, "critic_loss": 1.3834076423645019, "actor_loss": -90.59582440185547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.19212770462036, "step": 42000}
{"episode_reward": 823.2462495267631, "episode": 43.0, "batch_reward": 0.7624840890169143, "critic_loss": 1.380361012995243, "actor_loss": -91.20742965698243, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.19094443321228, "step": 43000}
{"episode_reward": 900.6459851661299, "episode": 44.0, "batch_reward": 0.7647399377822875, "critic_loss": 1.3841690282821655, "actor_loss": -91.22664761352539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.186785221099854, "step": 44000}
{"episode_reward": 873.0107227742861, "episode": 45.0, "batch_reward": 0.7678655926585197, "critic_loss": 1.3999616221785545, "actor_loss": -91.16876753234864, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.215514659881592, "step": 45000}
{"episode_reward": 901.2482914626744, "episode": 46.0, "batch_reward": 0.7711445394754409, "critic_loss": 1.3204405905604362, "actor_loss": -91.2309779663086, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.203293085098267, "step": 46000}
{"episode_reward": 849.2186365092895, "episode": 47.0, "batch_reward": 0.7705018764734268, "critic_loss": 1.3475194424986838, "actor_loss": -91.45208688354492, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.214343786239624, "step": 47000}
{"episode_reward": 839.7406867627967, "episode": 48.0, "batch_reward": 0.7734230794906616, "critic_loss": 1.3349376799464225, "actor_loss": -91.46003401184082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20466709136963, "step": 48000}
{"episode_reward": 936.7329625998954, "episode": 49.0, "batch_reward": 0.7760669948458672, "critic_loss": 1.3311248047351838, "actor_loss": -91.65408599853515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.197025775909424, "step": 49000}
{"episode_reward": 829.3224285796343, "episode": 50.0, "batch_reward": 0.7782196421027183, "critic_loss": 1.306788565814495, "actor_loss": -91.37184562683106, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.18435263633728, "step": 50000}
{"episode_reward": 877.4508139524926, "episode": 51.0, "batch_reward": 0.7812539672255516, "critic_loss": 1.3106867313385009, "actor_loss": -91.589439453125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.6935088634491, "step": 51000}
{"episode_reward": 879.3853014351478, "episode": 52.0, "batch_reward": 0.780601906478405, "critic_loss": 1.26724119079113, "actor_loss": -91.80426776123046, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.190603733062744, "step": 52000}
{"episode_reward": 934.046166605196, "episode": 53.0, "batch_reward": 0.7843640776872635, "critic_loss": 1.234870303094387, "actor_loss": -91.38414436340332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.198708534240723, "step": 53000}
{"episode_reward": 888.3567890015788, "episode": 54.0, "batch_reward": 0.7864232041239738, "critic_loss": 1.2561497261822223, "actor_loss": -92.16083053588868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.188737154006958, "step": 54000}
{"episode_reward": 901.6719978867332, "episode": 55.0, "batch_reward": 0.7879835854768753, "critic_loss": 1.302486829996109, "actor_loss": -91.99399504089355, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.19484257698059, "step": 55000}
{"episode_reward": 944.6073269883011, "episode": 56.0, "batch_reward": 0.7922957955598832, "critic_loss": 1.1917001000344754, "actor_loss": -91.69718273925781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20047926902771, "step": 56000}
{"episode_reward": 979.4026543816261, "episode": 57.0, "batch_reward": 0.794673048555851, "critic_loss": 1.1575231952667235, "actor_loss": -92.24827850341796, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20637536048889, "step": 57000}
{"episode_reward": 909.293290939802, "episode": 58.0, "batch_reward": 0.7962360391616822, "critic_loss": 1.1789468480944634, "actor_loss": -92.0751106414795, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.200666904449463, "step": 58000}
{"episode_reward": 887.2282581535301, "episode": 59.0, "batch_reward": 0.7991835907697677, "critic_loss": 1.1033267837166787, "actor_loss": -92.19461848449707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.202241897583008, "step": 59000}
{"episode_reward": 936.0194201238459, "episode": 60.0, "batch_reward": 0.8008661168813705, "critic_loss": 1.1235480106174947, "actor_loss": -92.22707936096191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.21176242828369, "step": 60000}
{"episode_reward": 902.4243131652647, "episode": 61.0, "batch_reward": 0.8034679402112961, "critic_loss": 1.0545096040070057, "actor_loss": -92.50930838012695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.732292890548706, "step": 61000}
{"episode_reward": 852.262223121395, "episode": 62.0, "batch_reward": 0.8010771706700325, "critic_loss": 1.0231841157078743, "actor_loss": -92.16434411621094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.198983430862427, "step": 62000}
{"episode_reward": 923.5664623897766, "episode": 63.0, "batch_reward": 0.8008640827536583, "critic_loss": 1.021886460930109, "actor_loss": -92.3146926574707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20893883705139, "step": 63000}
{"episode_reward": 775.6848279824839, "episode": 64.0, "batch_reward": 0.8047785291075706, "critic_loss": 1.0440117962360382, "actor_loss": -92.44998876953125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.199374437332153, "step": 64000}
{"episode_reward": 856.5435996419403, "episode": 65.0, "batch_reward": 0.8065504024028778, "critic_loss": 1.047496399909258, "actor_loss": -92.41547961425782, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1994571685791, "step": 65000}
{"episode_reward": 908.6296843443922, "episode": 66.0, "batch_reward": 0.8079606955051422, "critic_loss": 1.0268047279715538, "actor_loss": -92.43918971252441, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.184340000152588, "step": 66000}
{"episode_reward": 939.338983164301, "episode": 67.0, "batch_reward": 0.8103940444588661, "critic_loss": 1.0323622768223286, "actor_loss": -92.42996484375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.190502405166626, "step": 67000}
{"episode_reward": 929.050732814828, "episode": 68.0, "batch_reward": 0.8096387152671813, "critic_loss": 1.019507953375578, "actor_loss": -92.73768775939942, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.44596242904663, "step": 68000}
{"episode_reward": 897.9567732920067, "episode": 69.0, "batch_reward": 0.8131337184309959, "critic_loss": 0.9599875691831112, "actor_loss": -92.82074000549316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.258437633514404, "step": 69000}
{"episode_reward": 956.4510885973623, "episode": 70.0, "batch_reward": 0.8135486230254173, "critic_loss": 0.9536544270217419, "actor_loss": -92.8506630859375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.163859128952026, "step": 70000}
{"episode_reward": 873.4375244020835, "episode": 71.0, "batch_reward": 0.8148158970475197, "critic_loss": 0.8988336746394634, "actor_loss": -92.66542250061035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.712592124938965, "step": 71000}
{"episode_reward": 921.0432419529961, "episode": 72.0, "batch_reward": 0.816962287068367, "critic_loss": 0.9227794767618179, "actor_loss": -93.01219604492188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20475673675537, "step": 72000}
{"episode_reward": 864.9662739659558, "episode": 73.0, "batch_reward": 0.8171679933667183, "critic_loss": 0.9155888892710209, "actor_loss": -92.95745506286622, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.511295557022095, "step": 73000}
{"episode_reward": 931.4986095987445, "episode": 74.0, "batch_reward": 0.8184519703984261, "critic_loss": 0.9173597155809402, "actor_loss": -92.85138082885742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.156882524490356, "step": 74000}
{"episode_reward": 894.1888783767632, "episode": 75.0, "batch_reward": 0.8208821546435356, "critic_loss": 0.8872886148393154, "actor_loss": -93.1451725769043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1553738117218, "step": 75000}
{"episode_reward": 914.5129656343411, "episode": 76.0, "batch_reward": 0.8206963630914688, "critic_loss": 0.8548694916367531, "actor_loss": -93.06077996826171, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.169263124465942, "step": 76000}
{"episode_reward": 926.3729091741237, "episode": 77.0, "batch_reward": 0.8231986247897148, "critic_loss": 0.9090702028870583, "actor_loss": -93.06956677246093, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.179108381271362, "step": 77000}
{"episode_reward": 917.3625741803586, "episode": 78.0, "batch_reward": 0.8223276964426041, "critic_loss": 0.8519120788276195, "actor_loss": -92.94488159179687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.18057870864868, "step": 78000}
{"episode_reward": 917.5093668628391, "episode": 79.0, "batch_reward": 0.8241735926270485, "critic_loss": 0.8705982141196728, "actor_loss": -93.15763038635254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.189284563064575, "step": 79000}
{"episode_reward": 919.1131263869215, "episode": 80.0, "batch_reward": 0.8263267859816551, "critic_loss": 0.8746417323052883, "actor_loss": -93.25087353515624, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.191280603408813, "step": 80000}
{"episode_reward": 905.8588910199602, "episode": 81.0, "batch_reward": 0.8271633440852165, "critic_loss": 0.8457127709388733, "actor_loss": -93.24601959228515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.635838985443115, "step": 81000}
{"episode_reward": 906.9559582401962, "episode": 82.0, "batch_reward": 0.8261594258546829, "critic_loss": 0.8595722381770611, "actor_loss": -93.19942427062988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.186378717422485, "step": 82000}
{"episode_reward": 896.9379238054102, "episode": 83.0, "batch_reward": 0.8286602638959885, "critic_loss": 0.8577519580423832, "actor_loss": -93.27501266479493, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.203594207763672, "step": 83000}
{"episode_reward": 931.1460632320188, "episode": 84.0, "batch_reward": 0.8298441324830055, "critic_loss": 0.8484660634994506, "actor_loss": -93.55364880371094, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.191861629486084, "step": 84000}
{"episode_reward": 886.2783003710164, "episode": 85.0, "batch_reward": 0.8288524442911148, "critic_loss": 0.884203378856182, "actor_loss": -93.3451206817627, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.206443548202515, "step": 85000}
{"episode_reward": 906.0599523256238, "episode": 86.0, "batch_reward": 0.8318427702188492, "critic_loss": 0.8645332406461239, "actor_loss": -93.54231608581543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.192760944366455, "step": 86000}
{"episode_reward": 930.7606108831017, "episode": 87.0, "batch_reward": 0.8320583616495132, "critic_loss": 0.8438107893764972, "actor_loss": -93.51220059204101, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1873881816864, "step": 87000}
{"episode_reward": 895.9120072041787, "episode": 88.0, "batch_reward": 0.8329110987782479, "critic_loss": 0.8681441128849984, "actor_loss": -93.54431175231933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.174445629119873, "step": 88000}
{"episode_reward": 922.7336868296951, "episode": 89.0, "batch_reward": 0.8340496884584427, "critic_loss": 0.8433657760918141, "actor_loss": -93.43862486267089, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.173068523406982, "step": 89000}
{"episode_reward": 943.6158483478032, "episode": 90.0, "batch_reward": 0.8357680235505104, "critic_loss": 0.8678531495034695, "actor_loss": -93.50189785766601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.189509630203247, "step": 90000}
{"episode_reward": 942.3332552744138, "episode": 91.0, "batch_reward": 0.8354712316393852, "critic_loss": 0.8806447429656983, "actor_loss": -93.41275422668457, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.67948293685913, "step": 91000}
{"episode_reward": 899.9060444508958, "episode": 92.0, "batch_reward": 0.8379442556500435, "critic_loss": 0.8152651667892933, "actor_loss": -93.58471182250976, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.17490839958191, "step": 92000}
{"episode_reward": 936.5006393595689, "episode": 93.0, "batch_reward": 0.8403378536105156, "critic_loss": 0.796170517206192, "actor_loss": -93.79307838439941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.17134404182434, "step": 93000}
{"episode_reward": 952.0664878013716, "episode": 94.0, "batch_reward": 0.8400152007341385, "critic_loss": 0.790558903157711, "actor_loss": -93.81050068664551, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.177682161331177, "step": 94000}
{"episode_reward": 927.5012776298153, "episode": 95.0, "batch_reward": 0.8403153666853904, "critic_loss": 0.7721897312104702, "actor_loss": -93.81812660217285, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.182262182235718, "step": 95000}
{"episode_reward": 906.8705675758231, "episode": 96.0, "batch_reward": 0.8411068040132522, "critic_loss": 0.7905161139070987, "actor_loss": -93.704384765625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.174635887145996, "step": 96000}
{"episode_reward": 862.414792458345, "episode": 97.0, "batch_reward": 0.8421444176435471, "critic_loss": 0.8027658189833164, "actor_loss": -93.83718821716309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.194514751434326, "step": 97000}
{"episode_reward": 945.6104075117318, "episode": 98.0, "batch_reward": 0.8429751867651939, "critic_loss": 0.763626306682825, "actor_loss": -93.84821115112305, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.186864852905273, "step": 98000}
{"episode_reward": 922.4976130663107, "episode": 99.0, "batch_reward": 0.8430944750905037, "critic_loss": 0.7875333532691002, "actor_loss": -93.79603744506836, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.184367656707764, "step": 99000}
{"episode_reward": 918.6775877676253, "episode": 100.0, "batch_reward": 0.8432253024578095, "critic_loss": 0.8061882942318916, "actor_loss": -93.97942170715332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.17651104927063, "step": 100000}
{"episode_reward": 878.6947153846011, "episode": 101.0, "batch_reward": 0.8456297305226326, "critic_loss": 0.7281210821866989, "actor_loss": -93.99234732055665, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.680073261260986, "step": 101000}
{"episode_reward": 954.8469345167993, "episode": 102.0, "batch_reward": 0.8458648697137833, "critic_loss": 0.7743893657624722, "actor_loss": -94.08277882385254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.173726320266724, "step": 102000}
{"episode_reward": 897.9010949704348, "episode": 103.0, "batch_reward": 0.8452191972136498, "critic_loss": 0.7892791068851948, "actor_loss": -93.7274264831543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.179960250854492, "step": 103000}
{"episode_reward": 884.7057317396914, "episode": 104.0, "batch_reward": 0.8461574981808663, "critic_loss": 0.7683215717673302, "actor_loss": -93.93005787658691, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.17687153816223, "step": 104000}
{"episode_reward": 899.430253422057, "episode": 105.0, "batch_reward": 0.8474070204496383, "critic_loss": 0.7431214751154185, "actor_loss": -93.85174711608887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.177615642547607, "step": 105000}
{"episode_reward": 948.484224482025, "episode": 106.0, "batch_reward": 0.8466498087644577, "critic_loss": 0.775116744607687, "actor_loss": -94.12890795898437, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.168395519256592, "step": 106000}
{"episode_reward": 872.2563881549956, "episode": 107.0, "batch_reward": 0.8474984844326973, "critic_loss": 0.7815534955859185, "actor_loss": -94.08629214477538, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.183866262435913, "step": 107000}
{"episode_reward": 797.8856414078632, "episode": 108.0, "batch_reward": 0.8470470478534698, "critic_loss": 0.8024396440982818, "actor_loss": -93.84706785583496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16255521774292, "step": 108000}
{"episode_reward": 915.9164137334395, "episode": 109.0, "batch_reward": 0.8456834126710892, "critic_loss": 0.8053209696114063, "actor_loss": -93.9872328491211, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.177045345306396, "step": 109000}
{"episode_reward": 863.7119880101483, "episode": 110.0, "batch_reward": 0.8486462358236313, "critic_loss": 0.7814284757971763, "actor_loss": -93.96971182250977, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.176956176757812, "step": 110000}
{"episode_reward": 918.7270430694862, "episode": 111.0, "batch_reward": 0.8488148438930512, "critic_loss": 0.8065404190123081, "actor_loss": -93.89055676269531, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.71400856971741, "step": 111000}
{"episode_reward": 907.9474159260203, "episode": 112.0, "batch_reward": 0.8493056694865226, "critic_loss": 0.7941728169620037, "actor_loss": -94.09380992126465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.187484979629517, "step": 112000}
{"episode_reward": 896.5165316465923, "episode": 113.0, "batch_reward": 0.8503043529391289, "critic_loss": 0.7884300982654094, "actor_loss": -94.1511487121582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.17790913581848, "step": 113000}
{"episode_reward": 947.9948434172526, "episode": 114.0, "batch_reward": 0.8506258671283722, "critic_loss": 0.7740117183923721, "actor_loss": -94.14437278747559, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.176920652389526, "step": 114000}
{"episode_reward": 955.9015924773724, "episode": 115.0, "batch_reward": 0.8508493407964707, "critic_loss": 0.7877469001114369, "actor_loss": -93.9777060699463, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.18675398826599, "step": 115000}
{"episode_reward": 910.4993830038443, "episode": 116.0, "batch_reward": 0.8538501682281494, "critic_loss": 0.837118893712759, "actor_loss": -94.11456427001953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.18950080871582, "step": 116000}
{"episode_reward": 910.0370154135813, "episode": 117.0, "batch_reward": 0.8522181983590126, "critic_loss": 0.8011511406600476, "actor_loss": -93.8753498840332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.17486071586609, "step": 117000}
{"episode_reward": 891.3357322834121, "episode": 118.0, "batch_reward": 0.8526312386989594, "critic_loss": 0.8035010729581118, "actor_loss": -94.00117668151856, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.17876696586609, "step": 118000}
{"episode_reward": 928.3051304549995, "episode": 119.0, "batch_reward": 0.8549425224065781, "critic_loss": 0.8383040718436241, "actor_loss": -94.06377061462402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.185508728027344, "step": 119000}
{"episode_reward": 902.230118755304, "episode": 120.0, "batch_reward": 0.8545172712802886, "critic_loss": 0.7866719592809677, "actor_loss": -94.05076438903808, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.169791221618652, "step": 120000}
{"episode_reward": 944.8766054978853, "episode": 121.0, "batch_reward": 0.8556858428120613, "critic_loss": 0.774302635371685, "actor_loss": -94.08338354492187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.67204022407532, "step": 121000}
{"episode_reward": 939.5265539269259, "episode": 122.0, "batch_reward": 0.8557172473073006, "critic_loss": 0.7681930675804615, "actor_loss": -94.2286259765625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.16896080970764, "step": 122000}
{"episode_reward": 936.1624330832127, "episode": 123.0, "batch_reward": 0.8565496089458465, "critic_loss": 0.7628595999479294, "actor_loss": -94.36192692565918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.188941478729248, "step": 123000}
{"episode_reward": 838.0180208897254, "episode": 124.0, "batch_reward": 0.8566646009087563, "critic_loss": 0.7740301647484302, "actor_loss": -94.32708262634277, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.18648386001587, "step": 124000}
{"episode_reward": 873.6612173678498, "episode": 125.0, "batch_reward": 0.8562851808667183, "critic_loss": 0.8032042480409145, "actor_loss": -94.31217036437988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.17465829849243, "step": 125000}
{"episode_reward": 896.4553912627691, "episode": 126.0, "batch_reward": 0.8577539749741554, "critic_loss": 0.7925350334197283, "actor_loss": -94.2072367553711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.168979167938232, "step": 126000}
{"episode_reward": 925.746191090052, "episode": 127.0, "batch_reward": 0.8559968923330307, "critic_loss": 0.8116196047365666, "actor_loss": -94.05533471679688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.168986797332764, "step": 127000}
{"episode_reward": 898.9252638248003, "episode": 128.0, "batch_reward": 0.8564871839880943, "critic_loss": 0.7921597961783409, "actor_loss": -94.14741038513183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.18584704399109, "step": 128000}
{"episode_reward": 861.0411652742567, "episode": 129.0, "batch_reward": 0.8573230283856392, "critic_loss": 0.7281740407049656, "actor_loss": -94.23939190673828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.182083129882812, "step": 129000}
{"episode_reward": 950.5167623753903, "episode": 130.0, "batch_reward": 0.858841939151287, "critic_loss": 0.7271190176308155, "actor_loss": -94.19674789428711, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.17865777015686, "step": 130000}
{"episode_reward": 903.6503473849647, "episode": 131.0, "batch_reward": 0.8575115879774093, "critic_loss": 0.781257057338953, "actor_loss": -94.30122482299805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.68498706817627, "step": 131000}
{"episode_reward": 906.0695341821579, "episode": 132.0, "batch_reward": 0.8584070276618004, "critic_loss": 0.7689886032789945, "actor_loss": -94.45907006835938, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.1758291721344, "step": 132000}
{"episode_reward": 887.9072104258989, "episode": 133.0, "batch_reward": 0.8597260273098946, "critic_loss": 0.7711771687567234, "actor_loss": -94.39296446228028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.180964708328247, "step": 133000}
{"episode_reward": 957.1501737899911, "episode": 134.0, "batch_reward": 0.8594412135481835, "critic_loss": 0.7595083174407482, "actor_loss": -94.28267306518555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.17480969429016, "step": 134000}
{"episode_reward": 845.3536865564097, "episode": 135.0, "batch_reward": 0.8602263961434364, "critic_loss": 0.7935683608949184, "actor_loss": -94.23293209838867, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.19595217704773, "step": 135000}
{"episode_reward": 926.9077946624467, "episode": 136.0, "batch_reward": 0.8602657154798508, "critic_loss": 0.7591086927652358, "actor_loss": -94.15743815612792, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.19118022918701, "step": 136000}
{"episode_reward": 911.0964008753733, "episode": 137.0, "batch_reward": 0.8603962930440903, "critic_loss": 0.7461787148267031, "actor_loss": -94.49465263366699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.20478916168213, "step": 137000}
{"episode_reward": 951.4097402717257, "episode": 138.0, "batch_reward": 0.861993275821209, "critic_loss": 0.7430028246343136, "actor_loss": -94.40160859680176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.18641710281372, "step": 138000}
{"episode_reward": 931.9951492534622, "episode": 139.0, "batch_reward": 0.8616018889546394, "critic_loss": 0.7214909275174141, "actor_loss": -94.33598680114746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.183416604995728, "step": 139000}
{"episode_reward": 884.8489508753297, "episode": 140.0, "batch_reward": 0.8643904372453689, "critic_loss": 0.7122800635397434, "actor_loss": -94.41768565368652, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.171631574630737, "step": 140000}
{"episode_reward": 894.6102255499864, "episode": 141.0, "batch_reward": 0.8607431285381317, "critic_loss": 0.7816098898649215, "actor_loss": -94.36388264465332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.73244524002075, "step": 141000}
{"episode_reward": 800.8723783120432, "episode": 142.0, "batch_reward": 0.8615824472904205, "critic_loss": 0.7839394125342369, "actor_loss": -94.09432821655274, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.171607494354248, "step": 142000}
{"episode_reward": 897.2185016917676, "episode": 143.0, "batch_reward": 0.8613497240543365, "critic_loss": 0.769685652345419, "actor_loss": -94.2436837463379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.17255687713623, "step": 143000}
{"episode_reward": 927.7755942419313, "episode": 144.0, "batch_reward": 0.8624137971997261, "critic_loss": 0.7785108390301466, "actor_loss": -94.40919358825684, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.172728538513184, "step": 144000}
{"episode_reward": 882.2731359654987, "episode": 145.0, "batch_reward": 0.8631489463448524, "critic_loss": 0.7583580374121666, "actor_loss": -94.5598522644043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.168688774108887, "step": 145000}
{"episode_reward": 850.2433861274999, "episode": 146.0, "batch_reward": 0.8627654912471772, "critic_loss": 0.7574861104041338, "actor_loss": -94.5226351776123, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.167768239974976, "step": 146000}
{"episode_reward": 892.6306919010677, "episode": 147.0, "batch_reward": 0.8625161416530609, "critic_loss": 0.7869103263616561, "actor_loss": -94.36525466918945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.176786422729492, "step": 147000}
{"episode_reward": 915.6528308966192, "episode": 148.0, "batch_reward": 0.8624776600003242, "critic_loss": 0.7704538535177707, "actor_loss": -94.53313285827636, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.170714616775513, "step": 148000}
{"episode_reward": 918.687520241883, "episode": 149.0, "batch_reward": 0.8636250585317612, "critic_loss": 0.7206884357482195, "actor_loss": -94.37226358032227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.189924240112305, "step": 149000}
{"episode_reward": 955.8321586278887, "episode": 150.0, "batch_reward": 0.8626396395564079, "critic_loss": 0.715833320081234, "actor_loss": -94.52012802124024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
