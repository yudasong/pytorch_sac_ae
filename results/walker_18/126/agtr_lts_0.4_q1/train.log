{"episode_reward": 0.0, "episode": 1.0, "duration": 24.53636622428894, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 2.238755702972412, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.4465482467987332, "critic_loss": 0.1928661957509858, "actor_loss": -83.10524859357805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 66.99989986419678, "step": 3000}
{"episode_reward": 219.01897275792203, "episode": 4.0, "batch_reward": 0.3448305969983339, "critic_loss": 0.39171888379752634, "actor_loss": -80.25603042602539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.84125542640686, "step": 4000}
{"episode_reward": 80.46559065638534, "episode": 5.0, "batch_reward": 0.28263369245827197, "critic_loss": 0.8323621310591698, "actor_loss": -77.68815187072754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.299351453781128, "step": 5000}
{"episode_reward": 168.50564630646247, "episode": 6.0, "batch_reward": 0.2942880998104811, "critic_loss": 1.385549792766571, "actor_loss": -77.11693560791015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.77966809272766, "step": 6000}
{"episode_reward": 444.9412785509168, "episode": 7.0, "batch_reward": 0.3042737311124802, "critic_loss": 1.94728915143013, "actor_loss": -77.33344157409668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.981398105621338, "step": 7000}
{"episode_reward": 212.89990391162792, "episode": 8.0, "batch_reward": 0.31755070343613623, "critic_loss": 1.551586476624012, "actor_loss": -76.88084002685547, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.732730388641357, "step": 8000}
{"episode_reward": 546.2435702207545, "episode": 9.0, "batch_reward": 0.33801720348000525, "critic_loss": 1.4071173585653305, "actor_loss": -76.88008833312988, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.107073068618774, "step": 9000}
{"episode_reward": 502.5299587934899, "episode": 10.0, "batch_reward": 0.36265572446584704, "critic_loss": 1.6641049236655234, "actor_loss": -76.81689266967773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.531205892562866, "step": 10000}
{"episode_reward": 654.4232868183368, "episode": 11.0, "batch_reward": 0.3829802079498768, "critic_loss": 1.7060878797769548, "actor_loss": -76.33216883850098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.88289141654968, "step": 11000}
{"episode_reward": 427.917178037244, "episode": 12.0, "batch_reward": 0.38924395135045053, "critic_loss": 1.744700453698635, "actor_loss": -76.33407585144043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.852336883544922, "step": 12000}
{"episode_reward": 451.2555258204794, "episode": 13.0, "batch_reward": 0.39618707343935966, "critic_loss": 1.8985534144639968, "actor_loss": -75.28003932189941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.653528690338135, "step": 13000}
{"episode_reward": 631.561544418347, "episode": 14.0, "batch_reward": 0.40368415248394013, "critic_loss": 1.9795452777147293, "actor_loss": -74.66259907531739, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.40317964553833, "step": 14000}
{"episode_reward": 281.98284311156965, "episode": 15.0, "batch_reward": 0.40348958885669706, "critic_loss": 1.9730492593050004, "actor_loss": -72.93841079711915, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.00049328804016, "step": 15000}
{"episode_reward": 684.2403716925938, "episode": 16.0, "batch_reward": 0.43004342848062516, "critic_loss": 2.013537199854851, "actor_loss": -75.46461061096191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.951661586761475, "step": 16000}
{"episode_reward": 892.1588471547306, "episode": 17.0, "batch_reward": 0.455147672444582, "critic_loss": 1.9058130025267601, "actor_loss": -75.64082803344726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.13576030731201, "step": 17000}
{"episode_reward": 841.6015010037288, "episode": 18.0, "batch_reward": 0.47566233628988264, "critic_loss": 1.868804445028305, "actor_loss": -76.07869387817382, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.264845371246338, "step": 18000}
{"episode_reward": 817.7653264320796, "episode": 19.0, "batch_reward": 0.49419352698326113, "critic_loss": 1.896646385550499, "actor_loss": -76.52552308654785, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.845192909240723, "step": 19000}
{"episode_reward": 802.668967626531, "episode": 20.0, "batch_reward": 0.5119334842860699, "critic_loss": 1.7915251610279084, "actor_loss": -76.0599487915039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.583656549453735, "step": 20000}
{"episode_reward": 783.6969037522537, "episode": 21.0, "batch_reward": 0.5226673861443997, "critic_loss": 1.7956509373188019, "actor_loss": -76.77597158050537, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.804378271102905, "step": 21000}
{"episode_reward": 818.5513944595058, "episode": 22.0, "batch_reward": 0.5385924818813801, "critic_loss": 1.7564420914649963, "actor_loss": -76.35241557312011, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.84118413925171, "step": 22000}
{"episode_reward": 843.7711847273804, "episode": 23.0, "batch_reward": 0.5514789161682129, "critic_loss": 1.7069449504613876, "actor_loss": -77.34535305786133, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.983243227005005, "step": 23000}
{"episode_reward": 819.3496842627428, "episode": 24.0, "batch_reward": 0.5616704750657081, "critic_loss": 1.770115383565426, "actor_loss": -77.33304568481445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.6063072681427, "step": 24000}
{"episode_reward": 782.2461420494523, "episode": 25.0, "batch_reward": 0.572179331958294, "critic_loss": 1.8356087688207627, "actor_loss": -77.83679658508301, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.740025997161865, "step": 25000}
{"episode_reward": 763.2049639414543, "episode": 26.0, "batch_reward": 0.58130178591609, "critic_loss": 1.7378567998409271, "actor_loss": -78.5960329284668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.300790071487427, "step": 26000}
{"episode_reward": 872.7446923088489, "episode": 27.0, "batch_reward": 0.5910297711491584, "critic_loss": 1.7318102791905403, "actor_loss": -78.12209371948242, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.396313190460205, "step": 27000}
{"episode_reward": 814.1468715744217, "episode": 28.0, "batch_reward": 0.5984356664419174, "critic_loss": 1.6150446842908859, "actor_loss": -79.33757676696777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.145480632781982, "step": 28000}
{"episode_reward": 865.0465518787294, "episode": 29.0, "batch_reward": 0.6115077873468399, "critic_loss": 1.6111399291157722, "actor_loss": -78.96702655029297, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.244893312454224, "step": 29000}
{"episode_reward": 903.6233298317393, "episode": 30.0, "batch_reward": 0.6190273106098175, "critic_loss": 1.496177914440632, "actor_loss": -79.69423602294921, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.075600624084473, "step": 30000}
{"episode_reward": 870.1557940509729, "episode": 31.0, "batch_reward": 0.6240314958095551, "critic_loss": 1.4717769212126732, "actor_loss": -80.4304580078125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.61565971374512, "step": 31000}
{"episode_reward": 839.1023770002823, "episode": 32.0, "batch_reward": 0.6340275608301162, "critic_loss": 1.412752891421318, "actor_loss": -80.38779425048828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.077113151550293, "step": 32000}
{"episode_reward": 821.3677049526652, "episode": 33.0, "batch_reward": 0.6354294059872627, "critic_loss": 1.4304835567474365, "actor_loss": -79.72236093139648, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.993556261062622, "step": 33000}
{"episode_reward": 689.9943903288461, "episode": 34.0, "batch_reward": 0.6390624178647994, "critic_loss": 1.3476766360998154, "actor_loss": -80.91920471191406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.651345252990723, "step": 34000}
{"episode_reward": 673.6022095110874, "episode": 35.0, "batch_reward": 0.6430294896364213, "critic_loss": 1.3917957826256753, "actor_loss": -81.18685592651367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.05438208580017, "step": 35000}
{"episode_reward": 879.2367541265855, "episode": 36.0, "batch_reward": 0.6490838448405266, "critic_loss": 1.4718180906772613, "actor_loss": -81.38576007080079, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.142168760299683, "step": 36000}
{"episode_reward": 830.2803405779578, "episode": 37.0, "batch_reward": 0.6526400955915451, "critic_loss": 1.5701561718583108, "actor_loss": -81.68906182861328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.062126636505127, "step": 37000}
{"episode_reward": 757.3574053167634, "episode": 38.0, "batch_reward": 0.6560806208848953, "critic_loss": 1.4641164870858192, "actor_loss": -81.1951780090332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.057703495025635, "step": 38000}
{"episode_reward": 886.16043279182, "episode": 39.0, "batch_reward": 0.6640419617295266, "critic_loss": 1.370093035519123, "actor_loss": -81.83172132873536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.08029055595398, "step": 39000}
{"episode_reward": 941.9815792694013, "episode": 40.0, "batch_reward": 0.6675996935367584, "critic_loss": 1.3650905568003655, "actor_loss": -82.32138339233398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.376951217651367, "step": 40000}
{"episode_reward": 893.8845346589309, "episode": 41.0, "batch_reward": 0.6739272421002388, "critic_loss": 1.3004089591503143, "actor_loss": -82.94430348205566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.63148260116577, "step": 41000}
{"episode_reward": 892.4222807709161, "episode": 42.0, "batch_reward": 0.6811478378772735, "critic_loss": 1.2624191995263099, "actor_loss": -82.68525213623047, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.334235191345215, "step": 42000}
{"episode_reward": 930.5019815669153, "episode": 43.0, "batch_reward": 0.6870937735438347, "critic_loss": 1.1916642988324164, "actor_loss": -82.86398025512695, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.627241373062134, "step": 43000}
{"episode_reward": 920.1646924717307, "episode": 44.0, "batch_reward": 0.6930939850211143, "critic_loss": 1.1804105536341667, "actor_loss": -83.00217329406738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.67771339416504, "step": 44000}
{"episode_reward": 914.9078330777672, "episode": 45.0, "batch_reward": 0.6982776682972908, "critic_loss": 1.1627404765486717, "actor_loss": -82.96700691223144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.034427404403687, "step": 45000}
{"episode_reward": 913.0033660967521, "episode": 46.0, "batch_reward": 0.7012895011305809, "critic_loss": 1.1067247051894664, "actor_loss": -83.70088459777833, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.0064058303833, "step": 46000}
{"episode_reward": 887.9946481100668, "episode": 47.0, "batch_reward": 0.7061347447633743, "critic_loss": 1.138420692741871, "actor_loss": -84.54600852966308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.346965074539185, "step": 47000}
{"episode_reward": 904.4478656869045, "episode": 48.0, "batch_reward": 0.7105350862145424, "critic_loss": 1.0933241530060769, "actor_loss": -84.31104655456544, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.793020725250244, "step": 48000}
{"episode_reward": 901.8549078689815, "episode": 49.0, "batch_reward": 0.714252906024456, "critic_loss": 1.0375820286273956, "actor_loss": -84.73304678344726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.07770299911499, "step": 49000}
{"episode_reward": 876.7006307186567, "episode": 50.0, "batch_reward": 0.7174367333054542, "critic_loss": 1.09953909021616, "actor_loss": -85.30015272521973, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.091153383255005, "step": 50000}
{"episode_reward": 807.1917983546809, "episode": 51.0, "batch_reward": 0.7191348577141762, "critic_loss": 1.0854132178425788, "actor_loss": -84.75131758117676, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.96488547325134, "step": 51000}
{"episode_reward": 890.9882754891323, "episode": 52.0, "batch_reward": 0.7225140060186386, "critic_loss": 1.0560401993989945, "actor_loss": -85.92625398254394, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.92171597480774, "step": 52000}
{"episode_reward": 899.0698532514256, "episode": 53.0, "batch_reward": 0.7258887005448341, "critic_loss": 1.023207696378231, "actor_loss": -85.23494831848144, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.58091926574707, "step": 53000}
{"episode_reward": 928.4661656575788, "episode": 54.0, "batch_reward": 0.7295480120182037, "critic_loss": 0.9872549875080585, "actor_loss": -86.23821147155762, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.22360110282898, "step": 54000}
{"episode_reward": 884.3625130415148, "episode": 55.0, "batch_reward": 0.7325908274650573, "critic_loss": 1.0014269632399082, "actor_loss": -86.24085597229003, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.737647533416748, "step": 55000}
{"episode_reward": 894.310770945668, "episode": 56.0, "batch_reward": 0.7355935174226761, "critic_loss": 0.9849733647108078, "actor_loss": -85.96175784301758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.778621435165405, "step": 56000}
{"episode_reward": 956.0455698092672, "episode": 57.0, "batch_reward": 0.7400417023897171, "critic_loss": 1.0315808269679547, "actor_loss": -86.3419698638916, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.576512813568115, "step": 57000}
{"episode_reward": 907.0038915941423, "episode": 58.0, "batch_reward": 0.7416934022903442, "critic_loss": 1.021027943700552, "actor_loss": -86.30937646484375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.872402906417847, "step": 58000}
{"episode_reward": 849.7579481968288, "episode": 59.0, "batch_reward": 0.7451074061989784, "critic_loss": 1.0539807572066784, "actor_loss": -87.03548948669433, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.046767234802246, "step": 59000}
{"episode_reward": 906.2441687306278, "episode": 60.0, "batch_reward": 0.746619612455368, "critic_loss": 0.9930442480444908, "actor_loss": -87.4045107421875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.321889877319336, "step": 60000}
{"episode_reward": 906.3897421065388, "episode": 61.0, "batch_reward": 0.7492598760724067, "critic_loss": 1.0064244152903556, "actor_loss": -87.19864349365234, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 45.31587290763855, "step": 61000}
{"episode_reward": 842.5936364483792, "episode": 62.0, "batch_reward": 0.7482281848788261, "critic_loss": 0.9759464744627476, "actor_loss": -86.82830003356933, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.913981914520264, "step": 62000}
{"episode_reward": 953.2563902762838, "episode": 63.0, "batch_reward": 0.7533317851424217, "critic_loss": 0.9861937123239041, "actor_loss": -87.01033651733398, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.622579097747803, "step": 63000}
{"episode_reward": 943.2695123639684, "episode": 64.0, "batch_reward": 0.7557310670018196, "critic_loss": 0.9874553591609001, "actor_loss": -87.59709001159668, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.180094718933105, "step": 64000}
{"episode_reward": 815.0778104278872, "episode": 65.0, "batch_reward": 0.7574343311190606, "critic_loss": 1.0389801554083824, "actor_loss": -87.68345343017577, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.531311511993408, "step": 65000}
{"episode_reward": 879.373617704726, "episode": 66.0, "batch_reward": 0.7593388395905495, "critic_loss": 1.0393872851133346, "actor_loss": -87.61705151367188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.77562975883484, "step": 66000}
{"episode_reward": 922.8174838676113, "episode": 67.0, "batch_reward": 0.7627808226346969, "critic_loss": 0.9990452319681644, "actor_loss": -87.97331323242187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.591742515563965, "step": 67000}
{"episode_reward": 891.2030517912898, "episode": 68.0, "batch_reward": 0.764726091504097, "critic_loss": 0.9881437439322471, "actor_loss": -88.34631379699707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.43613290786743, "step": 68000}
{"episode_reward": 913.0548084930948, "episode": 69.0, "batch_reward": 0.7667152055501938, "critic_loss": 0.9549368221759796, "actor_loss": -88.27284106445312, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.18269395828247, "step": 69000}
{"episode_reward": 893.4736922067877, "episode": 70.0, "batch_reward": 0.7682285581231117, "critic_loss": 0.9943336926400661, "actor_loss": -88.74017668151855, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.061989545822144, "step": 70000}
{"episode_reward": 912.4057296477735, "episode": 71.0, "batch_reward": 0.7697344483137131, "critic_loss": 0.9952846924662591, "actor_loss": -88.75262181091308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.64790654182434, "step": 71000}
{"episode_reward": 937.4194703032614, "episode": 72.0, "batch_reward": 0.7728123126626014, "critic_loss": 1.012725850492716, "actor_loss": -88.79133154296875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.269547700881958, "step": 72000}
{"episode_reward": 867.5962051390521, "episode": 73.0, "batch_reward": 0.7735546200275422, "critic_loss": 1.0131524819731712, "actor_loss": -88.82397370910644, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.360203504562378, "step": 73000}
{"episode_reward": 905.336466197684, "episode": 74.0, "batch_reward": 0.7764879276156426, "critic_loss": 0.9849849577546119, "actor_loss": -89.2040537109375, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.090219736099243, "step": 74000}
{"episode_reward": 909.9292020411168, "episode": 75.0, "batch_reward": 0.7786547517180443, "critic_loss": 0.9413154531121254, "actor_loss": -89.23463923645019, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.97462272644043, "step": 75000}
{"episode_reward": 921.4625622720752, "episode": 76.0, "batch_reward": 0.7803251752853394, "critic_loss": 0.8992912527024746, "actor_loss": -89.51925634765625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.266119718551636, "step": 76000}
{"episode_reward": 924.2973921020124, "episode": 77.0, "batch_reward": 0.7828085129261017, "critic_loss": 0.8751890115737915, "actor_loss": -89.32866551208497, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.314889192581177, "step": 77000}
{"episode_reward": 954.171910521184, "episode": 78.0, "batch_reward": 0.7837610857486725, "critic_loss": 0.8515882021784782, "actor_loss": -89.44636473083496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.644355297088623, "step": 78000}
{"episode_reward": 913.1768246247391, "episode": 79.0, "batch_reward": 0.785283652305603, "critic_loss": 0.8883510052561759, "actor_loss": -89.44988209533692, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.384684562683105, "step": 79000}
{"episode_reward": 904.0766226993726, "episode": 80.0, "batch_reward": 0.7875199601650238, "critic_loss": 0.8335319894254207, "actor_loss": -89.72805554199219, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.31864833831787, "step": 80000}
{"episode_reward": 910.3211836753476, "episode": 81.0, "batch_reward": 0.7885449645519257, "critic_loss": 0.8419723961949348, "actor_loss": -89.63140930175781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 45.13125443458557, "step": 81000}
{"episode_reward": 892.1371778404432, "episode": 82.0, "batch_reward": 0.7821401730179787, "critic_loss": 0.8643800659179688, "actor_loss": -89.43419772338868, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.822272062301636, "step": 82000}
{"episode_reward": 67.78399364947222, "episode": 83.0, "batch_reward": 0.7799579872488975, "critic_loss": 0.8676895479857921, "actor_loss": -89.48945126342774, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.721348762512207, "step": 83000}
{"episode_reward": 934.1875434154917, "episode": 84.0, "batch_reward": 0.7819458231925964, "critic_loss": 0.8692685080468655, "actor_loss": -89.6300256652832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.05572533607483, "step": 84000}
{"episode_reward": 914.783900456285, "episode": 85.0, "batch_reward": 0.7825079062581062, "critic_loss": 0.913980904340744, "actor_loss": -89.26757063293456, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.37714457511902, "step": 85000}
{"episode_reward": 885.104102620801, "episode": 86.0, "batch_reward": 0.7850367345809937, "critic_loss": 0.9200334902405739, "actor_loss": -89.53348463439941, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.529940605163574, "step": 86000}
{"episode_reward": 940.1546536364426, "episode": 87.0, "batch_reward": 0.7872943531274795, "critic_loss": 0.9130700109899044, "actor_loss": -89.69813328552246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.774290084838867, "step": 87000}
{"episode_reward": 903.1401933311394, "episode": 88.0, "batch_reward": 0.7883462077379226, "critic_loss": 0.9164891583621502, "actor_loss": -89.74504940795899, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.531318187713623, "step": 88000}
{"episode_reward": 954.0776194810895, "episode": 89.0, "batch_reward": 0.7854837059974671, "critic_loss": 0.965069742411375, "actor_loss": -89.61826348876953, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.525145053863525, "step": 89000}
{"episode_reward": 41.614227070197025, "episode": 90.0, "batch_reward": 0.7815803886651993, "critic_loss": 0.8999825156629085, "actor_loss": -89.76922727966308, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.304134607315063, "step": 90000}
{"episode_reward": 967.958722197439, "episode": 91.0, "batch_reward": 0.7840645315051079, "critic_loss": 0.848896093249321, "actor_loss": -89.90725448608399, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 45.01143503189087, "step": 91000}
{"episode_reward": 900.5616861953588, "episode": 92.0, "batch_reward": 0.7859696605205536, "critic_loss": 0.7815962477624416, "actor_loss": -90.06883406066895, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.421010732650757, "step": 92000}
{"episode_reward": 949.9917685174113, "episode": 93.0, "batch_reward": 0.7871333847641945, "critic_loss": 0.7979291858077049, "actor_loss": -90.08421376037597, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.573060035705566, "step": 93000}
{"episode_reward": 953.1608798655077, "episode": 94.0, "batch_reward": 0.7907167019844055, "critic_loss": 0.7996128881275654, "actor_loss": -90.28381993103028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.47456693649292, "step": 94000}
{"episode_reward": 921.9145211251662, "episode": 95.0, "batch_reward": 0.7899549028277397, "critic_loss": 0.7939068661630153, "actor_loss": -90.16127784729004, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.900546073913574, "step": 95000}
{"episode_reward": 860.1708833888682, "episode": 96.0, "batch_reward": 0.7910125934481621, "critic_loss": 0.8101437415182591, "actor_loss": -90.42954319763183, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.448312997817993, "step": 96000}
{"episode_reward": 924.5628326042969, "episode": 97.0, "batch_reward": 0.7915558658838272, "critic_loss": 0.8060256273448467, "actor_loss": -90.25390408325195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.622552156448364, "step": 97000}
{"episode_reward": 935.6653221111084, "episode": 98.0, "batch_reward": 0.7937233613729477, "critic_loss": 0.8341935741007328, "actor_loss": -90.2067145690918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.73289203643799, "step": 98000}
{"episode_reward": 898.6750092460007, "episode": 99.0, "batch_reward": 0.7949471681118011, "critic_loss": 0.8298021698892116, "actor_loss": -90.64182302856446, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.110174655914307, "step": 99000}
{"episode_reward": 915.9449477221644, "episode": 100.0, "batch_reward": 0.7940682602524758, "critic_loss": 0.8910210373401641, "actor_loss": -90.37065808105469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.714452743530273, "step": 100000}
{"episode_reward": 907.0441009580877, "episode": 101.0, "batch_reward": 0.797731734931469, "critic_loss": 0.8450900391042232, "actor_loss": -90.55736972045898, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.42015528678894, "step": 101000}
{"episode_reward": 953.1302254950065, "episode": 102.0, "batch_reward": 0.7998544996380806, "critic_loss": 0.8376820597052574, "actor_loss": -90.60963597106934, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.003172636032104, "step": 102000}
{"episode_reward": 966.1905050453627, "episode": 103.0, "batch_reward": 0.8008566784858704, "critic_loss": 0.8420603081285953, "actor_loss": -90.57518650817872, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.948971271514893, "step": 103000}
{"episode_reward": 936.1049134079533, "episode": 104.0, "batch_reward": 0.8012235894203186, "critic_loss": 0.817351679712534, "actor_loss": -90.84923713684083, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.15074372291565, "step": 104000}
{"episode_reward": 888.6413238482472, "episode": 105.0, "batch_reward": 0.8021497789025307, "critic_loss": 0.8160186601281166, "actor_loss": -90.90370114135742, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.29946231842041, "step": 105000}
{"episode_reward": 947.1278936070646, "episode": 106.0, "batch_reward": 0.8040743125081062, "critic_loss": 0.8355850301384926, "actor_loss": -91.02363395690918, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 24.08330225944519, "step": 106000}
{"episode_reward": 884.4637987748191, "episode": 107.0, "batch_reward": 0.8048187075257301, "critic_loss": 0.8117651502490044, "actor_loss": -91.05358738708496, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.357923984527588, "step": 107000}
{"episode_reward": 881.0717156608195, "episode": 108.0, "batch_reward": 0.8045332685709, "critic_loss": 0.84659138032794, "actor_loss": -90.76521955871581, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.38099503517151, "step": 108000}
{"episode_reward": 899.2890679998828, "episode": 109.0, "batch_reward": 0.8043635668158531, "critic_loss": 0.8303793553411961, "actor_loss": -91.08032336425781, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.46105933189392, "step": 109000}
{"episode_reward": 888.6169219013857, "episode": 110.0, "batch_reward": 0.8062464473247528, "critic_loss": 0.7732675134837628, "actor_loss": -91.18641777038575, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.82113552093506, "step": 110000}
{"episode_reward": 910.2236078336642, "episode": 111.0, "batch_reward": 0.8084519709944725, "critic_loss": 0.8082220294475555, "actor_loss": -90.91870555114745, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.38998627662659, "step": 111000}
{"episode_reward": 920.2873093032847, "episode": 112.0, "batch_reward": 0.8100689508318901, "critic_loss": 0.7989684999287129, "actor_loss": -91.45059216308594, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.713788986206055, "step": 112000}
{"episode_reward": 925.2788069063907, "episode": 113.0, "batch_reward": 0.8104464433193207, "critic_loss": 0.8027289826273918, "actor_loss": -91.31917044067383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.99765396118164, "step": 113000}
{"episode_reward": 941.6395857664228, "episode": 114.0, "batch_reward": 0.810174558877945, "critic_loss": 0.8333665415942669, "actor_loss": -91.3649853515625, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.730937004089355, "step": 114000}
{"episode_reward": 964.6432228480842, "episode": 115.0, "batch_reward": 0.8111677623391151, "critic_loss": 0.7992421740293503, "actor_loss": -91.37960389709473, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.993263244628906, "step": 115000}
{"episode_reward": 923.467465762897, "episode": 116.0, "batch_reward": 0.8139050619006157, "critic_loss": 0.7752174093425274, "actor_loss": -91.40258549499512, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.576330423355103, "step": 116000}
{"episode_reward": 884.9564341674645, "episode": 117.0, "batch_reward": 0.813383955359459, "critic_loss": 0.8082467913925647, "actor_loss": -91.22131369018555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.339178800582886, "step": 117000}
{"episode_reward": 921.9219406014587, "episode": 118.0, "batch_reward": 0.8144359558224677, "critic_loss": 0.7876514331102371, "actor_loss": -91.41370274353028, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.037517786026, "step": 118000}
{"episode_reward": 905.237785096647, "episode": 119.0, "batch_reward": 0.8160651171803475, "critic_loss": 0.8009233213067055, "actor_loss": -91.46277796936035, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.464455366134644, "step": 119000}
{"episode_reward": 908.0647806456027, "episode": 120.0, "batch_reward": 0.8170201482772828, "critic_loss": 0.8029139360487461, "actor_loss": -91.41988665771484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.663163900375366, "step": 120000}
{"episode_reward": 914.8962326540577, "episode": 121.0, "batch_reward": 0.8176139976978302, "critic_loss": 0.7862462960779667, "actor_loss": -91.62820094299316, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.42271566390991, "step": 121000}
{"episode_reward": 949.0610092616221, "episode": 122.0, "batch_reward": 0.819442151427269, "critic_loss": 0.7732841952741146, "actor_loss": -91.71102061462402, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.587565898895264, "step": 122000}
{"episode_reward": 920.0670523649216, "episode": 123.0, "batch_reward": 0.8195387189388275, "critic_loss": 0.7569732907414436, "actor_loss": -91.90031127929687, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.945298671722412, "step": 123000}
{"episode_reward": 928.2785452733758, "episode": 124.0, "batch_reward": 0.8200484301447868, "critic_loss": 0.7757685892581939, "actor_loss": -91.89154432678222, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.424790382385254, "step": 124000}
{"episode_reward": 832.702707484388, "episode": 125.0, "batch_reward": 0.8198764081597328, "critic_loss": 0.7702640997469425, "actor_loss": -91.91438227844239, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.167386293411255, "step": 125000}
{"episode_reward": 923.2682704328427, "episode": 126.0, "batch_reward": 0.821153971850872, "critic_loss": 0.7378823185563087, "actor_loss": -91.71244165039063, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.2322096824646, "step": 126000}
{"episode_reward": 894.3598607365824, "episode": 127.0, "batch_reward": 0.8208433698415756, "critic_loss": 0.7605742791295051, "actor_loss": -92.01416975402832, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.30271077156067, "step": 127000}
{"episode_reward": 920.1209730008064, "episode": 128.0, "batch_reward": 0.821840050816536, "critic_loss": 0.7785776671469211, "actor_loss": -91.89917886352539, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.990230083465576, "step": 128000}
{"episode_reward": 936.6881272801539, "episode": 129.0, "batch_reward": 0.8222286014556884, "critic_loss": 0.7684387816786766, "actor_loss": -91.81079077148438, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.88209056854248, "step": 129000}
{"episode_reward": 945.3043924729961, "episode": 130.0, "batch_reward": 0.8261692756414414, "critic_loss": 0.7551015738248825, "actor_loss": -92.00468826293945, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.36486577987671, "step": 130000}
{"episode_reward": 927.8696729121084, "episode": 131.0, "batch_reward": 0.8247603495717049, "critic_loss": 0.7988376762866974, "actor_loss": -92.06097454833984, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.82723951339722, "step": 131000}
{"episode_reward": 917.6144785936419, "episode": 132.0, "batch_reward": 0.825972994685173, "critic_loss": 0.8435882545113563, "actor_loss": -92.15498014831543, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.604920387268066, "step": 132000}
{"episode_reward": 945.7440770394321, "episode": 133.0, "batch_reward": 0.8270826536417007, "critic_loss": 0.7781393302679062, "actor_loss": -91.92602346801758, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.91555953025818, "step": 133000}
{"episode_reward": 969.833030512921, "episode": 134.0, "batch_reward": 0.8280734914541245, "critic_loss": 0.7637851131260395, "actor_loss": -91.87523847961425, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.844999313354492, "step": 134000}
{"episode_reward": 950.9876516707366, "episode": 135.0, "batch_reward": 0.8286145941615105, "critic_loss": 0.7772434412539005, "actor_loss": -92.15305419921874, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.459802865982056, "step": 135000}
{"episode_reward": 936.3734056025114, "episode": 136.0, "batch_reward": 0.8312752963900566, "critic_loss": 0.7483398655354977, "actor_loss": -91.83874682617187, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.75717806816101, "step": 136000}
{"episode_reward": 919.7792564752564, "episode": 137.0, "batch_reward": 0.8295241049528121, "critic_loss": 0.7602071455419064, "actor_loss": -92.1685544128418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.71995711326599, "step": 137000}
{"episode_reward": 963.0972962875326, "episode": 138.0, "batch_reward": 0.8323369862437249, "critic_loss": 0.7387839577496051, "actor_loss": -92.25708515930175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.724323511123657, "step": 138000}
{"episode_reward": 951.7346019210739, "episode": 139.0, "batch_reward": 0.832012171626091, "critic_loss": 0.7584017499983311, "actor_loss": -92.15529136657715, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 21.811663389205933, "step": 139000}
{"episode_reward": 937.1803659726426, "episode": 140.0, "batch_reward": 0.8341371503472328, "critic_loss": 0.752881067186594, "actor_loss": -92.4457010345459, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.940119743347168, "step": 140000}
{"episode_reward": 918.1670434230344, "episode": 141.0, "batch_reward": 0.8321150243282318, "critic_loss": 0.7286075245440006, "actor_loss": -92.34712663269043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 44.723570346832275, "step": 141000}
{"episode_reward": 914.9197919575955, "episode": 142.0, "batch_reward": 0.8332872192859649, "critic_loss": 0.7274524809867143, "actor_loss": -92.25166357421875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.91171669960022, "step": 142000}
{"episode_reward": 874.7575592830324, "episode": 143.0, "batch_reward": 0.833415954053402, "critic_loss": 0.7296769582629203, "actor_loss": -92.24505914306641, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.940677642822266, "step": 143000}
{"episode_reward": 932.345337114477, "episode": 144.0, "batch_reward": 0.8345372830033302, "critic_loss": 0.759428615629673, "actor_loss": -92.42722439575195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.722959756851196, "step": 144000}
{"episode_reward": 898.180658960375, "episode": 145.0, "batch_reward": 0.8368433419466018, "critic_loss": 0.7442714501917362, "actor_loss": -92.52243522644044, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.307463884353638, "step": 145000}
{"episode_reward": 889.9148042417419, "episode": 146.0, "batch_reward": 0.8350296635627746, "critic_loss": 0.7454037357717752, "actor_loss": -92.50520494079589, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.292189598083496, "step": 146000}
{"episode_reward": 871.0721985422578, "episode": 147.0, "batch_reward": 0.835004520714283, "critic_loss": 0.7267774197608232, "actor_loss": -92.44370983886719, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.40738534927368, "step": 147000}
{"episode_reward": 898.9698786141952, "episode": 148.0, "batch_reward": 0.8350416327118874, "critic_loss": 0.7366011034846306, "actor_loss": -92.49313101196289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 22.212690114974976, "step": 148000}
{"episode_reward": 909.5758262489474, "episode": 149.0, "batch_reward": 0.8365500251054764, "critic_loss": 0.7057511224150658, "actor_loss": -92.59524855041504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 23.319406270980835, "step": 149000}
{"episode_reward": 935.5526161542222, "episode": 150.0, "batch_reward": 0.8363234210014343, "critic_loss": 0.7128594173192978, "actor_loss": -92.68096418762207, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
