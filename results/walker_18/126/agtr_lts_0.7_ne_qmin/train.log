{"episode_reward": 0.0, "episode": 1.0, "duration": 20.98354983329773, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.8252537250518799, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.46604369126108736, "critic_loss": 0.193594214024793, "actor_loss": -83.91550034625666, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 60.816784381866455, "step": 3000}
{"episode_reward": 572.762132611977, "episode": 4.0, "batch_reward": 0.5268458933234215, "critic_loss": 0.44733723014593124, "actor_loss": -86.40786532592773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.357091426849365, "step": 4000}
{"episode_reward": 764.6889715339247, "episode": 5.0, "batch_reward": 0.5805202547609806, "critic_loss": 0.4906536657214165, "actor_loss": -88.19444998168946, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.376616954803467, "step": 5000}
{"episode_reward": 707.8701100685109, "episode": 6.0, "batch_reward": 0.6028093088269234, "critic_loss": 0.6509199749529362, "actor_loss": -88.62759086608887, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.367536544799805, "step": 6000}
{"episode_reward": 732.1071606935144, "episode": 7.0, "batch_reward": 0.6103465317487716, "critic_loss": 0.8078274551331996, "actor_loss": -88.47267742919922, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.369817972183228, "step": 7000}
{"episode_reward": 629.0439654892072, "episode": 8.0, "batch_reward": 0.6290516701340675, "critic_loss": 0.8353240622282028, "actor_loss": -88.94470851135254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.371551990509033, "step": 8000}
{"episode_reward": 805.639352865009, "episode": 9.0, "batch_reward": 0.649407004058361, "critic_loss": 0.9735604941248893, "actor_loss": -89.07020062255859, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.353617191314697, "step": 9000}
{"episode_reward": 813.6434416532472, "episode": 10.0, "batch_reward": 0.6700464049577713, "critic_loss": 0.9330077517032623, "actor_loss": -89.37655587768555, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.34973645210266, "step": 10000}
{"episode_reward": 866.6360142364422, "episode": 11.0, "batch_reward": 0.6899739378094674, "critic_loss": 0.9165122561454773, "actor_loss": -89.81393630981445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.007956981658936, "step": 11000}
{"episode_reward": 872.4330941898457, "episode": 12.0, "batch_reward": 0.694176985502243, "critic_loss": 1.0123101913928985, "actor_loss": -89.78490193176269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.354674577713013, "step": 12000}
{"episode_reward": 679.4726347781536, "episode": 13.0, "batch_reward": 0.7050480567216874, "critic_loss": 0.9038676544725895, "actor_loss": -89.99447346496582, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.316386699676514, "step": 13000}
{"episode_reward": 896.2955693213867, "episode": 14.0, "batch_reward": 0.7174965096712113, "critic_loss": 0.8773711216449738, "actor_loss": -90.27360998535156, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33995246887207, "step": 14000}
{"episode_reward": 839.3631182899524, "episode": 15.0, "batch_reward": 0.7121905986666679, "critic_loss": 0.9366867448985576, "actor_loss": -89.66684713745117, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.376307249069214, "step": 15000}
{"episode_reward": 652.9696983062099, "episode": 16.0, "batch_reward": 0.7237810586094856, "critic_loss": 0.8730385351777077, "actor_loss": -90.57165214538574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37433695793152, "step": 16000}
{"episode_reward": 942.1202653285483, "episode": 17.0, "batch_reward": 0.7342893592119217, "critic_loss": 0.838184813708067, "actor_loss": -90.6375193786621, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.372878551483154, "step": 17000}
{"episode_reward": 865.1915529808638, "episode": 18.0, "batch_reward": 0.7424253099560738, "critic_loss": 0.8814512725770474, "actor_loss": -90.893509475708, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37806749343872, "step": 18000}
{"episode_reward": 895.0468263949772, "episode": 19.0, "batch_reward": 0.7501106590032578, "critic_loss": 0.8537754889428616, "actor_loss": -91.15443827819824, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.387423515319824, "step": 19000}
{"episode_reward": 879.55070157044, "episode": 20.0, "batch_reward": 0.7532569385766983, "critic_loss": 0.931097991168499, "actor_loss": -90.88398092651367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.382108211517334, "step": 20000}
{"episode_reward": 808.3028245862535, "episode": 21.0, "batch_reward": 0.7577655831575394, "critic_loss": 0.9077804427146912, "actor_loss": -91.11188626098632, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.058109760284424, "step": 21000}
{"episode_reward": 855.8350883824478, "episode": 22.0, "batch_reward": 0.761029614329338, "critic_loss": 0.9873917709887028, "actor_loss": -91.1761050415039, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37815809249878, "step": 22000}
{"episode_reward": 790.2553577930802, "episode": 23.0, "batch_reward": 0.7625182188749313, "critic_loss": 0.9717929790616036, "actor_loss": -91.28354933166504, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.369189023971558, "step": 23000}
{"episode_reward": 809.7235226062312, "episode": 24.0, "batch_reward": 0.768075906932354, "critic_loss": 0.997066110253334, "actor_loss": -91.43811827087403, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35212016105652, "step": 24000}
{"episode_reward": 935.3942763797373, "episode": 25.0, "batch_reward": 0.772542735338211, "critic_loss": 0.9646608336567879, "actor_loss": -91.36188706970215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.353986740112305, "step": 25000}
{"episode_reward": 844.987250023413, "episode": 26.0, "batch_reward": 0.7753712681531906, "critic_loss": 0.8969802032411098, "actor_loss": -91.43552615356445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36627984046936, "step": 26000}
{"episode_reward": 849.4904230374095, "episode": 27.0, "batch_reward": 0.7803248946666718, "critic_loss": 0.9117816776037216, "actor_loss": -91.41476356506348, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36124014854431, "step": 27000}
{"episode_reward": 853.933970752476, "episode": 28.0, "batch_reward": 0.7819312749505043, "critic_loss": 0.9271988918781281, "actor_loss": -91.64768270874023, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.359505653381348, "step": 28000}
{"episode_reward": 876.6973601655848, "episode": 29.0, "batch_reward": 0.7871795704364777, "critic_loss": 0.9105713475346565, "actor_loss": -91.5300163269043, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.380691051483154, "step": 29000}
{"episode_reward": 947.1716080837492, "episode": 30.0, "batch_reward": 0.7889153255224228, "critic_loss": 0.8850252013206482, "actor_loss": -91.61955256652833, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.378662824630737, "step": 30000}
{"episode_reward": 851.1324092795854, "episode": 31.0, "batch_reward": 0.7901829082965851, "critic_loss": 0.8837501798272133, "actor_loss": -91.77436296081542, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.93385052680969, "step": 31000}
{"episode_reward": 804.6027806484684, "episode": 32.0, "batch_reward": 0.7944593633413315, "critic_loss": 0.8526849864423275, "actor_loss": -91.82757792663574, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.39283537864685, "step": 32000}
{"episode_reward": 909.5206730313126, "episode": 33.0, "batch_reward": 0.7975191633701324, "critic_loss": 0.8056318513453007, "actor_loss": -91.7596298828125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37647533416748, "step": 33000}
{"episode_reward": 930.2005603972838, "episode": 34.0, "batch_reward": 0.8018396206498146, "critic_loss": 0.7690068738162518, "actor_loss": -92.14232258605956, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.401580333709717, "step": 34000}
{"episode_reward": 918.3454052517585, "episode": 35.0, "batch_reward": 0.804737807393074, "critic_loss": 0.7672853270471096, "actor_loss": -91.98103840637206, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.367798328399658, "step": 35000}
{"episode_reward": 926.3065072661875, "episode": 36.0, "batch_reward": 0.8071397502422333, "critic_loss": 0.7768541196584702, "actor_loss": -92.42071961975098, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.369729042053223, "step": 36000}
{"episode_reward": 798.3131313919548, "episode": 37.0, "batch_reward": 0.8084347475171089, "critic_loss": 0.787230840653181, "actor_loss": -92.29422953796387, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.398505449295044, "step": 37000}
{"episode_reward": 914.1528986651456, "episode": 38.0, "batch_reward": 0.8104072412252427, "critic_loss": 0.7796242316067219, "actor_loss": -92.09976904296875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.363630056381226, "step": 38000}
{"episode_reward": 854.1457003540233, "episode": 39.0, "batch_reward": 0.8121479999423027, "critic_loss": 0.7413079759776592, "actor_loss": -92.34616394042969, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.365468978881836, "step": 39000}
{"episode_reward": 926.1103015474106, "episode": 40.0, "batch_reward": 0.8137345449924469, "critic_loss": 0.712222748696804, "actor_loss": -92.42895826721191, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.375406503677368, "step": 40000}
{"episode_reward": 907.5073230043955, "episode": 41.0, "batch_reward": 0.816725789308548, "critic_loss": 0.6986610171794891, "actor_loss": -92.66130421447754, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.995325565338135, "step": 41000}
{"episode_reward": 922.3460641878467, "episode": 42.0, "batch_reward": 0.8173400699496269, "critic_loss": 0.6721059376001358, "actor_loss": -92.43764889526368, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38416337966919, "step": 42000}
{"episode_reward": 872.448538793857, "episode": 43.0, "batch_reward": 0.8215844317674637, "critic_loss": 0.6627506091743708, "actor_loss": -92.67016485595703, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.334242582321167, "step": 43000}
{"episode_reward": 905.7426116699066, "episode": 44.0, "batch_reward": 0.8213402368426322, "critic_loss": 0.6622956947684288, "actor_loss": -92.50958840942383, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35283899307251, "step": 44000}
{"episode_reward": 834.1001828028225, "episode": 45.0, "batch_reward": 0.8212583947181702, "critic_loss": 0.6735185827612877, "actor_loss": -92.43103717041015, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.39672303199768, "step": 45000}
{"episode_reward": 791.0642820416703, "episode": 46.0, "batch_reward": 0.82331919246912, "critic_loss": 0.6686226886808873, "actor_loss": -92.66748693847656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36384129524231, "step": 46000}
{"episode_reward": 893.7574697486006, "episode": 47.0, "batch_reward": 0.8246750689744949, "critic_loss": 0.6956167098283768, "actor_loss": -92.76506188964844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.349081993103027, "step": 47000}
{"episode_reward": 943.2500590298672, "episode": 48.0, "batch_reward": 0.8271651352643967, "critic_loss": 0.699428485929966, "actor_loss": -92.77709907531738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.384397268295288, "step": 48000}
{"episode_reward": 908.0770369225578, "episode": 49.0, "batch_reward": 0.827851690530777, "critic_loss": 0.7256372611522675, "actor_loss": -92.86872575378418, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.381477117538452, "step": 49000}
{"episode_reward": 868.576737540345, "episode": 50.0, "batch_reward": 0.8291106696128845, "critic_loss": 0.725116164714098, "actor_loss": -92.71435111999511, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.348140001296997, "step": 50000}
{"episode_reward": 887.1894730107911, "episode": 51.0, "batch_reward": 0.83134427434206, "critic_loss": 0.7048355389237404, "actor_loss": -92.9758203125, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.93093204498291, "step": 51000}
{"episode_reward": 933.5942879498539, "episode": 52.0, "batch_reward": 0.8315668511986732, "critic_loss": 0.7679887800514698, "actor_loss": -93.04977725219726, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38876724243164, "step": 52000}
{"episode_reward": 858.1191739580131, "episode": 53.0, "batch_reward": 0.8317972833514213, "critic_loss": 0.7193615547418595, "actor_loss": -92.76855783081055, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.39672827720642, "step": 53000}
{"episode_reward": 887.359320132382, "episode": 54.0, "batch_reward": 0.8355709071159363, "critic_loss": 0.7029952639639377, "actor_loss": -93.42753753662109, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.347870111465454, "step": 54000}
{"episode_reward": 914.7738217167903, "episode": 55.0, "batch_reward": 0.834556020796299, "critic_loss": 0.6743950327038765, "actor_loss": -93.25900236511231, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.370254278182983, "step": 55000}
{"episode_reward": 918.3869423890359, "episode": 56.0, "batch_reward": 0.8381116541028023, "critic_loss": 0.6438144018054008, "actor_loss": -93.03909255981445, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.370922088623047, "step": 56000}
{"episode_reward": 969.1516462885451, "episode": 57.0, "batch_reward": 0.8382321415543557, "critic_loss": 0.6691209636330605, "actor_loss": -93.3099949798584, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.350717544555664, "step": 57000}
{"episode_reward": 883.804118416998, "episode": 58.0, "batch_reward": 0.8398793857097626, "critic_loss": 0.6367700502276421, "actor_loss": -93.34823034667968, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36265540122986, "step": 58000}
{"episode_reward": 889.1757184678133, "episode": 59.0, "batch_reward": 0.8401511318683624, "critic_loss": 0.6681302588284016, "actor_loss": -93.42919020080566, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.2984778881073, "step": 59000}
{"episode_reward": 857.973781678244, "episode": 60.0, "batch_reward": 0.8412471169233322, "critic_loss": 0.681080849558115, "actor_loss": -93.2412315826416, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32824730873108, "step": 60000}
{"episode_reward": 885.6696294970158, "episode": 61.0, "batch_reward": 0.8417163637280464, "critic_loss": 0.6900642902553081, "actor_loss": -93.40326545715332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.911922216415405, "step": 61000}
{"episode_reward": 887.735906011139, "episode": 62.0, "batch_reward": 0.8414477842450142, "critic_loss": 0.6748197909593582, "actor_loss": -93.15283526611329, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.383389949798584, "step": 62000}
{"episode_reward": 969.4936847051594, "episode": 63.0, "batch_reward": 0.8421406800150871, "critic_loss": 0.6740483087301254, "actor_loss": -93.27734550476075, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.359778881072998, "step": 63000}
{"episode_reward": 877.8687996596129, "episode": 64.0, "batch_reward": 0.8448395986557007, "critic_loss": 0.6843663633465767, "actor_loss": -93.4667529296875, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37588620185852, "step": 64000}
{"episode_reward": 878.8614144790157, "episode": 65.0, "batch_reward": 0.8447028918266296, "critic_loss": 0.7025670849680901, "actor_loss": -93.18926501464844, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.380290031433105, "step": 65000}
{"episode_reward": 869.1238355254741, "episode": 66.0, "batch_reward": 0.845284870147705, "critic_loss": 0.6595684710443019, "actor_loss": -93.28803273010254, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.348719358444214, "step": 66000}
{"episode_reward": 939.0905821819254, "episode": 67.0, "batch_reward": 0.8477861792445183, "critic_loss": 0.64947602891922, "actor_loss": -93.29908531188966, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35971188545227, "step": 67000}
{"episode_reward": 933.8930617411363, "episode": 68.0, "batch_reward": 0.8472866284251213, "critic_loss": 0.6799880625605583, "actor_loss": -93.58105493164062, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.364773750305176, "step": 68000}
{"episode_reward": 931.8014478603775, "episode": 69.0, "batch_reward": 0.8507913278341294, "critic_loss": 0.647278663367033, "actor_loss": -93.62371395874024, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.365007877349854, "step": 69000}
{"episode_reward": 948.0660570649079, "episode": 70.0, "batch_reward": 0.850438497543335, "critic_loss": 0.6710771323442459, "actor_loss": -93.72989288330078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.320573568344116, "step": 70000}
{"episode_reward": 857.9881315816833, "episode": 71.0, "batch_reward": 0.8506328094601631, "critic_loss": 0.6623440652787685, "actor_loss": -93.37544427490235, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.00569438934326, "step": 71000}
{"episode_reward": 914.0332662303418, "episode": 72.0, "batch_reward": 0.8529318033456802, "critic_loss": 0.6643801289498806, "actor_loss": -93.70628257751464, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.375638008117676, "step": 72000}
{"episode_reward": 898.3343248961928, "episode": 73.0, "batch_reward": 0.8521155628561974, "critic_loss": 0.6674849813580513, "actor_loss": -93.70588145446777, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37661361694336, "step": 73000}
{"episode_reward": 905.7182224737082, "episode": 74.0, "batch_reward": 0.8539429681301117, "critic_loss": 0.6688294503390789, "actor_loss": -93.72126466369629, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37943148612976, "step": 74000}
{"episode_reward": 925.2270893652822, "episode": 75.0, "batch_reward": 0.8557013816833496, "critic_loss": 0.6738211915194988, "actor_loss": -93.82680294799805, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.375007390975952, "step": 75000}
{"episode_reward": 928.7270736562134, "episode": 76.0, "batch_reward": 0.8559720244407654, "critic_loss": 0.6743675371557474, "actor_loss": -93.80633515930175, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.39633846282959, "step": 76000}
{"episode_reward": 925.8635553811765, "episode": 77.0, "batch_reward": 0.8567078688144684, "critic_loss": 0.6655438531339168, "actor_loss": -93.77646913146972, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.337340593338013, "step": 77000}
{"episode_reward": 943.9882093375231, "episode": 78.0, "batch_reward": 0.8571808080673218, "critic_loss": 0.6567340475767851, "actor_loss": -93.78470776367188, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.362424612045288, "step": 78000}
{"episode_reward": 929.4351562579814, "episode": 79.0, "batch_reward": 0.857280788242817, "critic_loss": 0.6815381571352482, "actor_loss": -93.81550379943847, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.34215998649597, "step": 79000}
{"episode_reward": 924.4385673341002, "episode": 80.0, "batch_reward": 0.8595997005105018, "critic_loss": 0.6864993160665035, "actor_loss": -93.91755601501465, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.397719144821167, "step": 80000}
{"episode_reward": 911.2134869807023, "episode": 81.0, "batch_reward": 0.8595781923532486, "critic_loss": 0.6552155079394579, "actor_loss": -93.74486524963379, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.93830943107605, "step": 81000}
{"episode_reward": 922.1675433763784, "episode": 82.0, "batch_reward": 0.859813383102417, "critic_loss": 0.6895181371569633, "actor_loss": -93.80656675720215, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.378382682800293, "step": 82000}
{"episode_reward": 876.7319749244868, "episode": 83.0, "batch_reward": 0.8606990699768067, "critic_loss": 0.6877411096990108, "actor_loss": -94.07030027770996, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.338301181793213, "step": 83000}
{"episode_reward": 939.3334765891572, "episode": 84.0, "batch_reward": 0.8615303587317467, "critic_loss": 0.685811138421297, "actor_loss": -94.10824119567872, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.362306356430054, "step": 84000}
{"episode_reward": 908.7537585726404, "episode": 85.0, "batch_reward": 0.8619774379134179, "critic_loss": 0.7141165504753589, "actor_loss": -93.88016387939453, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.374353408813477, "step": 85000}
{"episode_reward": 940.0102097905444, "episode": 86.0, "batch_reward": 0.8636777397394181, "critic_loss": 0.6851861343681812, "actor_loss": -93.98358828735351, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.34779191017151, "step": 86000}
{"episode_reward": 927.0560679199025, "episode": 87.0, "batch_reward": 0.8641627637147904, "critic_loss": 0.666016686424613, "actor_loss": -94.0772084350586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33912968635559, "step": 87000}
{"episode_reward": 883.1053184271167, "episode": 88.0, "batch_reward": 0.864110550224781, "critic_loss": 0.7053386530131102, "actor_loss": -94.14321714782714, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.328099250793457, "step": 88000}
{"episode_reward": 947.3579426474341, "episode": 89.0, "batch_reward": 0.8651147935390472, "critic_loss": 0.703265645235777, "actor_loss": -94.01312092590332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.331582069396973, "step": 89000}
{"episode_reward": 958.5509472073883, "episode": 90.0, "batch_reward": 0.8664065276384354, "critic_loss": 0.7068556427359581, "actor_loss": -94.12963417053223, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.353421926498413, "step": 90000}
{"episode_reward": 934.5719171424571, "episode": 91.0, "batch_reward": 0.8667743514776229, "critic_loss": 0.6905816285014152, "actor_loss": -94.05193891906738, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.92037391662598, "step": 91000}
{"episode_reward": 923.8525057103003, "episode": 92.0, "batch_reward": 0.8677107334136963, "critic_loss": 0.6438060472607613, "actor_loss": -94.18708331298828, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.347662687301636, "step": 92000}
{"episode_reward": 952.9994475205099, "episode": 93.0, "batch_reward": 0.8690905137658119, "critic_loss": 0.637975339114666, "actor_loss": -94.2708950958252, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37381362915039, "step": 93000}
{"episode_reward": 932.044205668406, "episode": 94.0, "batch_reward": 0.8692935365438461, "critic_loss": 0.685405973881483, "actor_loss": -94.4537707824707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.33078360557556, "step": 94000}
{"episode_reward": 919.0503014741832, "episode": 95.0, "batch_reward": 0.8706284644007682, "critic_loss": 0.6671072738468647, "actor_loss": -94.47752210998536, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32172703742981, "step": 95000}
{"episode_reward": 924.8146519137882, "episode": 96.0, "batch_reward": 0.8703659959435462, "critic_loss": 0.7169014532417058, "actor_loss": -94.35284963989258, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.66264843940735, "step": 96000}
{"episode_reward": 951.8229756924534, "episode": 97.0, "batch_reward": 0.8701060431599617, "critic_loss": 0.6942069332748652, "actor_loss": -94.37312377929688, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.368876218795776, "step": 97000}
{"episode_reward": 938.0037289845354, "episode": 98.0, "batch_reward": 0.8711748220920563, "critic_loss": 0.6669986288845539, "actor_loss": -94.29761128234863, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.348644018173218, "step": 98000}
{"episode_reward": 903.3288065691866, "episode": 99.0, "batch_reward": 0.8704725114107132, "critic_loss": 0.6807769474238158, "actor_loss": -94.38383462524413, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30573272705078, "step": 99000}
{"episode_reward": 888.5595240545268, "episode": 100.0, "batch_reward": 0.8696286296844482, "critic_loss": 0.6866171703487635, "actor_loss": -94.37407354736328, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.34343194961548, "step": 100000}
{"episode_reward": 771.5657507067712, "episode": 101.0, "batch_reward": 0.8730628741979599, "critic_loss": 0.6631658947616815, "actor_loss": -94.41159075927735, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.93507695198059, "step": 101000}
{"episode_reward": 954.7998422011684, "episode": 102.0, "batch_reward": 0.8728562851548195, "critic_loss": 0.6681206622421741, "actor_loss": -94.58513133239747, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.333889722824097, "step": 102000}
{"episode_reward": 941.8169660061136, "episode": 103.0, "batch_reward": 0.8729591599702835, "critic_loss": 0.7018632435798645, "actor_loss": -94.35131071472168, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.396061658859253, "step": 103000}
{"episode_reward": 930.3758269913952, "episode": 104.0, "batch_reward": 0.8730794088840484, "critic_loss": 0.6332440245747566, "actor_loss": -94.50207678222657, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.380489587783813, "step": 104000}
{"episode_reward": 930.5034172437438, "episode": 105.0, "batch_reward": 0.8735567698478699, "critic_loss": 0.651302836149931, "actor_loss": -94.29116242980957, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.371816396713257, "step": 105000}
{"episode_reward": 968.7067389321863, "episode": 106.0, "batch_reward": 0.8749349051713944, "critic_loss": 0.6930148687958717, "actor_loss": -94.62273623657227, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.364845037460327, "step": 106000}
{"episode_reward": 920.6528023077218, "episode": 107.0, "batch_reward": 0.8761829456686974, "critic_loss": 0.6588309681713581, "actor_loss": -94.46101600646972, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.375683307647705, "step": 107000}
{"episode_reward": 924.7082935291141, "episode": 108.0, "batch_reward": 0.8747998208999633, "critic_loss": 0.6307564783394337, "actor_loss": -94.29275045776367, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.370691061019897, "step": 108000}
{"episode_reward": 945.4075715996007, "episode": 109.0, "batch_reward": 0.8745912992954255, "critic_loss": 0.6335297287106514, "actor_loss": -94.55560375976563, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.361365795135498, "step": 109000}
{"episode_reward": 929.6270243350876, "episode": 110.0, "batch_reward": 0.8780119182467461, "critic_loss": 0.5998797589540481, "actor_loss": -94.53949813842773, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38732933998108, "step": 110000}
{"episode_reward": 926.3595429181652, "episode": 111.0, "batch_reward": 0.8765877445340157, "critic_loss": 0.6333304891586303, "actor_loss": -94.42204121398926, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.304988384246826, "step": 111000}
{"episode_reward": 940.4448889124321, "episode": 112.0, "batch_reward": 0.8779168781042099, "critic_loss": 0.5881237898468972, "actor_loss": -94.65789021301269, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.343803644180298, "step": 112000}
{"episode_reward": 943.5276145093628, "episode": 113.0, "batch_reward": 0.8792451063990593, "critic_loss": 0.5818146890103817, "actor_loss": -94.642263961792, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.359532117843628, "step": 113000}
{"episode_reward": 933.041118064842, "episode": 114.0, "batch_reward": 0.879375209569931, "critic_loss": 0.6052611896693707, "actor_loss": -94.75019537353515, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.34990406036377, "step": 114000}
{"episode_reward": 964.068729718354, "episode": 115.0, "batch_reward": 0.8802110003232956, "critic_loss": 0.5664486905187368, "actor_loss": -94.65461766052246, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.318753480911255, "step": 115000}
{"episode_reward": 939.6056330264233, "episode": 116.0, "batch_reward": 0.8809340226650239, "critic_loss": 0.5642781890183687, "actor_loss": -94.7100754699707, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.337804317474365, "step": 116000}
{"episode_reward": 925.5748295911948, "episode": 117.0, "batch_reward": 0.8811006171703338, "critic_loss": 0.5545703518986702, "actor_loss": -94.56679571533203, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.331167459487915, "step": 117000}
{"episode_reward": 927.7716223109378, "episode": 118.0, "batch_reward": 0.8805825338363648, "critic_loss": 0.5409816100895405, "actor_loss": -94.66785356140137, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.30937695503235, "step": 118000}
{"episode_reward": 957.614187785727, "episode": 119.0, "batch_reward": 0.8820032004714012, "critic_loss": 0.5273649695515633, "actor_loss": -94.75132165527344, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.348620176315308, "step": 119000}
{"episode_reward": 929.9987248457569, "episode": 120.0, "batch_reward": 0.8816702322363853, "critic_loss": 0.5241496813297272, "actor_loss": -94.64649942016601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37579846382141, "step": 120000}
{"episode_reward": 921.0154298772054, "episode": 121.0, "batch_reward": 0.882597616136074, "critic_loss": 0.5138563913106918, "actor_loss": -94.67706278991699, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.94073939323425, "step": 121000}
{"episode_reward": 946.8354116883124, "episode": 122.0, "batch_reward": 0.8822175285816193, "critic_loss": 0.5212882163897157, "actor_loss": -94.76479219055176, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.34512972831726, "step": 122000}
{"episode_reward": 911.8473250851088, "episode": 123.0, "batch_reward": 0.8827909908890724, "critic_loss": 0.5236808270066976, "actor_loss": -94.93769602966309, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.332439661026, "step": 123000}
{"episode_reward": 929.2513563668485, "episode": 124.0, "batch_reward": 0.8839770651459694, "critic_loss": 0.5376488543003798, "actor_loss": -94.90662051391601, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.35488796234131, "step": 124000}
{"episode_reward": 901.8553738472782, "episode": 125.0, "batch_reward": 0.8842645042538643, "critic_loss": 0.5282077368348836, "actor_loss": -94.90576805114746, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.352309226989746, "step": 125000}
{"episode_reward": 929.3825860284545, "episode": 126.0, "batch_reward": 0.8852580453157425, "critic_loss": 0.5334354663193226, "actor_loss": -94.80779522705078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.369079113006592, "step": 126000}
{"episode_reward": 936.9511207670804, "episode": 127.0, "batch_reward": 0.8841781544685364, "critic_loss": 0.5510863518416882, "actor_loss": -94.79300210571289, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.365045309066772, "step": 127000}
{"episode_reward": 935.8396020390556, "episode": 128.0, "batch_reward": 0.8839170749187469, "critic_loss": 0.5288637278527022, "actor_loss": -94.86994618225097, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.384491205215454, "step": 128000}
{"episode_reward": 923.5368154174985, "episode": 129.0, "batch_reward": 0.884256971359253, "critic_loss": 0.5229851863086223, "actor_loss": -94.78989463806153, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.397582530975342, "step": 129000}
{"episode_reward": 953.3157706155, "episode": 130.0, "batch_reward": 0.887285147368908, "critic_loss": 0.5116768436729908, "actor_loss": -94.88012477111816, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.34951162338257, "step": 130000}
{"episode_reward": 916.3588089447491, "episode": 131.0, "batch_reward": 0.8858822145462036, "critic_loss": 0.5025985727012158, "actor_loss": -94.88232208251954, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 39.96466302871704, "step": 131000}
{"episode_reward": 939.8067399462625, "episode": 132.0, "batch_reward": 0.8859374722242356, "critic_loss": 0.49726069793105127, "actor_loss": -94.99234594726562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.385841608047485, "step": 132000}
{"episode_reward": 942.6261391664785, "episode": 133.0, "batch_reward": 0.8875691265463829, "critic_loss": 0.5113872920870781, "actor_loss": -94.97007009887696, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.404364585876465, "step": 133000}
{"episode_reward": 925.6288361084876, "episode": 134.0, "batch_reward": 0.8874670716524125, "critic_loss": 0.5629193438440562, "actor_loss": -94.89826235961914, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.408716917037964, "step": 134000}
{"episode_reward": 947.1723564892328, "episode": 135.0, "batch_reward": 0.8873000440597534, "critic_loss": 0.5119022337347269, "actor_loss": -94.95814723205567, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.39297103881836, "step": 135000}
{"episode_reward": 906.2982591634202, "episode": 136.0, "batch_reward": 0.8886893886327744, "critic_loss": 0.5134134710133076, "actor_loss": -94.77201428222656, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.38621234893799, "step": 136000}
{"episode_reward": 895.7238227066927, "episode": 137.0, "batch_reward": 0.8872834863066673, "critic_loss": 0.5043949748575688, "actor_loss": -95.02112385559082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.32876205444336, "step": 137000}
{"episode_reward": 956.0000957710088, "episode": 138.0, "batch_reward": 0.8889832705259323, "critic_loss": 0.48259428653120995, "actor_loss": -95.11868127441406, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.325942516326904, "step": 138000}
{"episode_reward": 957.2505820620772, "episode": 139.0, "batch_reward": 0.8892402371764183, "critic_loss": 0.473690608009696, "actor_loss": -95.0247891998291, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.330821990966797, "step": 139000}
{"episode_reward": 949.2938828933387, "episode": 140.0, "batch_reward": 0.8904790825247765, "critic_loss": 0.4891697937101126, "actor_loss": -95.03297396850586, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.344090938568115, "step": 140000}
{"episode_reward": 925.6241065005833, "episode": 141.0, "batch_reward": 0.8878772956728935, "critic_loss": 0.5282576706856489, "actor_loss": -94.94708073425294, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 40.031248807907104, "step": 141000}
{"episode_reward": 932.5093712529274, "episode": 142.0, "batch_reward": 0.8894971157312394, "critic_loss": 0.49835935355722905, "actor_loss": -94.88497932434082, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.374879360198975, "step": 142000}
{"episode_reward": 949.9157112132315, "episode": 143.0, "batch_reward": 0.8892564384937286, "critic_loss": 0.5016574886441231, "actor_loss": -94.96992752075195, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.386919736862183, "step": 143000}
{"episode_reward": 921.531093221572, "episode": 144.0, "batch_reward": 0.8905877205729484, "critic_loss": 0.530377327695489, "actor_loss": -95.04274223327637, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.36684226989746, "step": 144000}
{"episode_reward": 912.0137170089138, "episode": 145.0, "batch_reward": 0.8896525179147721, "critic_loss": 0.530644513040781, "actor_loss": -95.09539305114745, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.335572242736816, "step": 145000}
{"episode_reward": 887.8280512286213, "episode": 146.0, "batch_reward": 0.8908776896595955, "critic_loss": 0.5341431932449341, "actor_loss": -95.15204681396484, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.382909774780273, "step": 146000}
{"episode_reward": 927.7020835779571, "episode": 147.0, "batch_reward": 0.8908635702133179, "critic_loss": 0.5348011957406997, "actor_loss": -95.10604132080078, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.353440523147583, "step": 147000}
{"episode_reward": 853.4613740738976, "episode": 148.0, "batch_reward": 0.8891393166184426, "critic_loss": 0.5567217312306165, "actor_loss": -95.11155688476562, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.37941026687622, "step": 148000}
{"episode_reward": 919.8154195971317, "episode": 149.0, "batch_reward": 0.890087448656559, "critic_loss": 0.5483232428878546, "actor_loss": -95.01441780090332, "actor_target_entropy": -6.0, "alpha_value": 0.0, "duration": 20.378255605697632, "step": 149000}
{"episode_reward": 955.9048604654853, "episode": 150.0, "batch_reward": 0.8893566443324089, "critic_loss": 0.549548377752304, "actor_loss": -95.00343151855469, "actor_target_entropy": -6.0, "alpha_value": 0.0, "step": 150000}
