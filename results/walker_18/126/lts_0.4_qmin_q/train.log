{"episode_reward": 0.0, "episode": 1.0, "duration": 21.549919843673706, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.9083709716796875, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.43819742446821824, "critic_loss": 0.1437025199265093, "actor_loss": -81.552284045332, "actor_target_entropy": -6.0, "alpha_value": 0.002642586817083679, "duration": 61.70490074157715, "step": 3000}
{"episode_reward": 81.32903763141786, "episode": 4.0, "batch_reward": 0.30765583527088164, "critic_loss": 0.4329127122163773, "actor_loss": -78.42273571777343, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.136433124542236, "step": 4000}
{"episode_reward": 134.81538465393507, "episode": 5.0, "batch_reward": 0.2791713700890541, "critic_loss": 0.5831399082690477, "actor_loss": -78.344316116333, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.089598894119263, "step": 5000}
{"episode_reward": 249.25813823507553, "episode": 6.0, "batch_reward": 0.28453737634420395, "critic_loss": 0.7551771640777588, "actor_loss": -78.46505055236817, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.194165229797363, "step": 6000}
{"episode_reward": 350.6336416431622, "episode": 7.0, "batch_reward": 0.2916760994791985, "critic_loss": 0.9616042836010457, "actor_loss": -78.41429510498047, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.789472579956055, "step": 7000}
{"episode_reward": 381.6181122003834, "episode": 8.0, "batch_reward": 0.2947088341861963, "critic_loss": 1.1522730579376221, "actor_loss": -79.01781687927246, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.48880887031555, "step": 8000}
{"episode_reward": 175.68948528211175, "episode": 9.0, "batch_reward": 0.2933014282286167, "critic_loss": 1.3491127935647964, "actor_loss": -79.60650721740723, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.160024404525757, "step": 9000}
{"episode_reward": 392.60303106415137, "episode": 10.0, "batch_reward": 0.31182922977209093, "critic_loss": 1.4470854525566101, "actor_loss": -79.85103732299805, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.116461038589478, "step": 10000}
{"episode_reward": 591.3720729368044, "episode": 11.0, "batch_reward": 0.34293222787976263, "critic_loss": 1.4216354256868362, "actor_loss": -80.24027178955077, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.718236446380615, "step": 11000}
{"episode_reward": 643.9449830823925, "episode": 12.0, "batch_reward": 0.36882517287135125, "critic_loss": 1.5432845965623856, "actor_loss": -80.82204301452637, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.44568133354187, "step": 12000}
{"episode_reward": 650.7799983269679, "episode": 13.0, "batch_reward": 0.37612025848031044, "critic_loss": 1.4711176030635833, "actor_loss": -80.41094021606445, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.207889318466187, "step": 13000}
{"episode_reward": 406.2975626416517, "episode": 14.0, "batch_reward": 0.3935493319928646, "critic_loss": 1.3750872881412506, "actor_loss": -80.80856973266602, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.538668155670166, "step": 14000}
{"episode_reward": 751.6907139587852, "episode": 15.0, "batch_reward": 0.4215254681110382, "critic_loss": 1.3526299973130227, "actor_loss": -80.99101315307617, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.858109712600708, "step": 15000}
{"episode_reward": 799.610471625178, "episode": 16.0, "batch_reward": 0.44555486118793486, "critic_loss": 1.328008984386921, "actor_loss": -82.54201039123535, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.128097534179688, "step": 16000}
{"episode_reward": 776.7407021369544, "episode": 17.0, "batch_reward": 0.4631734950840473, "critic_loss": 1.2836942511200904, "actor_loss": -82.81521412658691, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.413440942764282, "step": 17000}
{"episode_reward": 714.9454286080716, "episode": 18.0, "batch_reward": 0.4785269941687584, "critic_loss": 1.2103860220313072, "actor_loss": -83.01159324645997, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.56291174888611, "step": 18000}
{"episode_reward": 758.3187956282587, "episode": 19.0, "batch_reward": 0.4912842143177986, "critic_loss": 1.1612723351716996, "actor_loss": -83.2422293395996, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.889708995819092, "step": 19000}
{"episode_reward": 776.1805742730016, "episode": 20.0, "batch_reward": 0.5122006376981735, "critic_loss": 1.0775707159042358, "actor_loss": -83.31010919189453, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.116700887680054, "step": 20000}
{"episode_reward": 844.5695138678685, "episode": 21.0, "batch_reward": 0.5272243449687958, "critic_loss": 0.9900348094105721, "actor_loss": -83.90704895019532, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.729613065719604, "step": 21000}
{"episode_reward": 818.0715430956187, "episode": 22.0, "batch_reward": 0.5422572060823441, "critic_loss": 0.9451940711140633, "actor_loss": -83.79954716491699, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.405713081359863, "step": 22000}
{"episode_reward": 818.644923144879, "episode": 23.0, "batch_reward": 0.5493027777373791, "critic_loss": 0.843695731729269, "actor_loss": -84.11669132995605, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.104117393493652, "step": 23000}
{"episode_reward": 759.0916925288627, "episode": 24.0, "batch_reward": 0.5448024548888206, "critic_loss": 0.8636628951728343, "actor_loss": -84.04892707824708, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.485854864120483, "step": 24000}
{"episode_reward": 15.267535170106246, "episode": 25.0, "batch_reward": 0.5404951824843883, "critic_loss": 0.7514855921566487, "actor_loss": -84.16369825744628, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.8205726146698, "step": 25000}
{"episode_reward": 813.7226806727448, "episode": 26.0, "batch_reward": 0.5500776944756508, "critic_loss": 0.7450898996889591, "actor_loss": -84.41219631958008, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.115833044052124, "step": 26000}
{"episode_reward": 863.2353730173207, "episode": 27.0, "batch_reward": 0.5626135440766812, "critic_loss": 0.6967411402463913, "actor_loss": -84.17570948791504, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.063055515289307, "step": 27000}
{"episode_reward": 858.121771611606, "episode": 28.0, "batch_reward": 0.5718142286837101, "critic_loss": 0.6748270036876202, "actor_loss": -84.62647421264649, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.865151405334473, "step": 28000}
{"episode_reward": 901.3570271478694, "episode": 29.0, "batch_reward": 0.5867866044640541, "critic_loss": 0.6453706245422364, "actor_loss": -84.4164313659668, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.13087034225464, "step": 29000}
{"episode_reward": 925.9767407150775, "episode": 30.0, "batch_reward": 0.5940379986763, "critic_loss": 0.584299415051937, "actor_loss": -84.66930923461913, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.107347011566162, "step": 30000}
{"episode_reward": 856.9896009183125, "episode": 31.0, "batch_reward": 0.6016487056314945, "critic_loss": 0.5960288144648075, "actor_loss": -84.99144090270997, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.3496310710907, "step": 31000}
{"episode_reward": 853.5797101374154, "episode": 32.0, "batch_reward": 0.612555487215519, "critic_loss": 0.5787558882832528, "actor_loss": -84.90818321228028, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.118788957595825, "step": 32000}
{"episode_reward": 929.1048735431613, "episode": 33.0, "batch_reward": 0.6213262325525284, "critic_loss": 0.5969002812206745, "actor_loss": -84.55631588745118, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.136032342910767, "step": 33000}
{"episode_reward": 811.0746534058961, "episode": 34.0, "batch_reward": 0.6287679365873337, "critic_loss": 0.6032859911620617, "actor_loss": -85.21058868408203, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.352015733718872, "step": 34000}
{"episode_reward": 912.5855748756885, "episode": 35.0, "batch_reward": 0.6390310336351395, "critic_loss": 0.6005690763890743, "actor_loss": -85.39684790039063, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.307349920272827, "step": 35000}
{"episode_reward": 909.848827120021, "episode": 36.0, "batch_reward": 0.6425552462339401, "critic_loss": 0.6364764181375504, "actor_loss": -85.35188914489746, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.126116037368774, "step": 36000}
{"episode_reward": 795.9955080026153, "episode": 37.0, "batch_reward": 0.6518175739049912, "critic_loss": 0.5820867593884468, "actor_loss": -85.51287619018555, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.613269090652466, "step": 37000}
{"episode_reward": 954.8905330814129, "episode": 38.0, "batch_reward": 0.6561803721189499, "critic_loss": 0.566197688639164, "actor_loss": -85.09864485168457, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.551204442977905, "step": 38000}
{"episode_reward": 864.1402766129661, "episode": 39.0, "batch_reward": 0.6627744305729866, "critic_loss": 0.5511916387677193, "actor_loss": -85.46175801086426, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.408562660217285, "step": 39000}
{"episode_reward": 910.1970100324689, "episode": 40.0, "batch_reward": 0.6658874143958091, "critic_loss": 0.5452292354404926, "actor_loss": -85.78236717224121, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.130330801010132, "step": 40000}
{"episode_reward": 906.3622777787094, "episode": 41.0, "batch_reward": 0.673168413579464, "critic_loss": 0.5444700072705746, "actor_loss": -86.16871028137207, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.09985327720642, "step": 41000}
{"episode_reward": 906.8671960679009, "episode": 42.0, "batch_reward": 0.6790948653817177, "critic_loss": 0.538882705450058, "actor_loss": -86.04590994262695, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.25435996055603, "step": 42000}
{"episode_reward": 917.4201455372349, "episode": 43.0, "batch_reward": 0.6867821634411811, "critic_loss": 0.5500766234993935, "actor_loss": -86.22298852539062, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.120978355407715, "step": 43000}
{"episode_reward": 881.1415992874996, "episode": 44.0, "batch_reward": 0.6895891177654266, "critic_loss": 0.5204715642035007, "actor_loss": -86.22847077941894, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.816097259521484, "step": 44000}
{"episode_reward": 881.8704676946736, "episode": 45.0, "batch_reward": 0.6943923187851906, "critic_loss": 0.5125495759248734, "actor_loss": -86.1719171295166, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.554791927337646, "step": 45000}
{"episode_reward": 872.5541190660492, "episode": 46.0, "batch_reward": 0.6965962483286857, "critic_loss": 0.5004106815755367, "actor_loss": -86.57202276611328, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.536478519439697, "step": 46000}
{"episode_reward": 896.7504096985249, "episode": 47.0, "batch_reward": 0.7027384760379791, "critic_loss": 0.4978278802037239, "actor_loss": -87.04521697998047, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.079008102416992, "step": 47000}
{"episode_reward": 901.7451969884298, "episode": 48.0, "batch_reward": 0.7080013387203217, "critic_loss": 0.503790514588356, "actor_loss": -86.79516514587402, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.0021550655365, "step": 48000}
{"episode_reward": 899.5220375748997, "episode": 49.0, "batch_reward": 0.7111023312211037, "critic_loss": 0.48763746705651284, "actor_loss": -86.98486828613281, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.45009970664978, "step": 49000}
{"episode_reward": 898.9683240772567, "episode": 50.0, "batch_reward": 0.7155142009854317, "critic_loss": 0.47251095312833785, "actor_loss": -87.34956820678711, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.20860266685486, "step": 50000}
{"episode_reward": 869.595626074641, "episode": 51.0, "batch_reward": 0.7193253898024559, "critic_loss": 0.47474954660236834, "actor_loss": -86.89909605407715, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.975621700286865, "step": 51000}
{"episode_reward": 916.9148271962829, "episode": 52.0, "batch_reward": 0.7204085303544998, "critic_loss": 0.475206156000495, "actor_loss": -87.6790934753418, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.534247159957886, "step": 52000}
{"episode_reward": 912.7315909096903, "episode": 53.0, "batch_reward": 0.7259512951970101, "critic_loss": 0.4674707067608833, "actor_loss": -87.1938102722168, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.214507341384888, "step": 53000}
{"episode_reward": 899.4266367305503, "episode": 54.0, "batch_reward": 0.7294099696874619, "critic_loss": 0.4654200836867094, "actor_loss": -87.92479585266113, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.128411531448364, "step": 54000}
{"episode_reward": 908.3547711362854, "episode": 55.0, "batch_reward": 0.731111692070961, "critic_loss": 0.4729931192100048, "actor_loss": -87.89147247314453, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.253735065460205, "step": 55000}
{"episode_reward": 877.6227311106936, "episode": 56.0, "batch_reward": 0.733931004524231, "critic_loss": 0.4552895613908768, "actor_loss": -87.56790702819825, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.80992293357849, "step": 56000}
{"episode_reward": 972.1122843436075, "episode": 57.0, "batch_reward": 0.739755471944809, "critic_loss": 0.44167191933095457, "actor_loss": -87.93683708190918, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.109235286712646, "step": 57000}
{"episode_reward": 952.6650966646388, "episode": 58.0, "batch_reward": 0.7431637188792228, "critic_loss": 0.43876243849098684, "actor_loss": -87.92012519836426, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.2826509475708, "step": 58000}
{"episode_reward": 910.4798358594664, "episode": 59.0, "batch_reward": 0.7454373714327812, "critic_loss": 0.455565932109952, "actor_loss": -88.41798553466796, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.527153253555298, "step": 59000}
{"episode_reward": 904.9970208530591, "episode": 60.0, "batch_reward": 0.7476086217164993, "critic_loss": 0.43112870810925963, "actor_loss": -88.65561143493652, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.2255117893219, "step": 60000}
{"episode_reward": 897.9780348062725, "episode": 61.0, "batch_reward": 0.7508656069040298, "critic_loss": 0.4411864991337061, "actor_loss": -88.48345816040039, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.322149991989136, "step": 61000}
{"episode_reward": 904.7627274238745, "episode": 62.0, "batch_reward": 0.7524679829478264, "critic_loss": 0.4194807190150022, "actor_loss": -88.3056558227539, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.54954433441162, "step": 62000}
{"episode_reward": 956.4019136288958, "episode": 63.0, "batch_reward": 0.7536169702410698, "critic_loss": 0.44622739881277085, "actor_loss": -88.39737515258788, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.298423051834106, "step": 63000}
{"episode_reward": 884.3849132849865, "episode": 64.0, "batch_reward": 0.7574106788039208, "critic_loss": 0.42392809309065344, "actor_loss": -88.87073017883301, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.142052173614502, "step": 64000}
{"episode_reward": 832.4712619912741, "episode": 65.0, "batch_reward": 0.7589377572536469, "critic_loss": 0.4413967895358801, "actor_loss": -88.89811936950683, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.960174560546875, "step": 65000}
{"episode_reward": 913.5682190502632, "episode": 66.0, "batch_reward": 0.7617523239254952, "critic_loss": 0.4220542486310005, "actor_loss": -88.91367123413086, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.507441520690918, "step": 66000}
{"episode_reward": 941.8454502684499, "episode": 67.0, "batch_reward": 0.7656288340687751, "critic_loss": 0.422466062694788, "actor_loss": -89.14985366821288, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.25563073158264, "step": 67000}
{"episode_reward": 925.8857825134988, "episode": 68.0, "batch_reward": 0.767770633161068, "critic_loss": 0.42440571054816245, "actor_loss": -89.418896484375, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.201201915740967, "step": 68000}
{"episode_reward": 951.7035255387306, "episode": 69.0, "batch_reward": 0.7697157016396523, "critic_loss": 0.4100960036814213, "actor_loss": -89.33835583496094, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.033254146575928, "step": 69000}
{"episode_reward": 937.9710550378209, "episode": 70.0, "batch_reward": 0.772817161500454, "critic_loss": 0.41862642543017864, "actor_loss": -89.67689730834961, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.825155019760132, "step": 70000}
{"episode_reward": 948.8683847767122, "episode": 71.0, "batch_reward": 0.773172681927681, "critic_loss": 0.4337072759270668, "actor_loss": -89.67975569152831, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.47235631942749, "step": 71000}
{"episode_reward": 900.4605231900304, "episode": 72.0, "batch_reward": 0.7755884012579918, "critic_loss": 0.4223737480342388, "actor_loss": -89.62310025024414, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.545114755630493, "step": 72000}
{"episode_reward": 839.0994620586107, "episode": 73.0, "batch_reward": 0.7754436984062195, "critic_loss": 0.42358091197907927, "actor_loss": -89.68068353271484, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.239123344421387, "step": 73000}
{"episode_reward": 935.6792509923988, "episode": 74.0, "batch_reward": 0.7796945173144341, "critic_loss": 0.43897832664847375, "actor_loss": -90.01821185302734, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.08347511291504, "step": 74000}
{"episode_reward": 938.5255132335127, "episode": 75.0, "batch_reward": 0.7825884703397751, "critic_loss": 0.4507636508494616, "actor_loss": -90.02289738464356, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.01263427734375, "step": 75000}
{"episode_reward": 903.9223673535669, "episode": 76.0, "batch_reward": 0.7836023329496383, "critic_loss": 0.4281036020219326, "actor_loss": -90.25391290283203, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.334202527999878, "step": 76000}
{"episode_reward": 939.3901103783318, "episode": 77.0, "batch_reward": 0.7864872975945473, "critic_loss": 0.44649674889445307, "actor_loss": -90.06963018798828, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.607115030288696, "step": 77000}
{"episode_reward": 941.7238662801284, "episode": 78.0, "batch_reward": 0.7864641314744949, "critic_loss": 0.43423477417230605, "actor_loss": -90.11295346069336, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.10830044746399, "step": 78000}
{"episode_reward": 913.9343635483303, "episode": 79.0, "batch_reward": 0.7876322298049927, "critic_loss": 0.4382619534432888, "actor_loss": -90.17040388488769, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.34327244758606, "step": 79000}
{"episode_reward": 903.9991752038896, "episode": 80.0, "batch_reward": 0.7900104430317879, "critic_loss": 0.42659465004503727, "actor_loss": -90.43818727111817, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.984555959701538, "step": 80000}
{"episode_reward": 928.6585552198069, "episode": 81.0, "batch_reward": 0.7920110875964165, "critic_loss": 0.43622766360640525, "actor_loss": -90.34859913635253, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.17489218711853, "step": 81000}
{"episode_reward": 935.1554666264087, "episode": 82.0, "batch_reward": 0.7929053806066513, "critic_loss": 0.43920944432914255, "actor_loss": -90.45586610412597, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.526374340057373, "step": 82000}
{"episode_reward": 912.8125320699943, "episode": 83.0, "batch_reward": 0.7944277366399765, "critic_loss": 0.4250884774327278, "actor_loss": -90.68156045532227, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.311435222625732, "step": 83000}
{"episode_reward": 932.5275803987386, "episode": 84.0, "batch_reward": 0.7953235009312629, "critic_loss": 0.4197868794202805, "actor_loss": -90.77109286499024, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.163525581359863, "step": 84000}
{"episode_reward": 897.1961447925363, "episode": 85.0, "batch_reward": 0.7967394091486931, "critic_loss": 0.4206091133803129, "actor_loss": -90.54714190673828, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.198281288146973, "step": 85000}
{"episode_reward": 941.6536381378755, "episode": 86.0, "batch_reward": 0.7993396980166435, "critic_loss": 0.40789672619104383, "actor_loss": -90.79926245117187, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.446274280548096, "step": 86000}
{"episode_reward": 927.8328972616644, "episode": 87.0, "batch_reward": 0.800773740708828, "critic_loss": 0.42122176609933376, "actor_loss": -90.91510772705078, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.210569858551025, "step": 87000}
{"episode_reward": 878.1985019907836, "episode": 88.0, "batch_reward": 0.8024101062417031, "critic_loss": 0.42605351280421017, "actor_loss": -90.99367524719239, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.11314868927002, "step": 88000}
{"episode_reward": 948.90497073787, "episode": 89.0, "batch_reward": 0.8035856969952583, "critic_loss": 0.4074405102580786, "actor_loss": -90.9504596862793, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.439676523208618, "step": 89000}
{"episode_reward": 941.1886313430219, "episode": 90.0, "batch_reward": 0.8033513144254685, "critic_loss": 0.4289603418558836, "actor_loss": -90.98459880065919, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.5186505317688, "step": 90000}
{"episode_reward": 898.2245685022027, "episode": 91.0, "batch_reward": 0.8059561660289765, "critic_loss": 0.4269506382495165, "actor_loss": -91.03538708496093, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 39.94276237487793, "step": 91000}
{"episode_reward": 897.3324113254198, "episode": 92.0, "batch_reward": 0.8078451631069183, "critic_loss": 0.42777678136527536, "actor_loss": -91.22488345336915, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.235533237457275, "step": 92000}
{"episode_reward": 967.4864579913834, "episode": 93.0, "batch_reward": 0.8102720218896866, "critic_loss": 0.4161835490614176, "actor_loss": -91.28669436645508, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.32757830619812, "step": 93000}
{"episode_reward": 985.4830569214101, "episode": 94.0, "batch_reward": 0.8112830215096474, "critic_loss": 0.4256703969836235, "actor_loss": -91.38245309448243, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.16395401954651, "step": 94000}
{"episode_reward": 922.2213068600291, "episode": 95.0, "batch_reward": 0.8103473923206329, "critic_loss": 0.4276874981224537, "actor_loss": -91.29632077026368, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.65668296813965, "step": 95000}
{"episode_reward": 897.5965995584108, "episode": 96.0, "batch_reward": 0.812036301612854, "critic_loss": 0.4105295489728451, "actor_loss": -91.5757610168457, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.995373964309692, "step": 96000}
{"episode_reward": 914.1944157554002, "episode": 97.0, "batch_reward": 0.8131234598755837, "critic_loss": 0.41033676406741143, "actor_loss": -91.42824436950684, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.68858504295349, "step": 97000}
{"episode_reward": 944.8939780041894, "episode": 98.0, "batch_reward": 0.8149167991876602, "critic_loss": 0.38223444944620133, "actor_loss": -91.41764801025391, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.100436210632324, "step": 98000}
{"episode_reward": 929.795526168775, "episode": 99.0, "batch_reward": 0.8174125112891197, "critic_loss": 0.3981040666997433, "actor_loss": -91.7784587249756, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.755006313323975, "step": 99000}
{"episode_reward": 923.1514484158301, "episode": 100.0, "batch_reward": 0.8155537940263748, "critic_loss": 0.3993707125633955, "actor_loss": -91.63699964904785, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.847986936569214, "step": 100000}
{"episode_reward": 940.5882957237758, "episode": 101.0, "batch_reward": 0.8199374933838844, "critic_loss": 0.4071795719861984, "actor_loss": -91.76188893127441, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.52468824386597, "step": 101000}
{"episode_reward": 954.6036268761138, "episode": 102.0, "batch_reward": 0.8202899413108826, "critic_loss": 0.41008641695976256, "actor_loss": -91.6644384765625, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.442317247390747, "step": 102000}
{"episode_reward": 940.3485722462735, "episode": 103.0, "batch_reward": 0.8219548645019531, "critic_loss": 0.4145046550631523, "actor_loss": -91.73811865234374, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.233875513076782, "step": 103000}
{"episode_reward": 948.0937707704727, "episode": 104.0, "batch_reward": 0.8214102945327759, "critic_loss": 0.4080376734733582, "actor_loss": -91.87625283813476, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.346998929977417, "step": 104000}
{"episode_reward": 914.1459253224185, "episode": 105.0, "batch_reward": 0.8220880288481712, "critic_loss": 0.41438149024546145, "actor_loss": -91.86222137451172, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.485913515090942, "step": 105000}
{"episode_reward": 897.1097643905706, "episode": 106.0, "batch_reward": 0.8239284271001815, "critic_loss": 0.4206121495217085, "actor_loss": -91.98584855651856, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.86202836036682, "step": 106000}
{"episode_reward": 918.4757695428249, "episode": 107.0, "batch_reward": 0.8255736801028252, "critic_loss": 0.4149921323657036, "actor_loss": -92.03491848754882, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.115713357925415, "step": 107000}
{"episode_reward": 902.6717928384065, "episode": 108.0, "batch_reward": 0.8249136769175529, "critic_loss": 0.41555073840916157, "actor_loss": -91.8029313659668, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.596245527267456, "step": 108000}
{"episode_reward": 931.2344140463804, "episode": 109.0, "batch_reward": 0.825475777208805, "critic_loss": 0.3809238147288561, "actor_loss": -92.11503106689453, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.5014545917511, "step": 109000}
{"episode_reward": 947.2901144836372, "episode": 110.0, "batch_reward": 0.8285362438559533, "critic_loss": 0.394406642138958, "actor_loss": -92.17179158020019, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.323918104171753, "step": 110000}
{"episode_reward": 937.3641331792134, "episode": 111.0, "batch_reward": 0.8276292470693588, "critic_loss": 0.4080084952414036, "actor_loss": -91.95034370422363, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.71877861022949, "step": 111000}
{"episode_reward": 920.7238029694028, "episode": 112.0, "batch_reward": 0.8300161502957344, "critic_loss": 0.3944616994559765, "actor_loss": -92.37979167175293, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.734636068344116, "step": 112000}
{"episode_reward": 910.6328881036476, "episode": 113.0, "batch_reward": 0.831099795281887, "critic_loss": 0.4061999967247248, "actor_loss": -92.2528104248047, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.125367641448975, "step": 113000}
{"episode_reward": 935.140426668537, "episode": 114.0, "batch_reward": 0.8305855999588967, "critic_loss": 0.4041885598599911, "actor_loss": -92.25302018737793, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.17402672767639, "step": 114000}
{"episode_reward": 969.5153641355882, "episode": 115.0, "batch_reward": 0.8312641388177872, "critic_loss": 0.4009470052421093, "actor_loss": -92.28154837036132, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.529399871826172, "step": 115000}
{"episode_reward": 948.1309922753487, "episode": 116.0, "batch_reward": 0.8344552338123321, "critic_loss": 0.38255554492771626, "actor_loss": -92.31537637329102, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.03868293762207, "step": 116000}
{"episode_reward": 905.7607173519564, "episode": 117.0, "batch_reward": 0.833622384428978, "critic_loss": 0.38240154582262037, "actor_loss": -92.16570736694337, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.11077857017517, "step": 117000}
{"episode_reward": 943.0631438158308, "episode": 118.0, "batch_reward": 0.8338611547350884, "critic_loss": 0.36538993199169634, "actor_loss": -92.31129336547852, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.82547116279602, "step": 118000}
{"episode_reward": 913.3958082309098, "episode": 119.0, "batch_reward": 0.8366419793963432, "critic_loss": 0.3646942611187696, "actor_loss": -92.39423448181152, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.505111932754517, "step": 119000}
{"episode_reward": 918.5315998751023, "episode": 120.0, "batch_reward": 0.836308519244194, "critic_loss": 0.364533967897296, "actor_loss": -92.30720234680176, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.265169620513916, "step": 120000}
{"episode_reward": 935.8702615950557, "episode": 121.0, "batch_reward": 0.8362856299281121, "critic_loss": 0.37765040110051634, "actor_loss": -92.44313133239746, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.630237340927124, "step": 121000}
{"episode_reward": 937.0915692678947, "episode": 122.0, "batch_reward": 0.8382109680771828, "critic_loss": 0.3676659563332796, "actor_loss": -92.49956874084472, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.01603055000305, "step": 122000}
{"episode_reward": 948.46170415838, "episode": 123.0, "batch_reward": 0.8394497725367546, "critic_loss": 0.3680262433066964, "actor_loss": -92.63262973022461, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.123445510864258, "step": 123000}
{"episode_reward": 955.9473644611975, "episode": 124.0, "batch_reward": 0.8404251102805138, "critic_loss": 0.3616611964404583, "actor_loss": -92.71161123657227, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.306041955947876, "step": 124000}
{"episode_reward": 920.4349781406951, "episode": 125.0, "batch_reward": 0.8397321410179138, "critic_loss": 0.36383033262193204, "actor_loss": -92.70749935913086, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.54209327697754, "step": 125000}
{"episode_reward": 924.8251225399878, "episode": 126.0, "batch_reward": 0.8422389894723892, "critic_loss": 0.36214318330585954, "actor_loss": -92.59659629821778, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.84235405921936, "step": 126000}
{"episode_reward": 894.7858415025433, "episode": 127.0, "batch_reward": 0.8406496627926826, "critic_loss": 0.3691839568093419, "actor_loss": -92.84027764892578, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.125880479812622, "step": 127000}
{"episode_reward": 948.3225807912975, "episode": 128.0, "batch_reward": 0.8409060111641884, "critic_loss": 0.37264853014051913, "actor_loss": -92.71738414001464, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.403438806533813, "step": 128000}
{"episode_reward": 908.6470117037453, "episode": 129.0, "batch_reward": 0.8428137522935867, "critic_loss": 0.38214079415798186, "actor_loss": -92.63485737609864, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.547850131988525, "step": 129000}
{"episode_reward": 976.0187780993989, "episode": 130.0, "batch_reward": 0.845988529920578, "critic_loss": 0.36521201384067536, "actor_loss": -92.81174299621583, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.832062482833862, "step": 130000}
{"episode_reward": 911.5250458920403, "episode": 131.0, "batch_reward": 0.8441767538189888, "critic_loss": 0.35512120281159876, "actor_loss": -92.82111776733399, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.58679986000061, "step": 131000}
{"episode_reward": 947.6405248026239, "episode": 132.0, "batch_reward": 0.8453499150276184, "critic_loss": 0.375349919244647, "actor_loss": -92.96664613342286, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.540521144866943, "step": 132000}
{"episode_reward": 926.0548358068482, "episode": 133.0, "batch_reward": 0.84570474588871, "critic_loss": 0.37546377009153364, "actor_loss": -92.78582214355468, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.394855737686157, "step": 133000}
{"episode_reward": 923.779775279999, "episode": 134.0, "batch_reward": 0.8467309209108352, "critic_loss": 0.35284542782604694, "actor_loss": -92.80733515930176, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.128034591674805, "step": 134000}
{"episode_reward": 942.6583301329503, "episode": 135.0, "batch_reward": 0.8472496058940887, "critic_loss": 0.36375645788013933, "actor_loss": -92.99398333740234, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.3151216506958, "step": 135000}
{"episode_reward": 924.2369089736237, "episode": 136.0, "batch_reward": 0.8491638353466988, "critic_loss": 0.3814532850384712, "actor_loss": -92.77182093811035, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.409883975982666, "step": 136000}
{"episode_reward": 931.5136354979334, "episode": 137.0, "batch_reward": 0.8476206830739975, "critic_loss": 0.37384384022653105, "actor_loss": -93.0547554321289, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.1418137550354, "step": 137000}
{"episode_reward": 953.6902718559651, "episode": 138.0, "batch_reward": 0.8497404383420945, "critic_loss": 0.3606270388364792, "actor_loss": -93.10153077697754, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.154426336288452, "step": 138000}
{"episode_reward": 943.001598278425, "episode": 139.0, "batch_reward": 0.8509730752110481, "critic_loss": 0.37385403488576413, "actor_loss": -93.08674229431152, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.288392066955566, "step": 139000}
{"episode_reward": 944.6371855173055, "episode": 140.0, "batch_reward": 0.8520416915416718, "critic_loss": 0.37591730496287346, "actor_loss": -93.21075546264649, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.195612907409668, "step": 140000}
{"episode_reward": 929.2797457672058, "episode": 141.0, "batch_reward": 0.8492539410591126, "critic_loss": 0.35823399084061386, "actor_loss": -93.10439370727539, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 40.073458194732666, "step": 141000}
{"episode_reward": 933.9379435056907, "episode": 142.0, "batch_reward": 0.8507712806463241, "critic_loss": 0.3683725769221783, "actor_loss": -93.0550630493164, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.575324773788452, "step": 142000}
{"episode_reward": 929.7914137442388, "episode": 143.0, "batch_reward": 0.8524080439805984, "critic_loss": 0.357093565762043, "actor_loss": -93.07260203552246, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.688586711883545, "step": 143000}
{"episode_reward": 941.752684374408, "episode": 144.0, "batch_reward": 0.8529791321754455, "critic_loss": 0.3561750098466873, "actor_loss": -93.18215005493164, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.142471075057983, "step": 144000}
{"episode_reward": 900.361503322484, "episode": 145.0, "batch_reward": 0.8537868512868881, "critic_loss": 0.3399719802588224, "actor_loss": -93.23249255371094, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.655787706375122, "step": 145000}
{"episode_reward": 903.8525381061446, "episode": 146.0, "batch_reward": 0.8526797360777855, "critic_loss": 0.3689582748115063, "actor_loss": -93.27940588378907, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.560481548309326, "step": 146000}
{"episode_reward": 942.0973191108382, "episode": 147.0, "batch_reward": 0.8544913752675056, "critic_loss": 0.3565210452228785, "actor_loss": -93.26490132141113, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.33767008781433, "step": 147000}
{"episode_reward": 953.4084797829325, "episode": 148.0, "batch_reward": 0.8536028020381927, "critic_loss": 0.36780948062241076, "actor_loss": -93.26479885864258, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.286922693252563, "step": 148000}
{"episode_reward": 917.3276198940129, "episode": 149.0, "batch_reward": 0.8551084355711936, "critic_loss": 0.36647951033711434, "actor_loss": -93.34440734863281, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.84715700149536, "step": 149000}
{"episode_reward": 983.6729163571281, "episode": 150.0, "batch_reward": 0.8546812717318535, "critic_loss": 0.35782994163036347, "actor_loss": -93.35913784790039, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "step": 150000}
