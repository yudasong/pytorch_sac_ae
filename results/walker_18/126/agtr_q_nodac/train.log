{"episode": 1.0, "duration": 21.8443341255188, "episode_reward": 29.08591335645728, "step": 1000}
{"episode": 2.0, "duration": 1.897745132446289, "episode_reward": 898.6342244091321, "step": 2000}
{"episode": 3.0, "batch_reward": 0.4389272224271087, "actor_loss": -83.45658283454983, "actor_target_entropy": -6.0, "alpha_value": 0.002642586817083679, "duration": 58.319480180740356, "episode_reward": 65.43545183568409, "step": 3000}
{"episode": 4.0, "batch_reward": 0.30244501420855524, "actor_loss": -80.50070724487304, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.02375030517578, "episode_reward": 104.00569814547171, "step": 4000}
{"episode": 5.0, "batch_reward": 0.2690569648593664, "actor_loss": -80.38291415405273, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.66840958595276, "episode_reward": 220.94539241550808, "step": 5000}
{"episode": 6.0, "batch_reward": 0.2695369303971529, "actor_loss": -81.25549095153809, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.63968586921692, "episode_reward": 318.6257299906921, "step": 6000}
{"episode": 7.0, "batch_reward": 0.27768883810937406, "actor_loss": -81.5433392944336, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.50856351852417, "episode_reward": 319.37027127048697, "step": 7000}
{"episode": 8.0, "batch_reward": 0.2886754979342222, "actor_loss": -82.13210488891602, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.51656150817871, "episode_reward": 421.2029282924179, "step": 8000}
{"episode": 9.0, "batch_reward": 0.30727881215512753, "actor_loss": -83.01116871643066, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.61051344871521, "episode_reward": 477.44110445864663, "step": 9000}
{"episode": 10.0, "batch_reward": 0.32411233116686344, "actor_loss": -83.7857251586914, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.659043788909912, "episode_reward": 456.3303454289517, "step": 10000}
{"episode": 11.0, "batch_reward": 0.33860421761870385, "actor_loss": -84.37895065307617, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 44.185821533203125, "episode_reward": 514.7958248350049, "step": 11000}
{"episode": 12.0, "batch_reward": 0.3548370181024075, "actor_loss": -84.92044343566894, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.663483381271362, "episode_reward": 522.3208582516522, "step": 12000}
{"episode": 13.0, "batch_reward": 0.365007121771574, "actor_loss": -85.19208261108399, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 18.835495710372925, "episode_reward": 449.60246291034116, "step": 13000}
{"episode": 14.0, "batch_reward": 0.37016911017894744, "actor_loss": -85.23711546325684, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.420201301574707, "episode_reward": 512.0554441068713, "step": 14000}
{"episode": 15.0, "batch_reward": 0.37546034520864485, "actor_loss": -85.32311915588379, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.462262868881226, "episode_reward": 353.3559600032926, "step": 15000}
{"episode": 16.0, "batch_reward": 0.3817392535805702, "actor_loss": -85.4683645477295, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.506380319595337, "episode_reward": 545.1415934326695, "step": 16000}
{"episode": 17.0, "batch_reward": 0.38985422706604006, "actor_loss": -85.87910563659668, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.558713674545288, "episode_reward": 528.3979897509042, "step": 17000}
{"episode": 18.0, "batch_reward": 0.3941368018090725, "actor_loss": -85.9786012878418, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.479212284088135, "episode_reward": 447.19262125244677, "step": 18000}
{"episode": 19.0, "batch_reward": 0.39959646126627923, "actor_loss": -86.23512789916992, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.63173246383667, "episode_reward": 360.99778759338335, "step": 19000}
{"episode": 20.0, "batch_reward": 0.38978787860274317, "actor_loss": -86.05949113464355, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.714027643203735, "episode_reward": 72.65850849092547, "step": 20000}
{"episode": 21.0, "batch_reward": 0.38756081476807597, "actor_loss": -86.06659033203125, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.689013719558716, "episode_reward": 642.371737792082, "step": 21000}
{"episode": 22.0, "batch_reward": 0.39607943180203437, "actor_loss": -86.3097655029297, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.611985206604004, "episode_reward": 549.3740583770073, "step": 22000}
{"episode": 23.0, "batch_reward": 0.4013485201895237, "actor_loss": -86.33170550537109, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.16562032699585, "episode_reward": 435.3139528313502, "step": 23000}
{"episode": 24.0, "batch_reward": 0.3990022869706154, "actor_loss": -86.35395198059082, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.823731422424316, "episode_reward": 439.335219660222, "step": 24000}
{"episode": 25.0, "batch_reward": 0.404312501758337, "actor_loss": -86.50887434387207, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.844508409500122, "episode_reward": 469.8053403179651, "step": 25000}
{"episode": 26.0, "batch_reward": 0.40680782854557035, "actor_loss": -86.62381845092773, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.71988582611084, "episode_reward": 489.54485334433906, "step": 26000}
{"episode": 27.0, "batch_reward": 0.4129110241830349, "actor_loss": -86.65364103698731, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.257701635360718, "episode_reward": 607.4087586374987, "step": 27000}
{"episode": 28.0, "batch_reward": 0.41490918016433714, "actor_loss": -86.77604705810546, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.520336151123047, "episode_reward": 255.5704642267332, "step": 28000}
{"episode": 29.0, "batch_reward": 0.4143928816616535, "actor_loss": -86.69408720397949, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.696197509765625, "episode_reward": 625.6130166661378, "step": 29000}
{"episode": 30.0, "batch_reward": 0.42053624004125595, "actor_loss": -86.87080383300781, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.7296941280365, "episode_reward": 488.4461561874911, "step": 30000}
{"episode": 31.0, "batch_reward": 0.41890300127863883, "actor_loss": -86.76954484558105, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.48805260658264, "episode_reward": 229.21327622660806, "step": 31000}
{"episode": 32.0, "batch_reward": 0.41395789840817454, "actor_loss": -86.75495747375489, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.390244722366333, "episode_reward": 624.6047584228978, "step": 32000}
{"episode": 33.0, "batch_reward": 0.423940790861845, "actor_loss": -86.99270764160157, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.034533977508545, "episode_reward": 556.2391195897789, "step": 33000}
{"episode": 34.0, "batch_reward": 0.4278863732814789, "actor_loss": -87.02045910644532, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.368167877197266, "episode_reward": 553.7892586434373, "step": 34000}
{"episode": 35.0, "batch_reward": 0.4295653121471405, "actor_loss": -87.05762796020508, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.73239803314209, "episode_reward": 547.7288864949019, "step": 35000}
{"episode": 36.0, "batch_reward": 0.4329039316773415, "actor_loss": -87.10365773010254, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.614893913269043, "episode_reward": 494.3819514478931, "step": 36000}
{"episode": 37.0, "batch_reward": 0.43626894292235374, "actor_loss": -87.21520741271972, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.647942066192627, "episode_reward": 580.1257845922856, "step": 37000}
{"episode": 38.0, "batch_reward": 0.43629730767011643, "actor_loss": -87.2748045501709, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.007075786590576, "episode_reward": 197.3645391397462, "step": 38000}
{"episode": 39.0, "batch_reward": 0.4350633825659752, "actor_loss": -87.28449723815918, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.488388776779175, "episode_reward": 417.0355813674115, "step": 39000}
{"episode": 40.0, "batch_reward": 0.4301842651665211, "actor_loss": -87.15416975402832, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.55528688430786, "episode_reward": 246.52346325678974, "step": 40000}
{"episode": 41.0, "batch_reward": 0.42526205199956896, "actor_loss": -87.20046243286133, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.28369426727295, "episode_reward": 243.45224595117466, "step": 41000}
{"episode": 42.0, "batch_reward": 0.42287579327821734, "actor_loss": -87.1559200592041, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.93562912940979, "episode_reward": 337.3235910341952, "step": 42000}
{"episode": 43.0, "batch_reward": 0.42285043820738794, "actor_loss": -87.20329318237305, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.733116388320923, "episode_reward": 655.6980575429346, "step": 43000}
{"episode": 44.0, "batch_reward": 0.427651158541441, "actor_loss": -87.31722981262207, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.670602798461914, "episode_reward": 601.2298065831219, "step": 44000}
{"episode": 45.0, "batch_reward": 0.431900825470686, "actor_loss": -87.33030488586425, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.338103532791138, "episode_reward": 625.1710597463987, "step": 45000}
{"episode": 46.0, "batch_reward": 0.43591052663326263, "actor_loss": -87.44026760864257, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.698099851608276, "episode_reward": 643.8089986439642, "step": 46000}
{"episode": 47.0, "batch_reward": 0.43735816222429275, "actor_loss": -87.46628707885742, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.265833139419556, "episode_reward": 283.7534102850547, "step": 47000}
{"episode": 48.0, "batch_reward": 0.43660763669013974, "actor_loss": -87.48292253112793, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.106550216674805, "episode_reward": 564.8541903477972, "step": 48000}
{"episode": 49.0, "batch_reward": 0.43653785160183906, "actor_loss": -87.44652149963379, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.602415084838867, "episode_reward": 203.5356597154356, "step": 49000}
{"episode": 50.0, "batch_reward": 0.43579022657871247, "actor_loss": -87.46483369445801, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.670921325683594, "episode_reward": 631.1682788433898, "step": 50000}
{"episode": 51.0, "batch_reward": 0.43872296446561815, "actor_loss": -87.50377940368652, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.30075740814209, "episode_reward": 668.5806129956836, "step": 51000}
{"episode": 52.0, "batch_reward": 0.44416315817832946, "actor_loss": -87.61666375732422, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.192301750183105, "episode_reward": 687.0789908278007, "step": 52000}
{"episode": 53.0, "batch_reward": 0.44675598812103273, "actor_loss": -87.70585890197754, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.767385721206665, "episode_reward": 373.8317979411249, "step": 53000}
{"episode": 54.0, "batch_reward": 0.4472677733302116, "actor_loss": -87.67227955627442, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.452196836471558, "episode_reward": 630.5170059807938, "step": 54000}
{"episode": 55.0, "batch_reward": 0.4483821651637554, "actor_loss": -87.67768969726562, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.894775390625, "episode_reward": 634.0271963312026, "step": 55000}
{"episode": 56.0, "batch_reward": 0.45234425047039983, "actor_loss": -87.8020266418457, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.35562038421631, "episode_reward": 414.9643027342758, "step": 56000}
{"episode": 57.0, "batch_reward": 0.4513365828692913, "actor_loss": -87.76709950256348, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.730397701263428, "episode_reward": 612.8618151850358, "step": 57000}
{"episode": 58.0, "batch_reward": 0.4568187347650528, "actor_loss": -87.86957708740235, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.554954767227173, "episode_reward": 650.5367605676562, "step": 58000}
{"episode": 59.0, "batch_reward": 0.46053928580880166, "actor_loss": -87.96110563659668, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.730422496795654, "episode_reward": 667.9826460458725, "step": 59000}
{"episode": 60.0, "batch_reward": 0.4610286037325859, "actor_loss": -87.88404531860351, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.585298776626587, "episode_reward": 560.2266806902732, "step": 60000}
{"episode": 61.0, "batch_reward": 0.46425409963727, "actor_loss": -87.97219812011718, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 44.76821684837341, "episode_reward": 395.2684241497456, "step": 61000}
{"episode": 62.0, "batch_reward": 0.4623955554068089, "actor_loss": -87.92241600036621, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.6328125, "episode_reward": 686.6931923183073, "step": 62000}
{"episode": 63.0, "batch_reward": 0.4630974431633949, "actor_loss": -87.93893147277832, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.510640382766724, "episode_reward": 204.11442823869078, "step": 63000}
{"episode": 64.0, "batch_reward": 0.4576685582697392, "actor_loss": -87.79212895202637, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.507288455963135, "episode_reward": 184.77986887220328, "step": 64000}
{"episode": 65.0, "batch_reward": 0.456719661206007, "actor_loss": -87.83025460815429, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.43273949623108, "episode_reward": 512.9358764234872, "step": 65000}
{"episode": 66.0, "batch_reward": 0.4582692686915398, "actor_loss": -87.82492630004883, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.584498643875122, "episode_reward": 655.2588404269258, "step": 66000}
{"episode": 67.0, "batch_reward": 0.4619376177191734, "actor_loss": -87.90466116333008, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.7038414478302, "episode_reward": 660.2526752937081, "step": 67000}
{"episode": 68.0, "batch_reward": 0.4651051512658596, "actor_loss": -87.99636553955078, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.67028045654297, "episode_reward": 717.1244238822377, "step": 68000}
{"episode": 69.0, "batch_reward": 0.4689142964184284, "actor_loss": -88.09685063171386, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.92759346961975, "episode_reward": 628.8337690942692, "step": 69000}
{"episode": 70.0, "batch_reward": 0.47200739857554436, "actor_loss": -88.17513706970215, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.515196084976196, "episode_reward": 652.2070320869016, "step": 70000}
{"episode": 71.0, "batch_reward": 0.4727945459783077, "actor_loss": -88.15090740966797, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 44.50151801109314, "episode_reward": 599.2051754267148, "step": 71000}
{"episode": 72.0, "batch_reward": 0.4757445237636566, "actor_loss": -88.18258094787598, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.211936712265015, "episode_reward": 661.1503894286647, "step": 72000}
{"episode": 73.0, "batch_reward": 0.4774560133814812, "actor_loss": -88.25677947998047, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.096811294555664, "episode_reward": 747.4430806510235, "step": 73000}
{"episode": 74.0, "batch_reward": 0.4810280367732048, "actor_loss": -88.30005784606934, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.72198176383972, "episode_reward": 686.351181117785, "step": 74000}
{"episode": 75.0, "batch_reward": 0.484334509909153, "actor_loss": -88.43970457458497, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.75834560394287, "episode_reward": 693.8929504740875, "step": 75000}
{"episode": 76.0, "batch_reward": 0.4867336570620537, "actor_loss": -88.44690371704101, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.22221851348877, "episode_reward": 432.5222548598933, "step": 76000}
{"episode": 77.0, "batch_reward": 0.4877823001742363, "actor_loss": -88.43270948791503, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.69228768348694, "episode_reward": 627.6430861403365, "step": 77000}
{"episode": 78.0, "batch_reward": 0.48556326016783713, "actor_loss": -88.43388185119629, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.243095636367798, "episode_reward": 610.5021017243698, "step": 78000}
{"episode": 79.0, "batch_reward": 0.48862157183885574, "actor_loss": -88.41637312316894, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.503462553024292, "episode_reward": 683.5192772958004, "step": 79000}
{"episode": 80.0, "batch_reward": 0.49263393077254297, "actor_loss": -88.60112799072266, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.232144355773926, "episode_reward": 691.5249077496443, "step": 80000}
{"episode": 81.0, "batch_reward": 0.4954259992539883, "actor_loss": -88.6147811126709, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 44.20047998428345, "episode_reward": 705.8059664210292, "step": 81000}
{"episode": 82.0, "batch_reward": 0.49582690495252607, "actor_loss": -88.6923424987793, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.32833695411682, "episode_reward": 651.1367864708069, "step": 82000}
{"episode": 83.0, "batch_reward": 0.4983069649934769, "actor_loss": -88.69580039978027, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.11570692062378, "episode_reward": 735.2314896928627, "step": 83000}
{"episode": 84.0, "batch_reward": 0.49974006894230844, "actor_loss": -88.75960670471191, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.34446406364441, "episode_reward": 690.3492045444102, "step": 84000}
{"episode": 85.0, "batch_reward": 0.5009869247078895, "actor_loss": -88.79300350952148, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.546903371810913, "episode_reward": 151.55911805592393, "step": 85000}
{"episode": 86.0, "batch_reward": 0.5001715614795684, "actor_loss": -88.76241667175293, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.895585775375366, "episode_reward": 674.5844494718973, "step": 86000}
{"episode": 87.0, "batch_reward": 0.5025948330461979, "actor_loss": -88.85820372009277, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.66642117500305, "episode_reward": 365.0423766659923, "step": 87000}
{"episode": 88.0, "batch_reward": 0.500498297393322, "actor_loss": -88.81814907836915, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.926753997802734, "episode_reward": 802.1072045057883, "step": 88000}
{"episode": 89.0, "batch_reward": 0.5028968048989773, "actor_loss": -88.85024397277832, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.907626390457153, "episode_reward": 663.6426418882862, "step": 89000}
{"episode": 90.0, "batch_reward": 0.5051548258662224, "actor_loss": -88.91090757751465, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.492483854293823, "episode_reward": 688.0831801488883, "step": 90000}
{"episode": 91.0, "batch_reward": 0.5053939200937748, "actor_loss": -88.87977194213867, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.626298666000366, "episode_reward": 222.66743262564484, "step": 91000}
{"episode": 92.0, "batch_reward": 0.5058542522192001, "actor_loss": -88.96054057312011, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.24448823928833, "episode_reward": 702.2084205870804, "step": 92000}
{"episode": 93.0, "batch_reward": 0.5062787375152111, "actor_loss": -88.98266036987305, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.998657941818237, "episode_reward": 692.2498625200204, "step": 93000}
{"episode": 94.0, "batch_reward": 0.5068116614818573, "actor_loss": -88.94733222961426, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.372069120407104, "episode_reward": 641.3134305733314, "step": 94000}
{"episode": 95.0, "batch_reward": 0.5110363689661026, "actor_loss": -89.01284281921387, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.66104245185852, "episode_reward": 713.9726974589877, "step": 95000}
{"episode": 96.0, "batch_reward": 0.5132344182729721, "actor_loss": -89.0395931854248, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.534858226776123, "episode_reward": 631.0920680438858, "step": 96000}
{"episode": 97.0, "batch_reward": 0.512920584499836, "actor_loss": -89.06986987304687, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.606398582458496, "episode_reward": 676.5718012010972, "step": 97000}
{"episode": 98.0, "batch_reward": 0.5155145654380322, "actor_loss": -89.13738537597656, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.789414644241333, "episode_reward": 744.5813950184746, "step": 98000}
{"episode": 99.0, "batch_reward": 0.5166898255348206, "actor_loss": -89.15041758728027, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.675657272338867, "episode_reward": 408.5857518110015, "step": 99000}
{"episode": 100.0, "batch_reward": 0.516288750141859, "actor_loss": -89.15319926452636, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.662819623947144, "episode_reward": 731.855376225355, "step": 100000}
{"episode": 101.0, "batch_reward": 0.519191433519125, "actor_loss": -89.22691636657714, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.23969268798828, "episode_reward": 679.1656590261257, "step": 101000}
{"episode": 102.0, "batch_reward": 0.5188936069011688, "actor_loss": -89.25082493591309, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.207796812057495, "episode_reward": 684.3042495513832, "step": 102000}
{"episode": 103.0, "batch_reward": 0.5222887928485871, "actor_loss": -89.30021406555176, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.963658571243286, "episode_reward": 691.0111952769153, "step": 103000}
{"episode": 104.0, "batch_reward": 0.5204962425231934, "actor_loss": -89.31768788146972, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.588378429412842, "episode_reward": 554.2861355509566, "step": 104000}
{"episode": 105.0, "batch_reward": 0.5245392685234547, "actor_loss": -89.35640353393555, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.401036500930786, "episode_reward": 677.3659848372271, "step": 105000}
{"episode": 106.0, "batch_reward": 0.5242298929691315, "actor_loss": -89.35132177734376, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.866991996765137, "episode_reward": 670.4908501663941, "step": 106000}
{"episode": 107.0, "batch_reward": 0.5263593631982804, "actor_loss": -89.42099674987793, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.946495056152344, "episode_reward": 650.6154231354692, "step": 107000}
{"episode": 108.0, "batch_reward": 0.5272243980467319, "actor_loss": -89.37165647888183, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.52581238746643, "episode_reward": 612.0264067623438, "step": 108000}
{"episode": 109.0, "batch_reward": 0.5285217433571815, "actor_loss": -89.42443348693848, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.702013969421387, "episode_reward": 719.6963488206461, "step": 109000}
{"episode": 110.0, "batch_reward": 0.5307677724361419, "actor_loss": -89.48422604370117, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.587626934051514, "episode_reward": 739.6690378649336, "step": 110000}
{"episode": 111.0, "batch_reward": 0.5317819783091545, "actor_loss": -89.49563465881347, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 43.502564668655396, "episode_reward": 723.276939669574, "step": 111000}
{"episode": 112.0, "batch_reward": 0.5338809625506401, "actor_loss": -89.5331600036621, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.39691948890686, "episode_reward": 687.8161121333228, "step": 112000}
{"episode": 113.0, "batch_reward": 0.533931066930294, "actor_loss": -89.51766941833496, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.60181212425232, "episode_reward": 563.3027962548379, "step": 113000}
{"episode": 114.0, "batch_reward": 0.535782619714737, "actor_loss": -89.56159927368164, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 23.08413815498352, "episode_reward": 756.2331456566645, "step": 114000}
{"episode": 115.0, "batch_reward": 0.5370236066877841, "actor_loss": -89.59386219787598, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.66459059715271, "episode_reward": 680.8765047535612, "step": 115000}
{"episode": 116.0, "batch_reward": 0.5377564316987992, "actor_loss": -89.6423413848877, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.7538104057312, "episode_reward": 689.0379810905775, "step": 116000}
{"episode": 117.0, "batch_reward": 0.540149409621954, "actor_loss": -89.66540715026855, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.833748817443848, "episode_reward": 674.2245455227637, "step": 117000}
{"episode": 118.0, "batch_reward": 0.5408378049433231, "actor_loss": -89.68129508972169, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.88023018836975, "episode_reward": 284.80593882315924, "step": 118000}
{"episode": 119.0, "batch_reward": 0.5365766145586968, "actor_loss": -89.63386152648926, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.539226055145264, "episode_reward": 179.02316194525497, "step": 119000}
{"episode": 120.0, "batch_reward": 0.5379977348744869, "actor_loss": -89.64337135314942, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.635225534439087, "episode_reward": 702.9809324744559, "step": 120000}
{"episode": 121.0, "batch_reward": 0.5374811603724956, "actor_loss": -89.63584547424317, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.49205303192139, "episode_reward": 432.9020634026197, "step": 121000}
{"episode": 122.0, "batch_reward": 0.5342953352928161, "actor_loss": -89.54646676635743, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.695924520492554, "episode_reward": 284.7547817666166, "step": 122000}
{"episode": 123.0, "batch_reward": 0.5338022102713584, "actor_loss": -89.55645697021484, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.32303214073181, "episode_reward": 636.9310533983327, "step": 123000}
{"episode": 124.0, "batch_reward": 0.5358003271222115, "actor_loss": -89.58218463134766, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.910457134246826, "episode_reward": 691.6617225537542, "step": 124000}
{"episode": 125.0, "batch_reward": 0.5376205857992172, "actor_loss": -89.61563148498536, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.44038414955139, "episode_reward": 715.8606464535395, "step": 125000}
{"episode": 126.0, "batch_reward": 0.5390563540458679, "actor_loss": -89.67668290710449, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.869323253631592, "episode_reward": 701.9479238189286, "step": 126000}
{"episode": 127.0, "batch_reward": 0.5397845224142075, "actor_loss": -89.72358406066894, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.347921133041382, "episode_reward": 692.3688006855969, "step": 127000}
{"episode": 128.0, "batch_reward": 0.538596787750721, "actor_loss": -89.67987533569335, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.59845805168152, "episode_reward": 289.67793451418606, "step": 128000}
{"episode": 129.0, "batch_reward": 0.5381607690751553, "actor_loss": -89.69422657775878, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.376013040542603, "episode_reward": 708.7611564138043, "step": 129000}
{"episode": 130.0, "batch_reward": 0.5395637991726399, "actor_loss": -89.70498080444337, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.380656719207764, "episode_reward": 693.5452728343023, "step": 130000}
{"episode": 131.0, "batch_reward": 0.5422894792258739, "actor_loss": -89.78690406799316, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.658323526382446, "episode_reward": 669.8044558842552, "step": 131000}
{"episode": 132.0, "batch_reward": 0.541307920485735, "actor_loss": -89.76557481384278, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.876847505569458, "episode_reward": 581.2626283439155, "step": 132000}
{"episode": 133.0, "batch_reward": 0.5415592500865459, "actor_loss": -89.70959455871582, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.663934469223022, "episode_reward": 666.9936810316243, "step": 133000}
{"episode": 134.0, "batch_reward": 0.5437596588134765, "actor_loss": -89.79708911132812, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.755947589874268, "episode_reward": 680.9491375802297, "step": 134000}
{"episode": 135.0, "batch_reward": 0.5437550961375236, "actor_loss": -89.85785003662109, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.56492018699646, "episode_reward": 625.6556378397237, "step": 135000}
{"episode": 136.0, "batch_reward": 0.5431666185557842, "actor_loss": -89.78612306213378, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.521923065185547, "episode_reward": 698.8678614909885, "step": 136000}
{"episode": 137.0, "batch_reward": 0.5472270584404468, "actor_loss": -89.85204400634765, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.707592725753784, "episode_reward": 703.6216280692438, "step": 137000}
{"episode": 138.0, "batch_reward": 0.546808044821024, "actor_loss": -89.86176188659668, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.23607087135315, "episode_reward": 743.8451407774287, "step": 138000}
{"episode": 139.0, "batch_reward": 0.549014033049345, "actor_loss": -89.92203451538086, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.185513019561768, "episode_reward": 750.3204468078284, "step": 139000}
{"episode": 140.0, "batch_reward": 0.5511656940579415, "actor_loss": -89.93769900512696, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.60157060623169, "episode_reward": 452.6347447455004, "step": 140000}
{"episode": 141.0, "batch_reward": 0.5493938199281693, "actor_loss": -89.92504454040527, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.92507529258728, "episode_reward": 646.3612732658893, "step": 141000}
{"episode": 142.0, "batch_reward": 0.5487333765029907, "actor_loss": -89.85875949096679, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 19.814841747283936, "episode_reward": 734.7441869839457, "step": 142000}
{"episode": 143.0, "batch_reward": 0.5497435786724091, "actor_loss": -89.8989553527832, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.214787006378174, "episode_reward": 613.8848311968809, "step": 143000}
{"episode": 144.0, "batch_reward": 0.5517700792253017, "actor_loss": -89.92518070983887, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.034337997436523, "episode_reward": 436.2510065158321, "step": 144000}
{"episode": 145.0, "batch_reward": 0.5499181353151799, "actor_loss": -89.97229458618165, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.968045234680176, "episode_reward": 516.3541738004668, "step": 145000}
{"episode": 146.0, "batch_reward": 0.5502329361438751, "actor_loss": -89.94335917663574, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.81931185722351, "episode_reward": 752.1674104026616, "step": 146000}
{"episode": 147.0, "batch_reward": 0.5490803024172783, "actor_loss": -89.90317282104492, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.901344776153564, "episode_reward": 96.5033253419524, "step": 147000}
{"episode": 148.0, "batch_reward": 0.5503998963832856, "actor_loss": -89.9462687072754, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.96871542930603, "episode_reward": 769.7075097074068, "step": 148000}
{"episode": 149.0, "batch_reward": 0.5505543077588081, "actor_loss": -89.91473414611816, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.227030277252197, "episode_reward": 768.0014040779582, "step": 149000}
{"episode": 150.0, "batch_reward": 0.5503002971410751, "actor_loss": -89.90822354125977, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "step": 150000}
