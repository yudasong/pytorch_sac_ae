{"episode": 1.0, "duration": 22.69109559059143, "episode_reward": 29.08591335645728, "step": 1000}
{"episode": 2.0, "duration": 2.113654136657715, "episode_reward": 898.6342244091321, "step": 2000}
{"episode": 3.0, "batch_reward": 0.4730075948553985, "critic_loss": 0.24125479974868735, "actor_loss": -83.91343458770227, "actor_target_entropy": -6.0, "alpha_value": 0.002642586817083679, "duration": 101.39094376564026, "episode_reward": 687.1254241399888, "step": 3000}
{"episode": 4.0, "batch_reward": 0.5474086328744888, "critic_loss": 0.695025459587574, "actor_loss": -86.94377691650391, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 32.27638220787048, "episode_reward": 618.0989708194489, "step": 4000}
{"episode": 5.0, "batch_reward": 0.5647362280786038, "critic_loss": 0.9668789351582527, "actor_loss": -87.8754649810791, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 29.647218465805054, "episode_reward": 670.9700462641258, "step": 5000}
{"episode": 6.0, "batch_reward": 0.5574761761426925, "critic_loss": 1.5390541614294053, "actor_loss": -88.00047381591797, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 31.165841341018677, "episode_reward": 211.76089176708746, "step": 6000}
{"episode": 7.0, "batch_reward": 0.4924978405833244, "critic_loss": 1.3990031272768975, "actor_loss": -86.3323106994629, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 33.746647119522095, "episode_reward": 107.97293778621417, "step": 7000}
{"episode": 8.0, "batch_reward": 0.44378736916184425, "critic_loss": 1.4238241515755654, "actor_loss": -84.93562930297851, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 28.601906538009644, "episode_reward": 147.1149420176141, "step": 8000}
{"episode": 9.0, "batch_reward": 0.4281097851395607, "critic_loss": 1.9741253629922866, "actor_loss": -84.40908319091797, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 30.202015161514282, "episode_reward": 548.8821937329452, "step": 9000}
{"episode": 10.0, "batch_reward": 0.43106477344036104, "critic_loss": 2.7536742641925813, "actor_loss": -73.68654922485352, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 4976.133180141449, "episode_reward": 281.9111836551115, "step": 10000}
{"episode": 11.0, "batch_reward": 0.4249138988852501, "critic_loss": 2.2219758539199828, "actor_loss": -74.1364647064209, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 50.66473722457886, "episode_reward": 550.9239118734666, "step": 11000}
{"episode": 12.0, "batch_reward": 0.43221488654613494, "critic_loss": 2.214733228325844, "actor_loss": -70.84223707580567, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 585.1304337978363, "episode_reward": 393.9465761577102, "step": 12000}
{"episode": 13.0, "batch_reward": 0.43175124153494837, "critic_loss": 2.2206556742191315, "actor_loss": -71.22489108276368, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 35.1777720451355, "episode_reward": 520.456834903991, "step": 13000}
{"episode": 14.0, "batch_reward": 0.4414239795207977, "critic_loss": 2.4259468573331833, "actor_loss": -67.4668765182495, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 597.143089056015, "episode_reward": 668.2667709563248, "step": 14000}
{"episode": 15.0, "batch_reward": 0.4556301522254944, "critic_loss": 2.4764969556331633, "actor_loss": -68.23200917816162, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 30.046656131744385, "episode_reward": 658.2922866943018, "step": 15000}
{"episode": 16.0, "batch_reward": 0.4750509477853775, "critic_loss": 2.3297214434146882, "actor_loss": -66.53237871551514, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 582.8482737541199, "episode_reward": 752.1972331624158, "step": 16000}
{"episode": 17.0, "batch_reward": 0.48867632061243055, "critic_loss": 2.2111967223882676, "actor_loss": -67.36981980895996, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 30.71859335899353, "episode_reward": 676.6966558667037, "step": 17000}
{"episode": 18.0, "batch_reward": 0.49999358141422273, "critic_loss": 2.182137992978096, "actor_loss": -66.97455443572998, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 593.097971200943, "episode_reward": 581.8427807573845, "step": 18000}
{"episode": 19.0, "batch_reward": 0.5073788817226886, "critic_loss": 2.1499647068977357, "actor_loss": -67.44002687835693, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 28.664353370666504, "episode_reward": 777.890102496836, "step": 19000}
{"episode": 20.0, "batch_reward": 0.5130767533183098, "critic_loss": 2.2110665699243546, "actor_loss": -66.9903146057129, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 570.3651313781738, "episode_reward": 556.9936222140062, "step": 20000}
{"episode": 21.0, "batch_reward": 0.5226723964512349, "critic_loss": 2.2331047848463057, "actor_loss": -67.48511830902099, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 50.494526863098145, "episode_reward": 755.6245726646272, "step": 21000}
{"episode": 22.0, "batch_reward": 0.5330450696051121, "critic_loss": 2.2511398421525954, "actor_loss": -67.82488693237305, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 565.2639365196228, "episode_reward": 771.3189058936243, "step": 22000}
{"episode": 23.0, "batch_reward": 0.5431815833747387, "critic_loss": 2.53849485039711, "actor_loss": -68.16954797363282, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 28.98581886291504, "episode_reward": 697.8107342066099, "step": 23000}
{"episode": 24.0, "batch_reward": 0.5500247888565063, "critic_loss": 2.469044345498085, "actor_loss": -66.9540241241455, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 583.4580340385437, "episode_reward": 801.1783082600098, "step": 24000}
{"episode": 25.0, "batch_reward": 0.5620148206651211, "critic_loss": 2.2612259608507155, "actor_loss": -67.5268962020874, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 28.444993019104004, "episode_reward": 872.3429147446718, "step": 25000}
{"episode": 26.0, "batch_reward": 0.5738634680509567, "critic_loss": 2.1809853700399398, "actor_loss": -65.84730809020996, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 596.5994024276733, "episode_reward": 850.0982818678128, "step": 26000}
{"episode": 27.0, "batch_reward": 0.5863151106536388, "critic_loss": 2.0167905946969986, "actor_loss": -66.54888633728028, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 28.811532020568848, "episode_reward": 897.2397486595511, "step": 27000}
{"episode": 28.0, "batch_reward": 0.5952555010914803, "critic_loss": 1.9499936108589173, "actor_loss": -66.93083850860596, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 549.9187324047089, "episode_reward": 745.8328852118235, "step": 28000}
{"episode": 29.0, "batch_reward": 0.6034688240885735, "critic_loss": 2.101477057099342, "actor_loss": -67.2425184020996, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 30.36238932609558, "episode_reward": 887.1513377218733, "step": 29000}
{"episode": 30.0, "batch_reward": 0.6113995521962643, "critic_loss": 1.980986775994301, "actor_loss": -67.52085006713867, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 590.9573178291321, "episode_reward": 891.5309605082772, "step": 30000}
{"episode": 31.0, "batch_reward": 0.618053570240736, "critic_loss": 1.993443464756012, "actor_loss": -67.88450560760498, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 50.50715637207031, "episode_reward": 874.5157984590411, "step": 31000}
{"episode": 32.0, "batch_reward": 0.6284363675713539, "critic_loss": 1.8729764983654023, "actor_loss": -68.53535926818847, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 565.9852464199066, "episode_reward": 822.9460842928152, "step": 32000}
{"episode": 33.0, "batch_reward": 0.6355779173970223, "critic_loss": 1.8196872507929802, "actor_loss": -68.93217166137696, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 28.53299570083618, "episode_reward": 873.8670814161203, "step": 33000}
{"episode": 34.0, "batch_reward": 0.6421771636605262, "critic_loss": 1.70729739266634, "actor_loss": -69.82090321350098, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 559.8170728683472, "episode_reward": 879.3705985860333, "step": 34000}
{"episode": 35.0, "batch_reward": 0.6484981676340104, "critic_loss": 1.6220555669665337, "actor_loss": -70.27667503356933, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 33.932037115097046, "episode_reward": 819.3058474159897, "step": 35000}
{"episode": 36.0, "batch_reward": 0.6535081709623337, "critic_loss": 1.61142343634367, "actor_loss": -70.78870957946778, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 611.072788476944, "episode_reward": 834.0491601798027, "step": 36000}
{"episode": 37.0, "batch_reward": 0.65862201744318, "critic_loss": 1.5854019924402236, "actor_loss": -71.10450415039062, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 28.29717755317688, "episode_reward": 838.7664111244284, "step": 37000}
{"episode": 38.0, "batch_reward": 0.6630826794505119, "critic_loss": 1.5270866053700447, "actor_loss": -71.38010530090332, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 555.4516520500183, "episode_reward": 890.6780584989564, "step": 38000}
{"episode": 39.0, "batch_reward": 0.6701826357245445, "critic_loss": 1.4397343852519988, "actor_loss": -71.74339517211914, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 30.883572816848755, "episode_reward": 843.7377538299065, "step": 39000}
{"episode": 40.0, "batch_reward": 0.6718863791823387, "critic_loss": 1.3905306356549263, "actor_loss": -72.16895053100586, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 567.823531627655, "episode_reward": 871.95791914479, "step": 40000}
{"episode": 41.0, "batch_reward": 0.6758123210668564, "critic_loss": 1.4459008640050888, "actor_loss": -72.45625183105469, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 50.12515997886658, "episode_reward": 793.0150399731967, "step": 41000}
{"episode": 42.0, "batch_reward": 0.6807747666835785, "critic_loss": 1.3736391787528992, "actor_loss": -72.6601681060791, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 568.3604774475098, "episode_reward": 855.9793731444422, "step": 42000}
{"episode": 43.0, "batch_reward": 0.6857641994953155, "critic_loss": 1.309672293305397, "actor_loss": -72.99809043884278, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 29.160974979400635, "episode_reward": 909.0015943237131, "step": 43000}
{"episode": 44.0, "batch_reward": 0.6889331703782081, "critic_loss": 1.2517746084332466, "actor_loss": -73.331171875, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 568.1101126670837, "episode_reward": 878.505032862087, "step": 44000}
{"episode": 45.0, "batch_reward": 0.6922918794751167, "critic_loss": 1.2864151064753533, "actor_loss": -73.58203958129883, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 30.59147572517395, "episode_reward": 737.7693475773384, "step": 45000}
{"episode": 46.0, "batch_reward": 0.6974616273641586, "critic_loss": 1.2722900525927543, "actor_loss": -73.80380891418457, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 596.213390827179, "episode_reward": 904.5867746526892, "step": 46000}
{"episode": 47.0, "batch_reward": 0.7016312974095344, "critic_loss": 1.1531106332540513, "actor_loss": -74.16564945983886, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 28.394925355911255, "episode_reward": 921.2359255076663, "step": 47000}
{"episode": 48.0, "batch_reward": 0.705345484316349, "critic_loss": 1.1461862099170685, "actor_loss": -74.43753648376465, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 582.6722304821014, "episode_reward": 874.0744505154353, "step": 48000}
{"episode": 49.0, "batch_reward": 0.7082673007845879, "critic_loss": 1.1205396881699563, "actor_loss": -74.60412013244628, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 28.917977333068848, "episode_reward": 890.6335192018046, "step": 49000}
{"episode": 50.0, "batch_reward": 0.7125753536820412, "critic_loss": 1.0998101251125336, "actor_loss": -74.75023014831542, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 569.7393269538879, "episode_reward": 907.5093616905593, "step": 50000}
{"episode": 51.0, "batch_reward": 0.7156393438577652, "critic_loss": 1.0621488063931466, "actor_loss": -74.95985975646973, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 54.09449791908264, "episode_reward": 876.3227585114232, "step": 51000}
{"episode": 52.0, "batch_reward": 0.7191452168822289, "critic_loss": 1.072025593817234, "actor_loss": -75.35373016357421, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 563.8018181324005, "episode_reward": 893.5186651851369, "step": 52000}
{"episode": 53.0, "batch_reward": 0.7229403622150421, "critic_loss": 1.0248993586301804, "actor_loss": -75.6278455505371, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 29.61714506149292, "episode_reward": 911.1133671830696, "step": 53000}
{"episode": 54.0, "batch_reward": 0.7265441005825997, "critic_loss": 0.981677546441555, "actor_loss": -75.91019636535644, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 579.9524691104889, "episode_reward": 915.007114777608, "step": 54000}
{"episode": 55.0, "batch_reward": 0.727516476213932, "critic_loss": 0.9830304841399193, "actor_loss": -76.11090567016602, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 29.405768632888794, "episode_reward": 874.3512718588967, "step": 55000}
{"episode": 56.0, "batch_reward": 0.7326089751124382, "critic_loss": 0.9638287094831467, "actor_loss": -76.47974531555175, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 577.9607124328613, "episode_reward": 907.4978365448902, "step": 56000}
{"episode": 57.0, "batch_reward": 0.7348431605100632, "critic_loss": 0.9581536618173122, "actor_loss": -76.71709210205078, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 32.941505670547485, "episode_reward": 919.3006388686842, "step": 57000}
{"episode": 58.0, "batch_reward": 0.7372347564101219, "critic_loss": 0.9269102638363839, "actor_loss": -76.77349075317383, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 551.7491688728333, "episode_reward": 897.3763172361782, "step": 58000}
{"episode": 59.0, "batch_reward": 0.7424852167963981, "critic_loss": 0.9032179079353809, "actor_loss": -77.10338879394531, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 29.824826955795288, "episode_reward": 929.0820904427575, "step": 59000}
{"episode": 60.0, "batch_reward": 0.7440227712392807, "critic_loss": 0.8719601271748543, "actor_loss": -77.07198184204101, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 591.7704064846039, "episode_reward": 874.8760563794923, "step": 60000}
{"episode": 61.0, "batch_reward": 0.7463317955136299, "critic_loss": 0.844027363806963, "actor_loss": -77.28903411865234, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 50.61906957626343, "episode_reward": 912.6744625615693, "step": 61000}
{"episode": 62.0, "batch_reward": 0.7492778189778327, "critic_loss": 0.8434705325067043, "actor_loss": -76.9224446105957, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 597.7646114826202, "episode_reward": 959.9346784277777, "step": 62000}
{"episode": 63.0, "batch_reward": 0.7526492431759835, "critic_loss": 0.8032999742627144, "actor_loss": -77.23221151733398, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 29.083547115325928, "episode_reward": 898.4764020312205, "step": 63000}
{"episode": 64.0, "batch_reward": 0.754001229763031, "critic_loss": 0.8019073621928692, "actor_loss": -76.9217424621582, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 604.3146858215332, "episode_reward": 917.2172388789287, "step": 64000}
{"episode": 65.0, "batch_reward": 0.7566831287741661, "critic_loss": 0.7718640398383141, "actor_loss": -77.15800578308105, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 34.8283531665802, "episode_reward": 912.8476864506922, "step": 65000}
{"episode": 66.0, "batch_reward": 0.7610308312177658, "critic_loss": 0.777681748598814, "actor_loss": -77.39629634094238, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 578.6556441783905, "episode_reward": 897.417993623024, "step": 66000}
{"episode": 67.0, "batch_reward": 0.7611767964959144, "critic_loss": 0.7429264435470104, "actor_loss": -77.60302180480957, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 30.316829204559326, "episode_reward": 896.1113791759693, "step": 67000}
{"episode": 68.0, "batch_reward": 0.7645818600654603, "critic_loss": 0.7151079956889153, "actor_loss": -77.77841796875, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 552.5190160274506, "episode_reward": 941.0697842917637, "step": 68000}
{"episode": 69.0, "batch_reward": 0.76693526750803, "critic_loss": 0.6998612545728683, "actor_loss": -78.0463532409668, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 28.108330726623535, "episode_reward": 936.7177482863893, "step": 69000}
{"episode": 70.0, "batch_reward": 0.7679380786418915, "critic_loss": 0.6989543689489365, "actor_loss": -78.20047375488281, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 590.2662382125854, "episode_reward": 863.3945725329163, "step": 70000}
{"episode": 71.0, "batch_reward": 0.7699619081020356, "critic_loss": 0.6831980928480625, "actor_loss": -78.42102981567383, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 51.477670431137085, "episode_reward": 871.8806007877265, "step": 71000}
{"episode": 72.0, "batch_reward": 0.7722199782729149, "critic_loss": 0.684962228089571, "actor_loss": -78.64092254638672, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 571.5965464115143, "episode_reward": 904.3302652232665, "step": 72000}
{"episode": 73.0, "batch_reward": 0.7741670773625374, "critic_loss": 0.6540014259517193, "actor_loss": -78.93448007202149, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 28.59850835800171, "episode_reward": 953.1547487596339, "step": 73000}
{"episode": 74.0, "batch_reward": 0.7754418887495994, "critic_loss": 0.6840228655338287, "actor_loss": -78.82179167175293, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 579.775377035141, "episode_reward": 895.3803377390026, "step": 74000}
{"episode": 75.0, "batch_reward": 0.7769905503392219, "critic_loss": 0.6397141651511192, "actor_loss": -78.93727665710449, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 31.00580883026123, "episode_reward": 862.82930109446, "step": 75000}
{"episode": 76.0, "batch_reward": 0.7796505845189095, "critic_loss": 0.6165160869657993, "actor_loss": -79.17999432373047, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 557.805490732193, "episode_reward": 899.0592203188332, "step": 76000}
{"episode": 77.0, "batch_reward": 0.7799852209687232, "critic_loss": 0.6201388990283012, "actor_loss": -79.36456623840333, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 28.865760326385498, "episode_reward": 955.923779853698, "step": 77000}
{"episode": 78.0, "batch_reward": 0.7823090642690659, "critic_loss": 0.6044219219684601, "actor_loss": -79.67495863342285, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 589.3425602912903, "episode_reward": 916.4727422546719, "step": 78000}
{"episode": 79.0, "batch_reward": 0.783746549487114, "critic_loss": 0.5914336394965649, "actor_loss": -79.93299992370605, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 31.462048053741455, "episode_reward": 838.0135404737432, "step": 79000}
{"episode": 80.0, "batch_reward": 0.7830424513816834, "critic_loss": 0.5872430410385132, "actor_loss": -80.01325244140625, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 566.6890196800232, "episode_reward": 827.409208130887, "step": 80000}
{"episode": 81.0, "batch_reward": 0.7858825634121895, "critic_loss": 0.5955754199922085, "actor_loss": -80.25954382324218, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 56.308911085128784, "episode_reward": 877.5324035987026, "step": 81000}
{"episode": 82.0, "batch_reward": 0.7861472702026367, "critic_loss": 0.5920272999256849, "actor_loss": -80.56336283874512, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 587.8349406719208, "episode_reward": 893.8483710798124, "step": 82000}
{"episode": 83.0, "batch_reward": 0.7876742287874222, "critic_loss": 0.5769790117442608, "actor_loss": -80.68360459899903, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 28.401857376098633, "episode_reward": 890.9677552003227, "step": 83000}
{"episode": 84.0, "batch_reward": 0.7888710534572602, "critic_loss": 0.5342952871620655, "actor_loss": -80.8506509552002, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 542.5703737735748, "episode_reward": 835.8365725739089, "step": 84000}
{"episode": 85.0, "batch_reward": 0.789052285850048, "critic_loss": 0.5430817796289921, "actor_loss": -80.98155293273926, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 27.67899513244629, "episode_reward": 891.2260085425285, "step": 85000}
{"episode": 86.0, "batch_reward": 0.791076924443245, "critic_loss": 0.5317600247114896, "actor_loss": -81.3353377685547, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 546.0942575931549, "episode_reward": 893.5114609751683, "step": 86000}
{"episode": 87.0, "batch_reward": 0.79228735435009, "critic_loss": 0.5061057287752628, "actor_loss": -81.60438815307617, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 27.99337363243103, "episode_reward": 909.127419496107, "step": 87000}
{"episode": 88.0, "batch_reward": 0.7951063074469567, "critic_loss": 0.5196702040731906, "actor_loss": -81.81204066467285, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 532.0531797409058, "episode_reward": 936.2179099372488, "step": 88000}
{"episode": 89.0, "batch_reward": 0.7961134064793587, "critic_loss": 0.5089592385739088, "actor_loss": -82.00229243469238, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.51486301422119, "episode_reward": 922.8138844095513, "step": 89000}
{"episode": 90.0, "batch_reward": 0.7967262697219849, "critic_loss": 0.4980086633116007, "actor_loss": -82.11132113647461, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 494.9878034591675, "episode_reward": 890.3605310647118, "step": 90000}
{"episode": 91.0, "batch_reward": 0.7977674332857132, "critic_loss": 0.5035289962142706, "actor_loss": -82.29823040771484, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 47.84978914260864, "episode_reward": 909.7535227560791, "step": 91000}
{"episode": 92.0, "batch_reward": 0.7996042218804359, "critic_loss": 0.481887565895915, "actor_loss": -82.46217666625977, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 485.19505977630615, "episode_reward": 938.3187190098229, "step": 92000}
{"episode": 93.0, "batch_reward": 0.7993892738223076, "critic_loss": 0.48260009463131426, "actor_loss": -82.58682220458985, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.491296768188477, "episode_reward": 954.3144209243083, "step": 93000}
{"episode": 94.0, "batch_reward": 0.8026782898306847, "critic_loss": 0.45904035595059395, "actor_loss": -82.95738038635254, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 492.94086050987244, "episode_reward": 906.3398737732512, "step": 94000}
{"episode": 95.0, "batch_reward": 0.8038951874375343, "critic_loss": 0.4771009854078293, "actor_loss": -83.10528883361816, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.777610540390015, "episode_reward": 913.7887917632271, "step": 95000}
{"episode": 96.0, "batch_reward": 0.8037910617589951, "critic_loss": 0.49031384533643724, "actor_loss": -83.32042607116699, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 493.70903968811035, "episode_reward": 913.7368700071391, "step": 96000}
{"episode": 97.0, "batch_reward": 0.8069273161292077, "critic_loss": 0.43398026879131796, "actor_loss": -83.6267774810791, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.701364517211914, "episode_reward": 941.8651814270831, "step": 97000}
{"episode": 98.0, "batch_reward": 0.8057022635936737, "critic_loss": 0.43322086964547635, "actor_loss": -83.79387480163574, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 494.54330611228943, "episode_reward": 943.3291757556432, "step": 98000}
{"episode": 99.0, "batch_reward": 0.8090421185493469, "critic_loss": 0.44023277765512464, "actor_loss": -84.12943089294434, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.633410453796387, "episode_reward": 926.0403252638927, "step": 99000}
{"episode": 100.0, "batch_reward": 0.8101090435385704, "critic_loss": 0.4341430933624506, "actor_loss": -84.35665211486817, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 493.18824911117554, "episode_reward": 959.2383478739997, "step": 100000}
{"episode": 101.0, "batch_reward": 0.8130092694163322, "critic_loss": 0.4571862297058105, "actor_loss": -84.61005502319335, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 47.66035437583923, "episode_reward": 969.8929697193258, "step": 101000}
{"episode": 102.0, "batch_reward": 0.8116524978876114, "critic_loss": 0.4423023020774126, "actor_loss": -84.75172109985351, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 493.1876769065857, "episode_reward": 949.1274014422532, "step": 102000}
{"episode": 103.0, "batch_reward": 0.8136176685094834, "critic_loss": 0.4162026464343071, "actor_loss": -85.05614421081543, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.837233543395996, "episode_reward": 928.5921921996447, "step": 103000}
{"episode": 104.0, "batch_reward": 0.8154852201342583, "critic_loss": 0.4307196448296309, "actor_loss": -85.34990353393555, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 493.68628430366516, "episode_reward": 951.4024048241192, "step": 104000}
{"episode": 105.0, "batch_reward": 0.8170729415416718, "critic_loss": 0.42588309246301653, "actor_loss": -85.54041912841797, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.60279655456543, "episode_reward": 941.5261247132876, "step": 105000}
{"episode": 106.0, "batch_reward": 0.8179291995763779, "critic_loss": 0.41719336208701135, "actor_loss": -85.89342488098144, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 494.6244103908539, "episode_reward": 909.2727981906157, "step": 106000}
{"episode": 107.0, "batch_reward": 0.8165851214528084, "critic_loss": 0.4079663247466087, "actor_loss": -86.02768840026856, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.763638257980347, "episode_reward": 933.4776023386979, "step": 107000}
{"episode": 108.0, "batch_reward": 0.8202773561477661, "critic_loss": 0.41276350276172163, "actor_loss": -86.28013082885742, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 493.7226960659027, "episode_reward": 919.6313766852163, "step": 108000}
{"episode": 109.0, "batch_reward": 0.8208557515740394, "critic_loss": 0.39941667783260343, "actor_loss": -86.42699899291992, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.669273853302002, "episode_reward": 923.5558888930722, "step": 109000}
{"episode": 110.0, "batch_reward": 0.8207526494264603, "critic_loss": 0.40342762719094755, "actor_loss": -86.65627781677246, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 494.17247319221497, "episode_reward": 923.0852267940923, "step": 110000}
{"episode": 111.0, "batch_reward": 0.8217052763700485, "critic_loss": 0.39135024209320546, "actor_loss": -86.76025263977051, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 47.76255822181702, "episode_reward": 916.3983892956246, "step": 111000}
{"episode": 112.0, "batch_reward": 0.8215054302811623, "critic_loss": 0.39674085430800915, "actor_loss": -86.9752430114746, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 494.9159939289093, "episode_reward": 940.9150207061406, "step": 112000}
{"episode": 113.0, "batch_reward": 0.8242973218560219, "critic_loss": 0.3983505385518074, "actor_loss": -87.15764541625977, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.732013940811157, "episode_reward": 935.9258590477107, "step": 113000}
{"episode": 114.0, "batch_reward": 0.8249730132222176, "critic_loss": 0.4044262787997723, "actor_loss": -87.31450398254394, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 494.9387958049774, "episode_reward": 958.4354438382813, "step": 114000}
{"episode": 115.0, "batch_reward": 0.8248869696259499, "critic_loss": 0.42261894191801547, "actor_loss": -87.49802661132813, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.446099996566772, "episode_reward": 944.6253004117599, "step": 115000}
{"episode": 116.0, "batch_reward": 0.8278929907083511, "critic_loss": 0.4524639595299959, "actor_loss": -87.67743682861328, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 493.90091466903687, "episode_reward": 935.6905349093354, "step": 116000}
{"episode": 117.0, "batch_reward": 0.828229743719101, "critic_loss": 0.528772896528244, "actor_loss": -87.8804998626709, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.47864031791687, "episode_reward": 943.0837311475725, "step": 117000}
{"episode": 118.0, "batch_reward": 0.8285717544555664, "critic_loss": 0.6579847907871008, "actor_loss": -88.10831407165527, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 493.7780730724335, "episode_reward": 958.1838910863647, "step": 118000}
{"episode": 119.0, "batch_reward": 0.8267686720490456, "critic_loss": 1.0872625838071108, "actor_loss": -88.43955117797852, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.521522521972656, "episode_reward": 49.27736407065832, "step": 119000}
{"episode": 120.0, "batch_reward": 0.8197105051875114, "critic_loss": 1.7107933164834976, "actor_loss": -89.15973213195801, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 494.3136463165283, "episode_reward": 46.88562353914136, "step": 120000}
{"episode": 121.0, "batch_reward": 0.8139957289099693, "critic_loss": 2.4511882475018503, "actor_loss": -91.01557971191406, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 47.83273243904114, "episode_reward": 72.16346831695654, "step": 121000}
{"episode": 122.0, "batch_reward": 0.8070367107987404, "critic_loss": 3.9648771586418152, "actor_loss": -98.29362733459473, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 493.7611622810364, "episode_reward": 67.49719677026289, "step": 122000}
{"episode": 123.0, "batch_reward": 0.8011148822307587, "critic_loss": 4.415891232967376, "actor_loss": -107.16389364624024, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.514007091522217, "episode_reward": 226.99614759716863, "step": 123000}
{"episode": 124.0, "batch_reward": 0.797849662065506, "critic_loss": 3.500894249200821, "actor_loss": -111.93097077941894, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 493.74794006347656, "episode_reward": 337.56490322670396, "step": 124000}
{"episode": 125.0, "batch_reward": 0.7958794273734092, "critic_loss": 2.9802004907131194, "actor_loss": -113.76617706298828, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.52718472480774, "episode_reward": 610.0333237149963, "step": 125000}
{"episode": 126.0, "batch_reward": 0.7937041265964508, "critic_loss": 2.7230094774961473, "actor_loss": -113.86275422668457, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 493.1646647453308, "episode_reward": 703.4042777266981, "step": 126000}
{"episode": 127.0, "batch_reward": 0.7920367218255997, "critic_loss": 2.306343568086624, "actor_loss": -113.50706025695801, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.528971195220947, "episode_reward": 533.2861594595463, "step": 127000}
{"episode": 128.0, "batch_reward": 0.7906966664195061, "critic_loss": 1.8441230351924895, "actor_loss": -112.93337322998048, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 493.2756612300873, "episode_reward": 744.5167072715961, "step": 128000}
{"episode": 129.0, "batch_reward": 0.7919575979113579, "critic_loss": 1.6540904617905616, "actor_loss": -112.30329495239258, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.575946807861328, "episode_reward": 781.246257464279, "step": 129000}
{"episode": 130.0, "batch_reward": 0.7899560878276825, "critic_loss": 1.4104747169017793, "actor_loss": -111.49334254455566, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 493.1916677951813, "episode_reward": 816.0511995471026, "step": 130000}
{"episode": 131.0, "batch_reward": 0.7918068743944168, "critic_loss": 1.2656314019560815, "actor_loss": -110.83961517333984, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 47.66336631774902, "episode_reward": 795.3869603809309, "step": 131000}
{"episode": 132.0, "batch_reward": 0.7933190774321556, "critic_loss": 1.2002166433036328, "actor_loss": -110.26202049255372, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 493.695515871048, "episode_reward": 896.7602398175472, "step": 132000}
{"episode": 133.0, "batch_reward": 0.7937033354043961, "critic_loss": 1.0659525555372238, "actor_loss": -109.6218119506836, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.680001258850098, "episode_reward": 926.7145566766782, "step": 133000}
{"episode": 134.0, "batch_reward": 0.7941933283209801, "critic_loss": 0.9260659936070442, "actor_loss": -108.94663342285156, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 494.16949486732483, "episode_reward": 888.1421772695187, "step": 134000}
{"episode": 135.0, "batch_reward": 0.7939934512972832, "critic_loss": 0.8549320877790451, "actor_loss": -108.27533879089356, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.603365421295166, "episode_reward": 920.661000170494, "step": 135000}
{"episode": 136.0, "batch_reward": 0.7959051796793938, "critic_loss": 0.7404058322012425, "actor_loss": -107.7233009185791, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 494.54466438293457, "episode_reward": 898.557028538136, "step": 136000}
{"episode": 137.0, "batch_reward": 0.7979262915849685, "critic_loss": 0.7345279849469661, "actor_loss": -107.09095756530762, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.504892110824585, "episode_reward": 950.8140674345992, "step": 137000}
{"episode": 138.0, "batch_reward": 0.7962993813157082, "critic_loss": 0.6876903050243854, "actor_loss": -106.5589677734375, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 494.1849455833435, "episode_reward": 950.9640329009792, "step": 138000}
{"episode": 139.0, "batch_reward": 0.7993956850171089, "critic_loss": 0.6867656174004078, "actor_loss": -106.08028523254394, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.567566871643066, "episode_reward": 930.4178488946983, "step": 139000}
{"episode": 140.0, "batch_reward": 0.7992697207331657, "critic_loss": 0.6507587187886238, "actor_loss": -105.59746813964844, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 494.93258476257324, "episode_reward": 937.975937248503, "step": 140000}
{"episode": 141.0, "batch_reward": 0.7992840824127198, "critic_loss": 0.6495408908128738, "actor_loss": -105.05595011901856, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 47.4617486000061, "episode_reward": 846.9583238639161, "step": 141000}
{"episode": 142.0, "batch_reward": 0.800480376124382, "critic_loss": 0.6192073668539524, "actor_loss": -104.62977076721191, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 484.7414586544037, "episode_reward": 886.0196761271129, "step": 142000}
{"episode": 143.0, "batch_reward": 0.8006128115057946, "critic_loss": 0.6293323543965816, "actor_loss": -104.20577041625977, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.7449312210083, "episode_reward": 662.9191176129252, "step": 143000}
{"episode": 144.0, "batch_reward": 0.7995134381055832, "critic_loss": 0.7149298659265041, "actor_loss": -103.86775302124023, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 493.09184551239014, "episode_reward": 618.8517347159485, "step": 144000}
{"episode": 145.0, "batch_reward": 0.7967653646469116, "critic_loss": 0.8023016046285629, "actor_loss": -103.64645594787598, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.659321069717407, "episode_reward": 111.68841115594066, "step": 145000}
{"episode": 146.0, "batch_reward": 0.7924190621972084, "critic_loss": 0.8632778740227223, "actor_loss": -103.34283848571778, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 493.723210811615, "episode_reward": 505.2990738679772, "step": 146000}
{"episode": 147.0, "batch_reward": 0.7912887763381005, "critic_loss": 0.8820024728477002, "actor_loss": -103.16218556213379, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.73993444442749, "episode_reward": 91.64570999083709, "step": 147000}
{"episode": 148.0, "batch_reward": 0.7851821405291557, "critic_loss": 0.8503691466748714, "actor_loss": -102.66878221130371, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 493.9222321510315, "episode_reward": 760.4909961156385, "step": 148000}
{"episode": 149.0, "batch_reward": 0.7882117727994918, "critic_loss": 0.7843957163691521, "actor_loss": -102.41157392883301, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 26.66279625892639, "episode_reward": 748.6357417785854, "step": 149000}
{"episode": 150.0, "batch_reward": 0.7875686832070351, "critic_loss": 0.7087355788052082, "actor_loss": -102.0842092590332, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "step": 150000}
