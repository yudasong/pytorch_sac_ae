{"episode_reward": 0.0, "episode": 1.0, "duration": 22.334022283554077, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.9375197887420654, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.43497698112860167, "critic_loss": 0.06295695472039747, "actor_loss": -36.22627739212355, "actor_target_entropy": -6.0, "alpha_value": 0.002642586817083679, "duration": 63.03020620346069, "step": 3000}
{"episode_reward": 3.9733894895983295, "episode": 4.0, "batch_reward": 0.2713303233832121, "critic_loss": 0.17592532384395598, "actor_loss": -33.18795484828949, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.31799054145813, "step": 4000}
{"episode_reward": 15.758634444073172, "episode": 5.0, "batch_reward": 0.21422282147407531, "critic_loss": 0.19181791745871304, "actor_loss": -34.8265845413208, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.18802499771118, "step": 5000}
{"episode_reward": 12.25849089027079, "episode": 6.0, "batch_reward": 0.17876014798879625, "critic_loss": 0.15272259917668998, "actor_loss": -32.618637597084046, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.52367353439331, "step": 6000}
{"episode_reward": 27.4714166863307, "episode": 7.0, "batch_reward": 0.15723036740720273, "critic_loss": 0.3205209226049483, "actor_loss": -33.037711345672605, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.360920190811157, "step": 7000}
{"episode_reward": 52.49696912380866, "episode": 8.0, "batch_reward": 0.143520893342793, "critic_loss": 0.4167408385649323, "actor_loss": -34.260723923683166, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.913297414779663, "step": 8000}
{"episode_reward": 68.73297063965094, "episode": 9.0, "batch_reward": 0.1351542510986328, "critic_loss": 0.7781479372978211, "actor_loss": -36.02261009407044, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.486074924468994, "step": 9000}
{"episode_reward": 81.90264389666854, "episode": 10.0, "batch_reward": 0.133351363517344, "critic_loss": 0.8026337256580591, "actor_loss": -36.13954894542694, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.83772563934326, "step": 10000}
{"episode_reward": 159.57433811149318, "episode": 11.0, "batch_reward": 0.13197442489862443, "critic_loss": 1.7359218269288539, "actor_loss": -34.74964137649536, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.09009313583374, "step": 11000}
{"episode_reward": 55.079819296435694, "episode": 12.0, "batch_reward": 0.12474055027961731, "critic_loss": 1.954319255590439, "actor_loss": -39.33659743309021, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.370258331298828, "step": 12000}
{"episode_reward": 43.61380422768634, "episode": 13.0, "batch_reward": 0.11997841840237379, "critic_loss": 3.1594857668876646, "actor_loss": -41.2701192817688, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.346779584884644, "step": 13000}
{"episode_reward": 73.69381080821796, "episode": 14.0, "batch_reward": 0.11547586503624917, "critic_loss": 4.316512499570846, "actor_loss": -47.526363227844236, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.32801389694214, "step": 14000}
{"episode_reward": 87.20859486653849, "episode": 15.0, "batch_reward": 0.1197494656741619, "critic_loss": 6.684851426124573, "actor_loss": -52.19071982955933, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.359757900238037, "step": 15000}
{"episode_reward": 190.98264745914483, "episode": 16.0, "batch_reward": 0.12385084579139947, "critic_loss": 7.81949715924263, "actor_loss": -61.4211800994873, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.631999731063843, "step": 16000}
{"episode_reward": 214.87981129054643, "episode": 17.0, "batch_reward": 0.12764808573573827, "critic_loss": 8.7562310860157, "actor_loss": -65.92980828857422, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.336832284927368, "step": 17000}
{"episode_reward": 183.08513106067386, "episode": 18.0, "batch_reward": 0.13392561089247465, "critic_loss": 9.487304534435273, "actor_loss": -69.30436037445068, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.512385606765747, "step": 18000}
{"episode_reward": 309.8105850219302, "episode": 19.0, "batch_reward": 0.14074495234340428, "critic_loss": 10.31611590051651, "actor_loss": -71.86737730407715, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.22801637649536, "step": 19000}
{"episode_reward": 139.34447366448507, "episode": 20.0, "batch_reward": 0.14069399485737086, "critic_loss": 9.923524846076965, "actor_loss": -73.91336207580567, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.363229274749756, "step": 20000}
{"episode_reward": 130.1528670970863, "episode": 21.0, "batch_reward": 0.13639697378873825, "critic_loss": 9.50404961848259, "actor_loss": -75.6250068206787, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.363574743270874, "step": 21000}
{"episode_reward": 66.11188055188266, "episode": 22.0, "batch_reward": 0.13921560802310706, "critic_loss": 14.086557657718659, "actor_loss": -77.86822285461426, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.70605707168579, "step": 22000}
{"episode_reward": 197.78210919992196, "episode": 23.0, "batch_reward": 0.13633829836547376, "critic_loss": 12.36154496717453, "actor_loss": -80.90785566711426, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.32541823387146, "step": 23000}
{"episode_reward": 71.32000495284464, "episode": 24.0, "batch_reward": 0.1357636645436287, "critic_loss": 13.614032272338868, "actor_loss": -84.64155807495118, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.411307096481323, "step": 24000}
{"episode_reward": 168.84230638592754, "episode": 25.0, "batch_reward": 0.13662509583681823, "critic_loss": 17.059862274169923, "actor_loss": -88.04852722167969, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.316094398498535, "step": 25000}
{"episode_reward": 87.44278026040494, "episode": 26.0, "batch_reward": 0.13582503499090673, "critic_loss": 15.544150082588196, "actor_loss": -90.98535919189453, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.12544012069702, "step": 26000}
{"episode_reward": 143.2651712506654, "episode": 27.0, "batch_reward": 0.1339578630849719, "critic_loss": 16.25823997402191, "actor_loss": -96.95083493041992, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.78225564956665, "step": 27000}
{"episode_reward": 49.06477640864537, "episode": 28.0, "batch_reward": 0.12967109804600477, "critic_loss": 15.145970343112946, "actor_loss": -98.96685804748535, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.84065866470337, "step": 28000}
{"episode_reward": 59.796643474330494, "episode": 29.0, "batch_reward": 0.12723076924681664, "critic_loss": 14.720466752529145, "actor_loss": -104.09079273986816, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.080193281173706, "step": 29000}
{"episode_reward": 38.284833722630005, "episode": 30.0, "batch_reward": 0.1271617252752185, "critic_loss": 13.80830826663971, "actor_loss": -105.50764065551758, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.188520908355713, "step": 30000}
{"episode_reward": 117.33799765955507, "episode": 31.0, "batch_reward": 0.12577245534211398, "critic_loss": 13.922412093162537, "actor_loss": -105.00483609008789, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.98346400260925, "step": 31000}
{"episode_reward": 202.75823563324383, "episode": 32.0, "batch_reward": 0.12809043590724467, "critic_loss": 14.241517894744874, "actor_loss": -108.9141625213623, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.711265325546265, "step": 32000}
{"episode_reward": 74.17966439661078, "episode": 33.0, "batch_reward": 0.1257097670957446, "critic_loss": 12.819915408134461, "actor_loss": -112.627648147583, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.25142741203308, "step": 33000}
{"episode_reward": 78.24441101933458, "episode": 34.0, "batch_reward": 0.12586493634432555, "critic_loss": 14.245631620407105, "actor_loss": -109.4776173248291, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.40131950378418, "step": 34000}
{"episode_reward": 131.49980429354406, "episode": 35.0, "batch_reward": 0.1262101718708873, "critic_loss": 15.00270294380188, "actor_loss": -110.86503187561036, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.48738956451416, "step": 35000}
{"episode_reward": 99.61057067736094, "episode": 36.0, "batch_reward": 0.12394891101121902, "critic_loss": 15.396981513023377, "actor_loss": -114.39432113647462, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.69865083694458, "step": 36000}
{"episode_reward": 45.51852635933755, "episode": 37.0, "batch_reward": 0.1220158050507307, "critic_loss": 18.767314712524414, "actor_loss": -117.56778155517578, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.040205478668213, "step": 37000}
{"episode_reward": 80.05011416853321, "episode": 38.0, "batch_reward": 0.12073955682665109, "critic_loss": 16.313734322547912, "actor_loss": -124.10260189819336, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.365119457244873, "step": 38000}
{"episode_reward": 80.21399783180769, "episode": 39.0, "batch_reward": 0.12125431447476148, "critic_loss": 15.596501299858094, "actor_loss": -125.33322489929199, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.884454250335693, "step": 39000}
{"episode_reward": 123.48504858645872, "episode": 40.0, "batch_reward": 0.11914694003015756, "critic_loss": 15.473421217918396, "actor_loss": -124.65813792419434, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.918666124343872, "step": 40000}
{"episode_reward": 165.8832461204982, "episode": 41.0, "batch_reward": 0.12163618541508912, "critic_loss": 16.14453986930847, "actor_loss": -125.04610803222656, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.88601303100586, "step": 41000}
{"episode_reward": 98.00632864852794, "episode": 42.0, "batch_reward": 0.12054430662095547, "critic_loss": 17.611694209098815, "actor_loss": -131.4028794555664, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.355647087097168, "step": 42000}
{"episode_reward": 87.08642323181769, "episode": 43.0, "batch_reward": 0.11987487570941448, "critic_loss": 18.81204448413849, "actor_loss": -134.87866780090332, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.628358602523804, "step": 43000}
{"episode_reward": 87.70931078786852, "episode": 44.0, "batch_reward": 0.11756762067973614, "critic_loss": 19.696506553649904, "actor_loss": -140.1792046661377, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.836892127990723, "step": 44000}
{"episode_reward": 75.2733857664438, "episode": 45.0, "batch_reward": 0.1175192718282342, "critic_loss": 20.348047691345215, "actor_loss": -146.87258294677736, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.632498025894165, "step": 45000}
{"episode_reward": 47.432625064564625, "episode": 46.0, "batch_reward": 0.11650085358321667, "critic_loss": 21.371688613891603, "actor_loss": -146.81726664733887, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.888720273971558, "step": 46000}
{"episode_reward": 53.435168514852435, "episode": 47.0, "batch_reward": 0.1162061262279749, "critic_loss": 19.956386148452758, "actor_loss": -144.99308711242676, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.37995481491089, "step": 47000}
{"episode_reward": 84.61724814638376, "episode": 48.0, "batch_reward": 0.11457392324507236, "critic_loss": 19.630388538360595, "actor_loss": -152.0967488861084, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.229251623153687, "step": 48000}
{"episode_reward": 86.27677853518162, "episode": 49.0, "batch_reward": 0.11444713949412108, "critic_loss": 18.595608533859252, "actor_loss": -152.6710796813965, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.54271411895752, "step": 49000}
{"episode_reward": 85.1667956296623, "episode": 50.0, "batch_reward": 0.11293020364642144, "critic_loss": 17.974986473083497, "actor_loss": -150.06747784423828, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.308954000473022, "step": 50000}
{"episode_reward": 43.63587623028139, "episode": 51.0, "batch_reward": 0.11169820351153611, "critic_loss": 15.350347562313079, "actor_loss": -159.23774169921876, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.42898464202881, "step": 51000}
{"episode_reward": 45.82445981017218, "episode": 52.0, "batch_reward": 0.11109888362884522, "critic_loss": 14.170283374786377, "actor_loss": -147.29678218078612, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.440139532089233, "step": 52000}
{"episode_reward": 59.50990708939764, "episode": 53.0, "batch_reward": 0.10919419111311436, "critic_loss": 15.009041552066803, "actor_loss": -157.62688011169433, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.81985330581665, "step": 53000}
{"episode_reward": 80.20996514773454, "episode": 54.0, "batch_reward": 0.10995357032865286, "critic_loss": 17.01402169036865, "actor_loss": -151.21723059082032, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.10330104827881, "step": 54000}
{"episode_reward": 220.73487402236924, "episode": 55.0, "batch_reward": 0.11212555987387895, "critic_loss": 20.43009976005554, "actor_loss": -155.7464629058838, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.339621782302856, "step": 55000}
{"episode_reward": 290.3957440961514, "episode": 56.0, "batch_reward": 0.11398524532467127, "critic_loss": 27.985830739974976, "actor_loss": -165.82187280273436, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.80821394920349, "step": 56000}
{"episode_reward": 25.125381920173226, "episode": 57.0, "batch_reward": 0.11254946666955948, "critic_loss": 27.618487840652467, "actor_loss": -166.02866139221192, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.85213541984558, "step": 57000}
{"episode_reward": 60.8300022177756, "episode": 58.0, "batch_reward": 0.11189711634069681, "critic_loss": 34.68419334411621, "actor_loss": -175.01880854797363, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.820467948913574, "step": 58000}
{"episode_reward": 82.12721341769326, "episode": 59.0, "batch_reward": 0.11080152832716704, "critic_loss": 50.00637237548828, "actor_loss": -174.08819635009766, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.61454153060913, "step": 59000}
{"episode_reward": 102.02399521596284, "episode": 60.0, "batch_reward": 0.11124391277879477, "critic_loss": 64.85817148780822, "actor_loss": -179.37363679504395, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.702657461166382, "step": 60000}
{"episode_reward": 71.65730552015845, "episode": 61.0, "batch_reward": 0.11115608316659928, "critic_loss": 65.43014284515381, "actor_loss": -196.15787492370606, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.959142446517944, "step": 61000}
{"episode_reward": 112.93443207109445, "episode": 62.0, "batch_reward": 0.1106920902878046, "critic_loss": 68.85392936897277, "actor_loss": -215.5310910949707, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.35341477394104, "step": 62000}
{"episode_reward": 164.71524374300296, "episode": 63.0, "batch_reward": 0.11136885729432106, "critic_loss": 63.83027605628967, "actor_loss": -223.89293280029298, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.800349235534668, "step": 63000}
{"episode_reward": 88.20758974316719, "episode": 64.0, "batch_reward": 0.11121721179038287, "critic_loss": 62.171747911453245, "actor_loss": -222.4371706237793, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.61150574684143, "step": 64000}
{"episode_reward": 98.39144295412905, "episode": 65.0, "batch_reward": 0.11095009347051382, "critic_loss": 57.37622741317749, "actor_loss": -229.63887042236328, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.42864441871643, "step": 65000}
{"episode_reward": 87.60319913150946, "episode": 66.0, "batch_reward": 0.11064181712269783, "critic_loss": 49.309465463638304, "actor_loss": -239.41451663208008, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.80412220954895, "step": 66000}
{"episode_reward": 103.93861867311762, "episode": 67.0, "batch_reward": 0.10949308421462774, "critic_loss": 41.938258195877076, "actor_loss": -237.2325762939453, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.540528535842896, "step": 67000}
{"episode_reward": 26.27018710231049, "episode": 68.0, "batch_reward": 0.10919684850424528, "critic_loss": 34.86499341773987, "actor_loss": -231.1231531677246, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.34194040298462, "step": 68000}
{"episode_reward": 41.414246525050764, "episode": 69.0, "batch_reward": 0.1084213851839304, "critic_loss": 30.03293929004669, "actor_loss": -234.16919091796876, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.25112247467041, "step": 69000}
{"episode_reward": 79.41358695247801, "episode": 70.0, "batch_reward": 0.10767574656009674, "critic_loss": 26.39155532360077, "actor_loss": -222.34895303344726, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.629026651382446, "step": 70000}
{"episode_reward": 64.0601668027007, "episode": 71.0, "batch_reward": 0.10704027758538723, "critic_loss": 23.002797300338745, "actor_loss": -222.1613338623047, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.8053662776947, "step": 71000}
{"episode_reward": 37.05548692873461, "episode": 72.0, "batch_reward": 0.10539191458374261, "critic_loss": 20.903369904518126, "actor_loss": -223.01414096069337, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.140811920166016, "step": 72000}
{"episode_reward": 26.897991242101426, "episode": 73.0, "batch_reward": 0.10513456397503615, "critic_loss": 18.34334241294861, "actor_loss": -219.46791227722167, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.33607292175293, "step": 73000}
{"episode_reward": 42.222508054479334, "episode": 74.0, "batch_reward": 0.10420754516869783, "critic_loss": 15.84869216299057, "actor_loss": -207.38082843017577, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.797101259231567, "step": 74000}
{"episode_reward": 36.05000902847202, "episode": 75.0, "batch_reward": 0.10388573148846626, "critic_loss": 14.71764334154129, "actor_loss": -205.6707366027832, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.410470962524414, "step": 75000}
{"episode_reward": 83.46349338535765, "episode": 76.0, "batch_reward": 0.10224816908687354, "critic_loss": 13.066821999549866, "actor_loss": -194.3310433959961, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.488982439041138, "step": 76000}
{"episode_reward": 24.453248342550477, "episode": 77.0, "batch_reward": 0.10143803521990775, "critic_loss": 11.599208158493042, "actor_loss": -201.4044676361084, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.8261296749115, "step": 77000}
{"episode_reward": 120.13701748165657, "episode": 78.0, "batch_reward": 0.10250877649337053, "critic_loss": 9.97590768957138, "actor_loss": -194.26967373657226, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.648686170578003, "step": 78000}
{"episode_reward": 223.94297868312233, "episode": 79.0, "batch_reward": 0.10489511456340551, "critic_loss": 8.971800070762635, "actor_loss": -192.15612762451173, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.41497015953064, "step": 79000}
{"episode_reward": 296.0753509068981, "episode": 80.0, "batch_reward": 0.10630853086709977, "critic_loss": 7.330503576517105, "actor_loss": -181.92197116088866, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.71397614479065, "step": 80000}
{"episode_reward": 62.242580425692566, "episode": 81.0, "batch_reward": 0.10719949861615896, "critic_loss": 6.4502231583595275, "actor_loss": -181.7129420928955, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.242103099823, "step": 81000}
{"episode_reward": 264.87476844503595, "episode": 82.0, "batch_reward": 0.1087293125912547, "critic_loss": 5.67073250579834, "actor_loss": -177.19174157714843, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.18424367904663, "step": 82000}
{"episode_reward": 310.7443589998268, "episode": 83.0, "batch_reward": 0.11027013139426708, "critic_loss": 5.330850382566452, "actor_loss": -166.2784837036133, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.3357412815094, "step": 83000}
{"episode_reward": 305.4961174213041, "episode": 84.0, "batch_reward": 0.11314594327658414, "critic_loss": 5.267411077022553, "actor_loss": -161.0201271209717, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.237532138824463, "step": 84000}
{"episode_reward": 311.1114378360874, "episode": 85.0, "batch_reward": 0.11465408366173506, "critic_loss": 4.508830974698067, "actor_loss": -163.7747839050293, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.11455726623535, "step": 85000}
{"episode_reward": 35.325637461174175, "episode": 86.0, "batch_reward": 0.11570608130097389, "critic_loss": 4.285386481285095, "actor_loss": -154.89961248779298, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.36622643470764, "step": 86000}
{"episode_reward": 397.0659044123018, "episode": 87.0, "batch_reward": 0.11818478391319513, "critic_loss": 3.9332873586416244, "actor_loss": -149.5497989501953, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.884331941604614, "step": 87000}
{"episode_reward": 34.77647696420765, "episode": 88.0, "batch_reward": 0.11744452026486397, "critic_loss": 3.772602511763573, "actor_loss": -144.79151400756837, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.565001726150513, "step": 88000}
{"episode_reward": 193.87814991077977, "episode": 89.0, "batch_reward": 0.11852209009975195, "critic_loss": 3.5794141496419907, "actor_loss": -143.2076410217285, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.87321639060974, "step": 89000}
{"episode_reward": 340.87773111283957, "episode": 90.0, "batch_reward": 0.12060741495341062, "critic_loss": 3.1949527766704557, "actor_loss": -138.6883189086914, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.780755519866943, "step": 90000}
{"episode_reward": 501.62902618214514, "episode": 91.0, "batch_reward": 0.12418018365651369, "critic_loss": 2.9399446028470995, "actor_loss": -134.92909323120116, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.284193992614746, "step": 91000}
{"episode_reward": 125.40519553431164, "episode": 92.0, "batch_reward": 0.12601792073249818, "critic_loss": 2.8506832159757614, "actor_loss": -130.19562649536132, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.643792152404785, "step": 92000}
{"episode_reward": 282.0716458428117, "episode": 93.0, "batch_reward": 0.1268888241574168, "critic_loss": 2.742011855959892, "actor_loss": -127.11333818054199, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.564945936203003, "step": 93000}
{"episode_reward": 262.22559522879203, "episode": 94.0, "batch_reward": 0.12822114524245262, "critic_loss": 2.600755067229271, "actor_loss": -123.19127522277832, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.575523138046265, "step": 94000}
{"episode_reward": 179.7711343042748, "episode": 95.0, "batch_reward": 0.12772801918536425, "critic_loss": 2.588542905330658, "actor_loss": -121.32421380615234, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.55486512184143, "step": 95000}
{"episode_reward": 126.95326172583728, "episode": 96.0, "batch_reward": 0.1282448434829712, "critic_loss": 2.437820230960846, "actor_loss": -115.763668258667, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.54965114593506, "step": 96000}
{"episode_reward": 143.87206767917996, "episode": 97.0, "batch_reward": 0.12858702439069747, "critic_loss": 2.4354943375587466, "actor_loss": -115.65809796142578, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.506898880004883, "step": 97000}
{"episode_reward": 169.9544405562008, "episode": 98.0, "batch_reward": 0.1276548429504037, "critic_loss": 2.446586243510246, "actor_loss": -114.1891743927002, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.183972597122192, "step": 98000}
{"episode_reward": 134.959639217625, "episode": 99.0, "batch_reward": 0.12958614212274552, "critic_loss": 2.5926290192604067, "actor_loss": -108.46534866333008, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.830817699432373, "step": 99000}
{"episode_reward": 129.22303781619505, "episode": 100.0, "batch_reward": 0.12967461907863617, "critic_loss": 2.6667742158174517, "actor_loss": -107.66945469665528, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.633341312408447, "step": 100000}
{"episode_reward": 288.81597201343567, "episode": 101.0, "batch_reward": 0.12989558386057615, "critic_loss": 2.8445850406885147, "actor_loss": -105.49972988891602, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.260239124298096, "step": 101000}
{"episode_reward": 92.11874500077467, "episode": 102.0, "batch_reward": 0.12995820554345847, "critic_loss": 2.725403990983963, "actor_loss": -104.63565934753419, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.248419284820557, "step": 102000}
{"episode_reward": 121.58177292458487, "episode": 103.0, "batch_reward": 0.13029938458651305, "critic_loss": 2.910762013673782, "actor_loss": -103.66651792907714, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.32570457458496, "step": 103000}
{"episode_reward": 176.0664367450513, "episode": 104.0, "batch_reward": 0.13212479487061501, "critic_loss": 2.771746454000473, "actor_loss": -101.48274153137207, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.7544367313385, "step": 104000}
{"episode_reward": 311.1103114872682, "episode": 105.0, "batch_reward": 0.13338495689630508, "critic_loss": 2.6296958535909654, "actor_loss": -100.32227740478515, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.538865089416504, "step": 105000}
{"episode_reward": 377.9157404411884, "episode": 106.0, "batch_reward": 0.1367711790651083, "critic_loss": 2.5830416036844253, "actor_loss": -99.21862164306641, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.55943775177002, "step": 106000}
{"episode_reward": 480.4889960550159, "episode": 107.0, "batch_reward": 0.13936753544956446, "critic_loss": 2.4236266188621522, "actor_loss": -97.49535736083985, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.817786693572998, "step": 107000}
{"episode_reward": 590.5436175647403, "episode": 108.0, "batch_reward": 0.1437693018168211, "critic_loss": 2.3006214138865473, "actor_loss": -97.64873649597168, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.44877004623413, "step": 108000}
{"episode_reward": 555.3400422051227, "episode": 109.0, "batch_reward": 0.1476710811778903, "critic_loss": 1.9888993442058562, "actor_loss": -94.49392875671387, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.366386890411377, "step": 109000}
{"episode_reward": 373.3604169095934, "episode": 110.0, "batch_reward": 0.14891728550195693, "critic_loss": 1.9418948065042496, "actor_loss": -93.18703494262695, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.652244806289673, "step": 110000}
{"episode_reward": 653.7692444209518, "episode": 111.0, "batch_reward": 0.15422951373457908, "critic_loss": 1.8425870018601418, "actor_loss": -93.37407864379882, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.041874170303345, "step": 111000}
{"episode_reward": 650.6915175198785, "episode": 112.0, "batch_reward": 0.158784688167274, "critic_loss": 1.723820516228676, "actor_loss": -90.47553149414063, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.8171603679657, "step": 112000}
{"episode_reward": 704.867546695393, "episode": 113.0, "batch_reward": 0.1646268959864974, "critic_loss": 1.682321402013302, "actor_loss": -90.23504904174804, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.784364938735962, "step": 113000}
{"episode_reward": 703.9428981799535, "episode": 114.0, "batch_reward": 0.16966084786504507, "critic_loss": 1.6944352260828017, "actor_loss": -89.17820742797852, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.430437803268433, "step": 114000}
{"episode_reward": 834.0335776500094, "episode": 115.0, "batch_reward": 0.17351915139704943, "critic_loss": 1.8134199063181877, "actor_loss": -88.50968992614746, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.844687461853027, "step": 115000}
{"episode_reward": 703.426085839183, "episode": 116.0, "batch_reward": 0.17874019426852464, "critic_loss": 2.059155068874359, "actor_loss": -88.20338583374023, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.320261001586914, "step": 116000}
{"episode_reward": 740.1064581452725, "episode": 117.0, "batch_reward": 0.18452110850811004, "critic_loss": 2.1798484467864037, "actor_loss": -88.20846209716797, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.35315704345703, "step": 117000}
{"episode_reward": 646.7708325120173, "episode": 118.0, "batch_reward": 0.18864658825844527, "critic_loss": 2.1912806301116943, "actor_loss": -87.45639692687988, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.67060923576355, "step": 118000}
{"episode_reward": 821.2009287833911, "episode": 119.0, "batch_reward": 0.19221726709604264, "critic_loss": 2.132512524366379, "actor_loss": -87.25946408081055, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.09796643257141, "step": 119000}
{"episode_reward": 829.7829158726656, "episode": 120.0, "batch_reward": 0.19799654733389616, "critic_loss": 2.0515782417058945, "actor_loss": -87.45712855529786, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.345919847488403, "step": 120000}
{"episode_reward": 737.6079083759106, "episode": 121.0, "batch_reward": 0.20090116885304451, "critic_loss": 2.161854079902172, "actor_loss": -86.8161363067627, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.230225801467896, "step": 121000}
{"episode_reward": 318.7649933326658, "episode": 122.0, "batch_reward": 0.2032614842802286, "critic_loss": 2.240759351491928, "actor_loss": -86.62546627807617, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.811213731765747, "step": 122000}
{"episode_reward": 401.6056290812476, "episode": 123.0, "batch_reward": 0.20378601296246052, "critic_loss": 2.3317241418361663, "actor_loss": -86.02360221862793, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.605432510375977, "step": 123000}
{"episode_reward": 279.26640822706577, "episode": 124.0, "batch_reward": 0.20432210645079613, "critic_loss": 2.530276512861252, "actor_loss": -85.6673744354248, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.934290409088135, "step": 124000}
{"episode_reward": 635.8533531035791, "episode": 125.0, "batch_reward": 0.20854620398581028, "critic_loss": 2.8511972204446794, "actor_loss": -85.50814462280273, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.09088945388794, "step": 125000}
{"episode_reward": 294.84834042221155, "episode": 126.0, "batch_reward": 0.20846667204797267, "critic_loss": 3.0309257830381395, "actor_loss": -85.7352613067627, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.296236038208008, "step": 126000}
{"episode_reward": 153.02386862815368, "episode": 127.0, "batch_reward": 0.20727357472479344, "critic_loss": 3.0626892186403274, "actor_loss": -85.40308029174804, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.521822452545166, "step": 127000}
{"episode_reward": 110.26219724835198, "episode": 128.0, "batch_reward": 0.20616801868379117, "critic_loss": 2.963093448519707, "actor_loss": -85.76107707214355, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.75944447517395, "step": 128000}
{"episode_reward": 148.2873481856446, "episode": 129.0, "batch_reward": 0.2070130763053894, "critic_loss": 2.9536081919670103, "actor_loss": -86.09089219665528, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.735126495361328, "step": 129000}
{"episode_reward": 150.38525539062735, "episode": 130.0, "batch_reward": 0.2059190085530281, "critic_loss": 2.5813467935323717, "actor_loss": -86.07368157958985, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.184780597686768, "step": 130000}
{"episode_reward": 90.42825264431167, "episode": 131.0, "batch_reward": 0.20362342110276221, "critic_loss": 2.394236115217209, "actor_loss": -85.88290644836425, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.032498836517334, "step": 131000}
{"episode_reward": 88.7228561957236, "episode": 132.0, "batch_reward": 0.2027953373044729, "critic_loss": 2.251799209356308, "actor_loss": -85.36382377624511, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.101420640945435, "step": 132000}
{"episode_reward": 168.726505328388, "episode": 133.0, "batch_reward": 0.20438989646732808, "critic_loss": 2.012645174205303, "actor_loss": -85.29587785339355, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.48045563697815, "step": 133000}
{"episode_reward": 92.60735948186446, "episode": 134.0, "batch_reward": 0.2023469484001398, "critic_loss": 2.056815218627453, "actor_loss": -84.98236053466798, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.35474729537964, "step": 134000}
{"episode_reward": 95.00924096263132, "episode": 135.0, "batch_reward": 0.20325614143908025, "critic_loss": 1.8800521356463433, "actor_loss": -84.42172840881348, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.575825691223145, "step": 135000}
{"episode_reward": 157.84640337522885, "episode": 136.0, "batch_reward": 0.20207253162562847, "critic_loss": 1.700594097852707, "actor_loss": -84.02212844848633, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.709769248962402, "step": 136000}
{"episode_reward": 396.74780513717997, "episode": 137.0, "batch_reward": 0.20537889508903026, "critic_loss": 1.5795004616975785, "actor_loss": -83.28964451599121, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.353344440460205, "step": 137000}
{"episode_reward": 795.4937658400169, "episode": 138.0, "batch_reward": 0.21108209864795208, "critic_loss": 1.4941499875187874, "actor_loss": -82.72495587158203, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.21103858947754, "step": 138000}
{"episode_reward": 868.8852660867449, "episode": 139.0, "batch_reward": 0.21551178139448166, "critic_loss": 1.481583542883396, "actor_loss": -82.14811128234864, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.213841438293457, "step": 139000}
{"episode_reward": 810.1816174228707, "episode": 140.0, "batch_reward": 0.22119940042495728, "critic_loss": 1.3779765695333481, "actor_loss": -81.61898963928223, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.46056342124939, "step": 140000}
{"episode_reward": 839.2839975881068, "episode": 141.0, "batch_reward": 0.22374990870058536, "critic_loss": 1.359736715555191, "actor_loss": -81.00712440490723, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.37740159034729, "step": 141000}
{"episode_reward": 861.0586466043857, "episode": 142.0, "batch_reward": 0.22830875787138938, "critic_loss": 1.3235230515003205, "actor_loss": -80.38798966979981, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.04953622817993, "step": 142000}
{"episode_reward": 881.1256873601743, "episode": 143.0, "batch_reward": 0.2312887002825737, "critic_loss": 1.303546339094639, "actor_loss": -79.89492803955078, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.59774088859558, "step": 143000}
{"episode_reward": 24.47247223084431, "episode": 144.0, "batch_reward": 0.23144585241377352, "critic_loss": 1.264485419034958, "actor_loss": -79.51681805419922, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.323837280273438, "step": 144000}
{"episode_reward": 900.5466342339769, "episode": 145.0, "batch_reward": 0.23624638380110263, "critic_loss": 1.1990972703993321, "actor_loss": -79.19386312866212, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.016413927078247, "step": 145000}
{"episode_reward": 856.9735039339832, "episode": 146.0, "batch_reward": 0.24080550292134284, "critic_loss": 1.3107117968201638, "actor_loss": -78.84047415161133, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.82593822479248, "step": 146000}
{"episode_reward": 898.0047515679181, "episode": 147.0, "batch_reward": 0.24321425914764405, "critic_loss": 1.2589928105473518, "actor_loss": -78.31773963928222, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.335552215576172, "step": 147000}
{"episode_reward": 423.3393203455139, "episode": 148.0, "batch_reward": 0.24618100555241107, "critic_loss": 1.3869711773991584, "actor_loss": -78.10712504577637, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.815243244171143, "step": 148000}
{"episode_reward": 801.6836695589445, "episode": 149.0, "batch_reward": 0.2496789378374815, "critic_loss": 1.3497975873351098, "actor_loss": -78.0772755279541, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.641263008117676, "step": 149000}
{"episode_reward": 954.4524011687653, "episode": 150.0, "batch_reward": 0.25599778540432455, "critic_loss": 1.3869290379881858, "actor_loss": -78.27238871765137, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "step": 150000}
