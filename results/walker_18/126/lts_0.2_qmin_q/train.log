{"episode_reward": 0.0, "episode": 1.0, "duration": 22.04753279685974, "step": 1000}
{"episode_reward": 29.08591335645728, "episode": 2.0, "duration": 1.951909065246582, "step": 2000}
{"episode_reward": 898.6342244091321, "episode": 3.0, "batch_reward": 0.43814777355068485, "critic_loss": 0.10867826542970775, "actor_loss": -81.23591428759003, "actor_target_entropy": -6.0, "alpha_value": 0.002642586817083679, "duration": 64.15120577812195, "step": 3000}
{"episode_reward": 84.70693713519312, "episode": 4.0, "batch_reward": 0.3249273023754358, "critic_loss": 0.3371901320666075, "actor_loss": -79.68313063049317, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.71853733062744, "step": 4000}
{"episode_reward": 297.4657593910381, "episode": 5.0, "batch_reward": 0.3326853407472372, "critic_loss": 0.4606187420934439, "actor_loss": -80.77670706176758, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.918829202651978, "step": 5000}
{"episode_reward": 303.22746443671457, "episode": 6.0, "batch_reward": 0.3121941569447517, "critic_loss": 0.5290004770159722, "actor_loss": -80.20721766662598, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.07266640663147, "step": 6000}
{"episode_reward": 200.30626649328872, "episode": 7.0, "batch_reward": 0.3161822925657034, "critic_loss": 0.7187484876513481, "actor_loss": -80.0438380279541, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.063437938690186, "step": 7000}
{"episode_reward": 482.4281857458309, "episode": 8.0, "batch_reward": 0.3364548337459564, "critic_loss": 0.9534138886928558, "actor_loss": -80.48255041503906, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.84979772567749, "step": 8000}
{"episode_reward": 493.88490442455316, "episode": 9.0, "batch_reward": 0.3603620765507221, "critic_loss": 1.0362350122332573, "actor_loss": -80.86820603942871, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.854285955429077, "step": 9000}
{"episode_reward": 592.7795517933582, "episode": 10.0, "batch_reward": 0.39383601674437524, "critic_loss": 1.0413067319989204, "actor_loss": -81.65504988098145, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.164144277572632, "step": 10000}
{"episode_reward": 759.2453737037615, "episode": 11.0, "batch_reward": 0.428444759875536, "critic_loss": 1.0437490457892418, "actor_loss": -82.6073302001953, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.435842752456665, "step": 11000}
{"episode_reward": 722.9388614324391, "episode": 12.0, "batch_reward": 0.45518069848418236, "critic_loss": 1.114173945605755, "actor_loss": -83.66513111877441, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.282247304916382, "step": 12000}
{"episode_reward": 784.0056279060041, "episode": 13.0, "batch_reward": 0.48230774214863775, "critic_loss": 1.02912547570467, "actor_loss": -84.4543825378418, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.093868255615234, "step": 13000}
{"episode_reward": 785.864386315694, "episode": 14.0, "batch_reward": 0.49012523514032363, "critic_loss": 0.9550767787694932, "actor_loss": -84.8065315246582, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.75972294807434, "step": 14000}
{"episode_reward": 502.29969161184647, "episode": 15.0, "batch_reward": 0.4986529683470726, "critic_loss": 0.8350018703937531, "actor_loss": -84.90298919677734, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.165616512298584, "step": 15000}
{"episode_reward": 650.8747910930815, "episode": 16.0, "batch_reward": 0.5168034889996052, "critic_loss": 0.7348431468307972, "actor_loss": -85.62713752746582, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.15669822692871, "step": 16000}
{"episode_reward": 860.279550314227, "episode": 17.0, "batch_reward": 0.5328497821986675, "critic_loss": 0.6899895984530449, "actor_loss": -85.92394491577149, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.087434768676758, "step": 17000}
{"episode_reward": 767.2042827358721, "episode": 18.0, "batch_reward": 0.5475362181663513, "critic_loss": 0.622473651766777, "actor_loss": -85.93925260925293, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.09368348121643, "step": 18000}
{"episode_reward": 818.4048322896717, "episode": 19.0, "batch_reward": 0.5595402857363224, "critic_loss": 0.5871922028660774, "actor_loss": -86.1351413269043, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.53192448616028, "step": 19000}
{"episode_reward": 684.980901825467, "episode": 20.0, "batch_reward": 0.569678048491478, "critic_loss": 0.5627654711008072, "actor_loss": -85.96513919067382, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.069318532943726, "step": 20000}
{"episode_reward": 817.6895195135768, "episode": 21.0, "batch_reward": 0.5827936437129975, "critic_loss": 0.5333569207191468, "actor_loss": -86.13596264648437, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.49849033355713, "step": 21000}
{"episode_reward": 886.8565345936302, "episode": 22.0, "batch_reward": 0.5967184586822987, "critic_loss": 0.5539766622185707, "actor_loss": -86.05368518066406, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.707245349884033, "step": 22000}
{"episode_reward": 824.9927509531224, "episode": 23.0, "batch_reward": 0.6040556700527668, "critic_loss": 0.5337361261546612, "actor_loss": -85.9889108428955, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.076749801635742, "step": 23000}
{"episode_reward": 831.2165447927059, "episode": 24.0, "batch_reward": 0.6191290172934533, "critic_loss": 0.5199768645763397, "actor_loss": -86.10621687316895, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.90861988067627, "step": 24000}
{"episode_reward": 917.3254209368977, "episode": 25.0, "batch_reward": 0.6292193332910537, "critic_loss": 0.5345265473425388, "actor_loss": -86.14184005737305, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.060083389282227, "step": 25000}
{"episode_reward": 865.5014492907366, "episode": 26.0, "batch_reward": 0.6378189002275467, "critic_loss": 0.5309983557760716, "actor_loss": -86.27213862609864, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.268588066101074, "step": 26000}
{"episode_reward": 861.73908984156, "episode": 27.0, "batch_reward": 0.6472612202763558, "critic_loss": 0.5191598979234695, "actor_loss": -86.1469855041504, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.98225498199463, "step": 27000}
{"episode_reward": 831.339081807759, "episode": 28.0, "batch_reward": 0.6515641072988511, "critic_loss": 0.514767608165741, "actor_loss": -86.37512269592285, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.95038628578186, "step": 28000}
{"episode_reward": 852.5159509399793, "episode": 29.0, "batch_reward": 0.66147401958704, "critic_loss": 0.5069492796957493, "actor_loss": -86.26104547119141, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.744925260543823, "step": 29000}
{"episode_reward": 907.9351523359638, "episode": 30.0, "batch_reward": 0.6671021708250046, "critic_loss": 0.5217720551490783, "actor_loss": -86.5272399597168, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.07047414779663, "step": 30000}
{"episode_reward": 854.4098460939001, "episode": 31.0, "batch_reward": 0.6728645904660225, "critic_loss": 0.5111494763940573, "actor_loss": -86.60551571655273, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.707847118377686, "step": 31000}
{"episode_reward": 811.0895618550139, "episode": 32.0, "batch_reward": 0.6804379842877388, "critic_loss": 0.5074523631334305, "actor_loss": -86.66454345703124, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.462778091430664, "step": 32000}
{"episode_reward": 921.6740224523312, "episode": 33.0, "batch_reward": 0.686009041428566, "critic_loss": 0.5181804160475731, "actor_loss": -86.7842451171875, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.075851917266846, "step": 33000}
{"episode_reward": 795.3415341587337, "episode": 34.0, "batch_reward": 0.6898958447575569, "critic_loss": 0.555583432495594, "actor_loss": -86.90877360534668, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.95224094390869, "step": 34000}
{"episode_reward": 864.9029126484767, "episode": 35.0, "batch_reward": 0.6947067303657531, "critic_loss": 0.5496165438592434, "actor_loss": -86.89760462951661, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.82476496696472, "step": 35000}
{"episode_reward": 879.3420214540355, "episode": 36.0, "batch_reward": 0.7007805700302124, "critic_loss": 0.5285793843567371, "actor_loss": -87.14609490966797, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.889485359191895, "step": 36000}
{"episode_reward": 869.437556115243, "episode": 37.0, "batch_reward": 0.7043342145681382, "critic_loss": 0.5569895646870137, "actor_loss": -87.3489961090088, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.307883501052856, "step": 37000}
{"episode_reward": 842.6165375091865, "episode": 38.0, "batch_reward": 0.7108012070059776, "critic_loss": 0.5203947732448578, "actor_loss": -87.13126751708984, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.267024278640747, "step": 38000}
{"episode_reward": 840.1436352399234, "episode": 39.0, "batch_reward": 0.7131519051790237, "critic_loss": 0.508491883546114, "actor_loss": -87.3721403503418, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.30902361869812, "step": 39000}
{"episode_reward": 956.7739243947651, "episode": 40.0, "batch_reward": 0.7153341305851937, "critic_loss": 0.5054276571571827, "actor_loss": -87.48829920959473, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.156447887420654, "step": 40000}
{"episode_reward": 918.261605903432, "episode": 41.0, "batch_reward": 0.7216613484025002, "critic_loss": 0.5234825312793255, "actor_loss": -87.74535827636718, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.284791231155396, "step": 41000}
{"episode_reward": 894.3715954254304, "episode": 42.0, "batch_reward": 0.7266384067535401, "critic_loss": 0.5062111538946629, "actor_loss": -87.87614350891113, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.163426637649536, "step": 42000}
{"episode_reward": 932.7634949738391, "episode": 43.0, "batch_reward": 0.7335312362313271, "critic_loss": 0.4933307021856308, "actor_loss": -87.9205403137207, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.17692732810974, "step": 43000}
{"episode_reward": 910.5693202763479, "episode": 44.0, "batch_reward": 0.7378824801445008, "critic_loss": 0.47740212482213973, "actor_loss": -88.14228598022461, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.979801416397095, "step": 44000}
{"episode_reward": 906.0518488799545, "episode": 45.0, "batch_reward": 0.7324737170934678, "critic_loss": 0.5023934555351734, "actor_loss": -87.98147868347168, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.80443835258484, "step": 45000}
{"episode_reward": 76.15974589812954, "episode": 46.0, "batch_reward": 0.725832734823227, "critic_loss": 0.4996065125316381, "actor_loss": -87.99250498962402, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.16117286682129, "step": 46000}
{"episode_reward": 901.4353254056077, "episode": 47.0, "batch_reward": 0.7298296019434929, "critic_loss": 0.4666317541152239, "actor_loss": -88.108083984375, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.662089109420776, "step": 47000}
{"episode_reward": 904.4320539212462, "episode": 48.0, "batch_reward": 0.7320728502869606, "critic_loss": 0.47337185963988304, "actor_loss": -87.84343783569336, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.036447286605835, "step": 48000}
{"episode_reward": 938.3019623344245, "episode": 49.0, "batch_reward": 0.7389573468565941, "critic_loss": 0.4697612744271755, "actor_loss": -88.14800872802735, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.705787181854248, "step": 49000}
{"episode_reward": 915.9045759126578, "episode": 50.0, "batch_reward": 0.7407176545858383, "critic_loss": 0.479472203373909, "actor_loss": -88.33075939941406, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.148388862609863, "step": 50000}
{"episode_reward": 829.3917710944787, "episode": 51.0, "batch_reward": 0.7431082102656364, "critic_loss": 0.46787858673930166, "actor_loss": -88.31217869567871, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.247591495513916, "step": 51000}
{"episode_reward": 865.3411150143062, "episode": 52.0, "batch_reward": 0.7444742349982262, "critic_loss": 0.479086822360754, "actor_loss": -88.43942568969726, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.136492252349854, "step": 52000}
{"episode_reward": 834.4985780689195, "episode": 53.0, "batch_reward": 0.7482758038043976, "critic_loss": 0.45566157858073714, "actor_loss": -88.43754525756836, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.16308856010437, "step": 53000}
{"episode_reward": 943.1601841726139, "episode": 54.0, "batch_reward": 0.7505810614228249, "critic_loss": 0.46821846982836723, "actor_loss": -88.65471862792968, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.36028289794922, "step": 54000}
{"episode_reward": 929.9561210953183, "episode": 55.0, "batch_reward": 0.7536430463194848, "critic_loss": 0.48676082088053224, "actor_loss": -88.79417510986327, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.774863481521606, "step": 55000}
{"episode_reward": 906.1956597778669, "episode": 56.0, "batch_reward": 0.7582174857854843, "critic_loss": 0.4619340759962797, "actor_loss": -88.77216711425781, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.184444427490234, "step": 56000}
{"episode_reward": 952.5126712633775, "episode": 57.0, "batch_reward": 0.7607006523609161, "critic_loss": 0.46172124503552914, "actor_loss": -88.95059321594238, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.598503589630127, "step": 57000}
{"episode_reward": 940.4026859505072, "episode": 58.0, "batch_reward": 0.7621637790799141, "critic_loss": 0.44743359710276126, "actor_loss": -88.95776194763184, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.30139684677124, "step": 58000}
{"episode_reward": 921.0954905238021, "episode": 59.0, "batch_reward": 0.766265676498413, "critic_loss": 0.45142039278149604, "actor_loss": -89.21663914489746, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.385843515396118, "step": 59000}
{"episode_reward": 892.6671469684021, "episode": 60.0, "batch_reward": 0.7673215429782867, "critic_loss": 0.4608734478056431, "actor_loss": -89.29503485107422, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.26991581916809, "step": 60000}
{"episode_reward": 834.6626708068201, "episode": 61.0, "batch_reward": 0.7702271155118943, "critic_loss": 0.4489397872984409, "actor_loss": -89.35584928894043, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.759103775024414, "step": 61000}
{"episode_reward": 861.6367479653742, "episode": 62.0, "batch_reward": 0.7697426437735557, "critic_loss": 0.4600718156248331, "actor_loss": -89.38028918457032, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.138762950897217, "step": 62000}
{"episode_reward": 963.0497487089875, "episode": 63.0, "batch_reward": 0.7728451151847839, "critic_loss": 0.44385097578167915, "actor_loss": -89.49593263244628, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.787671089172363, "step": 63000}
{"episode_reward": 942.2688273121009, "episode": 64.0, "batch_reward": 0.7764256174564361, "critic_loss": 0.4559182454943657, "actor_loss": -89.68683653259278, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.071150064468384, "step": 64000}
{"episode_reward": 888.4596589739893, "episode": 65.0, "batch_reward": 0.7783584316372871, "critic_loss": 0.46877408431470396, "actor_loss": -89.67588642883301, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.145452976226807, "step": 65000}
{"episode_reward": 935.5775335897106, "episode": 66.0, "batch_reward": 0.780829858481884, "critic_loss": 0.4366627088934183, "actor_loss": -89.90895664978028, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.81534218788147, "step": 66000}
{"episode_reward": 960.1016138201571, "episode": 67.0, "batch_reward": 0.7838057286143303, "critic_loss": 0.43090808409452436, "actor_loss": -89.97948416137696, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.878319025039673, "step": 67000}
{"episode_reward": 947.8798320232745, "episode": 68.0, "batch_reward": 0.7862078639864921, "critic_loss": 0.440147147834301, "actor_loss": -90.09813345336914, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.192233085632324, "step": 68000}
{"episode_reward": 931.7210931154067, "episode": 69.0, "batch_reward": 0.7880382785201072, "critic_loss": 0.42698432609438897, "actor_loss": -90.21303887939453, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.051257848739624, "step": 69000}
{"episode_reward": 969.2356941593072, "episode": 70.0, "batch_reward": 0.791122115790844, "critic_loss": 0.42957514832913873, "actor_loss": -90.27578462219239, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.91557288169861, "step": 70000}
{"episode_reward": 901.988944052197, "episode": 71.0, "batch_reward": 0.7918858256936073, "critic_loss": 0.42291956788301466, "actor_loss": -90.33197862243652, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 41.38564682006836, "step": 71000}
{"episode_reward": 918.3573755671374, "episode": 72.0, "batch_reward": 0.7889230393767357, "critic_loss": 0.4136110616773367, "actor_loss": -90.27297006225587, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.904715538024902, "step": 72000}
{"episode_reward": 257.26084554057576, "episode": 73.0, "batch_reward": 0.786343656361103, "critic_loss": 0.4039111437499523, "actor_loss": -90.28909461975098, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.764629364013672, "step": 73000}
{"episode_reward": 865.6461973102452, "episode": 74.0, "batch_reward": 0.7885157564878463, "critic_loss": 0.4157825016379356, "actor_loss": -90.22281039428711, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.222466468811035, "step": 74000}
{"episode_reward": 917.3525506457728, "episode": 75.0, "batch_reward": 0.7908046867847442, "critic_loss": 0.4156583405137062, "actor_loss": -90.32933345031738, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.28736114501953, "step": 75000}
{"episode_reward": 970.5483169226497, "episode": 76.0, "batch_reward": 0.7925387883782387, "critic_loss": 0.3992730477154255, "actor_loss": -90.51425561523438, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.043825387954712, "step": 76000}
{"episode_reward": 951.8990219616126, "episode": 77.0, "batch_reward": 0.795896076798439, "critic_loss": 0.40669218565523624, "actor_loss": -90.52435153198242, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.139798402786255, "step": 77000}
{"episode_reward": 920.1674926204606, "episode": 78.0, "batch_reward": 0.7946002659201622, "critic_loss": 0.4264203025251627, "actor_loss": -90.35402372741699, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.04297137260437, "step": 78000}
{"episode_reward": 919.6629594338484, "episode": 79.0, "batch_reward": 0.7967711306214332, "critic_loss": 0.4265303897559643, "actor_loss": -90.46139318847656, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.466266632080078, "step": 79000}
{"episode_reward": 930.7550114170231, "episode": 80.0, "batch_reward": 0.798982338309288, "critic_loss": 0.40274333019554615, "actor_loss": -90.7408757019043, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.10274386405945, "step": 80000}
{"episode_reward": 938.7359923498589, "episode": 81.0, "batch_reward": 0.7998705843687057, "critic_loss": 0.4233516764044762, "actor_loss": -90.67727534484864, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.242159366607666, "step": 81000}
{"episode_reward": 927.3077228816634, "episode": 82.0, "batch_reward": 0.7993925704360009, "critic_loss": 0.4232822389304638, "actor_loss": -90.72615283203125, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.854281187057495, "step": 82000}
{"episode_reward": 941.6181166982157, "episode": 83.0, "batch_reward": 0.8021802341938019, "critic_loss": 0.4130736314505339, "actor_loss": -90.9897964630127, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.719834327697754, "step": 83000}
{"episode_reward": 913.0170848371043, "episode": 84.0, "batch_reward": 0.8041952987909317, "critic_loss": 0.4113658304065466, "actor_loss": -90.98298825073242, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.020935773849487, "step": 84000}
{"episode_reward": 933.9618705954156, "episode": 85.0, "batch_reward": 0.8054641257524491, "critic_loss": 0.3980577297359705, "actor_loss": -91.03403521728515, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.821354389190674, "step": 85000}
{"episode_reward": 937.4887587242071, "episode": 86.0, "batch_reward": 0.8071172792315483, "critic_loss": 0.40327457450330256, "actor_loss": -91.17488340759277, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.850693702697754, "step": 86000}
{"episode_reward": 941.1842556041564, "episode": 87.0, "batch_reward": 0.8100636605024337, "critic_loss": 0.4095354995280504, "actor_loss": -91.25409606933594, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.08745312690735, "step": 87000}
{"episode_reward": 913.0123175408986, "episode": 88.0, "batch_reward": 0.8098807939291001, "critic_loss": 0.3820438545793295, "actor_loss": -91.31155949401855, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.60285711288452, "step": 88000}
{"episode_reward": 964.5044379579838, "episode": 89.0, "batch_reward": 0.8120984756350518, "critic_loss": 0.4027545123696327, "actor_loss": -91.29753793334962, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.414962768554688, "step": 89000}
{"episode_reward": 908.4533743230613, "episode": 90.0, "batch_reward": 0.8119657877087593, "critic_loss": 0.3905591575950384, "actor_loss": -91.21993017578124, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.432381868362427, "step": 90000}
{"episode_reward": 946.2196251751689, "episode": 91.0, "batch_reward": 0.8144158710241318, "critic_loss": 0.4081068921983242, "actor_loss": -91.3695089416504, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.22154998779297, "step": 91000}
{"episode_reward": 911.1675430292961, "episode": 92.0, "batch_reward": 0.8169190412163735, "critic_loss": 0.39256729240715504, "actor_loss": -91.5352116241455, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.73912787437439, "step": 92000}
{"episode_reward": 983.1057688402373, "episode": 93.0, "batch_reward": 0.8194548708200454, "critic_loss": 0.3900949474275112, "actor_loss": -91.53263452148437, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.187961101531982, "step": 93000}
{"episode_reward": 971.8501011360889, "episode": 94.0, "batch_reward": 0.8207284123897552, "critic_loss": 0.38103069105744364, "actor_loss": -91.60592987060546, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.414778470993042, "step": 94000}
{"episode_reward": 946.9817324866401, "episode": 95.0, "batch_reward": 0.8218109993934631, "critic_loss": 0.3957321993857622, "actor_loss": -91.55210661315918, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.939467191696167, "step": 95000}
{"episode_reward": 929.001836453738, "episode": 96.0, "batch_reward": 0.8215394778847694, "critic_loss": 0.4021515833437443, "actor_loss": -91.83695582580566, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.340797424316406, "step": 96000}
{"episode_reward": 952.595845504544, "episode": 97.0, "batch_reward": 0.8231610104441642, "critic_loss": 0.3807196362167597, "actor_loss": -91.73605755615235, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.15709114074707, "step": 97000}
{"episode_reward": 936.1721963021586, "episode": 98.0, "batch_reward": 0.822723217010498, "critic_loss": 0.38662736308574674, "actor_loss": -91.62749723815918, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.14536952972412, "step": 98000}
{"episode_reward": 932.8606291589136, "episode": 99.0, "batch_reward": 0.8268959055542946, "critic_loss": 0.3904549221247435, "actor_loss": -91.9757507019043, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.583749294281006, "step": 99000}
{"episode_reward": 904.3504385720411, "episode": 100.0, "batch_reward": 0.8209680777192115, "critic_loss": 0.3976836490482092, "actor_loss": -91.85137322998047, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.175417184829712, "step": 100000}
{"episode_reward": 60.62477863819986, "episode": 101.0, "batch_reward": 0.8188767265081406, "critic_loss": 0.3854509284943342, "actor_loss": -91.89044758605957, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.46349096298218, "step": 101000}
{"episode_reward": 961.925020236291, "episode": 102.0, "batch_reward": 0.8199223660826683, "critic_loss": 0.418031406968832, "actor_loss": -91.75055758666993, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.412208318710327, "step": 102000}
{"episode_reward": 901.3006500872596, "episode": 103.0, "batch_reward": 0.8203567938804627, "critic_loss": 0.40846025371551514, "actor_loss": -91.75358338928223, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.303647994995117, "step": 103000}
{"episode_reward": 937.7536352990309, "episode": 104.0, "batch_reward": 0.8204461717605591, "critic_loss": 0.3891635922342539, "actor_loss": -91.88445097351074, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.208488702774048, "step": 104000}
{"episode_reward": 929.9206451219067, "episode": 105.0, "batch_reward": 0.8239105988740921, "critic_loss": 0.3875810749232769, "actor_loss": -91.9777522277832, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.54129672050476, "step": 105000}
{"episode_reward": 930.2091149980394, "episode": 106.0, "batch_reward": 0.8239741299152374, "critic_loss": 0.3867416560202837, "actor_loss": -92.04864241027832, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 20.965441703796387, "step": 106000}
{"episode_reward": 922.7572948566774, "episode": 107.0, "batch_reward": 0.8255234896540642, "critic_loss": 0.38830706384778024, "actor_loss": -92.03481384277343, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.37178659439087, "step": 107000}
{"episode_reward": 864.041456835458, "episode": 108.0, "batch_reward": 0.8245470452308655, "critic_loss": 0.3896520575284958, "actor_loss": -91.89707196044922, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.916232347488403, "step": 108000}
{"episode_reward": 950.8957775235912, "episode": 109.0, "batch_reward": 0.8254708018302918, "critic_loss": 0.38547232231497763, "actor_loss": -91.96638778686524, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.627562284469604, "step": 109000}
{"episode_reward": 934.0767877630351, "episode": 110.0, "batch_reward": 0.8274817721843719, "critic_loss": 0.40116226696968077, "actor_loss": -92.07684089660644, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.06848978996277, "step": 110000}
{"episode_reward": 935.5540388238812, "episode": 111.0, "batch_reward": 0.8288131023049354, "critic_loss": 0.36084226064383984, "actor_loss": -92.02979974365235, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.46490740776062, "step": 111000}
{"episode_reward": 946.664955636714, "episode": 112.0, "batch_reward": 0.8293817218542099, "critic_loss": 0.3671433321684599, "actor_loss": -92.2141883392334, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.512255430221558, "step": 112000}
{"episode_reward": 942.2515549691926, "episode": 113.0, "batch_reward": 0.8306204169988632, "critic_loss": 0.37691326868534086, "actor_loss": -92.22281600952148, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.149379014968872, "step": 113000}
{"episode_reward": 964.4780045173567, "episode": 114.0, "batch_reward": 0.8313749381303788, "critic_loss": 0.364306508615613, "actor_loss": -92.2816512298584, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.977850437164307, "step": 114000}
{"episode_reward": 991.3189538499275, "episode": 115.0, "batch_reward": 0.8323705526590347, "critic_loss": 0.3632748265117407, "actor_loss": -92.27451139831543, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.784662008285522, "step": 115000}
{"episode_reward": 961.8563273061999, "episode": 116.0, "batch_reward": 0.8366290625333787, "critic_loss": 0.3681607642620802, "actor_loss": -92.39582545471191, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.112797498703003, "step": 116000}
{"episode_reward": 931.925535127325, "episode": 117.0, "batch_reward": 0.833216668009758, "critic_loss": 0.37690058183670044, "actor_loss": -92.25825587463379, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.255754947662354, "step": 117000}
{"episode_reward": 941.908610125431, "episode": 118.0, "batch_reward": 0.834443102657795, "critic_loss": 0.3693104856386781, "actor_loss": -92.35581274414062, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.90922451019287, "step": 118000}
{"episode_reward": 936.011010641138, "episode": 119.0, "batch_reward": 0.8373317507505417, "critic_loss": 0.37115173053741457, "actor_loss": -92.36375045776367, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.444803714752197, "step": 119000}
{"episode_reward": 950.1654243661828, "episode": 120.0, "batch_reward": 0.8381645466685295, "critic_loss": 0.3620256335735321, "actor_loss": -92.35349227905273, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.094643592834473, "step": 120000}
{"episode_reward": 961.2027828610213, "episode": 121.0, "batch_reward": 0.8370454859733581, "critic_loss": 0.3503119452595711, "actor_loss": -92.49710057067871, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.78502821922302, "step": 121000}
{"episode_reward": 952.1014399304636, "episode": 122.0, "batch_reward": 0.8401935920715332, "critic_loss": 0.3728696830570698, "actor_loss": -92.48416218566895, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.249937772750854, "step": 122000}
{"episode_reward": 936.179492728671, "episode": 123.0, "batch_reward": 0.839871680021286, "critic_loss": 0.3600188998878002, "actor_loss": -92.53255265808106, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.069222450256348, "step": 123000}
{"episode_reward": 937.6862237700083, "episode": 124.0, "batch_reward": 0.8419739058017731, "critic_loss": 0.40004029332101343, "actor_loss": -92.69978625488281, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.81542682647705, "step": 124000}
{"episode_reward": 947.1650669494622, "episode": 125.0, "batch_reward": 0.8421134712696076, "critic_loss": 0.3622703018337488, "actor_loss": -92.79105052185058, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.800722360610962, "step": 125000}
{"episode_reward": 937.7629464524423, "episode": 126.0, "batch_reward": 0.8437139813303948, "critic_loss": 0.3576119814291596, "actor_loss": -92.6594626159668, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.121671199798584, "step": 126000}
{"episode_reward": 966.890469652105, "episode": 127.0, "batch_reward": 0.843135531425476, "critic_loss": 0.3666818480491638, "actor_loss": -92.78766172790527, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.18417000770569, "step": 127000}
{"episode_reward": 940.772377444899, "episode": 128.0, "batch_reward": 0.8441044439077378, "critic_loss": 0.35276904118061064, "actor_loss": -92.79466931152344, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.93061900138855, "step": 128000}
{"episode_reward": 949.9764924559194, "episode": 129.0, "batch_reward": 0.8449070653319359, "critic_loss": 0.36058091769367456, "actor_loss": -92.77076580810547, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.485238552093506, "step": 129000}
{"episode_reward": 980.289704582306, "episode": 130.0, "batch_reward": 0.8476452185511589, "critic_loss": 0.34729492492973807, "actor_loss": -92.88488386535644, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.165040493011475, "step": 130000}
{"episode_reward": 917.9213331282945, "episode": 131.0, "batch_reward": 0.8469630111455917, "critic_loss": 0.3414435175508261, "actor_loss": -92.85946905517578, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.577943325042725, "step": 131000}
{"episode_reward": 919.9562935863423, "episode": 132.0, "batch_reward": 0.8476035796999931, "critic_loss": 0.3604940834492445, "actor_loss": -92.90476573181152, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.207719087600708, "step": 132000}
{"episode_reward": 922.3407119986313, "episode": 133.0, "batch_reward": 0.8491190791726112, "critic_loss": 0.36351367795467376, "actor_loss": -92.84110292053222, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.203762531280518, "step": 133000}
{"episode_reward": 955.9396385454901, "episode": 134.0, "batch_reward": 0.8495378178954125, "critic_loss": 0.35533911880850794, "actor_loss": -92.95156773376465, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.467326641082764, "step": 134000}
{"episode_reward": 906.5037108470909, "episode": 135.0, "batch_reward": 0.8490413669943809, "critic_loss": 0.35405818759649993, "actor_loss": -93.01055892944336, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.004127025604248, "step": 135000}
{"episode_reward": 856.1704214748842, "episode": 136.0, "batch_reward": 0.8507461981773377, "critic_loss": 0.3671214247047901, "actor_loss": -92.9368409576416, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.319525003433228, "step": 136000}
{"episode_reward": 911.7309351374372, "episode": 137.0, "batch_reward": 0.848458908855915, "critic_loss": 0.3840651471763849, "actor_loss": -93.00599887084961, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.167609214782715, "step": 137000}
{"episode_reward": 935.3404301634818, "episode": 138.0, "batch_reward": 0.8523333739638329, "critic_loss": 0.3749417173862457, "actor_loss": -93.13605548095703, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.7235004901886, "step": 138000}
{"episode_reward": 969.9028827613467, "episode": 139.0, "batch_reward": 0.852421424150467, "critic_loss": 0.37376516741514204, "actor_loss": -92.95989398193359, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.933025121688843, "step": 139000}
{"episode_reward": 928.0442673551213, "episode": 140.0, "batch_reward": 0.8547285606861115, "critic_loss": 0.3576604146957397, "actor_loss": -93.16602510070801, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.17792296409607, "step": 140000}
{"episode_reward": 958.231010230877, "episode": 141.0, "batch_reward": 0.8520751111507415, "critic_loss": 0.38486446438729766, "actor_loss": -93.10903552246094, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 42.19822430610657, "step": 141000}
{"episode_reward": 930.08065554969, "episode": 142.0, "batch_reward": 0.852618155837059, "critic_loss": 0.3741111314967275, "actor_loss": -93.00381271362305, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.217924118041992, "step": 142000}
{"episode_reward": 947.5106985779285, "episode": 143.0, "batch_reward": 0.8542936532497406, "critic_loss": 0.3648835390806198, "actor_loss": -93.12568464660644, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.14143967628479, "step": 143000}
{"episode_reward": 940.9677855219064, "episode": 144.0, "batch_reward": 0.8547061910033226, "critic_loss": 0.3652367072999477, "actor_loss": -93.14454965209961, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.440220832824707, "step": 144000}
{"episode_reward": 933.9040430142393, "episode": 145.0, "batch_reward": 0.8559976993203163, "critic_loss": 0.36403774622082713, "actor_loss": -93.26931880187988, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.992425680160522, "step": 145000}
{"episode_reward": 870.2084069621111, "episode": 146.0, "batch_reward": 0.8567505431771278, "critic_loss": 0.36736363418400286, "actor_loss": -93.36833090209961, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.521272659301758, "step": 146000}
{"episode_reward": 972.9729602984028, "episode": 147.0, "batch_reward": 0.8569400699734688, "critic_loss": 0.36894098594784736, "actor_loss": -93.29699114990234, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.160216093063354, "step": 147000}
{"episode_reward": 958.7014506756808, "episode": 148.0, "batch_reward": 0.8565746711492539, "critic_loss": 0.35119468504190443, "actor_loss": -93.22529374694824, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 22.254539251327515, "step": 148000}
{"episode_reward": 941.7525427849469, "episode": 149.0, "batch_reward": 0.8567748515605926, "critic_loss": 0.34706219951063394, "actor_loss": -93.25657131958008, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "duration": 21.59807538986206, "step": 149000}
{"episode_reward": 985.163989673939, "episode": 150.0, "batch_reward": 0.8574342187047005, "critic_loss": 0.36092329981923105, "actor_loss": -93.30740773010254, "actor_target_entropy": -6.0, "alpha_value": 0.0026425868170837793, "step": 150000}
