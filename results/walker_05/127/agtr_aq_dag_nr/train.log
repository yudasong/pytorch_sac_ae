{"episode": 1.0, "duration": 20.42341160774231, "episode_reward": 61.50603977848499, "step": 1000}
{"episode": 2.0, "duration": 1.775752067565918, "episode_reward": 808.9209525976895, "step": 2000}
{"episode": 3.0, "batch_reward": 0.45875775953180276, "critic_loss": 0.285475100498372, "actor_loss": -76.40452392199556, "actor_target_entropy": -6.0, "alpha_value": 0.004839161189226583, "duration": 65.9513008594513, "episode_reward": 846.7708771836834, "step": 3000}
{"episode": 4.0, "batch_reward": 0.6123546338677406, "critic_loss": 0.28244214528799055, "actor_loss": -81.0415983581543, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.560884714126587, "episode_reward": 873.5799575287102, "step": 4000}
{"episode": 5.0, "batch_reward": 0.6561265318989754, "critic_loss": 0.35766706776618956, "actor_loss": -82.18242401123047, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.55821394920349, "episode_reward": 805.6602713732984, "step": 5000}
{"episode": 6.0, "batch_reward": 0.6903893490433692, "critic_loss": 0.30109407258033755, "actor_loss": -83.0529592590332, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.908106088638306, "episode_reward": 846.9142313959719, "step": 6000}
{"episode": 7.0, "batch_reward": 0.715441553235054, "critic_loss": 0.34541950733959675, "actor_loss": -83.75479263305664, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.714672565460205, "episode_reward": 858.9544313917579, "step": 7000}
{"episode": 8.0, "batch_reward": 0.7348686227202416, "critic_loss": 0.3064027089625597, "actor_loss": -84.31934645080567, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.37052583694458, "episode_reward": 858.0665273439599, "step": 8000}
{"episode": 9.0, "batch_reward": 0.7509315859675407, "critic_loss": 0.29155649419128893, "actor_loss": -84.84467915344239, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.216935634613037, "episode_reward": 863.8972966015392, "step": 9000}
{"episode": 10.0, "batch_reward": 0.7607237786650658, "critic_loss": 0.43452979311347006, "actor_loss": -80.25981611633301, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 4604.035571336746, "episode_reward": 816.3366666925982, "step": 10000}
{"episode": 11.0, "batch_reward": 0.7593802709579468, "critic_loss": 0.4453208417147398, "actor_loss": -80.47358364868164, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 48.4909782409668, "episode_reward": 764.3138035573992, "step": 11000}
{"episode": 12.0, "batch_reward": 0.7638072978258132, "critic_loss": 0.5267522186040878, "actor_loss": -77.46213934326173, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 581.5018348693848, "episode_reward": 812.742825300655, "step": 12000}
{"episode": 13.0, "batch_reward": 0.7368552017211915, "critic_loss": 0.48899273969233037, "actor_loss": -76.5905040435791, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 26.62483263015747, "episode_reward": 11.513248242398856, "step": 13000}
{"episode": 14.0, "batch_reward": 0.7082678651213646, "critic_loss": 0.4643508397340775, "actor_loss": -74.11961082458497, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 563.5650339126587, "episode_reward": 562.6261863715679, "step": 14000}
{"episode": 15.0, "batch_reward": 0.7004425964355468, "critic_loss": 0.4467201982140541, "actor_loss": -74.0061589050293, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 26.802857637405396, "episode_reward": 770.96112597888, "step": 15000}
{"episode": 16.0, "batch_reward": 0.6942982385158539, "critic_loss": 0.5040728568136692, "actor_loss": -73.24875883483887, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 534.3908784389496, "episode_reward": 505.1188872317824, "step": 16000}
{"episode": 17.0, "batch_reward": 0.6877212626338005, "critic_loss": 0.5780863058269023, "actor_loss": -73.15796420288086, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.959924459457397, "episode_reward": 623.8999358722507, "step": 17000}
{"episode": 18.0, "batch_reward": 0.6866856647729873, "critic_loss": 0.728643735140562, "actor_loss": -72.49170980834961, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 546.0804626941681, "episode_reward": 716.6498962467125, "step": 18000}
{"episode": 19.0, "batch_reward": 0.6916068097352982, "critic_loss": 0.8842298658788205, "actor_loss": -72.71661956787109, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.306565046310425, "episode_reward": 769.083337789931, "step": 19000}
{"episode": 20.0, "batch_reward": 0.6946248639225959, "critic_loss": 1.1663636413216592, "actor_loss": -72.2449187927246, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 574.1463887691498, "episode_reward": 738.4561026941285, "step": 20000}
{"episode": 21.0, "batch_reward": 0.6955643439292908, "critic_loss": 1.5419079501032829, "actor_loss": -72.27625601196289, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 46.685585737228394, "episode_reward": 785.2111652202165, "step": 21000}
{"episode": 22.0, "batch_reward": 0.6992071081995964, "critic_loss": 1.8830932941436767, "actor_loss": -71.85734936523437, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 570.1661021709442, "episode_reward": 787.2699812132439, "step": 22000}
{"episode": 23.0, "batch_reward": 0.7057581164836884, "critic_loss": 2.320107047200203, "actor_loss": -72.00014469909668, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 30.406754970550537, "episode_reward": 804.181098217466, "step": 23000}
{"episode": 24.0, "batch_reward": 0.7083926623463631, "critic_loss": 2.712257455706596, "actor_loss": -72.05295265197753, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 525.1536242961884, "episode_reward": 699.2145747242658, "step": 24000}
{"episode": 25.0, "batch_reward": 0.7072417374253273, "critic_loss": 2.8775068011283875, "actor_loss": -72.06580186462402, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 27.225239276885986, "episode_reward": 752.8506074932343, "step": 25000}
{"episode": 26.0, "batch_reward": 0.7109558078050613, "critic_loss": 3.208275004386902, "actor_loss": -71.58349125671387, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 524.4401745796204, "episode_reward": 750.2448889539658, "step": 26000}
{"episode": 27.0, "batch_reward": 0.7089175946116447, "critic_loss": 3.630478565812111, "actor_loss": -71.39921655273437, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.874049425125122, "episode_reward": 564.8446268707501, "step": 27000}
{"episode": 28.0, "batch_reward": 0.708429967880249, "critic_loss": 3.614338643670082, "actor_loss": -71.0076030883789, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 498.99768352508545, "episode_reward": 846.4868681647333, "step": 28000}
{"episode": 29.0, "batch_reward": 0.7070744433999061, "critic_loss": 3.5251201088428497, "actor_loss": -71.05156422424317, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 26.946634769439697, "episode_reward": 659.8377444220001, "step": 29000}
{"episode": 30.0, "batch_reward": 0.7109519372582436, "critic_loss": 3.350300562620163, "actor_loss": -71.29206280517577, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 514.6536054611206, "episode_reward": 842.626487635872, "step": 30000}
{"episode": 31.0, "batch_reward": 0.7145003553628921, "critic_loss": 3.267049700498581, "actor_loss": -71.46922372436524, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 39.844614028930664, "episode_reward": 817.2909470836007, "step": 31000}
{"episode": 32.0, "batch_reward": 0.7167591522336006, "critic_loss": 3.6271747260093687, "actor_loss": -71.51800198364258, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 453.17277812957764, "episode_reward": 678.1290741242377, "step": 32000}
{"episode": 33.0, "batch_reward": 0.7152883715033531, "critic_loss": 3.640295467853546, "actor_loss": -71.42987196350097, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 27.4708194732666, "episode_reward": 765.3367451749488, "step": 33000}
{"episode": 34.0, "batch_reward": 0.7184803149104119, "critic_loss": 3.4293948068618776, "actor_loss": -71.6097437133789, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 541.0937838554382, "episode_reward": 797.2473174659012, "step": 34000}
{"episode": 35.0, "batch_reward": 0.7181674807667732, "critic_loss": 3.013029026269913, "actor_loss": -71.61987185668946, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 26.217613220214844, "episode_reward": 732.8209437877465, "step": 35000}
{"episode": 36.0, "batch_reward": 0.7199893629550934, "critic_loss": 2.9519552377462386, "actor_loss": -71.43032769775391, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 516.8737003803253, "episode_reward": 826.3611898417635, "step": 36000}
{"episode": 37.0, "batch_reward": 0.724055087864399, "critic_loss": 2.8725510843992232, "actor_loss": -71.62805996704101, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 28.156583786010742, "episode_reward": 832.3338275052844, "step": 37000}
{"episode": 38.0, "batch_reward": 0.7259005674719811, "critic_loss": 2.8414941309690476, "actor_loss": -71.85167756652832, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 513.2364292144775, "episode_reward": 855.0849154686409, "step": 38000}
{"episode": 39.0, "batch_reward": 0.731912446796894, "critic_loss": 2.6556869181394576, "actor_loss": -72.0333515777588, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 28.128218173980713, "episode_reward": 859.7861678331024, "step": 39000}
{"episode": 40.0, "batch_reward": 0.734544042468071, "critic_loss": 2.6016256947517395, "actor_loss": -72.14738217163087, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 528.5592319965363, "episode_reward": 851.7574088090912, "step": 40000}
{"episode": 41.0, "batch_reward": 0.7353228687047958, "critic_loss": 2.361074125289917, "actor_loss": -72.11965519714356, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 47.80527424812317, "episode_reward": 838.4937809074678, "step": 41000}
{"episode": 42.0, "batch_reward": 0.7374794833660125, "critic_loss": 2.1943763124346733, "actor_loss": -72.13895169067384, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 480.53812742233276, "episode_reward": 857.6132273551015, "step": 42000}
{"episode": 43.0, "batch_reward": 0.7436004211306572, "critic_loss": 2.1553416142463684, "actor_loss": -72.35120765686035, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.235238552093506, "episode_reward": 847.8213147275247, "step": 43000}
{"episode": 44.0, "batch_reward": 0.7446467204093933, "critic_loss": 2.1553333622217177, "actor_loss": -72.13807318115235, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 499.4702672958374, "episode_reward": 873.9619562627447, "step": 44000}
{"episode": 45.0, "batch_reward": 0.746603965818882, "critic_loss": 2.1236778504252434, "actor_loss": -72.29141215515136, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.43760871887207, "episode_reward": 876.1130337772826, "step": 45000}
{"episode": 46.0, "batch_reward": 0.7492199099063873, "critic_loss": 2.138441387653351, "actor_loss": -72.34143760681152, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 468.0781090259552, "episode_reward": 874.1213237923613, "step": 46000}
{"episode": 47.0, "batch_reward": 0.7518997641205788, "critic_loss": 2.2650251220464708, "actor_loss": -72.41278895568847, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.516947746276855, "episode_reward": 851.4896007067043, "step": 47000}
{"episode": 48.0, "batch_reward": 0.7532775009274483, "critic_loss": 2.193618492484093, "actor_loss": -72.94946980285644, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 535.8997495174408, "episode_reward": 837.9217242206619, "step": 48000}
{"episode": 49.0, "batch_reward": 0.7576690183281899, "critic_loss": 2.0896572837233545, "actor_loss": -72.98349046325684, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 26.701510190963745, "episode_reward": 889.3748502954513, "step": 49000}
{"episode": 50.0, "batch_reward": 0.758597514629364, "critic_loss": 2.1025899122953415, "actor_loss": -73.09242884826661, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 536.2110548019409, "episode_reward": 861.243000525072, "step": 50000}
{"episode": 51.0, "batch_reward": 0.7623571928143501, "critic_loss": 2.2709133883714676, "actor_loss": -73.22504472351075, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.92092752456665, "episode_reward": 838.7266736378367, "step": 51000}
{"episode": 52.0, "batch_reward": 0.7630321759581565, "critic_loss": 2.179857017338276, "actor_loss": -73.44961647033692, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 515.0884120464325, "episode_reward": 853.6989392460498, "step": 52000}
{"episode": 53.0, "batch_reward": 0.7645516249537468, "critic_loss": 1.9781631808876992, "actor_loss": -73.5684595489502, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.803800582885742, "episode_reward": 831.267482615331, "step": 53000}
{"episode": 54.0, "batch_reward": 0.766479759812355, "critic_loss": 1.9320940551757813, "actor_loss": -73.58135861206054, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 466.9182324409485, "episode_reward": 877.2549464194228, "step": 54000}
{"episode": 55.0, "batch_reward": 0.7687740350961685, "critic_loss": 1.855763674199581, "actor_loss": -73.69041093444824, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 26.918285846710205, "episode_reward": 845.1071109125953, "step": 55000}
{"episode": 56.0, "batch_reward": 0.7675266507267952, "critic_loss": 2.144522457897663, "actor_loss": -73.53244140625, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 543.5106031894684, "episode_reward": 756.6650319196161, "step": 56000}
{"episode": 57.0, "batch_reward": 0.7683105574846267, "critic_loss": 2.2906989977359773, "actor_loss": -73.60008633422852, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.426063060760498, "episode_reward": 784.3436851525084, "step": 57000}
{"episode": 58.0, "batch_reward": 0.768609066426754, "critic_loss": 2.522368754506111, "actor_loss": -73.77930583190918, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 538.4082729816437, "episode_reward": 779.8730662974486, "step": 58000}
{"episode": 59.0, "batch_reward": 0.7695299357771873, "critic_loss": 2.6526512610912323, "actor_loss": -73.86932920837403, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.992289066314697, "episode_reward": 845.4692255510739, "step": 59000}
{"episode": 60.0, "batch_reward": 0.7709326118230819, "critic_loss": 2.760587610721588, "actor_loss": -73.81015084838867, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 519.4050960540771, "episode_reward": 778.2757711484767, "step": 60000}
{"episode": 61.0, "batch_reward": 0.7693408556580543, "critic_loss": 2.7506790335178377, "actor_loss": -73.74875918579102, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 47.98546266555786, "episode_reward": 777.3989509995773, "step": 61000}
{"episode": 62.0, "batch_reward": 0.7699789907932282, "critic_loss": 2.924536588191986, "actor_loss": -73.35132678222656, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 514.4887466430664, "episode_reward": 767.3764845488544, "step": 62000}
{"episode": 63.0, "batch_reward": 0.7712774125933647, "critic_loss": 2.8529088941812515, "actor_loss": -73.39942858886718, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.8154559135437, "episode_reward": 818.1850876647404, "step": 63000}
{"episode": 64.0, "batch_reward": 0.7702868630290032, "critic_loss": 2.9857160526514055, "actor_loss": -73.25484559631347, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 527.1374280452728, "episode_reward": 754.1899970190932, "step": 64000}
{"episode": 65.0, "batch_reward": 0.7709725033640862, "critic_loss": 3.5317913370132445, "actor_loss": -73.30694876098633, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.262458562850952, "episode_reward": 838.7161419645355, "step": 65000}
{"episode": 66.0, "batch_reward": 0.7716628457307816, "critic_loss": 3.606500634074211, "actor_loss": -73.05532649230958, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 524.0503368377686, "episode_reward": 824.3083214768164, "step": 66000}
{"episode": 67.0, "batch_reward": 0.7728923110365867, "critic_loss": 3.4136399354934692, "actor_loss": -73.07291439819336, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.750295400619507, "episode_reward": 862.4628778841289, "step": 67000}
{"episode": 68.0, "batch_reward": 0.7751256906986237, "critic_loss": 3.451793730735779, "actor_loss": -73.11096055603028, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 519.5493516921997, "episode_reward": 844.2441671296552, "step": 68000}
{"episode": 69.0, "batch_reward": 0.77434673422575, "critic_loss": 3.6137396261692047, "actor_loss": -73.16160270690918, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 26.607755184173584, "episode_reward": 833.054690754866, "step": 69000}
{"episode": 70.0, "batch_reward": 0.7746506958603859, "critic_loss": 3.3239136431217196, "actor_loss": -73.29948747253418, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 500.37644815444946, "episode_reward": 778.9727439216272, "step": 70000}
{"episode": 71.0, "batch_reward": 0.7753690567016601, "critic_loss": 3.202210005402565, "actor_loss": -73.32542994689942, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 46.68924927711487, "episode_reward": 819.932248700898, "step": 71000}
{"episode": 72.0, "batch_reward": 0.7765707228183746, "critic_loss": 3.222070193886757, "actor_loss": -72.40373318481446, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 486.81604981422424, "episode_reward": 849.4883383245983, "step": 72000}
{"episode": 73.0, "batch_reward": 0.7785374726653099, "critic_loss": 2.9664881335496904, "actor_loss": -72.48177796936035, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 24.55009126663208, "episode_reward": 824.6942453976558, "step": 73000}
{"episode": 74.0, "batch_reward": 0.7777199407219887, "critic_loss": 3.0461005123853684, "actor_loss": -71.85502362060546, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 537.1574411392212, "episode_reward": 826.5473151247094, "step": 74000}
{"episode": 75.0, "batch_reward": 0.7800073308348656, "critic_loss": 2.983751657485962, "actor_loss": -72.00158525085449, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.8936448097229, "episode_reward": 817.2344037757748, "step": 75000}
{"episode": 76.0, "batch_reward": 0.7776430317163467, "critic_loss": 3.158166800618172, "actor_loss": -71.43282008361817, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 527.2012758255005, "episode_reward": 783.6284842547669, "step": 76000}
{"episode": 77.0, "batch_reward": 0.7796145488023758, "critic_loss": 3.2537571927309035, "actor_loss": -71.5302138671875, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.682916402816772, "episode_reward": 792.1363777390271, "step": 77000}
{"episode": 78.0, "batch_reward": 0.7794690728783608, "critic_loss": 3.39905366563797, "actor_loss": -71.57801239013672, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 504.78943729400635, "episode_reward": 854.6732320299213, "step": 78000}
{"episode": 79.0, "batch_reward": 0.7796656602025032, "critic_loss": 3.372087100625038, "actor_loss": -71.72139646911621, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 28.11191725730896, "episode_reward": 839.3654931905086, "step": 79000}
{"episode": 80.0, "batch_reward": 0.7818654606342316, "critic_loss": 3.2867284890413284, "actor_loss": -71.86376765441895, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 461.17554473876953, "episode_reward": 823.026832961517, "step": 80000}
{"episode": 81.0, "batch_reward": 0.7819073410630226, "critic_loss": 2.9664641057252883, "actor_loss": -71.9033270111084, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 39.5489182472229, "episode_reward": 788.6447980058372, "step": 81000}
{"episode": 82.0, "batch_reward": 0.7827521719932556, "critic_loss": 2.4620409953594207, "actor_loss": -71.97963127136231, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 486.29181957244873, "episode_reward": 843.2928241692724, "step": 82000}
{"episode": 83.0, "batch_reward": 0.7836199285387992, "critic_loss": 2.1207361773252487, "actor_loss": -71.9886821899414, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.901440620422363, "episode_reward": 850.282517380134, "step": 83000}
{"episode": 84.0, "batch_reward": 0.7830630655288696, "critic_loss": 1.9402792660593986, "actor_loss": -71.6067518157959, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 480.28804087638855, "episode_reward": 798.7291941545255, "step": 84000}
{"episode": 85.0, "batch_reward": 0.7841932018995285, "critic_loss": 1.802331786632538, "actor_loss": -71.61700161743164, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 29.98624086380005, "episode_reward": 798.7134985994926, "step": 85000}
{"episode": 86.0, "batch_reward": 0.7839584420323372, "critic_loss": 1.7766917171478271, "actor_loss": -71.62626647949219, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 524.0900986194611, "episode_reward": 851.8068045919359, "step": 86000}
{"episode": 87.0, "batch_reward": 0.7848634949922562, "critic_loss": 1.6980171985030175, "actor_loss": -71.56828652954101, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 26.745051383972168, "episode_reward": 883.2835596534937, "step": 87000}
{"episode": 88.0, "batch_reward": 0.7872390490174294, "critic_loss": 1.5793452707529068, "actor_loss": -71.58187590026856, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 502.3982787132263, "episode_reward": 879.0007781301925, "step": 88000}
{"episode": 89.0, "batch_reward": 0.7862858206629754, "critic_loss": 1.5386194176673889, "actor_loss": -71.55240071105958, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.89493155479431, "episode_reward": 848.5002359172438, "step": 89000}
{"episode": 90.0, "batch_reward": 0.7881124244332314, "critic_loss": 1.5928270340561868, "actor_loss": -71.44829652404785, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 517.2687475681305, "episode_reward": 819.4495995457435, "step": 90000}
{"episode": 91.0, "batch_reward": 0.7881363814473152, "critic_loss": 1.526797021985054, "actor_loss": -71.4668464050293, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.75410318374634, "episode_reward": 885.7373238843994, "step": 91000}
{"episode": 92.0, "batch_reward": 0.7883486354351044, "critic_loss": 1.5382797726392745, "actor_loss": -71.67618013000488, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 500.419460773468, "episode_reward": 773.4614745617262, "step": 92000}
{"episode": 93.0, "batch_reward": 0.7888164348602295, "critic_loss": 1.40350473600626, "actor_loss": -71.73009626770019, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.097352743148804, "episode_reward": 853.4683090825876, "step": 93000}
{"episode": 94.0, "batch_reward": 0.7889496065974235, "critic_loss": 1.3943144452869891, "actor_loss": -71.87810989379882, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 497.84795594215393, "episode_reward": 836.1725891803653, "step": 94000}
{"episode": 95.0, "batch_reward": 0.7892595857381821, "critic_loss": 1.4352629182338714, "actor_loss": -71.93970118713379, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 22.893426179885864, "episode_reward": 800.4822293400341, "step": 95000}
{"episode": 96.0, "batch_reward": 0.7905348040461541, "critic_loss": 1.4220587084293366, "actor_loss": -71.43973512268066, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 531.5393877029419, "episode_reward": 873.3202317779109, "step": 96000}
{"episode": 97.0, "batch_reward": 0.7930243655443191, "critic_loss": 1.2193841065764428, "actor_loss": -71.5054309539795, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 26.972050189971924, "episode_reward": 882.3608733002549, "step": 97000}
{"episode": 98.0, "batch_reward": 0.7925550503730774, "critic_loss": 1.1758045996427535, "actor_loss": -71.6173611907959, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 505.79478430747986, "episode_reward": 890.5538040311964, "step": 98000}
{"episode": 99.0, "batch_reward": 0.7942354348301888, "critic_loss": 1.1181239456236363, "actor_loss": -71.65134886169433, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.915131330490112, "episode_reward": 895.869996834188, "step": 99000}
{"episode": 100.0, "batch_reward": 0.7939181477427483, "critic_loss": 1.1194291765391826, "actor_loss": -71.56265327453613, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 519.6336929798126, "episode_reward": 863.9505982779835, "step": 100000}
{"episode": 101.0, "batch_reward": 0.7954930209517479, "critic_loss": 1.0653324199914933, "actor_loss": -71.62851956176758, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 47.22343683242798, "episode_reward": 875.5539033937752, "step": 101000}
{"episode": 102.0, "batch_reward": 0.7964297680258751, "critic_loss": 1.0115374678075313, "actor_loss": -71.28932284545898, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 527.8429284095764, "episode_reward": 878.4721771695985, "step": 102000}
{"episode": 103.0, "batch_reward": 0.7964836490750313, "critic_loss": 0.9971573609411717, "actor_loss": -71.33185113525391, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 26.282923936843872, "episode_reward": 816.9784071183112, "step": 103000}
{"episode": 104.0, "batch_reward": 0.7963743261694908, "critic_loss": 0.968245075583458, "actor_loss": -71.81088494873048, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 496.1184673309326, "episode_reward": 859.1618725285483, "step": 104000}
{"episode": 105.0, "batch_reward": 0.7959271055459977, "critic_loss": 0.9227989051043988, "actor_loss": -71.82448181152344, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 26.00215983390808, "episode_reward": 825.6298577221949, "step": 105000}
{"episode": 106.0, "batch_reward": 0.7982977162599564, "critic_loss": 0.9152064819037914, "actor_loss": -72.10834184265137, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 488.26465940475464, "episode_reward": 877.0211896985949, "step": 106000}
{"episode": 107.0, "batch_reward": 0.7974752414822578, "critic_loss": 0.9902084076404571, "actor_loss": -72.13114233398437, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.661925792694092, "episode_reward": 800.0467397116224, "step": 107000}
{"episode": 108.0, "batch_reward": 0.7985604994297028, "critic_loss": 1.0273482497930526, "actor_loss": -71.96354457092285, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 502.7769010066986, "episode_reward": 831.8026774427925, "step": 108000}
{"episode": 109.0, "batch_reward": 0.7995865272879601, "critic_loss": 1.0199399893283845, "actor_loss": -72.05368901062012, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 26.151964902877808, "episode_reward": 787.500208969237, "step": 109000}
{"episode": 110.0, "batch_reward": 0.7990335764884948, "critic_loss": 0.940910962432623, "actor_loss": -72.22304870605468, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 512.0919644832611, "episode_reward": 834.0918333344276, "step": 110000}
{"episode": 111.0, "batch_reward": 0.7994740707278252, "critic_loss": 1.0184602694511413, "actor_loss": -72.25922929382324, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 44.590736627578735, "episode_reward": 853.0421275321664, "step": 111000}
{"episode": 112.0, "batch_reward": 0.799378674685955, "critic_loss": 1.0791825093626977, "actor_loss": -72.07435443115234, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 529.2451603412628, "episode_reward": 849.1428340315613, "step": 112000}
{"episode": 113.0, "batch_reward": 0.8008904747366905, "critic_loss": 1.090647129178047, "actor_loss": -72.14198876953125, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 25.40506148338318, "episode_reward": 861.4623984084056, "step": 113000}
{"episode": 114.0, "batch_reward": 0.7994217027425766, "critic_loss": 1.1595242609083654, "actor_loss": -72.00712078857421, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 509.3151071071625, "episode_reward": 851.9017567546621, "step": 114000}
{"episode": 115.0, "batch_reward": 0.8005196321010589, "critic_loss": 1.0434661375284195, "actor_loss": -72.15351989746094, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.091169595718384, "episode_reward": 859.6875189617282, "step": 115000}
{"episode": 116.0, "batch_reward": 0.7999619064927102, "critic_loss": 1.0678805220127106, "actor_loss": -72.26203445434571, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 483.46868777275085, "episode_reward": 877.1817368374009, "step": 116000}
{"episode": 117.0, "batch_reward": 0.8019504057765007, "critic_loss": 1.0428642196059228, "actor_loss": -72.2915068359375, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.504087686538696, "episode_reward": 862.6423085981078, "step": 117000}
{"episode": 118.0, "batch_reward": 0.8008016428351402, "critic_loss": 1.0951837580502033, "actor_loss": -72.58073696899415, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 556.9161412715912, "episode_reward": 801.5228682105869, "step": 118000}
{"episode": 119.0, "batch_reward": 0.801925656914711, "critic_loss": 1.0834221268296242, "actor_loss": -72.63140213012696, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 26.727097034454346, "episode_reward": 853.6843468285076, "step": 119000}
{"episode": 120.0, "batch_reward": 0.8029877067804336, "critic_loss": 1.0143241054713725, "actor_loss": -72.78460475158691, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 487.865562915802, "episode_reward": 876.8191898398344, "step": 120000}
{"episode": 121.0, "batch_reward": 0.801838774740696, "critic_loss": 0.9984644504487514, "actor_loss": -72.84179899597169, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 48.88989472389221, "episode_reward": 856.0426699365009, "step": 121000}
{"episode": 122.0, "batch_reward": 0.8034652444124222, "critic_loss": 0.9973334666490555, "actor_loss": -72.97346006774902, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 480.86082005500793, "episode_reward": 839.1599291110232, "step": 122000}
{"episode": 123.0, "batch_reward": 0.8027307633757591, "critic_loss": 1.0576508273780345, "actor_loss": -72.95044874572754, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 23.475808143615723, "episode_reward": 829.5591139610066, "step": 123000}
{"episode": 124.0, "batch_reward": 0.8061716966032982, "critic_loss": 0.9655121805369854, "actor_loss": -73.07806407165528, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 470.04837369918823, "episode_reward": 877.1098889020928, "step": 124000}
{"episode": 125.0, "batch_reward": 0.8054748997688294, "critic_loss": 0.9630999417603016, "actor_loss": -73.19159535217285, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 28.369207620620728, "episode_reward": 867.9880899083801, "step": 125000}
{"episode": 126.0, "batch_reward": 0.8070446031689644, "critic_loss": 1.0243460846543313, "actor_loss": -73.07449331665039, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 487.69304394721985, "episode_reward": 861.9805182920524, "step": 126000}
{"episode": 127.0, "batch_reward": 0.8058543566465378, "critic_loss": 1.0539003860652447, "actor_loss": -73.10908316040039, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 20.41351628303528, "episode_reward": 864.0801301518421, "step": 127000}
{"episode": 128.0, "batch_reward": 0.8054974464178085, "critic_loss": 1.0218233027160168, "actor_loss": -73.22630686950684, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 465.1082396507263, "episode_reward": 872.8914483980491, "step": 128000}
{"episode": 129.0, "batch_reward": 0.8075098361968994, "critic_loss": 1.1265635155141354, "actor_loss": -73.24049961853028, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 21.337007999420166, "episode_reward": 840.9056436013623, "step": 129000}
{"episode": 130.0, "batch_reward": 0.8066201496124268, "critic_loss": 1.0887614078819752, "actor_loss": -73.23878414916992, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 539.1416954994202, "episode_reward": 830.5035624415033, "step": 130000}
{"episode": 131.0, "batch_reward": 0.8083922221660614, "critic_loss": 1.0517431312203407, "actor_loss": -73.3059220275879, "actor_target_entropy": -6.0, "alpha_value": 0.0048391611892268475, "duration": 40.185404539108276, "episode_reward": 868.6768286912888, "step": 131000}
