{"episode": 1.0, "duration": 20.18383526802063, "episode_reward": 51.16415125024753, "step": 1000}
{"episode": 2.0, "duration": 1.7557530403137207, "episode_reward": 519.9299312670827, "step": 2000}
{"episode": 3.0, "batch_reward": 0.3179652828321969, "critic_loss": 0.6541836077807625, "actor_loss": -69.30726085294958, "actor_target_entropy": -6.0, "alpha_value": 0.00389112377954371, "duration": 77.16332483291626, "episode_reward": 828.7603412266413, "step": 3000}
{"episode": 4.0, "batch_reward": 0.4816834092736244, "critic_loss": 1.1707352707087995, "actor_loss": -74.63919206237793, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 25.217449426651, "episode_reward": 569.9887576509361, "step": 4000}
{"episode": 5.0, "batch_reward": 0.5199619203209876, "critic_loss": 1.0921451363563537, "actor_loss": -75.84963008117676, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 25.233577489852905, "episode_reward": 814.8632358375265, "step": 5000}
{"episode": 6.0, "batch_reward": 0.5798804313540459, "critic_loss": 0.994731482565403, "actor_loss": -77.7810144958496, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 25.379387617111206, "episode_reward": 842.7443019595809, "step": 6000}
{"episode": 7.0, "batch_reward": 0.6015508110523224, "critic_loss": 1.1441651690602304, "actor_loss": -78.35493217468262, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 25.31519365310669, "episode_reward": 590.1338432827357, "step": 7000}
{"episode": 8.0, "batch_reward": 0.5973289607167244, "critic_loss": 1.310868517458439, "actor_loss": -78.2901510925293, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 25.25981044769287, "episode_reward": 623.4663896297238, "step": 8000}
{"episode": 9.0, "batch_reward": 0.6132445450425148, "critic_loss": 1.3361745089888573, "actor_loss": -78.76792428588867, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 25.480870485305786, "episode_reward": 726.5875060382057, "step": 9000}
{"episode": 10.0, "batch_reward": 0.625953162074089, "critic_loss": 1.4776570852398871, "actor_loss": -74.7806395111084, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 4235.274922370911, "episode_reward": 824.0701845433476, "step": 10000}
{"episode": 11.0, "batch_reward": 0.6470181304216385, "critic_loss": 1.385522511959076, "actor_loss": -75.65436552429199, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.281986713409424, "episode_reward": 843.3523525050878, "step": 11000}
{"episode": 12.0, "batch_reward": 0.6657944881319999, "critic_loss": 1.3510723743438722, "actor_loss": -74.50818516540528, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 495.1075484752655, "episode_reward": 829.9541383796976, "step": 12000}
{"episode": 13.0, "batch_reward": 0.676187368452549, "critic_loss": 1.3383166643977165, "actor_loss": -74.94560731506348, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.06256937980652, "episode_reward": 815.6551324350158, "step": 13000}
{"episode": 14.0, "batch_reward": 0.687043944299221, "critic_loss": 1.4005039210915566, "actor_loss": -74.60708052062988, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 485.49366426467896, "episode_reward": 844.8298189920732, "step": 14000}
{"episode": 15.0, "batch_reward": 0.7017865836024284, "critic_loss": 1.4126104035377502, "actor_loss": -75.21655839538575, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 25.360724449157715, "episode_reward": 875.1767631912809, "step": 15000}
{"episode": 16.0, "batch_reward": 0.7102948402166367, "critic_loss": 1.2867814051508903, "actor_loss": -74.94581503295899, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 512.807044506073, "episode_reward": 877.2954663606755, "step": 16000}
{"episode": 17.0, "batch_reward": 0.719921264886856, "critic_loss": 1.2937468834519386, "actor_loss": -75.37354876708984, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.51402735710144, "episode_reward": 846.4182747216622, "step": 17000}
{"episode": 18.0, "batch_reward": 0.7264624131917954, "critic_loss": 1.3001057525277138, "actor_loss": -75.2700108947754, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 495.1782896518707, "episode_reward": 818.9788993495815, "step": 18000}
{"episode": 19.0, "batch_reward": 0.7331506643891335, "critic_loss": 1.2889510254263878, "actor_loss": -75.66503527832032, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 25.29524254798889, "episode_reward": 869.1597918538805, "step": 19000}
{"episode": 20.0, "batch_reward": 0.7387809641957283, "critic_loss": 1.3469530596137047, "actor_loss": -75.39409986877442, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 507.71352982521057, "episode_reward": 844.192940253246, "step": 20000}
{"episode": 21.0, "batch_reward": 0.74602582269907, "critic_loss": 1.3892037434577942, "actor_loss": -75.69595750427246, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 44.94149827957153, "episode_reward": 887.0548232726871, "step": 21000}
{"episode": 22.0, "batch_reward": 0.7498375276923179, "critic_loss": 1.699168563246727, "actor_loss": -75.7273709411621, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 499.224417924881, "episode_reward": 829.312304144233, "step": 22000}
{"episode": 23.0, "batch_reward": 0.7512872809767723, "critic_loss": 1.9779280350208281, "actor_loss": -75.7636640625, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.030056953430176, "episode_reward": 758.3948710993957, "step": 23000}
{"episode": 24.0, "batch_reward": 0.7549549278616905, "critic_loss": 2.0419426176548003, "actor_loss": -75.70486383056641, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 497.0250942707062, "episode_reward": 859.444611876856, "step": 24000}
{"episode": 25.0, "batch_reward": 0.7580575630068779, "critic_loss": 2.2319754804372787, "actor_loss": -75.93105366516113, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.14088797569275, "episode_reward": 842.9732930103092, "step": 25000}
{"episode": 26.0, "batch_reward": 0.761064977824688, "critic_loss": 2.4963424228429796, "actor_loss": -74.80846919250489, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 482.4394257068634, "episode_reward": 717.6046455871336, "step": 26000}
{"episode": 27.0, "batch_reward": 0.7579354446530342, "critic_loss": 3.4275550858974455, "actor_loss": -74.757158203125, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.282007694244385, "episode_reward": 754.6664444464205, "step": 27000}
{"episode": 28.0, "batch_reward": 0.7552636253833771, "critic_loss": 3.7590378329753875, "actor_loss": -73.82639524841309, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 475.72812962532043, "episode_reward": 689.3876071311996, "step": 28000}
{"episode": 29.0, "batch_reward": 0.7605508820414543, "critic_loss": 4.085335416078568, "actor_loss": -74.07028877258301, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 25.080503702163696, "episode_reward": 880.8497773355183, "step": 29000}
{"episode": 30.0, "batch_reward": 0.7586687198281288, "critic_loss": 4.012285428762436, "actor_loss": -73.12166320800782, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 461.2539801597595, "episode_reward": 807.5907664012453, "step": 30000}
{"episode": 31.0, "batch_reward": 0.7632573004961014, "critic_loss": 4.330212485313416, "actor_loss": -73.34427349853516, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 44.62064170837402, "episode_reward": 821.2999839909045, "step": 31000}
{"episode": 32.0, "batch_reward": 0.7645890100002288, "critic_loss": 4.625084059119224, "actor_loss": -72.81248799133301, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 488.8270981311798, "episode_reward": 795.8067949269689, "step": 32000}
{"episode": 33.0, "batch_reward": 0.7652762306928634, "critic_loss": 4.4999939835071565, "actor_loss": -72.8826248626709, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.793203592300415, "episode_reward": 834.6147849181697, "step": 33000}
{"episode": 34.0, "batch_reward": 0.7661713507771492, "critic_loss": 4.5278540823459625, "actor_loss": -72.4589329071045, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 445.8986461162567, "episode_reward": 780.0770359342151, "step": 34000}
{"episode": 35.0, "batch_reward": 0.7696412366628647, "critic_loss": 4.4186700856685635, "actor_loss": -72.63105397033691, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.81298542022705, "episode_reward": 823.0018357878763, "step": 35000}
{"episode": 36.0, "batch_reward": 0.7694999585151673, "critic_loss": 4.737646602869034, "actor_loss": -72.65872053527832, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 443.1106581687927, "episode_reward": 845.0356800773958, "step": 36000}
{"episode": 37.0, "batch_reward": 0.772918604850769, "critic_loss": 4.4368058775663375, "actor_loss": -72.70328031921386, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 25.17414164543152, "episode_reward": 813.1742364060106, "step": 37000}
{"episode": 38.0, "batch_reward": 0.7746755854487419, "critic_loss": 4.596157892227173, "actor_loss": -72.11151501464843, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 488.7620425224304, "episode_reward": 845.0769014431613, "step": 38000}
{"episode": 39.0, "batch_reward": 0.7704701371192932, "critic_loss": 5.205483186960221, "actor_loss": -71.99431044006347, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.627527713775635, "episode_reward": 505.4186122397244, "step": 39000}
{"episode": 40.0, "batch_reward": 0.7648198764324188, "critic_loss": 6.517210683584214, "actor_loss": -71.18974787902832, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 484.6826288700104, "episode_reward": 490.94180326503624, "step": 40000}
{"episode": 41.0, "batch_reward": 0.7586116027832032, "critic_loss": 8.093115645170212, "actor_loss": -70.9852841796875, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 38.65230631828308, "episode_reward": 670.0862621844965, "step": 41000}
{"episode": 42.0, "batch_reward": 0.7564447215795517, "critic_loss": 9.762756449222564, "actor_loss": -70.63856448364258, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 454.26539945602417, "episode_reward": 553.1384311437698, "step": 42000}
{"episode": 43.0, "batch_reward": 0.750725725710392, "critic_loss": 10.780999098777771, "actor_loss": -70.45473489379883, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.26269555091858, "episode_reward": 571.1431958769206, "step": 43000}
{"episode": 44.0, "batch_reward": 0.7481810488700866, "critic_loss": 11.835679275989532, "actor_loss": -70.11156196594239, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 438.5764591693878, "episode_reward": 643.219796645637, "step": 44000}
{"episode": 45.0, "batch_reward": 0.7459661063551902, "critic_loss": 12.374523249149323, "actor_loss": -69.9917724609375, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.622376918792725, "episode_reward": 712.442444057222, "step": 45000}
{"episode": 46.0, "batch_reward": 0.7464499844908714, "critic_loss": 12.806493196010589, "actor_loss": -69.66213491821289, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 461.80722188949585, "episode_reward": 676.2701553663348, "step": 46000}
{"episode": 47.0, "batch_reward": 0.7442432597279549, "critic_loss": 12.967718060970306, "actor_loss": -69.53623265075683, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.97664737701416, "episode_reward": 610.4076846132486, "step": 47000}
{"episode": 48.0, "batch_reward": 0.7403866249322891, "critic_loss": 13.320494751930237, "actor_loss": -69.44336758422851, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 467.0436179637909, "episode_reward": 519.0444843220322, "step": 48000}
{"episode": 49.0, "batch_reward": 0.7348455673456192, "critic_loss": 13.332096826553345, "actor_loss": -69.23130081176758, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.51195478439331, "episode_reward": 568.0695429204237, "step": 49000}
{"episode": 50.0, "batch_reward": 0.7319539785385132, "critic_loss": 13.790542418956756, "actor_loss": -69.29799607849121, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 459.0759479999542, "episode_reward": 540.2174201310954, "step": 50000}
{"episode": 51.0, "batch_reward": 0.7296766058802605, "critic_loss": 13.784231143474578, "actor_loss": -69.2191803894043, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 40.11583065986633, "episode_reward": 671.0800422348907, "step": 51000}
{"episode": 52.0, "batch_reward": 0.7270053426623344, "critic_loss": 14.435766181468964, "actor_loss": -69.0792921218872, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 448.7615432739258, "episode_reward": 704.2769108340714, "step": 52000}
{"episode": 53.0, "batch_reward": 0.7256930454969406, "critic_loss": 14.833231101989746, "actor_loss": -69.04442042541504, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.800766468048096, "episode_reward": 657.8830822116456, "step": 53000}
{"episode": 54.0, "batch_reward": 0.7263508795499801, "critic_loss": 15.79007400894165, "actor_loss": -68.81987838745117, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 419.92635321617126, "episode_reward": 741.0003052203435, "step": 54000}
{"episode": 55.0, "batch_reward": 0.7261847441196442, "critic_loss": 15.225967172622681, "actor_loss": -68.87923809814453, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.23623776435852, "episode_reward": 755.0558944383318, "step": 55000}
{"episode": 56.0, "batch_reward": 0.727399464726448, "critic_loss": 14.448510809898377, "actor_loss": -69.80320988464355, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 490.71383690834045, "episode_reward": 826.3929985085995, "step": 56000}
{"episode": 57.0, "batch_reward": 0.7295747745037079, "critic_loss": 13.789185177326202, "actor_loss": -69.98367637634277, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.206377744674683, "episode_reward": 795.9852561656671, "step": 57000}
{"episode": 58.0, "batch_reward": 0.7298776704072952, "critic_loss": 13.425759851932526, "actor_loss": -70.16357690429687, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 480.59154176712036, "episode_reward": 759.5188025847755, "step": 58000}
{"episode": 59.0, "batch_reward": 0.7330606853961945, "critic_loss": 12.665546705722809, "actor_loss": -70.44265617370606, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.89828658103943, "episode_reward": 878.3922942431178, "step": 59000}
{"episode": 60.0, "batch_reward": 0.7336264915466308, "critic_loss": 11.940824949741364, "actor_loss": -70.28509593200684, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 437.5413467884064, "episode_reward": 822.8280505724823, "step": 60000}
{"episode": 61.0, "batch_reward": 0.7357300325632096, "critic_loss": 12.235305320262908, "actor_loss": -70.37166891479492, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 41.07052969932556, "episode_reward": 830.8957498771584, "step": 61000}
{"episode": 62.0, "batch_reward": 0.7375761065483093, "critic_loss": 13.53578137254715, "actor_loss": -70.23144734191895, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 443.25265979766846, "episode_reward": 808.5214511318997, "step": 62000}
{"episode": 63.0, "batch_reward": 0.7377725847959519, "critic_loss": 15.255950109004974, "actor_loss": -70.18754740905761, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.158321142196655, "episode_reward": 743.2003300613072, "step": 63000}
{"episode": 64.0, "batch_reward": 0.7376822103261947, "critic_loss": 15.674072734832764, "actor_loss": -70.01449668884277, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 469.4134113788605, "episode_reward": 697.8646465503863, "step": 64000}
{"episode": 65.0, "batch_reward": 0.7370667198300361, "critic_loss": 16.673970544338225, "actor_loss": -70.03938679504394, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.4687979221344, "episode_reward": 678.9465126590349, "step": 65000}
{"episode": 66.0, "batch_reward": 0.7374811284542083, "critic_loss": 17.678672473907472, "actor_loss": -69.63508279418946, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 464.99370312690735, "episode_reward": 801.7291961942777, "step": 66000}
{"episode": 67.0, "batch_reward": 0.7367576867341995, "critic_loss": 18.6643633852005, "actor_loss": -69.51191856384277, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.61069083213806, "episode_reward": 763.7416573901858, "step": 67000}
{"episode": 68.0, "batch_reward": 0.7394689989686012, "critic_loss": 19.240961550712587, "actor_loss": -69.62969934082031, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 492.28377771377563, "episode_reward": 764.9490016573296, "step": 68000}
{"episode": 69.0, "batch_reward": 0.7387835718989372, "critic_loss": 20.021025703430176, "actor_loss": -69.62135328674316, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 25.241386890411377, "episode_reward": 804.7805804181156, "step": 69000}
{"episode": 70.0, "batch_reward": 0.7384546139240264, "critic_loss": 20.782978937149046, "actor_loss": -69.85808320617676, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 472.6229622364044, "episode_reward": 764.8941663686431, "step": 70000}
{"episode": 71.0, "batch_reward": 0.7407235535383224, "critic_loss": 19.31128437423706, "actor_loss": -69.93685342407227, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 44.99845337867737, "episode_reward": 802.527365756892, "step": 71000}
{"episode": 72.0, "batch_reward": 0.7396699960827827, "critic_loss": 18.64105971622467, "actor_loss": -70.02921853637696, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 483.5260829925537, "episode_reward": 770.2084217915789, "step": 72000}
{"episode": 73.0, "batch_reward": 0.7410494164228439, "critic_loss": 18.72233401298523, "actor_loss": -70.08134115600586, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.27426266670227, "episode_reward": 821.0454110609053, "step": 73000}
{"episode": 74.0, "batch_reward": 0.7420992819666863, "critic_loss": 18.69187585926056, "actor_loss": -69.86271771240234, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 463.11910581588745, "episode_reward": 769.822681812234, "step": 74000}
{"episode": 75.0, "batch_reward": 0.7410949401855469, "critic_loss": 18.610070910453796, "actor_loss": -69.91801731872559, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 25.19808864593506, "episode_reward": 694.5404572137835, "step": 75000}
{"episode": 76.0, "batch_reward": 0.7415719161629677, "critic_loss": 18.525392251014708, "actor_loss": -69.62211511230468, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 494.40470933914185, "episode_reward": 710.8280761270395, "step": 76000}
{"episode": 77.0, "batch_reward": 0.7418167942762375, "critic_loss": 17.616531138420104, "actor_loss": -69.64786837768554, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.802655696868896, "episode_reward": 781.7951843566963, "step": 77000}
{"episode": 78.0, "batch_reward": 0.741380969285965, "critic_loss": 17.089687782287598, "actor_loss": -69.39057653808594, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 464.7361674308777, "episode_reward": 764.4675337048149, "step": 78000}
{"episode": 79.0, "batch_reward": 0.7414360479712486, "critic_loss": 16.220602575302124, "actor_loss": -69.40746716308594, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.4553062915802, "episode_reward": 783.783782502629, "step": 79000}
{"episode": 80.0, "batch_reward": 0.7416447746157646, "critic_loss": 15.105655105113984, "actor_loss": -69.4409176940918, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 430.8773844242096, "episode_reward": 770.6911349036077, "step": 80000}
{"episode": 81.0, "batch_reward": 0.7426198025941849, "critic_loss": 14.951619978427887, "actor_loss": -69.48395498657227, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 39.204644441604614, "episode_reward": 747.3348254144439, "step": 81000}
{"episode": 82.0, "batch_reward": 0.742343789100647, "critic_loss": 14.314352148532867, "actor_loss": -69.05296699523926, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 470.9961426258087, "episode_reward": 795.7336109321727, "step": 82000}
{"episode": 83.0, "batch_reward": 0.7451418814063072, "critic_loss": 14.153677552700042, "actor_loss": -69.26599214172363, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.627835512161255, "episode_reward": 765.890661259285, "step": 83000}
{"episode": 84.0, "batch_reward": 0.7430162785649299, "critic_loss": 13.78579752779007, "actor_loss": -68.88660070800782, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 470.8324854373932, "episode_reward": 726.7612931094488, "step": 84000}
{"episode": 85.0, "batch_reward": 0.7429157546758651, "critic_loss": 12.577168396949768, "actor_loss": -68.82482402038575, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.78638195991516, "episode_reward": 805.3894703813256, "step": 85000}
{"episode": 86.0, "batch_reward": 0.7458458051681519, "critic_loss": 12.565413608074188, "actor_loss": -68.69342794799805, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 464.4191288948059, "episode_reward": 787.8128928441361, "step": 86000}
{"episode": 87.0, "batch_reward": 0.7462152681946754, "critic_loss": 12.600709466457367, "actor_loss": -68.73551475524903, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.050516366958618, "episode_reward": 769.1912491385426, "step": 87000}
{"episode": 88.0, "batch_reward": 0.7456960847377777, "critic_loss": 12.960625221729279, "actor_loss": -68.92016546630859, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 422.6708724498749, "episode_reward": 843.46174062415, "step": 88000}
{"episode": 89.0, "batch_reward": 0.74658069896698, "critic_loss": 12.653654338359832, "actor_loss": -68.92061978149414, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.962929010391235, "episode_reward": 860.5469320742023, "step": 89000}
{"episode": 90.0, "batch_reward": 0.7494195153713227, "critic_loss": 13.212146119117737, "actor_loss": -69.01282925415039, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 450.2526824474335, "episode_reward": 858.4516571937471, "step": 90000}
{"episode": 91.0, "batch_reward": 0.7481296383142472, "critic_loss": 13.543328191280365, "actor_loss": -69.07412184143067, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 39.23439288139343, "episode_reward": 740.6728739500487, "step": 91000}
{"episode": 92.0, "batch_reward": 0.7492281782627106, "critic_loss": 12.69870403623581, "actor_loss": -69.17049841308594, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 444.37478041648865, "episode_reward": 868.4722646934258, "step": 92000}
{"episode": 93.0, "batch_reward": 0.7508553537130356, "critic_loss": 12.347091264724732, "actor_loss": -69.37092478942871, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.329916954040527, "episode_reward": 832.0975453994339, "step": 93000}
{"episode": 94.0, "batch_reward": 0.7511864092946052, "critic_loss": 12.229946686267853, "actor_loss": -69.61727482604981, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 464.0348582267761, "episode_reward": 801.184563039387, "step": 94000}
{"episode": 95.0, "batch_reward": 0.7520490553975105, "critic_loss": 11.924000444889069, "actor_loss": -69.65878283691406, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.409051656723022, "episode_reward": 817.1177380484303, "step": 95000}
{"episode": 96.0, "batch_reward": 0.7511716638803482, "critic_loss": 12.227889765739441, "actor_loss": -69.90461962890625, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 497.46287751197815, "episode_reward": 810.3921777367661, "step": 96000}
{"episode": 97.0, "batch_reward": 0.7534178184270859, "critic_loss": 12.37030242729187, "actor_loss": -70.0154687347412, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.396235704421997, "episode_reward": 807.5898603664953, "step": 97000}
{"episode": 98.0, "batch_reward": 0.7552969477772713, "critic_loss": 12.506880044937134, "actor_loss": -70.22413314819336, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 483.329651594162, "episode_reward": 807.5550987060401, "step": 98000}
{"episode": 99.0, "batch_reward": 0.7545602774620056, "critic_loss": 13.304540603637696, "actor_loss": -70.39077543640137, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.116450548171997, "episode_reward": 808.1191084948174, "step": 99000}
{"episode": 100.0, "batch_reward": 0.7539933093190193, "critic_loss": 13.092710984230042, "actor_loss": -70.50438090515136, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 459.4569203853607, "episode_reward": 795.589388118345, "step": 100000}
{"episode": 101.0, "batch_reward": 0.754925263762474, "critic_loss": 13.752173883438111, "actor_loss": -70.54728659057618, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 42.51828050613403, "episode_reward": 827.5320809944238, "step": 101000}
{"episode": 102.0, "batch_reward": 0.7556953553557396, "critic_loss": 15.22265395784378, "actor_loss": -70.49048570251465, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 448.2390983104706, "episode_reward": 870.696451550279, "step": 102000}
{"episode": 103.0, "batch_reward": 0.7555546190738678, "critic_loss": 16.58493259191513, "actor_loss": -70.50459080505371, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.992830991744995, "episode_reward": 635.7287686823827, "step": 103000}
{"episode": 104.0, "batch_reward": 0.7535020877718925, "critic_loss": 18.166017326354982, "actor_loss": -70.39365002441406, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 435.2479510307312, "episode_reward": 602.2339767096092, "step": 104000}
{"episode": 105.0, "batch_reward": 0.7551285806894302, "critic_loss": 19.72789051389694, "actor_loss": -70.56356454467773, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.914971113204956, "episode_reward": 697.3381120060023, "step": 105000}
{"episode": 106.0, "batch_reward": 0.754935626745224, "critic_loss": 22.082523628234863, "actor_loss": -70.68088514709473, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 460.278817653656, "episode_reward": 712.1059315348606, "step": 106000}
{"episode": 107.0, "batch_reward": 0.7524767360091209, "critic_loss": 24.05368071460724, "actor_loss": -70.59821218872071, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 22.023325204849243, "episode_reward": 681.6807547834022, "step": 107000}
{"episode": 108.0, "batch_reward": 0.7532290871143341, "critic_loss": 27.099156472206115, "actor_loss": -70.56684030151368, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 487.65934920310974, "episode_reward": 730.4291061505589, "step": 108000}
{"episode": 109.0, "batch_reward": 0.7527628929615021, "critic_loss": 29.64500896549225, "actor_loss": -70.4570225982666, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.852522134780884, "episode_reward": 723.8349638831753, "step": 109000}
{"episode": 110.0, "batch_reward": 0.7519919021129609, "critic_loss": 31.78337619972229, "actor_loss": -70.43473023986816, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 427.02254581451416, "episode_reward": 757.1862610903186, "step": 110000}
{"episode": 111.0, "batch_reward": 0.7520081558823586, "critic_loss": 33.80003483390808, "actor_loss": -70.46210060119628, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 39.18830871582031, "episode_reward": 701.4406687937961, "step": 111000}
{"episode": 112.0, "batch_reward": 0.7517430455088615, "critic_loss": 35.46238304805755, "actor_loss": -70.62376210021972, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 454.1823229789734, "episode_reward": 865.489319490644, "step": 112000}
{"episode": 113.0, "batch_reward": 0.7514819911122322, "critic_loss": 31.802435242652894, "actor_loss": -70.56012655639648, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.797475814819336, "episode_reward": 741.754254349258, "step": 113000}
{"episode": 114.0, "batch_reward": 0.7528667169213294, "critic_loss": 29.168735016822815, "actor_loss": -71.01332319641114, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 426.8510241508484, "episode_reward": 878.6657076501776, "step": 114000}
{"episode": 115.0, "batch_reward": 0.7530185423493385, "critic_loss": 27.30566625213623, "actor_loss": -71.0896979675293, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 21.345914840698242, "episode_reward": 789.3735949852233, "step": 115000}
{"episode": 116.0, "batch_reward": 0.7536343337893486, "critic_loss": 27.771306373596193, "actor_loss": -71.51115338134765, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 459.61035323143005, "episode_reward": 861.1145078246345, "step": 116000}
{"episode": 117.0, "batch_reward": 0.7533815721869469, "critic_loss": 27.459565156936645, "actor_loss": -71.57982919311523, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.148062467575073, "episode_reward": 830.2843558395928, "step": 117000}
{"episode": 118.0, "batch_reward": 0.7561563726663589, "critic_loss": 26.386279155731202, "actor_loss": -72.22858203125, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 446.49236154556274, "episode_reward": 887.3045773371215, "step": 118000}
{"episode": 119.0, "batch_reward": 0.7572969664335251, "critic_loss": 25.331728055000305, "actor_loss": -72.34414042663575, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.326607704162598, "episode_reward": 892.6281216622205, "step": 119000}
{"episode": 120.0, "batch_reward": 0.7565672810673714, "critic_loss": 23.968313528060914, "actor_loss": -72.60594732666016, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 441.2517035007477, "episode_reward": 889.252848395489, "step": 120000}
{"episode": 121.0, "batch_reward": 0.7593441022634506, "critic_loss": 21.333392696380614, "actor_loss": -72.82386192321778, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 39.237549781799316, "episode_reward": 831.3371725787246, "step": 121000}
{"episode": 122.0, "batch_reward": 0.7603411763906479, "critic_loss": 19.53721876811981, "actor_loss": -73.14526460266113, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 466.9822630882263, "episode_reward": 836.0515314019826, "step": 122000}
{"episode": 123.0, "batch_reward": 0.7587640764713287, "critic_loss": 18.08160795736313, "actor_loss": -73.12748945617676, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 25.080366134643555, "episode_reward": 875.6527634939002, "step": 123000}
{"episode": 124.0, "batch_reward": 0.761864309489727, "critic_loss": 17.837264917373655, "actor_loss": -73.0977019958496, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 484.00077772140503, "episode_reward": 887.3566993267336, "step": 124000}
{"episode": 125.0, "batch_reward": 0.7631270409226417, "critic_loss": 18.044911865234376, "actor_loss": -73.19322531127929, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.063926696777344, "episode_reward": 875.166783209476, "step": 125000}
{"episode": 126.0, "batch_reward": 0.7644848501086235, "critic_loss": 17.809739651679994, "actor_loss": -72.4474774017334, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 492.64616107940674, "episode_reward": 877.834079583633, "step": 126000}
{"episode": 127.0, "batch_reward": 0.764872632086277, "critic_loss": 16.87010309123993, "actor_loss": -72.48511671447754, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.31659436225891, "episode_reward": 853.0866194442663, "step": 127000}
{"episode": 128.0, "batch_reward": 0.7640596505403519, "critic_loss": 16.897341887950898, "actor_loss": -71.59427201843262, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 471.55784845352173, "episode_reward": 901.3227259806474, "step": 128000}
{"episode": 129.0, "batch_reward": 0.7643335866332054, "critic_loss": 16.560587406158447, "actor_loss": -71.6419934539795, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 23.61638045310974, "episode_reward": 833.7550787694564, "step": 129000}
{"episode": 130.0, "batch_reward": 0.7642627510428429, "critic_loss": 17.367394114971162, "actor_loss": -71.44963500976563, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 452.90825963020325, "episode_reward": 810.0350527129708, "step": 130000}
{"episode": 131.0, "batch_reward": 0.7665654096007347, "critic_loss": 17.463410635471345, "actor_loss": -71.57024291992188, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 39.46209979057312, "episode_reward": 837.1339189124792, "step": 131000}
{"episode": 132.0, "batch_reward": 0.7671883312463761, "critic_loss": 17.468828553676605, "actor_loss": -71.48829859924317, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 479.83821058273315, "episode_reward": 792.4622691577454, "step": 132000}
{"episode": 133.0, "batch_reward": 0.766878623008728, "critic_loss": 17.062389640808107, "actor_loss": -71.5727707824707, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 24.483558416366577, "episode_reward": 886.0436058058777, "step": 133000}
{"episode": 134.0, "batch_reward": 0.7675024689435959, "critic_loss": 16.592132255554198, "actor_loss": -71.37423330688476, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 482.0778295993805, "episode_reward": 801.4873996446271, "step": 134000}
{"episode": 135.0, "batch_reward": 0.7682698873281479, "critic_loss": 16.055285645484926, "actor_loss": -71.43354220581055, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 19.825945615768433, "episode_reward": 796.0417353975837, "step": 135000}
{"episode": 136.0, "batch_reward": 0.7693348990082741, "critic_loss": 15.169821014881133, "actor_loss": -70.61692984008789, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 416.280476808548, "episode_reward": 822.7814694542402, "step": 136000}
{"episode": 137.0, "batch_reward": 0.770182187139988, "critic_loss": 14.784265115261078, "actor_loss": -70.68269718933105, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.459063291549683, "episode_reward": 822.4828133454464, "step": 137000}
{"episode": 138.0, "batch_reward": 0.7700610945224762, "critic_loss": 14.929353946685792, "actor_loss": -70.65709661865235, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 457.6308579444885, "episode_reward": 887.3823871086344, "step": 138000}
{"episode": 139.0, "batch_reward": 0.7690452910661697, "critic_loss": 15.3070020236969, "actor_loss": -70.57622772216797, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 25.002931118011475, "episode_reward": 837.8113550755368, "step": 139000}
{"episode": 140.0, "batch_reward": 0.7716705560684204, "critic_loss": 17.17559105873108, "actor_loss": -70.5668621673584, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 450.1547622680664, "episode_reward": 800.8211116883838, "step": 140000}
{"episode": 141.0, "batch_reward": 0.7712051202058792, "critic_loss": 17.61914006137848, "actor_loss": -70.54716119384766, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 38.66297125816345, "episode_reward": 634.7860102664326, "step": 141000}
{"episode": 142.0, "batch_reward": 0.7681832267045975, "critic_loss": 21.008508900642394, "actor_loss": -69.6521770477295, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 429.0107305049896, "episode_reward": 671.8225911159202, "step": 142000}
{"episode": 143.0, "batch_reward": 0.7678876208662987, "critic_loss": 19.36759554862976, "actor_loss": -69.62688273620606, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.174891233444214, "episode_reward": 764.8581642067161, "step": 143000}
{"episode": 144.0, "batch_reward": 0.7686571645736694, "critic_loss": 17.722239894390107, "actor_loss": -69.6945266418457, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 442.7664301395416, "episode_reward": 701.4810296182604, "step": 144000}
{"episode": 145.0, "batch_reward": 0.7686083853244782, "critic_loss": 16.011396655082702, "actor_loss": -69.7173936920166, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.3746657371521, "episode_reward": 759.8385457610382, "step": 145000}
{"episode": 146.0, "batch_reward": 0.7703052726387978, "critic_loss": 15.577243814468384, "actor_loss": -69.41980226135254, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 434.4688937664032, "episode_reward": 765.6465168830863, "step": 146000}
{"episode": 147.0, "batch_reward": 0.769475896537304, "critic_loss": 16.19932029771805, "actor_loss": -69.38792427062988, "actor_target_entropy": -6.0, "alpha_value": 0.003891123779543812, "duration": 20.066903352737427, "episode_reward": 561.9308460200808, "step": 147000}
