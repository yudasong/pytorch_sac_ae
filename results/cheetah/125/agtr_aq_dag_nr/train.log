{"episode": 1.0, "duration": 17.913553476333618, "episode_reward": 7.579367547095394, "step": 1000}
{"episode": 2.0, "duration": 1.5731689929962158, "episode_reward": 587.3438790414032, "step": 2000}
{"episode": 3.0, "batch_reward": 0.31007831972732114, "critic_loss": 0.18102179266942187, "actor_loss": -48.79773389610971, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230756, "duration": 82.16426849365234, "episode_reward": 529.0950558507425, "step": 3000}
{"episode": 4.0, "batch_reward": 0.3665535672903061, "critic_loss": 0.2945448866486549, "actor_loss": -51.146661239624024, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.389270544052124, "episode_reward": 427.932674631393, "step": 4000}
{"episode": 5.0, "batch_reward": 0.3777279311418533, "critic_loss": 0.3514668506681919, "actor_loss": -51.51151531982422, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.679657697677612, "episode_reward": 375.817261406543, "step": 5000}
{"episode": 6.0, "batch_reward": 0.37861960086226465, "critic_loss": 0.38117865881323815, "actor_loss": -51.13159828186035, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.220937967300415, "episode_reward": 322.41362949006236, "step": 6000}
{"episode": 7.0, "batch_reward": 0.37352358120679857, "critic_loss": 0.3907268575280905, "actor_loss": -49.62868235778809, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.259454011917114, "episode_reward": 464.3760405164066, "step": 7000}
{"episode": 8.0, "batch_reward": 0.3860623341500759, "critic_loss": 0.5047659239470959, "actor_loss": -50.48042009735107, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.46654224395752, "episode_reward": 431.7851634167991, "step": 8000}
{"episode": 9.0, "batch_reward": 0.3963142838478088, "critic_loss": 0.5349461013376713, "actor_loss": -51.1894324798584, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.317540407180786, "episode_reward": 535.9157192085773, "step": 9000}
{"episode": 10.0, "batch_reward": 0.4000908409953117, "critic_loss": 0.6286590758264065, "actor_loss": -44.34528595733643, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 5081.097180843353, "episode_reward": 169.03229787895674, "step": 10000}
{"episode": 11.0, "batch_reward": 0.37926222145557403, "critic_loss": 0.6317774499058724, "actor_loss": -41.83844880676269, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 44.63059854507446, "episode_reward": 170.53565406451003, "step": 11000}
{"episode": 12.0, "batch_reward": 0.36588488081097603, "critic_loss": 0.7485517257153987, "actor_loss": -37.62791481781006, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 569.4660410881042, "episode_reward": 449.3898098494818, "step": 12000}
{"episode": 13.0, "batch_reward": 0.3748079307973385, "critic_loss": 0.825436676621437, "actor_loss": -38.3585562210083, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.665857076644897, "episode_reward": 513.123075626467, "step": 13000}
{"episode": 14.0, "batch_reward": 0.38691171142458913, "critic_loss": 0.8755291052460671, "actor_loss": -37.40167474365234, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 565.6192104816437, "episode_reward": 457.9100026248476, "step": 14000}
{"episode": 15.0, "batch_reward": 0.3924654434323311, "critic_loss": 0.797348780721426, "actor_loss": -37.72879168701172, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.4115788936615, "episode_reward": 558.4993299514224, "step": 15000}
{"episode": 16.0, "batch_reward": 0.4015796545743942, "critic_loss": 0.7174385969638825, "actor_loss": -37.26591873550415, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 585.4959254264832, "episode_reward": 511.55509339124455, "step": 16000}
{"episode": 17.0, "batch_reward": 0.4090091643333435, "critic_loss": 0.6797961044013501, "actor_loss": -37.93813774871826, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 31.207693338394165, "episode_reward": 497.1169501654363, "step": 17000}
{"episode": 18.0, "batch_reward": 0.41416414293646814, "critic_loss": 0.7045439424216747, "actor_loss": -37.39633863067627, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 571.6725339889526, "episode_reward": 522.4879369111544, "step": 18000}
{"episode": 19.0, "batch_reward": 0.4194259876310825, "critic_loss": 0.6854435823261738, "actor_loss": -38.010346534729, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.535953044891357, "episode_reward": 553.2467011546273, "step": 19000}
{"episode": 20.0, "batch_reward": 0.42855480101704596, "critic_loss": 0.7111595962941647, "actor_loss": -38.475761604309085, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 551.2578599452972, "episode_reward": 556.2669300956708, "step": 20000}
{"episode": 21.0, "batch_reward": 0.4341547592580318, "critic_loss": 0.7151271625459195, "actor_loss": -39.05941532897949, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 44.23624873161316, "episode_reward": 514.3138109435374, "step": 21000}
{"episode": 22.0, "batch_reward": 0.4359249300956726, "critic_loss": 0.702177813500166, "actor_loss": -38.97268152618408, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 568.8815915584564, "episode_reward": 482.24453199277315, "step": 22000}
{"episode": 23.0, "batch_reward": 0.4385888835191727, "critic_loss": 0.7027627237141132, "actor_loss": -39.490953987121586, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.465335845947266, "episode_reward": 533.683520877931, "step": 23000}
{"episode": 24.0, "batch_reward": 0.44349934461712837, "critic_loss": 0.7334564486443996, "actor_loss": -39.54537261962891, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 558.0749626159668, "episode_reward": 548.9919715312362, "step": 24000}
{"episode": 25.0, "batch_reward": 0.4486799209713936, "critic_loss": 0.7629773476421833, "actor_loss": -40.174399871826175, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.302699089050293, "episode_reward": 602.1539674576842, "step": 25000}
{"episode": 26.0, "batch_reward": 0.4530101816654205, "critic_loss": 0.8115891554057598, "actor_loss": -39.70897857666016, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 555.7498300075531, "episode_reward": 522.6780794378762, "step": 26000}
{"episode": 27.0, "batch_reward": 0.4559354566037655, "critic_loss": 0.8045243551731109, "actor_loss": -40.07961318969726, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.11646866798401, "episode_reward": 541.967563639366, "step": 27000}
{"episode": 28.0, "batch_reward": 0.4589687527120113, "critic_loss": 0.8063877450227738, "actor_loss": -39.57464347076416, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 572.0684995651245, "episode_reward": 532.0314904225976, "step": 28000}
{"episode": 29.0, "batch_reward": 0.4624838777780533, "critic_loss": 0.862143331617117, "actor_loss": -39.819214225769045, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.518354654312134, "episode_reward": 566.2188962638736, "step": 29000}
{"episode": 30.0, "batch_reward": 0.4652652135193348, "critic_loss": 0.941187707066536, "actor_loss": -39.922962783813475, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 536.2689044475555, "episode_reward": 541.1529746171772, "step": 30000}
{"episode": 31.0, "batch_reward": 0.4670378256142139, "critic_loss": 0.9870575114488601, "actor_loss": -40.319642707824705, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 44.82088541984558, "episode_reward": 490.5741800394649, "step": 31000}
{"episode": 32.0, "batch_reward": 0.46816510102152825, "critic_loss": 1.004214532315731, "actor_loss": -40.116860733032226, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 569.3402233123779, "episode_reward": 512.7180152955673, "step": 32000}
{"episode": 33.0, "batch_reward": 0.4689473828673363, "critic_loss": 1.0701888159513473, "actor_loss": -40.34767280578613, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.35612416267395, "episode_reward": 507.73679076641986, "step": 33000}
{"episode": 34.0, "batch_reward": 0.47164484310150145, "critic_loss": 1.1882596673369408, "actor_loss": -40.11654296875, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 581.037394285202, "episode_reward": 498.7392827876521, "step": 34000}
{"episode": 35.0, "batch_reward": 0.47174949714541436, "critic_loss": 1.2786631811857223, "actor_loss": -40.19240948486328, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 29.55184245109558, "episode_reward": 491.5686167417278, "step": 35000}
{"episode": 36.0, "batch_reward": 0.47206919953227044, "critic_loss": 1.3151711337566376, "actor_loss": -40.307053833007814, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 581.5798213481903, "episode_reward": 534.389698777397, "step": 36000}
{"episode": 37.0, "batch_reward": 0.471991652071476, "critic_loss": 1.4041851912140846, "actor_loss": -40.21174623870849, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.24814796447754, "episode_reward": 205.9099406520268, "step": 37000}
{"episode": 38.0, "batch_reward": 0.4662540240585804, "critic_loss": 1.4918387114405631, "actor_loss": -39.29732281494141, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 569.0863101482391, "episode_reward": 486.836543403692, "step": 38000}
{"episode": 39.0, "batch_reward": 0.4671312009394169, "critic_loss": 1.5336176550984382, "actor_loss": -39.29222705078125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.71699357032776, "episode_reward": 501.7217443921723, "step": 39000}
{"episode": 40.0, "batch_reward": 0.4680766859948635, "critic_loss": 1.6268278607726097, "actor_loss": -39.29222135162353, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 568.7671077251434, "episode_reward": 509.60164012996427, "step": 40000}
{"episode": 41.0, "batch_reward": 0.4694912973046303, "critic_loss": 1.7248595774173736, "actor_loss": -39.46888750457764, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 45.20434331893921, "episode_reward": 546.9584454834281, "step": 41000}
{"episode": 42.0, "batch_reward": 0.47132213070988654, "critic_loss": 1.7191347587108612, "actor_loss": -39.89583281707764, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 563.0703618526459, "episode_reward": 525.3116519293741, "step": 42000}
{"episode": 43.0, "batch_reward": 0.47320299968123436, "critic_loss": 1.7363748517036437, "actor_loss": -40.04409951782227, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.84147810935974, "episode_reward": 565.0784902968737, "step": 43000}
{"episode": 44.0, "batch_reward": 0.4750335504412651, "critic_loss": 1.780124364733696, "actor_loss": -40.053445434570314, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 566.8227028846741, "episode_reward": 560.4064653965193, "step": 44000}
{"episode": 45.0, "batch_reward": 0.4742216084599495, "critic_loss": 1.8273797036409378, "actor_loss": -40.0050514755249, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.628419876098633, "episode_reward": 540.7177312862991, "step": 45000}
{"episode": 46.0, "batch_reward": 0.4768120809495449, "critic_loss": 1.8792332034111023, "actor_loss": -40.29572565460205, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 577.8182551860809, "episode_reward": 552.2114550824775, "step": 46000}
{"episode": 47.0, "batch_reward": 0.47889174658060074, "critic_loss": 1.9190302441120148, "actor_loss": -40.59716006469726, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.853081703186035, "episode_reward": 507.07574954425934, "step": 47000}
{"episode": 48.0, "batch_reward": 0.48053434285521507, "critic_loss": 1.9605343842506409, "actor_loss": -40.88852775573731, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 557.5668044090271, "episode_reward": 545.6028643597624, "step": 48000}
{"episode": 49.0, "batch_reward": 0.48199771988391876, "critic_loss": 1.996677424788475, "actor_loss": -41.1432523651123, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.291709899902344, "episode_reward": 591.7980731637997, "step": 49000}
{"episode": 50.0, "batch_reward": 0.48350582814216614, "critic_loss": 2.0539715275764467, "actor_loss": -41.70794984436035, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 566.299036026001, "episode_reward": 549.3409339482529, "step": 50000}
{"episode": 51.0, "batch_reward": 0.4842945869266987, "critic_loss": 2.163958316683769, "actor_loss": -41.76967304992676, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 45.06023383140564, "episode_reward": 547.0344991590888, "step": 51000}
{"episode": 52.0, "batch_reward": 0.4859938644170761, "critic_loss": 2.1489681017398836, "actor_loss": -42.43833953857422, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 556.6410920619965, "episode_reward": 526.4411295063537, "step": 52000}
{"episode": 53.0, "batch_reward": 0.4861875423491001, "critic_loss": 2.166167407274246, "actor_loss": -42.46188296508789, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.60151219367981, "episode_reward": 500.23219080410166, "step": 53000}
{"episode": 54.0, "batch_reward": 0.48691071245074274, "critic_loss": 2.1582690078020095, "actor_loss": -42.583580345153806, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 567.0361709594727, "episode_reward": 548.8876929053944, "step": 54000}
{"episode": 55.0, "batch_reward": 0.48823649445176126, "critic_loss": 2.0679569457769396, "actor_loss": -42.79468222808838, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.260850429534912, "episode_reward": 566.0160550153282, "step": 55000}
{"episode": 56.0, "batch_reward": 0.49018140068650246, "critic_loss": 2.0165784442424775, "actor_loss": -43.01557540130615, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 581.0612642765045, "episode_reward": 519.450244971986, "step": 56000}
{"episode": 57.0, "batch_reward": 0.48980593073368073, "critic_loss": 1.9968632081747055, "actor_loss": -43.16812407684326, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.948272943496704, "episode_reward": 502.72705030635365, "step": 57000}
{"episode": 58.0, "batch_reward": 0.49039631193876265, "critic_loss": 1.9495415147542954, "actor_loss": -43.13242421722412, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 578.8154964447021, "episode_reward": 506.30651156021713, "step": 58000}
{"episode": 59.0, "batch_reward": 0.49065033397078517, "critic_loss": 1.963226224064827, "actor_loss": -43.21874098968506, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.788869857788086, "episode_reward": 459.1377950735208, "step": 59000}
{"episode": 60.0, "batch_reward": 0.4899321759343147, "critic_loss": 1.9935227262973785, "actor_loss": -43.18313230895996, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 579.5739769935608, "episode_reward": 501.7931384819867, "step": 60000}
{"episode": 61.0, "batch_reward": 0.4907939392030239, "critic_loss": 2.032162744879723, "actor_loss": -43.33455503845215, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 45.879621505737305, "episode_reward": 478.70369466322535, "step": 61000}
{"episode": 62.0, "batch_reward": 0.4898635147213936, "critic_loss": 1.9911731044650078, "actor_loss": -42.923881103515626, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 552.3494036197662, "episode_reward": 518.7828561560679, "step": 62000}
{"episode": 63.0, "batch_reward": 0.4899651912152767, "critic_loss": 2.002017424464226, "actor_loss": -42.91565217590332, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.545690774917603, "episode_reward": 544.2146908995903, "step": 63000}
{"episode": 64.0, "batch_reward": 0.49069248351454736, "critic_loss": 2.1305159875154493, "actor_loss": -42.81698384857178, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 587.4705407619476, "episode_reward": 469.71767228574816, "step": 64000}
{"episode": 65.0, "batch_reward": 0.4903864471614361, "critic_loss": 2.1390359908342362, "actor_loss": -42.98587142944336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.64410948753357, "episode_reward": 507.45372910265536, "step": 65000}
{"episode": 66.0, "batch_reward": 0.4904151326417923, "critic_loss": 2.231126999616623, "actor_loss": -43.02253659057617, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 549.5838084220886, "episode_reward": 484.431029792933, "step": 66000}
{"episode": 67.0, "batch_reward": 0.4907984075844288, "critic_loss": 2.262055664420128, "actor_loss": -43.082596061706546, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.987370014190674, "episode_reward": 483.1932688445918, "step": 67000}
{"episode": 68.0, "batch_reward": 0.49158833533525464, "critic_loss": 2.2538483035564423, "actor_loss": -43.12707638549805, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 577.2719113826752, "episode_reward": 537.5281286668057, "step": 68000}
{"episode": 69.0, "batch_reward": 0.49062752187252046, "critic_loss": 2.2458234124183654, "actor_loss": -43.11050720214844, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.117053508758545, "episode_reward": 469.4931413624198, "step": 69000}
{"episode": 70.0, "batch_reward": 0.4921609897017479, "critic_loss": 2.307285725593567, "actor_loss": -43.59709730529785, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 559.3772552013397, "episode_reward": 559.7015643524394, "step": 70000}
{"episode": 71.0, "batch_reward": 0.4924014893174171, "critic_loss": 2.338506860733032, "actor_loss": -43.66925473022461, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 46.451332330703735, "episode_reward": 555.6708741099756, "step": 71000}
{"episode": 72.0, "batch_reward": 0.492366270005703, "critic_loss": 2.4198635479211807, "actor_loss": -44.037216148376466, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 565.3505966663361, "episode_reward": 517.8562899310361, "step": 72000}
{"episode": 73.0, "batch_reward": 0.49265916901826856, "critic_loss": 2.5797659769058225, "actor_loss": -44.12606436920166, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.89082646369934, "episode_reward": 514.0035198677933, "step": 73000}
{"episode": 74.0, "batch_reward": 0.49373129159212115, "critic_loss": 2.5867502199411394, "actor_loss": -44.203948890686036, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 539.492317199707, "episode_reward": 567.0135318931978, "step": 74000}
{"episode": 75.0, "batch_reward": 0.4955801972150803, "critic_loss": 2.7917262070178985, "actor_loss": -44.422659439086914, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 25.435394287109375, "episode_reward": 562.1963291938977, "step": 75000}
{"episode": 76.0, "batch_reward": 0.49581858575344084, "critic_loss": 2.873190669417381, "actor_loss": -43.587750259399414, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 494.84012961387634, "episode_reward": 549.0288919856309, "step": 76000}
{"episode": 77.0, "batch_reward": 0.4967950137257576, "critic_loss": 2.926795297265053, "actor_loss": -43.52223677825928, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.86668610572815, "episode_reward": 525.3863687371742, "step": 77000}
{"episode": 78.0, "batch_reward": 0.49710485365986823, "critic_loss": 3.0142683514356614, "actor_loss": -43.170036468505856, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 517.4353024959564, "episode_reward": 520.5521849344002, "step": 78000}
{"episode": 79.0, "batch_reward": 0.4979167658984661, "critic_loss": 3.12741306746006, "actor_loss": -43.23012107849121, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.274787664413452, "episode_reward": 549.0392587830386, "step": 79000}
{"episode": 80.0, "batch_reward": 0.4971437061727047, "critic_loss": 3.3285085279941558, "actor_loss": -42.57377487945557, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 472.3002178668976, "episode_reward": 508.7270884365335, "step": 80000}
{"episode": 81.0, "batch_reward": 0.4980540700554848, "critic_loss": 3.7316617184877394, "actor_loss": -42.68048609161377, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 44.6130154132843, "episode_reward": 503.9798394435778, "step": 81000}
{"episode": 82.0, "batch_reward": 0.49775976353883744, "critic_loss": 4.064515978336334, "actor_loss": -41.833309623718264, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 537.3546307086945, "episode_reward": 469.7554446472981, "step": 82000}
{"episode": 83.0, "batch_reward": 0.49788247334957125, "critic_loss": 3.9905083459615707, "actor_loss": -41.910809028625486, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.805524110794067, "episode_reward": 467.0763676514441, "step": 83000}
{"episode": 84.0, "batch_reward": 0.49637573131918905, "critic_loss": 4.040273177146911, "actor_loss": -41.65478144836426, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 518.1403267383575, "episode_reward": 497.16370704208435, "step": 84000}
{"episode": 85.0, "batch_reward": 0.4979985793530941, "critic_loss": 3.8756358740329744, "actor_loss": -41.78689743041992, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.820586681365967, "episode_reward": 510.28503750808875, "step": 85000}
{"episode": 86.0, "batch_reward": 0.49781224605441093, "critic_loss": 3.7338395057916642, "actor_loss": -41.690308654785156, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 469.35581278800964, "episode_reward": 533.4926578462948, "step": 86000}
{"episode": 87.0, "batch_reward": 0.4976741251051426, "critic_loss": 3.6791513075828552, "actor_loss": -41.700112236022946, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.22170066833496, "episode_reward": 506.2993016983839, "step": 87000}
{"episode": 88.0, "batch_reward": 0.4980084120929241, "critic_loss": 3.646917696475983, "actor_loss": -41.859639144897464, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 500.377525806427, "episode_reward": 514.9098819415591, "step": 88000}
{"episode": 89.0, "batch_reward": 0.49819797816872596, "critic_loss": 3.3415568243265152, "actor_loss": -41.9700647354126, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.46836566925049, "episode_reward": 525.5902128142324, "step": 89000}
{"episode": 90.0, "batch_reward": 0.4988436323404312, "critic_loss": 3.168435038566589, "actor_loss": -42.38398241424561, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 527.6811158657074, "episode_reward": 523.8887571367572, "step": 90000}
{"episode": 91.0, "batch_reward": 0.49853524631261825, "critic_loss": 3.0719359673261644, "actor_loss": -42.37062344360351, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 40.5026159286499, "episode_reward": 524.7745167559121, "step": 91000}
{"episode": 92.0, "batch_reward": 0.49858357605338094, "critic_loss": 2.9213734200000765, "actor_loss": -42.41939707946777, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 521.1824460029602, "episode_reward": 504.9986964408347, "step": 92000}
{"episode": 93.0, "batch_reward": 0.4991901845932007, "critic_loss": 2.7906599330902098, "actor_loss": -42.461090675354, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 25.979405879974365, "episode_reward": 514.8599773363544, "step": 93000}
{"episode": 94.0, "batch_reward": 0.4994746354520321, "critic_loss": 2.66741787815094, "actor_loss": -42.50532279205322, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 488.1483426094055, "episode_reward": 510.8422612560171, "step": 94000}
{"episode": 95.0, "batch_reward": 0.49853219106793406, "critic_loss": 2.5662875328063963, "actor_loss": -42.423946113586425, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.48662543296814, "episode_reward": 534.1414603706559, "step": 95000}
{"episode": 96.0, "batch_reward": 0.499251084446907, "critic_loss": 2.605625075817108, "actor_loss": -42.19626848602295, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 507.2681305408478, "episode_reward": 538.7959837702491, "step": 96000}
{"episode": 97.0, "batch_reward": 0.5001920619010926, "critic_loss": 2.395275907993317, "actor_loss": -42.3264038772583, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.827113151550293, "episode_reward": 463.4086755045224, "step": 97000}
{"episode": 98.0, "batch_reward": 0.5004471970498562, "critic_loss": 2.5090119466781617, "actor_loss": -42.684453048706054, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 514.5049366950989, "episode_reward": 498.8626888885433, "step": 98000}
{"episode": 99.0, "batch_reward": 0.49992682713270187, "critic_loss": 2.4534526069164277, "actor_loss": -42.64264572143555, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.93746829032898, "episode_reward": 536.1242128378417, "step": 99000}
{"episode": 100.0, "batch_reward": 0.500153306722641, "critic_loss": 2.3801645098924635, "actor_loss": -42.756630477905276, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 488.59754395484924, "episode_reward": 539.7242388264443, "step": 100000}
{"episode": 101.0, "batch_reward": 0.5005255626440048, "critic_loss": 2.319531518816948, "actor_loss": -42.79041850280762, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 43.30151081085205, "episode_reward": 568.2952873022173, "step": 101000}
{"episode": 102.0, "batch_reward": 0.5005482345223426, "critic_loss": 2.303395815253258, "actor_loss": -42.76409592437744, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 504.9411578178406, "episode_reward": 530.599859934513, "step": 102000}
{"episode": 103.0, "batch_reward": 0.5014300439357757, "critic_loss": 2.277942933678627, "actor_loss": -42.82155951690674, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.923065185546875, "episode_reward": 531.9729334630124, "step": 103000}
{"episode": 104.0, "batch_reward": 0.5016967715620995, "critic_loss": 2.1158065152168275, "actor_loss": -43.11050909423828, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 495.98482751846313, "episode_reward": 529.3281895922496, "step": 104000}
{"episode": 105.0, "batch_reward": 0.5019448412358761, "critic_loss": 2.207565216064453, "actor_loss": -43.11120355987549, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.543912410736084, "episode_reward": 548.2666523595789, "step": 105000}
{"episode": 106.0, "batch_reward": 0.5034173547327518, "critic_loss": 2.3823622227311136, "actor_loss": -43.200337509155275, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 479.7108430862427, "episode_reward": 569.8156349988624, "step": 106000}
{"episode": 107.0, "batch_reward": 0.5032610585093498, "critic_loss": 2.172192800760269, "actor_loss": -43.34013706970215, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.198611974716187, "episode_reward": 577.719128093429, "step": 107000}
{"episode": 108.0, "batch_reward": 0.5040185963213444, "critic_loss": 2.1833891077041625, "actor_loss": -43.48418852233887, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 501.7300798892975, "episode_reward": 570.5917528155522, "step": 108000}
{"episode": 109.0, "batch_reward": 0.5040611374974251, "critic_loss": 2.201332263827324, "actor_loss": -43.510962867736815, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.4423348903656, "episode_reward": 561.3083696870676, "step": 109000}
{"episode": 110.0, "batch_reward": 0.5049236971437931, "critic_loss": 2.423130233645439, "actor_loss": -43.730044021606446, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 518.581752538681, "episode_reward": 556.0363817105401, "step": 110000}
{"episode": 111.0, "batch_reward": 0.5053217141330242, "critic_loss": 2.562469425916672, "actor_loss": -43.77299257659912, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 44.8048415184021, "episode_reward": 539.5921344609851, "step": 111000}
{"episode": 112.0, "batch_reward": 0.5064941405057907, "critic_loss": 2.750520579814911, "actor_loss": -44.03368478393555, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 512.5672433376312, "episode_reward": 563.7961762982628, "step": 112000}
{"episode": 113.0, "batch_reward": 0.5060453695952892, "critic_loss": 2.797434525847435, "actor_loss": -43.98585697174072, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 21.58555769920349, "episode_reward": 539.6847244110213, "step": 113000}
{"episode": 114.0, "batch_reward": 0.5069625017046928, "critic_loss": 2.7540948026180265, "actor_loss": -44.00252575683594, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 490.0229346752167, "episode_reward": 542.6122238658144, "step": 114000}
{"episode": 115.0, "batch_reward": 0.5076844167411327, "critic_loss": 2.7754578758478163, "actor_loss": -44.096624320983885, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 24.65701150894165, "episode_reward": 540.3397025670743, "step": 115000}
{"episode": 116.0, "batch_reward": 0.5071423134505749, "critic_loss": 2.692276217341423, "actor_loss": -44.241822677612305, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 499.6148684024811, "episode_reward": 551.0651703253001, "step": 116000}
{"episode": 117.0, "batch_reward": 0.5072141239345074, "critic_loss": 2.443315199136734, "actor_loss": -44.341654945373534, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 20.82711148262024, "episode_reward": 541.028441113678, "step": 117000}
{"episode": 118.0, "batch_reward": 0.5079000876545906, "critic_loss": 2.3478130729198456, "actor_loss": -44.54596272277832, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 504.2785303592682, "episode_reward": 530.2355911103109, "step": 118000}
{"episode": 119.0, "batch_reward": 0.5084839287102223, "critic_loss": 2.2516655654907227, "actor_loss": -44.662690879821774, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.263278245925903, "episode_reward": 538.2856439837751, "step": 119000}
{"episode": 120.0, "batch_reward": 0.5079201916754246, "critic_loss": 2.1680409798026083, "actor_loss": -44.620821517944336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 496.4430990219116, "episode_reward": 534.7706288801768, "step": 120000}
{"episode": 121.0, "batch_reward": 0.5086227707266807, "critic_loss": 2.01234193444252, "actor_loss": -44.673253105163575, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 37.938512563705444, "episode_reward": 568.3597545749174, "step": 121000}
{"episode": 122.0, "batch_reward": 0.5097043992877006, "critic_loss": 2.0162461322546004, "actor_loss": -44.84614814758301, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 487.6898057460785, "episode_reward": 558.2212221378367, "step": 122000}
{"episode": 123.0, "batch_reward": 0.5096296153366565, "critic_loss": 1.9070909804701806, "actor_loss": -44.88226458740235, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.02095627784729, "episode_reward": 570.0334477049734, "step": 123000}
{"episode": 124.0, "batch_reward": 0.5097371643483639, "critic_loss": 1.8437963009476661, "actor_loss": -44.9761302947998, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 469.0696771144867, "episode_reward": 576.2503914690532, "step": 124000}
{"episode": 125.0, "batch_reward": 0.5107103728950023, "critic_loss": 1.8975160103440285, "actor_loss": -45.15649125671387, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 26.733345985412598, "episode_reward": 591.8675934282198, "step": 125000}
{"episode": 126.0, "batch_reward": 0.511282432615757, "critic_loss": 1.7425539143681525, "actor_loss": -45.285448348999026, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 499.95958280563354, "episode_reward": 559.0320713412418, "step": 126000}
{"episode": 127.0, "batch_reward": 0.5109498650431633, "critic_loss": 1.631803641319275, "actor_loss": -45.37378232574463, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 22.496302127838135, "episode_reward": 558.9957665424309, "step": 127000}
{"episode": 128.0, "batch_reward": 0.512166403144598, "critic_loss": 1.6141536363363267, "actor_loss": -45.47566124725342, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 485.3056483268738, "episode_reward": 589.351946265318, "step": 128000}
{"episode": 129.0, "batch_reward": 0.5128491831719876, "critic_loss": 1.6582961618900298, "actor_loss": -45.56076205444336, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 23.024818897247314, "episode_reward": 594.1283123881354, "step": 129000}
{"episode": 130.0, "batch_reward": 0.512767704308033, "critic_loss": 1.7075526638031007, "actor_loss": -45.35579836273193, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 461.11783742904663, "episode_reward": 552.6438549939427, "step": 130000}
{"episode": 131.0, "batch_reward": 0.5131067511439323, "critic_loss": 1.7169016605615617, "actor_loss": -45.41002519226074, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 43.48019504547119, "episode_reward": 580.4422070717086, "step": 131000}
{"episode": 132.0, "batch_reward": 0.5143974210023881, "critic_loss": 1.6877294108867644, "actor_loss": -45.526662994384765, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 487.80763125419617, "episode_reward": 577.4163153080815, "step": 132000}
{"episode": 133.0, "batch_reward": 0.5145281362831593, "critic_loss": 1.7888099252581597, "actor_loss": -45.560407699584964, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.956066131591797, "episode_reward": 579.4109395089399, "step": 133000}
{"episode": 134.0, "batch_reward": 0.5146179207265377, "critic_loss": 1.646398913025856, "actor_loss": -45.84394602203369, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 719.4366481304169, "episode_reward": 596.9871639970382, "step": 134000}
{"episode": 135.0, "batch_reward": 0.5156043074727058, "critic_loss": 1.6887701726555824, "actor_loss": -45.98980517578125, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.06479001045227, "episode_reward": 573.7788994352636, "step": 135000}
{"episode": 136.0, "batch_reward": 0.516342735171318, "critic_loss": 1.6783389736413956, "actor_loss": -45.903988685607914, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 732.9069707393646, "episode_reward": 568.9603851810346, "step": 136000}
{"episode": 137.0, "batch_reward": 0.5172182271778584, "critic_loss": 1.7761989718079567, "actor_loss": -46.06120566558838, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 29.06639790534973, "episode_reward": 584.6271289657045, "step": 137000}
{"episode": 138.0, "batch_reward": 0.5173241435587406, "critic_loss": 1.7625286132097244, "actor_loss": -46.42703102111816, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 722.7127487659454, "episode_reward": 598.380227459851, "step": 138000}
{"episode": 139.0, "batch_reward": 0.5171823851466179, "critic_loss": 1.7993830330371856, "actor_loss": -46.45959033966064, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 29.481643199920654, "episode_reward": 526.662384134312, "step": 139000}
{"episode": 140.0, "batch_reward": 0.518395267277956, "critic_loss": 1.9368863759040833, "actor_loss": -46.728528450012206, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 725.0814807415009, "episode_reward": 568.7518804098269, "step": 140000}
{"episode": 141.0, "batch_reward": 0.5175883026123047, "critic_loss": 1.8985811682939528, "actor_loss": -46.72329558563232, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 45.68988871574402, "episode_reward": 569.2638341634382, "step": 141000}
{"episode": 142.0, "batch_reward": 0.5176101599931717, "critic_loss": 1.9328381058573723, "actor_loss": -46.52191281890869, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 693.3022725582123, "episode_reward": 571.6855579463371, "step": 142000}
{"episode": 143.0, "batch_reward": 0.5190561411082745, "critic_loss": 1.9530058662295342, "actor_loss": -46.68471511840821, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 28.75815987586975, "episode_reward": 571.4368481665626, "step": 143000}
{"episode": 144.0, "batch_reward": 0.5185783076286316, "critic_loss": 1.9807023760080338, "actor_loss": -46.575661056518555, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 713.1481230258942, "episode_reward": 559.2513932372709, "step": 144000}
{"episode": 145.0, "batch_reward": 0.5182898975610734, "critic_loss": 1.9708714972138406, "actor_loss": -46.59402256774902, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 29.328172206878662, "episode_reward": 556.1163928883092, "step": 145000}
{"episode": 146.0, "batch_reward": 0.5191898077726365, "critic_loss": 1.9717436327338218, "actor_loss": -46.09547143554688, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 697.8653991222382, "episode_reward": 585.2819240121588, "step": 146000}
{"episode": 147.0, "batch_reward": 0.5207606291770935, "critic_loss": 2.0001517152786255, "actor_loss": -46.19929074859619, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.486708164215088, "episode_reward": 598.7706320323689, "step": 147000}
{"episode": 148.0, "batch_reward": 0.5204391038417816, "critic_loss": 2.053271131813526, "actor_loss": -46.00157942199707, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 714.5057170391083, "episode_reward": 601.7734449216985, "step": 148000}
{"episode": 149.0, "batch_reward": 0.5207535744905472, "critic_loss": 2.238841777026653, "actor_loss": -46.09254974365234, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "duration": 27.67245125770569, "episode_reward": 606.8985009394737, "step": 149000}
{"episode": 150.0, "batch_reward": 0.5215676091313363, "critic_loss": 2.240600346982479, "actor_loss": -46.1014242477417, "actor_target_entropy": -6.0, "alpha_value": 0.008529113283230454, "step": 150000}
